[INFO 2017-06-28 23:36:23,380 main.py:175] Namespace(batch_size=32, display=False, flow_dir='flow', flow_video_dir='flow-video', flow_video_fps=1, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=4, num_channel=3, num_inputs=2, save_dir='./model', test=False, test_dir='/home/yi/Downloads/mpii-test-64', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='/home/yi/Downloads/mpii-64', train_epoch=100000)
[INFO 2017-06-28 23:36:28,203 main.py:57] epoch 0, training loss: 44957.91, average training loss: 44957.91, base loss: 22071.15
[INFO 2017-06-28 23:36:30,368 main.py:57] epoch 1, training loss: 37102.17, average training loss: 41030.04, base loss: 20918.76
[INFO 2017-06-28 23:36:32,578 main.py:57] epoch 2, training loss: 34114.63, average training loss: 38724.90, base loss: 21428.57
[INFO 2017-06-28 23:36:34,836 main.py:57] epoch 3, training loss: 31415.31, average training loss: 36897.51, base loss: 22095.99
[INFO 2017-06-28 23:36:36,915 main.py:57] epoch 4, training loss: 27665.62, average training loss: 35051.13, base loss: 22127.86
[INFO 2017-06-28 23:36:39,220 main.py:57] epoch 5, training loss: 26668.56, average training loss: 33654.03, base loss: 22067.48
[INFO 2017-06-28 23:36:41,498 main.py:57] epoch 6, training loss: 24665.34, average training loss: 32369.93, base loss: 22322.05
[INFO 2017-06-28 23:36:43,746 main.py:57] epoch 7, training loss: 25193.47, average training loss: 31472.88, base loss: 22541.62
[INFO 2017-06-28 23:36:46,016 main.py:57] epoch 8, training loss: 23975.32, average training loss: 30639.82, base loss: 22586.96
[INFO 2017-06-28 23:36:48,255 main.py:57] epoch 9, training loss: 21353.76, average training loss: 29711.21, base loss: 22498.40
[INFO 2017-06-28 23:36:50,519 main.py:57] epoch 10, training loss: 20754.85, average training loss: 28897.00, base loss: 22361.24
[INFO 2017-06-28 23:36:52,782 main.py:57] epoch 11, training loss: 22342.73, average training loss: 28350.81, base loss: 22543.32
[INFO 2017-06-28 23:36:54,964 main.py:57] epoch 12, training loss: 20771.14, average training loss: 27767.76, base loss: 22559.62
[INFO 2017-06-28 23:36:57,167 main.py:57] epoch 13, training loss: 19701.02, average training loss: 27191.56, base loss: 22607.55
[INFO 2017-06-28 23:36:59,487 main.py:57] epoch 14, training loss: 18429.88, average training loss: 26607.45, base loss: 22592.29
[INFO 2017-06-28 23:37:01,846 main.py:57] epoch 15, training loss: 18095.64, average training loss: 26075.46, base loss: 22558.78
[INFO 2017-06-28 23:37:04,223 main.py:57] epoch 16, training loss: 18092.42, average training loss: 25605.87, base loss: 22523.90
[INFO 2017-06-28 23:37:06,469 main.py:57] epoch 17, training loss: 18658.99, average training loss: 25219.93, base loss: 22569.60
[INFO 2017-06-28 23:37:08,848 main.py:57] epoch 18, training loss: 18112.15, average training loss: 24845.84, base loss: 22599.85
[INFO 2017-06-28 23:37:11,223 main.py:57] epoch 19, training loss: 16547.29, average training loss: 24430.91, base loss: 22464.98
[INFO 2017-06-28 23:37:13,417 main.py:57] epoch 20, training loss: 17379.23, average training loss: 24095.12, base loss: 22478.39
[INFO 2017-06-28 23:37:15,678 main.py:57] epoch 21, training loss: 17769.05, average training loss: 23807.57, base loss: 22541.46
[INFO 2017-06-28 23:37:17,873 main.py:57] epoch 22, training loss: 17048.19, average training loss: 23513.68, base loss: 22550.49
[INFO 2017-06-28 23:37:20,088 main.py:57] epoch 23, training loss: 15802.86, average training loss: 23192.40, base loss: 22520.55
[INFO 2017-06-28 23:37:22,295 main.py:57] epoch 24, training loss: 14306.08, average training loss: 22836.95, base loss: 22403.06
[INFO 2017-06-28 23:37:24,577 main.py:57] epoch 25, training loss: 16827.37, average training loss: 22605.81, base loss: 22422.32
[INFO 2017-06-28 23:37:26,686 main.py:57] epoch 26, training loss: 16702.45, average training loss: 22387.17, base loss: 22429.58
[INFO 2017-06-28 23:37:28,799 main.py:57] epoch 27, training loss: 16271.16, average training loss: 22168.74, base loss: 22445.23
[INFO 2017-06-28 23:37:30,948 main.py:57] epoch 28, training loss: 15718.15, average training loss: 21946.30, base loss: 22432.56
[INFO 2017-06-28 23:37:33,252 main.py:57] epoch 29, training loss: 15460.47, average training loss: 21730.11, base loss: 22417.09
[INFO 2017-06-28 23:37:35,594 main.py:57] epoch 30, training loss: 15643.79, average training loss: 21533.78, base loss: 22415.31
[INFO 2017-06-28 23:37:37,829 main.py:57] epoch 31, training loss: 13143.95, average training loss: 21271.59, base loss: 22312.09
[INFO 2017-06-28 23:37:40,076 main.py:57] epoch 32, training loss: 15459.65, average training loss: 21095.47, base loss: 22308.22
[INFO 2017-06-28 23:37:42,373 main.py:57] epoch 33, training loss: 14907.84, average training loss: 20913.48, base loss: 22275.09
[INFO 2017-06-28 23:37:44,786 main.py:57] epoch 34, training loss: 14681.50, average training loss: 20735.43, base loss: 22262.71
[INFO 2017-06-28 23:37:47,146 main.py:57] epoch 35, training loss: 14283.69, average training loss: 20556.21, base loss: 22219.77
[INFO 2017-06-28 23:37:49,321 main.py:57] epoch 36, training loss: 16007.10, average training loss: 20433.26, base loss: 22241.67
[INFO 2017-06-28 23:37:51,641 main.py:57] epoch 37, training loss: 15703.82, average training loss: 20308.80, base loss: 22279.84
[INFO 2017-06-28 23:37:53,986 main.py:57] epoch 38, training loss: 14082.07, average training loss: 20149.15, base loss: 22231.88
[INFO 2017-06-28 23:37:56,086 main.py:57] epoch 39, training loss: 16459.30, average training loss: 20056.90, base loss: 22288.55
[INFO 2017-06-28 23:37:58,260 main.py:57] epoch 40, training loss: 17858.60, average training loss: 20003.28, base loss: 22375.88
[INFO 2017-06-28 23:38:00,459 main.py:57] epoch 41, training loss: 13362.63, average training loss: 19845.17, base loss: 22317.84
[INFO 2017-06-28 23:38:02,628 main.py:57] epoch 42, training loss: 15954.71, average training loss: 19754.70, base loss: 22345.21
[INFO 2017-06-28 23:38:05,063 main.py:57] epoch 43, training loss: 13967.37, average training loss: 19623.17, base loss: 22300.63
[INFO 2017-06-28 23:38:07,238 main.py:57] epoch 44, training loss: 14945.18, average training loss: 19519.21, base loss: 22306.74
[INFO 2017-06-28 23:38:09,669 main.py:57] epoch 45, training loss: 15757.72, average training loss: 19437.44, base loss: 22336.33
[INFO 2017-06-28 23:38:12,015 main.py:57] epoch 46, training loss: 15434.08, average training loss: 19352.26, base loss: 22339.23
[INFO 2017-06-28 23:38:14,514 main.py:57] epoch 47, training loss: 13871.31, average training loss: 19238.07, base loss: 22313.76
[INFO 2017-06-28 23:38:16,916 main.py:57] epoch 48, training loss: 15736.84, average training loss: 19166.62, base loss: 22336.11
[INFO 2017-06-28 23:38:19,195 main.py:57] epoch 49, training loss: 14096.30, average training loss: 19065.21, base loss: 22312.40
[INFO 2017-06-28 23:38:21,515 main.py:57] epoch 50, training loss: 12893.66, average training loss: 18944.20, base loss: 22265.64
[INFO 2017-06-28 23:38:23,903 main.py:57] epoch 51, training loss: 15682.93, average training loss: 18881.49, base loss: 22279.12
[INFO 2017-06-28 23:38:26,267 main.py:57] epoch 52, training loss: 13545.01, average training loss: 18780.80, base loss: 22254.91
[INFO 2017-06-28 23:38:28,689 main.py:57] epoch 53, training loss: 15285.34, average training loss: 18716.07, base loss: 22268.91
[INFO 2017-06-28 23:38:31,060 main.py:57] epoch 54, training loss: 13521.29, average training loss: 18621.62, base loss: 22252.70
[INFO 2017-06-28 23:38:33,490 main.py:57] epoch 55, training loss: 14140.38, average training loss: 18541.59, base loss: 22240.22
[INFO 2017-06-28 23:38:36,000 main.py:57] epoch 56, training loss: 15467.45, average training loss: 18487.66, base loss: 22252.54
[INFO 2017-06-28 23:38:38,469 main.py:57] epoch 57, training loss: 15200.16, average training loss: 18430.98, base loss: 22257.81
[INFO 2017-06-28 23:38:40,948 main.py:57] epoch 58, training loss: 15927.77, average training loss: 18388.55, base loss: 22302.10
[INFO 2017-06-28 23:38:43,340 main.py:57] epoch 59, training loss: 14125.93, average training loss: 18317.51, base loss: 22291.17
[INFO 2017-06-28 23:38:45,752 main.py:57] epoch 60, training loss: 15354.41, average training loss: 18268.93, base loss: 22307.98
[INFO 2017-06-28 23:38:48,256 main.py:57] epoch 61, training loss: 14977.26, average training loss: 18215.84, base loss: 22321.22
[INFO 2017-06-28 23:38:50,868 main.py:57] epoch 62, training loss: 13402.72, average training loss: 18139.44, base loss: 22299.07
[INFO 2017-06-28 23:38:53,297 main.py:57] epoch 63, training loss: 13586.29, average training loss: 18068.30, base loss: 22283.94
[INFO 2017-06-28 23:38:55,725 main.py:57] epoch 64, training loss: 13376.41, average training loss: 17996.12, base loss: 22271.35
[INFO 2017-06-28 23:38:58,220 main.py:57] epoch 65, training loss: 12907.06, average training loss: 17919.01, base loss: 22238.61
[INFO 2017-06-28 23:39:00,711 main.py:57] epoch 66, training loss: 13400.08, average training loss: 17851.56, base loss: 22221.24
[INFO 2017-06-28 23:39:03,280 main.py:57] epoch 67, training loss: 15013.29, average training loss: 17809.83, base loss: 22248.06
[INFO 2017-06-28 23:39:05,796 main.py:57] epoch 68, training loss: 14680.95, average training loss: 17764.48, base loss: 22266.68
[INFO 2017-06-28 23:39:08,371 main.py:57] epoch 69, training loss: 14303.22, average training loss: 17715.03, base loss: 22280.06
[INFO 2017-06-28 23:39:10,808 main.py:57] epoch 70, training loss: 13818.63, average training loss: 17660.15, base loss: 22282.50
[INFO 2017-06-28 23:39:13,370 main.py:57] epoch 71, training loss: 13506.77, average training loss: 17602.47, base loss: 22285.45
[INFO 2017-06-28 23:39:15,870 main.py:57] epoch 72, training loss: 14643.30, average training loss: 17561.93, base loss: 22301.83
[INFO 2017-06-28 23:39:18,320 main.py:57] epoch 73, training loss: 14472.71, average training loss: 17520.19, base loss: 22324.31
[INFO 2017-06-28 23:39:20,840 main.py:57] epoch 74, training loss: 14073.21, average training loss: 17474.23, base loss: 22338.56
[INFO 2017-06-28 23:39:23,322 main.py:57] epoch 75, training loss: 13459.51, average training loss: 17421.40, base loss: 22321.00
[INFO 2017-06-28 23:39:25,983 main.py:57] epoch 76, training loss: 13608.52, average training loss: 17371.88, base loss: 22324.69
[INFO 2017-06-28 23:39:28,723 main.py:57] epoch 77, training loss: 12600.86, average training loss: 17310.72, base loss: 22303.91
[INFO 2017-06-28 23:39:31,268 main.py:57] epoch 78, training loss: 11952.60, average training loss: 17242.89, base loss: 22274.38
[INFO 2017-06-28 23:39:33,646 main.py:57] epoch 79, training loss: 12551.99, average training loss: 17184.26, base loss: 22256.39
[INFO 2017-06-28 23:39:36,147 main.py:57] epoch 80, training loss: 12741.42, average training loss: 17129.41, base loss: 22246.40
[INFO 2017-06-28 23:39:38,718 main.py:57] epoch 81, training loss: 12374.56, average training loss: 17071.42, base loss: 22244.74
[INFO 2017-06-28 23:39:41,266 main.py:57] epoch 82, training loss: 15363.95, average training loss: 17050.85, base loss: 22269.68
[INFO 2017-06-28 23:39:43,936 main.py:57] epoch 83, training loss: 12994.16, average training loss: 17002.55, base loss: 22271.70
[INFO 2017-06-28 23:39:46,396 main.py:57] epoch 84, training loss: 12252.82, average training loss: 16946.67, base loss: 22239.26
[INFO 2017-06-28 23:39:48,924 main.py:57] epoch 85, training loss: 13047.37, average training loss: 16901.33, base loss: 22222.20
[INFO 2017-06-28 23:39:51,539 main.py:57] epoch 86, training loss: 14103.12, average training loss: 16869.17, base loss: 22237.42
[INFO 2017-06-28 23:39:54,166 main.py:57] epoch 87, training loss: 13251.09, average training loss: 16828.06, base loss: 22239.65
[INFO 2017-06-28 23:39:56,588 main.py:57] epoch 88, training loss: 12825.25, average training loss: 16783.08, base loss: 22238.52
[INFO 2017-06-28 23:39:59,089 main.py:57] epoch 89, training loss: 13061.21, average training loss: 16741.73, base loss: 22227.98
[INFO 2017-06-28 23:40:01,668 main.py:57] epoch 90, training loss: 13882.28, average training loss: 16710.30, base loss: 22258.65
[INFO 2017-06-28 23:40:04,181 main.py:57] epoch 91, training loss: 10907.31, average training loss: 16647.23, base loss: 22237.57
[INFO 2017-06-28 23:40:06,575 main.py:57] epoch 92, training loss: 12876.78, average training loss: 16606.69, base loss: 22239.81
[INFO 2017-06-28 23:40:09,049 main.py:57] epoch 93, training loss: 12564.82, average training loss: 16563.69, base loss: 22238.04
[INFO 2017-06-28 23:40:11,708 main.py:57] epoch 94, training loss: 12198.67, average training loss: 16517.74, base loss: 22227.79
[INFO 2017-06-28 23:40:14,370 main.py:57] epoch 95, training loss: 14237.64, average training loss: 16493.99, base loss: 22239.62
[INFO 2017-06-28 23:40:16,944 main.py:57] epoch 96, training loss: 12724.78, average training loss: 16455.13, base loss: 22230.66
[INFO 2017-06-28 23:40:19,432 main.py:57] epoch 97, training loss: 12120.04, average training loss: 16410.89, base loss: 22213.48
[INFO 2017-06-28 23:40:22,016 main.py:57] epoch 98, training loss: 12604.48, average training loss: 16372.45, base loss: 22212.01
[INFO 2017-06-28 23:40:24,505 main.py:57] epoch 99, training loss: 12752.43, average training loss: 16336.25, base loss: 22219.13
[INFO 2017-06-28 23:40:24,506 main.py:59] epoch 99, testing
[INFO 2017-06-28 23:40:35,971 main.py:104] average testing loss: 14295.99, base loss: 22618.50
[INFO 2017-06-28 23:40:35,971 main.py:105] improve_loss: 8322.52, improve_percent: 0.37
[INFO 2017-06-28 23:40:35,972 main.py:67] model save to ./model/final.pth
[INFO 2017-06-28 23:40:35,985 main.py:71] current best improved percent: 0.37
[INFO 2017-06-28 23:40:38,622 main.py:57] epoch 100, training loss: 11930.61, average training loss: 16292.63, base loss: 22209.28
[INFO 2017-06-28 23:40:41,202 main.py:57] epoch 101, training loss: 13141.59, average training loss: 16261.73, base loss: 22220.32
[INFO 2017-06-28 23:40:43,810 main.py:57] epoch 102, training loss: 14283.57, average training loss: 16242.53, base loss: 22241.34
[INFO 2017-06-28 23:40:46,480 main.py:57] epoch 103, training loss: 14356.79, average training loss: 16224.40, base loss: 22262.79
[INFO 2017-06-28 23:40:49,129 main.py:57] epoch 104, training loss: 13582.59, average training loss: 16199.24, base loss: 22266.58
[INFO 2017-06-28 23:40:51,624 main.py:57] epoch 105, training loss: 12885.46, average training loss: 16167.97, base loss: 22271.71
[INFO 2017-06-28 23:40:54,373 main.py:57] epoch 106, training loss: 13917.31, average training loss: 16146.94, base loss: 22277.78
[INFO 2017-06-28 23:40:57,105 main.py:57] epoch 107, training loss: 11816.34, average training loss: 16106.84, base loss: 22267.59
[INFO 2017-06-28 23:40:59,736 main.py:57] epoch 108, training loss: 14288.08, average training loss: 16090.16, base loss: 22289.31
[INFO 2017-06-28 23:41:02,436 main.py:57] epoch 109, training loss: 13102.18, average training loss: 16062.99, base loss: 22297.91
[INFO 2017-06-28 23:41:05,321 main.py:57] epoch 110, training loss: 12909.16, average training loss: 16034.58, base loss: 22299.17
[INFO 2017-06-28 23:41:08,129 main.py:57] epoch 111, training loss: 12463.93, average training loss: 16002.70, base loss: 22284.89
[INFO 2017-06-28 23:41:10,713 main.py:57] epoch 112, training loss: 11556.25, average training loss: 15963.35, base loss: 22278.14
[INFO 2017-06-28 23:41:13,610 main.py:57] epoch 113, training loss: 11856.47, average training loss: 15927.32, base loss: 22264.55
[INFO 2017-06-28 23:41:16,554 main.py:57] epoch 114, training loss: 13027.10, average training loss: 15902.10, base loss: 22266.91
[INFO 2017-06-28 23:41:19,221 main.py:57] epoch 115, training loss: 13515.20, average training loss: 15881.53, base loss: 22280.77
[INFO 2017-06-28 23:41:21,818 main.py:57] epoch 116, training loss: 11905.85, average training loss: 15847.55, base loss: 22278.87
[INFO 2017-06-28 23:41:24,369 main.py:57] epoch 117, training loss: 13029.51, average training loss: 15823.67, base loss: 22279.35
[INFO 2017-06-28 23:41:27,053 main.py:57] epoch 118, training loss: 12935.43, average training loss: 15799.39, base loss: 22278.79
[INFO 2017-06-28 23:41:29,661 main.py:57] epoch 119, training loss: 13172.53, average training loss: 15777.50, base loss: 22284.14
[INFO 2017-06-28 23:41:32,476 main.py:57] epoch 120, training loss: 12974.51, average training loss: 15754.34, base loss: 22288.69
[INFO 2017-06-28 23:41:35,344 main.py:57] epoch 121, training loss: 11939.07, average training loss: 15723.07, base loss: 22281.01
[INFO 2017-06-28 23:41:38,014 main.py:57] epoch 122, training loss: 13619.17, average training loss: 15705.96, base loss: 22282.98
[INFO 2017-06-28 23:41:40,984 main.py:57] epoch 123, training loss: 11550.62, average training loss: 15672.45, base loss: 22269.99
[INFO 2017-06-28 23:41:43,781 main.py:57] epoch 124, training loss: 12344.37, average training loss: 15645.83, base loss: 22265.64
[INFO 2017-06-28 23:41:46,688 main.py:57] epoch 125, training loss: 13812.40, average training loss: 15631.28, base loss: 22269.89
[INFO 2017-06-28 23:41:49,427 main.py:57] epoch 126, training loss: 11683.37, average training loss: 15600.19, base loss: 22260.93
[INFO 2017-06-28 23:41:52,092 main.py:57] epoch 127, training loss: 11697.46, average training loss: 15569.70, base loss: 22250.57
[INFO 2017-06-28 23:41:54,918 main.py:57] epoch 128, training loss: 12494.90, average training loss: 15545.86, base loss: 22248.21
[INFO 2017-06-28 23:41:57,875 main.py:57] epoch 129, training loss: 11935.19, average training loss: 15518.09, base loss: 22244.93
[INFO 2017-06-28 23:42:00,811 main.py:57] epoch 130, training loss: 11650.43, average training loss: 15488.57, base loss: 22232.75
[INFO 2017-06-28 23:42:03,661 main.py:57] epoch 131, training loss: 11586.68, average training loss: 15459.01, base loss: 22230.35
[INFO 2017-06-28 23:42:06,451 main.py:57] epoch 132, training loss: 11821.08, average training loss: 15431.65, base loss: 22226.08
[INFO 2017-06-28 23:42:09,286 main.py:57] epoch 133, training loss: 12662.81, average training loss: 15410.99, base loss: 22231.99
[INFO 2017-06-28 23:42:12,232 main.py:57] epoch 134, training loss: 12275.42, average training loss: 15387.76, base loss: 22235.70
[INFO 2017-06-28 23:42:15,059 main.py:57] epoch 135, training loss: 12908.51, average training loss: 15369.53, base loss: 22244.97
[INFO 2017-06-28 23:42:17,949 main.py:57] epoch 136, training loss: 11409.28, average training loss: 15340.63, base loss: 22236.41
[INFO 2017-06-28 23:42:20,658 main.py:57] epoch 137, training loss: 11895.58, average training loss: 15315.66, base loss: 22230.51
[INFO 2017-06-28 23:42:23,554 main.py:57] epoch 138, training loss: 13496.39, average training loss: 15302.57, base loss: 22245.08
[INFO 2017-06-28 23:42:26,329 main.py:57] epoch 139, training loss: 11668.60, average training loss: 15276.62, base loss: 22249.99
[INFO 2017-06-28 23:42:29,095 main.py:57] epoch 140, training loss: 10965.02, average training loss: 15246.04, base loss: 22230.42
[INFO 2017-06-28 23:42:31,980 main.py:57] epoch 141, training loss: 11050.30, average training loss: 15216.49, base loss: 22214.33
[INFO 2017-06-28 23:42:34,989 main.py:57] epoch 142, training loss: 11409.11, average training loss: 15189.87, base loss: 22206.70
[INFO 2017-06-28 23:42:37,851 main.py:57] epoch 143, training loss: 12400.76, average training loss: 15170.50, base loss: 22201.85
[INFO 2017-06-28 23:42:40,652 main.py:57] epoch 144, training loss: 12721.67, average training loss: 15153.61, base loss: 22196.79
[INFO 2017-06-28 23:42:43,472 main.py:57] epoch 145, training loss: 11615.37, average training loss: 15129.37, base loss: 22185.06
[INFO 2017-06-28 23:42:46,393 main.py:57] epoch 146, training loss: 12504.04, average training loss: 15111.51, base loss: 22187.31
[INFO 2017-06-28 23:42:49,305 main.py:57] epoch 147, training loss: 12385.47, average training loss: 15093.10, base loss: 22186.53
[INFO 2017-06-28 23:42:52,153 main.py:57] epoch 148, training loss: 11229.67, average training loss: 15067.17, base loss: 22180.44
[INFO 2017-06-28 23:42:54,841 main.py:57] epoch 149, training loss: 12357.79, average training loss: 15049.10, base loss: 22175.72
[INFO 2017-06-28 23:42:57,687 main.py:57] epoch 150, training loss: 11640.39, average training loss: 15026.53, base loss: 22166.05
[INFO 2017-06-28 23:43:00,464 main.py:57] epoch 151, training loss: 11869.00, average training loss: 15005.76, base loss: 22161.25
[INFO 2017-06-28 23:43:03,270 main.py:57] epoch 152, training loss: 12824.25, average training loss: 14991.50, base loss: 22175.18
[INFO 2017-06-28 23:43:06,168 main.py:57] epoch 153, training loss: 14654.86, average training loss: 14989.31, base loss: 22199.52
[INFO 2017-06-28 23:43:08,999 main.py:57] epoch 154, training loss: 10056.30, average training loss: 14957.49, base loss: 22183.95
[INFO 2017-06-28 23:43:11,768 main.py:57] epoch 155, training loss: 14119.49, average training loss: 14952.11, base loss: 22194.43
[INFO 2017-06-28 23:43:14,624 main.py:57] epoch 156, training loss: 12388.96, average training loss: 14935.79, base loss: 22194.17
[INFO 2017-06-28 23:43:17,394 main.py:57] epoch 157, training loss: 11319.17, average training loss: 14912.90, base loss: 22203.12
[INFO 2017-06-28 23:43:20,138 main.py:57] epoch 158, training loss: 10424.44, average training loss: 14884.67, base loss: 22186.93
[INFO 2017-06-28 23:43:23,004 main.py:57] epoch 159, training loss: 13005.43, average training loss: 14872.92, base loss: 22194.03
[INFO 2017-06-28 23:43:25,962 main.py:57] epoch 160, training loss: 11926.06, average training loss: 14854.62, base loss: 22188.96
[INFO 2017-06-28 23:43:28,662 main.py:57] epoch 161, training loss: 11068.47, average training loss: 14831.25, base loss: 22184.28
[INFO 2017-06-28 23:43:31,277 main.py:57] epoch 162, training loss: 12971.56, average training loss: 14819.84, base loss: 22195.76
[INFO 2017-06-28 23:43:33,962 main.py:57] epoch 163, training loss: 11983.56, average training loss: 14802.55, base loss: 22189.44
[INFO 2017-06-28 23:43:36,718 main.py:57] epoch 164, training loss: 13572.89, average training loss: 14795.09, base loss: 22203.97
[INFO 2017-06-28 23:43:39,433 main.py:57] epoch 165, training loss: 11701.76, average training loss: 14776.46, base loss: 22193.91
[INFO 2017-06-28 23:43:42,351 main.py:57] epoch 166, training loss: 12347.08, average training loss: 14761.91, base loss: 22193.54
[INFO 2017-06-28 23:43:45,376 main.py:57] epoch 167, training loss: 12165.12, average training loss: 14746.45, base loss: 22199.23
[INFO 2017-06-28 23:43:48,176 main.py:57] epoch 168, training loss: 11797.94, average training loss: 14729.01, base loss: 22193.94
[INFO 2017-06-28 23:43:51,099 main.py:57] epoch 169, training loss: 13070.28, average training loss: 14719.25, base loss: 22199.47
[INFO 2017-06-28 23:43:53,877 main.py:57] epoch 170, training loss: 14468.57, average training loss: 14717.78, base loss: 22221.28
[INFO 2017-06-28 23:43:56,633 main.py:57] epoch 171, training loss: 11355.93, average training loss: 14698.24, base loss: 22212.27
[INFO 2017-06-28 23:43:59,499 main.py:57] epoch 172, training loss: 11959.26, average training loss: 14682.41, base loss: 22217.22
[INFO 2017-06-28 23:44:02,344 main.py:57] epoch 173, training loss: 11026.74, average training loss: 14661.40, base loss: 22208.44
[INFO 2017-06-28 23:44:05,165 main.py:57] epoch 174, training loss: 11250.62, average training loss: 14641.91, base loss: 22203.52
[INFO 2017-06-28 23:44:07,973 main.py:57] epoch 175, training loss: 11786.92, average training loss: 14625.69, base loss: 22203.70
[INFO 2017-06-28 23:44:10,767 main.py:57] epoch 176, training loss: 13464.20, average training loss: 14619.12, base loss: 22213.56
[INFO 2017-06-28 23:44:13,561 main.py:57] epoch 177, training loss: 12816.44, average training loss: 14609.00, base loss: 22214.82
[INFO 2017-06-28 23:44:16,552 main.py:57] epoch 178, training loss: 12523.02, average training loss: 14597.34, base loss: 22213.29
[INFO 2017-06-28 23:44:19,365 main.py:57] epoch 179, training loss: 12298.53, average training loss: 14584.57, base loss: 22218.07
[INFO 2017-06-28 23:44:22,233 main.py:57] epoch 180, training loss: 11726.96, average training loss: 14568.78, base loss: 22217.51
[INFO 2017-06-28 23:44:25,025 main.py:57] epoch 181, training loss: 13005.50, average training loss: 14560.19, base loss: 22232.67
[INFO 2017-06-28 23:44:27,768 main.py:57] epoch 182, training loss: 10833.84, average training loss: 14539.83, base loss: 22222.90
[INFO 2017-06-28 23:44:30,486 main.py:57] epoch 183, training loss: 13731.28, average training loss: 14535.44, base loss: 22224.01
[INFO 2017-06-28 23:44:33,451 main.py:57] epoch 184, training loss: 13761.44, average training loss: 14531.25, base loss: 22231.89
[INFO 2017-06-28 23:44:36,259 main.py:57] epoch 185, training loss: 12218.86, average training loss: 14518.82, base loss: 22232.18
[INFO 2017-06-28 23:44:39,182 main.py:57] epoch 186, training loss: 12734.02, average training loss: 14509.28, base loss: 22237.13
[INFO 2017-06-28 23:44:42,108 main.py:57] epoch 187, training loss: 11818.19, average training loss: 14494.96, base loss: 22232.53
[INFO 2017-06-28 23:44:44,845 main.py:57] epoch 188, training loss: 10363.98, average training loss: 14473.11, base loss: 22219.18
[INFO 2017-06-28 23:44:47,778 main.py:57] epoch 189, training loss: 14174.27, average training loss: 14471.53, base loss: 22237.92
[INFO 2017-06-28 23:44:50,600 main.py:57] epoch 190, training loss: 12025.81, average training loss: 14458.73, base loss: 22235.34
[INFO 2017-06-28 23:44:53,413 main.py:57] epoch 191, training loss: 11189.01, average training loss: 14441.70, base loss: 22231.71
[INFO 2017-06-28 23:44:56,178 main.py:57] epoch 192, training loss: 12440.12, average training loss: 14431.33, base loss: 22233.49
[INFO 2017-06-28 23:44:58,901 main.py:57] epoch 193, training loss: 12629.33, average training loss: 14422.04, base loss: 22241.07
[INFO 2017-06-28 23:45:01,792 main.py:57] epoch 194, training loss: 13200.53, average training loss: 14415.77, base loss: 22248.32
[INFO 2017-06-28 23:45:05,102 main.py:57] epoch 195, training loss: 12223.47, average training loss: 14404.59, base loss: 22254.24
[INFO 2017-06-28 23:45:07,933 main.py:57] epoch 196, training loss: 12403.50, average training loss: 14394.43, base loss: 22256.68
[INFO 2017-06-28 23:45:10,707 main.py:57] epoch 197, training loss: 11990.17, average training loss: 14382.29, base loss: 22253.87
[INFO 2017-06-28 23:45:13,606 main.py:57] epoch 198, training loss: 13574.79, average training loss: 14378.23, base loss: 22258.98
[INFO 2017-06-28 23:45:16,546 main.py:57] epoch 199, training loss: 11872.48, average training loss: 14365.70, base loss: 22257.31
[INFO 2017-06-28 23:45:16,546 main.py:59] epoch 199, testing
[INFO 2017-06-28 23:45:29,304 main.py:104] average testing loss: 12953.44, base loss: 21467.41
[INFO 2017-06-28 23:45:29,304 main.py:105] improve_loss: 8513.96, improve_percent: 0.40
[INFO 2017-06-28 23:45:29,305 main.py:67] model save to ./model/final.pth
[INFO 2017-06-28 23:45:29,320 main.py:71] current best improved percent: 0.40
[INFO 2017-06-28 23:45:32,193 main.py:57] epoch 200, training loss: 12370.22, average training loss: 14355.77, base loss: 22257.08
[INFO 2017-06-28 23:45:35,159 main.py:57] epoch 201, training loss: 11494.00, average training loss: 14341.61, base loss: 22251.43
[INFO 2017-06-28 23:45:38,014 main.py:57] epoch 202, training loss: 11430.54, average training loss: 14327.27, base loss: 22245.35
[INFO 2017-06-28 23:45:40,888 main.py:57] epoch 203, training loss: 11335.44, average training loss: 14312.60, base loss: 22235.15
[INFO 2017-06-28 23:45:43,880 main.py:57] epoch 204, training loss: 11224.26, average training loss: 14297.54, base loss: 22232.75
[INFO 2017-06-28 23:45:46,818 main.py:57] epoch 205, training loss: 11973.55, average training loss: 14286.25, base loss: 22230.86
[INFO 2017-06-28 23:45:49,670 main.py:57] epoch 206, training loss: 11530.29, average training loss: 14272.94, base loss: 22223.66
[INFO 2017-06-28 23:45:52,420 main.py:57] epoch 207, training loss: 12429.55, average training loss: 14264.08, base loss: 22224.74
[INFO 2017-06-28 23:45:55,244 main.py:57] epoch 208, training loss: 13217.01, average training loss: 14259.07, base loss: 22228.16
[INFO 2017-06-28 23:45:58,037 main.py:57] epoch 209, training loss: 12630.42, average training loss: 14251.31, base loss: 22230.02
[INFO 2017-06-28 23:46:00,896 main.py:57] epoch 210, training loss: 11792.42, average training loss: 14239.66, base loss: 22227.79
[INFO 2017-06-28 23:46:03,779 main.py:57] epoch 211, training loss: 13110.74, average training loss: 14234.33, base loss: 22238.23
[INFO 2017-06-28 23:46:06,627 main.py:57] epoch 212, training loss: 13248.68, average training loss: 14229.71, base loss: 22247.65
[INFO 2017-06-28 23:46:09,646 main.py:57] epoch 213, training loss: 11240.08, average training loss: 14215.74, base loss: 22242.24
[INFO 2017-06-28 23:46:13,039 main.py:57] epoch 214, training loss: 12331.72, average training loss: 14206.97, base loss: 22244.57
[INFO 2017-06-28 23:46:15,793 main.py:57] epoch 215, training loss: 12925.94, average training loss: 14201.04, base loss: 22249.75
[INFO 2017-06-28 23:46:18,724 main.py:57] epoch 216, training loss: 12590.28, average training loss: 14193.62, base loss: 22259.77
[INFO 2017-06-28 23:46:21,605 main.py:57] epoch 217, training loss: 11953.09, average training loss: 14183.34, base loss: 22264.13
[INFO 2017-06-28 23:46:24,456 main.py:57] epoch 218, training loss: 11911.01, average training loss: 14172.97, base loss: 22258.00
[INFO 2017-06-28 23:46:27,439 main.py:57] epoch 219, training loss: 12202.29, average training loss: 14164.01, base loss: 22260.83
[INFO 2017-06-28 23:46:30,069 main.py:57] epoch 220, training loss: 11630.16, average training loss: 14152.54, base loss: 22257.25
[INFO 2017-06-28 23:46:32,851 main.py:57] epoch 221, training loss: 11071.87, average training loss: 14138.67, base loss: 22254.15
[INFO 2017-06-28 23:46:35,577 main.py:57] epoch 222, training loss: 11105.08, average training loss: 14125.06, base loss: 22246.34
[INFO 2017-06-28 23:46:38,435 main.py:57] epoch 223, training loss: 10036.47, average training loss: 14106.81, base loss: 22238.87
[INFO 2017-06-28 23:46:41,407 main.py:57] epoch 224, training loss: 12191.14, average training loss: 14098.30, base loss: 22236.27
[INFO 2017-06-28 23:46:44,249 main.py:57] epoch 225, training loss: 12585.84, average training loss: 14091.60, base loss: 22235.19
[INFO 2017-06-28 23:46:47,325 main.py:57] epoch 226, training loss: 12705.75, average training loss: 14085.50, base loss: 22238.37
[INFO 2017-06-28 23:46:50,371 main.py:57] epoch 227, training loss: 13098.71, average training loss: 14081.17, base loss: 22242.92
[INFO 2017-06-28 23:46:53,267 main.py:57] epoch 228, training loss: 11053.85, average training loss: 14067.95, base loss: 22243.22
[INFO 2017-06-28 23:46:56,126 main.py:57] epoch 229, training loss: 13211.75, average training loss: 14064.23, base loss: 22248.50
[INFO 2017-06-28 23:46:59,075 main.py:57] epoch 230, training loss: 13536.96, average training loss: 14061.95, base loss: 22258.01
[INFO 2017-06-28 23:47:01,867 main.py:57] epoch 231, training loss: 12661.57, average training loss: 14055.91, base loss: 22261.86
[INFO 2017-06-28 23:47:04,912 main.py:57] epoch 232, training loss: 11978.16, average training loss: 14046.99, base loss: 22266.33
[INFO 2017-06-28 23:47:07,695 main.py:57] epoch 233, training loss: 11286.23, average training loss: 14035.19, base loss: 22261.58
[INFO 2017-06-28 23:47:10,718 main.py:57] epoch 234, training loss: 12407.00, average training loss: 14028.27, base loss: 22260.96
[INFO 2017-06-28 23:47:13,652 main.py:57] epoch 235, training loss: 11257.28, average training loss: 14016.52, base loss: 22251.54
[INFO 2017-06-28 23:47:16,620 main.py:57] epoch 236, training loss: 11481.18, average training loss: 14005.83, base loss: 22248.57
[INFO 2017-06-28 23:47:19,535 main.py:57] epoch 237, training loss: 11574.41, average training loss: 13995.61, base loss: 22241.68
[INFO 2017-06-28 23:47:22,597 main.py:57] epoch 238, training loss: 12360.64, average training loss: 13988.77, base loss: 22242.87
[INFO 2017-06-28 23:47:25,369 main.py:57] epoch 239, training loss: 10761.38, average training loss: 13975.32, base loss: 22238.57
[INFO 2017-06-28 23:47:28,298 main.py:57] epoch 240, training loss: 11880.46, average training loss: 13966.63, base loss: 22237.21
[INFO 2017-06-28 23:47:31,159 main.py:57] epoch 241, training loss: 12068.16, average training loss: 13958.78, base loss: 22237.62
[INFO 2017-06-28 23:47:33,915 main.py:57] epoch 242, training loss: 11576.49, average training loss: 13948.98, base loss: 22239.25
[INFO 2017-06-28 23:47:36,978 main.py:57] epoch 243, training loss: 10434.50, average training loss: 13934.58, base loss: 22227.64
[INFO 2017-06-28 23:47:39,787 main.py:57] epoch 244, training loss: 10867.75, average training loss: 13922.06, base loss: 22225.75
[INFO 2017-06-28 23:47:42,699 main.py:57] epoch 245, training loss: 12944.38, average training loss: 13918.09, base loss: 22229.50
[INFO 2017-06-28 23:47:45,680 main.py:57] epoch 246, training loss: 10669.62, average training loss: 13904.93, base loss: 22219.56
[INFO 2017-06-28 23:47:48,602 main.py:57] epoch 247, training loss: 11756.21, average training loss: 13896.27, base loss: 22214.55
[INFO 2017-06-28 23:47:51,538 main.py:57] epoch 248, training loss: 11046.02, average training loss: 13884.82, base loss: 22212.69
[INFO 2017-06-28 23:47:54,255 main.py:57] epoch 249, training loss: 11297.66, average training loss: 13874.47, base loss: 22202.35
[INFO 2017-06-28 23:47:57,407 main.py:57] epoch 250, training loss: 10515.85, average training loss: 13861.09, base loss: 22194.57
[INFO 2017-06-28 23:48:00,075 main.py:57] epoch 251, training loss: 10473.81, average training loss: 13847.65, base loss: 22184.08
[INFO 2017-06-28 23:48:02,933 main.py:57] epoch 252, training loss: 12725.69, average training loss: 13843.22, base loss: 22186.31
[INFO 2017-06-28 23:48:05,762 main.py:57] epoch 253, training loss: 12797.58, average training loss: 13839.10, base loss: 22193.14
[INFO 2017-06-28 23:48:08,531 main.py:57] epoch 254, training loss: 11657.29, average training loss: 13830.54, base loss: 22191.58
[INFO 2017-06-28 23:48:11,644 main.py:57] epoch 255, training loss: 12299.86, average training loss: 13824.57, base loss: 22193.59
[INFO 2017-06-28 23:48:14,557 main.py:57] epoch 256, training loss: 10875.47, average training loss: 13813.09, base loss: 22188.79
[INFO 2017-06-28 23:48:17,416 main.py:57] epoch 257, training loss: 10481.35, average training loss: 13800.18, base loss: 22181.50
[INFO 2017-06-28 23:48:20,267 main.py:57] epoch 258, training loss: 11414.48, average training loss: 13790.97, base loss: 22181.40
[INFO 2017-06-28 23:48:23,160 main.py:57] epoch 259, training loss: 10846.95, average training loss: 13779.64, base loss: 22174.02
[INFO 2017-06-28 23:48:26,028 main.py:57] epoch 260, training loss: 13203.35, average training loss: 13777.43, base loss: 22180.73
[INFO 2017-06-28 23:48:28,733 main.py:57] epoch 261, training loss: 12694.38, average training loss: 13773.30, base loss: 22182.16
[INFO 2017-06-28 23:48:31,537 main.py:57] epoch 262, training loss: 11088.79, average training loss: 13763.09, base loss: 22174.78
[INFO 2017-06-28 23:48:34,341 main.py:57] epoch 263, training loss: 12277.38, average training loss: 13757.47, base loss: 22177.67
[INFO 2017-06-28 23:48:37,121 main.py:57] epoch 264, training loss: 11996.18, average training loss: 13750.82, base loss: 22176.69
[INFO 2017-06-28 23:48:40,060 main.py:57] epoch 265, training loss: 12675.83, average training loss: 13746.78, base loss: 22181.08
[INFO 2017-06-28 23:48:42,997 main.py:57] epoch 266, training loss: 10237.16, average training loss: 13733.63, base loss: 22173.11
[INFO 2017-06-28 23:48:45,909 main.py:57] epoch 267, training loss: 11171.77, average training loss: 13724.07, base loss: 22172.26
[INFO 2017-06-28 23:48:48,805 main.py:57] epoch 268, training loss: 10727.98, average training loss: 13712.94, base loss: 22163.29
[INFO 2017-06-28 23:48:51,504 main.py:57] epoch 269, training loss: 11233.71, average training loss: 13703.75, base loss: 22155.50
[INFO 2017-06-28 23:48:54,374 main.py:57] epoch 270, training loss: 11197.04, average training loss: 13694.50, base loss: 22155.45
[INFO 2017-06-28 23:48:57,508 main.py:57] epoch 271, training loss: 11253.93, average training loss: 13685.53, base loss: 22152.39
[INFO 2017-06-28 23:49:00,367 main.py:57] epoch 272, training loss: 12473.07, average training loss: 13681.09, base loss: 22154.80
[INFO 2017-06-28 23:49:03,571 main.py:57] epoch 273, training loss: 11958.81, average training loss: 13674.80, base loss: 22153.62
[INFO 2017-06-28 23:49:06,365 main.py:57] epoch 274, training loss: 12524.78, average training loss: 13670.62, base loss: 22155.45
[INFO 2017-06-28 23:49:09,054 main.py:57] epoch 275, training loss: 10032.40, average training loss: 13657.44, base loss: 22151.77
[INFO 2017-06-28 23:49:11,934 main.py:57] epoch 276, training loss: 10864.00, average training loss: 13647.36, base loss: 22144.51
[INFO 2017-06-28 23:49:14,767 main.py:57] epoch 277, training loss: 10932.85, average training loss: 13637.59, base loss: 22134.89
[INFO 2017-06-28 23:49:17,579 main.py:57] epoch 278, training loss: 13738.49, average training loss: 13637.95, base loss: 22142.08
[INFO 2017-06-28 23:49:20,352 main.py:57] epoch 279, training loss: 10783.14, average training loss: 13627.76, base loss: 22134.78
[INFO 2017-06-28 23:49:23,185 main.py:57] epoch 280, training loss: 12458.71, average training loss: 13623.60, base loss: 22137.06
[INFO 2017-06-28 23:49:26,012 main.py:57] epoch 281, training loss: 9860.71, average training loss: 13610.25, base loss: 22126.20
[INFO 2017-06-28 23:49:28,726 main.py:57] epoch 282, training loss: 10983.03, average training loss: 13600.97, base loss: 22124.06
[INFO 2017-06-28 23:49:31,642 main.py:57] epoch 283, training loss: 10463.48, average training loss: 13589.92, base loss: 22116.42
[INFO 2017-06-28 23:49:34,425 main.py:57] epoch 284, training loss: 11479.61, average training loss: 13582.52, base loss: 22121.60
[INFO 2017-06-28 23:49:37,249 main.py:57] epoch 285, training loss: 11492.26, average training loss: 13575.21, base loss: 22118.44
[INFO 2017-06-28 23:49:40,151 main.py:57] epoch 286, training loss: 10877.42, average training loss: 13565.81, base loss: 22109.82
[INFO 2017-06-28 23:49:42,904 main.py:57] epoch 287, training loss: 11874.63, average training loss: 13559.94, base loss: 22109.57
[INFO 2017-06-28 23:49:45,844 main.py:57] epoch 288, training loss: 10390.39, average training loss: 13548.97, base loss: 22109.07
[INFO 2017-06-28 23:49:48,788 main.py:57] epoch 289, training loss: 11994.04, average training loss: 13543.61, base loss: 22117.07
[INFO 2017-06-28 23:49:51,830 main.py:57] epoch 290, training loss: 10489.78, average training loss: 13533.11, base loss: 22109.24
[INFO 2017-06-28 23:49:54,700 main.py:57] epoch 291, training loss: 11448.31, average training loss: 13525.97, base loss: 22109.69
[INFO 2017-06-28 23:49:57,374 main.py:57] epoch 292, training loss: 13091.17, average training loss: 13524.49, base loss: 22113.18
[INFO 2017-06-28 23:50:00,330 main.py:57] epoch 293, training loss: 10799.47, average training loss: 13515.22, base loss: 22107.79
[INFO 2017-06-28 23:50:03,229 main.py:57] epoch 294, training loss: 12569.24, average training loss: 13512.01, base loss: 22112.52
[INFO 2017-06-28 23:50:06,131 main.py:57] epoch 295, training loss: 11076.64, average training loss: 13503.79, base loss: 22116.38
[INFO 2017-06-28 23:50:08,972 main.py:57] epoch 296, training loss: 11487.23, average training loss: 13497.00, base loss: 22111.00
[INFO 2017-06-28 23:50:12,086 main.py:57] epoch 297, training loss: 10171.71, average training loss: 13485.84, base loss: 22102.78
[INFO 2017-06-28 23:50:14,976 main.py:57] epoch 298, training loss: 11540.51, average training loss: 13479.33, base loss: 22098.60
[INFO 2017-06-28 23:50:17,835 main.py:57] epoch 299, training loss: 11487.26, average training loss: 13472.69, base loss: 22098.68
[INFO 2017-06-28 23:50:17,835 main.py:59] epoch 299, testing
[INFO 2017-06-28 23:50:30,398 main.py:104] average testing loss: 12197.96, base loss: 21259.87
[INFO 2017-06-28 23:50:30,398 main.py:105] improve_loss: 9061.91, improve_percent: 0.43
[INFO 2017-06-28 23:50:30,400 main.py:67] model save to ./model/final.pth
[INFO 2017-06-28 23:50:30,413 main.py:71] current best improved percent: 0.43
[INFO 2017-06-28 23:50:33,166 main.py:57] epoch 300, training loss: 12227.41, average training loss: 13468.55, base loss: 22102.63
[INFO 2017-06-28 23:50:36,057 main.py:57] epoch 301, training loss: 12162.89, average training loss: 13464.23, base loss: 22106.78
[INFO 2017-06-28 23:50:39,009 main.py:57] epoch 302, training loss: 11758.83, average training loss: 13458.60, base loss: 22108.73
[INFO 2017-06-28 23:50:41,915 main.py:57] epoch 303, training loss: 11072.86, average training loss: 13450.76, base loss: 22105.83
[INFO 2017-06-28 23:50:44,968 main.py:57] epoch 304, training loss: 12766.82, average training loss: 13448.51, base loss: 22107.13
[INFO 2017-06-28 23:50:47,826 main.py:57] epoch 305, training loss: 11666.42, average training loss: 13442.69, base loss: 22105.25
[INFO 2017-06-28 23:50:50,734 main.py:57] epoch 306, training loss: 11904.72, average training loss: 13437.68, base loss: 22103.92
[INFO 2017-06-28 23:50:53,650 main.py:57] epoch 307, training loss: 11124.99, average training loss: 13430.17, base loss: 22103.18
[INFO 2017-06-28 23:50:56,419 main.py:57] epoch 308, training loss: 13375.57, average training loss: 13429.99, base loss: 22104.79
[INFO 2017-06-28 23:50:59,195 main.py:57] epoch 309, training loss: 11914.39, average training loss: 13425.10, base loss: 22107.10
[INFO 2017-06-28 23:51:02,012 main.py:57] epoch 310, training loss: 11159.29, average training loss: 13417.82, base loss: 22105.42
[INFO 2017-06-28 23:51:04,805 main.py:57] epoch 311, training loss: 11243.72, average training loss: 13410.85, base loss: 22104.52
[INFO 2017-06-28 23:51:07,758 main.py:57] epoch 312, training loss: 10647.05, average training loss: 13402.02, base loss: 22096.79
[INFO 2017-06-28 23:51:10,541 main.py:57] epoch 313, training loss: 11472.45, average training loss: 13395.88, base loss: 22099.15
[INFO 2017-06-28 23:51:13,363 main.py:57] epoch 314, training loss: 12618.29, average training loss: 13393.41, base loss: 22100.64
[INFO 2017-06-28 23:51:16,176 main.py:57] epoch 315, training loss: 10796.99, average training loss: 13385.19, base loss: 22095.17
[INFO 2017-06-28 23:51:19,149 main.py:57] epoch 316, training loss: 11738.94, average training loss: 13380.00, base loss: 22094.14
[INFO 2017-06-28 23:51:21,900 main.py:57] epoch 317, training loss: 12323.83, average training loss: 13376.68, base loss: 22096.31
[INFO 2017-06-28 23:51:24,577 main.py:57] epoch 318, training loss: 11642.05, average training loss: 13371.24, base loss: 22093.87
[INFO 2017-06-28 23:51:27,413 main.py:57] epoch 319, training loss: 10877.91, average training loss: 13363.45, base loss: 22088.58
[INFO 2017-06-28 23:51:30,421 main.py:57] epoch 320, training loss: 11063.12, average training loss: 13356.28, base loss: 22085.99
[INFO 2017-06-28 23:51:33,303 main.py:57] epoch 321, training loss: 12543.04, average training loss: 13353.76, base loss: 22088.93
[INFO 2017-06-28 23:51:36,172 main.py:57] epoch 322, training loss: 11763.96, average training loss: 13348.83, base loss: 22089.53
[INFO 2017-06-28 23:51:38,938 main.py:57] epoch 323, training loss: 11273.24, average training loss: 13342.43, base loss: 22084.62
[INFO 2017-06-28 23:51:41,799 main.py:57] epoch 324, training loss: 10125.26, average training loss: 13332.53, base loss: 22078.21
[INFO 2017-06-28 23:51:44,617 main.py:57] epoch 325, training loss: 10289.96, average training loss: 13323.19, base loss: 22069.22
[INFO 2017-06-28 23:51:47,559 main.py:57] epoch 326, training loss: 13423.91, average training loss: 13323.50, base loss: 22076.60
[INFO 2017-06-28 23:51:50,249 main.py:57] epoch 327, training loss: 11393.29, average training loss: 13317.62, base loss: 22078.41
[INFO 2017-06-28 23:51:53,032 main.py:57] epoch 328, training loss: 10664.02, average training loss: 13309.55, base loss: 22073.78
[INFO 2017-06-28 23:51:55,989 main.py:57] epoch 329, training loss: 12318.98, average training loss: 13306.55, base loss: 22075.76
[INFO 2017-06-28 23:51:58,739 main.py:57] epoch 330, training loss: 10825.20, average training loss: 13299.05, base loss: 22072.75
[INFO 2017-06-28 23:52:01,501 main.py:57] epoch 331, training loss: 11769.28, average training loss: 13294.45, base loss: 22073.74
[INFO 2017-06-28 23:52:04,519 main.py:57] epoch 332, training loss: 11541.14, average training loss: 13289.18, base loss: 22074.95
[INFO 2017-06-28 23:52:07,418 main.py:57] epoch 333, training loss: 11155.64, average training loss: 13282.79, base loss: 22069.93
[INFO 2017-06-28 23:52:10,223 main.py:57] epoch 334, training loss: 13890.94, average training loss: 13284.61, base loss: 22077.32
[INFO 2017-06-28 23:52:13,179 main.py:57] epoch 335, training loss: 12021.67, average training loss: 13280.85, base loss: 22077.04
[INFO 2017-06-28 23:52:16,032 main.py:57] epoch 336, training loss: 9384.95, average training loss: 13269.29, base loss: 22067.12
[INFO 2017-06-28 23:52:18,994 main.py:57] epoch 337, training loss: 11812.02, average training loss: 13264.98, base loss: 22065.46
[INFO 2017-06-28 23:52:21,730 main.py:57] epoch 338, training loss: 13361.33, average training loss: 13265.26, base loss: 22075.13
[INFO 2017-06-28 23:52:24,582 main.py:57] epoch 339, training loss: 11757.33, average training loss: 13260.83, base loss: 22073.97
[INFO 2017-06-28 23:52:27,322 main.py:57] epoch 340, training loss: 10472.57, average training loss: 13252.65, base loss: 22066.84
[INFO 2017-06-28 23:52:30,187 main.py:57] epoch 341, training loss: 12411.67, average training loss: 13250.19, base loss: 22065.39
[INFO 2017-06-28 23:52:33,091 main.py:57] epoch 342, training loss: 13696.00, average training loss: 13251.49, base loss: 22073.92
[INFO 2017-06-28 23:52:35,933 main.py:57] epoch 343, training loss: 12301.78, average training loss: 13248.73, base loss: 22080.52
[INFO 2017-06-28 23:52:38,803 main.py:57] epoch 344, training loss: 12197.31, average training loss: 13245.68, base loss: 22087.43
[INFO 2017-06-28 23:52:41,599 main.py:57] epoch 345, training loss: 11009.28, average training loss: 13239.22, base loss: 22085.45
[INFO 2017-06-28 23:52:44,301 main.py:57] epoch 346, training loss: 11752.95, average training loss: 13234.94, base loss: 22083.55
[INFO 2017-06-28 23:52:47,137 main.py:57] epoch 347, training loss: 12119.06, average training loss: 13231.73, base loss: 22083.11
[INFO 2017-06-28 23:52:50,079 main.py:57] epoch 348, training loss: 12186.74, average training loss: 13228.74, base loss: 22085.22
[INFO 2017-06-28 23:52:52,871 main.py:57] epoch 349, training loss: 11267.42, average training loss: 13223.13, base loss: 22084.01
[INFO 2017-06-28 23:52:55,619 main.py:57] epoch 350, training loss: 11680.79, average training loss: 13218.74, base loss: 22083.16
[INFO 2017-06-28 23:52:58,387 main.py:57] epoch 351, training loss: 11252.16, average training loss: 13213.15, base loss: 22082.41
[INFO 2017-06-28 23:53:01,163 main.py:57] epoch 352, training loss: 12284.16, average training loss: 13210.52, base loss: 22088.01
[INFO 2017-06-28 23:53:03,879 main.py:57] epoch 353, training loss: 10206.92, average training loss: 13202.03, base loss: 22082.93
[INFO 2017-06-28 23:53:06,773 main.py:57] epoch 354, training loss: 11787.94, average training loss: 13198.05, base loss: 22087.80
[INFO 2017-06-28 23:53:09,702 main.py:57] epoch 355, training loss: 12324.26, average training loss: 13195.60, base loss: 22089.92
[INFO 2017-06-28 23:53:12,480 main.py:57] epoch 356, training loss: 11791.12, average training loss: 13191.66, base loss: 22095.16
[INFO 2017-06-28 23:53:15,554 main.py:57] epoch 357, training loss: 10022.51, average training loss: 13182.81, base loss: 22093.74
[INFO 2017-06-28 23:53:18,598 main.py:57] epoch 358, training loss: 10681.81, average training loss: 13175.84, base loss: 22094.66
[INFO 2017-06-28 23:53:21,454 main.py:57] epoch 359, training loss: 14290.32, average training loss: 13178.94, base loss: 22103.96
[INFO 2017-06-28 23:53:24,281 main.py:57] epoch 360, training loss: 11182.19, average training loss: 13173.41, base loss: 22102.08
[INFO 2017-06-28 23:53:27,225 main.py:57] epoch 361, training loss: 10926.85, average training loss: 13167.20, base loss: 22099.50
[INFO 2017-06-28 23:53:30,166 main.py:57] epoch 362, training loss: 11522.09, average training loss: 13162.67, base loss: 22097.08
[INFO 2017-06-28 23:53:32,968 main.py:57] epoch 363, training loss: 11099.19, average training loss: 13157.00, base loss: 22093.72
[INFO 2017-06-28 23:53:36,077 main.py:57] epoch 364, training loss: 11352.57, average training loss: 13152.06, base loss: 22092.62
[INFO 2017-06-28 23:53:39,033 main.py:57] epoch 365, training loss: 13707.12, average training loss: 13153.57, base loss: 22096.06
[INFO 2017-06-28 23:53:41,987 main.py:57] epoch 366, training loss: 11156.41, average training loss: 13148.13, base loss: 22091.95
[INFO 2017-06-28 23:53:44,697 main.py:57] epoch 367, training loss: 11259.50, average training loss: 13143.00, base loss: 22090.31
[INFO 2017-06-28 23:53:47,599 main.py:57] epoch 368, training loss: 10991.00, average training loss: 13137.17, base loss: 22088.21
[INFO 2017-06-28 23:53:50,359 main.py:57] epoch 369, training loss: 10573.05, average training loss: 13130.24, base loss: 22085.28
[INFO 2017-06-28 23:53:53,159 main.py:57] epoch 370, training loss: 13207.22, average training loss: 13130.45, base loss: 22089.22
[INFO 2017-06-28 23:53:56,296 main.py:57] epoch 371, training loss: 9874.85, average training loss: 13121.69, base loss: 22081.65
[INFO 2017-06-28 23:53:59,081 main.py:57] epoch 372, training loss: 10937.33, average training loss: 13115.84, base loss: 22078.07
[INFO 2017-06-28 23:54:01,974 main.py:57] epoch 373, training loss: 11855.59, average training loss: 13112.47, base loss: 22080.00
[INFO 2017-06-28 23:54:05,054 main.py:57] epoch 374, training loss: 12694.09, average training loss: 13111.35, base loss: 22088.53
[INFO 2017-06-28 23:54:08,197 main.py:57] epoch 375, training loss: 11030.89, average training loss: 13105.82, base loss: 22089.75
[INFO 2017-06-28 23:54:11,157 main.py:57] epoch 376, training loss: 12094.18, average training loss: 13103.14, base loss: 22093.98
[INFO 2017-06-28 23:54:13,925 main.py:57] epoch 377, training loss: 10921.44, average training loss: 13097.36, base loss: 22093.62
[INFO 2017-06-28 23:54:16,931 main.py:57] epoch 378, training loss: 10324.56, average training loss: 13090.05, base loss: 22090.80
[INFO 2017-06-28 23:54:19,685 main.py:57] epoch 379, training loss: 11238.38, average training loss: 13085.18, base loss: 22088.08
[INFO 2017-06-28 23:54:22,691 main.py:57] epoch 380, training loss: 11640.60, average training loss: 13081.38, base loss: 22089.62
[INFO 2017-06-28 23:54:25,715 main.py:57] epoch 381, training loss: 11074.94, average training loss: 13076.13, base loss: 22087.77
[INFO 2017-06-28 23:54:28,410 main.py:57] epoch 382, training loss: 11005.65, average training loss: 13070.73, base loss: 22087.16
[INFO 2017-06-28 23:54:31,701 main.py:57] epoch 383, training loss: 11151.25, average training loss: 13065.73, base loss: 22088.87
[INFO 2017-06-28 23:54:34,515 main.py:57] epoch 384, training loss: 10439.04, average training loss: 13058.90, base loss: 22087.27
[INFO 2017-06-28 23:54:37,501 main.py:57] epoch 385, training loss: 11687.28, average training loss: 13055.35, base loss: 22088.82
[INFO 2017-06-28 23:54:40,525 main.py:57] epoch 386, training loss: 11178.40, average training loss: 13050.50, base loss: 22087.33
[INFO 2017-06-28 23:54:43,520 main.py:57] epoch 387, training loss: 11661.66, average training loss: 13046.92, base loss: 22087.95
[INFO 2017-06-28 23:54:46,512 main.py:57] epoch 388, training loss: 12126.55, average training loss: 13044.56, base loss: 22093.02
[INFO 2017-06-28 23:54:49,485 main.py:57] epoch 389, training loss: 10390.63, average training loss: 13037.75, base loss: 22085.68
[INFO 2017-06-28 23:54:52,335 main.py:57] epoch 390, training loss: 10595.13, average training loss: 13031.50, base loss: 22085.38
[INFO 2017-06-28 23:54:55,200 main.py:57] epoch 391, training loss: 11129.52, average training loss: 13026.65, base loss: 22086.21
[INFO 2017-06-28 23:54:57,995 main.py:57] epoch 392, training loss: 10191.29, average training loss: 13019.44, base loss: 22084.10
[INFO 2017-06-28 23:55:00,873 main.py:57] epoch 393, training loss: 11505.63, average training loss: 13015.59, base loss: 22087.10
[INFO 2017-06-28 23:55:03,886 main.py:57] epoch 394, training loss: 10999.41, average training loss: 13010.49, base loss: 22087.39
[INFO 2017-06-28 23:55:06,986 main.py:57] epoch 395, training loss: 10283.11, average training loss: 13003.60, base loss: 22082.87
[INFO 2017-06-28 23:55:09,796 main.py:57] epoch 396, training loss: 10637.60, average training loss: 12997.64, base loss: 22076.33
[INFO 2017-06-28 23:55:12,562 main.py:57] epoch 397, training loss: 9778.66, average training loss: 12989.56, base loss: 22075.47
[INFO 2017-06-28 23:55:15,647 main.py:57] epoch 398, training loss: 11248.33, average training loss: 12985.19, base loss: 22075.69
[INFO 2017-06-28 23:55:18,546 main.py:57] epoch 399, training loss: 9726.08, average training loss: 12977.04, base loss: 22067.78
[INFO 2017-06-28 23:55:18,547 main.py:59] epoch 399, testing
[INFO 2017-06-28 23:55:31,473 main.py:104] average testing loss: 12090.64, base loss: 21486.79
[INFO 2017-06-28 23:55:31,474 main.py:105] improve_loss: 9396.16, improve_percent: 0.44
[INFO 2017-06-28 23:55:31,475 main.py:67] model save to ./model/final.pth
[INFO 2017-06-28 23:55:31,488 main.py:71] current best improved percent: 0.44
[INFO 2017-06-28 23:55:34,110 main.py:57] epoch 400, training loss: 10504.54, average training loss: 12970.88, base loss: 22065.62
[INFO 2017-06-28 23:55:37,425 main.py:57] epoch 401, training loss: 11439.87, average training loss: 12967.07, base loss: 22065.71
[INFO 2017-06-28 23:55:40,216 main.py:57] epoch 402, training loss: 11825.00, average training loss: 12964.24, base loss: 22065.25
[INFO 2017-06-28 23:55:43,016 main.py:57] epoch 403, training loss: 12231.41, average training loss: 12962.42, base loss: 22066.48
[INFO 2017-06-28 23:55:45,817 main.py:57] epoch 404, training loss: 10440.75, average training loss: 12956.19, base loss: 22065.15
[INFO 2017-06-28 23:55:48,902 main.py:57] epoch 405, training loss: 10413.75, average training loss: 12949.93, base loss: 22062.54
[INFO 2017-06-28 23:55:51,680 main.py:57] epoch 406, training loss: 10020.85, average training loss: 12942.74, base loss: 22058.60
[INFO 2017-06-28 23:55:54,606 main.py:57] epoch 407, training loss: 12256.85, average training loss: 12941.05, base loss: 22058.67
[INFO 2017-06-28 23:55:57,621 main.py:57] epoch 408, training loss: 9832.70, average training loss: 12933.45, base loss: 22051.16
[INFO 2017-06-28 23:56:00,740 main.py:57] epoch 409, training loss: 12216.23, average training loss: 12931.71, base loss: 22053.67
[INFO 2017-06-28 23:56:03,479 main.py:57] epoch 410, training loss: 11798.04, average training loss: 12928.95, base loss: 22056.20
[INFO 2017-06-28 23:56:06,244 main.py:57] epoch 411, training loss: 10335.72, average training loss: 12922.65, base loss: 22052.12
[INFO 2017-06-28 23:56:09,356 main.py:57] epoch 412, training loss: 10853.50, average training loss: 12917.64, base loss: 22052.14
[INFO 2017-06-28 23:56:12,410 main.py:57] epoch 413, training loss: 11633.38, average training loss: 12914.54, base loss: 22053.68
[INFO 2017-06-28 23:56:15,208 main.py:57] epoch 414, training loss: 10921.65, average training loss: 12909.74, base loss: 22055.60
[INFO 2017-06-28 23:56:18,145 main.py:57] epoch 415, training loss: 10541.14, average training loss: 12904.04, base loss: 22051.52
[INFO 2017-06-28 23:56:20,988 main.py:57] epoch 416, training loss: 10896.05, average training loss: 12899.23, base loss: 22051.78
[INFO 2017-06-28 23:56:24,101 main.py:57] epoch 417, training loss: 11170.86, average training loss: 12895.09, base loss: 22053.84
[INFO 2017-06-28 23:56:26,940 main.py:57] epoch 418, training loss: 12761.74, average training loss: 12894.78, base loss: 22055.62
[INFO 2017-06-28 23:56:30,073 main.py:57] epoch 419, training loss: 12934.99, average training loss: 12894.87, base loss: 22059.72
[INFO 2017-06-28 23:56:32,710 main.py:57] epoch 420, training loss: 11196.99, average training loss: 12890.84, base loss: 22059.03
[INFO 2017-06-28 23:56:35,391 main.py:57] epoch 421, training loss: 11169.29, average training loss: 12886.76, base loss: 22058.30
[INFO 2017-06-28 23:56:38,256 main.py:57] epoch 422, training loss: 11285.39, average training loss: 12882.97, base loss: 22057.94
[INFO 2017-06-28 23:56:41,206 main.py:57] epoch 423, training loss: 11611.93, average training loss: 12879.98, base loss: 22060.08
[INFO 2017-06-28 23:56:44,132 main.py:57] epoch 424, training loss: 10119.04, average training loss: 12873.48, base loss: 22057.33
[INFO 2017-06-28 23:56:46,868 main.py:57] epoch 425, training loss: 10800.79, average training loss: 12868.61, base loss: 22055.20
[INFO 2017-06-28 23:56:49,643 main.py:57] epoch 426, training loss: 10965.37, average training loss: 12864.16, base loss: 22056.17
[INFO 2017-06-28 23:56:52,508 main.py:57] epoch 427, training loss: 10969.26, average training loss: 12859.73, base loss: 22054.17
[INFO 2017-06-28 23:56:55,477 main.py:57] epoch 428, training loss: 9784.82, average training loss: 12852.56, base loss: 22046.54
[INFO 2017-06-28 23:56:58,416 main.py:57] epoch 429, training loss: 10920.56, average training loss: 12848.07, base loss: 22044.07
[INFO 2017-06-28 23:57:01,507 main.py:57] epoch 430, training loss: 11110.62, average training loss: 12844.04, base loss: 22044.55
[INFO 2017-06-28 23:57:04,504 main.py:57] epoch 431, training loss: 10829.39, average training loss: 12839.37, base loss: 22044.59
[INFO 2017-06-28 23:57:07,407 main.py:57] epoch 432, training loss: 12403.24, average training loss: 12838.37, base loss: 22049.32
[INFO 2017-06-28 23:57:10,337 main.py:57] epoch 433, training loss: 11010.64, average training loss: 12834.16, base loss: 22051.08
[INFO 2017-06-28 23:57:13,434 main.py:57] epoch 434, training loss: 11389.27, average training loss: 12830.83, base loss: 22051.88
[INFO 2017-06-28 23:57:16,597 main.py:57] epoch 435, training loss: 12926.95, average training loss: 12831.05, base loss: 22055.84
[INFO 2017-06-28 23:57:19,775 main.py:57] epoch 436, training loss: 11335.04, average training loss: 12827.63, base loss: 22055.85
[INFO 2017-06-28 23:57:22,601 main.py:57] epoch 437, training loss: 10904.29, average training loss: 12823.24, base loss: 22055.97
[INFO 2017-06-28 23:57:25,572 main.py:57] epoch 438, training loss: 11020.53, average training loss: 12819.13, base loss: 22053.66
[INFO 2017-06-28 23:57:28,446 main.py:57] epoch 439, training loss: 12085.84, average training loss: 12817.47, base loss: 22055.75
[INFO 2017-06-28 23:57:31,255 main.py:57] epoch 440, training loss: 10095.49, average training loss: 12811.29, base loss: 22054.74
[INFO 2017-06-28 23:57:34,157 main.py:57] epoch 441, training loss: 10602.05, average training loss: 12806.30, base loss: 22055.27
[INFO 2017-06-28 23:57:37,000 main.py:57] epoch 442, training loss: 13052.59, average training loss: 12806.85, base loss: 22056.49
[INFO 2017-06-28 23:57:39,839 main.py:57] epoch 443, training loss: 11715.70, average training loss: 12804.40, base loss: 22057.79
[INFO 2017-06-28 23:57:42,632 main.py:57] epoch 444, training loss: 10019.71, average training loss: 12798.14, base loss: 22056.21
[INFO 2017-06-28 23:57:45,510 main.py:57] epoch 445, training loss: 11202.63, average training loss: 12794.56, base loss: 22054.79
[INFO 2017-06-28 23:57:48,336 main.py:57] epoch 446, training loss: 11258.11, average training loss: 12791.12, base loss: 22055.76
[INFO 2017-06-28 23:57:51,150 main.py:57] epoch 447, training loss: 11212.45, average training loss: 12787.60, base loss: 22058.68
[INFO 2017-06-28 23:57:54,135 main.py:57] epoch 448, training loss: 10786.65, average training loss: 12783.14, base loss: 22059.46
[INFO 2017-06-28 23:57:56,842 main.py:57] epoch 449, training loss: 11632.67, average training loss: 12780.59, base loss: 22057.33
[INFO 2017-06-28 23:57:59,778 main.py:57] epoch 450, training loss: 10771.71, average training loss: 12776.13, base loss: 22053.68
[INFO 2017-06-28 23:58:02,482 main.py:57] epoch 451, training loss: 11506.63, average training loss: 12773.32, base loss: 22054.59
[INFO 2017-06-28 23:58:05,408 main.py:57] epoch 452, training loss: 12243.84, average training loss: 12772.15, base loss: 22056.84
[INFO 2017-06-28 23:58:08,244 main.py:57] epoch 453, training loss: 11584.88, average training loss: 12769.54, base loss: 22057.09
[INFO 2017-06-28 23:58:10,963 main.py:57] epoch 454, training loss: 10278.32, average training loss: 12764.06, base loss: 22055.48
[INFO 2017-06-28 23:58:13,790 main.py:57] epoch 455, training loss: 10079.34, average training loss: 12758.18, base loss: 22052.13
[INFO 2017-06-28 23:58:16,629 main.py:57] epoch 456, training loss: 10038.69, average training loss: 12752.23, base loss: 22046.52
[INFO 2017-06-28 23:58:19,317 main.py:57] epoch 457, training loss: 11551.40, average training loss: 12749.60, base loss: 22045.22
[INFO 2017-06-28 23:58:22,054 main.py:57] epoch 458, training loss: 10507.00, average training loss: 12744.72, base loss: 22042.33
[INFO 2017-06-28 23:58:24,877 main.py:57] epoch 459, training loss: 10094.33, average training loss: 12738.96, base loss: 22037.81
[INFO 2017-06-28 23:58:27,628 main.py:57] epoch 460, training loss: 11753.25, average training loss: 12736.82, base loss: 22037.00
[INFO 2017-06-28 23:58:30,356 main.py:57] epoch 461, training loss: 9439.14, average training loss: 12729.68, base loss: 22030.73
[INFO 2017-06-28 23:58:33,331 main.py:57] epoch 462, training loss: 9953.97, average training loss: 12723.68, base loss: 22026.92
[INFO 2017-06-28 23:58:36,131 main.py:57] epoch 463, training loss: 10343.27, average training loss: 12718.55, base loss: 22024.37
[INFO 2017-06-28 23:58:39,023 main.py:57] epoch 464, training loss: 10798.80, average training loss: 12714.43, base loss: 22021.05
[INFO 2017-06-28 23:58:41,992 main.py:57] epoch 465, training loss: 11757.91, average training loss: 12712.37, base loss: 22022.56
[INFO 2017-06-28 23:58:44,916 main.py:57] epoch 466, training loss: 10250.15, average training loss: 12707.10, base loss: 22021.01
[INFO 2017-06-28 23:58:47,760 main.py:57] epoch 467, training loss: 11178.35, average training loss: 12703.83, base loss: 22021.94
[INFO 2017-06-28 23:58:50,652 main.py:57] epoch 468, training loss: 10048.16, average training loss: 12698.17, base loss: 22020.18
