[INFO 2017-06-29 12:06:35,976 main.py:175] Namespace(batch_size=32, display=False, flow_dir='flow', flow_video_dir='flow-video', flow_video_fps=1, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=4, num_channel=3, num_inputs=2, save_dir='./model', test=False, test_dir='/home/yi/Downloads/mpii-test-64', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='/home/yi/Downloads/mpii-64', train_epoch=100000)
[INFO 2017-06-29 12:06:41,141 main.py:57] epoch 0, training loss: 38269.71, average training loss: 38269.71, base loss: 14860.74
[INFO 2017-06-29 12:06:43,826 main.py:57] epoch 1, training loss: 29966.03, average training loss: 34117.87, base loss: 15118.15
[INFO 2017-06-29 12:06:46,546 main.py:57] epoch 2, training loss: 27553.17, average training loss: 31929.64, base loss: 15461.29
[INFO 2017-06-29 12:06:49,418 main.py:57] epoch 3, training loss: 22912.87, average training loss: 29675.44, base loss: 15156.70
[INFO 2017-06-29 12:06:52,728 main.py:57] epoch 4, training loss: 20829.29, average training loss: 27906.21, base loss: 15155.56
[INFO 2017-06-29 12:06:56,119 main.py:57] epoch 5, training loss: 19141.62, average training loss: 26445.45, base loss: 15326.60
[INFO 2017-06-29 12:06:59,268 main.py:57] epoch 6, training loss: 19932.87, average training loss: 25515.08, base loss: 15848.71
[INFO 2017-06-29 12:07:02,558 main.py:57] epoch 7, training loss: 18024.08, average training loss: 24578.70, base loss: 16021.99
[INFO 2017-06-29 12:07:05,907 main.py:57] epoch 8, training loss: 16242.67, average training loss: 23652.48, base loss: 16029.71
[INFO 2017-06-29 12:07:09,128 main.py:57] epoch 9, training loss: 15033.29, average training loss: 22790.56, base loss: 15961.64
[INFO 2017-06-29 12:07:12,380 main.py:57] epoch 10, training loss: 14039.69, average training loss: 21995.03, base loss: 15746.40
[INFO 2017-06-29 12:07:15,695 main.py:57] epoch 11, training loss: 14044.46, average training loss: 21332.48, base loss: 15683.61
[INFO 2017-06-29 12:07:19,017 main.py:57] epoch 12, training loss: 15117.15, average training loss: 20854.38, base loss: 15711.81
[INFO 2017-06-29 12:07:22,313 main.py:57] epoch 13, training loss: 12990.63, average training loss: 20292.68, base loss: 15593.94
[INFO 2017-06-29 12:07:25,582 main.py:57] epoch 14, training loss: 12687.61, average training loss: 19785.68, base loss: 15467.84
[INFO 2017-06-29 12:07:28,892 main.py:57] epoch 15, training loss: 13733.45, average training loss: 19407.41, base loss: 15463.56
[INFO 2017-06-29 12:07:32,132 main.py:57] epoch 16, training loss: 13026.97, average training loss: 19032.09, base loss: 15426.47
[INFO 2017-06-29 12:07:35,404 main.py:57] epoch 17, training loss: 14386.07, average training loss: 18773.98, base loss: 15486.07
[INFO 2017-06-29 12:07:38,563 main.py:57] epoch 18, training loss: 13628.59, average training loss: 18503.17, base loss: 15488.99
[INFO 2017-06-29 12:07:41,849 main.py:57] epoch 19, training loss: 11818.26, average training loss: 18168.92, base loss: 15390.13
[INFO 2017-06-29 12:07:45,170 main.py:57] epoch 20, training loss: 13511.90, average training loss: 17947.16, base loss: 15399.93
[INFO 2017-06-29 12:07:48,603 main.py:57] epoch 21, training loss: 13806.67, average training loss: 17758.96, base loss: 15421.06
[INFO 2017-06-29 12:07:51,953 main.py:57] epoch 22, training loss: 12569.24, average training loss: 17533.32, base loss: 15378.97
[INFO 2017-06-29 12:07:55,163 main.py:57] epoch 23, training loss: 14031.15, average training loss: 17387.39, base loss: 15424.55
[INFO 2017-06-29 12:07:58,419 main.py:57] epoch 24, training loss: 13605.59, average training loss: 17236.12, base loss: 15435.36
[INFO 2017-06-29 12:08:01,658 main.py:57] epoch 25, training loss: 12798.62, average training loss: 17065.45, base loss: 15418.99
[INFO 2017-06-29 12:08:05,143 main.py:57] epoch 26, training loss: 12202.54, average training loss: 16885.34, base loss: 15374.90
[INFO 2017-06-29 12:08:08,359 main.py:57] epoch 27, training loss: 15092.93, average training loss: 16821.33, base loss: 15465.99
[INFO 2017-06-29 12:08:11,648 main.py:57] epoch 28, training loss: 12437.96, average training loss: 16670.17, base loss: 15433.99
[INFO 2017-06-29 12:08:14,968 main.py:57] epoch 29, training loss: 13836.78, average training loss: 16575.73, base loss: 15458.40
[INFO 2017-06-29 12:08:18,155 main.py:57] epoch 30, training loss: 13445.07, average training loss: 16474.74, base loss: 15472.07
[INFO 2017-06-29 12:08:21,478 main.py:57] epoch 31, training loss: 14821.73, average training loss: 16423.08, base loss: 15534.84
[INFO 2017-06-29 12:08:24,709 main.py:57] epoch 32, training loss: 14186.60, average training loss: 16355.31, base loss: 15572.47
[INFO 2017-06-29 12:08:27,982 main.py:57] epoch 33, training loss: 13802.88, average training loss: 16280.24, base loss: 15596.98
[INFO 2017-06-29 12:08:31,318 main.py:57] epoch 34, training loss: 15625.62, average training loss: 16261.54, base loss: 15690.47
[INFO 2017-06-29 12:08:34,467 main.py:57] epoch 35, training loss: 13670.32, average training loss: 16189.56, base loss: 15702.08
[INFO 2017-06-29 12:08:37,738 main.py:57] epoch 36, training loss: 13819.05, average training loss: 16125.49, base loss: 15727.76
[INFO 2017-06-29 12:08:41,152 main.py:57] epoch 37, training loss: 12935.19, average training loss: 16041.53, base loss: 15720.89
[INFO 2017-06-29 12:08:44,313 main.py:57] epoch 38, training loss: 12195.62, average training loss: 15942.92, base loss: 15691.96
[INFO 2017-06-29 12:08:47,868 main.py:57] epoch 39, training loss: 12588.62, average training loss: 15859.06, base loss: 15682.24
[INFO 2017-06-29 12:08:51,164 main.py:57] epoch 40, training loss: 12798.48, average training loss: 15784.42, base loss: 15683.99
[INFO 2017-06-29 12:08:54,457 main.py:57] epoch 41, training loss: 13469.97, average training loss: 15729.31, base loss: 15702.18
[INFO 2017-06-29 12:08:57,813 main.py:57] epoch 42, training loss: 11831.81, average training loss: 15638.67, base loss: 15666.49
[INFO 2017-06-29 12:09:01,121 main.py:57] epoch 43, training loss: 13219.20, average training loss: 15583.68, base loss: 15683.19
[INFO 2017-06-29 12:09:04,368 main.py:57] epoch 44, training loss: 12416.99, average training loss: 15513.31, base loss: 15671.87
[INFO 2017-06-29 12:09:07,489 main.py:57] epoch 45, training loss: 10915.38, average training loss: 15413.36, base loss: 15616.89
[INFO 2017-06-29 12:09:10,750 main.py:57] epoch 46, training loss: 12215.37, average training loss: 15345.31, base loss: 15598.87
[INFO 2017-06-29 12:09:13,956 main.py:57] epoch 47, training loss: 14442.01, average training loss: 15326.50, base loss: 15650.00
[INFO 2017-06-29 12:09:17,536 main.py:57] epoch 48, training loss: 12212.33, average training loss: 15262.94, base loss: 15631.96
[INFO 2017-06-29 12:09:20,740 main.py:57] epoch 49, training loss: 12235.32, average training loss: 15202.39, base loss: 15624.91
[INFO 2017-06-29 12:09:24,087 main.py:57] epoch 50, training loss: 13745.39, average training loss: 15173.82, base loss: 15652.82
[INFO 2017-06-29 12:09:27,316 main.py:57] epoch 51, training loss: 13907.09, average training loss: 15149.46, base loss: 15694.17
[INFO 2017-06-29 12:09:30,541 main.py:57] epoch 52, training loss: 12168.38, average training loss: 15093.21, base loss: 15686.11
[INFO 2017-06-29 12:09:33,973 main.py:57] epoch 53, training loss: 10959.07, average training loss: 15016.65, base loss: 15649.20
[INFO 2017-06-29 12:09:37,080 main.py:57] epoch 54, training loss: 12688.69, average training loss: 14974.33, base loss: 15651.51
[INFO 2017-06-29 12:09:40,395 main.py:57] epoch 55, training loss: 12520.40, average training loss: 14930.51, base loss: 15653.14
[INFO 2017-06-29 12:09:43,571 main.py:57] epoch 56, training loss: 13256.62, average training loss: 14901.14, base loss: 15665.86
[INFO 2017-06-29 12:09:46,738 main.py:57] epoch 57, training loss: 13085.62, average training loss: 14869.84, base loss: 15678.36
[INFO 2017-06-29 12:09:50,075 main.py:57] epoch 58, training loss: 12907.96, average training loss: 14836.59, base loss: 15686.88
[INFO 2017-06-29 12:09:53,377 main.py:57] epoch 59, training loss: 11837.13, average training loss: 14786.60, base loss: 15666.21
[INFO 2017-06-29 12:09:56,720 main.py:57] epoch 60, training loss: 12388.71, average training loss: 14747.29, base loss: 15667.10
[INFO 2017-06-29 12:10:00,027 main.py:57] epoch 61, training loss: 13141.98, average training loss: 14721.39, base loss: 15685.45
[INFO 2017-06-29 12:10:03,183 main.py:57] epoch 62, training loss: 12884.71, average training loss: 14692.24, base loss: 15689.58
[INFO 2017-06-29 12:10:06,505 main.py:57] epoch 63, training loss: 12014.85, average training loss: 14650.41, base loss: 15684.94
[INFO 2017-06-29 12:10:09,851 main.py:57] epoch 64, training loss: 11528.18, average training loss: 14602.37, base loss: 15671.30
[INFO 2017-06-29 12:10:13,248 main.py:57] epoch 65, training loss: 13130.54, average training loss: 14580.07, base loss: 15682.18
[INFO 2017-06-29 12:10:16,486 main.py:57] epoch 66, training loss: 13521.33, average training loss: 14564.27, base loss: 15712.13
[INFO 2017-06-29 12:10:19,634 main.py:57] epoch 67, training loss: 11655.64, average training loss: 14521.50, base loss: 15690.66
[INFO 2017-06-29 12:10:22,922 main.py:57] epoch 68, training loss: 11326.44, average training loss: 14475.19, base loss: 15680.23
[INFO 2017-06-29 12:10:26,215 main.py:57] epoch 69, training loss: 12839.73, average training loss: 14451.83, base loss: 15692.97
[INFO 2017-06-29 12:10:29,456 main.py:57] epoch 70, training loss: 11724.65, average training loss: 14413.42, base loss: 15689.88
[INFO 2017-06-29 12:10:32,720 main.py:57] epoch 71, training loss: 11319.39, average training loss: 14370.44, base loss: 15674.87
[INFO 2017-06-29 12:10:35,896 main.py:57] epoch 72, training loss: 12758.60, average training loss: 14348.36, base loss: 15689.63
[INFO 2017-06-29 12:10:39,146 main.py:57] epoch 73, training loss: 12420.25, average training loss: 14322.31, base loss: 15694.28
[INFO 2017-06-29 12:10:42,382 main.py:57] epoch 74, training loss: 11568.62, average training loss: 14285.59, base loss: 15680.22
[INFO 2017-06-29 12:10:45,575 main.py:57] epoch 75, training loss: 11464.91, average training loss: 14248.48, base loss: 15671.54
[INFO 2017-06-29 12:10:48,856 main.py:57] epoch 76, training loss: 13803.74, average training loss: 14242.70, base loss: 15702.22
[INFO 2017-06-29 12:10:52,114 main.py:57] epoch 77, training loss: 11258.21, average training loss: 14204.44, base loss: 15709.24
[INFO 2017-06-29 12:10:55,259 main.py:57] epoch 78, training loss: 13783.85, average training loss: 14199.12, base loss: 15746.69
[INFO 2017-06-29 12:10:58,627 main.py:57] epoch 79, training loss: 12083.20, average training loss: 14172.67, base loss: 15754.18
[INFO 2017-06-29 12:11:01,846 main.py:57] epoch 80, training loss: 12627.84, average training loss: 14153.59, base loss: 15761.53
[INFO 2017-06-29 12:11:05,155 main.py:57] epoch 81, training loss: 11485.69, average training loss: 14121.06, base loss: 15751.65
[INFO 2017-06-29 12:11:08,409 main.py:57] epoch 82, training loss: 13200.54, average training loss: 14109.97, base loss: 15773.39
[INFO 2017-06-29 12:11:11,923 main.py:57] epoch 83, training loss: 11075.33, average training loss: 14073.84, base loss: 15764.20
[INFO 2017-06-29 12:11:15,192 main.py:57] epoch 84, training loss: 10421.07, average training loss: 14030.87, base loss: 15737.66
[INFO 2017-06-29 12:11:18,525 main.py:57] epoch 85, training loss: 11206.62, average training loss: 13998.03, base loss: 15723.05
[INFO 2017-06-29 12:11:21,668 main.py:57] epoch 86, training loss: 10981.42, average training loss: 13963.35, base loss: 15718.18
[INFO 2017-06-29 12:11:24,986 main.py:57] epoch 87, training loss: 11659.58, average training loss: 13937.17, base loss: 15716.47
[INFO 2017-06-29 12:11:28,287 main.py:57] epoch 88, training loss: 12350.37, average training loss: 13919.35, base loss: 15730.43
[INFO 2017-06-29 12:11:31,614 main.py:57] epoch 89, training loss: 10707.82, average training loss: 13883.66, base loss: 15715.84
[INFO 2017-06-29 12:11:34,848 main.py:57] epoch 90, training loss: 12169.03, average training loss: 13864.82, base loss: 15725.21
[INFO 2017-06-29 12:11:38,188 main.py:57] epoch 91, training loss: 11286.24, average training loss: 13836.79, base loss: 15726.06
[INFO 2017-06-29 12:11:41,547 main.py:57] epoch 92, training loss: 11962.33, average training loss: 13816.64, base loss: 15733.29
[INFO 2017-06-29 12:11:44,804 main.py:57] epoch 93, training loss: 11136.93, average training loss: 13788.13, base loss: 15736.64
[INFO 2017-06-29 12:11:48,119 main.py:57] epoch 94, training loss: 11638.48, average training loss: 13765.50, base loss: 15738.57
[INFO 2017-06-29 12:11:51,414 main.py:57] epoch 95, training loss: 10696.07, average training loss: 13733.53, base loss: 15728.92
[INFO 2017-06-29 12:11:54,801 main.py:57] epoch 96, training loss: 11162.21, average training loss: 13707.02, base loss: 15717.30
[INFO 2017-06-29 12:11:58,113 main.py:57] epoch 97, training loss: 10386.19, average training loss: 13673.13, base loss: 15706.18
[INFO 2017-06-29 12:12:01,368 main.py:57] epoch 98, training loss: 11338.31, average training loss: 13649.55, base loss: 15709.75
[INFO 2017-06-29 12:12:04,667 main.py:57] epoch 99, training loss: 10484.32, average training loss: 13617.90, base loss: 15703.59
[INFO 2017-06-29 12:12:04,667 main.py:59] epoch 99, testing
[INFO 2017-06-29 12:12:18,465 main.py:104] average testing loss: 10413.83, base loss: 16254.17
[INFO 2017-06-29 12:12:18,465 main.py:105] improve_loss: 5840.35, improve_percent: 0.36
[INFO 2017-06-29 12:12:18,466 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 12:12:18,503 main.py:71] current best improved percent: 0.36
[INFO 2017-06-29 12:12:21,841 main.py:57] epoch 100, training loss: 10185.56, average training loss: 13583.91, base loss: 15692.45
[INFO 2017-06-29 12:12:25,097 main.py:57] epoch 101, training loss: 11369.97, average training loss: 13562.21, base loss: 15693.25
[INFO 2017-06-29 12:12:28,382 main.py:57] epoch 102, training loss: 11805.96, average training loss: 13545.16, base loss: 15701.33
[INFO 2017-06-29 12:12:31,720 main.py:57] epoch 103, training loss: 10663.87, average training loss: 13517.45, base loss: 15697.96
[INFO 2017-06-29 12:12:34,971 main.py:57] epoch 104, training loss: 12034.25, average training loss: 13503.33, base loss: 15711.65
[INFO 2017-06-29 12:12:38,222 main.py:57] epoch 105, training loss: 10539.92, average training loss: 13475.37, base loss: 15705.93
[INFO 2017-06-29 12:12:41,450 main.py:57] epoch 106, training loss: 11585.34, average training loss: 13457.71, base loss: 15714.82
[INFO 2017-06-29 12:12:44,883 main.py:57] epoch 107, training loss: 11213.86, average training loss: 13436.93, base loss: 15715.13
[INFO 2017-06-29 12:12:48,233 main.py:57] epoch 108, training loss: 11690.73, average training loss: 13420.91, base loss: 15721.19
[INFO 2017-06-29 12:12:51,489 main.py:57] epoch 109, training loss: 10671.59, average training loss: 13395.92, base loss: 15713.77
[INFO 2017-06-29 12:12:54,830 main.py:57] epoch 110, training loss: 12891.09, average training loss: 13391.37, base loss: 15731.64
[INFO 2017-06-29 12:12:58,177 main.py:57] epoch 111, training loss: 10413.53, average training loss: 13364.78, base loss: 15721.29
[INFO 2017-06-29 12:13:01,478 main.py:57] epoch 112, training loss: 10637.92, average training loss: 13340.65, base loss: 15718.08
[INFO 2017-06-29 12:13:04,900 main.py:57] epoch 113, training loss: 10151.84, average training loss: 13312.68, base loss: 15702.45
[INFO 2017-06-29 12:13:08,131 main.py:57] epoch 114, training loss: 11180.45, average training loss: 13294.14, base loss: 15708.37
[INFO 2017-06-29 12:13:11,379 main.py:57] epoch 115, training loss: 10898.69, average training loss: 13273.48, base loss: 15703.69
[INFO 2017-06-29 12:13:14,591 main.py:57] epoch 116, training loss: 12056.53, average training loss: 13263.08, base loss: 15719.52
[INFO 2017-06-29 12:13:17,980 main.py:57] epoch 117, training loss: 10887.27, average training loss: 13242.95, base loss: 15727.73
[INFO 2017-06-29 12:13:21,224 main.py:57] epoch 118, training loss: 9783.47, average training loss: 13213.88, base loss: 15708.58
[INFO 2017-06-29 12:13:24,501 main.py:57] epoch 119, training loss: 10353.88, average training loss: 13190.04, base loss: 15703.20
[INFO 2017-06-29 12:13:27,680 main.py:57] epoch 120, training loss: 11584.88, average training loss: 13176.78, base loss: 15711.52
[INFO 2017-06-29 12:13:30,991 main.py:57] epoch 121, training loss: 11859.23, average training loss: 13165.98, base loss: 15711.74
[INFO 2017-06-29 12:13:34,174 main.py:57] epoch 122, training loss: 10574.73, average training loss: 13144.91, base loss: 15714.24
[INFO 2017-06-29 12:13:37,476 main.py:57] epoch 123, training loss: 11201.38, average training loss: 13129.24, base loss: 15716.31
[INFO 2017-06-29 12:13:40,618 main.py:57] epoch 124, training loss: 10947.13, average training loss: 13111.78, base loss: 15716.39
[INFO 2017-06-29 12:13:43,870 main.py:57] epoch 125, training loss: 11321.66, average training loss: 13097.57, base loss: 15711.61
[INFO 2017-06-29 12:13:47,060 main.py:57] epoch 126, training loss: 9944.07, average training loss: 13072.74, base loss: 15705.44
[INFO 2017-06-29 12:13:50,326 main.py:57] epoch 127, training loss: 10395.45, average training loss: 13051.83, base loss: 15701.68
[INFO 2017-06-29 12:13:53,734 main.py:57] epoch 128, training loss: 10058.88, average training loss: 13028.63, base loss: 15693.96
[INFO 2017-06-29 12:13:57,027 main.py:57] epoch 129, training loss: 11925.77, average training loss: 13020.14, base loss: 15706.47
[INFO 2017-06-29 12:14:00,325 main.py:57] epoch 130, training loss: 10981.94, average training loss: 13004.58, base loss: 15701.43
[INFO 2017-06-29 12:14:03,465 main.py:57] epoch 131, training loss: 11019.80, average training loss: 12989.55, base loss: 15701.05
[INFO 2017-06-29 12:14:06,733 main.py:57] epoch 132, training loss: 12415.00, average training loss: 12985.23, base loss: 15716.35
[INFO 2017-06-29 12:14:09,908 main.py:57] epoch 133, training loss: 11657.12, average training loss: 12975.32, base loss: 15728.39
[INFO 2017-06-29 12:14:13,058 main.py:57] epoch 134, training loss: 10751.04, average training loss: 12958.84, base loss: 15731.97
[INFO 2017-06-29 12:14:16,222 main.py:57] epoch 135, training loss: 11766.53, average training loss: 12950.07, base loss: 15749.84
[INFO 2017-06-29 12:14:19,538 main.py:57] epoch 136, training loss: 10738.43, average training loss: 12933.93, base loss: 15743.12
[INFO 2017-06-29 12:14:22,843 main.py:57] epoch 137, training loss: 11007.71, average training loss: 12919.97, base loss: 15743.01
[INFO 2017-06-29 12:14:26,218 main.py:57] epoch 138, training loss: 11017.82, average training loss: 12906.29, base loss: 15741.13
[INFO 2017-06-29 12:14:29,538 main.py:57] epoch 139, training loss: 10067.21, average training loss: 12886.01, base loss: 15736.25
[INFO 2017-06-29 12:14:32,808 main.py:57] epoch 140, training loss: 10807.77, average training loss: 12871.27, base loss: 15731.49
[INFO 2017-06-29 12:14:36,192 main.py:57] epoch 141, training loss: 10618.08, average training loss: 12855.40, base loss: 15734.82
[INFO 2017-06-29 12:14:39,350 main.py:57] epoch 142, training loss: 10182.17, average training loss: 12836.71, base loss: 15734.65
[INFO 2017-06-29 12:14:42,628 main.py:57] epoch 143, training loss: 10468.86, average training loss: 12820.26, base loss: 15732.29
[INFO 2017-06-29 12:14:46,002 main.py:57] epoch 144, training loss: 10288.46, average training loss: 12802.80, base loss: 15731.94
[INFO 2017-06-29 12:14:49,472 main.py:57] epoch 145, training loss: 10663.99, average training loss: 12788.15, base loss: 15727.36
[INFO 2017-06-29 12:14:52,898 main.py:57] epoch 146, training loss: 11586.42, average training loss: 12779.98, base loss: 15736.96
[INFO 2017-06-29 12:14:56,209 main.py:57] epoch 147, training loss: 9010.97, average training loss: 12754.51, base loss: 15717.73
[INFO 2017-06-29 12:14:59,438 main.py:57] epoch 148, training loss: 11464.18, average training loss: 12745.85, base loss: 15719.15
[INFO 2017-06-29 12:15:02,626 main.py:57] epoch 149, training loss: 10526.87, average training loss: 12731.06, base loss: 15718.11
[INFO 2017-06-29 12:15:05,832 main.py:57] epoch 150, training loss: 10334.68, average training loss: 12715.19, base loss: 15716.51
[INFO 2017-06-29 12:15:09,041 main.py:57] epoch 151, training loss: 10675.68, average training loss: 12701.77, base loss: 15715.91
[INFO 2017-06-29 12:15:12,361 main.py:57] epoch 152, training loss: 11901.13, average training loss: 12696.54, base loss: 15724.30
[INFO 2017-06-29 12:15:15,591 main.py:57] epoch 153, training loss: 10785.91, average training loss: 12684.13, base loss: 15728.61
[INFO 2017-06-29 12:15:18,902 main.py:57] epoch 154, training loss: 10345.10, average training loss: 12669.04, base loss: 15722.98
[INFO 2017-06-29 12:15:22,219 main.py:57] epoch 155, training loss: 9410.36, average training loss: 12648.15, base loss: 15704.01
[INFO 2017-06-29 12:15:25,399 main.py:57] epoch 156, training loss: 10387.61, average training loss: 12633.75, base loss: 15698.86
[INFO 2017-06-29 12:15:28,548 main.py:57] epoch 157, training loss: 10410.12, average training loss: 12619.68, base loss: 15698.73
[INFO 2017-06-29 12:15:31,833 main.py:57] epoch 158, training loss: 10397.00, average training loss: 12605.70, base loss: 15694.21
[INFO 2017-06-29 12:15:35,198 main.py:57] epoch 159, training loss: 9002.04, average training loss: 12583.18, base loss: 15680.78
[INFO 2017-06-29 12:15:38,463 main.py:57] epoch 160, training loss: 10495.33, average training loss: 12570.21, base loss: 15685.73
[INFO 2017-06-29 12:15:41,586 main.py:57] epoch 161, training loss: 11337.21, average training loss: 12562.60, base loss: 15689.21
[INFO 2017-06-29 12:15:44,959 main.py:57] epoch 162, training loss: 11923.43, average training loss: 12558.68, base loss: 15704.35
[INFO 2017-06-29 12:15:48,313 main.py:57] epoch 163, training loss: 9735.76, average training loss: 12541.47, base loss: 15699.58
[INFO 2017-06-29 12:15:51,724 main.py:57] epoch 164, training loss: 10044.85, average training loss: 12526.33, base loss: 15695.43
[INFO 2017-06-29 12:15:55,139 main.py:57] epoch 165, training loss: 11774.38, average training loss: 12521.80, base loss: 15707.65
[INFO 2017-06-29 12:15:58,507 main.py:57] epoch 166, training loss: 10848.74, average training loss: 12511.79, base loss: 15710.46
[INFO 2017-06-29 12:16:01,813 main.py:57] epoch 167, training loss: 10211.77, average training loss: 12498.10, base loss: 15707.82
[INFO 2017-06-29 12:16:05,165 main.py:57] epoch 168, training loss: 9740.12, average training loss: 12481.78, base loss: 15702.30
[INFO 2017-06-29 12:16:08,632 main.py:57] epoch 169, training loss: 9071.62, average training loss: 12461.72, base loss: 15691.23
[INFO 2017-06-29 12:16:11,825 main.py:57] epoch 170, training loss: 9951.33, average training loss: 12447.04, base loss: 15686.72
[INFO 2017-06-29 12:16:15,209 main.py:57] epoch 171, training loss: 10661.90, average training loss: 12436.66, base loss: 15689.10
[INFO 2017-06-29 12:16:18,560 main.py:57] epoch 172, training loss: 9888.28, average training loss: 12421.93, base loss: 15691.49
[INFO 2017-06-29 12:16:21,690 main.py:57] epoch 173, training loss: 10526.29, average training loss: 12411.03, base loss: 15689.14
[INFO 2017-06-29 12:16:24,976 main.py:57] epoch 174, training loss: 10676.32, average training loss: 12401.12, base loss: 15700.26
[INFO 2017-06-29 12:16:28,376 main.py:57] epoch 175, training loss: 11104.59, average training loss: 12393.75, base loss: 15697.99
[INFO 2017-06-29 12:16:31,539 main.py:57] epoch 176, training loss: 11016.25, average training loss: 12385.97, base loss: 15705.33
[INFO 2017-06-29 12:16:34,838 main.py:57] epoch 177, training loss: 11085.08, average training loss: 12378.66, base loss: 15714.88
[INFO 2017-06-29 12:16:38,089 main.py:57] epoch 178, training loss: 10976.77, average training loss: 12370.83, base loss: 15719.97
[INFO 2017-06-29 12:16:41,444 main.py:57] epoch 179, training loss: 12063.50, average training loss: 12369.12, base loss: 15741.18
[INFO 2017-06-29 12:16:44,643 main.py:57] epoch 180, training loss: 10543.32, average training loss: 12359.04, base loss: 15743.10
[INFO 2017-06-29 12:16:48,072 main.py:57] epoch 181, training loss: 10182.79, average training loss: 12347.08, base loss: 15742.42
[INFO 2017-06-29 12:16:51,371 main.py:57] epoch 182, training loss: 9383.14, average training loss: 12330.88, base loss: 15729.20
[INFO 2017-06-29 12:16:54,624 main.py:57] epoch 183, training loss: 11975.03, average training loss: 12328.95, base loss: 15735.45
[INFO 2017-06-29 12:16:57,993 main.py:57] epoch 184, training loss: 11220.11, average training loss: 12322.95, base loss: 15742.41
[INFO 2017-06-29 12:17:01,356 main.py:57] epoch 185, training loss: 11703.19, average training loss: 12319.62, base loss: 15749.90
[INFO 2017-06-29 12:17:04,612 main.py:57] epoch 186, training loss: 10554.39, average training loss: 12310.18, base loss: 15753.58
[INFO 2017-06-29 12:17:07,880 main.py:57] epoch 187, training loss: 10887.31, average training loss: 12302.61, base loss: 15756.37
[INFO 2017-06-29 12:17:11,261 main.py:57] epoch 188, training loss: 10166.49, average training loss: 12291.31, base loss: 15755.12
[INFO 2017-06-29 12:17:14,487 main.py:57] epoch 189, training loss: 10202.39, average training loss: 12280.32, base loss: 15755.86
[INFO 2017-06-29 12:17:17,800 main.py:57] epoch 190, training loss: 10329.19, average training loss: 12270.10, base loss: 15756.15
[INFO 2017-06-29 12:17:21,068 main.py:57] epoch 191, training loss: 9926.88, average training loss: 12257.90, base loss: 15755.44
[INFO 2017-06-29 12:17:24,263 main.py:57] epoch 192, training loss: 10120.90, average training loss: 12246.83, base loss: 15756.94
[INFO 2017-06-29 12:17:27,703 main.py:57] epoch 193, training loss: 10021.76, average training loss: 12235.36, base loss: 15759.42
[INFO 2017-06-29 12:17:30,894 main.py:57] epoch 194, training loss: 9536.55, average training loss: 12221.52, base loss: 15745.51
[INFO 2017-06-29 12:17:34,297 main.py:57] epoch 195, training loss: 9881.72, average training loss: 12209.58, base loss: 15743.42
[INFO 2017-06-29 12:17:37,667 main.py:57] epoch 196, training loss: 10606.27, average training loss: 12201.44, base loss: 15748.92
[INFO 2017-06-29 12:17:40,973 main.py:57] epoch 197, training loss: 10279.66, average training loss: 12191.73, base loss: 15752.13
[INFO 2017-06-29 12:17:44,239 main.py:57] epoch 198, training loss: 9906.79, average training loss: 12180.25, base loss: 15750.96
[INFO 2017-06-29 12:17:47,662 main.py:57] epoch 199, training loss: 10229.08, average training loss: 12170.50, base loss: 15751.13
[INFO 2017-06-29 12:17:47,662 main.py:59] epoch 199, testing
[INFO 2017-06-29 12:18:01,309 main.py:104] average testing loss: 9655.95, base loss: 16765.94
[INFO 2017-06-29 12:18:01,309 main.py:105] improve_loss: 7109.99, improve_percent: 0.42
[INFO 2017-06-29 12:18:01,311 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 12:18:01,350 main.py:71] current best improved percent: 0.42
[INFO 2017-06-29 12:18:04,712 main.py:57] epoch 200, training loss: 10448.03, average training loss: 12161.93, base loss: 15748.97
[INFO 2017-06-29 12:18:08,242 main.py:57] epoch 201, training loss: 10149.99, average training loss: 12151.97, base loss: 15751.54
[INFO 2017-06-29 12:18:11,560 main.py:57] epoch 202, training loss: 10390.10, average training loss: 12143.29, base loss: 15751.36
[INFO 2017-06-29 12:18:14,775 main.py:57] epoch 203, training loss: 11182.26, average training loss: 12138.58, base loss: 15758.61
[INFO 2017-06-29 12:18:17,992 main.py:57] epoch 204, training loss: 9936.85, average training loss: 12127.84, base loss: 15753.58
[INFO 2017-06-29 12:18:21,313 main.py:57] epoch 205, training loss: 10012.28, average training loss: 12117.57, base loss: 15756.51
[INFO 2017-06-29 12:18:24,679 main.py:57] epoch 206, training loss: 9701.08, average training loss: 12105.89, base loss: 15754.39
[INFO 2017-06-29 12:18:27,959 main.py:57] epoch 207, training loss: 10410.45, average training loss: 12097.74, base loss: 15754.29
[INFO 2017-06-29 12:18:31,311 main.py:57] epoch 208, training loss: 9907.75, average training loss: 12087.26, base loss: 15751.38
[INFO 2017-06-29 12:18:34,537 main.py:57] epoch 209, training loss: 8738.91, average training loss: 12071.32, base loss: 15739.64
[INFO 2017-06-29 12:18:37,948 main.py:57] epoch 210, training loss: 10914.27, average training loss: 12065.83, base loss: 15747.50
[INFO 2017-06-29 12:18:41,225 main.py:57] epoch 211, training loss: 8609.21, average training loss: 12049.53, base loss: 15741.02
[INFO 2017-06-29 12:18:44,416 main.py:57] epoch 212, training loss: 10954.34, average training loss: 12044.39, base loss: 15746.91
[INFO 2017-06-29 12:18:47,802 main.py:57] epoch 213, training loss: 9630.26, average training loss: 12033.11, base loss: 15744.08
[INFO 2017-06-29 12:18:51,074 main.py:57] epoch 214, training loss: 11093.91, average training loss: 12028.74, base loss: 15753.49
[INFO 2017-06-29 12:18:54,425 main.py:57] epoch 215, training loss: 10744.43, average training loss: 12022.79, base loss: 15754.32
[INFO 2017-06-29 12:18:57,805 main.py:57] epoch 216, training loss: 8882.33, average training loss: 12008.32, base loss: 15746.06
[INFO 2017-06-29 12:19:01,086 main.py:57] epoch 217, training loss: 9712.97, average training loss: 11997.79, base loss: 15743.42
[INFO 2017-06-29 12:19:04,315 main.py:57] epoch 218, training loss: 9362.41, average training loss: 11985.76, base loss: 15736.21
[INFO 2017-06-29 12:19:07,496 main.py:57] epoch 219, training loss: 10349.81, average training loss: 11978.32, base loss: 15734.60
[INFO 2017-06-29 12:19:10,732 main.py:57] epoch 220, training loss: 9157.76, average training loss: 11965.56, base loss: 15726.92
[INFO 2017-06-29 12:19:13,952 main.py:57] epoch 221, training loss: 10608.52, average training loss: 11959.45, base loss: 15729.15
[INFO 2017-06-29 12:19:17,379 main.py:57] epoch 222, training loss: 10072.29, average training loss: 11950.98, base loss: 15729.49
[INFO 2017-06-29 12:19:20,653 main.py:57] epoch 223, training loss: 10772.41, average training loss: 11945.72, base loss: 15735.50
[INFO 2017-06-29 12:19:23,916 main.py:57] epoch 224, training loss: 9808.54, average training loss: 11936.22, base loss: 15733.31
[INFO 2017-06-29 12:19:27,161 main.py:57] epoch 225, training loss: 10143.99, average training loss: 11928.29, base loss: 15738.39
[INFO 2017-06-29 12:19:30,504 main.py:57] epoch 226, training loss: 9990.77, average training loss: 11919.76, base loss: 15739.70
[INFO 2017-06-29 12:19:33,837 main.py:57] epoch 227, training loss: 9198.76, average training loss: 11907.82, base loss: 15733.69
[INFO 2017-06-29 12:19:37,042 main.py:57] epoch 228, training loss: 10176.91, average training loss: 11900.26, base loss: 15732.93
[INFO 2017-06-29 12:19:40,363 main.py:57] epoch 229, training loss: 12274.40, average training loss: 11901.89, base loss: 15745.41
[INFO 2017-06-29 12:19:43,714 main.py:57] epoch 230, training loss: 10123.61, average training loss: 11894.19, base loss: 15746.71
[INFO 2017-06-29 12:19:46,932 main.py:57] epoch 231, training loss: 9990.32, average training loss: 11885.99, base loss: 15747.33
[INFO 2017-06-29 12:19:50,247 main.py:57] epoch 232, training loss: 9135.23, average training loss: 11874.18, base loss: 15741.06
[INFO 2017-06-29 12:19:53,361 main.py:57] epoch 233, training loss: 9899.77, average training loss: 11865.74, base loss: 15739.57
[INFO 2017-06-29 12:19:56,633 main.py:57] epoch 234, training loss: 9952.16, average training loss: 11857.60, base loss: 15737.73
[INFO 2017-06-29 12:19:59,830 main.py:57] epoch 235, training loss: 10124.62, average training loss: 11850.26, base loss: 15741.58
[INFO 2017-06-29 12:20:03,201 main.py:57] epoch 236, training loss: 12154.44, average training loss: 11851.54, base loss: 15753.08
[INFO 2017-06-29 12:20:06,605 main.py:57] epoch 237, training loss: 9781.54, average training loss: 11842.84, base loss: 15747.54
[INFO 2017-06-29 12:20:09,856 main.py:57] epoch 238, training loss: 9810.65, average training loss: 11834.34, base loss: 15748.48
[INFO 2017-06-29 12:20:13,062 main.py:57] epoch 239, training loss: 9938.76, average training loss: 11826.44, base loss: 15753.15
[INFO 2017-06-29 12:20:16,351 main.py:57] epoch 240, training loss: 8949.38, average training loss: 11814.50, base loss: 15745.96
[INFO 2017-06-29 12:20:19,624 main.py:57] epoch 241, training loss: 9384.29, average training loss: 11804.46, base loss: 15743.40
[INFO 2017-06-29 12:20:22,949 main.py:57] epoch 242, training loss: 11035.75, average training loss: 11801.30, base loss: 15753.93
[INFO 2017-06-29 12:20:26,210 main.py:57] epoch 243, training loss: 8845.25, average training loss: 11789.18, base loss: 15748.69
[INFO 2017-06-29 12:20:29,596 main.py:57] epoch 244, training loss: 10598.67, average training loss: 11784.32, base loss: 15752.62
[INFO 2017-06-29 12:20:32,863 main.py:57] epoch 245, training loss: 9410.45, average training loss: 11774.67, base loss: 15745.34
[INFO 2017-06-29 12:20:36,269 main.py:57] epoch 246, training loss: 10234.68, average training loss: 11768.44, base loss: 15744.64
[INFO 2017-06-29 12:20:39,505 main.py:57] epoch 247, training loss: 9483.22, average training loss: 11759.23, base loss: 15742.65
[INFO 2017-06-29 12:20:42,790 main.py:57] epoch 248, training loss: 9761.44, average training loss: 11751.20, base loss: 15743.91
[INFO 2017-06-29 12:20:46,140 main.py:57] epoch 249, training loss: 9723.41, average training loss: 11743.09, base loss: 15744.78
[INFO 2017-06-29 12:20:49,521 main.py:57] epoch 250, training loss: 10700.53, average training loss: 11738.94, base loss: 15748.71
[INFO 2017-06-29 12:20:52,648 main.py:57] epoch 251, training loss: 9875.90, average training loss: 11731.54, base loss: 15745.80
[INFO 2017-06-29 12:20:55,927 main.py:57] epoch 252, training loss: 10873.61, average training loss: 11728.15, base loss: 15750.70
[INFO 2017-06-29 12:20:59,192 main.py:57] epoch 253, training loss: 12857.56, average training loss: 11732.60, base loss: 15767.34
[INFO 2017-06-29 12:21:02,531 main.py:57] epoch 254, training loss: 10173.96, average training loss: 11726.49, base loss: 15766.94
[INFO 2017-06-29 12:21:05,777 main.py:57] epoch 255, training loss: 9621.95, average training loss: 11718.27, base loss: 15761.54
[INFO 2017-06-29 12:21:08,975 main.py:57] epoch 256, training loss: 10020.07, average training loss: 11711.66, base loss: 15762.35
[INFO 2017-06-29 12:21:12,262 main.py:57] epoch 257, training loss: 8836.70, average training loss: 11700.52, base loss: 15751.00
[INFO 2017-06-29 12:21:15,486 main.py:57] epoch 258, training loss: 8883.14, average training loss: 11689.64, base loss: 15746.44
[INFO 2017-06-29 12:21:18,843 main.py:57] epoch 259, training loss: 9862.05, average training loss: 11682.61, base loss: 15746.07
[INFO 2017-06-29 12:21:22,181 main.py:57] epoch 260, training loss: 11008.23, average training loss: 11680.02, base loss: 15752.46
[INFO 2017-06-29 12:21:25,460 main.py:57] epoch 261, training loss: 9471.70, average training loss: 11671.60, base loss: 15748.93
[INFO 2017-06-29 12:21:28,641 main.py:57] epoch 262, training loss: 9710.66, average training loss: 11664.14, base loss: 15748.41
[INFO 2017-06-29 12:21:31,861 main.py:57] epoch 263, training loss: 10353.56, average training loss: 11659.18, base loss: 15749.28
[INFO 2017-06-29 12:21:35,085 main.py:57] epoch 264, training loss: 10355.24, average training loss: 11654.25, base loss: 15750.71
[INFO 2017-06-29 12:21:38,339 main.py:57] epoch 265, training loss: 10440.62, average training loss: 11649.69, base loss: 15754.99
[INFO 2017-06-29 12:21:41,676 main.py:57] epoch 266, training loss: 8417.82, average training loss: 11637.59, base loss: 15745.04
[INFO 2017-06-29 12:21:44,924 main.py:57] epoch 267, training loss: 10085.90, average training loss: 11631.80, base loss: 15750.84
[INFO 2017-06-29 12:21:48,196 main.py:57] epoch 268, training loss: 9882.06, average training loss: 11625.29, base loss: 15751.44
[INFO 2017-06-29 12:21:51,461 main.py:57] epoch 269, training loss: 9753.11, average training loss: 11618.36, base loss: 15752.44
[INFO 2017-06-29 12:21:54,720 main.py:57] epoch 270, training loss: 10375.78, average training loss: 11613.77, base loss: 15759.42
[INFO 2017-06-29 12:21:58,070 main.py:57] epoch 271, training loss: 8872.24, average training loss: 11603.70, base loss: 15757.17
[INFO 2017-06-29 12:22:01,278 main.py:57] epoch 272, training loss: 10472.09, average training loss: 11599.55, base loss: 15757.86
[INFO 2017-06-29 12:22:04,525 main.py:57] epoch 273, training loss: 8968.16, average training loss: 11589.95, base loss: 15755.89
[INFO 2017-06-29 12:22:07,858 main.py:57] epoch 274, training loss: 9443.13, average training loss: 11582.14, base loss: 15752.71
[INFO 2017-06-29 12:22:11,126 main.py:57] epoch 275, training loss: 9580.98, average training loss: 11574.89, base loss: 15750.53
[INFO 2017-06-29 12:22:14,320 main.py:57] epoch 276, training loss: 10490.43, average training loss: 11570.97, base loss: 15751.77
[INFO 2017-06-29 12:22:17,730 main.py:57] epoch 277, training loss: 10708.60, average training loss: 11567.87, base loss: 15755.70
[INFO 2017-06-29 12:22:20,964 main.py:57] epoch 278, training loss: 9158.96, average training loss: 11559.24, base loss: 15754.98
[INFO 2017-06-29 12:22:24,185 main.py:57] epoch 279, training loss: 9167.56, average training loss: 11550.70, base loss: 15751.28
[INFO 2017-06-29 12:22:27,482 main.py:57] epoch 280, training loss: 10477.79, average training loss: 11546.88, base loss: 15754.05
[INFO 2017-06-29 12:22:30,800 main.py:57] epoch 281, training loss: 9875.58, average training loss: 11540.95, base loss: 15753.43
[INFO 2017-06-29 12:22:34,050 main.py:57] epoch 282, training loss: 9858.90, average training loss: 11535.01, base loss: 15753.88
[INFO 2017-06-29 12:22:37,378 main.py:57] epoch 283, training loss: 10263.32, average training loss: 11530.53, base loss: 15754.15
[INFO 2017-06-29 12:22:40,723 main.py:57] epoch 284, training loss: 9973.44, average training loss: 11525.07, base loss: 15758.28
[INFO 2017-06-29 12:22:43,979 main.py:57] epoch 285, training loss: 9340.15, average training loss: 11517.43, base loss: 15753.79
[INFO 2017-06-29 12:22:47,319 main.py:57] epoch 286, training loss: 9350.86, average training loss: 11509.88, base loss: 15751.11
[INFO 2017-06-29 12:22:50,690 main.py:57] epoch 287, training loss: 9878.18, average training loss: 11504.21, base loss: 15753.66
[INFO 2017-06-29 12:22:53,812 main.py:57] epoch 288, training loss: 9908.89, average training loss: 11498.69, base loss: 15754.84
[INFO 2017-06-29 12:22:57,140 main.py:57] epoch 289, training loss: 9787.60, average training loss: 11492.79, base loss: 15752.98
[INFO 2017-06-29 12:23:00,486 main.py:57] epoch 290, training loss: 10571.01, average training loss: 11489.62, base loss: 15758.75
[INFO 2017-06-29 12:23:03,809 main.py:57] epoch 291, training loss: 10645.73, average training loss: 11486.73, base loss: 15765.87
[INFO 2017-06-29 12:23:07,017 main.py:57] epoch 292, training loss: 8952.10, average training loss: 11478.08, base loss: 15760.65
[INFO 2017-06-29 12:23:10,460 main.py:57] epoch 293, training loss: 10291.25, average training loss: 11474.05, base loss: 15760.31
[INFO 2017-06-29 12:23:13,838 main.py:57] epoch 294, training loss: 9018.38, average training loss: 11465.72, base loss: 15753.85
[INFO 2017-06-29 12:23:17,165 main.py:57] epoch 295, training loss: 9980.94, average training loss: 11460.71, base loss: 15755.91
[INFO 2017-06-29 12:23:20,524 main.py:57] epoch 296, training loss: 10701.07, average training loss: 11458.15, base loss: 15764.27
[INFO 2017-06-29 12:23:23,857 main.py:57] epoch 297, training loss: 10077.87, average training loss: 11453.52, base loss: 15765.65
[INFO 2017-06-29 12:23:27,171 main.py:57] epoch 298, training loss: 9383.90, average training loss: 11446.60, base loss: 15762.80
[INFO 2017-06-29 12:23:30,527 main.py:57] epoch 299, training loss: 10596.85, average training loss: 11443.76, base loss: 15766.12
[INFO 2017-06-29 12:23:30,527 main.py:59] epoch 299, testing
[INFO 2017-06-29 12:23:44,536 main.py:104] average testing loss: 8846.88, base loss: 16199.68
[INFO 2017-06-29 12:23:44,536 main.py:105] improve_loss: 7352.80, improve_percent: 0.45
[INFO 2017-06-29 12:23:44,538 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 12:23:44,579 main.py:71] current best improved percent: 0.45
[INFO 2017-06-29 12:23:47,887 main.py:57] epoch 300, training loss: 9920.12, average training loss: 11438.70, base loss: 15767.38
[INFO 2017-06-29 12:23:51,247 main.py:57] epoch 301, training loss: 10542.53, average training loss: 11435.73, base loss: 15769.97
[INFO 2017-06-29 12:23:54,424 main.py:57] epoch 302, training loss: 9117.17, average training loss: 11428.08, base loss: 15766.07
[INFO 2017-06-29 12:23:57,782 main.py:57] epoch 303, training loss: 10453.58, average training loss: 11424.88, base loss: 15770.84
[INFO 2017-06-29 12:24:01,024 main.py:57] epoch 304, training loss: 9338.62, average training loss: 11418.04, base loss: 15768.60
[INFO 2017-06-29 12:24:04,269 main.py:57] epoch 305, training loss: 10609.02, average training loss: 11415.39, base loss: 15773.11
[INFO 2017-06-29 12:24:07,534 main.py:57] epoch 306, training loss: 8013.87, average training loss: 11404.31, base loss: 15764.87
[INFO 2017-06-29 12:24:10,873 main.py:57] epoch 307, training loss: 9724.80, average training loss: 11398.86, base loss: 15770.70
[INFO 2017-06-29 12:24:14,101 main.py:57] epoch 308, training loss: 9942.38, average training loss: 11394.15, base loss: 15771.11
[INFO 2017-06-29 12:24:17,510 main.py:57] epoch 309, training loss: 10525.39, average training loss: 11391.34, base loss: 15775.63
[INFO 2017-06-29 12:24:20,839 main.py:57] epoch 310, training loss: 10226.68, average training loss: 11387.60, base loss: 15775.90
[INFO 2017-06-29 12:24:24,064 main.py:57] epoch 311, training loss: 10511.59, average training loss: 11384.79, base loss: 15782.90
[INFO 2017-06-29 12:24:27,278 main.py:57] epoch 312, training loss: 10729.51, average training loss: 11382.70, base loss: 15788.16
[INFO 2017-06-29 12:24:30,355 main.py:57] epoch 313, training loss: 10070.88, average training loss: 11378.52, base loss: 15791.87
[INFO 2017-06-29 12:24:33,609 main.py:57] epoch 314, training loss: 9676.34, average training loss: 11373.12, base loss: 15790.58
[INFO 2017-06-29 12:24:36,953 main.py:57] epoch 315, training loss: 10572.89, average training loss: 11370.58, base loss: 15795.13
[INFO 2017-06-29 12:24:40,225 main.py:57] epoch 316, training loss: 8927.20, average training loss: 11362.87, base loss: 15791.74
[INFO 2017-06-29 12:24:43,477 main.py:57] epoch 317, training loss: 9117.51, average training loss: 11355.81, base loss: 15789.99
[INFO 2017-06-29 12:24:46,793 main.py:57] epoch 318, training loss: 10315.57, average training loss: 11352.55, base loss: 15792.27
[INFO 2017-06-29 12:24:49,966 main.py:57] epoch 319, training loss: 8430.87, average training loss: 11343.42, base loss: 15786.78
[INFO 2017-06-29 12:24:53,257 main.py:57] epoch 320, training loss: 10103.56, average training loss: 11339.56, base loss: 15789.11
[INFO 2017-06-29 12:24:56,578 main.py:57] epoch 321, training loss: 10096.97, average training loss: 11335.70, base loss: 15790.66
[INFO 2017-06-29 12:24:59,748 main.py:57] epoch 322, training loss: 10045.81, average training loss: 11331.71, base loss: 15792.64
[INFO 2017-06-29 12:25:02,945 main.py:57] epoch 323, training loss: 10155.79, average training loss: 11328.08, base loss: 15797.84
[INFO 2017-06-29 12:25:06,096 main.py:57] epoch 324, training loss: 10131.94, average training loss: 11324.40, base loss: 15801.01
[INFO 2017-06-29 12:25:09,427 main.py:57] epoch 325, training loss: 9656.35, average training loss: 11319.28, base loss: 15801.07
[INFO 2017-06-29 12:25:12,789 main.py:57] epoch 326, training loss: 9921.79, average training loss: 11315.01, base loss: 15800.75
[INFO 2017-06-29 12:25:15,989 main.py:57] epoch 327, training loss: 9552.82, average training loss: 11309.64, base loss: 15799.29
[INFO 2017-06-29 12:25:19,462 main.py:57] epoch 328, training loss: 9538.87, average training loss: 11304.25, base loss: 15798.86
[INFO 2017-06-29 12:25:22,753 main.py:57] epoch 329, training loss: 10033.74, average training loss: 11300.40, base loss: 15798.94
[INFO 2017-06-29 12:25:26,004 main.py:57] epoch 330, training loss: 9275.69, average training loss: 11294.29, base loss: 15797.40
[INFO 2017-06-29 12:25:29,324 main.py:57] epoch 331, training loss: 9091.24, average training loss: 11287.65, base loss: 15792.03
[INFO 2017-06-29 12:25:32,653 main.py:57] epoch 332, training loss: 10399.44, average training loss: 11284.98, base loss: 15795.60
[INFO 2017-06-29 12:25:36,081 main.py:57] epoch 333, training loss: 9942.45, average training loss: 11280.96, base loss: 15797.22
[INFO 2017-06-29 12:25:39,388 main.py:57] epoch 334, training loss: 9451.25, average training loss: 11275.50, base loss: 15797.58
[INFO 2017-06-29 12:25:42,708 main.py:57] epoch 335, training loss: 9413.29, average training loss: 11269.96, base loss: 15794.88
[INFO 2017-06-29 12:25:45,911 main.py:57] epoch 336, training loss: 9964.82, average training loss: 11266.09, base loss: 15794.40
[INFO 2017-06-29 12:25:49,302 main.py:57] epoch 337, training loss: 9861.06, average training loss: 11261.93, base loss: 15794.73
[INFO 2017-06-29 12:25:52,639 main.py:57] epoch 338, training loss: 11004.73, average training loss: 11261.17, base loss: 15806.32
[INFO 2017-06-29 12:25:55,908 main.py:57] epoch 339, training loss: 8805.90, average training loss: 11253.95, base loss: 15803.39
[INFO 2017-06-29 12:25:59,280 main.py:57] epoch 340, training loss: 9947.24, average training loss: 11250.12, base loss: 15802.33
[INFO 2017-06-29 12:26:02,417 main.py:57] epoch 341, training loss: 9914.74, average training loss: 11246.21, base loss: 15802.48
[INFO 2017-06-29 12:26:05,741 main.py:57] epoch 342, training loss: 9307.76, average training loss: 11240.56, base loss: 15803.41
[INFO 2017-06-29 12:26:08,937 main.py:57] epoch 343, training loss: 10387.00, average training loss: 11238.08, base loss: 15806.24
[INFO 2017-06-29 12:26:12,216 main.py:57] epoch 344, training loss: 9541.94, average training loss: 11233.16, base loss: 15808.05
[INFO 2017-06-29 12:26:15,470 main.py:57] epoch 345, training loss: 10057.15, average training loss: 11229.76, base loss: 15809.97
[INFO 2017-06-29 12:26:18,772 main.py:57] epoch 346, training loss: 9173.71, average training loss: 11223.84, base loss: 15806.74
[INFO 2017-06-29 12:26:22,045 main.py:57] epoch 347, training loss: 10098.72, average training loss: 11220.61, base loss: 15811.63
[INFO 2017-06-29 12:26:25,208 main.py:57] epoch 348, training loss: 9274.35, average training loss: 11215.03, base loss: 15811.52
[INFO 2017-06-29 12:26:28,574 main.py:57] epoch 349, training loss: 9390.81, average training loss: 11209.82, base loss: 15811.81
[INFO 2017-06-29 12:26:31,928 main.py:57] epoch 350, training loss: 10236.55, average training loss: 11207.05, base loss: 15817.36
[INFO 2017-06-29 12:26:35,124 main.py:57] epoch 351, training loss: 9521.51, average training loss: 11202.26, base loss: 15816.10
[INFO 2017-06-29 12:26:38,372 main.py:57] epoch 352, training loss: 9826.25, average training loss: 11198.36, base loss: 15819.15
[INFO 2017-06-29 12:26:41,779 main.py:57] epoch 353, training loss: 10718.85, average training loss: 11197.00, base loss: 15826.97
[INFO 2017-06-29 12:26:45,005 main.py:57] epoch 354, training loss: 9871.12, average training loss: 11193.27, base loss: 15829.92
[INFO 2017-06-29 12:26:48,235 main.py:57] epoch 355, training loss: 9440.78, average training loss: 11188.35, base loss: 15826.82
[INFO 2017-06-29 12:26:51,417 main.py:57] epoch 356, training loss: 9684.09, average training loss: 11184.13, base loss: 15828.23
[INFO 2017-06-29 12:26:54,787 main.py:57] epoch 357, training loss: 10148.45, average training loss: 11181.24, base loss: 15829.62
[INFO 2017-06-29 12:26:58,058 main.py:57] epoch 358, training loss: 10844.79, average training loss: 11180.30, base loss: 15834.97
[INFO 2017-06-29 12:27:01,594 main.py:57] epoch 359, training loss: 9259.10, average training loss: 11174.97, base loss: 15832.45
[INFO 2017-06-29 12:27:04,893 main.py:57] epoch 360, training loss: 8528.71, average training loss: 11167.64, base loss: 15826.53
[INFO 2017-06-29 12:27:08,112 main.py:57] epoch 361, training loss: 8681.45, average training loss: 11160.77, base loss: 15823.17
[INFO 2017-06-29 12:27:11,446 main.py:57] epoch 362, training loss: 9923.38, average training loss: 11157.36, base loss: 15827.56
[INFO 2017-06-29 12:27:14,645 main.py:57] epoch 363, training loss: 8978.98, average training loss: 11151.37, base loss: 15822.82
[INFO 2017-06-29 12:27:17,868 main.py:57] epoch 364, training loss: 9025.37, average training loss: 11145.55, base loss: 15822.51
[INFO 2017-06-29 12:27:21,118 main.py:57] epoch 365, training loss: 8658.62, average training loss: 11138.75, base loss: 15818.31
[INFO 2017-06-29 12:27:24,333 main.py:57] epoch 366, training loss: 10997.98, average training loss: 11138.37, base loss: 15826.59
[INFO 2017-06-29 12:27:27,557 main.py:57] epoch 367, training loss: 8843.47, average training loss: 11132.14, base loss: 15825.74
[INFO 2017-06-29 12:27:30,971 main.py:57] epoch 368, training loss: 8635.57, average training loss: 11125.37, base loss: 15823.52
[INFO 2017-06-29 12:27:34,258 main.py:57] epoch 369, training loss: 9609.33, average training loss: 11121.27, base loss: 15824.12
[INFO 2017-06-29 12:27:37,502 main.py:57] epoch 370, training loss: 9901.40, average training loss: 11117.98, base loss: 15823.58
[INFO 2017-06-29 12:27:40,850 main.py:57] epoch 371, training loss: 8256.76, average training loss: 11110.29, base loss: 15817.39
[INFO 2017-06-29 12:27:44,312 main.py:57] epoch 372, training loss: 9608.76, average training loss: 11106.27, base loss: 15817.52
[INFO 2017-06-29 12:27:47,620 main.py:57] epoch 373, training loss: 8837.73, average training loss: 11100.20, base loss: 15811.39
[INFO 2017-06-29 12:27:50,802 main.py:57] epoch 374, training loss: 8513.21, average training loss: 11093.30, base loss: 15806.03
[INFO 2017-06-29 12:27:54,052 main.py:57] epoch 375, training loss: 9091.32, average training loss: 11087.98, base loss: 15804.67
[INFO 2017-06-29 12:27:57,496 main.py:57] epoch 376, training loss: 11006.38, average training loss: 11087.76, base loss: 15812.99
[INFO 2017-06-29 12:28:00,903 main.py:57] epoch 377, training loss: 9702.75, average training loss: 11084.10, base loss: 15814.43
[INFO 2017-06-29 12:28:04,259 main.py:57] epoch 378, training loss: 10061.25, average training loss: 11081.40, base loss: 15817.48
[INFO 2017-06-29 12:28:07,742 main.py:57] epoch 379, training loss: 9943.32, average training loss: 11078.40, base loss: 15816.07
[INFO 2017-06-29 12:28:11,010 main.py:57] epoch 380, training loss: 10328.64, average training loss: 11076.44, base loss: 15819.57
[INFO 2017-06-29 12:28:14,275 main.py:57] epoch 381, training loss: 9545.23, average training loss: 11072.43, base loss: 15820.19
[INFO 2017-06-29 12:28:17,606 main.py:57] epoch 382, training loss: 9438.00, average training loss: 11068.16, base loss: 15821.34
[INFO 2017-06-29 12:28:20,949 main.py:57] epoch 383, training loss: 10571.34, average training loss: 11066.87, base loss: 15825.11
[INFO 2017-06-29 12:28:24,346 main.py:57] epoch 384, training loss: 10052.77, average training loss: 11064.23, base loss: 15830.47
[INFO 2017-06-29 12:28:27,680 main.py:57] epoch 385, training loss: 9120.60, average training loss: 11059.20, base loss: 15830.29
[INFO 2017-06-29 12:28:31,002 main.py:57] epoch 386, training loss: 10348.70, average training loss: 11057.36, base loss: 15833.11
[INFO 2017-06-29 12:28:34,193 main.py:57] epoch 387, training loss: 8630.17, average training loss: 11051.11, base loss: 15830.29
[INFO 2017-06-29 12:28:37,599 main.py:57] epoch 388, training loss: 9252.74, average training loss: 11046.48, base loss: 15828.67
[INFO 2017-06-29 12:28:40,863 main.py:57] epoch 389, training loss: 8317.47, average training loss: 11039.48, base loss: 15825.32
[INFO 2017-06-29 12:28:44,052 main.py:57] epoch 390, training loss: 9610.88, average training loss: 11035.83, base loss: 15827.35
[INFO 2017-06-29 12:28:47,425 main.py:57] epoch 391, training loss: 11127.30, average training loss: 11036.06, base loss: 15833.23
[INFO 2017-06-29 12:28:50,712 main.py:57] epoch 392, training loss: 10240.04, average training loss: 11034.04, base loss: 15838.96
[INFO 2017-06-29 12:28:53,938 main.py:57] epoch 393, training loss: 8939.45, average training loss: 11028.72, base loss: 15833.77
[INFO 2017-06-29 12:28:57,113 main.py:57] epoch 394, training loss: 10774.28, average training loss: 11028.08, base loss: 15838.45
[INFO 2017-06-29 12:29:00,484 main.py:57] epoch 395, training loss: 9353.60, average training loss: 11023.85, base loss: 15835.39
[INFO 2017-06-29 12:29:03,871 main.py:57] epoch 396, training loss: 10347.94, average training loss: 11022.15, base loss: 15839.41
[INFO 2017-06-29 12:29:07,086 main.py:57] epoch 397, training loss: 10342.82, average training loss: 11020.44, base loss: 15842.83
[INFO 2017-06-29 12:29:10,473 main.py:57] epoch 398, training loss: 10560.44, average training loss: 11019.29, base loss: 15848.16
[INFO 2017-06-29 12:29:13,713 main.py:57] epoch 399, training loss: 9678.43, average training loss: 11015.94, base loss: 15847.74
[INFO 2017-06-29 12:29:13,714 main.py:59] epoch 399, testing
[INFO 2017-06-29 12:29:27,828 main.py:104] average testing loss: 8780.92, base loss: 16412.63
[INFO 2017-06-29 12:29:27,828 main.py:105] improve_loss: 7631.70, improve_percent: 0.46
[INFO 2017-06-29 12:29:27,829 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 12:29:27,868 main.py:71] current best improved percent: 0.46
[INFO 2017-06-29 12:29:31,146 main.py:57] epoch 400, training loss: 9556.05, average training loss: 11012.30, base loss: 15849.36
[INFO 2017-06-29 12:29:34,411 main.py:57] epoch 401, training loss: 8952.30, average training loss: 11007.17, base loss: 15845.75
[INFO 2017-06-29 12:29:37,720 main.py:57] epoch 402, training loss: 8775.60, average training loss: 11001.63, base loss: 15842.53
[INFO 2017-06-29 12:29:41,066 main.py:57] epoch 403, training loss: 10371.76, average training loss: 11000.07, base loss: 15844.53
[INFO 2017-06-29 12:29:44,212 main.py:57] epoch 404, training loss: 8479.90, average training loss: 10993.85, base loss: 15839.69
[INFO 2017-06-29 12:29:47,588 main.py:57] epoch 405, training loss: 8887.04, average training loss: 10988.66, base loss: 15837.19
[INFO 2017-06-29 12:29:51,052 main.py:57] epoch 406, training loss: 10032.52, average training loss: 10986.31, base loss: 15840.31
[INFO 2017-06-29 12:29:54,418 main.py:57] epoch 407, training loss: 8726.58, average training loss: 10980.77, base loss: 15835.41
[INFO 2017-06-29 12:29:57,711 main.py:57] epoch 408, training loss: 9401.10, average training loss: 10976.91, base loss: 15835.09
[INFO 2017-06-29 12:30:00,935 main.py:57] epoch 409, training loss: 9833.47, average training loss: 10974.12, base loss: 15838.56
[INFO 2017-06-29 12:30:04,099 main.py:57] epoch 410, training loss: 9556.84, average training loss: 10970.68, base loss: 15839.91
[INFO 2017-06-29 12:30:07,334 main.py:57] epoch 411, training loss: 8785.53, average training loss: 10965.37, base loss: 15839.68
[INFO 2017-06-29 12:30:10,614 main.py:57] epoch 412, training loss: 9622.02, average training loss: 10962.12, base loss: 15838.69
[INFO 2017-06-29 12:30:13,708 main.py:57] epoch 413, training loss: 9977.00, average training loss: 10959.74, base loss: 15838.72
[INFO 2017-06-29 12:30:16,997 main.py:57] epoch 414, training loss: 10408.04, average training loss: 10958.41, base loss: 15843.36
[INFO 2017-06-29 12:30:20,124 main.py:57] epoch 415, training loss: 9266.18, average training loss: 10954.34, base loss: 15844.05
[INFO 2017-06-29 12:30:23,413 main.py:57] epoch 416, training loss: 9848.95, average training loss: 10951.69, base loss: 15846.92
[INFO 2017-06-29 12:30:26,709 main.py:57] epoch 417, training loss: 8313.00, average training loss: 10945.38, base loss: 15841.24
[INFO 2017-06-29 12:30:30,003 main.py:57] epoch 418, training loss: 8540.43, average training loss: 10939.64, base loss: 15836.69
[INFO 2017-06-29 12:30:33,291 main.py:57] epoch 419, training loss: 9851.04, average training loss: 10937.05, base loss: 15837.66
[INFO 2017-06-29 12:30:36,616 main.py:57] epoch 420, training loss: 9768.93, average training loss: 10934.27, base loss: 15841.23
[INFO 2017-06-29 12:30:40,027 main.py:57] epoch 421, training loss: 9952.39, average training loss: 10931.95, base loss: 15842.86
[INFO 2017-06-29 12:30:43,342 main.py:57] epoch 422, training loss: 9411.06, average training loss: 10928.35, base loss: 15844.98
[INFO 2017-06-29 12:30:46,627 main.py:57] epoch 423, training loss: 9925.18, average training loss: 10925.98, base loss: 15845.66
[INFO 2017-06-29 12:30:49,855 main.py:57] epoch 424, training loss: 10341.94, average training loss: 10924.61, base loss: 15849.97
[INFO 2017-06-29 12:30:53,156 main.py:57] epoch 425, training loss: 8737.95, average training loss: 10919.48, base loss: 15845.31
[INFO 2017-06-29 12:30:56,381 main.py:57] epoch 426, training loss: 10515.00, average training loss: 10918.53, base loss: 15846.61
[INFO 2017-06-29 12:30:59,565 main.py:57] epoch 427, training loss: 10867.40, average training loss: 10918.41, base loss: 15850.36
[INFO 2017-06-29 12:31:02,986 main.py:57] epoch 428, training loss: 8496.75, average training loss: 10912.77, base loss: 15844.31
[INFO 2017-06-29 12:31:06,200 main.py:57] epoch 429, training loss: 9203.77, average training loss: 10908.79, base loss: 15842.85
[INFO 2017-06-29 12:31:09,391 main.py:57] epoch 430, training loss: 9302.32, average training loss: 10905.06, base loss: 15841.44
[INFO 2017-06-29 12:31:12,563 main.py:57] epoch 431, training loss: 9443.92, average training loss: 10901.68, base loss: 15841.26
[INFO 2017-06-29 12:31:15,827 main.py:57] epoch 432, training loss: 9595.05, average training loss: 10898.66, base loss: 15842.38
[INFO 2017-06-29 12:31:19,238 main.py:57] epoch 433, training loss: 9775.12, average training loss: 10896.07, base loss: 15842.22
[INFO 2017-06-29 12:31:22,508 main.py:57] epoch 434, training loss: 9045.09, average training loss: 10891.82, base loss: 15839.02
[INFO 2017-06-29 12:31:25,827 main.py:57] epoch 435, training loss: 8510.66, average training loss: 10886.36, base loss: 15834.22
[INFO 2017-06-29 12:31:29,077 main.py:57] epoch 436, training loss: 8845.19, average training loss: 10881.69, base loss: 15832.26
[INFO 2017-06-29 12:31:32,275 main.py:57] epoch 437, training loss: 10895.36, average training loss: 10881.72, base loss: 15835.85
[INFO 2017-06-29 12:31:35,583 main.py:57] epoch 438, training loss: 8445.96, average training loss: 10876.17, base loss: 15833.17
[INFO 2017-06-29 12:31:38,813 main.py:57] epoch 439, training loss: 9537.23, average training loss: 10873.13, base loss: 15834.15
[INFO 2017-06-29 12:31:42,116 main.py:57] epoch 440, training loss: 8790.29, average training loss: 10868.40, base loss: 15832.68
[INFO 2017-06-29 12:31:45,423 main.py:57] epoch 441, training loss: 9394.20, average training loss: 10865.07, base loss: 15832.58
[INFO 2017-06-29 12:31:48,684 main.py:57] epoch 442, training loss: 9915.83, average training loss: 10862.93, base loss: 15833.17
[INFO 2017-06-29 12:31:51,945 main.py:57] epoch 443, training loss: 9091.90, average training loss: 10858.94, base loss: 15831.52
[INFO 2017-06-29 12:31:55,212 main.py:57] epoch 444, training loss: 9307.90, average training loss: 10855.45, base loss: 15832.09
[INFO 2017-06-29 12:31:58,510 main.py:57] epoch 445, training loss: 8451.69, average training loss: 10850.06, base loss: 15829.16
[INFO 2017-06-29 12:32:01,891 main.py:57] epoch 446, training loss: 8644.48, average training loss: 10845.13, base loss: 15826.73
[INFO 2017-06-29 12:32:05,276 main.py:57] epoch 447, training loss: 9088.00, average training loss: 10841.21, base loss: 15826.50
[INFO 2017-06-29 12:32:08,614 main.py:57] epoch 448, training loss: 9806.80, average training loss: 10838.90, base loss: 15827.70
[INFO 2017-06-29 12:32:11,939 main.py:57] epoch 449, training loss: 10023.12, average training loss: 10837.09, base loss: 15832.34
[INFO 2017-06-29 12:32:15,024 main.py:57] epoch 450, training loss: 8883.02, average training loss: 10832.76, base loss: 15829.43
[INFO 2017-06-29 12:32:18,365 main.py:57] epoch 451, training loss: 9263.83, average training loss: 10829.29, base loss: 15829.81
[INFO 2017-06-29 12:32:21,672 main.py:57] epoch 452, training loss: 8681.23, average training loss: 10824.54, base loss: 15827.61
[INFO 2017-06-29 12:32:24,989 main.py:57] epoch 453, training loss: 9799.53, average training loss: 10822.29, base loss: 15830.11
[INFO 2017-06-29 12:32:28,273 main.py:57] epoch 454, training loss: 9844.52, average training loss: 10820.14, base loss: 15831.78
[INFO 2017-06-29 12:32:31,395 main.py:57] epoch 455, training loss: 9190.81, average training loss: 10816.56, base loss: 15829.02
[INFO 2017-06-29 12:32:34,789 main.py:57] epoch 456, training loss: 9972.06, average training loss: 10814.72, base loss: 15832.34
[INFO 2017-06-29 12:32:38,048 main.py:57] epoch 457, training loss: 9330.46, average training loss: 10811.48, base loss: 15828.75
[INFO 2017-06-29 12:32:41,224 main.py:57] epoch 458, training loss: 9947.66, average training loss: 10809.59, base loss: 15828.89
[INFO 2017-06-29 12:32:44,522 main.py:57] epoch 459, training loss: 8196.56, average training loss: 10803.91, base loss: 15823.44
[INFO 2017-06-29 12:32:47,776 main.py:57] epoch 460, training loss: 9019.43, average training loss: 10800.04, base loss: 15821.20
[INFO 2017-06-29 12:32:51,126 main.py:57] epoch 461, training loss: 9250.33, average training loss: 10796.69, base loss: 15821.37
[INFO 2017-06-29 12:32:54,341 main.py:57] epoch 462, training loss: 8956.29, average training loss: 10792.71, base loss: 15821.40
[INFO 2017-06-29 12:32:57,722 main.py:57] epoch 463, training loss: 8370.68, average training loss: 10787.49, base loss: 15820.07
[INFO 2017-06-29 12:33:00,966 main.py:57] epoch 464, training loss: 8573.83, average training loss: 10782.73, base loss: 15819.17
[INFO 2017-06-29 12:33:04,191 main.py:57] epoch 465, training loss: 8968.69, average training loss: 10778.84, base loss: 15820.29
[INFO 2017-06-29 12:33:07,561 main.py:57] epoch 466, training loss: 10115.23, average training loss: 10777.42, base loss: 15821.67
[INFO 2017-06-29 12:33:10,776 main.py:57] epoch 467, training loss: 8673.82, average training loss: 10772.92, base loss: 15820.52
[INFO 2017-06-29 12:33:14,108 main.py:57] epoch 468, training loss: 10421.02, average training loss: 10772.17, base loss: 15822.26
[INFO 2017-06-29 12:33:17,461 main.py:57] epoch 469, training loss: 9955.66, average training loss: 10770.44, base loss: 15823.91
[INFO 2017-06-29 12:33:20,781 main.py:57] epoch 470, training loss: 9229.31, average training loss: 10767.16, base loss: 15824.72
[INFO 2017-06-29 12:33:24,134 main.py:57] epoch 471, training loss: 10199.89, average training loss: 10765.96, base loss: 15826.14
[INFO 2017-06-29 12:33:27,499 main.py:57] epoch 472, training loss: 9780.68, average training loss: 10763.88, base loss: 15823.83
[INFO 2017-06-29 12:33:30,881 main.py:57] epoch 473, training loss: 9378.91, average training loss: 10760.96, base loss: 15820.23
[INFO 2017-06-29 12:33:34,134 main.py:57] epoch 474, training loss: 9046.63, average training loss: 10757.35, base loss: 15817.26
[INFO 2017-06-29 12:33:37,402 main.py:57] epoch 475, training loss: 8952.42, average training loss: 10753.56, base loss: 15813.97
[INFO 2017-06-29 12:33:40,645 main.py:57] epoch 476, training loss: 8906.48, average training loss: 10749.68, base loss: 15812.61
[INFO 2017-06-29 12:33:43,953 main.py:57] epoch 477, training loss: 9753.91, average training loss: 10747.60, base loss: 15813.16
[INFO 2017-06-29 12:33:47,273 main.py:57] epoch 478, training loss: 8955.32, average training loss: 10743.86, base loss: 15812.78
[INFO 2017-06-29 12:33:50,660 main.py:57] epoch 479, training loss: 10764.71, average training loss: 10743.90, base loss: 15819.73
[INFO 2017-06-29 12:33:53,890 main.py:57] epoch 480, training loss: 9850.71, average training loss: 10742.05, base loss: 15818.16
[INFO 2017-06-29 12:33:57,225 main.py:57] epoch 481, training loss: 8549.14, average training loss: 10737.50, base loss: 15814.31
[INFO 2017-06-29 12:34:00,506 main.py:57] epoch 482, training loss: 9807.28, average training loss: 10735.57, base loss: 15817.04
[INFO 2017-06-29 12:34:04,080 main.py:57] epoch 483, training loss: 10407.55, average training loss: 10734.89, base loss: 15820.39
[INFO 2017-06-29 12:34:07,449 main.py:57] epoch 484, training loss: 8903.36, average training loss: 10731.12, base loss: 15818.69
[INFO 2017-06-29 12:34:10,917 main.py:57] epoch 485, training loss: 9793.31, average training loss: 10729.19, base loss: 15820.86
[INFO 2017-06-29 12:34:14,139 main.py:57] epoch 486, training loss: 9945.77, average training loss: 10727.58, base loss: 15825.34
[INFO 2017-06-29 12:34:17,330 main.py:57] epoch 487, training loss: 10081.74, average training loss: 10726.25, base loss: 15826.65
[INFO 2017-06-29 12:34:20,683 main.py:57] epoch 488, training loss: 9833.00, average training loss: 10724.43, base loss: 15828.88
[INFO 2017-06-29 12:34:23,952 main.py:57] epoch 489, training loss: 9390.73, average training loss: 10721.71, base loss: 15829.40
[INFO 2017-06-29 12:34:27,162 main.py:57] epoch 490, training loss: 8855.91, average training loss: 10717.91, base loss: 15829.16
[INFO 2017-06-29 12:34:30,569 main.py:57] epoch 491, training loss: 9341.44, average training loss: 10715.11, base loss: 15827.97
[INFO 2017-06-29 12:34:33,866 main.py:57] epoch 492, training loss: 8647.26, average training loss: 10710.91, base loss: 15825.44
[INFO 2017-06-29 12:34:37,151 main.py:57] epoch 493, training loss: 8834.33, average training loss: 10707.11, base loss: 15825.20
[INFO 2017-06-29 12:34:40,581 main.py:57] epoch 494, training loss: 9218.44, average training loss: 10704.11, base loss: 15824.98
[INFO 2017-06-29 12:34:43,854 main.py:57] epoch 495, training loss: 8795.26, average training loss: 10700.26, base loss: 15823.47
[INFO 2017-06-29 12:34:47,160 main.py:57] epoch 496, training loss: 9604.45, average training loss: 10698.05, base loss: 15824.76
[INFO 2017-06-29 12:34:50,712 main.py:57] epoch 497, training loss: 9706.08, average training loss: 10696.06, base loss: 15827.36
[INFO 2017-06-29 12:34:54,084 main.py:57] epoch 498, training loss: 10295.11, average training loss: 10695.26, base loss: 15830.45
[INFO 2017-06-29 12:34:57,364 main.py:57] epoch 499, training loss: 9500.33, average training loss: 10692.87, base loss: 15831.83
[INFO 2017-06-29 12:34:57,365 main.py:59] epoch 499, testing
[INFO 2017-06-29 12:35:11,287 main.py:104] average testing loss: 8464.00, base loss: 16028.26
[INFO 2017-06-29 12:35:11,287 main.py:105] improve_loss: 7564.26, improve_percent: 0.47
[INFO 2017-06-29 12:35:11,288 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 12:35:11,327 main.py:71] current best improved percent: 0.47
[INFO 2017-06-29 12:35:14,558 main.py:57] epoch 500, training loss: 9776.97, average training loss: 10691.04, base loss: 15834.85
[INFO 2017-06-29 12:35:17,818 main.py:57] epoch 501, training loss: 8689.02, average training loss: 10687.05, base loss: 15833.09
[INFO 2017-06-29 12:35:21,188 main.py:57] epoch 502, training loss: 9408.81, average training loss: 10684.51, base loss: 15830.52
[INFO 2017-06-29 12:35:24,426 main.py:57] epoch 503, training loss: 9256.38, average training loss: 10681.68, base loss: 15830.26
[INFO 2017-06-29 12:35:27,854 main.py:57] epoch 504, training loss: 8670.81, average training loss: 10677.70, base loss: 15827.86
[INFO 2017-06-29 12:35:31,105 main.py:57] epoch 505, training loss: 10027.03, average training loss: 10676.41, base loss: 15831.02
[INFO 2017-06-29 12:35:34,375 main.py:57] epoch 506, training loss: 9766.08, average training loss: 10674.61, base loss: 15835.64
[INFO 2017-06-29 12:35:37,573 main.py:57] epoch 507, training loss: 8970.54, average training loss: 10671.26, base loss: 15835.73
[INFO 2017-06-29 12:35:40,969 main.py:57] epoch 508, training loss: 10553.02, average training loss: 10671.03, base loss: 15841.46
[INFO 2017-06-29 12:35:44,335 main.py:57] epoch 509, training loss: 9389.48, average training loss: 10668.51, base loss: 15841.76
[INFO 2017-06-29 12:35:47,483 main.py:57] epoch 510, training loss: 9590.02, average training loss: 10666.40, base loss: 15843.19
[INFO 2017-06-29 12:35:50,628 main.py:57] epoch 511, training loss: 10655.61, average training loss: 10666.38, base loss: 15848.72
[INFO 2017-06-29 12:35:54,006 main.py:57] epoch 512, training loss: 9267.92, average training loss: 10663.66, base loss: 15847.67
[INFO 2017-06-29 12:35:57,182 main.py:57] epoch 513, training loss: 9634.92, average training loss: 10661.66, base loss: 15846.25
[INFO 2017-06-29 12:36:00,462 main.py:57] epoch 514, training loss: 9403.26, average training loss: 10659.21, base loss: 15845.47
[INFO 2017-06-29 12:36:03,744 main.py:57] epoch 515, training loss: 9110.76, average training loss: 10656.21, base loss: 15843.31
[INFO 2017-06-29 12:36:07,010 main.py:57] epoch 516, training loss: 9239.98, average training loss: 10653.47, base loss: 15844.26
[INFO 2017-06-29 12:36:10,257 main.py:57] epoch 517, training loss: 9129.09, average training loss: 10650.53, base loss: 15841.21
[INFO 2017-06-29 12:36:13,560 main.py:57] epoch 518, training loss: 9797.76, average training loss: 10648.89, base loss: 15844.87
[INFO 2017-06-29 12:36:16,768 main.py:57] epoch 519, training loss: 10769.47, average training loss: 10649.12, base loss: 15851.30
[INFO 2017-06-29 12:36:20,095 main.py:57] epoch 520, training loss: 8510.39, average training loss: 10645.01, base loss: 15849.96
[INFO 2017-06-29 12:36:23,301 main.py:57] epoch 521, training loss: 9112.22, average training loss: 10642.08, base loss: 15852.03
[INFO 2017-06-29 12:36:26,651 main.py:57] epoch 522, training loss: 8524.25, average training loss: 10638.03, base loss: 15851.18
[INFO 2017-06-29 12:36:30,010 main.py:57] epoch 523, training loss: 8715.69, average training loss: 10634.36, base loss: 15847.62
[INFO 2017-06-29 12:36:33,457 main.py:57] epoch 524, training loss: 8448.65, average training loss: 10630.20, base loss: 15844.64
[INFO 2017-06-29 12:36:36,716 main.py:57] epoch 525, training loss: 8823.81, average training loss: 10626.76, base loss: 15841.18
[INFO 2017-06-29 12:36:39,811 main.py:57] epoch 526, training loss: 9502.50, average training loss: 10624.63, base loss: 15842.15
[INFO 2017-06-29 12:36:43,145 main.py:57] epoch 527, training loss: 8572.99, average training loss: 10620.74, base loss: 15840.69
[INFO 2017-06-29 12:36:46,300 main.py:57] epoch 528, training loss: 9212.08, average training loss: 10618.08, base loss: 15840.22
[INFO 2017-06-29 12:36:49,636 main.py:57] epoch 529, training loss: 9230.90, average training loss: 10615.46, base loss: 15841.30
[INFO 2017-06-29 12:36:53,053 main.py:57] epoch 530, training loss: 9451.44, average training loss: 10613.27, base loss: 15841.88
[INFO 2017-06-29 12:36:56,340 main.py:57] epoch 531, training loss: 9127.79, average training loss: 10610.48, base loss: 15841.82
[INFO 2017-06-29 12:36:59,678 main.py:57] epoch 532, training loss: 9866.38, average training loss: 10609.08, base loss: 15843.27
[INFO 2017-06-29 12:37:02,832 main.py:57] epoch 533, training loss: 9342.58, average training loss: 10606.71, base loss: 15846.58
[INFO 2017-06-29 12:37:06,120 main.py:57] epoch 534, training loss: 9147.75, average training loss: 10603.98, base loss: 15847.16
[INFO 2017-06-29 12:37:09,435 main.py:57] epoch 535, training loss: 10328.08, average training loss: 10603.47, base loss: 15849.00
[INFO 2017-06-29 12:37:12,756 main.py:57] epoch 536, training loss: 8779.13, average training loss: 10600.07, base loss: 15848.68
[INFO 2017-06-29 12:37:16,093 main.py:57] epoch 537, training loss: 11107.87, average training loss: 10601.01, base loss: 15854.12
[INFO 2017-06-29 12:37:19,479 main.py:57] epoch 538, training loss: 9837.83, average training loss: 10599.60, base loss: 15858.16
[INFO 2017-06-29 12:37:22,778 main.py:57] epoch 539, training loss: 9925.38, average training loss: 10598.35, base loss: 15862.98
[INFO 2017-06-29 12:37:25,965 main.py:57] epoch 540, training loss: 8491.38, average training loss: 10594.46, base loss: 15860.51
[INFO 2017-06-29 12:37:29,262 main.py:57] epoch 541, training loss: 9528.00, average training loss: 10592.49, base loss: 15861.71
[INFO 2017-06-29 12:37:32,670 main.py:57] epoch 542, training loss: 9446.59, average training loss: 10590.38, base loss: 15864.57
[INFO 2017-06-29 12:37:35,897 main.py:57] epoch 543, training loss: 8866.31, average training loss: 10587.21, base loss: 15863.42
[INFO 2017-06-29 12:37:39,296 main.py:57] epoch 544, training loss: 9679.33, average training loss: 10585.54, base loss: 15863.47
[INFO 2017-06-29 12:37:42,541 main.py:57] epoch 545, training loss: 8604.97, average training loss: 10581.91, base loss: 15862.60
[INFO 2017-06-29 12:37:45,880 main.py:57] epoch 546, training loss: 8464.05, average training loss: 10578.04, base loss: 15860.92
[INFO 2017-06-29 12:37:49,197 main.py:57] epoch 547, training loss: 9810.83, average training loss: 10576.64, base loss: 15860.40
[INFO 2017-06-29 12:37:52,504 main.py:57] epoch 548, training loss: 8683.97, average training loss: 10573.20, base loss: 15858.25
[INFO 2017-06-29 12:37:55,775 main.py:57] epoch 549, training loss: 9058.13, average training loss: 10570.44, base loss: 15858.67
[INFO 2017-06-29 12:37:58,974 main.py:57] epoch 550, training loss: 8548.93, average training loss: 10566.77, base loss: 15857.44
[INFO 2017-06-29 12:38:02,249 main.py:57] epoch 551, training loss: 8716.69, average training loss: 10563.42, base loss: 15857.37
[INFO 2017-06-29 12:38:05,465 main.py:57] epoch 552, training loss: 9013.76, average training loss: 10560.62, base loss: 15858.51
[INFO 2017-06-29 12:38:08,752 main.py:57] epoch 553, training loss: 8758.72, average training loss: 10557.37, base loss: 15858.73
[INFO 2017-06-29 12:38:12,078 main.py:57] epoch 554, training loss: 9037.58, average training loss: 10554.63, base loss: 15856.62
[INFO 2017-06-29 12:38:15,463 main.py:57] epoch 555, training loss: 9198.61, average training loss: 10552.19, base loss: 15852.68
[INFO 2017-06-29 12:38:18,745 main.py:57] epoch 556, training loss: 9322.17, average training loss: 10549.98, base loss: 15854.31
[INFO 2017-06-29 12:38:22,015 main.py:57] epoch 557, training loss: 8053.47, average training loss: 10545.51, base loss: 15852.12
[INFO 2017-06-29 12:38:25,282 main.py:57] epoch 558, training loss: 8498.30, average training loss: 10541.84, base loss: 15849.57
[INFO 2017-06-29 12:38:28,458 main.py:57] epoch 559, training loss: 10649.09, average training loss: 10542.04, base loss: 15853.67
[INFO 2017-06-29 12:38:31,818 main.py:57] epoch 560, training loss: 9184.20, average training loss: 10539.61, base loss: 15855.61
[INFO 2017-06-29 12:38:34,984 main.py:57] epoch 561, training loss: 9979.26, average training loss: 10538.62, base loss: 15855.10
[INFO 2017-06-29 12:38:38,347 main.py:57] epoch 562, training loss: 9091.28, average training loss: 10536.05, base loss: 15852.27
[INFO 2017-06-29 12:38:41,553 main.py:57] epoch 563, training loss: 9397.90, average training loss: 10534.03, base loss: 15852.95
[INFO 2017-06-29 12:38:44,815 main.py:57] epoch 564, training loss: 9791.63, average training loss: 10532.72, base loss: 15851.84
[INFO 2017-06-29 12:38:48,169 main.py:57] epoch 565, training loss: 10180.22, average training loss: 10532.09, base loss: 15851.83
[INFO 2017-06-29 12:38:51,486 main.py:57] epoch 566, training loss: 9171.19, average training loss: 10529.69, base loss: 15848.30
[INFO 2017-06-29 12:38:54,802 main.py:57] epoch 567, training loss: 10264.23, average training loss: 10529.22, base loss: 15851.06
[INFO 2017-06-29 12:38:58,274 main.py:57] epoch 568, training loss: 8286.49, average training loss: 10525.28, base loss: 15845.77
[INFO 2017-06-29 12:39:01,610 main.py:57] epoch 569, training loss: 9289.54, average training loss: 10523.12, base loss: 15840.45
[INFO 2017-06-29 12:39:04,991 main.py:57] epoch 570, training loss: 8346.83, average training loss: 10519.30, base loss: 15836.15
[INFO 2017-06-29 12:39:08,170 main.py:57] epoch 571, training loss: 9687.42, average training loss: 10517.85, base loss: 15839.19
[INFO 2017-06-29 12:39:11,384 main.py:57] epoch 572, training loss: 9903.51, average training loss: 10516.78, base loss: 15840.75
[INFO 2017-06-29 12:39:14,700 main.py:57] epoch 573, training loss: 8641.55, average training loss: 10513.51, base loss: 15837.62
[INFO 2017-06-29 12:39:17,977 main.py:57] epoch 574, training loss: 10016.90, average training loss: 10512.65, base loss: 15839.17
[INFO 2017-06-29 12:39:21,238 main.py:57] epoch 575, training loss: 9448.81, average training loss: 10510.80, base loss: 15837.64
[INFO 2017-06-29 12:39:24,579 main.py:57] epoch 576, training loss: 10147.22, average training loss: 10510.17, base loss: 15842.29
[INFO 2017-06-29 12:39:27,799 main.py:57] epoch 577, training loss: 9526.38, average training loss: 10508.47, base loss: 15842.59
[INFO 2017-06-29 12:39:31,054 main.py:57] epoch 578, training loss: 8267.35, average training loss: 10504.60, base loss: 15841.59
[INFO 2017-06-29 12:39:34,390 main.py:57] epoch 579, training loss: 9163.00, average training loss: 10502.28, base loss: 15843.15
[INFO 2017-06-29 12:39:37,793 main.py:57] epoch 580, training loss: 10005.79, average training loss: 10501.43, base loss: 15842.90
[INFO 2017-06-29 12:39:41,061 main.py:57] epoch 581, training loss: 8532.93, average training loss: 10498.05, base loss: 15839.94
[INFO 2017-06-29 12:39:44,215 main.py:57] epoch 582, training loss: 8447.71, average training loss: 10494.53, base loss: 15835.45
[INFO 2017-06-29 12:39:47,541 main.py:57] epoch 583, training loss: 8845.14, average training loss: 10491.71, base loss: 15833.56
[INFO 2017-06-29 12:39:50,881 main.py:57] epoch 584, training loss: 8846.70, average training loss: 10488.89, base loss: 15833.02
[INFO 2017-06-29 12:39:54,025 main.py:57] epoch 585, training loss: 9462.03, average training loss: 10487.14, base loss: 15834.71
[INFO 2017-06-29 12:39:57,259 main.py:57] epoch 586, training loss: 8811.81, average training loss: 10484.29, base loss: 15833.03
[INFO 2017-06-29 12:40:00,611 main.py:57] epoch 587, training loss: 9741.48, average training loss: 10483.02, base loss: 15832.59
[INFO 2017-06-29 12:40:04,023 main.py:57] epoch 588, training loss: 8827.94, average training loss: 10480.21, base loss: 15833.63
[INFO 2017-06-29 12:40:07,226 main.py:57] epoch 589, training loss: 8117.10, average training loss: 10476.21, base loss: 15831.78
[INFO 2017-06-29 12:40:10,515 main.py:57] epoch 590, training loss: 9153.39, average training loss: 10473.97, base loss: 15833.53
[INFO 2017-06-29 12:40:13,950 main.py:57] epoch 591, training loss: 8452.35, average training loss: 10470.56, base loss: 15831.74
[INFO 2017-06-29 12:40:17,387 main.py:57] epoch 592, training loss: 10077.39, average training loss: 10469.89, base loss: 15835.60
[INFO 2017-06-29 12:40:20,711 main.py:57] epoch 593, training loss: 9612.58, average training loss: 10468.45, base loss: 15836.40
[INFO 2017-06-29 12:40:23,987 main.py:57] epoch 594, training loss: 9337.84, average training loss: 10466.55, base loss: 15833.97
[INFO 2017-06-29 12:40:27,338 main.py:57] epoch 595, training loss: 9717.41, average training loss: 10465.29, base loss: 15833.52
[INFO 2017-06-29 12:40:30,733 main.py:57] epoch 596, training loss: 9670.16, average training loss: 10463.96, base loss: 15836.30
[INFO 2017-06-29 12:40:33,935 main.py:57] epoch 597, training loss: 8801.13, average training loss: 10461.18, base loss: 15836.23
[INFO 2017-06-29 12:40:37,186 main.py:57] epoch 598, training loss: 9375.81, average training loss: 10459.37, base loss: 15836.87
[INFO 2017-06-29 12:40:40,460 main.py:57] epoch 599, training loss: 9623.83, average training loss: 10457.98, base loss: 15836.73
[INFO 2017-06-29 12:40:40,460 main.py:59] epoch 599, testing
[INFO 2017-06-29 12:40:54,435 main.py:104] average testing loss: 8374.36, base loss: 16390.80
[INFO 2017-06-29 12:40:54,435 main.py:105] improve_loss: 8016.43, improve_percent: 0.49
[INFO 2017-06-29 12:40:54,438 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 12:40:54,477 main.py:71] current best improved percent: 0.49
[INFO 2017-06-29 12:40:57,914 main.py:57] epoch 600, training loss: 7939.46, average training loss: 10453.78, base loss: 15832.53
[INFO 2017-06-29 12:41:01,112 main.py:57] epoch 601, training loss: 8695.67, average training loss: 10450.86, base loss: 15830.88
[INFO 2017-06-29 12:41:04,365 main.py:57] epoch 602, training loss: 10006.42, average training loss: 10450.13, base loss: 15831.81
[INFO 2017-06-29 12:41:07,555 main.py:57] epoch 603, training loss: 8841.62, average training loss: 10447.46, base loss: 15827.90
[INFO 2017-06-29 12:41:10,789 main.py:57] epoch 604, training loss: 9745.06, average training loss: 10446.30, base loss: 15829.70
[INFO 2017-06-29 12:41:14,148 main.py:57] epoch 605, training loss: 8715.31, average training loss: 10443.45, base loss: 15829.95
[INFO 2017-06-29 12:41:17,449 main.py:57] epoch 606, training loss: 9407.09, average training loss: 10441.74, base loss: 15834.17
[INFO 2017-06-29 12:41:20,719 main.py:57] epoch 607, training loss: 8777.60, average training loss: 10439.00, base loss: 15835.35
[INFO 2017-06-29 12:41:23,996 main.py:57] epoch 608, training loss: 9709.01, average training loss: 10437.80, base loss: 15835.30
[INFO 2017-06-29 12:41:27,222 main.py:57] epoch 609, training loss: 10474.93, average training loss: 10437.86, base loss: 15840.66
[INFO 2017-06-29 12:41:30,728 main.py:57] epoch 610, training loss: 8309.47, average training loss: 10434.38, base loss: 15838.44
[INFO 2017-06-29 12:41:34,089 main.py:57] epoch 611, training loss: 9407.77, average training loss: 10432.70, base loss: 15837.81
[INFO 2017-06-29 12:41:37,358 main.py:57] epoch 612, training loss: 9034.70, average training loss: 10430.42, base loss: 15836.95
[INFO 2017-06-29 12:41:40,541 main.py:57] epoch 613, training loss: 9463.52, average training loss: 10428.85, base loss: 15838.62
[INFO 2017-06-29 12:41:43,866 main.py:57] epoch 614, training loss: 9793.97, average training loss: 10427.82, base loss: 15839.90
[INFO 2017-06-29 12:41:47,127 main.py:57] epoch 615, training loss: 8516.49, average training loss: 10424.71, base loss: 15836.87
[INFO 2017-06-29 12:41:50,565 main.py:57] epoch 616, training loss: 9238.00, average training loss: 10422.79, base loss: 15836.40
[INFO 2017-06-29 12:41:53,887 main.py:57] epoch 617, training loss: 9862.08, average training loss: 10421.88, base loss: 15836.80
[INFO 2017-06-29 12:41:57,248 main.py:57] epoch 618, training loss: 9287.61, average training loss: 10420.05, base loss: 15838.68
[INFO 2017-06-29 12:42:00,544 main.py:57] epoch 619, training loss: 7983.34, average training loss: 10416.12, base loss: 15836.08
[INFO 2017-06-29 12:42:03,759 main.py:57] epoch 620, training loss: 9735.76, average training loss: 10415.02, base loss: 15835.91
[INFO 2017-06-29 12:42:07,026 main.py:57] epoch 621, training loss: 9782.56, average training loss: 10414.01, base loss: 15837.97
[INFO 2017-06-29 12:42:10,374 main.py:57] epoch 622, training loss: 10075.98, average training loss: 10413.46, base loss: 15841.66
[INFO 2017-06-29 12:42:13,698 main.py:57] epoch 623, training loss: 8108.54, average training loss: 10409.77, base loss: 15837.74
[INFO 2017-06-29 12:42:16,958 main.py:57] epoch 624, training loss: 8838.57, average training loss: 10407.26, base loss: 15836.66
[INFO 2017-06-29 12:42:20,402 main.py:57] epoch 625, training loss: 8304.70, average training loss: 10403.90, base loss: 15834.39
[INFO 2017-06-29 12:42:23,614 main.py:57] epoch 626, training loss: 8393.79, average training loss: 10400.69, base loss: 15831.90
[INFO 2017-06-29 12:42:26,966 main.py:57] epoch 627, training loss: 8885.94, average training loss: 10398.28, base loss: 15830.96
[INFO 2017-06-29 12:42:30,211 main.py:57] epoch 628, training loss: 10024.18, average training loss: 10397.69, base loss: 15833.80
[INFO 2017-06-29 12:42:33,507 main.py:57] epoch 629, training loss: 10527.47, average training loss: 10397.89, base loss: 15837.33
[INFO 2017-06-29 12:42:36,743 main.py:57] epoch 630, training loss: 8892.42, average training loss: 10395.51, base loss: 15835.37
[INFO 2017-06-29 12:42:39,928 main.py:57] epoch 631, training loss: 9179.80, average training loss: 10393.58, base loss: 15835.74
[INFO 2017-06-29 12:42:43,161 main.py:57] epoch 632, training loss: 8608.96, average training loss: 10390.76, base loss: 15830.04
[INFO 2017-06-29 12:42:46,412 main.py:57] epoch 633, training loss: 10264.63, average training loss: 10390.56, base loss: 15832.83
[INFO 2017-06-29 12:42:49,835 main.py:57] epoch 634, training loss: 8495.40, average training loss: 10387.58, base loss: 15831.85
[INFO 2017-06-29 12:42:53,250 main.py:57] epoch 635, training loss: 8893.50, average training loss: 10385.23, base loss: 15832.81
[INFO 2017-06-29 12:42:56,542 main.py:57] epoch 636, training loss: 8849.60, average training loss: 10382.82, base loss: 15831.55
[INFO 2017-06-29 12:43:00,054 main.py:57] epoch 637, training loss: 9481.92, average training loss: 10381.41, base loss: 15832.20
[INFO 2017-06-29 12:43:03,454 main.py:57] epoch 638, training loss: 8877.59, average training loss: 10379.05, base loss: 15830.77
[INFO 2017-06-29 12:43:06,853 main.py:57] epoch 639, training loss: 9225.44, average training loss: 10377.25, base loss: 15829.98
[INFO 2017-06-29 12:43:10,159 main.py:57] epoch 640, training loss: 10068.49, average training loss: 10376.77, base loss: 15834.47
[INFO 2017-06-29 12:43:13,640 main.py:57] epoch 641, training loss: 8785.05, average training loss: 10374.29, base loss: 15836.02
[INFO 2017-06-29 12:43:16,881 main.py:57] epoch 642, training loss: 10093.70, average training loss: 10373.85, base loss: 15838.93
[INFO 2017-06-29 12:43:20,154 main.py:57] epoch 643, training loss: 8537.19, average training loss: 10371.00, base loss: 15838.99
[INFO 2017-06-29 12:43:23,370 main.py:57] epoch 644, training loss: 9471.80, average training loss: 10369.61, base loss: 15836.41
[INFO 2017-06-29 12:43:26,516 main.py:57] epoch 645, training loss: 9116.47, average training loss: 10367.67, base loss: 15834.71
[INFO 2017-06-29 12:43:29,732 main.py:57] epoch 646, training loss: 8931.48, average training loss: 10365.45, base loss: 15833.71
[INFO 2017-06-29 12:43:33,063 main.py:57] epoch 647, training loss: 9132.18, average training loss: 10363.55, base loss: 15833.23
[INFO 2017-06-29 12:43:36,474 main.py:57] epoch 648, training loss: 9188.78, average training loss: 10361.74, base loss: 15834.12
[INFO 2017-06-29 12:43:39,787 main.py:57] epoch 649, training loss: 9408.44, average training loss: 10360.27, base loss: 15834.44
[INFO 2017-06-29 12:43:43,203 main.py:57] epoch 650, training loss: 9854.54, average training loss: 10359.49, base loss: 15836.95
[INFO 2017-06-29 12:43:46,550 main.py:57] epoch 651, training loss: 9285.91, average training loss: 10357.85, base loss: 15836.90
[INFO 2017-06-29 12:43:49,901 main.py:57] epoch 652, training loss: 8463.19, average training loss: 10354.94, base loss: 15833.16
[INFO 2017-06-29 12:43:53,099 main.py:57] epoch 653, training loss: 8667.36, average training loss: 10352.36, base loss: 15829.11
[INFO 2017-06-29 12:43:56,432 main.py:57] epoch 654, training loss: 9200.44, average training loss: 10350.60, base loss: 15829.52
[INFO 2017-06-29 12:43:59,787 main.py:57] epoch 655, training loss: 8130.74, average training loss: 10347.22, base loss: 15827.73
[INFO 2017-06-29 12:44:03,038 main.py:57] epoch 656, training loss: 8444.38, average training loss: 10344.32, base loss: 15824.08
[INFO 2017-06-29 12:44:06,369 main.py:57] epoch 657, training loss: 9723.08, average training loss: 10343.38, base loss: 15821.77
[INFO 2017-06-29 12:44:09,696 main.py:57] epoch 658, training loss: 8828.82, average training loss: 10341.08, base loss: 15821.13
[INFO 2017-06-29 12:44:13,157 main.py:57] epoch 659, training loss: 9885.30, average training loss: 10340.39, base loss: 15822.94
[INFO 2017-06-29 12:44:16,408 main.py:57] epoch 660, training loss: 9011.89, average training loss: 10338.38, base loss: 15821.17
[INFO 2017-06-29 12:44:19,595 main.py:57] epoch 661, training loss: 8747.10, average training loss: 10335.98, base loss: 15820.73
[INFO 2017-06-29 12:44:22,856 main.py:57] epoch 662, training loss: 8602.93, average training loss: 10333.36, base loss: 15819.84
[INFO 2017-06-29 12:44:26,068 main.py:57] epoch 663, training loss: 8962.89, average training loss: 10331.30, base loss: 15819.22
[INFO 2017-06-29 12:44:29,396 main.py:57] epoch 664, training loss: 8676.11, average training loss: 10328.81, base loss: 15814.63
[INFO 2017-06-29 12:44:32,636 main.py:57] epoch 665, training loss: 9582.81, average training loss: 10327.69, base loss: 15814.99
[INFO 2017-06-29 12:44:36,022 main.py:57] epoch 666, training loss: 9518.27, average training loss: 10326.48, base loss: 15817.13
[INFO 2017-06-29 12:44:39,290 main.py:57] epoch 667, training loss: 8896.83, average training loss: 10324.34, base loss: 15818.65
[INFO 2017-06-29 12:44:42,547 main.py:57] epoch 668, training loss: 8790.16, average training loss: 10322.04, base loss: 15819.21
[INFO 2017-06-29 12:44:45,894 main.py:57] epoch 669, training loss: 8015.76, average training loss: 10318.60, base loss: 15817.36
[INFO 2017-06-29 12:44:49,070 main.py:57] epoch 670, training loss: 8190.03, average training loss: 10315.43, base loss: 15817.23
[INFO 2017-06-29 12:44:52,330 main.py:57] epoch 671, training loss: 9552.67, average training loss: 10314.29, base loss: 15818.87
[INFO 2017-06-29 12:44:55,509 main.py:57] epoch 672, training loss: 9575.85, average training loss: 10313.20, base loss: 15820.54
[INFO 2017-06-29 12:44:58,793 main.py:57] epoch 673, training loss: 8599.93, average training loss: 10310.66, base loss: 15818.10
[INFO 2017-06-29 12:45:02,052 main.py:57] epoch 674, training loss: 8566.97, average training loss: 10308.07, base loss: 15817.92
[INFO 2017-06-29 12:45:05,308 main.py:57] epoch 675, training loss: 8480.19, average training loss: 10305.37, base loss: 15815.29
[INFO 2017-06-29 12:45:08,696 main.py:57] epoch 676, training loss: 10679.76, average training loss: 10305.92, base loss: 15818.68
[INFO 2017-06-29 12:45:11,945 main.py:57] epoch 677, training loss: 8927.45, average training loss: 10303.89, base loss: 15817.50
[INFO 2017-06-29 12:45:15,228 main.py:57] epoch 678, training loss: 9530.03, average training loss: 10302.75, base loss: 15821.92
[INFO 2017-06-29 12:45:18,446 main.py:57] epoch 679, training loss: 9367.62, average training loss: 10301.37, base loss: 15820.59
[INFO 2017-06-29 12:45:21,720 main.py:57] epoch 680, training loss: 8078.28, average training loss: 10298.11, base loss: 15815.83
[INFO 2017-06-29 12:45:24,916 main.py:57] epoch 681, training loss: 8262.11, average training loss: 10295.12, base loss: 15811.85
[INFO 2017-06-29 12:45:28,219 main.py:57] epoch 682, training loss: 9154.98, average training loss: 10293.45, base loss: 15811.06
[INFO 2017-06-29 12:45:31,594 main.py:57] epoch 683, training loss: 9259.73, average training loss: 10291.94, base loss: 15810.63
[INFO 2017-06-29 12:45:34,922 main.py:57] epoch 684, training loss: 9307.45, average training loss: 10290.51, base loss: 15808.70
[INFO 2017-06-29 12:45:38,260 main.py:57] epoch 685, training loss: 9378.68, average training loss: 10289.18, base loss: 15808.37
[INFO 2017-06-29 12:45:41,646 main.py:57] epoch 686, training loss: 7889.05, average training loss: 10285.68, base loss: 15803.82
[INFO 2017-06-29 12:45:44,925 main.py:57] epoch 687, training loss: 9446.73, average training loss: 10284.46, base loss: 15804.55
[INFO 2017-06-29 12:45:48,255 main.py:57] epoch 688, training loss: 9365.89, average training loss: 10283.13, base loss: 15806.32
[INFO 2017-06-29 12:45:51,469 main.py:57] epoch 689, training loss: 9028.59, average training loss: 10281.31, base loss: 15806.62
[INFO 2017-06-29 12:45:54,781 main.py:57] epoch 690, training loss: 9814.39, average training loss: 10280.64, base loss: 15811.59
[INFO 2017-06-29 12:45:58,071 main.py:57] epoch 691, training loss: 10065.32, average training loss: 10280.33, base loss: 15816.20
[INFO 2017-06-29 12:46:01,358 main.py:57] epoch 692, training loss: 9149.42, average training loss: 10278.69, base loss: 15819.57
[INFO 2017-06-29 12:46:04,494 main.py:57] epoch 693, training loss: 10218.64, average training loss: 10278.61, base loss: 15823.31
[INFO 2017-06-29 12:46:07,971 main.py:57] epoch 694, training loss: 8551.68, average training loss: 10276.12, base loss: 15819.60
[INFO 2017-06-29 12:46:11,183 main.py:57] epoch 695, training loss: 9677.41, average training loss: 10275.26, base loss: 15820.24
[INFO 2017-06-29 12:46:14,394 main.py:57] epoch 696, training loss: 9134.03, average training loss: 10273.62, base loss: 15818.59
[INFO 2017-06-29 12:46:17,542 main.py:57] epoch 697, training loss: 9486.66, average training loss: 10272.50, base loss: 15819.30
[INFO 2017-06-29 12:46:20,787 main.py:57] epoch 698, training loss: 9345.18, average training loss: 10271.17, base loss: 15821.15
[INFO 2017-06-29 12:46:24,151 main.py:57] epoch 699, training loss: 10023.92, average training loss: 10270.82, base loss: 15823.49
[INFO 2017-06-29 12:46:24,151 main.py:59] epoch 699, testing
[INFO 2017-06-29 12:46:37,975 main.py:104] average testing loss: 8133.47, base loss: 15883.86
[INFO 2017-06-29 12:46:37,975 main.py:105] improve_loss: 7750.38, improve_percent: 0.49
[INFO 2017-06-29 12:46:37,977 main.py:71] current best improved percent: 0.49
[INFO 2017-06-29 12:46:41,188 main.py:57] epoch 700, training loss: 9292.09, average training loss: 10269.42, base loss: 15824.58
[INFO 2017-06-29 12:46:44,596 main.py:57] epoch 701, training loss: 8512.77, average training loss: 10266.92, base loss: 15823.58
[INFO 2017-06-29 12:46:48,094 main.py:57] epoch 702, training loss: 8983.19, average training loss: 10265.09, base loss: 15821.65
[INFO 2017-06-29 12:46:51,641 main.py:57] epoch 703, training loss: 9760.51, average training loss: 10264.38, base loss: 15823.57
[INFO 2017-06-29 12:46:54,934 main.py:57] epoch 704, training loss: 7976.37, average training loss: 10261.13, base loss: 15818.06
[INFO 2017-06-29 12:46:58,313 main.py:57] epoch 705, training loss: 9384.04, average training loss: 10259.89, base loss: 15817.33
[INFO 2017-06-29 12:47:01,779 main.py:57] epoch 706, training loss: 9013.14, average training loss: 10258.12, base loss: 15815.71
[INFO 2017-06-29 12:47:05,050 main.py:57] epoch 707, training loss: 8345.24, average training loss: 10255.42, base loss: 15812.83
[INFO 2017-06-29 12:47:08,245 main.py:57] epoch 708, training loss: 8101.29, average training loss: 10252.38, base loss: 15808.95
[INFO 2017-06-29 12:47:11,637 main.py:57] epoch 709, training loss: 9245.46, average training loss: 10250.97, base loss: 15806.58
[INFO 2017-06-29 12:47:14,874 main.py:57] epoch 710, training loss: 8948.97, average training loss: 10249.13, base loss: 15806.20
[INFO 2017-06-29 12:47:18,209 main.py:57] epoch 711, training loss: 9613.21, average training loss: 10248.24, base loss: 15808.05
[INFO 2017-06-29 12:47:21,455 main.py:57] epoch 712, training loss: 8014.44, average training loss: 10245.11, base loss: 15803.51
[INFO 2017-06-29 12:47:24,728 main.py:57] epoch 713, training loss: 8944.41, average training loss: 10243.29, base loss: 15801.50
[INFO 2017-06-29 12:47:27,918 main.py:57] epoch 714, training loss: 9048.03, average training loss: 10241.62, base loss: 15801.06
[INFO 2017-06-29 12:47:31,323 main.py:57] epoch 715, training loss: 8526.32, average training loss: 10239.22, base loss: 15799.68
[INFO 2017-06-29 12:47:34,664 main.py:57] epoch 716, training loss: 8939.18, average training loss: 10237.41, base loss: 15797.84
[INFO 2017-06-29 12:47:37,973 main.py:57] epoch 717, training loss: 9597.62, average training loss: 10236.52, base loss: 15798.95
[INFO 2017-06-29 12:47:41,326 main.py:57] epoch 718, training loss: 9580.00, average training loss: 10235.60, base loss: 15800.88
[INFO 2017-06-29 12:47:44,552 main.py:57] epoch 719, training loss: 8189.53, average training loss: 10232.76, base loss: 15800.30
[INFO 2017-06-29 12:47:47,677 main.py:57] epoch 720, training loss: 9866.43, average training loss: 10232.25, base loss: 15800.36
[INFO 2017-06-29 12:47:50,961 main.py:57] epoch 721, training loss: 9215.83, average training loss: 10230.84, base loss: 15797.75
[INFO 2017-06-29 12:47:54,235 main.py:57] epoch 722, training loss: 8715.34, average training loss: 10228.75, base loss: 15797.06
[INFO 2017-06-29 12:47:57,491 main.py:57] epoch 723, training loss: 9091.32, average training loss: 10227.18, base loss: 15796.90
[INFO 2017-06-29 12:48:00,781 main.py:57] epoch 724, training loss: 9424.42, average training loss: 10226.07, base loss: 15796.78
[INFO 2017-06-29 12:48:04,064 main.py:57] epoch 725, training loss: 8293.87, average training loss: 10223.41, base loss: 15794.77
[INFO 2017-06-29 12:48:07,406 main.py:57] epoch 726, training loss: 9219.74, average training loss: 10222.03, base loss: 15796.09
[INFO 2017-06-29 12:48:10,704 main.py:57] epoch 727, training loss: 9725.45, average training loss: 10221.35, base loss: 15799.81
[INFO 2017-06-29 12:48:13,896 main.py:57] epoch 728, training loss: 9135.38, average training loss: 10219.86, base loss: 15799.39
[INFO 2017-06-29 12:48:17,479 main.py:57] epoch 729, training loss: 9053.19, average training loss: 10218.26, base loss: 15797.29
[INFO 2017-06-29 12:48:20,783 main.py:57] epoch 730, training loss: 8683.44, average training loss: 10216.16, base loss: 15795.69
[INFO 2017-06-29 12:48:24,046 main.py:57] epoch 731, training loss: 9275.59, average training loss: 10214.87, base loss: 15796.64
[INFO 2017-06-29 12:48:27,291 main.py:57] epoch 732, training loss: 8244.96, average training loss: 10212.19, base loss: 15791.59
[INFO 2017-06-29 12:48:30,621 main.py:57] epoch 733, training loss: 8272.32, average training loss: 10209.54, base loss: 15788.68
[INFO 2017-06-29 12:48:33,938 main.py:57] epoch 734, training loss: 8677.08, average training loss: 10207.46, base loss: 15787.88
[INFO 2017-06-29 12:48:37,184 main.py:57] epoch 735, training loss: 8329.07, average training loss: 10204.91, base loss: 15785.92
[INFO 2017-06-29 12:48:40,388 main.py:57] epoch 736, training loss: 9188.85, average training loss: 10203.53, base loss: 15788.38
[INFO 2017-06-29 12:48:43,652 main.py:57] epoch 737, training loss: 8503.65, average training loss: 10201.22, base loss: 15788.34
[INFO 2017-06-29 12:48:46,942 main.py:57] epoch 738, training loss: 9225.83, average training loss: 10199.90, base loss: 15789.83
[INFO 2017-06-29 12:48:50,391 main.py:57] epoch 739, training loss: 8493.45, average training loss: 10197.60, base loss: 15788.68
[INFO 2017-06-29 12:48:53,575 main.py:57] epoch 740, training loss: 8630.72, average training loss: 10195.48, base loss: 15786.01
[INFO 2017-06-29 12:48:56,772 main.py:57] epoch 741, training loss: 8705.49, average training loss: 10193.48, base loss: 15784.34
[INFO 2017-06-29 12:49:00,119 main.py:57] epoch 742, training loss: 9061.83, average training loss: 10191.95, base loss: 15784.97
[INFO 2017-06-29 12:49:03,348 main.py:57] epoch 743, training loss: 11302.21, average training loss: 10193.45, base loss: 15789.98
[INFO 2017-06-29 12:49:06,672 main.py:57] epoch 744, training loss: 8480.77, average training loss: 10191.15, base loss: 15788.77
[INFO 2017-06-29 12:49:09,903 main.py:57] epoch 745, training loss: 8951.62, average training loss: 10189.48, base loss: 15788.94
[INFO 2017-06-29 12:49:13,231 main.py:57] epoch 746, training loss: 9047.30, average training loss: 10187.96, base loss: 15787.73
[INFO 2017-06-29 12:49:16,469 main.py:57] epoch 747, training loss: 8743.21, average training loss: 10186.02, base loss: 15788.88
[INFO 2017-06-29 12:49:19,743 main.py:57] epoch 748, training loss: 7924.81, average training loss: 10183.01, base loss: 15784.97
[INFO 2017-06-29 12:49:23,010 main.py:57] epoch 749, training loss: 8710.41, average training loss: 10181.04, base loss: 15783.64
[INFO 2017-06-29 12:49:26,365 main.py:57] epoch 750, training loss: 9591.79, average training loss: 10180.26, base loss: 15783.30
[INFO 2017-06-29 12:49:29,712 main.py:57] epoch 751, training loss: 9894.46, average training loss: 10179.88, base loss: 15783.43
[INFO 2017-06-29 12:49:32,980 main.py:57] epoch 752, training loss: 8262.51, average training loss: 10177.33, base loss: 15781.81
[INFO 2017-06-29 12:49:36,352 main.py:57] epoch 753, training loss: 9593.22, average training loss: 10176.56, base loss: 15783.66
[INFO 2017-06-29 12:49:39,650 main.py:57] epoch 754, training loss: 8619.46, average training loss: 10174.49, base loss: 15782.39
[INFO 2017-06-29 12:49:43,004 main.py:57] epoch 755, training loss: 9881.14, average training loss: 10174.11, base loss: 15786.26
[INFO 2017-06-29 12:49:46,384 main.py:57] epoch 756, training loss: 8733.26, average training loss: 10172.20, base loss: 15786.56
[INFO 2017-06-29 12:49:49,687 main.py:57] epoch 757, training loss: 8739.85, average training loss: 10170.31, base loss: 15787.50
[INFO 2017-06-29 12:49:53,015 main.py:57] epoch 758, training loss: 9547.49, average training loss: 10169.49, base loss: 15788.78
[INFO 2017-06-29 12:49:56,187 main.py:57] epoch 759, training loss: 8474.52, average training loss: 10167.26, base loss: 15784.99
[INFO 2017-06-29 12:49:59,613 main.py:57] epoch 760, training loss: 8308.37, average training loss: 10164.82, base loss: 15783.10
[INFO 2017-06-29 12:50:03,018 main.py:57] epoch 761, training loss: 8346.89, average training loss: 10162.43, base loss: 15781.38
[INFO 2017-06-29 12:50:06,465 main.py:57] epoch 762, training loss: 8629.17, average training loss: 10160.42, base loss: 15779.08
[INFO 2017-06-29 12:50:09,782 main.py:57] epoch 763, training loss: 7651.03, average training loss: 10157.14, base loss: 15776.26
[INFO 2017-06-29 12:50:13,156 main.py:57] epoch 764, training loss: 9785.72, average training loss: 10156.65, base loss: 15776.26
[INFO 2017-06-29 12:50:16,470 main.py:57] epoch 765, training loss: 8600.51, average training loss: 10154.62, base loss: 15772.62
[INFO 2017-06-29 12:50:19,755 main.py:57] epoch 766, training loss: 9770.75, average training loss: 10154.12, base loss: 15773.67
[INFO 2017-06-29 12:50:23,102 main.py:57] epoch 767, training loss: 9406.66, average training loss: 10153.15, base loss: 15774.40
[INFO 2017-06-29 12:50:26,396 main.py:57] epoch 768, training loss: 10293.50, average training loss: 10153.33, base loss: 15777.75
[INFO 2017-06-29 12:50:29,724 main.py:57] epoch 769, training loss: 8995.51, average training loss: 10151.83, base loss: 15778.75
[INFO 2017-06-29 12:50:33,098 main.py:57] epoch 770, training loss: 9484.30, average training loss: 10150.96, base loss: 15779.03
[INFO 2017-06-29 12:50:36,499 main.py:57] epoch 771, training loss: 9263.09, average training loss: 10149.81, base loss: 15777.09
[INFO 2017-06-29 12:50:39,772 main.py:57] epoch 772, training loss: 8993.85, average training loss: 10148.32, base loss: 15776.62
[INFO 2017-06-29 12:50:43,087 main.py:57] epoch 773, training loss: 9168.34, average training loss: 10147.05, base loss: 15777.47
[INFO 2017-06-29 12:50:46,356 main.py:57] epoch 774, training loss: 10109.76, average training loss: 10147.00, base loss: 15781.72
[INFO 2017-06-29 12:50:49,686 main.py:57] epoch 775, training loss: 8572.72, average training loss: 10144.97, base loss: 15778.46
[INFO 2017-06-29 12:50:53,015 main.py:57] epoch 776, training loss: 8229.61, average training loss: 10142.51, base loss: 15775.56
[INFO 2017-06-29 12:50:56,267 main.py:57] epoch 777, training loss: 8678.33, average training loss: 10140.63, base loss: 15775.03
[INFO 2017-06-29 12:50:59,491 main.py:57] epoch 778, training loss: 8850.13, average training loss: 10138.97, base loss: 15775.40
[INFO 2017-06-29 12:51:02,895 main.py:57] epoch 779, training loss: 8416.29, average training loss: 10136.76, base loss: 15773.76
[INFO 2017-06-29 12:51:06,149 main.py:57] epoch 780, training loss: 9700.70, average training loss: 10136.20, base loss: 15773.80
[INFO 2017-06-29 12:51:09,444 main.py:57] epoch 781, training loss: 10033.41, average training loss: 10136.07, base loss: 15776.61
[INFO 2017-06-29 12:51:12,880 main.py:57] epoch 782, training loss: 8761.44, average training loss: 10134.32, base loss: 15775.44
[INFO 2017-06-29 12:51:16,233 main.py:57] epoch 783, training loss: 8993.18, average training loss: 10132.86, base loss: 15775.78
[INFO 2017-06-29 12:51:19,561 main.py:57] epoch 784, training loss: 9750.28, average training loss: 10132.37, base loss: 15778.67
[INFO 2017-06-29 12:51:22,864 main.py:57] epoch 785, training loss: 9420.83, average training loss: 10131.47, base loss: 15781.00
[INFO 2017-06-29 12:51:26,241 main.py:57] epoch 786, training loss: 9046.53, average training loss: 10130.09, base loss: 15781.98
[INFO 2017-06-29 12:51:29,597 main.py:57] epoch 787, training loss: 9084.70, average training loss: 10128.76, base loss: 15780.90
[INFO 2017-06-29 12:51:32,838 main.py:57] epoch 788, training loss: 8763.50, average training loss: 10127.03, base loss: 15780.68
[INFO 2017-06-29 12:51:36,088 main.py:57] epoch 789, training loss: 8716.08, average training loss: 10125.25, base loss: 15779.51
[INFO 2017-06-29 12:51:39,342 main.py:57] epoch 790, training loss: 7928.53, average training loss: 10122.47, base loss: 15777.43
[INFO 2017-06-29 12:51:42,656 main.py:57] epoch 791, training loss: 9476.38, average training loss: 10121.65, base loss: 15779.06
[INFO 2017-06-29 12:51:45,995 main.py:57] epoch 792, training loss: 7954.08, average training loss: 10118.92, base loss: 15774.17
[INFO 2017-06-29 12:51:49,188 main.py:57] epoch 793, training loss: 8532.78, average training loss: 10116.92, base loss: 15772.42
[INFO 2017-06-29 12:51:52,449 main.py:57] epoch 794, training loss: 9894.71, average training loss: 10116.64, base loss: 15777.96
[INFO 2017-06-29 12:51:55,635 main.py:57] epoch 795, training loss: 9601.62, average training loss: 10116.00, base loss: 15781.61
[INFO 2017-06-29 12:51:58,976 main.py:57] epoch 796, training loss: 9300.47, average training loss: 10114.97, base loss: 15782.10
[INFO 2017-06-29 12:52:02,250 main.py:57] epoch 797, training loss: 8898.30, average training loss: 10113.45, base loss: 15782.42
[INFO 2017-06-29 12:52:05,559 main.py:57] epoch 798, training loss: 9457.82, average training loss: 10112.63, base loss: 15782.56
[INFO 2017-06-29 12:52:08,971 main.py:57] epoch 799, training loss: 9111.86, average training loss: 10111.38, base loss: 15783.43
[INFO 2017-06-29 12:52:08,972 main.py:59] epoch 799, testing
[INFO 2017-06-29 12:52:22,555 main.py:104] average testing loss: 8268.38, base loss: 16230.50
[INFO 2017-06-29 12:52:22,555 main.py:105] improve_loss: 7962.12, improve_percent: 0.49
[INFO 2017-06-29 12:52:22,557 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 12:52:22,596 main.py:71] current best improved percent: 0.49
[INFO 2017-06-29 12:52:25,678 main.py:57] epoch 800, training loss: 9955.53, average training loss: 10111.18, base loss: 15784.37
[INFO 2017-06-29 12:52:29,052 main.py:57] epoch 801, training loss: 8233.50, average training loss: 10108.84, base loss: 15780.86
[INFO 2017-06-29 12:52:32,299 main.py:57] epoch 802, training loss: 9137.38, average training loss: 10107.63, base loss: 15781.91
[INFO 2017-06-29 12:52:35,664 main.py:57] epoch 803, training loss: 10060.29, average training loss: 10107.57, base loss: 15784.49
[INFO 2017-06-29 12:52:39,057 main.py:57] epoch 804, training loss: 9184.01, average training loss: 10106.42, base loss: 15782.73
[INFO 2017-06-29 12:52:42,395 main.py:57] epoch 805, training loss: 9052.55, average training loss: 10105.12, base loss: 15782.66
[INFO 2017-06-29 12:52:45,678 main.py:57] epoch 806, training loss: 10001.19, average training loss: 10104.99, base loss: 15784.59
[INFO 2017-06-29 12:52:48,947 main.py:57] epoch 807, training loss: 9678.62, average training loss: 10104.46, base loss: 15784.68
[INFO 2017-06-29 12:52:52,273 main.py:57] epoch 808, training loss: 9853.35, average training loss: 10104.15, base loss: 15788.50
[INFO 2017-06-29 12:52:55,511 main.py:57] epoch 809, training loss: 9663.60, average training loss: 10103.61, base loss: 15791.38
[INFO 2017-06-29 12:52:58,736 main.py:57] epoch 810, training loss: 8807.18, average training loss: 10102.01, base loss: 15792.72
[INFO 2017-06-29 12:53:02,075 main.py:57] epoch 811, training loss: 8711.21, average training loss: 10100.29, base loss: 15794.99
[INFO 2017-06-29 12:53:05,384 main.py:57] epoch 812, training loss: 8942.00, average training loss: 10098.87, base loss: 15795.26
[INFO 2017-06-29 12:53:08,611 main.py:57] epoch 813, training loss: 9673.85, average training loss: 10098.35, base loss: 15797.88
[INFO 2017-06-29 12:53:11,852 main.py:57] epoch 814, training loss: 8289.52, average training loss: 10096.13, base loss: 15795.26
[INFO 2017-06-29 12:53:15,046 main.py:57] epoch 815, training loss: 8316.52, average training loss: 10093.95, base loss: 15793.16
[INFO 2017-06-29 12:53:18,355 main.py:57] epoch 816, training loss: 10630.06, average training loss: 10094.60, base loss: 15796.87
[INFO 2017-06-29 12:53:21,532 main.py:57] epoch 817, training loss: 8810.04, average training loss: 10093.03, base loss: 15796.15
[INFO 2017-06-29 12:53:24,982 main.py:57] epoch 818, training loss: 8546.70, average training loss: 10091.15, base loss: 15796.42
[INFO 2017-06-29 12:53:28,318 main.py:57] epoch 819, training loss: 10159.95, average training loss: 10091.23, base loss: 15802.62
[INFO 2017-06-29 12:53:31,593 main.py:57] epoch 820, training loss: 9102.01, average training loss: 10090.02, base loss: 15803.85
[INFO 2017-06-29 12:53:34,803 main.py:57] epoch 821, training loss: 8837.09, average training loss: 10088.50, base loss: 15803.21
[INFO 2017-06-29 12:53:38,067 main.py:57] epoch 822, training loss: 8172.06, average training loss: 10086.17, base loss: 15800.94
[INFO 2017-06-29 12:53:41,426 main.py:57] epoch 823, training loss: 9436.99, average training loss: 10085.38, base loss: 15800.95
[INFO 2017-06-29 12:53:44,662 main.py:57] epoch 824, training loss: 9719.56, average training loss: 10084.94, base loss: 15801.51
[INFO 2017-06-29 12:53:47,896 main.py:57] epoch 825, training loss: 9304.72, average training loss: 10084.00, base loss: 15798.02
[INFO 2017-06-29 12:53:51,216 main.py:57] epoch 826, training loss: 8248.40, average training loss: 10081.78, base loss: 15795.94
[INFO 2017-06-29 12:53:54,433 main.py:57] epoch 827, training loss: 8233.95, average training loss: 10079.54, base loss: 15794.85
[INFO 2017-06-29 12:53:57,755 main.py:57] epoch 828, training loss: 8626.25, average training loss: 10077.79, base loss: 15793.63
[INFO 2017-06-29 12:54:01,023 main.py:57] epoch 829, training loss: 8251.70, average training loss: 10075.59, base loss: 15792.16
[INFO 2017-06-29 12:54:04,277 main.py:57] epoch 830, training loss: 9714.38, average training loss: 10075.16, base loss: 15791.10
[INFO 2017-06-29 12:54:07,508 main.py:57] epoch 831, training loss: 9964.05, average training loss: 10075.02, base loss: 15792.35
[INFO 2017-06-29 12:54:10,751 main.py:57] epoch 832, training loss: 8029.40, average training loss: 10072.57, base loss: 15789.15
[INFO 2017-06-29 12:54:13,953 main.py:57] epoch 833, training loss: 8601.54, average training loss: 10070.80, base loss: 15788.37
[INFO 2017-06-29 12:54:17,402 main.py:57] epoch 834, training loss: 8919.37, average training loss: 10069.42, base loss: 15790.12
[INFO 2017-06-29 12:54:20,729 main.py:57] epoch 835, training loss: 8763.05, average training loss: 10067.86, base loss: 15788.73
[INFO 2017-06-29 12:54:24,065 main.py:57] epoch 836, training loss: 9007.93, average training loss: 10066.60, base loss: 15789.70
[INFO 2017-06-29 12:54:27,290 main.py:57] epoch 837, training loss: 8239.23, average training loss: 10064.41, base loss: 15787.58
[INFO 2017-06-29 12:54:30,602 main.py:57] epoch 838, training loss: 8651.72, average training loss: 10062.73, base loss: 15787.81
[INFO 2017-06-29 12:54:34,126 main.py:57] epoch 839, training loss: 8248.08, average training loss: 10060.57, base loss: 15786.39
[INFO 2017-06-29 12:54:37,529 main.py:57] epoch 840, training loss: 9308.22, average training loss: 10059.68, base loss: 15788.52
[INFO 2017-06-29 12:54:40,891 main.py:57] epoch 841, training loss: 8778.45, average training loss: 10058.15, base loss: 15789.37
[INFO 2017-06-29 12:54:44,149 main.py:57] epoch 842, training loss: 8915.83, average training loss: 10056.80, base loss: 15788.93
[INFO 2017-06-29 12:54:47,371 main.py:57] epoch 843, training loss: 9642.78, average training loss: 10056.31, base loss: 15789.69
[INFO 2017-06-29 12:54:50,618 main.py:57] epoch 844, training loss: 7966.25, average training loss: 10053.84, base loss: 15786.11
[INFO 2017-06-29 12:54:54,097 main.py:57] epoch 845, training loss: 8602.38, average training loss: 10052.12, base loss: 15783.93
[INFO 2017-06-29 12:54:57,570 main.py:57] epoch 846, training loss: 7727.22, average training loss: 10049.37, base loss: 15779.71
[INFO 2017-06-29 12:55:00,888 main.py:57] epoch 847, training loss: 8828.73, average training loss: 10047.94, base loss: 15779.75
[INFO 2017-06-29 12:55:04,170 main.py:57] epoch 848, training loss: 9309.50, average training loss: 10047.07, base loss: 15779.48
[INFO 2017-06-29 12:55:07,457 main.py:57] epoch 849, training loss: 8744.14, average training loss: 10045.53, base loss: 15778.18
[INFO 2017-06-29 12:55:10,838 main.py:57] epoch 850, training loss: 9058.02, average training loss: 10044.37, base loss: 15778.58
[INFO 2017-06-29 12:55:14,237 main.py:57] epoch 851, training loss: 8851.58, average training loss: 10042.97, base loss: 15779.11
[INFO 2017-06-29 12:55:17,558 main.py:57] epoch 852, training loss: 9990.23, average training loss: 10042.91, base loss: 15778.85
[INFO 2017-06-29 12:55:20,892 main.py:57] epoch 853, training loss: 9447.61, average training loss: 10042.21, base loss: 15778.06
[INFO 2017-06-29 12:55:24,188 main.py:57] epoch 854, training loss: 8426.52, average training loss: 10040.32, base loss: 15775.78
[INFO 2017-06-29 12:55:27,679 main.py:57] epoch 855, training loss: 8921.71, average training loss: 10039.02, base loss: 15777.18
[INFO 2017-06-29 12:55:31,046 main.py:57] epoch 856, training loss: 8678.22, average training loss: 10037.43, base loss: 15775.66
[INFO 2017-06-29 12:55:34,205 main.py:57] epoch 857, training loss: 8376.33, average training loss: 10035.49, base loss: 15773.09
[INFO 2017-06-29 12:55:37,504 main.py:57] epoch 858, training loss: 8552.27, average training loss: 10033.77, base loss: 15768.29
[INFO 2017-06-29 12:55:40,758 main.py:57] epoch 859, training loss: 8949.16, average training loss: 10032.51, base loss: 15765.38
[INFO 2017-06-29 12:55:44,058 main.py:57] epoch 860, training loss: 9411.23, average training loss: 10031.78, base loss: 15767.77
[INFO 2017-06-29 12:55:47,350 main.py:57] epoch 861, training loss: 9657.35, average training loss: 10031.35, base loss: 15769.97
[INFO 2017-06-29 12:55:50,690 main.py:57] epoch 862, training loss: 8333.24, average training loss: 10029.38, base loss: 15769.18
[INFO 2017-06-29 12:55:54,008 main.py:57] epoch 863, training loss: 8693.55, average training loss: 10027.84, base loss: 15768.71
[INFO 2017-06-29 12:55:57,382 main.py:57] epoch 864, training loss: 9796.04, average training loss: 10027.57, base loss: 15773.73
[INFO 2017-06-29 12:56:00,722 main.py:57] epoch 865, training loss: 9308.85, average training loss: 10026.74, base loss: 15775.39
[INFO 2017-06-29 12:56:04,075 main.py:57] epoch 866, training loss: 8219.52, average training loss: 10024.65, base loss: 15773.03
[INFO 2017-06-29 12:56:07,396 main.py:57] epoch 867, training loss: 8366.87, average training loss: 10022.74, base loss: 15770.53
[INFO 2017-06-29 12:56:10,677 main.py:57] epoch 868, training loss: 8511.67, average training loss: 10021.00, base loss: 15769.94
[INFO 2017-06-29 12:56:14,009 main.py:57] epoch 869, training loss: 8787.18, average training loss: 10019.59, base loss: 15769.04
[INFO 2017-06-29 12:56:17,404 main.py:57] epoch 870, training loss: 8615.08, average training loss: 10017.97, base loss: 15767.21
[INFO 2017-06-29 12:56:20,806 main.py:57] epoch 871, training loss: 8414.26, average training loss: 10016.13, base loss: 15763.91
[INFO 2017-06-29 12:56:24,190 main.py:57] epoch 872, training loss: 8309.14, average training loss: 10014.18, base loss: 15760.98
[INFO 2017-06-29 12:56:27,500 main.py:57] epoch 873, training loss: 9479.79, average training loss: 10013.57, base loss: 15761.05
[INFO 2017-06-29 12:56:30,714 main.py:57] epoch 874, training loss: 8396.02, average training loss: 10011.72, base loss: 15758.19
[INFO 2017-06-29 12:56:34,002 main.py:57] epoch 875, training loss: 8059.16, average training loss: 10009.49, base loss: 15755.46
[INFO 2017-06-29 12:56:37,184 main.py:57] epoch 876, training loss: 9033.79, average training loss: 10008.38, base loss: 15755.28
[INFO 2017-06-29 12:56:40,515 main.py:57] epoch 877, training loss: 8662.08, average training loss: 10006.84, base loss: 15753.46
[INFO 2017-06-29 12:56:43,841 main.py:57] epoch 878, training loss: 9368.19, average training loss: 10006.12, base loss: 15754.07
[INFO 2017-06-29 12:56:46,995 main.py:57] epoch 879, training loss: 8238.50, average training loss: 10004.11, base loss: 15752.05
[INFO 2017-06-29 12:56:50,565 main.py:57] epoch 880, training loss: 8780.57, average training loss: 10002.72, base loss: 15752.92
[INFO 2017-06-29 12:56:53,838 main.py:57] epoch 881, training loss: 9641.79, average training loss: 10002.31, base loss: 15752.71
[INFO 2017-06-29 12:56:57,144 main.py:57] epoch 882, training loss: 8632.73, average training loss: 10000.76, base loss: 15752.98
[INFO 2017-06-29 12:57:00,278 main.py:57] epoch 883, training loss: 8957.54, average training loss: 9999.58, base loss: 15753.84
[INFO 2017-06-29 12:57:03,680 main.py:57] epoch 884, training loss: 8499.26, average training loss: 9997.88, base loss: 15752.71
[INFO 2017-06-29 12:57:07,096 main.py:57] epoch 885, training loss: 8595.45, average training loss: 9996.30, base loss: 15751.30
[INFO 2017-06-29 12:57:10,254 main.py:57] epoch 886, training loss: 8408.47, average training loss: 9994.51, base loss: 15749.83
[INFO 2017-06-29 12:57:13,545 main.py:57] epoch 887, training loss: 9393.43, average training loss: 9993.83, base loss: 15751.13
[INFO 2017-06-29 12:57:16,877 main.py:57] epoch 888, training loss: 8929.42, average training loss: 9992.64, base loss: 15753.50
[INFO 2017-06-29 12:57:20,088 main.py:57] epoch 889, training loss: 8018.59, average training loss: 9990.42, base loss: 15753.23
[INFO 2017-06-29 12:57:23,639 main.py:57] epoch 890, training loss: 8450.88, average training loss: 9988.69, base loss: 15752.63
[INFO 2017-06-29 12:57:27,073 main.py:57] epoch 891, training loss: 9539.53, average training loss: 9988.19, base loss: 15753.54
[INFO 2017-06-29 12:57:30,382 main.py:57] epoch 892, training loss: 8084.98, average training loss: 9986.06, base loss: 15750.87
[INFO 2017-06-29 12:57:33,745 main.py:57] epoch 893, training loss: 8862.06, average training loss: 9984.80, base loss: 15748.41
[INFO 2017-06-29 12:57:37,020 main.py:57] epoch 894, training loss: 8966.69, average training loss: 9983.66, base loss: 15748.71
[INFO 2017-06-29 12:57:40,310 main.py:57] epoch 895, training loss: 8703.24, average training loss: 9982.23, base loss: 15748.29
[INFO 2017-06-29 12:57:43,593 main.py:57] epoch 896, training loss: 8129.99, average training loss: 9980.17, base loss: 15746.11
[INFO 2017-06-29 12:57:46,934 main.py:57] epoch 897, training loss: 9290.93, average training loss: 9979.40, base loss: 15748.50
[INFO 2017-06-29 12:57:50,236 main.py:57] epoch 898, training loss: 8449.40, average training loss: 9977.70, base loss: 15746.81
[INFO 2017-06-29 12:57:53,455 main.py:57] epoch 899, training loss: 8478.28, average training loss: 9976.03, base loss: 15745.52
[INFO 2017-06-29 12:57:53,455 main.py:59] epoch 899, testing
[INFO 2017-06-29 12:58:07,368 main.py:104] average testing loss: 8047.91, base loss: 15785.75
[INFO 2017-06-29 12:58:07,368 main.py:105] improve_loss: 7737.84, improve_percent: 0.49
[INFO 2017-06-29 12:58:07,370 main.py:71] current best improved percent: 0.49
[INFO 2017-06-29 12:58:10,801 main.py:57] epoch 900, training loss: 9543.30, average training loss: 9975.55, base loss: 15744.61
[INFO 2017-06-29 12:58:14,107 main.py:57] epoch 901, training loss: 9234.30, average training loss: 9974.73, base loss: 15746.53
[INFO 2017-06-29 12:58:17,526 main.py:57] epoch 902, training loss: 8633.30, average training loss: 9973.24, base loss: 15746.61
[INFO 2017-06-29 12:58:20,955 main.py:57] epoch 903, training loss: 10106.74, average training loss: 9973.39, base loss: 15748.73
[INFO 2017-06-29 12:58:24,304 main.py:57] epoch 904, training loss: 9601.35, average training loss: 9972.98, base loss: 15750.24
[INFO 2017-06-29 12:58:27,645 main.py:57] epoch 905, training loss: 8502.49, average training loss: 9971.36, base loss: 15749.39
[INFO 2017-06-29 12:58:30,998 main.py:57] epoch 906, training loss: 8214.06, average training loss: 9969.42, base loss: 15746.32
[INFO 2017-06-29 12:58:34,288 main.py:57] epoch 907, training loss: 8883.18, average training loss: 9968.22, base loss: 15746.20
[INFO 2017-06-29 12:58:37,537 main.py:57] epoch 908, training loss: 8410.23, average training loss: 9966.51, base loss: 15746.74
[INFO 2017-06-29 12:58:41,067 main.py:57] epoch 909, training loss: 9165.80, average training loss: 9965.63, base loss: 15747.40
[INFO 2017-06-29 12:58:44,317 main.py:57] epoch 910, training loss: 8235.31, average training loss: 9963.73, base loss: 15744.08
[INFO 2017-06-29 12:58:47,537 main.py:57] epoch 911, training loss: 9382.47, average training loss: 9963.09, base loss: 15744.26
[INFO 2017-06-29 12:58:50,934 main.py:57] epoch 912, training loss: 10112.29, average training loss: 9963.26, base loss: 15747.49
[INFO 2017-06-29 12:58:54,357 main.py:57] epoch 913, training loss: 8350.19, average training loss: 9961.49, base loss: 15746.80
[INFO 2017-06-29 12:58:57,683 main.py:57] epoch 914, training loss: 8653.58, average training loss: 9960.06, base loss: 15747.36
[INFO 2017-06-29 12:59:00,966 main.py:57] epoch 915, training loss: 9582.75, average training loss: 9959.65, base loss: 15749.19
[INFO 2017-06-29 12:59:04,236 main.py:57] epoch 916, training loss: 9150.28, average training loss: 9958.77, base loss: 15750.25
[INFO 2017-06-29 12:59:07,533 main.py:57] epoch 917, training loss: 9176.83, average training loss: 9957.92, base loss: 15747.97
[INFO 2017-06-29 12:59:10,888 main.py:57] epoch 918, training loss: 8305.73, average training loss: 9956.12, base loss: 15747.50
[INFO 2017-06-29 12:59:14,171 main.py:57] epoch 919, training loss: 8859.03, average training loss: 9954.93, base loss: 15748.19
[INFO 2017-06-29 12:59:17,692 main.py:57] epoch 920, training loss: 9202.87, average training loss: 9954.11, base loss: 15747.95
[INFO 2017-06-29 12:59:21,083 main.py:57] epoch 921, training loss: 8476.73, average training loss: 9952.51, base loss: 15744.91
[INFO 2017-06-29 12:59:24,259 main.py:57] epoch 922, training loss: 8775.80, average training loss: 9951.23, base loss: 15745.12
[INFO 2017-06-29 12:59:27,629 main.py:57] epoch 923, training loss: 9055.44, average training loss: 9950.26, base loss: 15746.78
[INFO 2017-06-29 12:59:30,894 main.py:57] epoch 924, training loss: 9248.35, average training loss: 9949.50, base loss: 15746.18
[INFO 2017-06-29 12:59:34,117 main.py:57] epoch 925, training loss: 9153.19, average training loss: 9948.64, base loss: 15743.89
[INFO 2017-06-29 12:59:37,449 main.py:57] epoch 926, training loss: 8650.58, average training loss: 9947.24, base loss: 15742.71
[INFO 2017-06-29 12:59:40,744 main.py:57] epoch 927, training loss: 8633.36, average training loss: 9945.83, base loss: 15742.30
[INFO 2017-06-29 12:59:44,165 main.py:57] epoch 928, training loss: 8377.88, average training loss: 9944.14, base loss: 15739.58
[INFO 2017-06-29 12:59:47,560 main.py:57] epoch 929, training loss: 8644.56, average training loss: 9942.74, base loss: 15736.81
[INFO 2017-06-29 12:59:50,947 main.py:57] epoch 930, training loss: 8792.19, average training loss: 9941.51, base loss: 15736.91
[INFO 2017-06-29 12:59:54,220 main.py:57] epoch 931, training loss: 9044.93, average training loss: 9940.55, base loss: 15735.94
[INFO 2017-06-29 12:59:57,512 main.py:57] epoch 932, training loss: 7634.92, average training loss: 9938.07, base loss: 15734.07
[INFO 2017-06-29 13:00:00,772 main.py:57] epoch 933, training loss: 8389.83, average training loss: 9936.42, base loss: 15734.64
[INFO 2017-06-29 13:00:04,078 main.py:57] epoch 934, training loss: 8792.52, average training loss: 9935.19, base loss: 15732.80
[INFO 2017-06-29 13:00:07,481 main.py:57] epoch 935, training loss: 9710.27, average training loss: 9934.95, base loss: 15735.38
[INFO 2017-06-29 13:00:10,629 main.py:57] epoch 936, training loss: 8523.57, average training loss: 9933.45, base loss: 15735.83
[INFO 2017-06-29 13:00:13,977 main.py:57] epoch 937, training loss: 8836.31, average training loss: 9932.28, base loss: 15737.65
[INFO 2017-06-29 13:00:17,228 main.py:57] epoch 938, training loss: 9394.98, average training loss: 9931.70, base loss: 15738.89
[INFO 2017-06-29 13:00:20,446 main.py:57] epoch 939, training loss: 8674.12, average training loss: 9930.37, base loss: 15737.53
[INFO 2017-06-29 13:00:23,616 main.py:57] epoch 940, training loss: 8522.94, average training loss: 9928.87, base loss: 15736.74
[INFO 2017-06-29 13:00:26,910 main.py:57] epoch 941, training loss: 8527.21, average training loss: 9927.38, base loss: 15735.87
[INFO 2017-06-29 13:00:30,043 main.py:57] epoch 942, training loss: 9180.85, average training loss: 9926.59, base loss: 15737.01
[INFO 2017-06-29 13:00:33,330 main.py:57] epoch 943, training loss: 8011.16, average training loss: 9924.56, base loss: 15735.11
[INFO 2017-06-29 13:00:36,588 main.py:57] epoch 944, training loss: 9044.25, average training loss: 9923.63, base loss: 15735.00
[INFO 2017-06-29 13:00:39,824 main.py:57] epoch 945, training loss: 9796.03, average training loss: 9923.50, base loss: 15737.63
[INFO 2017-06-29 13:00:43,087 main.py:57] epoch 946, training loss: 8040.50, average training loss: 9921.51, base loss: 15733.83
[INFO 2017-06-29 13:00:46,345 main.py:57] epoch 947, training loss: 8951.03, average training loss: 9920.48, base loss: 15732.37
[INFO 2017-06-29 13:00:49,656 main.py:57] epoch 948, training loss: 9482.07, average training loss: 9920.02, base loss: 15733.12
[INFO 2017-06-29 13:00:52,950 main.py:57] epoch 949, training loss: 9585.02, average training loss: 9919.67, base loss: 15734.39
[INFO 2017-06-29 13:00:56,170 main.py:57] epoch 950, training loss: 8517.59, average training loss: 9918.19, base loss: 15732.75
[INFO 2017-06-29 13:00:59,524 main.py:57] epoch 951, training loss: 8134.78, average training loss: 9916.32, base loss: 15728.69
[INFO 2017-06-29 13:01:02,858 main.py:57] epoch 952, training loss: 8641.02, average training loss: 9914.98, base loss: 15727.53
[INFO 2017-06-29 13:01:06,152 main.py:57] epoch 953, training loss: 10384.26, average training loss: 9915.48, base loss: 15731.19
[INFO 2017-06-29 13:01:09,587 main.py:57] epoch 954, training loss: 8726.56, average training loss: 9914.23, base loss: 15731.39
[INFO 2017-06-29 13:01:13,056 main.py:57] epoch 955, training loss: 8342.49, average training loss: 9912.59, base loss: 15730.59
[INFO 2017-06-29 13:01:16,376 main.py:57] epoch 956, training loss: 8636.82, average training loss: 9911.25, base loss: 15731.15
[INFO 2017-06-29 13:01:19,684 main.py:57] epoch 957, training loss: 8676.09, average training loss: 9909.96, base loss: 15731.19
[INFO 2017-06-29 13:01:22,887 main.py:57] epoch 958, training loss: 8579.56, average training loss: 9908.58, base loss: 15728.71
[INFO 2017-06-29 13:01:26,262 main.py:57] epoch 959, training loss: 7763.15, average training loss: 9906.34, base loss: 15725.04
[INFO 2017-06-29 13:01:29,597 main.py:57] epoch 960, training loss: 9322.83, average training loss: 9905.73, base loss: 15724.86
[INFO 2017-06-29 13:01:32,829 main.py:57] epoch 961, training loss: 9315.22, average training loss: 9905.12, base loss: 15726.56
[INFO 2017-06-29 13:01:36,096 main.py:57] epoch 962, training loss: 8462.99, average training loss: 9903.62, base loss: 15724.27
[INFO 2017-06-29 13:01:39,368 main.py:57] epoch 963, training loss: 9139.96, average training loss: 9902.83, base loss: 15725.93
[INFO 2017-06-29 13:01:42,817 main.py:57] epoch 964, training loss: 8602.58, average training loss: 9901.48, base loss: 15726.65
[INFO 2017-06-29 13:01:46,009 main.py:57] epoch 965, training loss: 7785.74, average training loss: 9899.29, base loss: 15724.41
[INFO 2017-06-29 13:01:49,316 main.py:57] epoch 966, training loss: 8649.80, average training loss: 9898.00, base loss: 15725.24
[INFO 2017-06-29 13:01:52,623 main.py:57] epoch 967, training loss: 9151.89, average training loss: 9897.23, base loss: 15726.94
[INFO 2017-06-29 13:01:55,901 main.py:57] epoch 968, training loss: 8636.53, average training loss: 9895.93, base loss: 15727.06
[INFO 2017-06-29 13:01:59,142 main.py:57] epoch 969, training loss: 8814.00, average training loss: 9894.81, base loss: 15727.72
[INFO 2017-06-29 13:02:02,478 main.py:57] epoch 970, training loss: 9605.45, average training loss: 9894.52, base loss: 15729.05
[INFO 2017-06-29 13:02:05,949 main.py:57] epoch 971, training loss: 8977.92, average training loss: 9893.57, base loss: 15728.51
[INFO 2017-06-29 13:02:09,179 main.py:57] epoch 972, training loss: 10231.23, average training loss: 9893.92, base loss: 15729.34
[INFO 2017-06-29 13:02:12,355 main.py:57] epoch 973, training loss: 8703.10, average training loss: 9892.70, base loss: 15726.36
[INFO 2017-06-29 13:02:15,691 main.py:57] epoch 974, training loss: 8428.60, average training loss: 9891.20, base loss: 15726.35
[INFO 2017-06-29 13:02:19,057 main.py:57] epoch 975, training loss: 8823.39, average training loss: 9890.10, base loss: 15726.19
[INFO 2017-06-29 13:02:22,304 main.py:57] epoch 976, training loss: 9187.58, average training loss: 9889.38, base loss: 15726.15
[INFO 2017-06-29 13:02:25,551 main.py:57] epoch 977, training loss: 9734.21, average training loss: 9889.22, base loss: 15726.75
[INFO 2017-06-29 13:02:28,921 main.py:57] epoch 978, training loss: 8816.46, average training loss: 9888.13, base loss: 15725.70
[INFO 2017-06-29 13:02:32,282 main.py:57] epoch 979, training loss: 9101.00, average training loss: 9887.33, base loss: 15724.24
[INFO 2017-06-29 13:02:35,538 main.py:57] epoch 980, training loss: 8670.94, average training loss: 9886.09, base loss: 15725.80
[INFO 2017-06-29 13:02:38,744 main.py:57] epoch 981, training loss: 9165.32, average training loss: 9885.35, base loss: 15729.24
[INFO 2017-06-29 13:02:42,117 main.py:57] epoch 982, training loss: 8216.27, average training loss: 9883.65, base loss: 15727.17
[INFO 2017-06-29 13:02:45,500 main.py:57] epoch 983, training loss: 8887.47, average training loss: 9882.64, base loss: 15726.94
[INFO 2017-06-29 13:02:48,879 main.py:57] epoch 984, training loss: 10094.77, average training loss: 9882.86, base loss: 15727.99
[INFO 2017-06-29 13:02:51,997 main.py:57] epoch 985, training loss: 9812.62, average training loss: 9882.78, base loss: 15728.22
[INFO 2017-06-29 13:02:55,431 main.py:57] epoch 986, training loss: 8241.84, average training loss: 9881.12, base loss: 15726.20
[INFO 2017-06-29 13:02:58,802 main.py:57] epoch 987, training loss: 8254.46, average training loss: 9879.48, base loss: 15725.70
[INFO 2017-06-29 13:03:02,038 main.py:57] epoch 988, training loss: 7594.84, average training loss: 9877.17, base loss: 15722.42
[INFO 2017-06-29 13:03:05,330 main.py:57] epoch 989, training loss: 8722.66, average training loss: 9876.00, base loss: 15720.31
[INFO 2017-06-29 13:03:08,669 main.py:57] epoch 990, training loss: 9777.26, average training loss: 9875.90, base loss: 15723.02
[INFO 2017-06-29 13:03:12,018 main.py:57] epoch 991, training loss: 9432.60, average training loss: 9875.45, base loss: 15724.65
[INFO 2017-06-29 13:03:15,279 main.py:57] epoch 992, training loss: 10181.80, average training loss: 9875.76, base loss: 15727.34
[INFO 2017-06-29 13:03:18,582 main.py:57] epoch 993, training loss: 8259.07, average training loss: 9874.14, base loss: 15727.14
[INFO 2017-06-29 13:03:21,879 main.py:57] epoch 994, training loss: 8332.03, average training loss: 9872.59, base loss: 15726.28
[INFO 2017-06-29 13:03:25,259 main.py:57] epoch 995, training loss: 9574.84, average training loss: 9872.29, base loss: 15725.88
[INFO 2017-06-29 13:03:28,513 main.py:57] epoch 996, training loss: 9176.67, average training loss: 9871.59, base loss: 15727.00
[INFO 2017-06-29 13:03:31,703 main.py:57] epoch 997, training loss: 9055.55, average training loss: 9870.77, base loss: 15726.60
[INFO 2017-06-29 13:03:34,894 main.py:57] epoch 998, training loss: 8902.54, average training loss: 9869.80, base loss: 15726.52
[INFO 2017-06-29 13:03:38,166 main.py:57] epoch 999, training loss: 9915.76, average training loss: 9869.85, base loss: 15728.33
[INFO 2017-06-29 13:03:38,167 main.py:59] epoch 999, testing
[INFO 2017-06-29 13:03:51,878 main.py:104] average testing loss: 8122.96, base loss: 16473.05
[INFO 2017-06-29 13:03:51,879 main.py:105] improve_loss: 8350.09, improve_percent: 0.51
[INFO 2017-06-29 13:03:51,881 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 13:03:51,924 main.py:71] current best improved percent: 0.51
[INFO 2017-06-29 13:03:55,216 main.py:57] epoch 1000, training loss: 9040.07, average training loss: 9840.62, base loss: 15727.59
[INFO 2017-06-29 13:03:58,678 main.py:57] epoch 1001, training loss: 8998.33, average training loss: 9819.65, base loss: 15728.44
[INFO 2017-06-29 13:04:02,033 main.py:57] epoch 1002, training loss: 9163.84, average training loss: 9801.26, base loss: 15729.74
[INFO 2017-06-29 13:04:05,308 main.py:57] epoch 1003, training loss: 8907.25, average training loss: 9787.26, base loss: 15729.81
[INFO 2017-06-29 13:04:08,687 main.py:57] epoch 1004, training loss: 9531.48, average training loss: 9775.96, base loss: 15730.23
[INFO 2017-06-29 13:04:11,993 main.py:57] epoch 1005, training loss: 7769.63, average training loss: 9764.59, base loss: 15727.37
[INFO 2017-06-29 13:04:15,529 main.py:57] epoch 1006, training loss: 8348.45, average training loss: 9753.00, base loss: 15723.17
[INFO 2017-06-29 13:04:18,784 main.py:57] epoch 1007, training loss: 9513.25, average training loss: 9744.49, base loss: 15720.68
[INFO 2017-06-29 13:04:22,030 main.py:57] epoch 1008, training loss: 10483.26, average training loss: 9738.73, base loss: 15724.07
[INFO 2017-06-29 13:04:25,204 main.py:57] epoch 1009, training loss: 7867.37, average training loss: 9731.57, base loss: 15721.79
[INFO 2017-06-29 13:04:28,613 main.py:57] epoch 1010, training loss: 8866.15, average training loss: 9726.39, base loss: 15721.18
[INFO 2017-06-29 13:04:32,029 main.py:57] epoch 1011, training loss: 10441.30, average training loss: 9722.79, base loss: 15725.87
[INFO 2017-06-29 13:04:35,508 main.py:57] epoch 1012, training loss: 8930.37, average training loss: 9716.60, base loss: 15726.52
[INFO 2017-06-29 13:04:38,808 main.py:57] epoch 1013, training loss: 8766.09, average training loss: 9712.38, base loss: 15726.97
[INFO 2017-06-29 13:04:42,082 main.py:57] epoch 1014, training loss: 9646.33, average training loss: 9709.34, base loss: 15730.74
[INFO 2017-06-29 13:04:45,409 main.py:57] epoch 1015, training loss: 9384.15, average training loss: 9704.99, base loss: 15733.38
[INFO 2017-06-29 13:04:48,807 main.py:57] epoch 1016, training loss: 8844.36, average training loss: 9700.80, base loss: 15733.65
[INFO 2017-06-29 13:04:52,072 main.py:57] epoch 1017, training loss: 8495.43, average training loss: 9694.91, base loss: 15733.61
[INFO 2017-06-29 13:04:55,481 main.py:57] epoch 1018, training loss: 8844.51, average training loss: 9690.13, base loss: 15734.23
[INFO 2017-06-29 13:04:58,712 main.py:57] epoch 1019, training loss: 7782.04, average training loss: 9686.09, base loss: 15730.67
[INFO 2017-06-29 13:05:02,061 main.py:57] epoch 1020, training loss: 9512.20, average training loss: 9682.09, base loss: 15731.18
[INFO 2017-06-29 13:05:05,367 main.py:57] epoch 1021, training loss: 8479.92, average training loss: 9676.77, base loss: 15728.34
[INFO 2017-06-29 13:05:08,706 main.py:57] epoch 1022, training loss: 8405.88, average training loss: 9672.60, base loss: 15727.56
[INFO 2017-06-29 13:05:12,123 main.py:57] epoch 1023, training loss: 8982.11, average training loss: 9667.55, base loss: 15728.14
[INFO 2017-06-29 13:05:15,462 main.py:57] epoch 1024, training loss: 8692.21, average training loss: 9662.64, base loss: 15727.46
[INFO 2017-06-29 13:05:18,832 main.py:57] epoch 1025, training loss: 8365.62, average training loss: 9658.21, base loss: 15726.31
[INFO 2017-06-29 13:05:22,163 main.py:57] epoch 1026, training loss: 8794.54, average training loss: 9654.80, base loss: 15725.27
[INFO 2017-06-29 13:05:25,408 main.py:57] epoch 1027, training loss: 10193.55, average training loss: 9649.90, base loss: 15728.62
[INFO 2017-06-29 13:05:28,600 main.py:57] epoch 1028, training loss: 8944.32, average training loss: 9646.41, base loss: 15728.21
[INFO 2017-06-29 13:05:31,860 main.py:57] epoch 1029, training loss: 8634.84, average training loss: 9641.20, base loss: 15728.51
[INFO 2017-06-29 13:05:35,383 main.py:57] epoch 1030, training loss: 10425.03, average training loss: 9638.18, base loss: 15731.71
[INFO 2017-06-29 13:05:38,687 main.py:57] epoch 1031, training loss: 9270.66, average training loss: 9632.63, base loss: 15731.64
[INFO 2017-06-29 13:05:42,216 main.py:57] epoch 1032, training loss: 9466.60, average training loss: 9627.91, base loss: 15735.21
[INFO 2017-06-29 13:05:45,767 main.py:57] epoch 1033, training loss: 9275.48, average training loss: 9623.39, base loss: 15738.05
[INFO 2017-06-29 13:05:49,192 main.py:57] epoch 1034, training loss: 10494.32, average training loss: 9618.26, base loss: 15743.38
[INFO 2017-06-29 13:05:52,683 main.py:57] epoch 1035, training loss: 8484.96, average training loss: 9613.07, base loss: 15742.71
[INFO 2017-06-29 13:05:55,953 main.py:57] epoch 1036, training loss: 8464.94, average training loss: 9607.72, base loss: 15741.56
[INFO 2017-06-29 13:05:59,257 main.py:57] epoch 1037, training loss: 9045.28, average training loss: 9603.83, base loss: 15742.84
[INFO 2017-06-29 13:06:02,634 main.py:57] epoch 1038, training loss: 9120.35, average training loss: 9600.75, base loss: 15744.09
[INFO 2017-06-29 13:06:05,926 main.py:57] epoch 1039, training loss: 8860.15, average training loss: 9597.02, base loss: 15743.84
[INFO 2017-06-29 13:06:09,375 main.py:57] epoch 1040, training loss: 8419.12, average training loss: 9592.64, base loss: 15741.57
[INFO 2017-06-29 13:06:12,844 main.py:57] epoch 1041, training loss: 8994.20, average training loss: 9588.17, base loss: 15741.35
[INFO 2017-06-29 13:06:16,255 main.py:57] epoch 1042, training loss: 7676.19, average training loss: 9584.01, base loss: 15739.89
[INFO 2017-06-29 13:06:19,574 main.py:57] epoch 1043, training loss: 9076.90, average training loss: 9579.87, base loss: 15741.58
[INFO 2017-06-29 13:06:22,878 main.py:57] epoch 1044, training loss: 7905.77, average training loss: 9575.36, base loss: 15739.43
[INFO 2017-06-29 13:06:26,259 main.py:57] epoch 1045, training loss: 8290.69, average training loss: 9572.73, base loss: 15738.97
[INFO 2017-06-29 13:06:29,601 main.py:57] epoch 1046, training loss: 8713.15, average training loss: 9569.23, base loss: 15739.85
[INFO 2017-06-29 13:06:32,834 main.py:57] epoch 1047, training loss: 9534.11, average training loss: 9564.32, base loss: 15741.32
[INFO 2017-06-29 13:06:36,148 main.py:57] epoch 1048, training loss: 8016.64, average training loss: 9560.13, base loss: 15742.07
[INFO 2017-06-29 13:06:39,486 main.py:57] epoch 1049, training loss: 8753.36, average training loss: 9556.65, base loss: 15742.37
