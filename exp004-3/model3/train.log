[INFO 2017-06-29 11:28:11,126 main.py:175] Namespace(batch_size=32, display=False, flow_dir='flow', flow_video_dir='flow-video', flow_video_fps=1, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=4, num_channel=3, num_inputs=2, save_dir='./model', test=False, test_dir='/home/yi/Downloads/mpii-test-64', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='/home/yi/Downloads/mpii-64', train_epoch=100000)
[INFO 2017-06-29 11:28:16,824 main.py:57] epoch 0, training loss: 39229.40, average training loss: 39229.40, base loss: 18013.42
[INFO 2017-06-29 11:28:19,390 main.py:57] epoch 1, training loss: 32820.09, average training loss: 36024.75, base loss: 17153.77
[INFO 2017-06-29 11:28:21,955 main.py:57] epoch 2, training loss: 27266.66, average training loss: 33105.38, base loss: 16347.60
[INFO 2017-06-29 11:28:24,713 main.py:57] epoch 3, training loss: 23449.48, average training loss: 30691.41, base loss: 16227.04
[INFO 2017-06-29 11:28:27,359 main.py:57] epoch 4, training loss: 20712.58, average training loss: 28695.64, base loss: 15916.35
[INFO 2017-06-29 11:28:30,045 main.py:57] epoch 5, training loss: 18487.77, average training loss: 26994.33, base loss: 15943.44
[INFO 2017-06-29 11:28:32,602 main.py:57] epoch 6, training loss: 16377.85, average training loss: 25477.69, base loss: 15857.13
[INFO 2017-06-29 11:28:35,123 main.py:57] epoch 7, training loss: 16438.79, average training loss: 24347.83, base loss: 15760.44
[INFO 2017-06-29 11:28:37,747 main.py:57] epoch 8, training loss: 14259.10, average training loss: 23226.86, base loss: 15629.12
[INFO 2017-06-29 11:28:40,368 main.py:57] epoch 9, training loss: 14277.47, average training loss: 22331.92, base loss: 15644.75
[INFO 2017-06-29 11:28:42,955 main.py:57] epoch 10, training loss: 14777.65, average training loss: 21645.17, base loss: 15706.56
[INFO 2017-06-29 11:28:45,758 main.py:57] epoch 11, training loss: 14065.32, average training loss: 21013.51, base loss: 15827.88
[INFO 2017-06-29 11:28:48,349 main.py:57] epoch 12, training loss: 13369.28, average training loss: 20425.50, base loss: 15907.76
[INFO 2017-06-29 11:28:51,007 main.py:57] epoch 13, training loss: 12041.78, average training loss: 19826.66, base loss: 15894.85
[INFO 2017-06-29 11:28:53,675 main.py:57] epoch 14, training loss: 10952.37, average training loss: 19235.04, base loss: 15778.64
[INFO 2017-06-29 11:28:56,286 main.py:57] epoch 15, training loss: 9586.50, average training loss: 18632.01, base loss: 15579.36
[INFO 2017-06-29 11:28:58,934 main.py:57] epoch 16, training loss: 10885.02, average training loss: 18176.30, base loss: 15535.96
[INFO 2017-06-29 11:29:01,621 main.py:57] epoch 17, training loss: 11167.97, average training loss: 17786.95, base loss: 15540.55
[INFO 2017-06-29 11:29:04,468 main.py:57] epoch 18, training loss: 11190.66, average training loss: 17439.78, base loss: 15558.53
[INFO 2017-06-29 11:29:07,129 main.py:57] epoch 19, training loss: 11187.61, average training loss: 17127.17, base loss: 15561.17
[INFO 2017-06-29 11:29:09,813 main.py:57] epoch 20, training loss: 11766.58, average training loss: 16871.90, base loss: 15618.51
[INFO 2017-06-29 11:29:12,514 main.py:57] epoch 21, training loss: 10339.79, average training loss: 16574.99, base loss: 15597.58
[INFO 2017-06-29 11:29:15,478 main.py:57] epoch 22, training loss: 9539.91, average training loss: 16269.11, base loss: 15508.69
[INFO 2017-06-29 11:29:18,631 main.py:57] epoch 23, training loss: 10679.65, average training loss: 16036.22, base loss: 15525.57
[INFO 2017-06-29 11:29:21,840 main.py:57] epoch 24, training loss: 11540.66, average training loss: 15856.40, base loss: 15572.85
[INFO 2017-06-29 11:29:25,043 main.py:57] epoch 25, training loss: 11283.10, average training loss: 15680.50, base loss: 15615.41
[INFO 2017-06-29 11:29:28,327 main.py:57] epoch 26, training loss: 10365.86, average training loss: 15483.66, base loss: 15588.20
[INFO 2017-06-29 11:29:31,735 main.py:57] epoch 27, training loss: 12072.66, average training loss: 15361.84, base loss: 15635.37
[INFO 2017-06-29 11:29:34,886 main.py:57] epoch 28, training loss: 13071.28, average training loss: 15282.86, base loss: 15726.33
[INFO 2017-06-29 11:29:38,146 main.py:57] epoch 29, training loss: 11407.33, average training loss: 15153.67, base loss: 15737.87
[INFO 2017-06-29 11:29:41,406 main.py:57] epoch 30, training loss: 10932.89, average training loss: 15017.52, base loss: 15739.70
[INFO 2017-06-29 11:29:44,541 main.py:57] epoch 31, training loss: 10096.32, average training loss: 14863.73, base loss: 15711.68
[INFO 2017-06-29 11:29:47,773 main.py:57] epoch 32, training loss: 10569.14, average training loss: 14733.59, base loss: 15704.60
[INFO 2017-06-29 11:29:51,003 main.py:57] epoch 33, training loss: 11653.29, average training loss: 14642.99, base loss: 15737.15
[INFO 2017-06-29 11:29:54,123 main.py:57] epoch 34, training loss: 10264.40, average training loss: 14517.89, base loss: 15733.23
[INFO 2017-06-29 11:29:57,388 main.py:57] epoch 35, training loss: 10366.36, average training loss: 14402.57, base loss: 15718.34
[INFO 2017-06-29 11:30:00,662 main.py:57] epoch 36, training loss: 10986.87, average training loss: 14310.25, base loss: 15725.43
[INFO 2017-06-29 11:30:03,898 main.py:57] epoch 37, training loss: 9823.13, average training loss: 14192.17, base loss: 15694.86
[INFO 2017-06-29 11:30:07,048 main.py:57] epoch 38, training loss: 11394.10, average training loss: 14120.43, base loss: 15712.21
[INFO 2017-06-29 11:30:10,397 main.py:57] epoch 39, training loss: 11362.02, average training loss: 14051.47, base loss: 15726.13
[INFO 2017-06-29 11:30:13,730 main.py:57] epoch 40, training loss: 9494.68, average training loss: 13940.33, base loss: 15690.19
[INFO 2017-06-29 11:30:16,908 main.py:57] epoch 41, training loss: 10365.45, average training loss: 13855.21, base loss: 15679.15
[INFO 2017-06-29 11:30:20,212 main.py:57] epoch 42, training loss: 10393.20, average training loss: 13774.70, base loss: 15686.30
[INFO 2017-06-29 11:30:23,635 main.py:57] epoch 43, training loss: 9936.55, average training loss: 13687.47, base loss: 15664.07
[INFO 2017-06-29 11:30:26,977 main.py:57] epoch 44, training loss: 10523.55, average training loss: 13617.16, base loss: 15667.22
[INFO 2017-06-29 11:30:30,321 main.py:57] epoch 45, training loss: 10211.68, average training loss: 13543.13, base loss: 15661.39
[INFO 2017-06-29 11:30:33,848 main.py:57] epoch 46, training loss: 10778.15, average training loss: 13484.30, base loss: 15672.08
[INFO 2017-06-29 11:30:37,064 main.py:57] epoch 47, training loss: 9548.17, average training loss: 13402.29, base loss: 15642.44
[INFO 2017-06-29 11:30:40,198 main.py:57] epoch 48, training loss: 11158.08, average training loss: 13356.49, base loss: 15658.42
[INFO 2017-06-29 11:30:43,589 main.py:57] epoch 49, training loss: 9727.21, average training loss: 13283.91, base loss: 15638.61
[INFO 2017-06-29 11:30:46,775 main.py:57] epoch 50, training loss: 9057.33, average training loss: 13201.03, base loss: 15612.25
[INFO 2017-06-29 11:30:50,087 main.py:57] epoch 51, training loss: 10600.70, average training loss: 13151.03, base loss: 15613.51
[INFO 2017-06-29 11:30:53,277 main.py:57] epoch 52, training loss: 11752.49, average training loss: 13124.64, base loss: 15653.08
[INFO 2017-06-29 11:30:56,574 main.py:57] epoch 53, training loss: 11951.38, average training loss: 13102.91, base loss: 15681.06
[INFO 2017-06-29 11:30:59,838 main.py:57] epoch 54, training loss: 10618.83, average training loss: 13057.75, base loss: 15684.25
[INFO 2017-06-29 11:31:03,045 main.py:57] epoch 55, training loss: 10546.47, average training loss: 13012.90, base loss: 15691.94
[INFO 2017-06-29 11:31:06,236 main.py:57] epoch 56, training loss: 11519.98, average training loss: 12986.71, base loss: 15722.36
[INFO 2017-06-29 11:31:09,671 main.py:57] epoch 57, training loss: 9118.41, average training loss: 12920.02, base loss: 15704.08
[INFO 2017-06-29 11:31:12,900 main.py:57] epoch 58, training loss: 11725.22, average training loss: 12899.77, base loss: 15733.05
[INFO 2017-06-29 11:31:16,156 main.py:57] epoch 59, training loss: 9853.99, average training loss: 12849.00, base loss: 15726.17
[INFO 2017-06-29 11:31:19,512 main.py:57] epoch 60, training loss: 10983.80, average training loss: 12818.43, base loss: 15733.43
[INFO 2017-06-29 11:31:22,751 main.py:57] epoch 61, training loss: 12166.13, average training loss: 12807.91, base loss: 15768.57
[INFO 2017-06-29 11:31:25,984 main.py:57] epoch 62, training loss: 9811.95, average training loss: 12760.35, base loss: 15761.27
[INFO 2017-06-29 11:31:29,199 main.py:57] epoch 63, training loss: 10455.76, average training loss: 12724.34, base loss: 15772.70
[INFO 2017-06-29 11:31:32,514 main.py:57] epoch 64, training loss: 9934.65, average training loss: 12681.42, base loss: 15768.50
[INFO 2017-06-29 11:31:35,712 main.py:57] epoch 65, training loss: 9119.08, average training loss: 12627.45, base loss: 15749.07
[INFO 2017-06-29 11:31:39,025 main.py:57] epoch 66, training loss: 10183.02, average training loss: 12590.96, base loss: 15754.45
[INFO 2017-06-29 11:31:42,561 main.py:57] epoch 67, training loss: 10541.81, average training loss: 12560.83, base loss: 15772.02
[INFO 2017-06-29 11:31:46,122 main.py:57] epoch 68, training loss: 10687.04, average training loss: 12533.67, base loss: 15780.67
[INFO 2017-06-29 11:31:49,414 main.py:57] epoch 69, training loss: 10914.59, average training loss: 12510.54, base loss: 15797.91
[INFO 2017-06-29 11:31:52,651 main.py:57] epoch 70, training loss: 8657.71, average training loss: 12456.28, base loss: 15773.43
[INFO 2017-06-29 11:31:55,934 main.py:57] epoch 71, training loss: 9473.82, average training loss: 12414.85, base loss: 15763.47
[INFO 2017-06-29 11:31:59,217 main.py:57] epoch 72, training loss: 10249.39, average training loss: 12385.19, base loss: 15763.72
[INFO 2017-06-29 11:32:02,564 main.py:57] epoch 73, training loss: 11182.78, average training loss: 12368.94, base loss: 15786.60
[INFO 2017-06-29 11:32:05,874 main.py:57] epoch 74, training loss: 8976.25, average training loss: 12323.71, base loss: 15773.06
[INFO 2017-06-29 11:32:09,055 main.py:57] epoch 75, training loss: 8874.85, average training loss: 12278.33, base loss: 15758.77
[INFO 2017-06-29 11:32:12,257 main.py:57] epoch 76, training loss: 8819.35, average training loss: 12233.40, base loss: 15741.93
[INFO 2017-06-29 11:32:15,511 main.py:57] epoch 77, training loss: 10790.74, average training loss: 12214.91, base loss: 15760.83
[INFO 2017-06-29 11:32:18,787 main.py:57] epoch 78, training loss: 8563.10, average training loss: 12168.68, base loss: 15751.99
[INFO 2017-06-29 11:32:22,029 main.py:57] epoch 79, training loss: 9384.94, average training loss: 12133.89, base loss: 15754.53
[INFO 2017-06-29 11:32:25,364 main.py:57] epoch 80, training loss: 9412.19, average training loss: 12100.29, base loss: 15743.76
[INFO 2017-06-29 11:32:28,739 main.py:57] epoch 81, training loss: 9474.85, average training loss: 12068.27, base loss: 15743.92
[INFO 2017-06-29 11:32:31,983 main.py:57] epoch 82, training loss: 10196.98, average training loss: 12045.72, base loss: 15755.20
[INFO 2017-06-29 11:32:35,210 main.py:57] epoch 83, training loss: 10178.82, average training loss: 12023.50, base loss: 15770.72
[INFO 2017-06-29 11:32:38,564 main.py:57] epoch 84, training loss: 9073.66, average training loss: 11988.79, base loss: 15757.72
[INFO 2017-06-29 11:32:41,798 main.py:57] epoch 85, training loss: 9110.48, average training loss: 11955.32, base loss: 15750.92
[INFO 2017-06-29 11:32:45,276 main.py:57] epoch 86, training loss: 10724.19, average training loss: 11941.17, base loss: 15769.07
[INFO 2017-06-29 11:32:48,669 main.py:57] epoch 87, training loss: 8995.34, average training loss: 11907.70, base loss: 15764.44
[INFO 2017-06-29 11:32:51,928 main.py:57] epoch 88, training loss: 10139.44, average training loss: 11887.83, base loss: 15778.60
[INFO 2017-06-29 11:32:55,203 main.py:57] epoch 89, training loss: 9035.32, average training loss: 11856.14, base loss: 15776.44
[INFO 2017-06-29 11:32:58,455 main.py:57] epoch 90, training loss: 9383.49, average training loss: 11828.96, base loss: 15786.27
[INFO 2017-06-29 11:33:01,740 main.py:57] epoch 91, training loss: 8381.68, average training loss: 11791.49, base loss: 15782.06
[INFO 2017-06-29 11:33:04,880 main.py:57] epoch 92, training loss: 8846.26, average training loss: 11759.82, base loss: 15780.56
[INFO 2017-06-29 11:33:08,116 main.py:57] epoch 93, training loss: 9239.92, average training loss: 11733.02, base loss: 15787.97
[INFO 2017-06-29 11:33:11,376 main.py:57] epoch 94, training loss: 9264.02, average training loss: 11707.03, base loss: 15776.57
[INFO 2017-06-29 11:33:14,593 main.py:57] epoch 95, training loss: 8855.27, average training loss: 11677.32, base loss: 15770.32
[INFO 2017-06-29 11:33:17,830 main.py:57] epoch 96, training loss: 8621.29, average training loss: 11645.82, base loss: 15758.36
[INFO 2017-06-29 11:33:21,247 main.py:57] epoch 97, training loss: 8827.97, average training loss: 11617.06, base loss: 15754.73
[INFO 2017-06-29 11:33:24,628 main.py:57] epoch 98, training loss: 9433.79, average training loss: 11595.01, base loss: 15763.72
[INFO 2017-06-29 11:33:27,921 main.py:57] epoch 99, training loss: 8271.07, average training loss: 11561.77, base loss: 15749.51
[INFO 2017-06-29 11:33:27,921 main.py:59] epoch 99, testing
[INFO 2017-06-29 11:33:41,759 main.py:104] average testing loss: 9770.50, base loss: 16109.96
[INFO 2017-06-29 11:33:41,759 main.py:105] improve_loss: 6339.46, improve_percent: 0.39
[INFO 2017-06-29 11:33:41,760 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 11:33:41,797 main.py:71] current best improved percent: 0.39
[INFO 2017-06-29 11:33:45,024 main.py:57] epoch 100, training loss: 8920.46, average training loss: 11535.62, base loss: 15734.09
[INFO 2017-06-29 11:33:48,272 main.py:57] epoch 101, training loss: 8701.66, average training loss: 11507.83, base loss: 15731.20
[INFO 2017-06-29 11:33:51,530 main.py:57] epoch 102, training loss: 9149.10, average training loss: 11484.93, base loss: 15735.80
[INFO 2017-06-29 11:33:54,718 main.py:57] epoch 103, training loss: 9350.57, average training loss: 11464.41, base loss: 15743.09
[INFO 2017-06-29 11:33:58,008 main.py:57] epoch 104, training loss: 8982.20, average training loss: 11440.77, base loss: 15735.41
[INFO 2017-06-29 11:34:01,282 main.py:57] epoch 105, training loss: 9965.05, average training loss: 11426.85, base loss: 15741.85
[INFO 2017-06-29 11:34:04,545 main.py:57] epoch 106, training loss: 9830.91, average training loss: 11411.93, base loss: 15748.98
[INFO 2017-06-29 11:34:07,875 main.py:57] epoch 107, training loss: 8768.75, average training loss: 11387.46, base loss: 15742.65
[INFO 2017-06-29 11:34:11,238 main.py:57] epoch 108, training loss: 7735.47, average training loss: 11353.96, base loss: 15727.17
[INFO 2017-06-29 11:34:14,704 main.py:57] epoch 109, training loss: 10972.54, average training loss: 11350.49, base loss: 15753.32
[INFO 2017-06-29 11:34:18,077 main.py:57] epoch 110, training loss: 8571.25, average training loss: 11325.45, base loss: 15749.67
[INFO 2017-06-29 11:34:21,750 main.py:57] epoch 111, training loss: 7784.00, average training loss: 11293.83, base loss: 15726.46
[INFO 2017-06-29 11:34:25,014 main.py:57] epoch 112, training loss: 9200.84, average training loss: 11275.31, base loss: 15733.60
[INFO 2017-06-29 11:34:28,308 main.py:57] epoch 113, training loss: 8352.20, average training loss: 11249.67, base loss: 15724.32
[INFO 2017-06-29 11:34:31,580 main.py:57] epoch 114, training loss: 9614.41, average training loss: 11235.45, base loss: 15733.24
[INFO 2017-06-29 11:34:34,786 main.py:57] epoch 115, training loss: 7978.15, average training loss: 11207.37, base loss: 15721.15
[INFO 2017-06-29 11:34:38,091 main.py:57] epoch 116, training loss: 7984.22, average training loss: 11179.82, base loss: 15714.53
[INFO 2017-06-29 11:34:41,843 main.py:57] epoch 117, training loss: 8295.26, average training loss: 11155.37, base loss: 15710.25
[INFO 2017-06-29 11:34:45,345 main.py:57] epoch 118, training loss: 8694.86, average training loss: 11134.70, base loss: 15714.12
[INFO 2017-06-29 11:34:48,696 main.py:57] epoch 119, training loss: 9083.52, average training loss: 11117.60, base loss: 15715.32
[INFO 2017-06-29 11:34:51,927 main.py:57] epoch 120, training loss: 8564.96, average training loss: 11096.51, base loss: 15708.64
[INFO 2017-06-29 11:34:55,532 main.py:57] epoch 121, training loss: 8966.43, average training loss: 11079.05, base loss: 15715.39
[INFO 2017-06-29 11:34:58,823 main.py:57] epoch 122, training loss: 9231.19, average training loss: 11064.02, base loss: 15713.86
[INFO 2017-06-29 11:35:02,308 main.py:57] epoch 123, training loss: 9003.11, average training loss: 11047.40, base loss: 15707.48
[INFO 2017-06-29 11:35:05,615 main.py:57] epoch 124, training loss: 8594.49, average training loss: 11027.78, base loss: 15707.72
[INFO 2017-06-29 11:35:08,916 main.py:57] epoch 125, training loss: 9491.31, average training loss: 11015.59, base loss: 15712.97
[INFO 2017-06-29 11:35:12,214 main.py:57] epoch 126, training loss: 8899.88, average training loss: 10998.93, base loss: 15718.89
[INFO 2017-06-29 11:35:15,593 main.py:57] epoch 127, training loss: 9869.58, average training loss: 10990.10, base loss: 15728.73
[INFO 2017-06-29 11:35:18,994 main.py:57] epoch 128, training loss: 7851.64, average training loss: 10965.78, base loss: 15715.54
[INFO 2017-06-29 11:35:22,441 main.py:57] epoch 129, training loss: 9272.29, average training loss: 10952.75, base loss: 15716.43
[INFO 2017-06-29 11:35:25,695 main.py:57] epoch 130, training loss: 8939.35, average training loss: 10937.38, base loss: 15722.91
[INFO 2017-06-29 11:35:28,875 main.py:57] epoch 131, training loss: 9233.01, average training loss: 10924.47, base loss: 15726.23
[INFO 2017-06-29 11:35:32,272 main.py:57] epoch 132, training loss: 7989.87, average training loss: 10902.40, base loss: 15718.82
[INFO 2017-06-29 11:35:35,589 main.py:57] epoch 133, training loss: 8288.29, average training loss: 10882.89, base loss: 15713.25
[INFO 2017-06-29 11:35:38,828 main.py:57] epoch 134, training loss: 9594.77, average training loss: 10873.35, base loss: 15723.36
[INFO 2017-06-29 11:35:42,189 main.py:57] epoch 135, training loss: 8880.17, average training loss: 10858.70, base loss: 15721.05
[INFO 2017-06-29 11:35:45,571 main.py:57] epoch 136, training loss: 8304.26, average training loss: 10840.05, base loss: 15717.29
[INFO 2017-06-29 11:35:48,959 main.py:57] epoch 137, training loss: 9179.54, average training loss: 10828.02, base loss: 15715.05
[INFO 2017-06-29 11:35:52,229 main.py:57] epoch 138, training loss: 9109.90, average training loss: 10815.66, base loss: 15716.88
[INFO 2017-06-29 11:35:55,676 main.py:57] epoch 139, training loss: 8767.83, average training loss: 10801.03, base loss: 15720.69
[INFO 2017-06-29 11:35:59,266 main.py:57] epoch 140, training loss: 7913.09, average training loss: 10780.55, base loss: 15713.57
[INFO 2017-06-29 11:36:02,530 main.py:57] epoch 141, training loss: 8299.32, average training loss: 10763.08, base loss: 15712.55
[INFO 2017-06-29 11:36:05,685 main.py:57] epoch 142, training loss: 7904.52, average training loss: 10743.09, base loss: 15703.42
[INFO 2017-06-29 11:36:09,171 main.py:57] epoch 143, training loss: 7880.71, average training loss: 10723.21, base loss: 15704.32
[INFO 2017-06-29 11:36:12,293 main.py:57] epoch 144, training loss: 9671.52, average training loss: 10715.95, base loss: 15713.84
[INFO 2017-06-29 11:36:15,503 main.py:57] epoch 145, training loss: 8342.06, average training loss: 10699.70, base loss: 15709.79
[INFO 2017-06-29 11:36:18,863 main.py:57] epoch 146, training loss: 8347.96, average training loss: 10683.70, base loss: 15710.02
[INFO 2017-06-29 11:36:22,228 main.py:57] epoch 147, training loss: 9271.03, average training loss: 10674.15, base loss: 15720.01
[INFO 2017-06-29 11:36:25,490 main.py:57] epoch 148, training loss: 8895.05, average training loss: 10662.21, base loss: 15724.11
[INFO 2017-06-29 11:36:28,793 main.py:57] epoch 149, training loss: 8188.16, average training loss: 10645.72, base loss: 15715.37
[INFO 2017-06-29 11:36:32,171 main.py:57] epoch 150, training loss: 9488.73, average training loss: 10638.06, base loss: 15728.09
[INFO 2017-06-29 11:36:35,337 main.py:57] epoch 151, training loss: 8056.06, average training loss: 10621.07, base loss: 15730.23
[INFO 2017-06-29 11:36:38,599 main.py:57] epoch 152, training loss: 8569.78, average training loss: 10607.66, base loss: 15733.40
[INFO 2017-06-29 11:36:41,799 main.py:57] epoch 153, training loss: 8683.22, average training loss: 10595.17, base loss: 15738.87
[INFO 2017-06-29 11:36:45,084 main.py:57] epoch 154, training loss: 8484.61, average training loss: 10581.55, base loss: 15726.15
[INFO 2017-06-29 11:36:48,392 main.py:57] epoch 155, training loss: 9264.07, average training loss: 10573.10, base loss: 15727.11
[INFO 2017-06-29 11:36:51,637 main.py:57] epoch 156, training loss: 8588.72, average training loss: 10560.46, base loss: 15727.65
[INFO 2017-06-29 11:36:55,108 main.py:57] epoch 157, training loss: 8774.34, average training loss: 10549.16, base loss: 15729.74
[INFO 2017-06-29 11:36:58,371 main.py:57] epoch 158, training loss: 9558.47, average training loss: 10542.93, base loss: 15729.68
[INFO 2017-06-29 11:37:01,596 main.py:57] epoch 159, training loss: 8741.25, average training loss: 10531.67, base loss: 15725.48
[INFO 2017-06-29 11:37:04,770 main.py:57] epoch 160, training loss: 8070.72, average training loss: 10516.38, base loss: 15714.88
[INFO 2017-06-29 11:37:07,992 main.py:57] epoch 161, training loss: 9023.84, average training loss: 10507.17, base loss: 15713.88
[INFO 2017-06-29 11:37:11,177 main.py:57] epoch 162, training loss: 8149.33, average training loss: 10492.70, base loss: 15705.61
[INFO 2017-06-29 11:37:14,590 main.py:57] epoch 163, training loss: 8357.43, average training loss: 10479.68, base loss: 15707.00
[INFO 2017-06-29 11:37:17,926 main.py:57] epoch 164, training loss: 7709.87, average training loss: 10462.90, base loss: 15699.50
[INFO 2017-06-29 11:37:21,284 main.py:57] epoch 165, training loss: 8717.61, average training loss: 10452.38, base loss: 15693.83
[INFO 2017-06-29 11:37:24,546 main.py:57] epoch 166, training loss: 7998.17, average training loss: 10437.69, base loss: 15685.68
[INFO 2017-06-29 11:37:27,933 main.py:57] epoch 167, training loss: 7620.29, average training loss: 10420.92, base loss: 15671.13
[INFO 2017-06-29 11:37:31,215 main.py:57] epoch 168, training loss: 7780.06, average training loss: 10405.29, base loss: 15664.81
[INFO 2017-06-29 11:37:34,521 main.py:57] epoch 169, training loss: 8521.85, average training loss: 10394.21, base loss: 15664.43
[INFO 2017-06-29 11:37:37,765 main.py:57] epoch 170, training loss: 8852.29, average training loss: 10385.20, base loss: 15670.17
[INFO 2017-06-29 11:37:41,061 main.py:57] epoch 171, training loss: 9323.04, average training loss: 10379.02, base loss: 15674.87
[INFO 2017-06-29 11:37:44,235 main.py:57] epoch 172, training loss: 8744.87, average training loss: 10369.57, base loss: 15674.56
[INFO 2017-06-29 11:37:47,659 main.py:57] epoch 173, training loss: 9289.71, average training loss: 10363.37, base loss: 15689.13
[INFO 2017-06-29 11:37:50,866 main.py:57] epoch 174, training loss: 8204.06, average training loss: 10351.03, base loss: 15676.85
[INFO 2017-06-29 11:37:54,175 main.py:57] epoch 175, training loss: 8511.81, average training loss: 10340.58, base loss: 15678.88
[INFO 2017-06-29 11:37:57,326 main.py:57] epoch 176, training loss: 9352.69, average training loss: 10335.00, base loss: 15686.23
[INFO 2017-06-29 11:38:00,712 main.py:57] epoch 177, training loss: 8993.91, average training loss: 10327.46, base loss: 15687.35
[INFO 2017-06-29 11:38:03,917 main.py:57] epoch 178, training loss: 7812.83, average training loss: 10313.42, base loss: 15686.26
[INFO 2017-06-29 11:38:07,280 main.py:57] epoch 179, training loss: 8361.71, average training loss: 10302.57, base loss: 15684.74
[INFO 2017-06-29 11:38:10,645 main.py:57] epoch 180, training loss: 9413.26, average training loss: 10297.66, base loss: 15699.79
[INFO 2017-06-29 11:38:13,923 main.py:57] epoch 181, training loss: 8150.60, average training loss: 10285.86, base loss: 15696.63
[INFO 2017-06-29 11:38:17,262 main.py:57] epoch 182, training loss: 9061.93, average training loss: 10279.17, base loss: 15696.55
[INFO 2017-06-29 11:38:20,541 main.py:57] epoch 183, training loss: 8078.56, average training loss: 10267.21, base loss: 15689.36
[INFO 2017-06-29 11:38:23,787 main.py:57] epoch 184, training loss: 8148.92, average training loss: 10255.76, base loss: 15689.56
[INFO 2017-06-29 11:38:27,136 main.py:57] epoch 185, training loss: 8462.69, average training loss: 10246.12, base loss: 15691.77
[INFO 2017-06-29 11:38:30,476 main.py:57] epoch 186, training loss: 8143.06, average training loss: 10234.88, base loss: 15687.17
[INFO 2017-06-29 11:38:33,723 main.py:57] epoch 187, training loss: 9425.58, average training loss: 10230.57, base loss: 15699.02
[INFO 2017-06-29 11:38:37,036 main.py:57] epoch 188, training loss: 9058.17, average training loss: 10224.37, base loss: 15703.36
[INFO 2017-06-29 11:38:40,311 main.py:57] epoch 189, training loss: 8661.62, average training loss: 10216.14, base loss: 15700.14
[INFO 2017-06-29 11:38:43,677 main.py:57] epoch 190, training loss: 8110.40, average training loss: 10205.12, base loss: 15697.13
[INFO 2017-06-29 11:38:46,951 main.py:57] epoch 191, training loss: 8688.24, average training loss: 10197.22, base loss: 15699.54
[INFO 2017-06-29 11:38:50,284 main.py:57] epoch 192, training loss: 7602.41, average training loss: 10183.77, base loss: 15692.59
[INFO 2017-06-29 11:38:53,962 main.py:57] epoch 193, training loss: 7293.36, average training loss: 10168.88, base loss: 15681.12
[INFO 2017-06-29 11:38:57,253 main.py:57] epoch 194, training loss: 8426.72, average training loss: 10159.94, base loss: 15679.63
[INFO 2017-06-29 11:39:00,558 main.py:57] epoch 195, training loss: 9536.89, average training loss: 10156.76, base loss: 15685.40
[INFO 2017-06-29 11:39:03,679 main.py:57] epoch 196, training loss: 8816.20, average training loss: 10149.96, base loss: 15688.95
[INFO 2017-06-29 11:39:07,060 main.py:57] epoch 197, training loss: 7388.48, average training loss: 10136.01, base loss: 15681.87
[INFO 2017-06-29 11:39:10,372 main.py:57] epoch 198, training loss: 8353.93, average training loss: 10127.06, base loss: 15676.95
[INFO 2017-06-29 11:39:13,713 main.py:57] epoch 199, training loss: 7456.81, average training loss: 10113.70, base loss: 15669.89
[INFO 2017-06-29 11:39:13,714 main.py:59] epoch 199, testing
[INFO 2017-06-29 11:39:27,416 main.py:104] average testing loss: 9376.37, base loss: 16787.82
[INFO 2017-06-29 11:39:27,416 main.py:105] improve_loss: 7411.45, improve_percent: 0.44
[INFO 2017-06-29 11:39:27,417 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 11:39:27,457 main.py:71] current best improved percent: 0.44
[INFO 2017-06-29 11:39:30,785 main.py:57] epoch 200, training loss: 6838.69, average training loss: 10097.41, base loss: 15662.49
[INFO 2017-06-29 11:39:34,161 main.py:57] epoch 201, training loss: 10633.69, average training loss: 10100.07, base loss: 15673.88
[INFO 2017-06-29 11:39:37,400 main.py:57] epoch 202, training loss: 7329.16, average training loss: 10086.42, base loss: 15669.12
[INFO 2017-06-29 11:39:40,610 main.py:57] epoch 203, training loss: 8380.56, average training loss: 10078.05, base loss: 15665.85
[INFO 2017-06-29 11:39:43,852 main.py:57] epoch 204, training loss: 8060.59, average training loss: 10068.21, base loss: 15668.50
[INFO 2017-06-29 11:39:47,143 main.py:57] epoch 205, training loss: 9411.55, average training loss: 10065.02, base loss: 15674.76
[INFO 2017-06-29 11:39:50,409 main.py:57] epoch 206, training loss: 8112.11, average training loss: 10055.59, base loss: 15670.00
[INFO 2017-06-29 11:39:53,635 main.py:57] epoch 207, training loss: 7580.50, average training loss: 10043.69, base loss: 15661.78
[INFO 2017-06-29 11:39:56,894 main.py:57] epoch 208, training loss: 7127.83, average training loss: 10029.74, base loss: 15650.42
[INFO 2017-06-29 11:40:00,142 main.py:57] epoch 209, training loss: 8804.33, average training loss: 10023.90, base loss: 15654.93
[INFO 2017-06-29 11:40:03,458 main.py:57] epoch 210, training loss: 8031.45, average training loss: 10014.46, base loss: 15653.58
[INFO 2017-06-29 11:40:06,658 main.py:57] epoch 211, training loss: 8634.27, average training loss: 10007.95, base loss: 15660.96
[INFO 2017-06-29 11:40:09,941 main.py:57] epoch 212, training loss: 9314.34, average training loss: 10004.69, base loss: 15672.31
[INFO 2017-06-29 11:40:13,182 main.py:57] epoch 213, training loss: 8207.99, average training loss: 9996.30, base loss: 15671.54
[INFO 2017-06-29 11:40:16,474 main.py:57] epoch 214, training loss: 8808.10, average training loss: 9990.77, base loss: 15686.33
[INFO 2017-06-29 11:40:19,797 main.py:57] epoch 215, training loss: 8164.74, average training loss: 9982.32, base loss: 15682.51
[INFO 2017-06-29 11:40:23,010 main.py:57] epoch 216, training loss: 8508.43, average training loss: 9975.53, base loss: 15680.69
[INFO 2017-06-29 11:40:26,299 main.py:57] epoch 217, training loss: 8847.85, average training loss: 9970.35, base loss: 15680.76
[INFO 2017-06-29 11:40:29,646 main.py:57] epoch 218, training loss: 7329.86, average training loss: 9958.30, base loss: 15673.18
[INFO 2017-06-29 11:40:33,035 main.py:57] epoch 219, training loss: 10428.76, average training loss: 9960.43, base loss: 15685.30
[INFO 2017-06-29 11:40:36,372 main.py:57] epoch 220, training loss: 8489.23, average training loss: 9953.78, base loss: 15682.90
[INFO 2017-06-29 11:40:39,716 main.py:57] epoch 221, training loss: 6920.75, average training loss: 9940.12, base loss: 15673.35
[INFO 2017-06-29 11:40:43,052 main.py:57] epoch 222, training loss: 9028.06, average training loss: 9936.03, base loss: 15678.17
[INFO 2017-06-29 11:40:46,490 main.py:57] epoch 223, training loss: 8226.83, average training loss: 9928.40, base loss: 15679.12
[INFO 2017-06-29 11:40:49,742 main.py:57] epoch 224, training loss: 8594.70, average training loss: 9922.47, base loss: 15681.29
[INFO 2017-06-29 11:40:53,116 main.py:57] epoch 225, training loss: 7824.30, average training loss: 9913.18, base loss: 15682.87
[INFO 2017-06-29 11:40:56,488 main.py:57] epoch 226, training loss: 8711.76, average training loss: 9907.89, base loss: 15681.60
[INFO 2017-06-29 11:40:59,758 main.py:57] epoch 227, training loss: 8062.30, average training loss: 9899.80, base loss: 15677.95
[INFO 2017-06-29 11:41:03,141 main.py:57] epoch 228, training loss: 8391.75, average training loss: 9893.21, base loss: 15681.69
[INFO 2017-06-29 11:41:06,602 main.py:57] epoch 229, training loss: 8732.97, average training loss: 9888.17, base loss: 15681.27
[INFO 2017-06-29 11:41:09,996 main.py:57] epoch 230, training loss: 8618.48, average training loss: 9882.67, base loss: 15682.45
[INFO 2017-06-29 11:41:13,320 main.py:57] epoch 231, training loss: 9320.33, average training loss: 9880.25, base loss: 15689.51
[INFO 2017-06-29 11:41:16,476 main.py:57] epoch 232, training loss: 7547.84, average training loss: 9870.24, base loss: 15687.88
[INFO 2017-06-29 11:41:19,803 main.py:57] epoch 233, training loss: 7801.37, average training loss: 9861.39, base loss: 15684.72
[INFO 2017-06-29 11:41:23,140 main.py:57] epoch 234, training loss: 8682.40, average training loss: 9856.38, base loss: 15686.24
[INFO 2017-06-29 11:41:26,371 main.py:57] epoch 235, training loss: 8105.86, average training loss: 9848.96, base loss: 15681.62
[INFO 2017-06-29 11:41:29,657 main.py:57] epoch 236, training loss: 7668.23, average training loss: 9839.76, base loss: 15679.71
[INFO 2017-06-29 11:41:32,877 main.py:57] epoch 237, training loss: 8011.02, average training loss: 9832.07, base loss: 15681.11
[INFO 2017-06-29 11:41:36,289 main.py:57] epoch 238, training loss: 8059.34, average training loss: 9824.66, base loss: 15680.66
[INFO 2017-06-29 11:41:39,387 main.py:57] epoch 239, training loss: 7592.13, average training loss: 9815.36, base loss: 15678.01
[INFO 2017-06-29 11:41:42,673 main.py:57] epoch 240, training loss: 7554.28, average training loss: 9805.97, base loss: 15675.09
[INFO 2017-06-29 11:41:45,961 main.py:57] epoch 241, training loss: 8681.22, average training loss: 9801.33, base loss: 15676.60
[INFO 2017-06-29 11:41:49,305 main.py:57] epoch 242, training loss: 8633.27, average training loss: 9796.52, base loss: 15675.97
[INFO 2017-06-29 11:41:52,521 main.py:57] epoch 243, training loss: 6977.60, average training loss: 9784.97, base loss: 15664.86
[INFO 2017-06-29 11:41:55,770 main.py:57] epoch 244, training loss: 8799.85, average training loss: 9780.94, base loss: 15669.92
[INFO 2017-06-29 11:41:58,961 main.py:57] epoch 245, training loss: 7000.70, average training loss: 9769.64, base loss: 15664.34
[INFO 2017-06-29 11:42:02,112 main.py:57] epoch 246, training loss: 8226.96, average training loss: 9763.40, base loss: 15663.76
[INFO 2017-06-29 11:42:05,283 main.py:57] epoch 247, training loss: 8703.50, average training loss: 9759.12, base loss: 15668.09
[INFO 2017-06-29 11:42:08,572 main.py:57] epoch 248, training loss: 8619.28, average training loss: 9754.55, base loss: 15673.67
[INFO 2017-06-29 11:42:11,820 main.py:57] epoch 249, training loss: 8600.04, average training loss: 9749.93, base loss: 15676.44
[INFO 2017-06-29 11:42:15,170 main.py:57] epoch 250, training loss: 9582.55, average training loss: 9749.26, base loss: 15679.96
[INFO 2017-06-29 11:42:18,468 main.py:57] epoch 251, training loss: 7990.35, average training loss: 9742.28, base loss: 15674.44
[INFO 2017-06-29 11:42:21,814 main.py:57] epoch 252, training loss: 7985.21, average training loss: 9735.34, base loss: 15675.73
[INFO 2017-06-29 11:42:25,007 main.py:57] epoch 253, training loss: 7491.29, average training loss: 9726.50, base loss: 15674.77
[INFO 2017-06-29 11:42:28,229 main.py:57] epoch 254, training loss: 7637.78, average training loss: 9718.31, base loss: 15670.42
[INFO 2017-06-29 11:42:31,635 main.py:57] epoch 255, training loss: 8177.19, average training loss: 9712.29, base loss: 15671.58
[INFO 2017-06-29 11:42:34,938 main.py:57] epoch 256, training loss: 8456.20, average training loss: 9707.40, base loss: 15671.16
[INFO 2017-06-29 11:42:38,195 main.py:57] epoch 257, training loss: 8152.17, average training loss: 9701.37, base loss: 15669.78
[INFO 2017-06-29 11:42:41,494 main.py:57] epoch 258, training loss: 7369.72, average training loss: 9692.37, base loss: 15662.22
[INFO 2017-06-29 11:42:44,698 main.py:57] epoch 259, training loss: 7115.74, average training loss: 9682.46, base loss: 15654.44
[INFO 2017-06-29 11:42:47,866 main.py:57] epoch 260, training loss: 7786.06, average training loss: 9675.20, base loss: 15652.63
[INFO 2017-06-29 11:42:51,343 main.py:57] epoch 261, training loss: 8253.54, average training loss: 9669.77, base loss: 15652.37
[INFO 2017-06-29 11:42:54,723 main.py:57] epoch 262, training loss: 7659.15, average training loss: 9662.13, base loss: 15648.69
[INFO 2017-06-29 11:42:57,987 main.py:57] epoch 263, training loss: 7984.62, average training loss: 9655.77, base loss: 15648.48
[INFO 2017-06-29 11:43:01,196 main.py:57] epoch 264, training loss: 9152.78, average training loss: 9653.87, base loss: 15654.96
[INFO 2017-06-29 11:43:04,443 main.py:57] epoch 265, training loss: 8459.26, average training loss: 9649.38, base loss: 15657.58
[INFO 2017-06-29 11:43:07,614 main.py:57] epoch 266, training loss: 8341.29, average training loss: 9644.48, base loss: 15658.79
[INFO 2017-06-29 11:43:11,027 main.py:57] epoch 267, training loss: 8039.35, average training loss: 9638.49, base loss: 15654.06
[INFO 2017-06-29 11:43:14,337 main.py:57] epoch 268, training loss: 8356.62, average training loss: 9633.73, base loss: 15656.09
[INFO 2017-06-29 11:43:17,709 main.py:57] epoch 269, training loss: 8026.61, average training loss: 9627.78, base loss: 15657.33
[INFO 2017-06-29 11:43:20,988 main.py:57] epoch 270, training loss: 8045.44, average training loss: 9621.94, base loss: 15656.90
[INFO 2017-06-29 11:43:24,326 main.py:57] epoch 271, training loss: 8808.24, average training loss: 9618.95, base loss: 15662.30
[INFO 2017-06-29 11:43:27,634 main.py:57] epoch 272, training loss: 9048.54, average training loss: 9616.86, base loss: 15666.56
[INFO 2017-06-29 11:43:30,946 main.py:57] epoch 273, training loss: 7959.30, average training loss: 9610.81, base loss: 15665.88
[INFO 2017-06-29 11:43:34,193 main.py:57] epoch 274, training loss: 7866.73, average training loss: 9604.46, base loss: 15664.63
[INFO 2017-06-29 11:43:37,489 main.py:57] epoch 275, training loss: 7630.69, average training loss: 9597.31, base loss: 15662.11
[INFO 2017-06-29 11:43:40,731 main.py:57] epoch 276, training loss: 7782.07, average training loss: 9590.76, base loss: 15661.65
[INFO 2017-06-29 11:43:44,010 main.py:57] epoch 277, training loss: 8588.19, average training loss: 9587.15, base loss: 15662.89
[INFO 2017-06-29 11:43:47,339 main.py:57] epoch 278, training loss: 8069.19, average training loss: 9581.71, base loss: 15656.94
[INFO 2017-06-29 11:43:50,689 main.py:57] epoch 279, training loss: 8956.89, average training loss: 9579.48, base loss: 15661.90
[INFO 2017-06-29 11:43:54,062 main.py:57] epoch 280, training loss: 7338.05, average training loss: 9571.50, base loss: 15658.29
[INFO 2017-06-29 11:43:57,424 main.py:57] epoch 281, training loss: 8484.43, average training loss: 9567.65, base loss: 15661.74
[INFO 2017-06-29 11:44:00,577 main.py:57] epoch 282, training loss: 8808.30, average training loss: 9564.97, base loss: 15664.29
[INFO 2017-06-29 11:44:03,911 main.py:57] epoch 283, training loss: 7185.59, average training loss: 9556.59, base loss: 15657.05
[INFO 2017-06-29 11:44:07,167 main.py:57] epoch 284, training loss: 7355.92, average training loss: 9548.87, base loss: 15647.18
[INFO 2017-06-29 11:44:10,497 main.py:57] epoch 285, training loss: 7227.68, average training loss: 9540.75, base loss: 15642.92
[INFO 2017-06-29 11:44:13,668 main.py:57] epoch 286, training loss: 8286.24, average training loss: 9536.38, base loss: 15644.89
[INFO 2017-06-29 11:44:16,899 main.py:57] epoch 287, training loss: 7996.37, average training loss: 9531.03, base loss: 15646.31
[INFO 2017-06-29 11:44:20,264 main.py:57] epoch 288, training loss: 9466.28, average training loss: 9530.81, base loss: 15652.16
[INFO 2017-06-29 11:44:23,576 main.py:57] epoch 289, training loss: 6875.67, average training loss: 9521.65, base loss: 15644.22
[INFO 2017-06-29 11:44:26,984 main.py:57] epoch 290, training loss: 7583.76, average training loss: 9514.99, base loss: 15645.58
[INFO 2017-06-29 11:44:30,205 main.py:57] epoch 291, training loss: 8448.44, average training loss: 9511.34, base loss: 15649.43
[INFO 2017-06-29 11:44:33,446 main.py:57] epoch 292, training loss: 8459.68, average training loss: 9507.75, base loss: 15649.64
[INFO 2017-06-29 11:44:36,739 main.py:57] epoch 293, training loss: 8365.15, average training loss: 9503.86, base loss: 15650.49
[INFO 2017-06-29 11:44:40,038 main.py:57] epoch 294, training loss: 8387.66, average training loss: 9500.08, base loss: 15651.03
[INFO 2017-06-29 11:44:43,226 main.py:57] epoch 295, training loss: 9007.53, average training loss: 9498.42, base loss: 15652.74
[INFO 2017-06-29 11:44:46,467 main.py:57] epoch 296, training loss: 7615.69, average training loss: 9492.08, base loss: 15650.45
[INFO 2017-06-29 11:44:49,769 main.py:57] epoch 297, training loss: 8015.08, average training loss: 9487.12, base loss: 15650.46
[INFO 2017-06-29 11:44:53,217 main.py:57] epoch 298, training loss: 10353.52, average training loss: 9490.02, base loss: 15665.99
[INFO 2017-06-29 11:44:56,449 main.py:57] epoch 299, training loss: 6951.88, average training loss: 9481.56, base loss: 15662.38
[INFO 2017-06-29 11:44:56,449 main.py:59] epoch 299, testing
[INFO 2017-06-29 11:45:10,473 main.py:104] average testing loss: 8692.85, base loss: 16063.36
[INFO 2017-06-29 11:45:10,473 main.py:105] improve_loss: 7370.51, improve_percent: 0.46
[INFO 2017-06-29 11:45:10,475 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 11:45:10,513 main.py:71] current best improved percent: 0.46
[INFO 2017-06-29 11:45:13,706 main.py:57] epoch 300, training loss: 8461.40, average training loss: 9478.17, base loss: 15669.02
[INFO 2017-06-29 11:45:17,019 main.py:57] epoch 301, training loss: 7631.21, average training loss: 9472.05, base loss: 15664.60
[INFO 2017-06-29 11:45:20,314 main.py:57] epoch 302, training loss: 7807.83, average training loss: 9466.56, base loss: 15664.14
[INFO 2017-06-29 11:45:23,591 main.py:57] epoch 303, training loss: 8018.28, average training loss: 9461.80, base loss: 15665.24
[INFO 2017-06-29 11:45:26,926 main.py:57] epoch 304, training loss: 6897.75, average training loss: 9453.39, base loss: 15657.04
[INFO 2017-06-29 11:45:30,256 main.py:57] epoch 305, training loss: 7388.83, average training loss: 9446.64, base loss: 15651.92
[INFO 2017-06-29 11:45:33,604 main.py:57] epoch 306, training loss: 8070.27, average training loss: 9442.16, base loss: 15653.55
[INFO 2017-06-29 11:45:37,142 main.py:57] epoch 307, training loss: 7801.51, average training loss: 9436.83, base loss: 15653.64
[INFO 2017-06-29 11:45:40,486 main.py:57] epoch 308, training loss: 8425.39, average training loss: 9433.56, base loss: 15655.38
[INFO 2017-06-29 11:45:43,696 main.py:57] epoch 309, training loss: 7452.78, average training loss: 9427.17, base loss: 15653.08
[INFO 2017-06-29 11:45:46,978 main.py:57] epoch 310, training loss: 8452.79, average training loss: 9424.04, base loss: 15655.62
[INFO 2017-06-29 11:45:50,371 main.py:57] epoch 311, training loss: 8774.76, average training loss: 9421.96, base loss: 15660.13
[INFO 2017-06-29 11:45:53,801 main.py:57] epoch 312, training loss: 8124.01, average training loss: 9417.81, base loss: 15660.37
[INFO 2017-06-29 11:45:57,157 main.py:57] epoch 313, training loss: 8641.30, average training loss: 9415.34, base loss: 15660.42
[INFO 2017-06-29 11:46:00,653 main.py:57] epoch 314, training loss: 6653.75, average training loss: 9406.57, base loss: 15651.92
[INFO 2017-06-29 11:46:04,130 main.py:57] epoch 315, training loss: 7398.11, average training loss: 9400.21, base loss: 15645.41
[INFO 2017-06-29 11:46:07,572 main.py:57] epoch 316, training loss: 9329.66, average training loss: 9399.99, base loss: 15649.47
[INFO 2017-06-29 11:46:10,879 main.py:57] epoch 317, training loss: 7706.07, average training loss: 9394.66, base loss: 15648.05
[INFO 2017-06-29 11:46:14,275 main.py:57] epoch 318, training loss: 7366.44, average training loss: 9388.31, base loss: 15643.59
[INFO 2017-06-29 11:46:17,475 main.py:57] epoch 319, training loss: 7165.10, average training loss: 9381.36, base loss: 15636.91
[INFO 2017-06-29 11:46:21,061 main.py:57] epoch 320, training loss: 8211.78, average training loss: 9377.72, base loss: 15634.71
[INFO 2017-06-29 11:46:24,416 main.py:57] epoch 321, training loss: 7896.18, average training loss: 9373.11, base loss: 15636.82
[INFO 2017-06-29 11:46:27,802 main.py:57] epoch 322, training loss: 8070.81, average training loss: 9369.08, base loss: 15635.46
[INFO 2017-06-29 11:46:31,164 main.py:57] epoch 323, training loss: 8379.55, average training loss: 9366.03, base loss: 15635.07
[INFO 2017-06-29 11:46:34,505 main.py:57] epoch 324, training loss: 7834.87, average training loss: 9361.32, base loss: 15636.99
[INFO 2017-06-29 11:46:37,795 main.py:57] epoch 325, training loss: 8139.41, average training loss: 9357.57, base loss: 15637.93
[INFO 2017-06-29 11:46:41,094 main.py:57] epoch 326, training loss: 8472.24, average training loss: 9354.86, base loss: 15636.25
[INFO 2017-06-29 11:46:44,304 main.py:57] epoch 327, training loss: 8185.53, average training loss: 9351.30, base loss: 15639.50
[INFO 2017-06-29 11:46:47,508 main.py:57] epoch 328, training loss: 7779.93, average training loss: 9346.52, base loss: 15638.87
[INFO 2017-06-29 11:46:50,707 main.py:57] epoch 329, training loss: 8172.69, average training loss: 9342.96, base loss: 15637.28
[INFO 2017-06-29 11:46:53,999 main.py:57] epoch 330, training loss: 7853.45, average training loss: 9338.46, base loss: 15639.60
[INFO 2017-06-29 11:46:57,316 main.py:57] epoch 331, training loss: 9273.16, average training loss: 9338.27, base loss: 15640.96
[INFO 2017-06-29 11:47:00,661 main.py:57] epoch 332, training loss: 8184.63, average training loss: 9334.80, base loss: 15645.81
[INFO 2017-06-29 11:47:03,994 main.py:57] epoch 333, training loss: 8375.53, average training loss: 9331.93, base loss: 15646.69
[INFO 2017-06-29 11:47:07,157 main.py:57] epoch 334, training loss: 7790.67, average training loss: 9327.33, base loss: 15644.76
[INFO 2017-06-29 11:47:10,331 main.py:57] epoch 335, training loss: 7980.37, average training loss: 9323.32, base loss: 15643.50
[INFO 2017-06-29 11:47:13,580 main.py:57] epoch 336, training loss: 7235.00, average training loss: 9317.12, base loss: 15642.29
[INFO 2017-06-29 11:47:16,922 main.py:57] epoch 337, training loss: 7884.95, average training loss: 9312.89, base loss: 15641.69
[INFO 2017-06-29 11:47:20,156 main.py:57] epoch 338, training loss: 8325.79, average training loss: 9309.97, base loss: 15644.06
[INFO 2017-06-29 11:47:23,371 main.py:57] epoch 339, training loss: 8266.18, average training loss: 9306.90, base loss: 15645.91
[INFO 2017-06-29 11:47:26,733 main.py:57] epoch 340, training loss: 7797.83, average training loss: 9302.48, base loss: 15643.55
[INFO 2017-06-29 11:47:30,006 main.py:57] epoch 341, training loss: 8879.63, average training loss: 9301.24, base loss: 15649.34
[INFO 2017-06-29 11:47:33,238 main.py:57] epoch 342, training loss: 9386.55, average training loss: 9301.49, base loss: 15655.56
[INFO 2017-06-29 11:47:36,361 main.py:57] epoch 343, training loss: 7941.39, average training loss: 9297.54, base loss: 15655.90
[INFO 2017-06-29 11:47:39,640 main.py:57] epoch 344, training loss: 8185.93, average training loss: 9294.32, base loss: 15655.39
[INFO 2017-06-29 11:47:42,848 main.py:57] epoch 345, training loss: 8156.15, average training loss: 9291.03, base loss: 15659.08
[INFO 2017-06-29 11:47:46,172 main.py:57] epoch 346, training loss: 7628.16, average training loss: 9286.23, base loss: 15658.62
[INFO 2017-06-29 11:47:49,526 main.py:57] epoch 347, training loss: 8839.72, average training loss: 9284.95, base loss: 15663.18
[INFO 2017-06-29 11:47:52,783 main.py:57] epoch 348, training loss: 8455.97, average training loss: 9282.58, base loss: 15665.38
[INFO 2017-06-29 11:47:56,034 main.py:57] epoch 349, training loss: 7105.49, average training loss: 9276.36, base loss: 15660.79
[INFO 2017-06-29 11:47:59,219 main.py:57] epoch 350, training loss: 7917.84, average training loss: 9272.49, base loss: 15660.45
[INFO 2017-06-29 11:48:02,558 main.py:57] epoch 351, training loss: 7261.64, average training loss: 9266.77, base loss: 15656.03
[INFO 2017-06-29 11:48:05,920 main.py:57] epoch 352, training loss: 8612.83, average training loss: 9264.92, base loss: 15657.82
[INFO 2017-06-29 11:48:09,052 main.py:57] epoch 353, training loss: 7384.52, average training loss: 9259.61, base loss: 15655.78
[INFO 2017-06-29 11:48:12,193 main.py:57] epoch 354, training loss: 7153.79, average training loss: 9253.68, base loss: 15651.57
[INFO 2017-06-29 11:48:15,383 main.py:57] epoch 355, training loss: 7071.87, average training loss: 9247.55, base loss: 15648.10
[INFO 2017-06-29 11:48:18,649 main.py:57] epoch 356, training loss: 7995.40, average training loss: 9244.04, base loss: 15646.69
[INFO 2017-06-29 11:48:21,947 main.py:57] epoch 357, training loss: 7653.51, average training loss: 9239.60, base loss: 15642.70
[INFO 2017-06-29 11:48:25,176 main.py:57] epoch 358, training loss: 8814.58, average training loss: 9238.41, base loss: 15646.05
[INFO 2017-06-29 11:48:28,464 main.py:57] epoch 359, training loss: 7895.34, average training loss: 9234.68, base loss: 15646.02
[INFO 2017-06-29 11:48:31,824 main.py:57] epoch 360, training loss: 8563.02, average training loss: 9232.82, base loss: 15649.64
[INFO 2017-06-29 11:48:35,170 main.py:57] epoch 361, training loss: 9172.60, average training loss: 9232.66, base loss: 15655.11
[INFO 2017-06-29 11:48:38,442 main.py:57] epoch 362, training loss: 7499.10, average training loss: 9227.88, base loss: 15655.19
[INFO 2017-06-29 11:48:41,805 main.py:57] epoch 363, training loss: 7611.35, average training loss: 9223.44, base loss: 15655.90
[INFO 2017-06-29 11:48:45,081 main.py:57] epoch 364, training loss: 8307.21, average training loss: 9220.93, base loss: 15657.17
[INFO 2017-06-29 11:48:48,348 main.py:57] epoch 365, training loss: 7346.38, average training loss: 9215.81, base loss: 15654.28
[INFO 2017-06-29 11:48:51,691 main.py:57] epoch 366, training loss: 8044.60, average training loss: 9212.62, base loss: 15652.19
[INFO 2017-06-29 11:48:54,890 main.py:57] epoch 367, training loss: 7290.84, average training loss: 9207.39, base loss: 15652.56
[INFO 2017-06-29 11:48:58,247 main.py:57] epoch 368, training loss: 7357.37, average training loss: 9202.38, base loss: 15648.91
[INFO 2017-06-29 11:49:01,511 main.py:57] epoch 369, training loss: 10346.77, average training loss: 9205.47, base loss: 15659.82
[INFO 2017-06-29 11:49:04,775 main.py:57] epoch 370, training loss: 6680.08, average training loss: 9198.67, base loss: 15655.35
[INFO 2017-06-29 11:49:08,126 main.py:57] epoch 371, training loss: 9434.43, average training loss: 9199.30, base loss: 15660.82
[INFO 2017-06-29 11:49:11,424 main.py:57] epoch 372, training loss: 7532.03, average training loss: 9194.83, base loss: 15657.37
[INFO 2017-06-29 11:49:14,759 main.py:57] epoch 373, training loss: 8249.06, average training loss: 9192.30, base loss: 15657.87
[INFO 2017-06-29 11:49:18,032 main.py:57] epoch 374, training loss: 8464.49, average training loss: 9190.36, base loss: 15663.35
[INFO 2017-06-29 11:49:21,195 main.py:57] epoch 375, training loss: 7666.29, average training loss: 9186.31, base loss: 15664.39
[INFO 2017-06-29 11:49:24,373 main.py:57] epoch 376, training loss: 9490.01, average training loss: 9187.11, base loss: 15668.71
[INFO 2017-06-29 11:49:27,812 main.py:57] epoch 377, training loss: 9131.75, average training loss: 9186.97, base loss: 15673.80
[INFO 2017-06-29 11:49:31,015 main.py:57] epoch 378, training loss: 7987.68, average training loss: 9183.80, base loss: 15671.66
[INFO 2017-06-29 11:49:34,370 main.py:57] epoch 379, training loss: 7735.37, average training loss: 9179.99, base loss: 15673.08
[INFO 2017-06-29 11:49:37,737 main.py:57] epoch 380, training loss: 7678.83, average training loss: 9176.05, base loss: 15671.21
[INFO 2017-06-29 11:49:40,978 main.py:57] epoch 381, training loss: 7540.70, average training loss: 9171.77, base loss: 15666.49
[INFO 2017-06-29 11:49:44,347 main.py:57] epoch 382, training loss: 8801.87, average training loss: 9170.80, base loss: 15670.62
[INFO 2017-06-29 11:49:47,799 main.py:57] epoch 383, training loss: 7857.51, average training loss: 9167.38, base loss: 15674.12
[INFO 2017-06-29 11:49:51,063 main.py:57] epoch 384, training loss: 7622.27, average training loss: 9163.37, base loss: 15672.69
[INFO 2017-06-29 11:49:54,374 main.py:57] epoch 385, training loss: 7805.91, average training loss: 9159.85, base loss: 15672.39
[INFO 2017-06-29 11:49:57,724 main.py:57] epoch 386, training loss: 8403.05, average training loss: 9157.90, base loss: 15674.29
[INFO 2017-06-29 11:50:01,028 main.py:57] epoch 387, training loss: 7716.88, average training loss: 9154.18, base loss: 15675.49
[INFO 2017-06-29 11:50:04,255 main.py:57] epoch 388, training loss: 6514.35, average training loss: 9147.40, base loss: 15668.60
[INFO 2017-06-29 11:50:07,580 main.py:57] epoch 389, training loss: 8165.13, average training loss: 9144.88, base loss: 15669.24
[INFO 2017-06-29 11:50:10,908 main.py:57] epoch 390, training loss: 8464.29, average training loss: 9143.14, base loss: 15672.78
[INFO 2017-06-29 11:50:14,099 main.py:57] epoch 391, training loss: 7479.61, average training loss: 9138.89, base loss: 15670.88
[INFO 2017-06-29 11:50:17,438 main.py:57] epoch 392, training loss: 7955.14, average training loss: 9135.88, base loss: 15672.85
[INFO 2017-06-29 11:50:20,639 main.py:57] epoch 393, training loss: 7477.30, average training loss: 9131.67, base loss: 15671.00
[INFO 2017-06-29 11:50:23,947 main.py:57] epoch 394, training loss: 7834.01, average training loss: 9128.39, base loss: 15667.76
[INFO 2017-06-29 11:50:27,261 main.py:57] epoch 395, training loss: 7814.54, average training loss: 9125.07, base loss: 15668.33
[INFO 2017-06-29 11:50:30,539 main.py:57] epoch 396, training loss: 7926.83, average training loss: 9122.05, base loss: 15668.60
[INFO 2017-06-29 11:50:33,704 main.py:57] epoch 397, training loss: 7199.55, average training loss: 9117.22, base loss: 15665.44
[INFO 2017-06-29 11:50:37,003 main.py:57] epoch 398, training loss: 7915.25, average training loss: 9114.21, base loss: 15665.72
[INFO 2017-06-29 11:50:40,345 main.py:57] epoch 399, training loss: 7559.25, average training loss: 9110.32, base loss: 15667.21
[INFO 2017-06-29 11:50:40,346 main.py:59] epoch 399, testing
[INFO 2017-06-29 11:50:54,070 main.py:104] average testing loss: 8859.23, base loss: 16647.70
[INFO 2017-06-29 11:50:54,071 main.py:105] improve_loss: 7788.47, improve_percent: 0.47
[INFO 2017-06-29 11:50:54,072 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 11:50:54,110 main.py:71] current best improved percent: 0.47
[INFO 2017-06-29 11:50:57,261 main.py:57] epoch 400, training loss: 7632.41, average training loss: 9106.64, base loss: 15669.93
[INFO 2017-06-29 11:51:00,473 main.py:57] epoch 401, training loss: 7847.55, average training loss: 9103.50, base loss: 15667.83
[INFO 2017-06-29 11:51:03,740 main.py:57] epoch 402, training loss: 8452.42, average training loss: 9101.89, base loss: 15670.61
[INFO 2017-06-29 11:51:07,013 main.py:57] epoch 403, training loss: 9098.58, average training loss: 9101.88, base loss: 15674.42
[INFO 2017-06-29 11:51:10,326 main.py:57] epoch 404, training loss: 8528.44, average training loss: 9100.46, base loss: 15677.74
[INFO 2017-06-29 11:51:13,552 main.py:57] epoch 405, training loss: 7179.51, average training loss: 9095.73, base loss: 15671.99
[INFO 2017-06-29 11:51:16,892 main.py:57] epoch 406, training loss: 7765.48, average training loss: 9092.46, base loss: 15670.55
[INFO 2017-06-29 11:51:20,266 main.py:57] epoch 407, training loss: 7814.80, average training loss: 9089.33, base loss: 15669.71
[INFO 2017-06-29 11:51:23,503 main.py:57] epoch 408, training loss: 9085.03, average training loss: 9089.32, base loss: 15675.96
[INFO 2017-06-29 11:51:26,744 main.py:57] epoch 409, training loss: 8097.90, average training loss: 9086.90, base loss: 15674.86
[INFO 2017-06-29 11:51:30,023 main.py:57] epoch 410, training loss: 7810.63, average training loss: 9083.80, base loss: 15676.17
[INFO 2017-06-29 11:51:33,285 main.py:57] epoch 411, training loss: 8720.00, average training loss: 9082.92, base loss: 15679.11
[INFO 2017-06-29 11:51:36,532 main.py:57] epoch 412, training loss: 7776.03, average training loss: 9079.75, base loss: 15677.56
[INFO 2017-06-29 11:51:39,816 main.py:57] epoch 413, training loss: 7355.67, average training loss: 9075.59, base loss: 15674.14
[INFO 2017-06-29 11:51:43,086 main.py:57] epoch 414, training loss: 7764.74, average training loss: 9072.43, base loss: 15676.52
[INFO 2017-06-29 11:51:46,436 main.py:57] epoch 415, training loss: 8622.51, average training loss: 9071.35, base loss: 15680.19
[INFO 2017-06-29 11:51:49,663 main.py:57] epoch 416, training loss: 7646.60, average training loss: 9067.93, base loss: 15678.48
[INFO 2017-06-29 11:51:52,938 main.py:57] epoch 417, training loss: 8110.90, average training loss: 9065.64, base loss: 15681.39
[INFO 2017-06-29 11:51:56,212 main.py:57] epoch 418, training loss: 7812.43, average training loss: 9062.65, base loss: 15681.49
[INFO 2017-06-29 11:51:59,562 main.py:57] epoch 419, training loss: 7513.86, average training loss: 9058.96, base loss: 15681.82
[INFO 2017-06-29 11:52:02,895 main.py:57] epoch 420, training loss: 8109.92, average training loss: 9056.71, base loss: 15686.04
[INFO 2017-06-29 11:52:06,022 main.py:57] epoch 421, training loss: 9148.78, average training loss: 9056.93, base loss: 15687.06
[INFO 2017-06-29 11:52:09,398 main.py:57] epoch 422, training loss: 7497.26, average training loss: 9053.24, base loss: 15684.29
[INFO 2017-06-29 11:52:12,618 main.py:57] epoch 423, training loss: 8375.41, average training loss: 9051.64, base loss: 15686.48
[INFO 2017-06-29 11:52:15,963 main.py:57] epoch 424, training loss: 8287.88, average training loss: 9049.84, base loss: 15686.45
[INFO 2017-06-29 11:52:19,224 main.py:57] epoch 425, training loss: 7597.93, average training loss: 9046.43, base loss: 15685.21
[INFO 2017-06-29 11:52:22,430 main.py:57] epoch 426, training loss: 7998.64, average training loss: 9043.98, base loss: 15683.20
[INFO 2017-06-29 11:52:25,829 main.py:57] epoch 427, training loss: 8432.98, average training loss: 9042.55, base loss: 15682.23
[INFO 2017-06-29 11:52:29,116 main.py:57] epoch 428, training loss: 7782.90, average training loss: 9039.62, base loss: 15681.92
[INFO 2017-06-29 11:52:32,368 main.py:57] epoch 429, training loss: 8867.51, average training loss: 9039.22, base loss: 15685.51
[INFO 2017-06-29 11:52:35,715 main.py:57] epoch 430, training loss: 8648.62, average training loss: 9038.31, base loss: 15688.06
[INFO 2017-06-29 11:52:39,020 main.py:57] epoch 431, training loss: 8175.48, average training loss: 9036.31, base loss: 15690.34
[INFO 2017-06-29 11:52:42,153 main.py:57] epoch 432, training loss: 8797.15, average training loss: 9035.76, base loss: 15691.62
[INFO 2017-06-29 11:52:45,552 main.py:57] epoch 433, training loss: 7774.36, average training loss: 9032.85, base loss: 15691.20
[INFO 2017-06-29 11:52:48,806 main.py:57] epoch 434, training loss: 7821.71, average training loss: 9030.07, base loss: 15690.50
[INFO 2017-06-29 11:52:52,042 main.py:57] epoch 435, training loss: 7256.12, average training loss: 9026.00, base loss: 15687.87
[INFO 2017-06-29 11:52:55,413 main.py:57] epoch 436, training loss: 8437.10, average training loss: 9024.65, base loss: 15690.33
[INFO 2017-06-29 11:52:58,749 main.py:57] epoch 437, training loss: 8070.03, average training loss: 9022.47, base loss: 15688.39
[INFO 2017-06-29 11:53:02,061 main.py:57] epoch 438, training loss: 8347.20, average training loss: 9020.94, base loss: 15690.40
[INFO 2017-06-29 11:53:05,266 main.py:57] epoch 439, training loss: 8010.87, average training loss: 9018.64, base loss: 15691.20
[INFO 2017-06-29 11:53:08,642 main.py:57] epoch 440, training loss: 7917.37, average training loss: 9016.14, base loss: 15691.26
[INFO 2017-06-29 11:53:11,959 main.py:57] epoch 441, training loss: 7470.91, average training loss: 9012.65, base loss: 15689.59
[INFO 2017-06-29 11:53:15,205 main.py:57] epoch 442, training loss: 8343.84, average training loss: 9011.14, base loss: 15693.92
[INFO 2017-06-29 11:53:18,523 main.py:57] epoch 443, training loss: 7905.42, average training loss: 9008.65, base loss: 15693.30
[INFO 2017-06-29 11:53:21,680 main.py:57] epoch 444, training loss: 7820.00, average training loss: 9005.98, base loss: 15691.86
[INFO 2017-06-29 11:53:24,929 main.py:57] epoch 445, training loss: 7855.12, average training loss: 9003.40, base loss: 15691.56
[INFO 2017-06-29 11:53:28,189 main.py:57] epoch 446, training loss: 8368.41, average training loss: 9001.98, base loss: 15692.89
[INFO 2017-06-29 11:53:31,475 main.py:57] epoch 447, training loss: 8806.96, average training loss: 9001.54, base loss: 15697.59
[INFO 2017-06-29 11:53:34,846 main.py:57] epoch 448, training loss: 7470.11, average training loss: 8998.13, base loss: 15697.36
[INFO 2017-06-29 11:53:38,318 main.py:57] epoch 449, training loss: 7841.25, average training loss: 8995.56, base loss: 15695.98
[INFO 2017-06-29 11:53:41,633 main.py:57] epoch 450, training loss: 8197.76, average training loss: 8993.79, base loss: 15693.00
[INFO 2017-06-29 11:53:44,956 main.py:57] epoch 451, training loss: 7624.87, average training loss: 8990.76, base loss: 15691.41
[INFO 2017-06-29 11:53:48,261 main.py:57] epoch 452, training loss: 9379.63, average training loss: 8991.62, base loss: 15697.40
[INFO 2017-06-29 11:53:51,401 main.py:57] epoch 453, training loss: 7299.94, average training loss: 8987.89, base loss: 15695.04
[INFO 2017-06-29 11:53:54,538 main.py:57] epoch 454, training loss: 8091.36, average training loss: 8985.92, base loss: 15696.35
[INFO 2017-06-29 11:53:57,763 main.py:57] epoch 455, training loss: 7845.13, average training loss: 8983.42, base loss: 15696.38
[INFO 2017-06-29 11:54:01,099 main.py:57] epoch 456, training loss: 7427.81, average training loss: 8980.02, base loss: 15692.21
[INFO 2017-06-29 11:54:04,467 main.py:57] epoch 457, training loss: 7447.13, average training loss: 8976.67, base loss: 15690.01
[INFO 2017-06-29 11:54:07,744 main.py:57] epoch 458, training loss: 7050.00, average training loss: 8972.47, base loss: 15689.07
[INFO 2017-06-29 11:54:10,864 main.py:57] epoch 459, training loss: 7983.28, average training loss: 8970.32, base loss: 15691.01
[INFO 2017-06-29 11:54:14,201 main.py:57] epoch 460, training loss: 7907.21, average training loss: 8968.02, base loss: 15688.12
[INFO 2017-06-29 11:54:17,337 main.py:57] epoch 461, training loss: 7175.88, average training loss: 8964.14, base loss: 15685.23
[INFO 2017-06-29 11:54:20,711 main.py:57] epoch 462, training loss: 7249.47, average training loss: 8960.43, base loss: 15683.06
[INFO 2017-06-29 11:54:24,025 main.py:57] epoch 463, training loss: 8111.00, average training loss: 8958.60, base loss: 15684.52
[INFO 2017-06-29 11:54:27,246 main.py:57] epoch 464, training loss: 7436.03, average training loss: 8955.33, base loss: 15683.48
[INFO 2017-06-29 11:54:30,525 main.py:57] epoch 465, training loss: 7611.29, average training loss: 8952.44, base loss: 15680.54
[INFO 2017-06-29 11:54:33,741 main.py:57] epoch 466, training loss: 8900.31, average training loss: 8952.33, base loss: 15683.99
[INFO 2017-06-29 11:54:37,087 main.py:57] epoch 467, training loss: 7783.85, average training loss: 8949.84, base loss: 15684.98
[INFO 2017-06-29 11:54:40,308 main.py:57] epoch 468, training loss: 7369.91, average training loss: 8946.47, base loss: 15684.59
[INFO 2017-06-29 11:54:43,611 main.py:57] epoch 469, training loss: 7522.40, average training loss: 8943.44, base loss: 15682.96
[INFO 2017-06-29 11:54:46,803 main.py:57] epoch 470, training loss: 9331.34, average training loss: 8944.26, base loss: 15687.90
[INFO 2017-06-29 11:54:50,113 main.py:57] epoch 471, training loss: 6645.04, average training loss: 8939.39, base loss: 15683.83
[INFO 2017-06-29 11:54:53,482 main.py:57] epoch 472, training loss: 8193.47, average training loss: 8937.81, base loss: 15685.74
[INFO 2017-06-29 11:54:56,785 main.py:57] epoch 473, training loss: 8030.48, average training loss: 8935.90, base loss: 15684.47
[INFO 2017-06-29 11:54:59,943 main.py:57] epoch 474, training loss: 8265.14, average training loss: 8934.49, base loss: 15688.39
[INFO 2017-06-29 11:55:03,209 main.py:57] epoch 475, training loss: 7551.02, average training loss: 8931.58, base loss: 15688.70
[INFO 2017-06-29 11:55:06,439 main.py:57] epoch 476, training loss: 6854.35, average training loss: 8927.22, base loss: 15684.67
[INFO 2017-06-29 11:55:09,700 main.py:57] epoch 477, training loss: 7460.83, average training loss: 8924.16, base loss: 15682.70
[INFO 2017-06-29 11:55:12,948 main.py:57] epoch 478, training loss: 6974.57, average training loss: 8920.09, base loss: 15679.11
[INFO 2017-06-29 11:55:16,226 main.py:57] epoch 479, training loss: 7526.80, average training loss: 8917.18, base loss: 15676.91
[INFO 2017-06-29 11:55:19,468 main.py:57] epoch 480, training loss: 7814.44, average training loss: 8914.89, base loss: 15676.63
[INFO 2017-06-29 11:55:22,741 main.py:57] epoch 481, training loss: 7982.43, average training loss: 8912.96, base loss: 15676.32
[INFO 2017-06-29 11:55:26,239 main.py:57] epoch 482, training loss: 8333.07, average training loss: 8911.76, base loss: 15676.55
[INFO 2017-06-29 11:55:29,702 main.py:57] epoch 483, training loss: 7143.05, average training loss: 8908.10, base loss: 15673.69
[INFO 2017-06-29 11:55:33,075 main.py:57] epoch 484, training loss: 7412.53, average training loss: 8905.02, base loss: 15672.82
[INFO 2017-06-29 11:55:36,515 main.py:57] epoch 485, training loss: 7270.41, average training loss: 8901.66, base loss: 15672.09
[INFO 2017-06-29 11:55:39,764 main.py:57] epoch 486, training loss: 8092.04, average training loss: 8899.99, base loss: 15673.19
[INFO 2017-06-29 11:55:43,004 main.py:57] epoch 487, training loss: 8455.94, average training loss: 8899.08, base loss: 15674.93
[INFO 2017-06-29 11:55:46,286 main.py:57] epoch 488, training loss: 7573.41, average training loss: 8896.37, base loss: 15676.20
[INFO 2017-06-29 11:55:49,462 main.py:57] epoch 489, training loss: 7612.46, average training loss: 8893.75, base loss: 15676.90
[INFO 2017-06-29 11:55:52,807 main.py:57] epoch 490, training loss: 8970.37, average training loss: 8893.91, base loss: 15681.18
[INFO 2017-06-29 11:55:56,174 main.py:57] epoch 491, training loss: 6820.87, average training loss: 8889.69, base loss: 15679.39
[INFO 2017-06-29 11:55:59,387 main.py:57] epoch 492, training loss: 7690.42, average training loss: 8887.26, base loss: 15678.81
[INFO 2017-06-29 11:56:02,568 main.py:57] epoch 493, training loss: 8061.97, average training loss: 8885.59, base loss: 15676.30
[INFO 2017-06-29 11:56:05,815 main.py:57] epoch 494, training loss: 7593.85, average training loss: 8882.98, base loss: 15673.05
[INFO 2017-06-29 11:56:09,251 main.py:57] epoch 495, training loss: 8317.12, average training loss: 8881.84, base loss: 15673.20
[INFO 2017-06-29 11:56:12,435 main.py:57] epoch 496, training loss: 8003.19, average training loss: 8880.07, base loss: 15674.43
[INFO 2017-06-29 11:56:15,605 main.py:57] epoch 497, training loss: 7755.44, average training loss: 8877.81, base loss: 15676.17
[INFO 2017-06-29 11:56:18,895 main.py:57] epoch 498, training loss: 6818.84, average training loss: 8873.69, base loss: 15673.48
[INFO 2017-06-29 11:56:22,237 main.py:57] epoch 499, training loss: 8517.48, average training loss: 8872.98, base loss: 15674.96
[INFO 2017-06-29 11:56:22,237 main.py:59] epoch 499, testing
[INFO 2017-06-29 11:56:36,016 main.py:104] average testing loss: 8736.33, base loss: 17230.33
[INFO 2017-06-29 11:56:36,016 main.py:105] improve_loss: 8493.99, improve_percent: 0.49
[INFO 2017-06-29 11:56:36,018 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 11:56:36,059 main.py:71] current best improved percent: 0.49
[INFO 2017-06-29 11:56:39,409 main.py:57] epoch 500, training loss: 9466.28, average training loss: 8874.16, base loss: 15681.92
[INFO 2017-06-29 11:56:42,703 main.py:57] epoch 501, training loss: 7435.87, average training loss: 8871.29, base loss: 15676.82
[INFO 2017-06-29 11:56:46,097 main.py:57] epoch 502, training loss: 8366.57, average training loss: 8870.29, base loss: 15677.17
[INFO 2017-06-29 11:56:49,319 main.py:57] epoch 503, training loss: 7369.27, average training loss: 8867.31, base loss: 15673.76
[INFO 2017-06-29 11:56:52,560 main.py:57] epoch 504, training loss: 7266.96, average training loss: 8864.14, base loss: 15672.57
[INFO 2017-06-29 11:56:55,819 main.py:57] epoch 505, training loss: 7947.33, average training loss: 8862.33, base loss: 15671.98
[INFO 2017-06-29 11:56:59,284 main.py:57] epoch 506, training loss: 7360.43, average training loss: 8859.37, base loss: 15669.87
[INFO 2017-06-29 11:57:02,565 main.py:57] epoch 507, training loss: 7978.78, average training loss: 8857.64, base loss: 15670.87
[INFO 2017-06-29 11:57:06,236 main.py:57] epoch 508, training loss: 8533.40, average training loss: 8857.00, base loss: 15673.56
[INFO 2017-06-29 11:57:09,563 main.py:57] epoch 509, training loss: 8405.93, average training loss: 8856.11, base loss: 15677.33
[INFO 2017-06-29 11:57:12,942 main.py:57] epoch 510, training loss: 7740.01, average training loss: 8853.93, base loss: 15676.43
[INFO 2017-06-29 11:57:16,275 main.py:57] epoch 511, training loss: 7440.42, average training loss: 8851.17, base loss: 15674.38
[INFO 2017-06-29 11:57:19,599 main.py:57] epoch 512, training loss: 7625.87, average training loss: 8848.78, base loss: 15672.08
[INFO 2017-06-29 11:57:22,972 main.py:57] epoch 513, training loss: 8632.61, average training loss: 8848.36, base loss: 15675.22
[INFO 2017-06-29 11:57:26,429 main.py:57] epoch 514, training loss: 7396.23, average training loss: 8845.54, base loss: 15675.84
[INFO 2017-06-29 11:57:29,732 main.py:57] epoch 515, training loss: 8691.59, average training loss: 8845.24, base loss: 15678.88
[INFO 2017-06-29 11:57:33,066 main.py:57] epoch 516, training loss: 7820.69, average training loss: 8843.26, base loss: 15679.31
[INFO 2017-06-29 11:57:36,240 main.py:57] epoch 517, training loss: 8128.77, average training loss: 8841.88, base loss: 15681.24
[INFO 2017-06-29 11:57:39,561 main.py:57] epoch 518, training loss: 8276.07, average training loss: 8840.79, base loss: 15684.21
[INFO 2017-06-29 11:57:42,707 main.py:57] epoch 519, training loss: 7715.66, average training loss: 8838.63, base loss: 15684.63
[INFO 2017-06-29 11:57:45,992 main.py:57] epoch 520, training loss: 7545.61, average training loss: 8836.15, base loss: 15683.79
[INFO 2017-06-29 11:57:49,359 main.py:57] epoch 521, training loss: 8169.00, average training loss: 8834.87, base loss: 15685.82
[INFO 2017-06-29 11:57:52,752 main.py:57] epoch 522, training loss: 8006.84, average training loss: 8833.28, base loss: 15683.45
[INFO 2017-06-29 11:57:56,088 main.py:57] epoch 523, training loss: 7496.52, average training loss: 8830.73, base loss: 15682.15
[INFO 2017-06-29 11:57:59,399 main.py:57] epoch 524, training loss: 8666.31, average training loss: 8830.42, base loss: 15685.33
[INFO 2017-06-29 11:58:02,628 main.py:57] epoch 525, training loss: 8426.94, average training loss: 8829.65, base loss: 15684.23
[INFO 2017-06-29 11:58:05,849 main.py:57] epoch 526, training loss: 8405.89, average training loss: 8828.85, base loss: 15687.60
[INFO 2017-06-29 11:58:09,128 main.py:57] epoch 527, training loss: 7906.54, average training loss: 8827.10, base loss: 15688.82
[INFO 2017-06-29 11:58:12,540 main.py:57] epoch 528, training loss: 7581.99, average training loss: 8824.75, base loss: 15687.55
[INFO 2017-06-29 11:58:15,756 main.py:57] epoch 529, training loss: 7908.52, average training loss: 8823.02, base loss: 15691.82
[INFO 2017-06-29 11:58:19,036 main.py:57] epoch 530, training loss: 7193.29, average training loss: 8819.95, base loss: 15692.92
[INFO 2017-06-29 11:58:22,285 main.py:57] epoch 531, training loss: 7696.63, average training loss: 8817.84, base loss: 15698.32
[INFO 2017-06-29 11:58:25,726 main.py:57] epoch 532, training loss: 7196.73, average training loss: 8814.80, base loss: 15696.57
[INFO 2017-06-29 11:58:29,284 main.py:57] epoch 533, training loss: 7817.08, average training loss: 8812.93, base loss: 15699.89
[INFO 2017-06-29 11:58:32,622 main.py:57] epoch 534, training loss: 8467.39, average training loss: 8812.28, base loss: 15700.61
[INFO 2017-06-29 11:58:36,097 main.py:57] epoch 535, training loss: 7873.01, average training loss: 8810.53, base loss: 15703.35
[INFO 2017-06-29 11:58:39,300 main.py:57] epoch 536, training loss: 7888.45, average training loss: 8808.81, base loss: 15703.55
[INFO 2017-06-29 11:58:42,722 main.py:57] epoch 537, training loss: 7861.51, average training loss: 8807.05, base loss: 15704.43
[INFO 2017-06-29 11:58:46,020 main.py:57] epoch 538, training loss: 7837.28, average training loss: 8805.25, base loss: 15705.86
[INFO 2017-06-29 11:58:49,311 main.py:57] epoch 539, training loss: 7803.63, average training loss: 8803.40, base loss: 15705.91
[INFO 2017-06-29 11:58:52,611 main.py:57] epoch 540, training loss: 8139.85, average training loss: 8802.17, base loss: 15707.65
[INFO 2017-06-29 11:58:56,017 main.py:57] epoch 541, training loss: 7223.75, average training loss: 8799.26, base loss: 15709.01
[INFO 2017-06-29 11:58:59,426 main.py:57] epoch 542, training loss: 7418.58, average training loss: 8796.72, base loss: 15710.94
[INFO 2017-06-29 11:59:02,914 main.py:57] epoch 543, training loss: 7076.32, average training loss: 8793.56, base loss: 15708.01
[INFO 2017-06-29 11:59:06,485 main.py:57] epoch 544, training loss: 8100.58, average training loss: 8792.28, base loss: 15712.46
[INFO 2017-06-29 11:59:09,796 main.py:57] epoch 545, training loss: 7499.03, average training loss: 8789.92, base loss: 15714.50
[INFO 2017-06-29 11:59:13,006 main.py:57] epoch 546, training loss: 7395.14, average training loss: 8787.37, base loss: 15711.60
[INFO 2017-06-29 11:59:16,317 main.py:57] epoch 547, training loss: 8613.54, average training loss: 8787.05, base loss: 15712.77
[INFO 2017-06-29 11:59:19,708 main.py:57] epoch 548, training loss: 9555.30, average training loss: 8788.45, base loss: 15716.78
[INFO 2017-06-29 11:59:23,236 main.py:57] epoch 549, training loss: 7169.46, average training loss: 8785.50, base loss: 15712.87
[INFO 2017-06-29 11:59:26,604 main.py:57] epoch 550, training loss: 8603.94, average training loss: 8785.17, base loss: 15713.81
[INFO 2017-06-29 11:59:29,846 main.py:57] epoch 551, training loss: 7751.02, average training loss: 8783.30, base loss: 15712.25
[INFO 2017-06-29 11:59:33,296 main.py:57] epoch 552, training loss: 7828.53, average training loss: 8781.57, base loss: 15713.40
[INFO 2017-06-29 11:59:36,524 main.py:57] epoch 553, training loss: 8457.99, average training loss: 8780.99, base loss: 15715.40
[INFO 2017-06-29 11:59:39,792 main.py:57] epoch 554, training loss: 7993.43, average training loss: 8779.57, base loss: 15717.05
[INFO 2017-06-29 11:59:43,138 main.py:57] epoch 555, training loss: 8648.80, average training loss: 8779.34, base loss: 15719.36
[INFO 2017-06-29 11:59:46,492 main.py:57] epoch 556, training loss: 7138.50, average training loss: 8776.39, base loss: 15716.16
[INFO 2017-06-29 11:59:49,873 main.py:57] epoch 557, training loss: 8548.16, average training loss: 8775.98, base loss: 15718.04
[INFO 2017-06-29 11:59:53,129 main.py:57] epoch 558, training loss: 8236.85, average training loss: 8775.02, base loss: 15720.87
[INFO 2017-06-29 11:59:56,325 main.py:57] epoch 559, training loss: 7907.05, average training loss: 8773.47, base loss: 15722.85
[INFO 2017-06-29 11:59:59,542 main.py:57] epoch 560, training loss: 7432.31, average training loss: 8771.08, base loss: 15721.04
[INFO 2017-06-29 12:00:02,762 main.py:57] epoch 561, training loss: 7290.93, average training loss: 8768.44, base loss: 15718.78
[INFO 2017-06-29 12:00:06,038 main.py:57] epoch 562, training loss: 7356.59, average training loss: 8765.93, base loss: 15716.83
[INFO 2017-06-29 12:00:09,306 main.py:57] epoch 563, training loss: 6811.29, average training loss: 8762.47, base loss: 15713.23
[INFO 2017-06-29 12:00:12,612 main.py:57] epoch 564, training loss: 6847.64, average training loss: 8759.08, base loss: 15710.32
[INFO 2017-06-29 12:00:15,995 main.py:57] epoch 565, training loss: 7708.63, average training loss: 8757.22, base loss: 15710.45
[INFO 2017-06-29 12:00:19,234 main.py:57] epoch 566, training loss: 7827.74, average training loss: 8755.58, base loss: 15711.52
[INFO 2017-06-29 12:00:22,654 main.py:57] epoch 567, training loss: 7955.98, average training loss: 8754.18, base loss: 15711.87
[INFO 2017-06-29 12:00:25,839 main.py:57] epoch 568, training loss: 7167.30, average training loss: 8751.39, base loss: 15709.75
[INFO 2017-06-29 12:00:29,197 main.py:57] epoch 569, training loss: 8234.64, average training loss: 8750.48, base loss: 15712.04
[INFO 2017-06-29 12:00:32,563 main.py:57] epoch 570, training loss: 8697.56, average training loss: 8750.39, base loss: 15715.42
[INFO 2017-06-29 12:00:35,723 main.py:57] epoch 571, training loss: 7573.69, average training loss: 8748.33, base loss: 15712.16
[INFO 2017-06-29 12:00:38,988 main.py:57] epoch 572, training loss: 8456.75, average training loss: 8747.82, base loss: 15714.14
[INFO 2017-06-29 12:00:42,200 main.py:57] epoch 573, training loss: 7224.20, average training loss: 8745.17, base loss: 15711.44
[INFO 2017-06-29 12:00:45,470 main.py:57] epoch 574, training loss: 7910.83, average training loss: 8743.72, base loss: 15711.92
[INFO 2017-06-29 12:00:48,661 main.py:57] epoch 575, training loss: 8455.59, average training loss: 8743.22, base loss: 15713.87
[INFO 2017-06-29 12:00:51,896 main.py:57] epoch 576, training loss: 7555.55, average training loss: 8741.16, base loss: 15711.64
[INFO 2017-06-29 12:00:55,232 main.py:57] epoch 577, training loss: 7286.47, average training loss: 8738.64, base loss: 15709.14
[INFO 2017-06-29 12:00:58,444 main.py:57] epoch 578, training loss: 7254.91, average training loss: 8736.08, base loss: 15707.00
[INFO 2017-06-29 12:01:01,578 main.py:57] epoch 579, training loss: 7569.69, average training loss: 8734.07, base loss: 15704.78
[INFO 2017-06-29 12:01:04,777 main.py:57] epoch 580, training loss: 7944.13, average training loss: 8732.71, base loss: 15705.36
[INFO 2017-06-29 12:01:08,153 main.py:57] epoch 581, training loss: 8787.42, average training loss: 8732.80, base loss: 15710.57
[INFO 2017-06-29 12:01:11,367 main.py:57] epoch 582, training loss: 7512.09, average training loss: 8730.71, base loss: 15707.17
[INFO 2017-06-29 12:01:14,765 main.py:57] epoch 583, training loss: 7338.45, average training loss: 8728.33, base loss: 15707.19
[INFO 2017-06-29 12:01:18,092 main.py:57] epoch 584, training loss: 7586.66, average training loss: 8726.37, base loss: 15706.22
[INFO 2017-06-29 12:01:21,366 main.py:57] epoch 585, training loss: 7347.64, average training loss: 8724.02, base loss: 15704.28
[INFO 2017-06-29 12:01:24,675 main.py:57] epoch 586, training loss: 9389.69, average training loss: 8725.15, base loss: 15711.75
[INFO 2017-06-29 12:01:28,037 main.py:57] epoch 587, training loss: 8102.15, average training loss: 8724.10, base loss: 15712.90
[INFO 2017-06-29 12:01:31,337 main.py:57] epoch 588, training loss: 7314.79, average training loss: 8721.70, base loss: 15710.80
[INFO 2017-06-29 12:01:34,620 main.py:57] epoch 589, training loss: 7322.90, average training loss: 8719.33, base loss: 15710.67
[INFO 2017-06-29 12:01:37,894 main.py:57] epoch 590, training loss: 8072.04, average training loss: 8718.24, base loss: 15714.64
[INFO 2017-06-29 12:01:41,211 main.py:57] epoch 591, training loss: 7740.37, average training loss: 8716.58, base loss: 15716.48
[INFO 2017-06-29 12:01:44,676 main.py:57] epoch 592, training loss: 7440.55, average training loss: 8714.43, base loss: 15716.97
[INFO 2017-06-29 12:01:47,911 main.py:57] epoch 593, training loss: 7274.01, average training loss: 8712.01, base loss: 15717.42
[INFO 2017-06-29 12:01:51,506 main.py:57] epoch 594, training loss: 7230.03, average training loss: 8709.52, base loss: 15718.79
[INFO 2017-06-29 12:01:54,657 main.py:57] epoch 595, training loss: 7448.99, average training loss: 8707.40, base loss: 15720.56
[INFO 2017-06-29 12:01:57,924 main.py:57] epoch 596, training loss: 6693.79, average training loss: 8704.03, base loss: 15717.14
[INFO 2017-06-29 12:02:01,063 main.py:57] epoch 597, training loss: 7427.47, average training loss: 8701.89, base loss: 15713.97
[INFO 2017-06-29 12:02:04,348 main.py:57] epoch 598, training loss: 7017.38, average training loss: 8699.08, base loss: 15710.94
[INFO 2017-06-29 12:02:07,671 main.py:57] epoch 599, training loss: 7929.84, average training loss: 8697.80, base loss: 15710.69
[INFO 2017-06-29 12:02:07,672 main.py:59] epoch 599, testing
[INFO 2017-06-29 12:02:21,651 main.py:104] average testing loss: 8275.21, base loss: 16416.04
[INFO 2017-06-29 12:02:21,651 main.py:105] improve_loss: 8140.84, improve_percent: 0.50
[INFO 2017-06-29 12:02:21,654 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 12:02:21,692 main.py:71] current best improved percent: 0.50
[INFO 2017-06-29 12:02:25,046 main.py:57] epoch 600, training loss: 7290.39, average training loss: 8695.46, base loss: 15712.90
[INFO 2017-06-29 12:02:28,241 main.py:57] epoch 601, training loss: 7713.14, average training loss: 8693.83, base loss: 15712.67
[INFO 2017-06-29 12:02:31,519 main.py:57] epoch 602, training loss: 8030.13, average training loss: 8692.73, base loss: 15716.52
[INFO 2017-06-29 12:02:34,924 main.py:57] epoch 603, training loss: 7206.81, average training loss: 8690.27, base loss: 15714.66
[INFO 2017-06-29 12:02:38,060 main.py:57] epoch 604, training loss: 7048.84, average training loss: 8687.55, base loss: 15712.33
[INFO 2017-06-29 12:02:41,294 main.py:57] epoch 605, training loss: 7946.89, average training loss: 8686.33, base loss: 15715.06
[INFO 2017-06-29 12:02:44,539 main.py:57] epoch 606, training loss: 8284.36, average training loss: 8685.67, base loss: 15717.30
[INFO 2017-06-29 12:02:47,769 main.py:57] epoch 607, training loss: 6888.92, average training loss: 8682.71, base loss: 15712.84
[INFO 2017-06-29 12:02:51,019 main.py:57] epoch 608, training loss: 7778.74, average training loss: 8681.23, base loss: 15711.65
[INFO 2017-06-29 12:02:54,190 main.py:57] epoch 609, training loss: 7341.97, average training loss: 8679.03, base loss: 15710.24
[INFO 2017-06-29 12:02:57,439 main.py:57] epoch 610, training loss: 8213.59, average training loss: 8678.27, base loss: 15713.25
[INFO 2017-06-29 12:03:00,708 main.py:57] epoch 611, training loss: 7783.09, average training loss: 8676.81, base loss: 15713.90
[INFO 2017-06-29 12:03:04,085 main.py:57] epoch 612, training loss: 8119.44, average training loss: 8675.90, base loss: 15713.92
[INFO 2017-06-29 12:03:07,381 main.py:57] epoch 613, training loss: 7417.83, average training loss: 8673.85, base loss: 15712.02
[INFO 2017-06-29 12:03:10,794 main.py:57] epoch 614, training loss: 6867.95, average training loss: 8670.91, base loss: 15710.01
[INFO 2017-06-29 12:03:14,081 main.py:57] epoch 615, training loss: 8192.95, average training loss: 8670.14, base loss: 15713.91
[INFO 2017-06-29 12:03:17,267 main.py:57] epoch 616, training loss: 7409.27, average training loss: 8668.09, base loss: 15709.87
[INFO 2017-06-29 12:03:20,412 main.py:57] epoch 617, training loss: 7224.00, average training loss: 8665.76, base loss: 15705.47
[INFO 2017-06-29 12:03:23,636 main.py:57] epoch 618, training loss: 6937.03, average training loss: 8662.97, base loss: 15704.82
[INFO 2017-06-29 12:03:26,893 main.py:57] epoch 619, training loss: 7403.70, average training loss: 8660.93, base loss: 15706.58
[INFO 2017-06-29 12:03:30,139 main.py:57] epoch 620, training loss: 6729.12, average training loss: 8657.82, base loss: 15704.68
[INFO 2017-06-29 12:03:33,456 main.py:57] epoch 621, training loss: 7037.10, average training loss: 8655.22, base loss: 15703.12
[INFO 2017-06-29 12:03:36,698 main.py:57] epoch 622, training loss: 7301.97, average training loss: 8653.05, base loss: 15700.01
[INFO 2017-06-29 12:03:39,965 main.py:57] epoch 623, training loss: 6877.02, average training loss: 8650.20, base loss: 15698.12
[INFO 2017-06-29 12:03:43,325 main.py:57] epoch 624, training loss: 7511.57, average training loss: 8648.38, base loss: 15697.45
[INFO 2017-06-29 12:03:46,510 main.py:57] epoch 625, training loss: 7281.67, average training loss: 8646.19, base loss: 15697.02
[INFO 2017-06-29 12:03:49,813 main.py:57] epoch 626, training loss: 7039.72, average training loss: 8643.63, base loss: 15693.73
[INFO 2017-06-29 12:03:53,151 main.py:57] epoch 627, training loss: 8860.14, average training loss: 8643.98, base loss: 15694.20
[INFO 2017-06-29 12:03:56,405 main.py:57] epoch 628, training loss: 7915.22, average training loss: 8642.82, base loss: 15694.92
[INFO 2017-06-29 12:03:59,651 main.py:57] epoch 629, training loss: 6848.15, average training loss: 8639.97, base loss: 15693.00
[INFO 2017-06-29 12:04:02,828 main.py:57] epoch 630, training loss: 7332.26, average training loss: 8637.90, base loss: 15693.25
[INFO 2017-06-29 12:04:06,111 main.py:57] epoch 631, training loss: 6966.98, average training loss: 8635.25, base loss: 15693.46
[INFO 2017-06-29 12:04:09,308 main.py:57] epoch 632, training loss: 6900.11, average training loss: 8632.51, base loss: 15689.33
[INFO 2017-06-29 12:04:12,586 main.py:57] epoch 633, training loss: 7852.92, average training loss: 8631.28, base loss: 15688.91
[INFO 2017-06-29 12:04:15,860 main.py:57] epoch 634, training loss: 7606.23, average training loss: 8629.67, base loss: 15685.50
[INFO 2017-06-29 12:04:19,069 main.py:57] epoch 635, training loss: 7711.05, average training loss: 8628.22, base loss: 15685.30
[INFO 2017-06-29 12:04:22,456 main.py:57] epoch 636, training loss: 6853.26, average training loss: 8625.44, base loss: 15684.36
[INFO 2017-06-29 12:04:25,808 main.py:57] epoch 637, training loss: 8561.77, average training loss: 8625.34, base loss: 15689.45
[INFO 2017-06-29 12:04:29,139 main.py:57] epoch 638, training loss: 7160.48, average training loss: 8623.05, base loss: 15688.26
[INFO 2017-06-29 12:04:32,422 main.py:57] epoch 639, training loss: 8457.30, average training loss: 8622.79, base loss: 15690.53
[INFO 2017-06-29 12:04:35,636 main.py:57] epoch 640, training loss: 7196.25, average training loss: 8620.56, base loss: 15690.03
[INFO 2017-06-29 12:04:38,775 main.py:57] epoch 641, training loss: 7470.83, average training loss: 8618.77, base loss: 15688.76
[INFO 2017-06-29 12:04:42,120 main.py:57] epoch 642, training loss: 9279.44, average training loss: 8619.80, base loss: 15695.24
[INFO 2017-06-29 12:04:45,517 main.py:57] epoch 643, training loss: 7209.09, average training loss: 8617.61, base loss: 15694.64
[INFO 2017-06-29 12:04:49,052 main.py:57] epoch 644, training loss: 6707.75, average training loss: 8614.65, base loss: 15691.81
[INFO 2017-06-29 12:04:52,402 main.py:57] epoch 645, training loss: 6306.34, average training loss: 8611.07, base loss: 15689.55
[INFO 2017-06-29 12:04:55,645 main.py:57] epoch 646, training loss: 7928.81, average training loss: 8610.02, base loss: 15689.74
[INFO 2017-06-29 12:04:58,819 main.py:57] epoch 647, training loss: 7092.62, average training loss: 8607.68, base loss: 15686.02
[INFO 2017-06-29 12:05:02,018 main.py:57] epoch 648, training loss: 7402.65, average training loss: 8605.82, base loss: 15686.04
[INFO 2017-06-29 12:05:05,311 main.py:57] epoch 649, training loss: 7993.65, average training loss: 8604.88, base loss: 15687.14
[INFO 2017-06-29 12:05:08,577 main.py:57] epoch 650, training loss: 7256.30, average training loss: 8602.81, base loss: 15688.64
[INFO 2017-06-29 12:05:11,777 main.py:57] epoch 651, training loss: 8364.05, average training loss: 8602.44, base loss: 15691.66
[INFO 2017-06-29 12:05:15,058 main.py:57] epoch 652, training loss: 7747.52, average training loss: 8601.13, base loss: 15694.53
[INFO 2017-06-29 12:05:18,430 main.py:57] epoch 653, training loss: 8523.65, average training loss: 8601.01, base loss: 15695.89
[INFO 2017-06-29 12:05:21,705 main.py:57] epoch 654, training loss: 7539.45, average training loss: 8599.39, base loss: 15694.67
[INFO 2017-06-29 12:05:25,106 main.py:57] epoch 655, training loss: 7236.86, average training loss: 8597.31, base loss: 15692.24
[INFO 2017-06-29 12:05:28,286 main.py:57] epoch 656, training loss: 6944.42, average training loss: 8594.80, base loss: 15691.60
[INFO 2017-06-29 12:05:31,625 main.py:57] epoch 657, training loss: 7499.00, average training loss: 8593.13, base loss: 15692.12
[INFO 2017-06-29 12:05:34,909 main.py:57] epoch 658, training loss: 6962.36, average training loss: 8590.66, base loss: 15690.61
[INFO 2017-06-29 12:05:38,135 main.py:57] epoch 659, training loss: 6784.24, average training loss: 8587.92, base loss: 15691.14
[INFO 2017-06-29 12:05:41,382 main.py:57] epoch 660, training loss: 7329.18, average training loss: 8586.02, base loss: 15691.35
[INFO 2017-06-29 12:05:44,732 main.py:57] epoch 661, training loss: 7986.52, average training loss: 8585.11, base loss: 15693.10
[INFO 2017-06-29 12:05:48,039 main.py:57] epoch 662, training loss: 7646.48, average training loss: 8583.70, base loss: 15689.62
[INFO 2017-06-29 12:05:51,256 main.py:57] epoch 663, training loss: 7524.07, average training loss: 8582.10, base loss: 15689.38
[INFO 2017-06-29 12:05:54,710 main.py:57] epoch 664, training loss: 7639.43, average training loss: 8580.68, base loss: 15690.35
[INFO 2017-06-29 12:05:57,992 main.py:57] epoch 665, training loss: 7429.93, average training loss: 8578.96, base loss: 15688.46
[INFO 2017-06-29 12:06:01,288 main.py:57] epoch 666, training loss: 7912.66, average training loss: 8577.96, base loss: 15686.54
[INFO 2017-06-29 12:06:04,408 main.py:57] epoch 667, training loss: 7189.32, average training loss: 8575.88, base loss: 15687.10
[INFO 2017-06-29 12:06:07,889 main.py:57] epoch 668, training loss: 8727.19, average training loss: 8576.10, base loss: 15690.78
[INFO 2017-06-29 12:06:11,140 main.py:57] epoch 669, training loss: 6867.42, average training loss: 8573.55, base loss: 15689.66
