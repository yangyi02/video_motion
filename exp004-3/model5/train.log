[INFO 2017-06-29 13:07:07,828 main.py:175] Namespace(batch_size=32, display=False, flow_dir='flow', flow_video_dir='flow-video', flow_video_fps=1, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=4, num_channel=3, num_inputs=2, save_dir='./model', test=False, test_dir='/home/yi/Downloads/mpii-test-64', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='/home/yi/Downloads/mpii-64', train_epoch=100000)
[INFO 2017-06-29 13:07:12,318 main.py:57] epoch 0, training loss: 42071.80, average training loss: 42071.80, base loss: 15547.25
[INFO 2017-06-29 13:07:14,270 main.py:57] epoch 1, training loss: 34113.55, average training loss: 38092.68, base loss: 15071.12
[INFO 2017-06-29 13:07:16,300 main.py:57] epoch 2, training loss: 31754.46, average training loss: 35979.94, base loss: 15504.11
[INFO 2017-06-29 13:07:18,287 main.py:57] epoch 3, training loss: 29533.60, average training loss: 34368.35, base loss: 16130.20
[INFO 2017-06-29 13:07:20,735 main.py:57] epoch 4, training loss: 24359.29, average training loss: 32366.54, base loss: 15669.89
[INFO 2017-06-29 13:07:23,262 main.py:57] epoch 5, training loss: 23471.65, average training loss: 30884.06, base loss: 15556.15
[INFO 2017-06-29 13:07:25,734 main.py:57] epoch 6, training loss: 23162.93, average training loss: 29781.04, base loss: 15648.20
[INFO 2017-06-29 13:07:28,221 main.py:57] epoch 7, training loss: 19484.94, average training loss: 28494.03, base loss: 15447.55
[INFO 2017-06-29 13:07:30,816 main.py:57] epoch 8, training loss: 18929.25, average training loss: 27431.27, base loss: 15249.67
[INFO 2017-06-29 13:07:33,365 main.py:57] epoch 9, training loss: 18977.13, average training loss: 26585.86, base loss: 15302.39
[INFO 2017-06-29 13:07:35,943 main.py:57] epoch 10, training loss: 18669.61, average training loss: 25866.20, base loss: 15379.85
[INFO 2017-06-29 13:07:38,496 main.py:57] epoch 11, training loss: 16834.68, average training loss: 25113.57, base loss: 15394.88
[INFO 2017-06-29 13:07:41,048 main.py:57] epoch 12, training loss: 17750.93, average training loss: 24547.22, base loss: 15512.68
[INFO 2017-06-29 13:07:43,552 main.py:57] epoch 13, training loss: 16818.58, average training loss: 23995.17, base loss: 15612.72
[INFO 2017-06-29 13:07:46,084 main.py:57] epoch 14, training loss: 14878.39, average training loss: 23387.39, base loss: 15555.88
[INFO 2017-06-29 13:07:48,589 main.py:57] epoch 15, training loss: 15628.65, average training loss: 22902.47, base loss: 15582.48
[INFO 2017-06-29 13:07:51,238 main.py:57] epoch 16, training loss: 14477.95, average training loss: 22406.91, base loss: 15541.06
[INFO 2017-06-29 13:07:53,797 main.py:57] epoch 17, training loss: 14725.43, average training loss: 21980.16, base loss: 15538.03
[INFO 2017-06-29 13:07:56,320 main.py:57] epoch 18, training loss: 15216.87, average training loss: 21624.19, base loss: 15570.30
[INFO 2017-06-29 13:07:58,856 main.py:57] epoch 19, training loss: 15080.77, average training loss: 21297.02, base loss: 15589.28
[INFO 2017-06-29 13:08:01,350 main.py:57] epoch 20, training loss: 13685.34, average training loss: 20934.56, base loss: 15553.88
[INFO 2017-06-29 13:08:03,840 main.py:57] epoch 21, training loss: 15073.26, average training loss: 20668.14, base loss: 15619.00
[INFO 2017-06-29 13:08:06,375 main.py:57] epoch 22, training loss: 13642.07, average training loss: 20362.66, base loss: 15589.47
[INFO 2017-06-29 13:08:08,964 main.py:57] epoch 23, training loss: 13544.78, average training loss: 20078.58, base loss: 15576.51
[INFO 2017-06-29 13:08:11,612 main.py:57] epoch 24, training loss: 14512.35, average training loss: 19855.93, base loss: 15597.99
[INFO 2017-06-29 13:08:14,172 main.py:57] epoch 25, training loss: 15290.04, average training loss: 19680.32, base loss: 15672.11
[INFO 2017-06-29 13:08:16,666 main.py:57] epoch 26, training loss: 13244.44, average training loss: 19441.95, base loss: 15660.51
[INFO 2017-06-29 13:08:19,164 main.py:57] epoch 27, training loss: 12633.63, average training loss: 19198.80, base loss: 15625.39
[INFO 2017-06-29 13:08:21,760 main.py:57] epoch 28, training loss: 14327.33, average training loss: 19030.82, base loss: 15659.49
[INFO 2017-06-29 13:08:24,317 main.py:57] epoch 29, training loss: 13012.75, average training loss: 18830.22, base loss: 15643.08
[INFO 2017-06-29 13:08:26,881 main.py:57] epoch 30, training loss: 12267.82, average training loss: 18618.53, base loss: 15593.96
[INFO 2017-06-29 13:08:29,363 main.py:57] epoch 31, training loss: 12625.66, average training loss: 18431.25, base loss: 15572.07
[INFO 2017-06-29 13:08:31,858 main.py:57] epoch 32, training loss: 14007.03, average training loss: 18297.18, base loss: 15608.25
[INFO 2017-06-29 13:08:34,369 main.py:57] epoch 33, training loss: 12863.98, average training loss: 18137.38, base loss: 15596.39
[INFO 2017-06-29 13:08:36,855 main.py:57] epoch 34, training loss: 12922.10, average training loss: 17988.37, base loss: 15593.24
[INFO 2017-06-29 13:08:39,390 main.py:57] epoch 35, training loss: 10753.60, average training loss: 17787.41, base loss: 15523.18
[INFO 2017-06-29 13:08:41,905 main.py:57] epoch 36, training loss: 13084.53, average training loss: 17660.30, base loss: 15529.80
[INFO 2017-06-29 13:08:44,409 main.py:57] epoch 37, training loss: 12961.26, average training loss: 17536.64, base loss: 15528.28
[INFO 2017-06-29 13:08:47,005 main.py:57] epoch 38, training loss: 12502.92, average training loss: 17407.57, base loss: 15513.26
[INFO 2017-06-29 13:08:49,527 main.py:57] epoch 39, training loss: 12359.26, average training loss: 17281.37, base loss: 15499.32
[INFO 2017-06-29 13:08:52,038 main.py:57] epoch 40, training loss: 11915.53, average training loss: 17150.49, base loss: 15470.60
[INFO 2017-06-29 13:08:54,501 main.py:57] epoch 41, training loss: 12125.96, average training loss: 17030.86, base loss: 15452.89
[INFO 2017-06-29 13:08:57,117 main.py:57] epoch 42, training loss: 13789.93, average training loss: 16955.49, base loss: 15484.77
[INFO 2017-06-29 13:08:59,652 main.py:57] epoch 43, training loss: 12242.44, average training loss: 16848.37, base loss: 15468.51
[INFO 2017-06-29 13:09:02,146 main.py:57] epoch 44, training loss: 13009.23, average training loss: 16763.06, base loss: 15474.71
[INFO 2017-06-29 13:09:04,612 main.py:57] epoch 45, training loss: 14564.79, average training loss: 16715.27, base loss: 15524.44
[INFO 2017-06-29 13:09:07,202 main.py:57] epoch 46, training loss: 11218.02, average training loss: 16598.31, base loss: 15483.31
[INFO 2017-06-29 13:09:09,738 main.py:57] epoch 47, training loss: 12408.78, average training loss: 16511.03, base loss: 15478.28
[INFO 2017-06-29 13:09:12,204 main.py:57] epoch 48, training loss: 12910.53, average training loss: 16437.55, base loss: 15491.16
[INFO 2017-06-29 13:09:14,710 main.py:57] epoch 49, training loss: 14488.98, average training loss: 16398.58, base loss: 15535.30
[INFO 2017-06-29 13:09:17,189 main.py:57] epoch 50, training loss: 13042.62, average training loss: 16332.77, base loss: 15537.37
[INFO 2017-06-29 13:09:19,769 main.py:57] epoch 51, training loss: 12523.98, average training loss: 16259.53, base loss: 15535.71
[INFO 2017-06-29 13:09:22,288 main.py:57] epoch 52, training loss: 13189.56, average training loss: 16201.60, base loss: 15549.65
[INFO 2017-06-29 13:09:24,802 main.py:57] epoch 53, training loss: 12468.45, average training loss: 16132.47, base loss: 15542.24
[INFO 2017-06-29 13:09:27,432 main.py:57] epoch 54, training loss: 13141.72, average training loss: 16078.09, base loss: 15553.71
[INFO 2017-06-29 13:09:29,911 main.py:57] epoch 55, training loss: 12499.65, average training loss: 16014.19, base loss: 15549.60
[INFO 2017-06-29 13:09:32,438 main.py:57] epoch 56, training loss: 11428.42, average training loss: 15933.74, base loss: 15521.15
[INFO 2017-06-29 13:09:35,085 main.py:57] epoch 57, training loss: 12625.16, average training loss: 15876.70, base loss: 15522.05
[INFO 2017-06-29 13:09:37,615 main.py:57] epoch 58, training loss: 12220.35, average training loss: 15814.72, base loss: 15511.29
[INFO 2017-06-29 13:09:40,147 main.py:57] epoch 59, training loss: 12759.46, average training loss: 15763.80, base loss: 15519.06
[INFO 2017-06-29 13:09:42,663 main.py:57] epoch 60, training loss: 12978.64, average training loss: 15718.14, base loss: 15533.08
[INFO 2017-06-29 13:09:45,170 main.py:57] epoch 61, training loss: 11648.18, average training loss: 15652.50, base loss: 15517.11
[INFO 2017-06-29 13:09:47,705 main.py:57] epoch 62, training loss: 12513.11, average training loss: 15602.67, base loss: 15523.92
[INFO 2017-06-29 13:09:50,223 main.py:57] epoch 63, training loss: 12431.88, average training loss: 15553.13, base loss: 15525.62
[INFO 2017-06-29 13:09:52,785 main.py:57] epoch 64, training loss: 12988.13, average training loss: 15513.66, base loss: 15536.82
[INFO 2017-06-29 13:09:55,322 main.py:57] epoch 65, training loss: 12526.69, average training loss: 15468.41, base loss: 15541.27
[INFO 2017-06-29 13:09:57,895 main.py:57] epoch 66, training loss: 12535.80, average training loss: 15424.64, base loss: 15542.17
[INFO 2017-06-29 13:10:00,462 main.py:57] epoch 67, training loss: 12900.74, average training loss: 15387.52, base loss: 15551.68
[INFO 2017-06-29 13:10:03,038 main.py:57] epoch 68, training loss: 14012.91, average training loss: 15367.60, base loss: 15579.57
[INFO 2017-06-29 13:10:05,645 main.py:57] epoch 69, training loss: 12864.83, average training loss: 15331.84, base loss: 15590.34
[INFO 2017-06-29 13:10:08,192 main.py:57] epoch 70, training loss: 11607.02, average training loss: 15279.38, base loss: 15574.33
[INFO 2017-06-29 13:10:10,727 main.py:57] epoch 71, training loss: 11569.74, average training loss: 15227.86, base loss: 15556.80
[INFO 2017-06-29 13:10:13,284 main.py:57] epoch 72, training loss: 12739.55, average training loss: 15193.77, base loss: 15566.56
[INFO 2017-06-29 13:10:15,774 main.py:57] epoch 73, training loss: 12786.63, average training loss: 15161.24, base loss: 15569.62
[INFO 2017-06-29 13:10:18,379 main.py:57] epoch 74, training loss: 13887.38, average training loss: 15144.26, base loss: 15593.54
[INFO 2017-06-29 13:10:20,906 main.py:57] epoch 75, training loss: 11636.16, average training loss: 15098.10, base loss: 15581.85
[INFO 2017-06-29 13:10:23,504 main.py:57] epoch 76, training loss: 13259.90, average training loss: 15074.23, base loss: 15601.41
[INFO 2017-06-29 13:10:26,053 main.py:57] epoch 77, training loss: 12087.45, average training loss: 15035.94, base loss: 15598.23
[INFO 2017-06-29 13:10:28,708 main.py:57] epoch 78, training loss: 12228.36, average training loss: 15000.40, base loss: 15596.88
[INFO 2017-06-29 13:10:31,267 main.py:57] epoch 79, training loss: 11945.28, average training loss: 14962.21, base loss: 15598.32
[INFO 2017-06-29 13:10:33,752 main.py:57] epoch 80, training loss: 10739.08, average training loss: 14910.07, base loss: 15574.53
[INFO 2017-06-29 13:10:36,326 main.py:57] epoch 81, training loss: 12279.10, average training loss: 14877.99, base loss: 15578.33
[INFO 2017-06-29 13:10:38,937 main.py:57] epoch 82, training loss: 11996.50, average training loss: 14843.27, base loss: 15578.36
[INFO 2017-06-29 13:10:41,574 main.py:57] epoch 83, training loss: 11976.61, average training loss: 14809.14, base loss: 15575.72
[INFO 2017-06-29 13:10:44,134 main.py:57] epoch 84, training loss: 11637.90, average training loss: 14771.83, base loss: 15570.50
[INFO 2017-06-29 13:10:46,670 main.py:57] epoch 85, training loss: 11991.00, average training loss: 14739.50, base loss: 15569.28
[INFO 2017-06-29 13:10:49,186 main.py:57] epoch 86, training loss: 11172.57, average training loss: 14698.50, base loss: 15554.01
[INFO 2017-06-29 13:10:51,670 main.py:57] epoch 87, training loss: 12158.61, average training loss: 14669.64, base loss: 15555.52
[INFO 2017-06-29 13:10:54,199 main.py:57] epoch 88, training loss: 12653.96, average training loss: 14646.99, base loss: 15560.12
[INFO 2017-06-29 13:10:56,757 main.py:57] epoch 89, training loss: 13629.54, average training loss: 14635.68, base loss: 15585.35
[INFO 2017-06-29 13:10:59,294 main.py:57] epoch 90, training loss: 12168.90, average training loss: 14608.58, base loss: 15584.06
[INFO 2017-06-29 13:11:01,814 main.py:57] epoch 91, training loss: 12455.55, average training loss: 14585.17, base loss: 15589.75
[INFO 2017-06-29 13:11:04,400 main.py:57] epoch 92, training loss: 12271.26, average training loss: 14560.29, base loss: 15588.39
[INFO 2017-06-29 13:11:06,957 main.py:57] epoch 93, training loss: 11354.56, average training loss: 14526.19, base loss: 15576.71
[INFO 2017-06-29 13:11:09,475 main.py:57] epoch 94, training loss: 13576.82, average training loss: 14516.20, base loss: 15591.24
[INFO 2017-06-29 13:11:12,064 main.py:57] epoch 95, training loss: 12270.20, average training loss: 14492.80, base loss: 15597.11
[INFO 2017-06-29 13:11:14,637 main.py:57] epoch 96, training loss: 12111.80, average training loss: 14468.25, base loss: 15597.44
[INFO 2017-06-29 13:11:17,174 main.py:57] epoch 97, training loss: 10974.30, average training loss: 14432.60, base loss: 15584.66
[INFO 2017-06-29 13:11:19,699 main.py:57] epoch 98, training loss: 10773.06, average training loss: 14395.64, base loss: 15570.84
[INFO 2017-06-29 13:11:22,256 main.py:57] epoch 99, training loss: 11698.18, average training loss: 14368.66, base loss: 15563.45
[INFO 2017-06-29 13:11:22,256 main.py:59] epoch 99, testing
[INFO 2017-06-29 13:11:33,341 main.py:104] average testing loss: 10956.58, base loss: 16157.00
[INFO 2017-06-29 13:11:33,341 main.py:105] improve_loss: 5200.43, improve_percent: 0.32
[INFO 2017-06-29 13:11:33,342 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 13:11:33,355 main.py:71] current best improved percent: 0.32
[INFO 2017-06-29 13:11:35,860 main.py:57] epoch 100, training loss: 12307.95, average training loss: 14348.26, base loss: 15570.13
[INFO 2017-06-29 13:11:38,407 main.py:57] epoch 101, training loss: 12568.55, average training loss: 14330.81, base loss: 15575.00
[INFO 2017-06-29 13:11:40,963 main.py:57] epoch 102, training loss: 11683.19, average training loss: 14305.10, base loss: 15580.08
[INFO 2017-06-29 13:11:43,484 main.py:57] epoch 103, training loss: 12907.79, average training loss: 14291.67, base loss: 15597.20
[INFO 2017-06-29 13:11:46,017 main.py:57] epoch 104, training loss: 11927.68, average training loss: 14269.15, base loss: 15603.65
[INFO 2017-06-29 13:11:48,524 main.py:57] epoch 105, training loss: 11585.52, average training loss: 14243.84, base loss: 15596.92
[INFO 2017-06-29 13:11:51,149 main.py:57] epoch 106, training loss: 11512.73, average training loss: 14218.31, base loss: 15588.98
[INFO 2017-06-29 13:11:53,698 main.py:57] epoch 107, training loss: 11335.54, average training loss: 14191.62, base loss: 15586.36
[INFO 2017-06-29 13:11:56,217 main.py:57] epoch 108, training loss: 10369.26, average training loss: 14156.55, base loss: 15575.12
[INFO 2017-06-29 13:11:58,726 main.py:57] epoch 109, training loss: 9623.26, average training loss: 14115.34, base loss: 15550.14
[INFO 2017-06-29 13:12:01,264 main.py:57] epoch 110, training loss: 11451.45, average training loss: 14091.34, base loss: 15546.45
[INFO 2017-06-29 13:12:03,752 main.py:57] epoch 111, training loss: 11457.19, average training loss: 14067.82, base loss: 15549.77
[INFO 2017-06-29 13:12:06,311 main.py:57] epoch 112, training loss: 11660.14, average training loss: 14046.52, base loss: 15546.03
[INFO 2017-06-29 13:12:08,857 main.py:57] epoch 113, training loss: 11469.45, average training loss: 14023.91, base loss: 15546.11
[INFO 2017-06-29 13:12:11,528 main.py:57] epoch 114, training loss: 10899.04, average training loss: 13996.74, base loss: 15538.03
[INFO 2017-06-29 13:12:14,098 main.py:57] epoch 115, training loss: 11815.94, average training loss: 13977.94, base loss: 15537.23
[INFO 2017-06-29 13:12:16,693 main.py:57] epoch 116, training loss: 12541.42, average training loss: 13965.66, base loss: 15551.62
[INFO 2017-06-29 13:12:19,269 main.py:57] epoch 117, training loss: 12593.86, average training loss: 13954.03, base loss: 15568.29
[INFO 2017-06-29 13:12:21,801 main.py:57] epoch 118, training loss: 9926.78, average training loss: 13920.19, base loss: 15550.17
[INFO 2017-06-29 13:12:24,358 main.py:57] epoch 119, training loss: 10589.62, average training loss: 13892.44, base loss: 15537.98
[INFO 2017-06-29 13:12:26,934 main.py:57] epoch 120, training loss: 10398.40, average training loss: 13863.56, base loss: 15525.10
[INFO 2017-06-29 13:12:29,523 main.py:57] epoch 121, training loss: 11019.06, average training loss: 13840.25, base loss: 15522.23
[INFO 2017-06-29 13:12:32,066 main.py:57] epoch 122, training loss: 10538.69, average training loss: 13813.40, base loss: 15517.10
[INFO 2017-06-29 13:12:34,615 main.py:57] epoch 123, training loss: 12000.96, average training loss: 13798.79, base loss: 15520.60
[INFO 2017-06-29 13:12:37,130 main.py:57] epoch 124, training loss: 10813.45, average training loss: 13774.90, base loss: 15516.60
[INFO 2017-06-29 13:12:39,698 main.py:57] epoch 125, training loss: 10630.67, average training loss: 13749.95, base loss: 15513.47
[INFO 2017-06-29 13:12:42,228 main.py:57] epoch 126, training loss: 11218.59, average training loss: 13730.02, base loss: 15511.82
[INFO 2017-06-29 13:12:44,734 main.py:57] epoch 127, training loss: 9704.72, average training loss: 13698.57, base loss: 15496.48
[INFO 2017-06-29 13:12:47,268 main.py:57] epoch 128, training loss: 11532.15, average training loss: 13681.78, base loss: 15503.50
[INFO 2017-06-29 13:12:49,807 main.py:57] epoch 129, training loss: 11401.95, average training loss: 13664.24, base loss: 15500.75
[INFO 2017-06-29 13:12:52,315 main.py:57] epoch 130, training loss: 12172.11, average training loss: 13652.85, base loss: 15517.11
[INFO 2017-06-29 13:12:54,894 main.py:57] epoch 131, training loss: 11335.96, average training loss: 13635.30, base loss: 15518.82
[INFO 2017-06-29 13:12:57,375 main.py:57] epoch 132, training loss: 11282.28, average training loss: 13617.60, base loss: 15521.73
[INFO 2017-06-29 13:12:59,890 main.py:57] epoch 133, training loss: 10669.73, average training loss: 13595.61, base loss: 15519.81
[INFO 2017-06-29 13:13:02,517 main.py:57] epoch 134, training loss: 12007.16, average training loss: 13583.84, base loss: 15538.54
[INFO 2017-06-29 13:13:04,984 main.py:57] epoch 135, training loss: 10696.00, average training loss: 13562.61, base loss: 15535.00
[INFO 2017-06-29 13:13:07,587 main.py:57] epoch 136, training loss: 11922.57, average training loss: 13550.63, base loss: 15545.24
[INFO 2017-06-29 13:13:10,126 main.py:57] epoch 137, training loss: 10461.71, average training loss: 13528.25, base loss: 15537.81
[INFO 2017-06-29 13:13:12,654 main.py:57] epoch 138, training loss: 11038.41, average training loss: 13510.34, base loss: 15535.50
[INFO 2017-06-29 13:13:15,224 main.py:57] epoch 139, training loss: 11993.12, average training loss: 13499.50, base loss: 15541.22
[INFO 2017-06-29 13:13:17,773 main.py:57] epoch 140, training loss: 9529.06, average training loss: 13471.34, base loss: 15525.71
[INFO 2017-06-29 13:13:20,312 main.py:57] epoch 141, training loss: 11991.75, average training loss: 13460.92, base loss: 15528.24
[INFO 2017-06-29 13:13:22,839 main.py:57] epoch 142, training loss: 11261.48, average training loss: 13445.54, base loss: 15526.56
[INFO 2017-06-29 13:13:25,351 main.py:57] epoch 143, training loss: 11597.94, average training loss: 13432.71, base loss: 15527.73
[INFO 2017-06-29 13:13:27,947 main.py:57] epoch 144, training loss: 11374.28, average training loss: 13418.51, base loss: 15530.59
[INFO 2017-06-29 13:13:30,483 main.py:57] epoch 145, training loss: 11455.43, average training loss: 13405.07, base loss: 15536.41
[INFO 2017-06-29 13:13:33,001 main.py:57] epoch 146, training loss: 9458.35, average training loss: 13378.22, base loss: 15518.52
[INFO 2017-06-29 13:13:35,474 main.py:57] epoch 147, training loss: 11300.95, average training loss: 13364.19, base loss: 15520.67
[INFO 2017-06-29 13:13:38,020 main.py:57] epoch 148, training loss: 10633.55, average training loss: 13345.86, base loss: 15516.12
[INFO 2017-06-29 13:13:40,500 main.py:57] epoch 149, training loss: 11290.27, average training loss: 13332.15, base loss: 15514.22
[INFO 2017-06-29 13:13:43,095 main.py:57] epoch 150, training loss: 10535.02, average training loss: 13313.63, base loss: 15514.05
[INFO 2017-06-29 13:13:45,605 main.py:57] epoch 151, training loss: 10091.05, average training loss: 13292.43, base loss: 15507.14
[INFO 2017-06-29 13:13:48,150 main.py:57] epoch 152, training loss: 11361.46, average training loss: 13279.81, base loss: 15508.50
[INFO 2017-06-29 13:13:50,732 main.py:57] epoch 153, training loss: 11842.21, average training loss: 13270.47, base loss: 15513.27
[INFO 2017-06-29 13:13:53,248 main.py:57] epoch 154, training loss: 10550.55, average training loss: 13252.93, base loss: 15509.92
[INFO 2017-06-29 13:13:55,815 main.py:57] epoch 155, training loss: 11388.57, average training loss: 13240.97, base loss: 15514.16
[INFO 2017-06-29 13:13:58,406 main.py:57] epoch 156, training loss: 10787.21, average training loss: 13225.35, base loss: 15513.51
[INFO 2017-06-29 13:14:00,983 main.py:57] epoch 157, training loss: 11363.30, average training loss: 13213.56, base loss: 15517.43
[INFO 2017-06-29 13:14:03,532 main.py:57] epoch 158, training loss: 10255.04, average training loss: 13194.95, base loss: 15515.06
[INFO 2017-06-29 13:14:06,007 main.py:57] epoch 159, training loss: 11156.26, average training loss: 13182.21, base loss: 15518.69
[INFO 2017-06-29 13:14:08,544 main.py:57] epoch 160, training loss: 11264.78, average training loss: 13170.30, base loss: 15518.52
[INFO 2017-06-29 13:14:11,078 main.py:57] epoch 161, training loss: 10809.06, average training loss: 13155.73, base loss: 15520.24
[INFO 2017-06-29 13:14:13,563 main.py:57] epoch 162, training loss: 9166.21, average training loss: 13131.25, base loss: 15507.22
[INFO 2017-06-29 13:14:16,081 main.py:57] epoch 163, training loss: 9971.14, average training loss: 13111.98, base loss: 15498.09
[INFO 2017-06-29 13:14:18,559 main.py:57] epoch 164, training loss: 10213.82, average training loss: 13094.42, base loss: 15491.62
[INFO 2017-06-29 13:14:21,076 main.py:57] epoch 165, training loss: 10235.08, average training loss: 13077.19, base loss: 15488.08
[INFO 2017-06-29 13:14:23,557 main.py:57] epoch 166, training loss: 11050.60, average training loss: 13065.06, base loss: 15488.04
[INFO 2017-06-29 13:14:26,077 main.py:57] epoch 167, training loss: 11155.26, average training loss: 13053.69, base loss: 15484.76
[INFO 2017-06-29 13:14:28,623 main.py:57] epoch 168, training loss: 10347.34, average training loss: 13037.68, base loss: 15479.19
[INFO 2017-06-29 13:14:31,218 main.py:57] epoch 169, training loss: 10259.09, average training loss: 13021.33, base loss: 15472.89
[INFO 2017-06-29 13:14:33,827 main.py:57] epoch 170, training loss: 11506.34, average training loss: 13012.47, base loss: 15479.37
[INFO 2017-06-29 13:14:36,348 main.py:57] epoch 171, training loss: 9567.81, average training loss: 12992.44, base loss: 15468.87
[INFO 2017-06-29 13:14:38,901 main.py:57] epoch 172, training loss: 10376.11, average training loss: 12977.32, base loss: 15461.99
[INFO 2017-06-29 13:14:41,413 main.py:57] epoch 173, training loss: 10658.78, average training loss: 12964.00, base loss: 15459.14
[INFO 2017-06-29 13:14:43,932 main.py:57] epoch 174, training loss: 10539.70, average training loss: 12950.14, base loss: 15454.99
[INFO 2017-06-29 13:14:46,417 main.py:57] epoch 175, training loss: 10226.73, average training loss: 12934.67, base loss: 15451.76
[INFO 2017-06-29 13:14:48,988 main.py:57] epoch 176, training loss: 11015.90, average training loss: 12923.83, base loss: 15457.17
[INFO 2017-06-29 13:14:51,556 main.py:57] epoch 177, training loss: 10114.44, average training loss: 12908.05, base loss: 15457.78
[INFO 2017-06-29 13:14:54,085 main.py:57] epoch 178, training loss: 11719.53, average training loss: 12901.41, base loss: 15458.61
[INFO 2017-06-29 13:14:56,671 main.py:57] epoch 179, training loss: 11022.45, average training loss: 12890.97, base loss: 15460.65
[INFO 2017-06-29 13:14:59,182 main.py:57] epoch 180, training loss: 11026.41, average training loss: 12880.67, base loss: 15463.40
[INFO 2017-06-29 13:15:01,825 main.py:57] epoch 181, training loss: 10296.74, average training loss: 12866.47, base loss: 15458.71
[INFO 2017-06-29 13:15:04,449 main.py:57] epoch 182, training loss: 9630.41, average training loss: 12848.78, base loss: 15449.66
[INFO 2017-06-29 13:15:06,991 main.py:57] epoch 183, training loss: 10144.49, average training loss: 12834.09, base loss: 15443.72
[INFO 2017-06-29 13:15:09,487 main.py:57] epoch 184, training loss: 10963.42, average training loss: 12823.98, base loss: 15444.68
[INFO 2017-06-29 13:15:12,035 main.py:57] epoch 185, training loss: 11904.23, average training loss: 12819.03, base loss: 15451.68
[INFO 2017-06-29 13:15:14,533 main.py:57] epoch 186, training loss: 9764.24, average training loss: 12802.70, base loss: 15445.36
[INFO 2017-06-29 13:15:17,175 main.py:57] epoch 187, training loss: 10611.32, average training loss: 12791.04, base loss: 15444.58
[INFO 2017-06-29 13:15:19,758 main.py:57] epoch 188, training loss: 10645.58, average training loss: 12779.69, base loss: 15440.96
[INFO 2017-06-29 13:15:22,341 main.py:57] epoch 189, training loss: 9765.92, average training loss: 12763.83, base loss: 15432.51
[INFO 2017-06-29 13:15:24,863 main.py:57] epoch 190, training loss: 11811.39, average training loss: 12758.84, base loss: 15441.73
[INFO 2017-06-29 13:15:27,412 main.py:57] epoch 191, training loss: 11601.17, average training loss: 12752.81, base loss: 15446.04
[INFO 2017-06-29 13:15:29,950 main.py:57] epoch 192, training loss: 9582.76, average training loss: 12736.38, base loss: 15438.40
[INFO 2017-06-29 13:15:32,493 main.py:57] epoch 193, training loss: 11121.42, average training loss: 12728.06, base loss: 15440.83
[INFO 2017-06-29 13:15:34,962 main.py:57] epoch 194, training loss: 9800.50, average training loss: 12713.05, base loss: 15433.02
[INFO 2017-06-29 13:15:37,486 main.py:57] epoch 195, training loss: 10680.02, average training loss: 12702.67, base loss: 15430.52
[INFO 2017-06-29 13:15:40,086 main.py:57] epoch 196, training loss: 10762.00, average training loss: 12692.82, base loss: 15434.85
[INFO 2017-06-29 13:15:42,652 main.py:57] epoch 197, training loss: 10697.69, average training loss: 12682.75, base loss: 15435.75
[INFO 2017-06-29 13:15:45,139 main.py:57] epoch 198, training loss: 11870.50, average training loss: 12678.66, base loss: 15449.46
[INFO 2017-06-29 13:15:47,595 main.py:57] epoch 199, training loss: 11304.83, average training loss: 12671.80, base loss: 15459.17
[INFO 2017-06-29 13:15:47,596 main.py:59] epoch 199, testing
[INFO 2017-06-29 13:15:58,709 main.py:104] average testing loss: 9881.55, base loss: 15983.26
[INFO 2017-06-29 13:15:58,709 main.py:105] improve_loss: 6101.71, improve_percent: 0.38
[INFO 2017-06-29 13:15:58,711 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 13:15:58,724 main.py:71] current best improved percent: 0.38
[INFO 2017-06-29 13:16:01,264 main.py:57] epoch 200, training loss: 11039.79, average training loss: 12663.68, base loss: 15457.16
[INFO 2017-06-29 13:16:03,819 main.py:57] epoch 201, training loss: 10126.27, average training loss: 12651.11, base loss: 15453.37
[INFO 2017-06-29 13:16:06,316 main.py:57] epoch 202, training loss: 9998.14, average training loss: 12638.05, base loss: 15450.93
[INFO 2017-06-29 13:16:08,891 main.py:57] epoch 203, training loss: 10754.08, average training loss: 12628.81, base loss: 15452.45
[INFO 2017-06-29 13:16:11,516 main.py:57] epoch 204, training loss: 10939.29, average training loss: 12620.57, base loss: 15455.82
[INFO 2017-06-29 13:16:14,063 main.py:57] epoch 205, training loss: 10615.74, average training loss: 12610.84, base loss: 15454.55
[INFO 2017-06-29 13:16:16,634 main.py:57] epoch 206, training loss: 11656.01, average training loss: 12606.22, base loss: 15458.97
[INFO 2017-06-29 13:16:19,151 main.py:57] epoch 207, training loss: 10266.92, average training loss: 12594.98, base loss: 15458.30
[INFO 2017-06-29 13:16:21,672 main.py:57] epoch 208, training loss: 10134.02, average training loss: 12583.20, base loss: 15456.58
[INFO 2017-06-29 13:16:24,203 main.py:57] epoch 209, training loss: 9312.71, average training loss: 12567.63, base loss: 15450.16
[INFO 2017-06-29 13:16:26,763 main.py:57] epoch 210, training loss: 10132.46, average training loss: 12556.09, base loss: 15449.01
[INFO 2017-06-29 13:16:29,356 main.py:57] epoch 211, training loss: 10313.90, average training loss: 12545.51, base loss: 15451.31
[INFO 2017-06-29 13:16:31,832 main.py:57] epoch 212, training loss: 11730.27, average training loss: 12541.68, base loss: 15463.15
[INFO 2017-06-29 13:16:34,357 main.py:57] epoch 213, training loss: 10328.47, average training loss: 12531.34, base loss: 15459.75
[INFO 2017-06-29 13:16:36,875 main.py:57] epoch 214, training loss: 10684.89, average training loss: 12522.75, base loss: 15458.03
[INFO 2017-06-29 13:16:39,425 main.py:57] epoch 215, training loss: 10303.08, average training loss: 12512.48, base loss: 15454.77
[INFO 2017-06-29 13:16:41,890 main.py:57] epoch 216, training loss: 10341.12, average training loss: 12502.47, base loss: 15454.85
[INFO 2017-06-29 13:16:44,437 main.py:57] epoch 217, training loss: 9758.35, average training loss: 12489.88, base loss: 15444.09
[INFO 2017-06-29 13:16:46,969 main.py:57] epoch 218, training loss: 10650.88, average training loss: 12481.49, base loss: 15443.36
[INFO 2017-06-29 13:16:49,490 main.py:57] epoch 219, training loss: 10881.98, average training loss: 12474.22, base loss: 15446.52
[INFO 2017-06-29 13:16:52,049 main.py:57] epoch 220, training loss: 11380.72, average training loss: 12469.27, base loss: 15449.32
[INFO 2017-06-29 13:16:54,607 main.py:57] epoch 221, training loss: 10412.99, average training loss: 12460.01, base loss: 15446.89
[INFO 2017-06-29 13:16:57,190 main.py:57] epoch 222, training loss: 10314.79, average training loss: 12450.39, base loss: 15442.21
[INFO 2017-06-29 13:16:59,696 main.py:57] epoch 223, training loss: 11066.41, average training loss: 12444.21, base loss: 15444.46
[INFO 2017-06-29 13:17:02,196 main.py:57] epoch 224, training loss: 11052.62, average training loss: 12438.02, base loss: 15450.27
[INFO 2017-06-29 13:17:04,699 main.py:57] epoch 225, training loss: 10319.43, average training loss: 12428.65, base loss: 15450.28
[INFO 2017-06-29 13:17:07,295 main.py:57] epoch 226, training loss: 10911.82, average training loss: 12421.97, base loss: 15454.54
[INFO 2017-06-29 13:17:09,859 main.py:57] epoch 227, training loss: 10407.70, average training loss: 12413.13, base loss: 15448.96
[INFO 2017-06-29 13:17:12,351 main.py:57] epoch 228, training loss: 9817.79, average training loss: 12401.80, base loss: 15445.67
[INFO 2017-06-29 13:17:14,892 main.py:57] epoch 229, training loss: 10685.23, average training loss: 12394.33, base loss: 15447.38
[INFO 2017-06-29 13:17:17,400 main.py:57] epoch 230, training loss: 10311.29, average training loss: 12385.32, base loss: 15448.81
[INFO 2017-06-29 13:17:19,873 main.py:57] epoch 231, training loss: 10035.25, average training loss: 12375.19, base loss: 15446.59
[INFO 2017-06-29 13:17:22,469 main.py:57] epoch 232, training loss: 10768.53, average training loss: 12368.29, base loss: 15449.07
[INFO 2017-06-29 13:17:24,969 main.py:57] epoch 233, training loss: 9481.21, average training loss: 12355.95, base loss: 15441.48
[INFO 2017-06-29 13:17:27,492 main.py:57] epoch 234, training loss: 9158.62, average training loss: 12342.35, base loss: 15436.87
[INFO 2017-06-29 13:17:29,978 main.py:57] epoch 235, training loss: 11281.68, average training loss: 12337.85, base loss: 15442.71
[INFO 2017-06-29 13:17:32,544 main.py:57] epoch 236, training loss: 10101.57, average training loss: 12328.42, base loss: 15441.25
[INFO 2017-06-29 13:17:35,114 main.py:57] epoch 237, training loss: 9982.10, average training loss: 12318.56, base loss: 15441.64
[INFO 2017-06-29 13:17:37,695 main.py:57] epoch 238, training loss: 10508.29, average training loss: 12310.99, base loss: 15443.16
[INFO 2017-06-29 13:17:40,208 main.py:57] epoch 239, training loss: 10505.41, average training loss: 12303.46, base loss: 15444.21
[INFO 2017-06-29 13:17:42,748 main.py:57] epoch 240, training loss: 9016.19, average training loss: 12289.82, base loss: 15434.20
[INFO 2017-06-29 13:17:45,252 main.py:57] epoch 241, training loss: 9403.07, average training loss: 12277.89, base loss: 15425.68
[INFO 2017-06-29 13:17:47,800 main.py:57] epoch 242, training loss: 11025.60, average training loss: 12272.74, base loss: 15425.40
[INFO 2017-06-29 13:17:50,334 main.py:57] epoch 243, training loss: 10807.08, average training loss: 12266.73, base loss: 15429.82
[INFO 2017-06-29 13:17:52,829 main.py:57] epoch 244, training loss: 9834.26, average training loss: 12256.80, base loss: 15429.19
[INFO 2017-06-29 13:17:55,385 main.py:57] epoch 245, training loss: 9640.96, average training loss: 12246.17, base loss: 15426.24
[INFO 2017-06-29 13:17:57,959 main.py:57] epoch 246, training loss: 10248.71, average training loss: 12238.08, base loss: 15425.81
[INFO 2017-06-29 13:18:00,537 main.py:57] epoch 247, training loss: 10056.66, average training loss: 12229.29, base loss: 15422.67
[INFO 2017-06-29 13:18:03,048 main.py:57] epoch 248, training loss: 11287.66, average training loss: 12225.51, base loss: 15430.45
[INFO 2017-06-29 13:18:05,512 main.py:57] epoch 249, training loss: 9565.71, average training loss: 12214.87, base loss: 15424.05
[INFO 2017-06-29 13:18:08,146 main.py:57] epoch 250, training loss: 10699.79, average training loss: 12208.83, base loss: 15428.69
[INFO 2017-06-29 13:18:10,720 main.py:57] epoch 251, training loss: 11255.35, average training loss: 12205.05, base loss: 15433.43
[INFO 2017-06-29 13:18:13,274 main.py:57] epoch 252, training loss: 9588.37, average training loss: 12194.70, base loss: 15429.27
[INFO 2017-06-29 13:18:15,822 main.py:57] epoch 253, training loss: 9868.20, average training loss: 12185.55, base loss: 15428.82
[INFO 2017-06-29 13:18:18,349 main.py:57] epoch 254, training loss: 10016.92, average training loss: 12177.04, base loss: 15428.95
[INFO 2017-06-29 13:18:20,885 main.py:57] epoch 255, training loss: 9591.19, average training loss: 12166.94, base loss: 15425.12
[INFO 2017-06-29 13:18:23,394 main.py:57] epoch 256, training loss: 10790.70, average training loss: 12161.59, base loss: 15429.14
[INFO 2017-06-29 13:18:25,931 main.py:57] epoch 257, training loss: 9055.67, average training loss: 12149.55, base loss: 15418.44
[INFO 2017-06-29 13:18:28,420 main.py:57] epoch 258, training loss: 10578.20, average training loss: 12143.48, base loss: 15416.35
[INFO 2017-06-29 13:18:30,988 main.py:57] epoch 259, training loss: 10536.30, average training loss: 12137.30, base loss: 15423.09
[INFO 2017-06-29 13:18:33,503 main.py:57] epoch 260, training loss: 10341.15, average training loss: 12130.42, base loss: 15421.97
[INFO 2017-06-29 13:18:36,008 main.py:57] epoch 261, training loss: 10884.26, average training loss: 12125.66, base loss: 15424.26
[INFO 2017-06-29 13:18:38,515 main.py:57] epoch 262, training loss: 8803.07, average training loss: 12113.03, base loss: 15415.21
[INFO 2017-06-29 13:18:41,090 main.py:57] epoch 263, training loss: 9255.25, average training loss: 12102.20, base loss: 15409.65
[INFO 2017-06-29 13:18:43,659 main.py:57] epoch 264, training loss: 9784.93, average training loss: 12093.46, base loss: 15409.96
[INFO 2017-06-29 13:18:46,229 main.py:57] epoch 265, training loss: 10641.90, average training loss: 12088.00, base loss: 15412.29
[INFO 2017-06-29 13:18:48,737 main.py:57] epoch 266, training loss: 10300.41, average training loss: 12081.31, base loss: 15412.96
[INFO 2017-06-29 13:18:51,296 main.py:57] epoch 267, training loss: 9341.63, average training loss: 12071.08, base loss: 15410.45
[INFO 2017-06-29 13:18:53,801 main.py:57] epoch 268, training loss: 11637.14, average training loss: 12069.47, base loss: 15420.29
[INFO 2017-06-29 13:18:56,391 main.py:57] epoch 269, training loss: 9735.39, average training loss: 12060.82, base loss: 15418.36
[INFO 2017-06-29 13:18:58,930 main.py:57] epoch 270, training loss: 9455.51, average training loss: 12051.21, base loss: 15412.22
[INFO 2017-06-29 13:19:01,417 main.py:57] epoch 271, training loss: 10454.71, average training loss: 12045.34, base loss: 15415.33
[INFO 2017-06-29 13:19:03,892 main.py:57] epoch 272, training loss: 10406.78, average training loss: 12039.34, base loss: 15416.79
[INFO 2017-06-29 13:19:06,458 main.py:57] epoch 273, training loss: 10132.39, average training loss: 12032.38, base loss: 15417.34
[INFO 2017-06-29 13:19:08,992 main.py:57] epoch 274, training loss: 9919.04, average training loss: 12024.69, base loss: 15416.54
[INFO 2017-06-29 13:19:11,498 main.py:57] epoch 275, training loss: 11897.05, average training loss: 12024.23, base loss: 15424.51
[INFO 2017-06-29 13:19:14,035 main.py:57] epoch 276, training loss: 10445.95, average training loss: 12018.53, base loss: 15426.47
[INFO 2017-06-29 13:19:16,518 main.py:57] epoch 277, training loss: 10732.07, average training loss: 12013.91, base loss: 15431.93
[INFO 2017-06-29 13:19:19,106 main.py:57] epoch 278, training loss: 10128.84, average training loss: 12007.15, base loss: 15431.65
[INFO 2017-06-29 13:19:21,628 main.py:57] epoch 279, training loss: 10571.76, average training loss: 12002.02, base loss: 15433.29
[INFO 2017-06-29 13:19:24,148 main.py:57] epoch 280, training loss: 10129.37, average training loss: 11995.36, base loss: 15435.37
[INFO 2017-06-29 13:19:26,674 main.py:57] epoch 281, training loss: 10221.79, average training loss: 11989.07, base loss: 15435.45
[INFO 2017-06-29 13:19:29,242 main.py:57] epoch 282, training loss: 9609.31, average training loss: 11980.66, base loss: 15433.47
[INFO 2017-06-29 13:19:31,827 main.py:57] epoch 283, training loss: 10753.94, average training loss: 11976.34, base loss: 15436.64
[INFO 2017-06-29 13:19:34,341 main.py:57] epoch 284, training loss: 9566.55, average training loss: 11967.89, base loss: 15434.79
[INFO 2017-06-29 13:19:36,861 main.py:57] epoch 285, training loss: 9718.07, average training loss: 11960.02, base loss: 15431.01
[INFO 2017-06-29 13:19:39,439 main.py:57] epoch 286, training loss: 9284.02, average training loss: 11950.70, base loss: 15423.35
[INFO 2017-06-29 13:19:41,955 main.py:57] epoch 287, training loss: 10369.68, average training loss: 11945.21, base loss: 15422.43
[INFO 2017-06-29 13:19:44,524 main.py:57] epoch 288, training loss: 11759.45, average training loss: 11944.56, base loss: 15430.94
[INFO 2017-06-29 13:19:47,121 main.py:57] epoch 289, training loss: 9636.30, average training loss: 11936.60, base loss: 15427.19
[INFO 2017-06-29 13:19:49,655 main.py:57] epoch 290, training loss: 9862.13, average training loss: 11929.48, base loss: 15425.40
[INFO 2017-06-29 13:19:52,209 main.py:57] epoch 291, training loss: 9781.12, average training loss: 11922.12, base loss: 15422.67
[INFO 2017-06-29 13:19:54,823 main.py:57] epoch 292, training loss: 10743.76, average training loss: 11918.10, base loss: 15427.22
[INFO 2017-06-29 13:19:57,465 main.py:57] epoch 293, training loss: 9311.96, average training loss: 11909.23, base loss: 15423.38
[INFO 2017-06-29 13:20:00,035 main.py:57] epoch 294, training loss: 10133.85, average training loss: 11903.21, base loss: 15421.92
[INFO 2017-06-29 13:20:02,524 main.py:57] epoch 295, training loss: 9946.85, average training loss: 11896.60, base loss: 15420.45
[INFO 2017-06-29 13:20:05,071 main.py:57] epoch 296, training loss: 11075.43, average training loss: 11893.84, base loss: 15426.78
[INFO 2017-06-29 13:20:07,586 main.py:57] epoch 297, training loss: 9656.92, average training loss: 11886.33, base loss: 15422.43
[INFO 2017-06-29 13:20:10,075 main.py:57] epoch 298, training loss: 10096.57, average training loss: 11880.35, base loss: 15423.10
[INFO 2017-06-29 13:20:12,582 main.py:57] epoch 299, training loss: 9928.09, average training loss: 11873.84, base loss: 15425.36
[INFO 2017-06-29 13:20:12,582 main.py:59] epoch 299, testing
[INFO 2017-06-29 13:20:23,891 main.py:104] average testing loss: 8977.42, base loss: 15505.89
[INFO 2017-06-29 13:20:23,892 main.py:105] improve_loss: 6528.47, improve_percent: 0.42
[INFO 2017-06-29 13:20:23,893 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 13:20:23,906 main.py:71] current best improved percent: 0.42
[INFO 2017-06-29 13:20:26,465 main.py:57] epoch 300, training loss: 11742.25, average training loss: 11873.40, base loss: 15432.39
[INFO 2017-06-29 13:20:29,043 main.py:57] epoch 301, training loss: 10765.44, average training loss: 11869.73, base loss: 15437.09
[INFO 2017-06-29 13:20:31,509 main.py:57] epoch 302, training loss: 10648.97, average training loss: 11865.70, base loss: 15441.84
[INFO 2017-06-29 13:20:33,991 main.py:57] epoch 303, training loss: 9532.72, average training loss: 11858.03, base loss: 15441.78
[INFO 2017-06-29 13:20:36,521 main.py:57] epoch 304, training loss: 10243.47, average training loss: 11852.74, base loss: 15442.11
[INFO 2017-06-29 13:20:39,105 main.py:57] epoch 305, training loss: 10525.60, average training loss: 11848.40, base loss: 15443.65
[INFO 2017-06-29 13:20:41,620 main.py:57] epoch 306, training loss: 9748.73, average training loss: 11841.56, base loss: 15442.76
[INFO 2017-06-29 13:20:44,152 main.py:57] epoch 307, training loss: 9764.65, average training loss: 11834.82, base loss: 15445.08
[INFO 2017-06-29 13:20:46,584 main.py:57] epoch 308, training loss: 11311.06, average training loss: 11833.12, base loss: 15450.61
[INFO 2017-06-29 13:20:49,173 main.py:57] epoch 309, training loss: 10472.06, average training loss: 11828.73, base loss: 15449.98
[INFO 2017-06-29 13:20:51,640 main.py:57] epoch 310, training loss: 10100.46, average training loss: 11823.17, base loss: 15448.50
[INFO 2017-06-29 13:20:54,189 main.py:57] epoch 311, training loss: 10397.06, average training loss: 11818.60, base loss: 15452.49
[INFO 2017-06-29 13:20:56,719 main.py:57] epoch 312, training loss: 10658.30, average training loss: 11814.90, base loss: 15454.24
[INFO 2017-06-29 13:20:59,328 main.py:57] epoch 313, training loss: 11342.58, average training loss: 11813.39, base loss: 15459.08
[INFO 2017-06-29 13:21:01,823 main.py:57] epoch 314, training loss: 9684.97, average training loss: 11806.64, base loss: 15457.19
[INFO 2017-06-29 13:21:04,466 main.py:57] epoch 315, training loss: 9467.47, average training loss: 11799.23, base loss: 15453.64
[INFO 2017-06-29 13:21:06,977 main.py:57] epoch 316, training loss: 10949.64, average training loss: 11796.55, base loss: 15460.12
[INFO 2017-06-29 13:21:09,473 main.py:57] epoch 317, training loss: 9257.77, average training loss: 11788.57, base loss: 15452.95
[INFO 2017-06-29 13:21:12,131 main.py:57] epoch 318, training loss: 8996.11, average training loss: 11779.82, base loss: 15444.06
[INFO 2017-06-29 13:21:14,702 main.py:57] epoch 319, training loss: 9965.11, average training loss: 11774.14, base loss: 15442.45
[INFO 2017-06-29 13:21:17,131 main.py:57] epoch 320, training loss: 9098.61, average training loss: 11765.81, base loss: 15439.62
[INFO 2017-06-29 13:21:19,600 main.py:57] epoch 321, training loss: 10538.25, average training loss: 11762.00, base loss: 15439.83
[INFO 2017-06-29 13:21:22,209 main.py:57] epoch 322, training loss: 9865.66, average training loss: 11756.13, base loss: 15439.37
[INFO 2017-06-29 13:21:24,719 main.py:57] epoch 323, training loss: 11730.84, average training loss: 11756.05, base loss: 15449.29
[INFO 2017-06-29 13:21:27,185 main.py:57] epoch 324, training loss: 10321.06, average training loss: 11751.63, base loss: 15453.84
[INFO 2017-06-29 13:21:29,768 main.py:57] epoch 325, training loss: 9842.74, average training loss: 11745.78, base loss: 15453.49
[INFO 2017-06-29 13:21:32,259 main.py:57] epoch 326, training loss: 10232.79, average training loss: 11741.15, base loss: 15453.97
[INFO 2017-06-29 13:21:34,803 main.py:57] epoch 327, training loss: 11063.74, average training loss: 11739.09, base loss: 15455.65
[INFO 2017-06-29 13:21:37,380 main.py:57] epoch 328, training loss: 9456.93, average training loss: 11732.15, base loss: 15453.86
[INFO 2017-06-29 13:21:39,861 main.py:57] epoch 329, training loss: 9101.39, average training loss: 11724.18, base loss: 15447.48
[INFO 2017-06-29 13:21:42,445 main.py:57] epoch 330, training loss: 10396.85, average training loss: 11720.17, base loss: 15449.48
[INFO 2017-06-29 13:21:45,052 main.py:57] epoch 331, training loss: 8582.27, average training loss: 11710.72, base loss: 15442.41
[INFO 2017-06-29 13:21:47,602 main.py:57] epoch 332, training loss: 10327.37, average training loss: 11706.56, base loss: 15442.79
[INFO 2017-06-29 13:21:50,097 main.py:57] epoch 333, training loss: 9803.32, average training loss: 11700.86, base loss: 15436.96
[INFO 2017-06-29 13:21:52,673 main.py:57] epoch 334, training loss: 9728.03, average training loss: 11694.97, base loss: 15436.19
[INFO 2017-06-29 13:21:55,228 main.py:57] epoch 335, training loss: 10281.04, average training loss: 11690.77, base loss: 15435.85
[INFO 2017-06-29 13:21:57,729 main.py:57] epoch 336, training loss: 10152.76, average training loss: 11686.20, base loss: 15432.86
[INFO 2017-06-29 13:22:00,241 main.py:57] epoch 337, training loss: 8159.60, average training loss: 11675.77, base loss: 15423.15
[INFO 2017-06-29 13:22:02,816 main.py:57] epoch 338, training loss: 9842.12, average training loss: 11670.36, base loss: 15421.23
[INFO 2017-06-29 13:22:05,328 main.py:57] epoch 339, training loss: 10788.69, average training loss: 11667.77, base loss: 15424.14
[INFO 2017-06-29 13:22:07,859 main.py:57] epoch 340, training loss: 10711.30, average training loss: 11664.96, base loss: 15428.25
[INFO 2017-06-29 13:22:10,366 main.py:57] epoch 341, training loss: 9178.25, average training loss: 11657.69, base loss: 15424.72
[INFO 2017-06-29 13:22:12,986 main.py:57] epoch 342, training loss: 10098.13, average training loss: 11653.14, base loss: 15426.77
[INFO 2017-06-29 13:22:15,559 main.py:57] epoch 343, training loss: 10214.89, average training loss: 11648.96, base loss: 15430.33
[INFO 2017-06-29 13:22:18,114 main.py:57] epoch 344, training loss: 9549.29, average training loss: 11642.88, base loss: 15428.22
[INFO 2017-06-29 13:22:20,665 main.py:57] epoch 345, training loss: 10395.33, average training loss: 11639.27, base loss: 15428.44
[INFO 2017-06-29 13:22:23,187 main.py:57] epoch 346, training loss: 8659.03, average training loss: 11630.68, base loss: 15420.15
[INFO 2017-06-29 13:22:25,767 main.py:57] epoch 347, training loss: 10357.79, average training loss: 11627.02, base loss: 15423.08
[INFO 2017-06-29 13:22:28,388 main.py:57] epoch 348, training loss: 10229.64, average training loss: 11623.02, base loss: 15421.89
[INFO 2017-06-29 13:22:30,987 main.py:57] epoch 349, training loss: 9726.55, average training loss: 11617.60, base loss: 15421.34
[INFO 2017-06-29 13:22:33,492 main.py:57] epoch 350, training loss: 8942.41, average training loss: 11609.98, base loss: 15415.57
[INFO 2017-06-29 13:22:36,044 main.py:57] epoch 351, training loss: 10058.50, average training loss: 11605.57, base loss: 15416.55
[INFO 2017-06-29 13:22:38,582 main.py:57] epoch 352, training loss: 9693.96, average training loss: 11600.16, base loss: 15414.18
[INFO 2017-06-29 13:22:41,097 main.py:57] epoch 353, training loss: 9112.79, average training loss: 11593.13, base loss: 15411.40
[INFO 2017-06-29 13:22:43,590 main.py:57] epoch 354, training loss: 9418.48, average training loss: 11587.00, base loss: 15410.60
[INFO 2017-06-29 13:22:46,104 main.py:57] epoch 355, training loss: 9960.34, average training loss: 11582.44, base loss: 15409.75
[INFO 2017-06-29 13:22:48,596 main.py:57] epoch 356, training loss: 10465.74, average training loss: 11579.31, base loss: 15411.88
[INFO 2017-06-29 13:22:51,133 main.py:57] epoch 357, training loss: 9038.00, average training loss: 11572.21, base loss: 15405.81
[INFO 2017-06-29 13:22:53,659 main.py:57] epoch 358, training loss: 9643.51, average training loss: 11566.84, base loss: 15405.45
[INFO 2017-06-29 13:22:56,136 main.py:57] epoch 359, training loss: 10423.46, average training loss: 11563.66, base loss: 15407.86
[INFO 2017-06-29 13:22:58,610 main.py:57] epoch 360, training loss: 9162.48, average training loss: 11557.01, base loss: 15402.34
[INFO 2017-06-29 13:23:01,074 main.py:57] epoch 361, training loss: 11048.99, average training loss: 11555.61, base loss: 15406.10
[INFO 2017-06-29 13:23:03,590 main.py:57] epoch 362, training loss: 9693.27, average training loss: 11550.48, base loss: 15405.60
[INFO 2017-06-29 13:23:06,112 main.py:57] epoch 363, training loss: 9695.43, average training loss: 11545.38, base loss: 15403.73
[INFO 2017-06-29 13:23:08,686 main.py:57] epoch 364, training loss: 10909.73, average training loss: 11543.64, base loss: 15407.19
[INFO 2017-06-29 13:23:11,228 main.py:57] epoch 365, training loss: 10362.95, average training loss: 11540.41, base loss: 15407.83
[INFO 2017-06-29 13:23:13,760 main.py:57] epoch 366, training loss: 10108.23, average training loss: 11536.51, base loss: 15409.74
[INFO 2017-06-29 13:23:16,323 main.py:57] epoch 367, training loss: 9542.85, average training loss: 11531.09, base loss: 15410.49
[INFO 2017-06-29 13:23:18,791 main.py:57] epoch 368, training loss: 9885.05, average training loss: 11526.63, base loss: 15408.06
[INFO 2017-06-29 13:23:21,342 main.py:57] epoch 369, training loss: 8893.08, average training loss: 11519.51, base loss: 15403.63
[INFO 2017-06-29 13:23:23,952 main.py:57] epoch 370, training loss: 9908.36, average training loss: 11515.17, base loss: 15406.11
[INFO 2017-06-29 13:23:26,510 main.py:57] epoch 371, training loss: 10315.61, average training loss: 11511.95, base loss: 15405.03
[INFO 2017-06-29 13:23:29,119 main.py:57] epoch 372, training loss: 8891.11, average training loss: 11504.92, base loss: 15400.82
[INFO 2017-06-29 13:23:31,719 main.py:57] epoch 373, training loss: 9826.17, average training loss: 11500.43, base loss: 15399.65
[INFO 2017-06-29 13:23:34,223 main.py:57] epoch 374, training loss: 10807.80, average training loss: 11498.58, base loss: 15404.17
[INFO 2017-06-29 13:23:36,848 main.py:57] epoch 375, training loss: 9259.70, average training loss: 11492.63, base loss: 15399.98
[INFO 2017-06-29 13:23:39,362 main.py:57] epoch 376, training loss: 10621.23, average training loss: 11490.32, base loss: 15402.33
[INFO 2017-06-29 13:23:41,987 main.py:57] epoch 377, training loss: 10480.27, average training loss: 11487.65, base loss: 15407.04
[INFO 2017-06-29 13:23:44,523 main.py:57] epoch 378, training loss: 9356.49, average training loss: 11482.02, base loss: 15405.82
[INFO 2017-06-29 13:23:47,030 main.py:57] epoch 379, training loss: 9601.35, average training loss: 11477.07, base loss: 15403.90
[INFO 2017-06-29 13:23:49,648 main.py:57] epoch 380, training loss: 9804.67, average training loss: 11472.68, base loss: 15404.26
[INFO 2017-06-29 13:23:52,198 main.py:57] epoch 381, training loss: 9591.34, average training loss: 11467.76, base loss: 15402.49
[INFO 2017-06-29 13:23:54,670 main.py:57] epoch 382, training loss: 9071.12, average training loss: 11461.50, base loss: 15400.00
[INFO 2017-06-29 13:23:57,184 main.py:57] epoch 383, training loss: 9277.45, average training loss: 11455.81, base loss: 15399.45
[INFO 2017-06-29 13:23:59,626 main.py:57] epoch 384, training loss: 10057.01, average training loss: 11452.18, base loss: 15400.50
[INFO 2017-06-29 13:24:02,100 main.py:57] epoch 385, training loss: 9804.44, average training loss: 11447.91, base loss: 15401.38
[INFO 2017-06-29 13:24:04,692 main.py:57] epoch 386, training loss: 10792.17, average training loss: 11446.22, base loss: 15403.37
[INFO 2017-06-29 13:24:07,188 main.py:57] epoch 387, training loss: 8730.87, average training loss: 11439.22, base loss: 15397.85
[INFO 2017-06-29 13:24:09,749 main.py:57] epoch 388, training loss: 9306.62, average training loss: 11433.74, base loss: 15397.05
[INFO 2017-06-29 13:24:12,244 main.py:57] epoch 389, training loss: 10024.55, average training loss: 11430.12, base loss: 15398.01
[INFO 2017-06-29 13:24:14,785 main.py:57] epoch 390, training loss: 10011.31, average training loss: 11426.49, base loss: 15400.46
[INFO 2017-06-29 13:24:17,311 main.py:57] epoch 391, training loss: 9168.93, average training loss: 11420.74, base loss: 15397.33
[INFO 2017-06-29 13:24:19,842 main.py:57] epoch 392, training loss: 9358.49, average training loss: 11415.49, base loss: 15395.88
[INFO 2017-06-29 13:24:22,382 main.py:57] epoch 393, training loss: 12199.85, average training loss: 11417.48, base loss: 15405.47
[INFO 2017-06-29 13:24:24,953 main.py:57] epoch 394, training loss: 9626.30, average training loss: 11412.94, base loss: 15405.49
[INFO 2017-06-29 13:24:27,504 main.py:57] epoch 395, training loss: 10634.74, average training loss: 11410.98, base loss: 15409.24
[INFO 2017-06-29 13:24:29,989 main.py:57] epoch 396, training loss: 9280.23, average training loss: 11405.61, base loss: 15407.04
[INFO 2017-06-29 13:24:32,558 main.py:57] epoch 397, training loss: 10868.44, average training loss: 11404.26, base loss: 15408.93
[INFO 2017-06-29 13:24:35,076 main.py:57] epoch 398, training loss: 9037.83, average training loss: 11398.33, base loss: 15402.64
[INFO 2017-06-29 13:24:37,745 main.py:57] epoch 399, training loss: 9541.96, average training loss: 11393.69, base loss: 15401.14
[INFO 2017-06-29 13:24:37,745 main.py:59] epoch 399, testing
[INFO 2017-06-29 13:24:49,092 main.py:104] average testing loss: 8792.02, base loss: 15958.47
[INFO 2017-06-29 13:24:49,092 main.py:105] improve_loss: 7166.45, improve_percent: 0.45
[INFO 2017-06-29 13:24:49,094 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 13:24:49,109 main.py:71] current best improved percent: 0.45
[INFO 2017-06-29 13:24:51,670 main.py:57] epoch 400, training loss: 10271.87, average training loss: 11390.89, base loss: 15404.36
[INFO 2017-06-29 13:24:54,359 main.py:57] epoch 401, training loss: 9530.06, average training loss: 11386.26, base loss: 15404.62
[INFO 2017-06-29 13:24:56,895 main.py:57] epoch 402, training loss: 9101.32, average training loss: 11380.59, base loss: 15404.33
[INFO 2017-06-29 13:24:59,372 main.py:57] epoch 403, training loss: 9815.50, average training loss: 11376.72, base loss: 15403.39
[INFO 2017-06-29 13:25:01,948 main.py:57] epoch 404, training loss: 9738.20, average training loss: 11372.67, base loss: 15404.26
[INFO 2017-06-29 13:25:04,462 main.py:57] epoch 405, training loss: 9278.96, average training loss: 11367.52, base loss: 15402.83
[INFO 2017-06-29 13:25:06,995 main.py:57] epoch 406, training loss: 9548.80, average training loss: 11363.05, base loss: 15401.85
[INFO 2017-06-29 13:25:09,508 main.py:57] epoch 407, training loss: 9367.93, average training loss: 11358.16, base loss: 15400.72
[INFO 2017-06-29 13:25:11,961 main.py:57] epoch 408, training loss: 10058.93, average training loss: 11354.98, base loss: 15399.98
[INFO 2017-06-29 13:25:14,451 main.py:57] epoch 409, training loss: 9560.66, average training loss: 11350.61, base loss: 15400.98
[INFO 2017-06-29 13:25:16,997 main.py:57] epoch 410, training loss: 9125.21, average training loss: 11345.19, base loss: 15400.04
[INFO 2017-06-29 13:25:19,606 main.py:57] epoch 411, training loss: 11359.98, average training loss: 11345.23, base loss: 15405.56
[INFO 2017-06-29 13:25:22,228 main.py:57] epoch 412, training loss: 9440.99, average training loss: 11340.62, base loss: 15405.82
[INFO 2017-06-29 13:25:24,762 main.py:57] epoch 413, training loss: 8985.46, average training loss: 11334.93, base loss: 15403.74
[INFO 2017-06-29 13:25:27,366 main.py:57] epoch 414, training loss: 10362.78, average training loss: 11332.59, base loss: 15402.44
[INFO 2017-06-29 13:25:30,066 main.py:57] epoch 415, training loss: 9282.49, average training loss: 11327.66, base loss: 15400.38
[INFO 2017-06-29 13:25:32,675 main.py:57] epoch 416, training loss: 9503.83, average training loss: 11323.28, base loss: 15401.07
[INFO 2017-06-29 13:25:35,228 main.py:57] epoch 417, training loss: 10670.98, average training loss: 11321.72, base loss: 15404.96
[INFO 2017-06-29 13:25:37,706 main.py:57] epoch 418, training loss: 9614.21, average training loss: 11317.65, base loss: 15405.46
[INFO 2017-06-29 13:25:40,231 main.py:57] epoch 419, training loss: 8358.91, average training loss: 11310.60, base loss: 15399.87
[INFO 2017-06-29 13:25:42,846 main.py:57] epoch 420, training loss: 9899.83, average training loss: 11307.25, base loss: 15399.92
[INFO 2017-06-29 13:25:45,435 main.py:57] epoch 421, training loss: 9584.72, average training loss: 11303.17, base loss: 15400.28
[INFO 2017-06-29 13:25:47,968 main.py:57] epoch 422, training loss: 9574.10, average training loss: 11299.08, base loss: 15400.40
[INFO 2017-06-29 13:25:50,564 main.py:57] epoch 423, training loss: 10288.59, average training loss: 11296.70, base loss: 15401.66
[INFO 2017-06-29 13:25:53,080 main.py:57] epoch 424, training loss: 8709.06, average training loss: 11290.61, base loss: 15397.71
[INFO 2017-06-29 13:25:55,677 main.py:57] epoch 425, training loss: 10200.67, average training loss: 11288.05, base loss: 15399.26
[INFO 2017-06-29 13:25:58,302 main.py:57] epoch 426, training loss: 8752.60, average training loss: 11282.11, base loss: 15395.52
[INFO 2017-06-29 13:26:00,847 main.py:57] epoch 427, training loss: 8992.80, average training loss: 11276.77, base loss: 15392.34
[INFO 2017-06-29 13:26:03,416 main.py:57] epoch 428, training loss: 9650.83, average training loss: 11272.98, base loss: 15393.13
[INFO 2017-06-29 13:26:05,990 main.py:57] epoch 429, training loss: 9375.21, average training loss: 11268.56, base loss: 15392.33
[INFO 2017-06-29 13:26:08,567 main.py:57] epoch 430, training loss: 9331.29, average training loss: 11264.07, base loss: 15389.82
[INFO 2017-06-29 13:26:11,125 main.py:57] epoch 431, training loss: 9177.19, average training loss: 11259.24, base loss: 15389.56
[INFO 2017-06-29 13:26:13,840 main.py:57] epoch 432, training loss: 10631.67, average training loss: 11257.79, base loss: 15393.47
[INFO 2017-06-29 13:26:16,390 main.py:57] epoch 433, training loss: 9417.76, average training loss: 11253.55, base loss: 15392.11
[INFO 2017-06-29 13:26:18,932 main.py:57] epoch 434, training loss: 9608.77, average training loss: 11249.77, base loss: 15389.78
[INFO 2017-06-29 13:26:21,527 main.py:57] epoch 435, training loss: 9673.63, average training loss: 11246.15, base loss: 15390.86
[INFO 2017-06-29 13:26:24,054 main.py:57] epoch 436, training loss: 8505.17, average training loss: 11239.88, base loss: 15387.21
[INFO 2017-06-29 13:26:26,623 main.py:57] epoch 437, training loss: 10927.27, average training loss: 11239.17, base loss: 15392.60
[INFO 2017-06-29 13:26:29,264 main.py:57] epoch 438, training loss: 9930.86, average training loss: 11236.19, base loss: 15393.48
[INFO 2017-06-29 13:26:31,818 main.py:57] epoch 439, training loss: 9190.64, average training loss: 11231.54, base loss: 15391.35
[INFO 2017-06-29 13:26:34,359 main.py:57] epoch 440, training loss: 11135.78, average training loss: 11231.32, base loss: 15393.84
[INFO 2017-06-29 13:26:36,895 main.py:57] epoch 441, training loss: 9138.07, average training loss: 11226.58, base loss: 15390.55
[INFO 2017-06-29 13:26:39,411 main.py:57] epoch 442, training loss: 10713.46, average training loss: 11225.43, base loss: 15393.29
[INFO 2017-06-29 13:26:41,907 main.py:57] epoch 443, training loss: 9365.27, average training loss: 11221.24, base loss: 15390.71
[INFO 2017-06-29 13:26:44,445 main.py:57] epoch 444, training loss: 10667.91, average training loss: 11219.99, base loss: 15393.77
[INFO 2017-06-29 13:26:46,999 main.py:57] epoch 445, training loss: 10301.15, average training loss: 11217.93, base loss: 15396.57
[INFO 2017-06-29 13:26:49,562 main.py:57] epoch 446, training loss: 10870.71, average training loss: 11217.16, base loss: 15401.43
[INFO 2017-06-29 13:26:52,172 main.py:57] epoch 447, training loss: 9665.83, average training loss: 11213.69, base loss: 15400.96
[INFO 2017-06-29 13:26:54,749 main.py:57] epoch 448, training loss: 9622.56, average training loss: 11210.15, base loss: 15402.65
[INFO 2017-06-29 13:26:57,304 main.py:57] epoch 449, training loss: 9571.97, average training loss: 11206.51, base loss: 15401.87
[INFO 2017-06-29 13:26:59,853 main.py:57] epoch 450, training loss: 10004.40, average training loss: 11203.84, base loss: 15403.06
[INFO 2017-06-29 13:27:02,577 main.py:57] epoch 451, training loss: 9946.65, average training loss: 11201.06, base loss: 15403.77
[INFO 2017-06-29 13:27:05,163 main.py:57] epoch 452, training loss: 10827.05, average training loss: 11200.24, base loss: 15406.26
[INFO 2017-06-29 13:27:07,823 main.py:57] epoch 453, training loss: 11082.58, average training loss: 11199.98, base loss: 15409.83
[INFO 2017-06-29 13:27:10,369 main.py:57] epoch 454, training loss: 9885.79, average training loss: 11197.09, base loss: 15408.02
[INFO 2017-06-29 13:27:12,998 main.py:57] epoch 455, training loss: 9158.10, average training loss: 11192.62, base loss: 15406.77
[INFO 2017-06-29 13:27:15,630 main.py:57] epoch 456, training loss: 10340.56, average training loss: 11190.75, base loss: 15410.09
[INFO 2017-06-29 13:27:18,270 main.py:57] epoch 457, training loss: 11012.90, average training loss: 11190.36, base loss: 15414.56
[INFO 2017-06-29 13:27:20,959 main.py:57] epoch 458, training loss: 8819.36, average training loss: 11185.20, base loss: 15410.40
[INFO 2017-06-29 13:27:23,572 main.py:57] epoch 459, training loss: 10395.47, average training loss: 11183.48, base loss: 15414.72
[INFO 2017-06-29 13:27:26,096 main.py:57] epoch 460, training loss: 10036.66, average training loss: 11180.99, base loss: 15414.33
[INFO 2017-06-29 13:27:28,745 main.py:57] epoch 461, training loss: 10086.17, average training loss: 11178.62, base loss: 15418.81
[INFO 2017-06-29 13:27:31,286 main.py:57] epoch 462, training loss: 9463.41, average training loss: 11174.92, base loss: 15415.75
[INFO 2017-06-29 13:27:34,064 main.py:57] epoch 463, training loss: 10678.89, average training loss: 11173.85, base loss: 15420.16
[INFO 2017-06-29 13:27:36,690 main.py:57] epoch 464, training loss: 10015.12, average training loss: 11171.36, base loss: 15420.94
[INFO 2017-06-29 13:27:39,330 main.py:57] epoch 465, training loss: 10900.88, average training loss: 11170.78, base loss: 15426.53
[INFO 2017-06-29 13:27:42,032 main.py:57] epoch 466, training loss: 9448.07, average training loss: 11167.09, base loss: 15425.38
[INFO 2017-06-29 13:27:44,687 main.py:57] epoch 467, training loss: 9443.14, average training loss: 11163.41, base loss: 15425.13
[INFO 2017-06-29 13:27:47,206 main.py:57] epoch 468, training loss: 9195.28, average training loss: 11159.21, base loss: 15425.83
[INFO 2017-06-29 13:27:49,727 main.py:57] epoch 469, training loss: 9961.88, average training loss: 11156.66, base loss: 15426.49
[INFO 2017-06-29 13:27:52,249 main.py:57] epoch 470, training loss: 9757.05, average training loss: 11153.69, base loss: 15428.32
[INFO 2017-06-29 13:27:54,839 main.py:57] epoch 471, training loss: 9761.97, average training loss: 11150.74, base loss: 15429.32
[INFO 2017-06-29 13:27:57,404 main.py:57] epoch 472, training loss: 9421.97, average training loss: 11147.09, base loss: 15429.19
[INFO 2017-06-29 13:27:59,973 main.py:57] epoch 473, training loss: 9254.50, average training loss: 11143.09, base loss: 15427.00
[INFO 2017-06-29 13:28:02,521 main.py:57] epoch 474, training loss: 9866.44, average training loss: 11140.41, base loss: 15425.14
[INFO 2017-06-29 13:28:05,025 main.py:57] epoch 475, training loss: 10050.31, average training loss: 11138.12, base loss: 15426.40
[INFO 2017-06-29 13:28:07,704 main.py:57] epoch 476, training loss: 8819.83, average training loss: 11133.26, base loss: 15423.58
[INFO 2017-06-29 13:28:10,262 main.py:57] epoch 477, training loss: 9979.33, average training loss: 11130.84, base loss: 15424.68
[INFO 2017-06-29 13:28:12,787 main.py:57] epoch 478, training loss: 9884.30, average training loss: 11128.24, base loss: 15425.90
[INFO 2017-06-29 13:28:15,429 main.py:57] epoch 479, training loss: 9992.30, average training loss: 11125.87, base loss: 15426.11
[INFO 2017-06-29 13:28:17,999 main.py:57] epoch 480, training loss: 8840.14, average training loss: 11121.12, base loss: 15423.83
[INFO 2017-06-29 13:28:20,506 main.py:57] epoch 481, training loss: 9331.23, average training loss: 11117.41, base loss: 15423.08
[INFO 2017-06-29 13:28:23,028 main.py:57] epoch 482, training loss: 10783.92, average training loss: 11116.72, base loss: 15426.75
[INFO 2017-06-29 13:28:25,561 main.py:57] epoch 483, training loss: 8747.20, average training loss: 11111.82, base loss: 15424.46
[INFO 2017-06-29 13:28:28,079 main.py:57] epoch 484, training loss: 10364.40, average training loss: 11110.28, base loss: 15425.31
[INFO 2017-06-29 13:28:30,705 main.py:57] epoch 485, training loss: 9838.65, average training loss: 11107.66, base loss: 15426.50
[INFO 2017-06-29 13:28:33,331 main.py:57] epoch 486, training loss: 10467.12, average training loss: 11106.35, base loss: 15430.18
[INFO 2017-06-29 13:28:35,888 main.py:57] epoch 487, training loss: 10179.72, average training loss: 11104.45, base loss: 15431.92
[INFO 2017-06-29 13:28:38,466 main.py:57] epoch 488, training loss: 10237.80, average training loss: 11102.68, base loss: 15434.09
[INFO 2017-06-29 13:28:40,990 main.py:57] epoch 489, training loss: 9696.63, average training loss: 11099.81, base loss: 15432.81
[INFO 2017-06-29 13:28:43,502 main.py:57] epoch 490, training loss: 9841.57, average training loss: 11097.25, base loss: 15433.45
[INFO 2017-06-29 13:28:46,024 main.py:57] epoch 491, training loss: 9509.35, average training loss: 11094.02, base loss: 15431.93
[INFO 2017-06-29 13:28:48,589 main.py:57] epoch 492, training loss: 9609.84, average training loss: 11091.01, base loss: 15431.38
[INFO 2017-06-29 13:28:51,213 main.py:57] epoch 493, training loss: 8811.49, average training loss: 11086.39, base loss: 15428.75
[INFO 2017-06-29 13:28:53,737 main.py:57] epoch 494, training loss: 9324.25, average training loss: 11082.83, base loss: 15427.18
[INFO 2017-06-29 13:28:56,284 main.py:57] epoch 495, training loss: 9141.50, average training loss: 11078.92, base loss: 15426.40
[INFO 2017-06-29 13:28:58,977 main.py:57] epoch 496, training loss: 9787.87, average training loss: 11076.32, base loss: 15426.38
[INFO 2017-06-29 13:29:01,510 main.py:57] epoch 497, training loss: 9247.04, average training loss: 11072.65, base loss: 15425.04
[INFO 2017-06-29 13:29:04,044 main.py:57] epoch 498, training loss: 9612.29, average training loss: 11069.72, base loss: 15423.30
[INFO 2017-06-29 13:29:06,565 main.py:57] epoch 499, training loss: 9364.29, average training loss: 11066.31, base loss: 15421.73
[INFO 2017-06-29 13:29:06,565 main.py:59] epoch 499, testing
[INFO 2017-06-29 13:29:17,734 main.py:104] average testing loss: 8555.59, base loss: 15561.56
[INFO 2017-06-29 13:29:17,734 main.py:105] improve_loss: 7005.97, improve_percent: 0.45
[INFO 2017-06-29 13:29:17,735 main.py:67] model save to ./model/final.pth
[INFO 2017-06-29 13:29:17,748 main.py:71] current best improved percent: 0.45
[INFO 2017-06-29 13:29:20,384 main.py:57] epoch 500, training loss: 9221.91, average training loss: 11062.63, base loss: 15421.36
[INFO 2017-06-29 13:29:23,047 main.py:57] epoch 501, training loss: 10163.93, average training loss: 11060.84, base loss: 15420.64
[INFO 2017-06-29 13:29:25,501 main.py:57] epoch 502, training loss: 9989.33, average training loss: 11058.71, base loss: 15423.83
