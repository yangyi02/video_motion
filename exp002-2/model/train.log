[INFO 2017-06-26 15:45:00,527 main.py:170] Namespace(batch_size=64, display=False, image_size=64, init_model_path='', input_video_path='video', learning_rate=0.001, method='unsupervised', motion_range=2, num_channel=3, num_inputs=1, output_flow_path='flow', output_flow_video_path='flow_video', save_dir='./model', test=False, test_dir='./mpii-64-few-2', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='./mpii-64-few', train_epoch=10000)
[INFO 2017-06-26 15:45:02,810 main.py:50] epoch 0, training loss: 168474.33, average training loss: 168474.33, base loss: 27457.77
[INFO 2017-06-26 15:45:03,342 main.py:50] epoch 1, training loss: 133785.73, average training loss: 151130.03, base loss: 27798.00
[INFO 2017-06-26 15:45:03,878 main.py:50] epoch 2, training loss: 116502.28, average training loss: 139587.45, base loss: 27613.34
[INFO 2017-06-26 15:45:04,410 main.py:50] epoch 3, training loss: 97743.51, average training loss: 129126.46, base loss: 27859.73
[INFO 2017-06-26 15:45:04,941 main.py:50] epoch 4, training loss: 89017.49, average training loss: 121104.67, base loss: 27861.26
[INFO 2017-06-26 15:45:05,473 main.py:50] epoch 5, training loss: 81266.24, average training loss: 114464.93, base loss: 28237.01
[INFO 2017-06-26 15:45:06,005 main.py:50] epoch 6, training loss: 73653.52, average training loss: 108634.73, base loss: 28136.03
[INFO 2017-06-26 15:45:06,535 main.py:50] epoch 7, training loss: 64655.50, average training loss: 103137.33, base loss: 27892.19
[INFO 2017-06-26 15:45:07,067 main.py:50] epoch 8, training loss: 59968.54, average training loss: 98340.79, base loss: 28315.51
[INFO 2017-06-26 15:45:07,603 main.py:50] epoch 9, training loss: 52451.59, average training loss: 93751.87, base loss: 28078.77
[INFO 2017-06-26 15:45:08,133 main.py:50] epoch 10, training loss: 48260.00, average training loss: 89616.25, base loss: 28131.67
[INFO 2017-06-26 15:45:08,688 main.py:50] epoch 11, training loss: 45401.59, average training loss: 85931.69, base loss: 28001.48
[INFO 2017-06-26 15:45:09,223 main.py:50] epoch 12, training loss: 41075.16, average training loss: 82481.19, base loss: 27851.01
[INFO 2017-06-26 15:45:09,760 main.py:50] epoch 13, training loss: 38167.90, average training loss: 79315.96, base loss: 27737.11
[INFO 2017-06-26 15:45:10,295 main.py:50] epoch 14, training loss: 37505.29, average training loss: 76528.58, base loss: 27705.92
[INFO 2017-06-26 15:45:10,830 main.py:50] epoch 15, training loss: 35798.51, average training loss: 73982.95, base loss: 27733.42
[INFO 2017-06-26 15:45:11,360 main.py:50] epoch 16, training loss: 33317.05, average training loss: 71590.84, base loss: 27705.27
[INFO 2017-06-26 15:45:11,892 main.py:50] epoch 17, training loss: 33149.30, average training loss: 69455.20, base loss: 27732.12
[INFO 2017-06-26 15:45:12,431 main.py:50] epoch 18, training loss: 29941.35, average training loss: 67375.52, base loss: 27633.70
[INFO 2017-06-26 15:45:12,963 main.py:50] epoch 19, training loss: 32157.09, average training loss: 65614.60, base loss: 27730.20
[INFO 2017-06-26 15:45:13,495 main.py:50] epoch 20, training loss: 28576.58, average training loss: 63850.88, base loss: 27634.90
[INFO 2017-06-26 15:45:14,033 main.py:50] epoch 21, training loss: 30947.41, average training loss: 62355.27, base loss: 27722.40
[INFO 2017-06-26 15:45:14,562 main.py:50] epoch 22, training loss: 28069.86, average training loss: 60864.60, base loss: 27673.19
[INFO 2017-06-26 15:45:15,092 main.py:50] epoch 23, training loss: 25501.45, average training loss: 59391.14, base loss: 27526.60
[INFO 2017-06-26 15:45:15,629 main.py:50] epoch 24, training loss: 30566.42, average training loss: 58238.15, base loss: 27637.62
[INFO 2017-06-26 15:45:16,164 main.py:50] epoch 25, training loss: 28262.49, average training loss: 57085.24, base loss: 27646.76
[INFO 2017-06-26 15:45:16,698 main.py:50] epoch 26, training loss: 28812.21, average training loss: 56038.09, base loss: 27684.54
[INFO 2017-06-26 15:45:17,233 main.py:50] epoch 27, training loss: 27000.01, average training loss: 55001.01, base loss: 27649.19
[INFO 2017-06-26 15:45:17,765 main.py:50] epoch 28, training loss: 27189.29, average training loss: 54041.99, base loss: 27632.89
[INFO 2017-06-26 15:45:18,296 main.py:50] epoch 29, training loss: 25731.33, average training loss: 53098.30, base loss: 27562.41
[INFO 2017-06-26 15:45:18,830 main.py:50] epoch 30, training loss: 31693.83, average training loss: 52407.83, base loss: 27708.80
[INFO 2017-06-26 15:45:19,368 main.py:50] epoch 31, training loss: 26684.03, average training loss: 51603.97, base loss: 27680.04
[INFO 2017-06-26 15:45:19,902 main.py:50] epoch 32, training loss: 27828.67, average training loss: 50883.50, base loss: 27690.56
[INFO 2017-06-26 15:45:20,440 main.py:50] epoch 33, training loss: 27452.13, average training loss: 50194.34, base loss: 27691.85
[INFO 2017-06-26 15:45:20,979 main.py:50] epoch 34, training loss: 27643.76, average training loss: 49550.04, base loss: 27700.31
[INFO 2017-06-26 15:45:21,513 main.py:50] epoch 35, training loss: 30382.78, average training loss: 49017.62, base loss: 27793.19
[INFO 2017-06-26 15:45:22,049 main.py:50] epoch 36, training loss: 26786.28, average training loss: 48416.77, base loss: 27777.78
[INFO 2017-06-26 15:45:22,583 main.py:50] epoch 37, training loss: 24025.94, average training loss: 47774.91, base loss: 27682.51
[INFO 2017-06-26 15:45:23,113 main.py:50] epoch 38, training loss: 25400.83, average training loss: 47201.21, base loss: 27630.25
[INFO 2017-06-26 15:45:23,648 main.py:50] epoch 39, training loss: 28337.22, average training loss: 46729.61, base loss: 27667.83
[INFO 2017-06-26 15:45:24,187 main.py:50] epoch 40, training loss: 26839.90, average training loss: 46244.50, base loss: 27663.57
[INFO 2017-06-26 15:45:24,721 main.py:50] epoch 41, training loss: 24726.96, average training loss: 45732.18, base loss: 27603.94
[INFO 2017-06-26 15:45:25,254 main.py:50] epoch 42, training loss: 27541.81, average training loss: 45309.14, base loss: 27618.84
[INFO 2017-06-26 15:45:25,790 main.py:50] epoch 43, training loss: 27272.99, average training loss: 44899.23, base loss: 27627.02
[INFO 2017-06-26 15:45:26,322 main.py:50] epoch 44, training loss: 27826.00, average training loss: 44519.83, base loss: 27648.49
[INFO 2017-06-26 15:45:26,858 main.py:50] epoch 45, training loss: 25191.62, average training loss: 44099.65, base loss: 27607.49
[INFO 2017-06-26 15:45:27,396 main.py:50] epoch 46, training loss: 26011.30, average training loss: 43714.79, base loss: 27588.23
[INFO 2017-06-26 15:45:27,932 main.py:50] epoch 47, training loss: 27863.44, average training loss: 43384.55, base loss: 27612.00
[INFO 2017-06-26 15:45:28,467 main.py:50] epoch 48, training loss: 27076.69, average training loss: 43051.74, base loss: 27614.58
[INFO 2017-06-26 15:45:29,004 main.py:50] epoch 49, training loss: 26969.69, average training loss: 42730.10, base loss: 27618.56
[INFO 2017-06-26 15:45:29,535 main.py:50] epoch 50, training loss: 27910.96, average training loss: 42439.53, base loss: 27641.77
[INFO 2017-06-26 15:45:30,066 main.py:50] epoch 51, training loss: 27406.70, average training loss: 42150.43, base loss: 27655.13
[INFO 2017-06-26 15:45:30,605 main.py:50] epoch 52, training loss: 23858.80, average training loss: 41805.31, base loss: 27598.87
[INFO 2017-06-26 15:45:31,137 main.py:50] epoch 53, training loss: 27401.61, average training loss: 41538.57, base loss: 27615.41
[INFO 2017-06-26 15:45:31,672 main.py:50] epoch 54, training loss: 25202.92, average training loss: 41241.56, base loss: 27579.14
[INFO 2017-06-26 15:45:32,225 main.py:50] epoch 55, training loss: 27099.28, average training loss: 40989.02, base loss: 27588.63
[INFO 2017-06-26 15:45:32,760 main.py:50] epoch 56, training loss: 28329.91, average training loss: 40766.93, base loss: 27622.67
[INFO 2017-06-26 15:45:33,295 main.py:50] epoch 57, training loss: 26719.58, average training loss: 40524.74, base loss: 27626.95
[INFO 2017-06-26 15:45:33,830 main.py:50] epoch 58, training loss: 25830.61, average training loss: 40275.68, base loss: 27615.05
[INFO 2017-06-26 15:45:34,363 main.py:50] epoch 59, training loss: 25395.58, average training loss: 40027.68, base loss: 27595.53
[INFO 2017-06-26 15:45:34,901 main.py:50] epoch 60, training loss: 23597.70, average training loss: 39758.34, base loss: 27540.14
[INFO 2017-06-26 15:45:35,441 main.py:50] epoch 61, training loss: 26879.24, average training loss: 39550.61, base loss: 27551.23
[INFO 2017-06-26 15:45:35,979 main.py:50] epoch 62, training loss: 26566.79, average training loss: 39344.52, base loss: 27555.30
[INFO 2017-06-26 15:45:36,516 main.py:50] epoch 63, training loss: 26077.86, average training loss: 39137.23, base loss: 27558.80
[INFO 2017-06-26 15:45:37,050 main.py:50] epoch 64, training loss: 25976.46, average training loss: 38934.75, base loss: 27551.29
[INFO 2017-06-26 15:45:37,583 main.py:50] epoch 65, training loss: 24504.53, average training loss: 38716.11, base loss: 27521.79
[INFO 2017-06-26 15:45:38,124 main.py:50] epoch 66, training loss: 26718.87, average training loss: 38537.05, base loss: 27532.11
[INFO 2017-06-26 15:45:38,661 main.py:50] epoch 67, training loss: 22892.90, average training loss: 38306.99, base loss: 27476.81
[INFO 2017-06-26 15:45:39,196 main.py:50] epoch 68, training loss: 24192.70, average training loss: 38102.43, base loss: 27446.87
[INFO 2017-06-26 15:45:39,742 main.py:50] epoch 69, training loss: 26670.40, average training loss: 37939.12, base loss: 27457.40
[INFO 2017-06-26 15:45:40,281 main.py:50] epoch 70, training loss: 26614.15, average training loss: 37779.61, base loss: 27471.13
[INFO 2017-06-26 15:45:40,827 main.py:50] epoch 71, training loss: 26058.39, average training loss: 37616.82, base loss: 27477.15
[INFO 2017-06-26 15:45:41,396 main.py:50] epoch 72, training loss: 25149.15, average training loss: 37446.03, base loss: 27463.31
[INFO 2017-06-26 15:45:41,979 main.py:50] epoch 73, training loss: 26368.53, average training loss: 37296.33, base loss: 27474.58
[INFO 2017-06-26 15:45:42,561 main.py:50] epoch 74, training loss: 26165.64, average training loss: 37147.92, base loss: 27476.52
[INFO 2017-06-26 15:45:43,145 main.py:50] epoch 75, training loss: 26447.13, average training loss: 37007.12, base loss: 27493.75
[INFO 2017-06-26 15:45:43,727 main.py:50] epoch 76, training loss: 24322.54, average training loss: 36842.39, base loss: 27465.73
[INFO 2017-06-26 15:45:44,310 main.py:50] epoch 77, training loss: 26709.61, average training loss: 36712.48, base loss: 27477.45
[INFO 2017-06-26 15:45:44,892 main.py:50] epoch 78, training loss: 24697.98, average training loss: 36560.40, base loss: 27462.10
[INFO 2017-06-26 15:45:45,478 main.py:50] epoch 79, training loss: 24849.51, average training loss: 36414.01, base loss: 27444.28
[INFO 2017-06-26 15:45:46,060 main.py:50] epoch 80, training loss: 25845.37, average training loss: 36283.53, base loss: 27440.12
[INFO 2017-06-26 15:45:46,642 main.py:50] epoch 81, training loss: 25031.34, average training loss: 36146.31, base loss: 27431.13
[INFO 2017-06-26 15:45:47,225 main.py:50] epoch 82, training loss: 23801.52, average training loss: 35997.58, base loss: 27398.73
[INFO 2017-06-26 15:45:47,809 main.py:50] epoch 83, training loss: 25442.65, average training loss: 35871.93, base loss: 27392.29
[INFO 2017-06-26 15:45:48,397 main.py:50] epoch 84, training loss: 25352.94, average training loss: 35748.17, base loss: 27388.37
[INFO 2017-06-26 15:45:48,989 main.py:50] epoch 85, training loss: 26511.29, average training loss: 35640.77, base loss: 27401.48
[INFO 2017-06-26 15:45:49,589 main.py:50] epoch 86, training loss: 24179.52, average training loss: 35509.03, base loss: 27383.09
[INFO 2017-06-26 15:45:50,188 main.py:50] epoch 87, training loss: 24267.76, average training loss: 35381.29, base loss: 27358.36
[INFO 2017-06-26 15:45:50,787 main.py:50] epoch 88, training loss: 25053.37, average training loss: 35265.24, base loss: 27348.84
[INFO 2017-06-26 15:45:51,387 main.py:50] epoch 89, training loss: 25504.22, average training loss: 35156.79, base loss: 27349.12
[INFO 2017-06-26 15:45:51,995 main.py:50] epoch 90, training loss: 25580.21, average training loss: 35051.55, base loss: 27351.55
[INFO 2017-06-26 15:45:52,605 main.py:50] epoch 91, training loss: 23797.57, average training loss: 34929.22, base loss: 27328.67
[INFO 2017-06-26 15:45:53,231 main.py:50] epoch 92, training loss: 25075.51, average training loss: 34823.27, base loss: 27324.77
[INFO 2017-06-26 15:45:53,856 main.py:50] epoch 93, training loss: 24083.32, average training loss: 34709.02, base loss: 27306.34
[INFO 2017-06-26 15:45:54,483 main.py:50] epoch 94, training loss: 26738.46, average training loss: 34625.12, base loss: 27325.92
[INFO 2017-06-26 15:45:55,109 main.py:50] epoch 95, training loss: 24831.62, average training loss: 34523.10, base loss: 27322.87
[INFO 2017-06-26 15:45:55,736 main.py:50] epoch 96, training loss: 25872.09, average training loss: 34433.91, base loss: 27331.74
[INFO 2017-06-26 15:45:56,362 main.py:50] epoch 97, training loss: 25675.44, average training loss: 34344.54, base loss: 27340.70
[INFO 2017-06-26 15:45:56,988 main.py:50] epoch 98, training loss: 25073.53, average training loss: 34250.90, base loss: 27347.33
[INFO 2017-06-26 15:45:57,630 main.py:50] epoch 99, training loss: 23949.09, average training loss: 34147.88, base loss: 27331.42
[INFO 2017-06-26 15:45:57,630 main.py:52] epoch 99, testing
[INFO 2017-06-26 15:45:59,731 main.py:103] average testing loss: 20883.41, base loss: 16117.04
[INFO 2017-06-26 15:45:59,732 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 15:45:59,738 main.py:76] current best accuracy: 20883.41
[INFO 2017-06-26 15:46:00,366 main.py:50] epoch 100, training loss: 25929.32, average training loss: 34066.51, base loss: 27345.27
[INFO 2017-06-26 15:46:01,002 main.py:50] epoch 101, training loss: 25084.04, average training loss: 33978.44, base loss: 27348.41
[INFO 2017-06-26 15:46:01,647 main.py:50] epoch 102, training loss: 26478.07, average training loss: 33905.62, base loss: 27363.55
[INFO 2017-06-26 15:46:02,293 main.py:50] epoch 103, training loss: 27334.45, average training loss: 33842.44, base loss: 27401.21
[INFO 2017-06-26 15:46:02,938 main.py:50] epoch 104, training loss: 26836.53, average training loss: 33775.72, base loss: 27418.16
[INFO 2017-06-26 15:46:03,584 main.py:50] epoch 105, training loss: 25353.35, average training loss: 33696.26, base loss: 27418.58
[INFO 2017-06-26 15:46:04,247 main.py:50] epoch 106, training loss: 25395.25, average training loss: 33618.68, base loss: 27426.73
[INFO 2017-06-26 15:46:04,924 main.py:50] epoch 107, training loss: 25645.91, average training loss: 33544.86, base loss: 27427.93
[INFO 2017-06-26 15:46:05,600 main.py:50] epoch 108, training loss: 26514.79, average training loss: 33480.36, base loss: 27439.97
[INFO 2017-06-26 15:46:06,277 main.py:50] epoch 109, training loss: 26977.11, average training loss: 33421.24, base loss: 27465.88
[INFO 2017-06-26 15:46:06,954 main.py:50] epoch 110, training loss: 24506.19, average training loss: 33340.93, base loss: 27458.47
[INFO 2017-06-26 15:46:07,632 main.py:50] epoch 111, training loss: 26546.03, average training loss: 33280.26, base loss: 27473.73
[INFO 2017-06-26 15:46:08,309 main.py:50] epoch 112, training loss: 25042.64, average training loss: 33207.36, base loss: 27477.29
[INFO 2017-06-26 15:46:08,985 main.py:50] epoch 113, training loss: 25785.39, average training loss: 33142.25, base loss: 27487.83
[INFO 2017-06-26 15:46:09,662 main.py:50] epoch 114, training loss: 26675.57, average training loss: 33086.02, base loss: 27507.17
[INFO 2017-06-26 15:46:10,340 main.py:50] epoch 115, training loss: 25823.29, average training loss: 33023.41, base loss: 27514.98
[INFO 2017-06-26 15:46:11,018 main.py:50] epoch 116, training loss: 25785.67, average training loss: 32961.55, base loss: 27523.86
[INFO 2017-06-26 15:46:11,696 main.py:50] epoch 117, training loss: 25260.53, average training loss: 32896.29, base loss: 27529.19
[INFO 2017-06-26 15:46:12,372 main.py:50] epoch 118, training loss: 25512.50, average training loss: 32834.24, base loss: 27536.33
[INFO 2017-06-26 15:46:13,050 main.py:50] epoch 119, training loss: 23646.07, average training loss: 32757.67, base loss: 27519.91
[INFO 2017-06-26 15:46:13,726 main.py:50] epoch 120, training loss: 23213.22, average training loss: 32678.79, base loss: 27509.31
[INFO 2017-06-26 15:46:14,402 main.py:50] epoch 121, training loss: 22720.38, average training loss: 32597.16, base loss: 27480.32
[INFO 2017-06-26 15:46:15,079 main.py:50] epoch 122, training loss: 25274.27, average training loss: 32537.63, base loss: 27481.87
[INFO 2017-06-26 15:46:15,757 main.py:50] epoch 123, training loss: 24184.98, average training loss: 32470.27, base loss: 27474.67
[INFO 2017-06-26 15:46:16,434 main.py:50] epoch 124, training loss: 24034.76, average training loss: 32402.78, base loss: 27472.81
[INFO 2017-06-26 15:46:17,112 main.py:50] epoch 125, training loss: 24582.28, average training loss: 32340.72, base loss: 27473.01
[INFO 2017-06-26 15:46:17,790 main.py:50] epoch 126, training loss: 25372.22, average training loss: 32285.85, base loss: 27480.01
[INFO 2017-06-26 15:46:18,467 main.py:50] epoch 127, training loss: 25694.66, average training loss: 32234.35, base loss: 27486.34
[INFO 2017-06-26 15:46:19,145 main.py:50] epoch 128, training loss: 24140.20, average training loss: 32171.61, base loss: 27483.11
[INFO 2017-06-26 15:46:19,823 main.py:50] epoch 129, training loss: 23593.17, average training loss: 32105.62, base loss: 27474.53
[INFO 2017-06-26 15:46:20,501 main.py:50] epoch 130, training loss: 24607.72, average training loss: 32048.38, base loss: 27469.90
[INFO 2017-06-26 15:46:21,179 main.py:50] epoch 131, training loss: 26083.59, average training loss: 32003.20, base loss: 27485.54
[INFO 2017-06-26 15:46:21,872 main.py:50] epoch 132, training loss: 24995.10, average training loss: 31950.50, base loss: 27484.48
[INFO 2017-06-26 15:46:22,548 main.py:50] epoch 133, training loss: 23728.84, average training loss: 31889.15, base loss: 27473.85
[INFO 2017-06-26 15:46:23,226 main.py:50] epoch 134, training loss: 24665.14, average training loss: 31835.64, base loss: 27479.84
[INFO 2017-06-26 15:46:23,903 main.py:50] epoch 135, training loss: 22525.90, average training loss: 31767.18, base loss: 27462.15
[INFO 2017-06-26 15:46:24,581 main.py:50] epoch 136, training loss: 25281.65, average training loss: 31719.84, base loss: 27470.28
[INFO 2017-06-26 15:46:25,258 main.py:50] epoch 137, training loss: 24557.92, average training loss: 31667.95, base loss: 27475.09
[INFO 2017-06-26 15:46:25,936 main.py:50] epoch 138, training loss: 23741.41, average training loss: 31610.92, base loss: 27471.12
[INFO 2017-06-26 15:46:26,613 main.py:50] epoch 139, training loss: 23409.42, average training loss: 31552.34, base loss: 27460.58
[INFO 2017-06-26 15:46:27,291 main.py:50] epoch 140, training loss: 24876.10, average training loss: 31504.99, base loss: 27467.72
[INFO 2017-06-26 15:46:27,968 main.py:50] epoch 141, training loss: 27412.45, average training loss: 31476.17, base loss: 27495.43
[INFO 2017-06-26 15:46:28,645 main.py:50] epoch 142, training loss: 22915.65, average training loss: 31416.30, base loss: 27482.10
[INFO 2017-06-26 15:46:29,324 main.py:50] epoch 143, training loss: 24444.29, average training loss: 31367.89, base loss: 27486.84
[INFO 2017-06-26 15:46:30,001 main.py:50] epoch 144, training loss: 23964.16, average training loss: 31316.83, base loss: 27481.52
[INFO 2017-06-26 15:46:30,678 main.py:50] epoch 145, training loss: 24887.84, average training loss: 31272.79, base loss: 27488.92
[INFO 2017-06-26 15:46:31,355 main.py:50] epoch 146, training loss: 24541.53, average training loss: 31227.00, base loss: 27489.17
[INFO 2017-06-26 15:46:32,033 main.py:50] epoch 147, training loss: 22802.60, average training loss: 31170.08, base loss: 27482.90
[INFO 2017-06-26 15:46:32,711 main.py:50] epoch 148, training loss: 23849.72, average training loss: 31120.95, base loss: 27478.66
[INFO 2017-06-26 15:46:33,387 main.py:50] epoch 149, training loss: 24303.46, average training loss: 31075.50, base loss: 27484.99
[INFO 2017-06-26 15:46:34,065 main.py:50] epoch 150, training loss: 26009.12, average training loss: 31041.95, base loss: 27502.72
[INFO 2017-06-26 15:46:34,743 main.py:50] epoch 151, training loss: 22078.29, average training loss: 30982.98, base loss: 27487.59
[INFO 2017-06-26 15:46:35,420 main.py:50] epoch 152, training loss: 24762.12, average training loss: 30942.32, base loss: 27491.65
[INFO 2017-06-26 15:46:36,097 main.py:50] epoch 153, training loss: 24414.37, average training loss: 30899.93, base loss: 27493.30
[INFO 2017-06-26 15:46:36,776 main.py:50] epoch 154, training loss: 23105.77, average training loss: 30849.64, base loss: 27488.55
[INFO 2017-06-26 15:46:37,453 main.py:50] epoch 155, training loss: 25700.48, average training loss: 30816.64, base loss: 27510.27
[INFO 2017-06-26 15:46:38,131 main.py:50] epoch 156, training loss: 23589.22, average training loss: 30770.60, base loss: 27511.60
[INFO 2017-06-26 15:46:38,808 main.py:50] epoch 157, training loss: 22413.45, average training loss: 30717.71, base loss: 27499.53
[INFO 2017-06-26 15:46:39,485 main.py:50] epoch 158, training loss: 24290.31, average training loss: 30677.28, base loss: 27501.98
[INFO 2017-06-26 15:46:40,163 main.py:50] epoch 159, training loss: 23682.91, average training loss: 30633.57, base loss: 27502.37
[INFO 2017-06-26 15:46:40,840 main.py:50] epoch 160, training loss: 22300.48, average training loss: 30581.81, base loss: 27489.46
[INFO 2017-06-26 15:46:41,518 main.py:50] epoch 161, training loss: 25181.57, average training loss: 30548.48, base loss: 27502.33
[INFO 2017-06-26 15:46:42,195 main.py:50] epoch 162, training loss: 21776.62, average training loss: 30494.66, base loss: 27484.04
[INFO 2017-06-26 15:46:42,871 main.py:50] epoch 163, training loss: 23871.57, average training loss: 30454.28, base loss: 27479.74
[INFO 2017-06-26 15:46:43,549 main.py:50] epoch 164, training loss: 24679.28, average training loss: 30419.28, base loss: 27486.34
[INFO 2017-06-26 15:46:44,226 main.py:50] epoch 165, training loss: 22278.02, average training loss: 30370.23, base loss: 27476.90
[INFO 2017-06-26 15:46:44,904 main.py:50] epoch 166, training loss: 23904.36, average training loss: 30331.51, base loss: 27479.97
[INFO 2017-06-26 15:46:45,582 main.py:50] epoch 167, training loss: 24458.12, average training loss: 30296.55, base loss: 27485.97
[INFO 2017-06-26 15:46:46,261 main.py:50] epoch 168, training loss: 23519.58, average training loss: 30256.45, base loss: 27483.35
[INFO 2017-06-26 15:46:46,938 main.py:50] epoch 169, training loss: 24486.85, average training loss: 30222.52, base loss: 27494.23
[INFO 2017-06-26 15:46:47,616 main.py:50] epoch 170, training loss: 26043.40, average training loss: 30198.08, base loss: 27513.25
[INFO 2017-06-26 15:46:48,294 main.py:50] epoch 171, training loss: 21819.24, average training loss: 30149.36, base loss: 27495.89
[INFO 2017-06-26 15:46:48,974 main.py:50] epoch 172, training loss: 21862.40, average training loss: 30101.46, base loss: 27479.42
[INFO 2017-06-26 15:46:49,651 main.py:50] epoch 173, training loss: 22823.94, average training loss: 30059.64, base loss: 27474.96
[INFO 2017-06-26 15:46:50,329 main.py:50] epoch 174, training loss: 24804.51, average training loss: 30029.61, base loss: 27483.84
[INFO 2017-06-26 15:46:51,007 main.py:50] epoch 175, training loss: 24767.80, average training loss: 29999.71, base loss: 27491.70
[INFO 2017-06-26 15:46:51,701 main.py:50] epoch 176, training loss: 22504.45, average training loss: 29957.36, base loss: 27477.38
[INFO 2017-06-26 15:46:52,379 main.py:50] epoch 177, training loss: 22165.93, average training loss: 29913.59, base loss: 27465.82
[INFO 2017-06-26 15:46:53,057 main.py:50] epoch 178, training loss: 22991.55, average training loss: 29874.92, base loss: 27464.32
[INFO 2017-06-26 15:46:53,734 main.py:50] epoch 179, training loss: 25848.94, average training loss: 29852.55, base loss: 27479.13
[INFO 2017-06-26 15:46:54,412 main.py:50] epoch 180, training loss: 24398.40, average training loss: 29822.42, base loss: 27486.34
[INFO 2017-06-26 15:46:55,089 main.py:50] epoch 181, training loss: 23048.93, average training loss: 29785.20, base loss: 27483.14
[INFO 2017-06-26 15:46:55,766 main.py:50] epoch 182, training loss: 22747.44, average training loss: 29746.75, base loss: 27473.49
[INFO 2017-06-26 15:46:56,444 main.py:50] epoch 183, training loss: 25414.76, average training loss: 29723.20, base loss: 27482.21
[INFO 2017-06-26 15:46:57,122 main.py:50] epoch 184, training loss: 21886.56, average training loss: 29680.84, base loss: 27471.01
[INFO 2017-06-26 15:46:57,800 main.py:50] epoch 185, training loss: 24290.43, average training loss: 29651.86, base loss: 27476.13
[INFO 2017-06-26 15:46:58,478 main.py:50] epoch 186, training loss: 24788.84, average training loss: 29625.86, base loss: 27482.64
[INFO 2017-06-26 15:46:59,156 main.py:50] epoch 187, training loss: 21699.89, average training loss: 29583.70, base loss: 27471.44
[INFO 2017-06-26 15:46:59,834 main.py:50] epoch 188, training loss: 22933.01, average training loss: 29548.51, base loss: 27466.76
[INFO 2017-06-26 15:47:00,513 main.py:50] epoch 189, training loss: 24025.21, average training loss: 29519.44, base loss: 27471.10
[INFO 2017-06-26 15:47:01,191 main.py:50] epoch 190, training loss: 25164.45, average training loss: 29496.64, base loss: 27479.67
[INFO 2017-06-26 15:47:01,869 main.py:50] epoch 191, training loss: 25383.94, average training loss: 29475.22, base loss: 27491.94
[INFO 2017-06-26 15:47:02,547 main.py:50] epoch 192, training loss: 22882.35, average training loss: 29441.06, base loss: 27483.53
[INFO 2017-06-26 15:47:03,225 main.py:50] epoch 193, training loss: 24818.46, average training loss: 29417.23, base loss: 27491.91
[INFO 2017-06-26 15:47:03,902 main.py:50] epoch 194, training loss: 26224.02, average training loss: 29400.85, base loss: 27515.35
[INFO 2017-06-26 15:47:04,579 main.py:50] epoch 195, training loss: 25390.71, average training loss: 29380.39, base loss: 27532.05
[INFO 2017-06-26 15:47:05,257 main.py:50] epoch 196, training loss: 21693.82, average training loss: 29341.38, base loss: 27519.60
[INFO 2017-06-26 15:47:05,934 main.py:50] epoch 197, training loss: 21858.81, average training loss: 29303.58, base loss: 27507.65
[INFO 2017-06-26 15:47:06,612 main.py:50] epoch 198, training loss: 24432.05, average training loss: 29279.10, base loss: 27514.38
[INFO 2017-06-26 15:47:07,290 main.py:50] epoch 199, training loss: 23202.47, average training loss: 29248.72, base loss: 27513.73
[INFO 2017-06-26 15:47:07,290 main.py:52] epoch 199, testing
[INFO 2017-06-26 15:47:09,545 main.py:103] average testing loss: 21644.14, base loss: 15632.31
[INFO 2017-06-26 15:47:09,546 main.py:76] current best accuracy: 20883.41
[INFO 2017-06-26 15:47:10,225 main.py:50] epoch 200, training loss: 23201.91, average training loss: 29218.64, base loss: 27512.92
[INFO 2017-06-26 15:47:10,903 main.py:50] epoch 201, training loss: 20864.95, average training loss: 29177.28, base loss: 27499.64
[INFO 2017-06-26 15:47:11,582 main.py:50] epoch 202, training loss: 22922.78, average training loss: 29146.47, base loss: 27496.19
[INFO 2017-06-26 15:47:12,259 main.py:50] epoch 203, training loss: 25080.91, average training loss: 29126.54, base loss: 27504.04
[INFO 2017-06-26 15:47:12,937 main.py:50] epoch 204, training loss: 25542.77, average training loss: 29109.06, base loss: 27517.48
[INFO 2017-06-26 15:47:13,615 main.py:50] epoch 205, training loss: 24399.31, average training loss: 29086.20, base loss: 27524.82
[INFO 2017-06-26 15:47:14,293 main.py:50] epoch 206, training loss: 24097.49, average training loss: 29062.10, base loss: 27529.26
[INFO 2017-06-26 15:47:14,971 main.py:50] epoch 207, training loss: 23095.76, average training loss: 29033.41, base loss: 27527.72
[INFO 2017-06-26 15:47:15,648 main.py:50] epoch 208, training loss: 22822.56, average training loss: 29003.70, base loss: 27523.26
[INFO 2017-06-26 15:47:16,341 main.py:50] epoch 209, training loss: 24287.54, average training loss: 28981.24, base loss: 27534.84
[INFO 2017-06-26 15:47:17,020 main.py:50] epoch 210, training loss: 23859.85, average training loss: 28956.97, base loss: 27535.92
[INFO 2017-06-26 15:47:17,698 main.py:50] epoch 211, training loss: 23707.73, average training loss: 28932.21, base loss: 27548.39
[INFO 2017-06-26 15:47:18,375 main.py:50] epoch 212, training loss: 22646.03, average training loss: 28902.69, base loss: 27549.77
[INFO 2017-06-26 15:47:19,052 main.py:50] epoch 213, training loss: 21340.43, average training loss: 28867.36, base loss: 27535.87
[INFO 2017-06-26 15:47:19,729 main.py:50] epoch 214, training loss: 24482.96, average training loss: 28846.96, base loss: 27544.76
[INFO 2017-06-26 15:47:20,407 main.py:50] epoch 215, training loss: 22374.37, average training loss: 28817.00, base loss: 27538.07
[INFO 2017-06-26 15:47:21,085 main.py:50] epoch 216, training loss: 23240.62, average training loss: 28791.30, base loss: 27538.97
[INFO 2017-06-26 15:47:21,764 main.py:50] epoch 217, training loss: 22933.81, average training loss: 28764.43, base loss: 27536.19
[INFO 2017-06-26 15:47:22,442 main.py:50] epoch 218, training loss: 25292.58, average training loss: 28748.58, base loss: 27544.70
[INFO 2017-06-26 15:47:23,120 main.py:50] epoch 219, training loss: 24322.03, average training loss: 28728.46, base loss: 27555.66
[INFO 2017-06-26 15:47:23,798 main.py:50] epoch 220, training loss: 23292.84, average training loss: 28703.86, base loss: 27557.43
[INFO 2017-06-26 15:47:24,476 main.py:50] epoch 221, training loss: 23823.80, average training loss: 28681.88, base loss: 27564.01
[INFO 2017-06-26 15:47:25,155 main.py:50] epoch 222, training loss: 22738.92, average training loss: 28655.23, base loss: 27559.61
[INFO 2017-06-26 15:47:25,832 main.py:50] epoch 223, training loss: 22565.67, average training loss: 28628.04, base loss: 27558.20
[INFO 2017-06-26 15:47:26,510 main.py:50] epoch 224, training loss: 22416.11, average training loss: 28600.44, base loss: 27553.49
[INFO 2017-06-26 15:47:27,187 main.py:50] epoch 225, training loss: 24427.52, average training loss: 28581.97, base loss: 27561.58
[INFO 2017-06-26 15:47:27,865 main.py:50] epoch 226, training loss: 22191.77, average training loss: 28553.82, base loss: 27562.02
[INFO 2017-06-26 15:47:28,543 main.py:50] epoch 227, training loss: 22404.83, average training loss: 28526.85, base loss: 27558.21
[INFO 2017-06-26 15:47:29,221 main.py:50] epoch 228, training loss: 22997.01, average training loss: 28502.70, base loss: 27555.54
[INFO 2017-06-26 15:47:29,899 main.py:50] epoch 229, training loss: 22195.00, average training loss: 28475.28, base loss: 27551.11
[INFO 2017-06-26 15:47:30,578 main.py:50] epoch 230, training loss: 21442.53, average training loss: 28444.83, base loss: 27545.29
[INFO 2017-06-26 15:47:31,257 main.py:50] epoch 231, training loss: 22738.85, average training loss: 28420.24, base loss: 27545.43
[INFO 2017-06-26 15:47:31,935 main.py:50] epoch 232, training loss: 24207.89, average training loss: 28402.16, base loss: 27553.29
[INFO 2017-06-26 15:47:32,613 main.py:50] epoch 233, training loss: 22962.12, average training loss: 28378.91, base loss: 27558.31
[INFO 2017-06-26 15:47:33,290 main.py:50] epoch 234, training loss: 23557.04, average training loss: 28358.39, base loss: 27563.80
[INFO 2017-06-26 15:47:33,967 main.py:50] epoch 235, training loss: 22957.57, average training loss: 28335.51, base loss: 27568.51
[INFO 2017-06-26 15:47:34,646 main.py:50] epoch 236, training loss: 24957.00, average training loss: 28321.25, base loss: 27581.05
[INFO 2017-06-26 15:47:35,324 main.py:50] epoch 237, training loss: 21318.13, average training loss: 28291.83, base loss: 27567.26
[INFO 2017-06-26 15:47:36,002 main.py:50] epoch 238, training loss: 22655.79, average training loss: 28268.25, base loss: 27561.84
[INFO 2017-06-26 15:47:36,680 main.py:50] epoch 239, training loss: 23246.81, average training loss: 28247.32, base loss: 27565.45
[INFO 2017-06-26 15:47:37,358 main.py:50] epoch 240, training loss: 22886.06, average training loss: 28225.08, base loss: 27563.03
[INFO 2017-06-26 15:47:38,036 main.py:50] epoch 241, training loss: 22691.86, average training loss: 28202.21, base loss: 27561.36
[INFO 2017-06-26 15:47:38,716 main.py:50] epoch 242, training loss: 21752.13, average training loss: 28175.67, base loss: 27551.74
[INFO 2017-06-26 15:47:39,395 main.py:50] epoch 243, training loss: 23715.11, average training loss: 28157.39, base loss: 27557.87
[INFO 2017-06-26 15:47:40,072 main.py:50] epoch 244, training loss: 21436.33, average training loss: 28129.96, base loss: 27547.87
[INFO 2017-06-26 15:47:40,750 main.py:50] epoch 245, training loss: 26358.01, average training loss: 28122.75, base loss: 27572.27
[INFO 2017-06-26 15:47:41,429 main.py:50] epoch 246, training loss: 24271.96, average training loss: 28107.16, base loss: 27574.97
[INFO 2017-06-26 15:47:42,108 main.py:50] epoch 247, training loss: 22723.73, average training loss: 28085.46, base loss: 27568.88
[INFO 2017-06-26 15:47:42,787 main.py:50] epoch 248, training loss: 21738.81, average training loss: 28059.97, base loss: 27561.25
[INFO 2017-06-26 15:47:43,465 main.py:50] epoch 249, training loss: 23375.35, average training loss: 28041.23, base loss: 27563.85
[INFO 2017-06-26 15:47:44,142 main.py:50] epoch 250, training loss: 20497.71, average training loss: 28011.17, base loss: 27550.90
[INFO 2017-06-26 15:47:44,821 main.py:50] epoch 251, training loss: 23768.46, average training loss: 27994.34, base loss: 27555.96
[INFO 2017-06-26 15:47:45,499 main.py:50] epoch 252, training loss: 22967.17, average training loss: 27974.47, base loss: 27553.67
[INFO 2017-06-26 15:47:46,195 main.py:50] epoch 253, training loss: 22581.50, average training loss: 27953.24, base loss: 27557.26
[INFO 2017-06-26 15:47:46,874 main.py:50] epoch 254, training loss: 22469.76, average training loss: 27931.73, base loss: 27551.80
[INFO 2017-06-26 15:47:47,552 main.py:50] epoch 255, training loss: 22192.80, average training loss: 27909.31, base loss: 27548.66
[INFO 2017-06-26 15:47:48,230 main.py:50] epoch 256, training loss: 25360.13, average training loss: 27899.40, base loss: 27564.97
[INFO 2017-06-26 15:47:48,908 main.py:50] epoch 257, training loss: 23927.17, average training loss: 27884.00, base loss: 27571.43
[INFO 2017-06-26 15:47:49,587 main.py:50] epoch 258, training loss: 20696.99, average training loss: 27856.25, base loss: 27556.79
[INFO 2017-06-26 15:47:50,264 main.py:50] epoch 259, training loss: 22547.95, average training loss: 27835.83, base loss: 27558.29
[INFO 2017-06-26 15:47:50,942 main.py:50] epoch 260, training loss: 22643.83, average training loss: 27815.94, base loss: 27558.44
[INFO 2017-06-26 15:47:51,620 main.py:50] epoch 261, training loss: 22851.44, average training loss: 27796.99, base loss: 27561.82
[INFO 2017-06-26 15:47:52,300 main.py:50] epoch 262, training loss: 22876.42, average training loss: 27778.28, base loss: 27557.31
[INFO 2017-06-26 15:47:52,977 main.py:50] epoch 263, training loss: 22658.51, average training loss: 27758.89, base loss: 27558.69
[INFO 2017-06-26 15:47:53,656 main.py:50] epoch 264, training loss: 23401.10, average training loss: 27742.45, base loss: 27561.12
[INFO 2017-06-26 15:47:54,336 main.py:50] epoch 265, training loss: 22762.35, average training loss: 27723.72, base loss: 27556.77
[INFO 2017-06-26 15:47:55,016 main.py:50] epoch 266, training loss: 22260.53, average training loss: 27703.26, base loss: 27556.34
[INFO 2017-06-26 15:47:55,697 main.py:50] epoch 267, training loss: 22081.95, average training loss: 27682.29, base loss: 27552.31
[INFO 2017-06-26 15:47:56,377 main.py:50] epoch 268, training loss: 22368.67, average training loss: 27662.53, base loss: 27549.73
[INFO 2017-06-26 15:47:57,058 main.py:50] epoch 269, training loss: 22281.44, average training loss: 27642.60, base loss: 27547.81
[INFO 2017-06-26 15:47:57,736 main.py:50] epoch 270, training loss: 23649.91, average training loss: 27627.87, base loss: 27554.53
[INFO 2017-06-26 15:47:58,415 main.py:50] epoch 271, training loss: 23669.54, average training loss: 27613.32, base loss: 27558.91
[INFO 2017-06-26 15:47:59,094 main.py:50] epoch 272, training loss: 22750.81, average training loss: 27595.51, base loss: 27561.17
[INFO 2017-06-26 15:47:59,771 main.py:50] epoch 273, training loss: 21982.25, average training loss: 27575.02, base loss: 27558.83
[INFO 2017-06-26 15:48:00,451 main.py:50] epoch 274, training loss: 21761.82, average training loss: 27553.88, base loss: 27555.77
[INFO 2017-06-26 15:48:01,130 main.py:50] epoch 275, training loss: 21371.88, average training loss: 27531.48, base loss: 27552.96
[INFO 2017-06-26 15:48:01,808 main.py:50] epoch 276, training loss: 21524.14, average training loss: 27509.80, base loss: 27545.90
[INFO 2017-06-26 15:48:02,487 main.py:50] epoch 277, training loss: 20875.00, average training loss: 27485.93, base loss: 27537.85
[INFO 2017-06-26 15:48:03,166 main.py:50] epoch 278, training loss: 21763.19, average training loss: 27465.42, base loss: 27531.31
[INFO 2017-06-26 15:48:03,847 main.py:50] epoch 279, training loss: 21600.13, average training loss: 27444.47, base loss: 27528.02
[INFO 2017-06-26 15:48:04,526 main.py:50] epoch 280, training loss: 21356.21, average training loss: 27422.80, base loss: 27522.80
[INFO 2017-06-26 15:48:05,206 main.py:50] epoch 281, training loss: 21670.45, average training loss: 27402.41, base loss: 27520.79
[INFO 2017-06-26 15:48:05,884 main.py:50] epoch 282, training loss: 22621.06, average training loss: 27385.51, base loss: 27523.30
[INFO 2017-06-26 15:48:06,562 main.py:50] epoch 283, training loss: 22673.18, average training loss: 27368.92, base loss: 27526.63
[INFO 2017-06-26 15:48:07,240 main.py:50] epoch 284, training loss: 22989.53, average training loss: 27353.55, base loss: 27528.40
[INFO 2017-06-26 15:48:07,920 main.py:50] epoch 285, training loss: 23232.11, average training loss: 27339.14, base loss: 27535.13
[INFO 2017-06-26 15:48:08,599 main.py:50] epoch 286, training loss: 24047.09, average training loss: 27327.67, base loss: 27543.52
[INFO 2017-06-26 15:48:09,278 main.py:50] epoch 287, training loss: 21248.57, average training loss: 27306.56, base loss: 27538.05
[INFO 2017-06-26 15:48:09,959 main.py:50] epoch 288, training loss: 22477.29, average training loss: 27289.85, base loss: 27539.15
[INFO 2017-06-26 15:48:10,639 main.py:50] epoch 289, training loss: 21290.86, average training loss: 27269.17, base loss: 27532.67
[INFO 2017-06-26 15:48:11,318 main.py:50] epoch 290, training loss: 23855.60, average training loss: 27257.44, base loss: 27540.88
[INFO 2017-06-26 15:48:11,997 main.py:50] epoch 291, training loss: 20877.40, average training loss: 27235.59, base loss: 27536.40
[INFO 2017-06-26 15:48:12,676 main.py:50] epoch 292, training loss: 22569.38, average training loss: 27219.66, base loss: 27537.07
[INFO 2017-06-26 15:48:13,355 main.py:50] epoch 293, training loss: 21625.82, average training loss: 27200.63, base loss: 27533.61
[INFO 2017-06-26 15:48:14,035 main.py:50] epoch 294, training loss: 21462.86, average training loss: 27181.18, base loss: 27531.40
[INFO 2017-06-26 15:48:14,714 main.py:50] epoch 295, training loss: 21396.43, average training loss: 27161.64, base loss: 27529.35
[INFO 2017-06-26 15:48:15,393 main.py:50] epoch 296, training loss: 25253.77, average training loss: 27155.22, base loss: 27545.12
[INFO 2017-06-26 15:48:16,087 main.py:50] epoch 297, training loss: 24396.09, average training loss: 27145.96, base loss: 27555.35
[INFO 2017-06-26 15:48:16,776 main.py:50] epoch 298, training loss: 24373.89, average training loss: 27136.69, base loss: 27562.57
[INFO 2017-06-26 15:48:17,460 main.py:50] epoch 299, training loss: 22065.61, average training loss: 27119.78, base loss: 27563.53
[INFO 2017-06-26 15:48:17,460 main.py:52] epoch 299, testing
[INFO 2017-06-26 15:48:19,727 main.py:103] average testing loss: 25394.96, base loss: 16407.50
[INFO 2017-06-26 15:48:19,728 main.py:76] current best accuracy: 20883.41
[INFO 2017-06-26 15:48:20,408 main.py:50] epoch 300, training loss: 22715.13, average training loss: 27105.15, base loss: 27563.44
[INFO 2017-06-26 15:48:21,088 main.py:50] epoch 301, training loss: 21343.59, average training loss: 27086.07, base loss: 27559.04
[INFO 2017-06-26 15:48:21,768 main.py:50] epoch 302, training loss: 22168.02, average training loss: 27069.84, base loss: 27559.02
[INFO 2017-06-26 15:48:22,451 main.py:50] epoch 303, training loss: 24353.14, average training loss: 27060.90, base loss: 27566.70
[INFO 2017-06-26 15:48:23,130 main.py:50] epoch 304, training loss: 21714.15, average training loss: 27043.37, base loss: 27559.60
[INFO 2017-06-26 15:48:23,808 main.py:50] epoch 305, training loss: 23324.51, average training loss: 27031.22, base loss: 27562.50
[INFO 2017-06-26 15:48:24,485 main.py:50] epoch 306, training loss: 21878.51, average training loss: 27014.44, base loss: 27559.31
[INFO 2017-06-26 15:48:25,163 main.py:50] epoch 307, training loss: 23956.75, average training loss: 27004.51, base loss: 27569.08
[INFO 2017-06-26 15:48:25,842 main.py:50] epoch 308, training loss: 20930.62, average training loss: 26984.85, base loss: 27562.97
[INFO 2017-06-26 15:48:26,521 main.py:50] epoch 309, training loss: 20983.16, average training loss: 26965.49, base loss: 27555.04
[INFO 2017-06-26 15:48:27,200 main.py:50] epoch 310, training loss: 22868.49, average training loss: 26952.32, base loss: 27558.18
[INFO 2017-06-26 15:48:27,879 main.py:50] epoch 311, training loss: 20905.50, average training loss: 26932.94, base loss: 27550.81
[INFO 2017-06-26 15:48:28,559 main.py:50] epoch 312, training loss: 23301.91, average training loss: 26921.34, base loss: 27555.54
[INFO 2017-06-26 15:48:29,236 main.py:50] epoch 313, training loss: 20553.42, average training loss: 26901.06, base loss: 27546.49
[INFO 2017-06-26 15:48:29,923 main.py:50] epoch 314, training loss: 19272.84, average training loss: 26876.84, base loss: 27533.14
[INFO 2017-06-26 15:48:30,602 main.py:50] epoch 315, training loss: 20836.55, average training loss: 26857.73, base loss: 27525.46
[INFO 2017-06-26 15:48:31,283 main.py:50] epoch 316, training loss: 23081.68, average training loss: 26845.81, base loss: 27528.68
[INFO 2017-06-26 15:48:31,979 main.py:50] epoch 317, training loss: 21933.10, average training loss: 26830.36, base loss: 27526.80
[INFO 2017-06-26 15:48:32,659 main.py:50] epoch 318, training loss: 21483.62, average training loss: 26813.60, base loss: 27522.05
[INFO 2017-06-26 15:48:33,376 main.py:50] epoch 319, training loss: 21225.79, average training loss: 26796.14, base loss: 27516.84
[INFO 2017-06-26 15:48:34,110 main.py:50] epoch 320, training loss: 21595.31, average training loss: 26779.94, base loss: 27514.67
[INFO 2017-06-26 15:48:34,815 main.py:50] epoch 321, training loss: 22227.33, average training loss: 26765.80, base loss: 27512.93
[INFO 2017-06-26 15:48:35,554 main.py:50] epoch 322, training loss: 20758.29, average training loss: 26747.20, base loss: 27510.01
[INFO 2017-06-26 15:48:36,245 main.py:50] epoch 323, training loss: 22939.24, average training loss: 26735.45, base loss: 27517.53
[INFO 2017-06-26 15:48:36,926 main.py:50] epoch 324, training loss: 22997.88, average training loss: 26723.95, base loss: 27523.40
[INFO 2017-06-26 15:48:37,607 main.py:50] epoch 325, training loss: 21547.64, average training loss: 26708.07, base loss: 27523.72
[INFO 2017-06-26 15:48:38,285 main.py:50] epoch 326, training loss: 22045.31, average training loss: 26693.81, base loss: 27525.35
[INFO 2017-06-26 15:48:38,965 main.py:50] epoch 327, training loss: 20232.96, average training loss: 26674.11, base loss: 27522.33
[INFO 2017-06-26 15:48:39,645 main.py:50] epoch 328, training loss: 23598.74, average training loss: 26664.77, base loss: 27527.65
[INFO 2017-06-26 15:48:40,326 main.py:50] epoch 329, training loss: 23445.97, average training loss: 26655.01, base loss: 27534.51
[INFO 2017-06-26 15:48:41,022 main.py:50] epoch 330, training loss: 19798.48, average training loss: 26634.30, base loss: 27523.32
[INFO 2017-06-26 15:48:41,702 main.py:50] epoch 331, training loss: 20728.57, average training loss: 26616.51, base loss: 27519.81
[INFO 2017-06-26 15:48:42,381 main.py:50] epoch 332, training loss: 21982.89, average training loss: 26602.59, base loss: 27518.56
[INFO 2017-06-26 15:48:43,062 main.py:50] epoch 333, training loss: 22446.76, average training loss: 26590.15, base loss: 27521.87
[INFO 2017-06-26 15:48:43,741 main.py:50] epoch 334, training loss: 21232.42, average training loss: 26574.16, base loss: 27520.42
[INFO 2017-06-26 15:48:44,420 main.py:50] epoch 335, training loss: 21560.16, average training loss: 26559.24, base loss: 27515.85
[INFO 2017-06-26 15:48:45,099 main.py:50] epoch 336, training loss: 19855.86, average training loss: 26539.34, base loss: 27506.02
[INFO 2017-06-26 15:48:45,777 main.py:50] epoch 337, training loss: 20929.33, average training loss: 26522.75, base loss: 27501.42
[INFO 2017-06-26 15:48:46,457 main.py:50] epoch 338, training loss: 19447.77, average training loss: 26501.88, base loss: 27491.61
[INFO 2017-06-26 15:48:47,140 main.py:50] epoch 339, training loss: 21266.50, average training loss: 26486.48, base loss: 27490.15
[INFO 2017-06-26 15:48:47,821 main.py:50] epoch 340, training loss: 21043.66, average training loss: 26470.52, base loss: 27482.24
[INFO 2017-06-26 15:48:48,502 main.py:50] epoch 341, training loss: 20940.07, average training loss: 26454.35, base loss: 27477.20
[INFO 2017-06-26 15:48:49,180 main.py:50] epoch 342, training loss: 21868.65, average training loss: 26440.98, base loss: 27477.66
[INFO 2017-06-26 15:48:49,859 main.py:50] epoch 343, training loss: 21497.14, average training loss: 26426.61, base loss: 27474.37
[INFO 2017-06-26 15:48:50,539 main.py:50] epoch 344, training loss: 22566.74, average training loss: 26415.42, base loss: 27480.03
[INFO 2017-06-26 15:48:51,234 main.py:50] epoch 345, training loss: 22073.85, average training loss: 26402.87, base loss: 27484.99
[INFO 2017-06-26 15:48:51,968 main.py:50] epoch 346, training loss: 21212.33, average training loss: 26387.91, base loss: 27483.55
[INFO 2017-06-26 15:48:52,692 main.py:50] epoch 347, training loss: 23189.93, average training loss: 26378.72, base loss: 27491.15
[INFO 2017-06-26 15:48:53,406 main.py:50] epoch 348, training loss: 20599.54, average training loss: 26362.16, base loss: 27484.27
[INFO 2017-06-26 15:48:54,102 main.py:50] epoch 349, training loss: 25271.60, average training loss: 26359.05, base loss: 27499.02
[INFO 2017-06-26 15:48:54,782 main.py:50] epoch 350, training loss: 23307.32, average training loss: 26350.35, base loss: 27507.22
[INFO 2017-06-26 15:48:55,460 main.py:50] epoch 351, training loss: 19993.51, average training loss: 26332.29, base loss: 27500.04
[INFO 2017-06-26 15:48:56,168 main.py:50] epoch 352, training loss: 23768.03, average training loss: 26325.03, base loss: 27506.14
[INFO 2017-06-26 15:48:56,878 main.py:50] epoch 353, training loss: 20191.84, average training loss: 26307.70, base loss: 27497.05
[INFO 2017-06-26 15:48:57,601 main.py:50] epoch 354, training loss: 22159.13, average training loss: 26296.02, base loss: 27499.89
[INFO 2017-06-26 15:48:58,298 main.py:50] epoch 355, training loss: 21298.10, average training loss: 26281.98, base loss: 27497.78
[INFO 2017-06-26 15:48:59,014 main.py:50] epoch 356, training loss: 20668.55, average training loss: 26266.25, base loss: 27494.90
[INFO 2017-06-26 15:48:59,736 main.py:50] epoch 357, training loss: 21236.20, average training loss: 26252.20, base loss: 27492.45
[INFO 2017-06-26 15:49:00,425 main.py:50] epoch 358, training loss: 21471.60, average training loss: 26238.89, base loss: 27492.07
[INFO 2017-06-26 15:49:01,125 main.py:50] epoch 359, training loss: 20186.93, average training loss: 26222.08, base loss: 27486.58
[INFO 2017-06-26 15:49:01,862 main.py:50] epoch 360, training loss: 21472.61, average training loss: 26208.92, base loss: 27480.16
[INFO 2017-06-26 15:49:02,548 main.py:50] epoch 361, training loss: 22646.97, average training loss: 26199.08, base loss: 27482.17
[INFO 2017-06-26 15:49:03,229 main.py:50] epoch 362, training loss: 21766.29, average training loss: 26186.87, base loss: 27485.49
[INFO 2017-06-26 15:49:03,906 main.py:50] epoch 363, training loss: 21462.84, average training loss: 26173.89, base loss: 27484.15
[INFO 2017-06-26 15:49:04,583 main.py:50] epoch 364, training loss: 20761.49, average training loss: 26159.06, base loss: 27481.24
[INFO 2017-06-26 15:49:05,293 main.py:50] epoch 365, training loss: 22517.34, average training loss: 26149.11, base loss: 27484.55
[INFO 2017-06-26 15:49:06,004 main.py:50] epoch 366, training loss: 22100.15, average training loss: 26138.08, base loss: 27486.36
[INFO 2017-06-26 15:49:06,715 main.py:50] epoch 367, training loss: 22473.43, average training loss: 26128.12, base loss: 27487.97
[INFO 2017-06-26 15:49:07,424 main.py:50] epoch 368, training loss: 19642.79, average training loss: 26110.55, base loss: 27476.91
[INFO 2017-06-26 15:49:08,135 main.py:50] epoch 369, training loss: 24216.56, average training loss: 26105.43, base loss: 27488.79
[INFO 2017-06-26 15:49:08,862 main.py:50] epoch 370, training loss: 21129.12, average training loss: 26092.01, base loss: 27485.52
[INFO 2017-06-26 15:49:09,589 main.py:50] epoch 371, training loss: 22557.28, average training loss: 26082.51, base loss: 27489.93
[INFO 2017-06-26 15:49:10,287 main.py:50] epoch 372, training loss: 23714.11, average training loss: 26076.16, base loss: 27498.82
[INFO 2017-06-26 15:49:10,998 main.py:50] epoch 373, training loss: 20986.48, average training loss: 26062.55, base loss: 27498.82
[INFO 2017-06-26 15:49:11,709 main.py:50] epoch 374, training loss: 20982.72, average training loss: 26049.01, base loss: 27493.85
[INFO 2017-06-26 15:49:12,388 main.py:50] epoch 375, training loss: 22101.14, average training loss: 26038.51, base loss: 27496.35
[INFO 2017-06-26 15:49:13,066 main.py:50] epoch 376, training loss: 19819.85, average training loss: 26022.01, base loss: 27486.22
[INFO 2017-06-26 15:49:13,776 main.py:50] epoch 377, training loss: 20027.42, average training loss: 26006.15, base loss: 27475.24
[INFO 2017-06-26 15:49:14,456 main.py:50] epoch 378, training loss: 22205.90, average training loss: 25996.13, base loss: 27476.83
[INFO 2017-06-26 15:49:15,135 main.py:50] epoch 379, training loss: 20309.72, average training loss: 25981.16, base loss: 27472.13
[INFO 2017-06-26 15:49:15,846 main.py:50] epoch 380, training loss: 20945.48, average training loss: 25967.95, base loss: 27469.11
[INFO 2017-06-26 15:49:16,527 main.py:50] epoch 381, training loss: 21596.00, average training loss: 25956.50, base loss: 27468.15
[INFO 2017-06-26 15:49:17,208 main.py:50] epoch 382, training loss: 23280.79, average training loss: 25949.51, base loss: 27474.67
[INFO 2017-06-26 15:49:17,890 main.py:50] epoch 383, training loss: 21764.91, average training loss: 25938.62, base loss: 27476.03
[INFO 2017-06-26 15:49:18,570 main.py:50] epoch 384, training loss: 19420.67, average training loss: 25921.69, base loss: 27465.71
[INFO 2017-06-26 15:49:19,251 main.py:50] epoch 385, training loss: 22580.25, average training loss: 25913.03, base loss: 27469.83
[INFO 2017-06-26 15:49:19,930 main.py:50] epoch 386, training loss: 20305.81, average training loss: 25898.54, base loss: 27465.12
[INFO 2017-06-26 15:49:20,610 main.py:50] epoch 387, training loss: 21107.48, average training loss: 25886.19, base loss: 27465.06
[INFO 2017-06-26 15:49:21,291 main.py:50] epoch 388, training loss: 22047.01, average training loss: 25876.32, base loss: 27467.09
[INFO 2017-06-26 15:49:21,971 main.py:50] epoch 389, training loss: 21419.30, average training loss: 25864.90, base loss: 27465.70
[INFO 2017-06-26 15:49:22,651 main.py:50] epoch 390, training loss: 22434.37, average training loss: 25856.12, base loss: 27473.19
[INFO 2017-06-26 15:49:23,330 main.py:50] epoch 391, training loss: 21524.68, average training loss: 25845.07, base loss: 27470.68
[INFO 2017-06-26 15:49:24,009 main.py:50] epoch 392, training loss: 22131.43, average training loss: 25835.62, base loss: 27469.42
[INFO 2017-06-26 15:49:24,719 main.py:50] epoch 393, training loss: 21292.90, average training loss: 25824.09, base loss: 27468.41
[INFO 2017-06-26 15:49:25,430 main.py:50] epoch 394, training loss: 22443.57, average training loss: 25815.54, base loss: 27472.74
[INFO 2017-06-26 15:49:26,120 main.py:50] epoch 395, training loss: 20858.74, average training loss: 25803.02, base loss: 27470.04
[INFO 2017-06-26 15:49:26,849 main.py:50] epoch 396, training loss: 21387.43, average training loss: 25791.90, base loss: 27469.70
[INFO 2017-06-26 15:49:27,577 main.py:50] epoch 397, training loss: 21678.79, average training loss: 25781.56, base loss: 27468.54
[INFO 2017-06-26 15:49:28,288 main.py:50] epoch 398, training loss: 22000.81, average training loss: 25772.09, base loss: 27469.64
[INFO 2017-06-26 15:49:28,984 main.py:50] epoch 399, training loss: 21484.75, average training loss: 25761.37, base loss: 27465.54
[INFO 2017-06-26 15:49:28,985 main.py:52] epoch 399, testing
[INFO 2017-06-26 15:49:31,312 main.py:103] average testing loss: 22196.74, base loss: 15886.65
[INFO 2017-06-26 15:49:31,313 main.py:76] current best accuracy: 20883.41
[INFO 2017-06-26 15:49:31,992 main.py:50] epoch 400, training loss: 20071.11, average training loss: 25747.18, base loss: 27459.37
[INFO 2017-06-26 15:49:32,668 main.py:50] epoch 401, training loss: 22379.41, average training loss: 25738.80, base loss: 27465.60
[INFO 2017-06-26 15:49:33,346 main.py:50] epoch 402, training loss: 21489.57, average training loss: 25728.26, base loss: 27463.09
[INFO 2017-06-26 15:49:34,025 main.py:50] epoch 403, training loss: 19188.77, average training loss: 25712.07, base loss: 27452.72
[INFO 2017-06-26 15:49:34,702 main.py:50] epoch 404, training loss: 20657.85, average training loss: 25699.59, base loss: 27450.21
[INFO 2017-06-26 15:49:35,381 main.py:50] epoch 405, training loss: 22735.27, average training loss: 25692.29, base loss: 27454.89
[INFO 2017-06-26 15:49:36,060 main.py:50] epoch 406, training loss: 22419.60, average training loss: 25684.25, base loss: 27459.96
[INFO 2017-06-26 15:49:36,753 main.py:50] epoch 407, training loss: 20599.87, average training loss: 25671.79, base loss: 27454.93
[INFO 2017-06-26 15:49:37,432 main.py:50] epoch 408, training loss: 21586.18, average training loss: 25661.80, base loss: 27455.00
[INFO 2017-06-26 15:49:38,111 main.py:50] epoch 409, training loss: 21912.73, average training loss: 25652.65, base loss: 27458.25
[INFO 2017-06-26 15:49:38,789 main.py:50] epoch 410, training loss: 21181.43, average training loss: 25641.77, base loss: 27456.12
[INFO 2017-06-26 15:49:39,498 main.py:50] epoch 411, training loss: 21971.78, average training loss: 25632.87, base loss: 27460.68
[INFO 2017-06-26 15:49:40,177 main.py:50] epoch 412, training loss: 20442.06, average training loss: 25620.30, base loss: 27457.66
[INFO 2017-06-26 15:49:40,854 main.py:50] epoch 413, training loss: 24074.79, average training loss: 25616.56, base loss: 27471.26
[INFO 2017-06-26 15:49:41,534 main.py:50] epoch 414, training loss: 21802.17, average training loss: 25607.37, base loss: 27467.65
[INFO 2017-06-26 15:49:42,212 main.py:50] epoch 415, training loss: 20381.11, average training loss: 25594.81, base loss: 27464.63
[INFO 2017-06-26 15:49:42,889 main.py:50] epoch 416, training loss: 22759.75, average training loss: 25588.01, base loss: 27470.92
[INFO 2017-06-26 15:49:43,567 main.py:50] epoch 417, training loss: 21659.26, average training loss: 25578.61, base loss: 27472.78
[INFO 2017-06-26 15:49:44,245 main.py:50] epoch 418, training loss: 20368.31, average training loss: 25566.18, base loss: 27468.11
[INFO 2017-06-26 15:49:44,922 main.py:50] epoch 419, training loss: 20511.95, average training loss: 25554.14, base loss: 27463.35
[INFO 2017-06-26 15:49:45,599 main.py:50] epoch 420, training loss: 19605.72, average training loss: 25540.01, base loss: 27457.65
[INFO 2017-06-26 15:49:46,277 main.py:50] epoch 421, training loss: 21636.07, average training loss: 25530.76, base loss: 27459.58
[INFO 2017-06-26 15:49:46,954 main.py:50] epoch 422, training loss: 23457.82, average training loss: 25525.86, base loss: 27466.77
[INFO 2017-06-26 15:49:47,633 main.py:50] epoch 423, training loss: 20143.91, average training loss: 25513.17, base loss: 27459.80
[INFO 2017-06-26 15:49:48,310 main.py:50] epoch 424, training loss: 19613.74, average training loss: 25499.29, base loss: 27452.54
[INFO 2017-06-26 15:49:48,993 main.py:50] epoch 425, training loss: 21915.20, average training loss: 25490.87, base loss: 27455.38
[INFO 2017-06-26 15:49:49,690 main.py:50] epoch 426, training loss: 19765.73, average training loss: 25477.47, base loss: 27449.86
[INFO 2017-06-26 15:49:59,099 main.py:50] epoch 427, training loss: 1.00, average training loss: 25464.64, base loss: 27432.43
