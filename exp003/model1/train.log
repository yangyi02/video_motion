[INFO 2017-06-26 21:14:52,134 main.py:123] Namespace(batch_size=32, display=False, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=2, num_channel=3, num_inputs=1, save_dir='./model', test=False, test_dir='/home/yi/Downloads/youtube-64', test_epoch=10, test_interval=100, train=True, train_dir='/home/yi/Downloads/youtube-64', train_epoch=10000)
[INFO 2017-06-26 21:14:54,527 main.py:47] epoch 0, training loss: 104253.07, average training loss: 104253.07, base loss: 7377.87
[INFO 2017-06-26 21:14:54,839 main.py:47] epoch 1, training loss: 84110.06, average training loss: 94181.57, base loss: 6186.75
[INFO 2017-06-26 21:14:55,137 main.py:47] epoch 2, training loss: 69628.40, average training loss: 85997.18, base loss: 6300.22
[INFO 2017-06-26 21:14:55,436 main.py:47] epoch 3, training loss: 58044.03, average training loss: 79008.89, base loss: 6134.59
[INFO 2017-06-26 21:14:55,722 main.py:47] epoch 4, training loss: 52243.94, average training loss: 73655.90, base loss: 5944.31
[INFO 2017-06-26 21:14:56,013 main.py:47] epoch 5, training loss: 43187.02, average training loss: 68577.75, base loss: 5770.37
[INFO 2017-06-26 21:14:56,304 main.py:47] epoch 6, training loss: 36631.55, average training loss: 64014.01, base loss: 5623.19
[INFO 2017-06-26 21:14:56,603 main.py:47] epoch 7, training loss: 31941.48, average training loss: 60004.94, base loss: 5521.41
[INFO 2017-06-26 21:14:56,891 main.py:47] epoch 8, training loss: 28646.57, average training loss: 56520.68, base loss: 5473.51
[INFO 2017-06-26 21:14:57,178 main.py:47] epoch 9, training loss: 22900.12, average training loss: 53158.62, base loss: 5400.04
[INFO 2017-06-26 21:14:57,477 main.py:47] epoch 10, training loss: 20084.18, average training loss: 50151.86, base loss: 5438.68
[INFO 2017-06-26 21:14:57,770 main.py:47] epoch 11, training loss: 17489.97, average training loss: 47430.03, base loss: 5358.46
[INFO 2017-06-26 21:14:58,059 main.py:47] epoch 12, training loss: 16005.99, average training loss: 45012.80, base loss: 5441.32
[INFO 2017-06-26 21:14:58,350 main.py:47] epoch 13, training loss: 13538.24, average training loss: 42764.62, base loss: 5404.23
[INFO 2017-06-26 21:14:58,636 main.py:47] epoch 14, training loss: 15040.17, average training loss: 40916.32, base loss: 5609.91
[INFO 2017-06-26 21:14:58,931 main.py:47] epoch 15, training loss: 10887.16, average training loss: 39039.50, base loss: 5535.09
[INFO 2017-06-26 21:14:59,222 main.py:47] epoch 16, training loss: 10378.98, average training loss: 37353.58, base loss: 5545.47
[INFO 2017-06-26 21:14:59,522 main.py:47] epoch 17, training loss: 10389.74, average training loss: 35855.59, base loss: 5578.21
[INFO 2017-06-26 21:14:59,816 main.py:47] epoch 18, training loss: 8223.64, average training loss: 34401.28, base loss: 5541.57
[INFO 2017-06-26 21:15:00,120 main.py:47] epoch 19, training loss: 8559.62, average training loss: 33109.20, base loss: 5557.22
[INFO 2017-06-26 21:15:00,417 main.py:47] epoch 20, training loss: 6766.11, average training loss: 31854.76, base loss: 5494.81
[INFO 2017-06-26 21:15:00,710 main.py:47] epoch 21, training loss: 6841.68, average training loss: 30717.80, base loss: 5465.96
[INFO 2017-06-26 21:15:00,996 main.py:47] epoch 22, training loss: 7047.33, average training loss: 29688.65, base loss: 5472.27
[INFO 2017-06-26 21:15:01,287 main.py:47] epoch 23, training loss: 6574.85, average training loss: 28725.58, base loss: 5468.00
[INFO 2017-06-26 21:15:01,580 main.py:47] epoch 24, training loss: 6706.82, average training loss: 27844.83, base loss: 5482.87
[INFO 2017-06-26 21:15:01,881 main.py:47] epoch 25, training loss: 5459.80, average training loss: 26983.87, base loss: 5445.69
[INFO 2017-06-26 21:15:02,176 main.py:47] epoch 26, training loss: 5824.15, average training loss: 26200.17, base loss: 5433.84
[INFO 2017-06-26 21:15:02,481 main.py:47] epoch 27, training loss: 7164.68, average training loss: 25520.33, base loss: 5477.12
[INFO 2017-06-26 21:15:02,772 main.py:47] epoch 28, training loss: 6327.28, average training loss: 24858.50, base loss: 5489.56
[INFO 2017-06-26 21:15:03,086 main.py:47] epoch 29, training loss: 7024.07, average training loss: 24264.02, base loss: 5525.90
[INFO 2017-06-26 21:15:03,380 main.py:47] epoch 30, training loss: 5590.09, average training loss: 23661.64, base loss: 5515.25
[INFO 2017-06-26 21:15:03,673 main.py:47] epoch 31, training loss: 6163.90, average training loss: 23114.83, base loss: 5525.99
[INFO 2017-06-26 21:15:03,965 main.py:47] epoch 32, training loss: 5839.40, average training loss: 22591.34, base loss: 5526.58
[INFO 2017-06-26 21:15:04,260 main.py:47] epoch 33, training loss: 5330.99, average training loss: 22083.68, base loss: 5512.10
[INFO 2017-06-26 21:15:04,556 main.py:47] epoch 34, training loss: 5673.57, average training loss: 21614.82, base loss: 5509.91
[INFO 2017-06-26 21:15:04,852 main.py:47] epoch 35, training loss: 5535.75, average training loss: 21168.18, base loss: 5502.97
[INFO 2017-06-26 21:15:05,150 main.py:47] epoch 36, training loss: 7099.02, average training loss: 20787.93, base loss: 5537.44
[INFO 2017-06-26 21:15:05,445 main.py:47] epoch 37, training loss: 5319.25, average training loss: 20380.86, base loss: 5525.60
[INFO 2017-06-26 21:15:05,732 main.py:47] epoch 38, training loss: 5990.21, average training loss: 20011.87, base loss: 5531.28
[INFO 2017-06-26 21:15:06,020 main.py:47] epoch 39, training loss: 5281.92, average training loss: 19643.62, base loss: 5520.35
[INFO 2017-06-26 21:15:06,310 main.py:47] epoch 40, training loss: 6276.87, average training loss: 19317.60, base loss: 5535.66
[INFO 2017-06-26 21:15:06,612 main.py:47] epoch 41, training loss: 5274.13, average training loss: 18983.23, base loss: 5525.11
[INFO 2017-06-26 21:15:06,912 main.py:47] epoch 42, training loss: 7097.47, average training loss: 18706.82, base loss: 5558.20
[INFO 2017-06-26 21:15:07,211 main.py:47] epoch 43, training loss: 5605.98, average training loss: 18409.07, base loss: 5556.43
[INFO 2017-06-26 21:15:07,502 main.py:47] epoch 44, training loss: 6065.77, average training loss: 18134.78, base loss: 5565.11
[INFO 2017-06-26 21:15:07,794 main.py:47] epoch 45, training loss: 5506.08, average training loss: 17860.24, base loss: 5560.66
[INFO 2017-06-26 21:15:08,088 main.py:47] epoch 46, training loss: 5259.43, average training loss: 17592.14, base loss: 5551.67
[INFO 2017-06-26 21:15:08,398 main.py:47] epoch 47, training loss: 4639.19, average training loss: 17322.29, base loss: 5530.27
[INFO 2017-06-26 21:15:08,691 main.py:47] epoch 48, training loss: 5082.10, average training loss: 17072.49, base loss: 5518.55
[INFO 2017-06-26 21:15:08,986 main.py:47] epoch 49, training loss: 6197.47, average training loss: 16854.99, base loss: 5529.76
[INFO 2017-06-26 21:15:09,289 main.py:47] epoch 50, training loss: 5273.55, average training loss: 16627.90, base loss: 5521.58
[INFO 2017-06-26 21:15:09,585 main.py:47] epoch 51, training loss: 5520.16, average training loss: 16414.29, base loss: 5518.19
[INFO 2017-06-26 21:15:09,883 main.py:47] epoch 52, training loss: 6659.99, average training loss: 16230.24, base loss: 5537.67
[INFO 2017-06-26 21:15:10,179 main.py:47] epoch 53, training loss: 5271.89, average training loss: 16027.31, base loss: 5530.76
[INFO 2017-06-26 21:15:10,471 main.py:47] epoch 54, training loss: 5080.88, average training loss: 15828.29, base loss: 5520.06
[INFO 2017-06-26 21:15:10,762 main.py:47] epoch 55, training loss: 5780.35, average training loss: 15648.86, base loss: 5522.81
[INFO 2017-06-26 21:15:11,058 main.py:47] epoch 56, training loss: 5026.30, average training loss: 15462.50, base loss: 5512.25
[INFO 2017-06-26 21:15:11,359 main.py:47] epoch 57, training loss: 6559.97, average training loss: 15309.01, base loss: 5528.43
[INFO 2017-06-26 21:15:11,650 main.py:47] epoch 58, training loss: 5417.35, average training loss: 15141.35, base loss: 5524.80
[INFO 2017-06-26 21:15:11,942 main.py:47] epoch 59, training loss: 5362.10, average training loss: 14978.36, base loss: 5520.79
[INFO 2017-06-26 21:15:12,236 main.py:47] epoch 60, training loss: 4516.17, average training loss: 14806.85, base loss: 5502.16
[INFO 2017-06-26 21:15:12,531 main.py:47] epoch 61, training loss: 6735.62, average training loss: 14676.67, base loss: 5520.77
[INFO 2017-06-26 21:15:12,822 main.py:47] epoch 62, training loss: 4224.38, average training loss: 14510.76, base loss: 5498.28
[INFO 2017-06-26 21:15:13,112 main.py:47] epoch 63, training loss: 5763.32, average training loss: 14374.08, base loss: 5500.78
[INFO 2017-06-26 21:15:13,404 main.py:47] epoch 64, training loss: 5359.51, average training loss: 14235.40, base loss: 5497.19
[INFO 2017-06-26 21:15:13,693 main.py:47] epoch 65, training loss: 5090.55, average training loss: 14096.84, base loss: 5489.76
[INFO 2017-06-26 21:15:13,983 main.py:47] epoch 66, training loss: 5938.78, average training loss: 13975.08, base loss: 5495.37
[INFO 2017-06-26 21:15:14,274 main.py:47] epoch 67, training loss: 5697.19, average training loss: 13853.34, base loss: 5496.89
[INFO 2017-06-26 21:15:14,561 main.py:47] epoch 68, training loss: 5473.65, average training loss: 13731.90, base loss: 5495.17
[INFO 2017-06-26 21:15:14,857 main.py:47] epoch 69, training loss: 5479.95, average training loss: 13614.01, base loss: 5493.66
[INFO 2017-06-26 21:15:15,155 main.py:47] epoch 70, training loss: 5736.49, average training loss: 13503.06, base loss: 5495.89
[INFO 2017-06-26 21:15:15,450 main.py:47] epoch 71, training loss: 6620.81, average training loss: 13407.48, base loss: 5510.63
[INFO 2017-06-26 21:15:15,740 main.py:47] epoch 72, training loss: 4796.92, average training loss: 13289.52, base loss: 5499.60
[INFO 2017-06-26 21:15:16,042 main.py:47] epoch 73, training loss: 6779.22, average training loss: 13201.55, base loss: 5515.86
[INFO 2017-06-26 21:15:16,341 main.py:47] epoch 74, training loss: 5766.37, average training loss: 13102.41, base loss: 5518.30
[INFO 2017-06-26 21:15:16,638 main.py:47] epoch 75, training loss: 5751.01, average training loss: 13005.68, base loss: 5520.46
[INFO 2017-06-26 21:15:16,931 main.py:47] epoch 76, training loss: 4778.16, average training loss: 12898.83, base loss: 5509.47
[INFO 2017-06-26 21:15:17,222 main.py:47] epoch 77, training loss: 5190.23, average training loss: 12800.00, base loss: 5504.32
[INFO 2017-06-26 21:15:17,515 main.py:47] epoch 78, training loss: 5924.77, average training loss: 12712.97, base loss: 5508.99
[INFO 2017-06-26 21:15:17,807 main.py:47] epoch 79, training loss: 5825.82, average training loss: 12626.88, base loss: 5512.04
[INFO 2017-06-26 21:15:18,099 main.py:47] epoch 80, training loss: 5755.79, average training loss: 12542.06, base loss: 5514.24
[INFO 2017-06-26 21:15:18,398 main.py:47] epoch 81, training loss: 5637.43, average training loss: 12457.85, base loss: 5514.58
[INFO 2017-06-26 21:15:18,687 main.py:47] epoch 82, training loss: 5868.89, average training loss: 12378.47, base loss: 5518.16
[INFO 2017-06-26 21:15:18,981 main.py:47] epoch 83, training loss: 5757.65, average training loss: 12299.65, base loss: 5520.16
[INFO 2017-06-26 21:15:19,271 main.py:47] epoch 84, training loss: 5524.85, average training loss: 12219.95, base loss: 5519.04
[INFO 2017-06-26 21:15:19,563 main.py:47] epoch 85, training loss: 5884.47, average training loss: 12146.28, base loss: 5522.42
[INFO 2017-06-26 21:15:19,860 main.py:47] epoch 86, training loss: 5923.74, average training loss: 12074.75, base loss: 5526.42
[INFO 2017-06-26 21:15:20,160 main.py:47] epoch 87, training loss: 6238.76, average training loss: 12008.44, base loss: 5533.70
[INFO 2017-06-26 21:15:20,461 main.py:47] epoch 88, training loss: 5030.73, average training loss: 11930.03, base loss: 5527.40
[INFO 2017-06-26 21:15:20,759 main.py:47] epoch 89, training loss: 5147.28, average training loss: 11854.67, base loss: 5522.51
[INFO 2017-06-26 21:15:21,048 main.py:47] epoch 90, training loss: 5615.68, average training loss: 11786.11, base loss: 5522.75
[INFO 2017-06-26 21:15:21,340 main.py:47] epoch 91, training loss: 6328.39, average training loss: 11726.79, base loss: 5531.00
[INFO 2017-06-26 21:15:21,635 main.py:47] epoch 92, training loss: 4682.70, average training loss: 11651.04, base loss: 5520.90
[INFO 2017-06-26 21:15:21,928 main.py:47] epoch 93, training loss: 4732.10, average training loss: 11577.44, base loss: 5511.63
[INFO 2017-06-26 21:15:22,218 main.py:47] epoch 94, training loss: 6587.63, average training loss: 11524.91, base loss: 5522.45
[INFO 2017-06-26 21:15:22,512 main.py:47] epoch 95, training loss: 5482.75, average training loss: 11461.97, base loss: 5521.43
[INFO 2017-06-26 21:15:22,814 main.py:47] epoch 96, training loss: 4905.54, average training loss: 11394.38, base loss: 5514.38
[INFO 2017-06-26 21:15:23,115 main.py:47] epoch 97, training loss: 4724.81, average training loss: 11326.33, base loss: 5505.66
[INFO 2017-06-26 21:15:23,417 main.py:47] epoch 98, training loss: 5848.78, average training loss: 11271.00, base loss: 5508.70
[INFO 2017-06-26 21:15:23,710 main.py:47] epoch 99, training loss: 5381.67, average training loss: 11212.10, base loss: 5507.03
[INFO 2017-06-26 21:15:23,710 main.py:49] epoch 99, testing
[INFO 2017-06-26 21:15:24,837 main.py:100] average testing loss: 5491.14, base loss: 5431.19
[INFO 2017-06-26 21:15:24,837 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:15:24,849 main.py:73] current best accuracy: 5491.14
[INFO 2017-06-26 21:15:25,140 main.py:47] epoch 100, training loss: 4599.36, average training loss: 11146.63, base loss: 5496.94
[INFO 2017-06-26 21:15:25,432 main.py:47] epoch 101, training loss: 5565.51, average training loss: 11091.91, base loss: 5497.19
[INFO 2017-06-26 21:15:25,721 main.py:47] epoch 102, training loss: 5279.85, average training loss: 11035.49, base loss: 5494.49
[INFO 2017-06-26 21:15:26,012 main.py:47] epoch 103, training loss: 6334.61, average training loss: 10990.29, base loss: 5502.18
[INFO 2017-06-26 21:15:26,314 main.py:47] epoch 104, training loss: 4890.57, average training loss: 10932.19, base loss: 5495.87
[INFO 2017-06-26 21:15:26,612 main.py:47] epoch 105, training loss: 4892.72, average training loss: 10875.22, base loss: 5489.73
[INFO 2017-06-26 21:15:26,913 main.py:47] epoch 106, training loss: 5613.93, average training loss: 10826.05, base loss: 5490.47
[INFO 2017-06-26 21:15:27,213 main.py:47] epoch 107, training loss: 5549.47, average training loss: 10777.19, base loss: 5490.60
[INFO 2017-06-26 21:15:27,521 main.py:47] epoch 108, training loss: 4153.11, average training loss: 10716.42, base loss: 5477.50
[INFO 2017-06-26 21:15:27,819 main.py:47] epoch 109, training loss: 4854.19, average training loss: 10663.12, base loss: 5471.23
[INFO 2017-06-26 21:15:28,120 main.py:47] epoch 110, training loss: 6395.84, average training loss: 10624.68, base loss: 5479.14
[INFO 2017-06-26 21:15:28,417 main.py:47] epoch 111, training loss: 4468.54, average training loss: 10569.71, base loss: 5469.17
[INFO 2017-06-26 21:15:28,718 main.py:47] epoch 112, training loss: 6747.23, average training loss: 10535.89, base loss: 5480.15
[INFO 2017-06-26 21:15:29,017 main.py:47] epoch 113, training loss: 5441.89, average training loss: 10491.20, base loss: 5479.47
[INFO 2017-06-26 21:15:29,308 main.py:47] epoch 114, training loss: 6379.58, average training loss: 10455.45, base loss: 5487.08
[INFO 2017-06-26 21:15:29,607 main.py:47] epoch 115, training loss: 5439.51, average training loss: 10412.21, base loss: 5486.31
[INFO 2017-06-26 21:15:29,902 main.py:47] epoch 116, training loss: 4994.80, average training loss: 10365.91, base loss: 5481.54
[INFO 2017-06-26 21:15:30,194 main.py:47] epoch 117, training loss: 5731.30, average training loss: 10326.63, base loss: 5483.49
[INFO 2017-06-26 21:15:30,490 main.py:47] epoch 118, training loss: 4811.30, average training loss: 10280.28, base loss: 5477.68
[INFO 2017-06-26 21:15:30,784 main.py:47] epoch 119, training loss: 5388.76, average training loss: 10239.52, base loss: 5476.58
[INFO 2017-06-26 21:15:31,077 main.py:47] epoch 120, training loss: 6118.23, average training loss: 10205.46, base loss: 5481.55
[INFO 2017-06-26 21:15:31,375 main.py:47] epoch 121, training loss: 4912.18, average training loss: 10162.07, base loss: 5476.34
[INFO 2017-06-26 21:15:31,670 main.py:47] epoch 122, training loss: 4858.30, average training loss: 10118.95, base loss: 5470.89
[INFO 2017-06-26 21:15:31,959 main.py:47] epoch 123, training loss: 5821.03, average training loss: 10084.29, base loss: 5473.55
[INFO 2017-06-26 21:15:32,255 main.py:47] epoch 124, training loss: 6171.25, average training loss: 10052.99, base loss: 5479.02
[INFO 2017-06-26 21:15:32,548 main.py:47] epoch 125, training loss: 4908.86, average training loss: 10012.16, base loss: 5474.10
[INFO 2017-06-26 21:15:32,855 main.py:47] epoch 126, training loss: 4578.40, average training loss: 9969.38, base loss: 5466.68
[INFO 2017-06-26 21:15:33,144 main.py:47] epoch 127, training loss: 5375.80, average training loss: 9933.49, base loss: 5465.86
[INFO 2017-06-26 21:15:33,436 main.py:47] epoch 128, training loss: 5120.07, average training loss: 9896.17, base loss: 5462.93
[INFO 2017-06-26 21:15:33,725 main.py:47] epoch 129, training loss: 5894.70, average training loss: 9865.39, base loss: 5465.99
[INFO 2017-06-26 21:15:34,021 main.py:47] epoch 130, training loss: 4916.46, average training loss: 9827.62, base loss: 5461.55
[INFO 2017-06-26 21:15:34,323 main.py:47] epoch 131, training loss: 4598.60, average training loss: 9788.00, base loss: 5454.88
[INFO 2017-06-26 21:15:34,621 main.py:47] epoch 132, training loss: 5015.07, average training loss: 9752.12, base loss: 5451.25
[INFO 2017-06-26 21:15:34,921 main.py:47] epoch 133, training loss: 5291.20, average training loss: 9718.83, base loss: 5449.90
[INFO 2017-06-26 21:15:35,218 main.py:47] epoch 134, training loss: 5233.44, average training loss: 9685.60, base loss: 5448.12
[INFO 2017-06-26 21:15:35,524 main.py:47] epoch 135, training loss: 5003.90, average training loss: 9651.18, base loss: 5444.79
[INFO 2017-06-26 21:15:35,826 main.py:47] epoch 136, training loss: 4826.39, average training loss: 9615.96, base loss: 5440.06
[INFO 2017-06-26 21:15:36,128 main.py:47] epoch 137, training loss: 4880.89, average training loss: 9581.65, base loss: 5435.74
[INFO 2017-06-26 21:15:36,429 main.py:47] epoch 138, training loss: 6360.58, average training loss: 9558.47, base loss: 5442.30
[INFO 2017-06-26 21:15:36,728 main.py:47] epoch 139, training loss: 5975.41, average training loss: 9532.88, base loss: 5446.15
[INFO 2017-06-26 21:15:37,030 main.py:47] epoch 140, training loss: 5064.30, average training loss: 9501.19, base loss: 5443.33
[INFO 2017-06-26 21:15:37,335 main.py:47] epoch 141, training loss: 5349.58, average training loss: 9471.95, base loss: 5442.48
[INFO 2017-06-26 21:15:37,643 main.py:47] epoch 142, training loss: 5776.16, average training loss: 9446.11, base loss: 5444.62
[INFO 2017-06-26 21:15:37,945 main.py:47] epoch 143, training loss: 5313.14, average training loss: 9417.41, base loss: 5443.60
[INFO 2017-06-26 21:15:38,240 main.py:47] epoch 144, training loss: 5610.83, average training loss: 9391.15, base loss: 5444.79
[INFO 2017-06-26 21:15:38,535 main.py:47] epoch 145, training loss: 5958.93, average training loss: 9367.64, base loss: 5448.16
[INFO 2017-06-26 21:15:38,833 main.py:47] epoch 146, training loss: 5825.51, average training loss: 9343.55, base loss: 5450.89
[INFO 2017-06-26 21:15:39,134 main.py:47] epoch 147, training loss: 6147.02, average training loss: 9321.95, base loss: 5455.62
[INFO 2017-06-26 21:15:39,433 main.py:47] epoch 148, training loss: 4696.70, average training loss: 9290.91, base loss: 5450.38
[INFO 2017-06-26 21:15:39,734 main.py:47] epoch 149, training loss: 5159.02, average training loss: 9263.36, base loss: 5448.31
[INFO 2017-06-26 21:15:40,024 main.py:47] epoch 150, training loss: 5476.53, average training loss: 9238.28, base loss: 5448.59
[INFO 2017-06-26 21:15:40,326 main.py:47] epoch 151, training loss: 5690.84, average training loss: 9214.95, base loss: 5450.24
[INFO 2017-06-26 21:15:40,628 main.py:47] epoch 152, training loss: 4209.27, average training loss: 9182.23, base loss: 5441.86
[INFO 2017-06-26 21:15:40,933 main.py:47] epoch 153, training loss: 5579.90, average training loss: 9158.84, base loss: 5442.57
[INFO 2017-06-26 21:15:41,237 main.py:47] epoch 154, training loss: 5005.09, average training loss: 9132.04, base loss: 5439.41
[INFO 2017-06-26 21:15:41,530 main.py:47] epoch 155, training loss: 6390.57, average training loss: 9114.47, base loss: 5445.54
[INFO 2017-06-26 21:15:41,832 main.py:47] epoch 156, training loss: 6002.39, average training loss: 9094.64, base loss: 5448.98
[INFO 2017-06-26 21:15:42,132 main.py:47] epoch 157, training loss: 5689.45, average training loss: 9073.09, base loss: 5450.63
[INFO 2017-06-26 21:15:42,436 main.py:47] epoch 158, training loss: 5428.18, average training loss: 9050.17, base loss: 5450.55
[INFO 2017-06-26 21:15:42,735 main.py:47] epoch 159, training loss: 5159.34, average training loss: 9025.85, base loss: 5448.67
[INFO 2017-06-26 21:15:43,033 main.py:47] epoch 160, training loss: 8828.01, average training loss: 9024.62, base loss: 5469.66
[INFO 2017-06-26 21:15:43,336 main.py:47] epoch 161, training loss: 6006.00, average training loss: 9005.99, base loss: 5472.86
[INFO 2017-06-26 21:15:43,634 main.py:47] epoch 162, training loss: 7364.98, average training loss: 8995.92, base loss: 5484.49
[INFO 2017-06-26 21:15:43,932 main.py:47] epoch 163, training loss: 5008.48, average training loss: 8971.61, base loss: 5481.61
[INFO 2017-06-26 21:15:44,230 main.py:47] epoch 164, training loss: 4399.43, average training loss: 8943.90, base loss: 5474.78
[INFO 2017-06-26 21:15:44,520 main.py:47] epoch 165, training loss: 5879.16, average training loss: 8925.43, base loss: 5477.37
[INFO 2017-06-26 21:15:44,813 main.py:47] epoch 166, training loss: 5250.15, average training loss: 8903.43, base loss: 5476.03
[INFO 2017-06-26 21:15:45,103 main.py:47] epoch 167, training loss: 5430.59, average training loss: 8882.75, base loss: 5475.66
[INFO 2017-06-26 21:15:45,393 main.py:47] epoch 168, training loss: 6250.21, average training loss: 8867.18, base loss: 5480.15
[INFO 2017-06-26 21:15:45,684 main.py:47] epoch 169, training loss: 6272.78, average training loss: 8851.92, base loss: 5485.01
[INFO 2017-06-26 21:15:45,979 main.py:47] epoch 170, training loss: 5905.33, average training loss: 8834.68, base loss: 5487.46
[INFO 2017-06-26 21:15:46,276 main.py:47] epoch 171, training loss: 5891.53, average training loss: 8817.57, base loss: 5490.02
[INFO 2017-06-26 21:15:46,570 main.py:47] epoch 172, training loss: 5691.10, average training loss: 8799.50, base loss: 5491.18
[INFO 2017-06-26 21:15:46,867 main.py:47] epoch 173, training loss: 6073.73, average training loss: 8783.84, base loss: 5494.47
[INFO 2017-06-26 21:15:47,166 main.py:47] epoch 174, training loss: 5397.19, average training loss: 8764.48, base loss: 5493.89
[INFO 2017-06-26 21:15:47,462 main.py:47] epoch 175, training loss: 5494.08, average training loss: 8745.90, base loss: 5493.92
[INFO 2017-06-26 21:15:47,750 main.py:47] epoch 176, training loss: 5931.86, average training loss: 8730.00, base loss: 5496.39
[INFO 2017-06-26 21:15:48,043 main.py:47] epoch 177, training loss: 5630.02, average training loss: 8712.59, base loss: 5497.20
[INFO 2017-06-26 21:15:48,348 main.py:47] epoch 178, training loss: 5940.67, average training loss: 8697.10, base loss: 5499.90
[INFO 2017-06-26 21:15:48,636 main.py:47] epoch 179, training loss: 5968.51, average training loss: 8681.94, base loss: 5502.62
[INFO 2017-06-26 21:15:48,940 main.py:47] epoch 180, training loss: 6114.44, average training loss: 8667.76, base loss: 5506.16
[INFO 2017-06-26 21:15:49,234 main.py:47] epoch 181, training loss: 5559.30, average training loss: 8650.68, base loss: 5506.60
[INFO 2017-06-26 21:15:49,533 main.py:47] epoch 182, training loss: 6503.68, average training loss: 8638.95, base loss: 5512.05
[INFO 2017-06-26 21:15:49,829 main.py:47] epoch 183, training loss: 9765.02, average training loss: 8645.07, base loss: 5535.37
[INFO 2017-06-26 21:15:50,120 main.py:47] epoch 184, training loss: 5620.46, average training loss: 8628.72, base loss: 5535.94
[INFO 2017-06-26 21:15:50,420 main.py:47] epoch 185, training loss: 6759.72, average training loss: 8618.67, base loss: 5542.61
[INFO 2017-06-26 21:15:50,719 main.py:47] epoch 186, training loss: 5753.05, average training loss: 8603.34, base loss: 5543.85
[INFO 2017-06-26 21:15:51,021 main.py:47] epoch 187, training loss: 6358.91, average training loss: 8591.41, base loss: 5548.33
[INFO 2017-06-26 21:15:51,316 main.py:47] epoch 188, training loss: 5794.51, average training loss: 8576.61, base loss: 5549.72
[INFO 2017-06-26 21:15:51,609 main.py:47] epoch 189, training loss: 4253.28, average training loss: 8553.85, base loss: 5542.78
[INFO 2017-06-26 21:15:51,907 main.py:47] epoch 190, training loss: 4851.96, average training loss: 8534.47, base loss: 5539.18
[INFO 2017-06-26 21:15:52,199 main.py:47] epoch 191, training loss: 7942.28, average training loss: 8531.39, base loss: 5551.98
[INFO 2017-06-26 21:15:52,497 main.py:47] epoch 192, training loss: 5109.03, average training loss: 8513.65, base loss: 5549.75
[INFO 2017-06-26 21:15:52,799 main.py:47] epoch 193, training loss: 6108.73, average training loss: 8501.26, base loss: 5552.91
[INFO 2017-06-26 21:15:53,104 main.py:47] epoch 194, training loss: 4659.37, average training loss: 8481.56, base loss: 5548.26
[INFO 2017-06-26 21:15:53,405 main.py:47] epoch 195, training loss: 4487.06, average training loss: 8461.18, base loss: 5542.88
[INFO 2017-06-26 21:15:53,702 main.py:47] epoch 196, training loss: 4742.32, average training loss: 8442.30, base loss: 5538.82
[INFO 2017-06-26 21:15:53,999 main.py:47] epoch 197, training loss: 5436.21, average training loss: 8427.12, base loss: 5538.42
[INFO 2017-06-26 21:15:54,299 main.py:47] epoch 198, training loss: 5145.98, average training loss: 8410.63, base loss: 5536.41
[INFO 2017-06-26 21:15:54,600 main.py:47] epoch 199, training loss: 4464.55, average training loss: 8390.90, base loss: 5531.04
[INFO 2017-06-26 21:15:54,601 main.py:49] epoch 199, testing
[INFO 2017-06-26 21:15:55,734 main.py:100] average testing loss: 5715.96, base loss: 5742.54
[INFO 2017-06-26 21:15:55,735 main.py:73] current best accuracy: 5491.14
[INFO 2017-06-26 21:15:56,040 main.py:47] epoch 200, training loss: 7633.68, average training loss: 8387.13, base loss: 5541.76
[INFO 2017-06-26 21:15:56,348 main.py:47] epoch 201, training loss: 4627.81, average training loss: 8368.52, base loss: 5537.15
[INFO 2017-06-26 21:15:56,640 main.py:47] epoch 202, training loss: 4948.92, average training loss: 8351.67, base loss: 5534.24
[INFO 2017-06-26 21:15:56,940 main.py:47] epoch 203, training loss: 6359.58, average training loss: 8341.91, base loss: 5538.46
[INFO 2017-06-26 21:15:57,238 main.py:47] epoch 204, training loss: 6809.66, average training loss: 8334.44, base loss: 5544.99
[INFO 2017-06-26 21:15:57,537 main.py:47] epoch 205, training loss: 5533.16, average training loss: 8320.84, base loss: 5545.15
[INFO 2017-06-26 21:15:57,834 main.py:47] epoch 206, training loss: 5553.86, average training loss: 8307.47, base loss: 5545.24
[INFO 2017-06-26 21:15:58,142 main.py:47] epoch 207, training loss: 6305.49, average training loss: 8297.84, base loss: 5549.16
[INFO 2017-06-26 21:15:58,438 main.py:47] epoch 208, training loss: 5748.59, average training loss: 8285.65, base loss: 5550.30
[INFO 2017-06-26 21:15:58,730 main.py:47] epoch 209, training loss: 4586.85, average training loss: 8268.03, base loss: 5545.64
[INFO 2017-06-26 21:15:59,026 main.py:47] epoch 210, training loss: 5706.20, average training loss: 8255.89, base loss: 5546.64
[INFO 2017-06-26 21:15:59,328 main.py:47] epoch 211, training loss: 5152.81, average training loss: 8241.26, base loss: 5544.83
[INFO 2017-06-26 21:15:59,633 main.py:47] epoch 212, training loss: 5261.34, average training loss: 8227.27, base loss: 5543.66
[INFO 2017-06-26 21:15:59,951 main.py:47] epoch 213, training loss: 6892.27, average training loss: 8221.03, base loss: 5550.23
[INFO 2017-06-26 21:16:00,255 main.py:47] epoch 214, training loss: 4895.48, average training loss: 8205.56, base loss: 5547.32
[INFO 2017-06-26 21:16:00,554 main.py:47] epoch 215, training loss: 5297.57, average training loss: 8192.10, base loss: 5546.26
[INFO 2017-06-26 21:16:00,851 main.py:47] epoch 216, training loss: 5633.12, average training loss: 8180.30, base loss: 5546.84
[INFO 2017-06-26 21:16:01,151 main.py:47] epoch 217, training loss: 5466.37, average training loss: 8167.85, base loss: 5546.64
[INFO 2017-06-26 21:16:01,446 main.py:47] epoch 218, training loss: 6166.68, average training loss: 8158.72, base loss: 5549.61
[INFO 2017-06-26 21:16:01,747 main.py:47] epoch 219, training loss: 5714.88, average training loss: 8147.61, base loss: 5550.63
[INFO 2017-06-26 21:16:02,046 main.py:47] epoch 220, training loss: 4778.93, average training loss: 8132.37, base loss: 5547.21
[INFO 2017-06-26 21:16:02,345 main.py:47] epoch 221, training loss: 6334.94, average training loss: 8124.27, base loss: 5551.02
[INFO 2017-06-26 21:16:02,650 main.py:47] epoch 222, training loss: 5052.43, average training loss: 8110.49, base loss: 5548.94
[INFO 2017-06-26 21:16:02,951 main.py:47] epoch 223, training loss: 6259.14, average training loss: 8102.23, base loss: 5552.34
[INFO 2017-06-26 21:16:03,245 main.py:47] epoch 224, training loss: 5157.82, average training loss: 8089.14, base loss: 5550.82
[INFO 2017-06-26 21:16:03,546 main.py:47] epoch 225, training loss: 7230.74, average training loss: 8085.34, base loss: 5558.63
[INFO 2017-06-26 21:16:03,850 main.py:47] epoch 226, training loss: 6325.32, average training loss: 8077.59, base loss: 5562.21
[INFO 2017-06-26 21:16:04,150 main.py:47] epoch 227, training loss: 4116.25, average training loss: 8060.22, base loss: 5555.67
[INFO 2017-06-26 21:16:04,451 main.py:47] epoch 228, training loss: 7056.68, average training loss: 8055.83, base loss: 5562.54
[INFO 2017-06-26 21:16:04,757 main.py:47] epoch 229, training loss: 5316.73, average training loss: 8043.93, base loss: 5561.50
[INFO 2017-06-26 21:16:05,057 main.py:47] epoch 230, training loss: 5634.73, average training loss: 8033.50, base loss: 5562.10
[INFO 2017-06-26 21:16:05,361 main.py:47] epoch 231, training loss: 6055.07, average training loss: 8024.97, base loss: 5564.48
[INFO 2017-06-26 21:16:05,672 main.py:47] epoch 232, training loss: 6088.69, average training loss: 8016.66, base loss: 5566.86
[INFO 2017-06-26 21:16:05,972 main.py:47] epoch 233, training loss: 4517.53, average training loss: 8001.70, base loss: 5562.49
[INFO 2017-06-26 21:16:06,279 main.py:47] epoch 234, training loss: 5809.56, average training loss: 7992.38, base loss: 5563.72
[INFO 2017-06-26 21:16:06,589 main.py:47] epoch 235, training loss: 5430.83, average training loss: 7981.52, base loss: 5563.41
[INFO 2017-06-26 21:16:06,893 main.py:47] epoch 236, training loss: 6057.45, average training loss: 7973.40, base loss: 5565.76
[INFO 2017-06-26 21:16:07,195 main.py:47] epoch 237, training loss: 4094.65, average training loss: 7957.11, base loss: 5559.42
[INFO 2017-06-26 21:16:07,495 main.py:47] epoch 238, training loss: 5611.89, average training loss: 7947.29, base loss: 5559.80
[INFO 2017-06-26 21:16:07,798 main.py:47] epoch 239, training loss: 5642.29, average training loss: 7937.69, base loss: 5560.27
[INFO 2017-06-26 21:16:08,099 main.py:47] epoch 240, training loss: 5009.38, average training loss: 7925.54, base loss: 5558.08
[INFO 2017-06-26 21:16:08,405 main.py:47] epoch 241, training loss: 6118.18, average training loss: 7918.07, base loss: 5560.57
[INFO 2017-06-26 21:16:08,717 main.py:47] epoch 242, training loss: 7851.50, average training loss: 7917.80, base loss: 5570.32
[INFO 2017-06-26 21:16:09,023 main.py:47] epoch 243, training loss: 4876.21, average training loss: 7905.33, base loss: 5567.65
[INFO 2017-06-26 21:16:09,331 main.py:47] epoch 244, training loss: 5995.01, average training loss: 7897.53, base loss: 5569.60
[INFO 2017-06-26 21:16:09,640 main.py:47] epoch 245, training loss: 5425.45, average training loss: 7887.49, base loss: 5569.08
[INFO 2017-06-26 21:16:09,947 main.py:47] epoch 246, training loss: 5099.11, average training loss: 7876.20, base loss: 5567.34
[INFO 2017-06-26 21:16:10,257 main.py:47] epoch 247, training loss: 5615.45, average training loss: 7867.08, base loss: 5567.73
[INFO 2017-06-26 21:16:10,564 main.py:47] epoch 248, training loss: 7805.83, average training loss: 7866.83, base loss: 5577.13
[INFO 2017-06-26 21:16:10,880 main.py:47] epoch 249, training loss: 5272.17, average training loss: 7856.46, base loss: 5576.14
[INFO 2017-06-26 21:16:11,188 main.py:47] epoch 250, training loss: 6265.87, average training loss: 7850.12, base loss: 5579.13
[INFO 2017-06-26 21:16:11,497 main.py:47] epoch 251, training loss: 4373.71, average training loss: 7836.32, base loss: 5574.28
[INFO 2017-06-26 21:16:11,806 main.py:47] epoch 252, training loss: 6096.49, average training loss: 7829.45, base loss: 5576.60
[INFO 2017-06-26 21:16:12,111 main.py:47] epoch 253, training loss: 5463.85, average training loss: 7820.13, base loss: 5576.33
[INFO 2017-06-26 21:16:12,415 main.py:47] epoch 254, training loss: 6282.87, average training loss: 7814.10, base loss: 5579.42
[INFO 2017-06-26 21:16:12,724 main.py:47] epoch 255, training loss: 5407.18, average training loss: 7804.70, base loss: 5578.92
[INFO 2017-06-26 21:16:13,046 main.py:47] epoch 256, training loss: 6145.21, average training loss: 7798.25, base loss: 5581.33
[INFO 2017-06-26 21:16:13,356 main.py:47] epoch 257, training loss: 7190.03, average training loss: 7795.89, base loss: 5588.04
[INFO 2017-06-26 21:16:13,661 main.py:47] epoch 258, training loss: 5723.19, average training loss: 7787.89, base loss: 5588.81
[INFO 2017-06-26 21:16:13,969 main.py:47] epoch 259, training loss: 4477.18, average training loss: 7775.15, base loss: 5584.47
[INFO 2017-06-26 21:16:14,274 main.py:47] epoch 260, training loss: 6233.01, average training loss: 7769.24, base loss: 5587.25
[INFO 2017-06-26 21:16:14,581 main.py:47] epoch 261, training loss: 5880.44, average training loss: 7762.03, base loss: 5588.75
[INFO 2017-06-26 21:16:14,889 main.py:47] epoch 262, training loss: 7063.69, average training loss: 7759.38, base loss: 5594.68
[INFO 2017-06-26 21:16:15,195 main.py:47] epoch 263, training loss: 5898.68, average training loss: 7752.33, base loss: 5596.01
[INFO 2017-06-26 21:16:15,501 main.py:47] epoch 264, training loss: 6174.50, average training loss: 7746.38, base loss: 5598.31
[INFO 2017-06-26 21:16:15,813 main.py:47] epoch 265, training loss: 4231.11, average training loss: 7733.16, base loss: 5593.09
[INFO 2017-06-26 21:16:16,122 main.py:47] epoch 266, training loss: 5798.01, average training loss: 7725.91, base loss: 5594.05
[INFO 2017-06-26 21:16:16,432 main.py:47] epoch 267, training loss: 5366.42, average training loss: 7717.11, base loss: 5593.35
[INFO 2017-06-26 21:16:16,739 main.py:47] epoch 268, training loss: 4882.22, average training loss: 7706.57, base loss: 5590.80
[INFO 2017-06-26 21:16:17,053 main.py:47] epoch 269, training loss: 4761.49, average training loss: 7695.66, base loss: 5587.85
[INFO 2017-06-26 21:16:17,367 main.py:47] epoch 270, training loss: 6152.67, average training loss: 7689.97, base loss: 5590.19
[INFO 2017-06-26 21:16:17,681 main.py:47] epoch 271, training loss: 7469.49, average training loss: 7689.16, base loss: 5597.41
[INFO 2017-06-26 21:16:17,993 main.py:47] epoch 272, training loss: 4851.46, average training loss: 7678.76, base loss: 5594.78
[INFO 2017-06-26 21:16:18,307 main.py:47] epoch 273, training loss: 6042.40, average training loss: 7672.79, base loss: 5596.60
[INFO 2017-06-26 21:16:18,624 main.py:47] epoch 274, training loss: 6720.03, average training loss: 7669.33, base loss: 5600.90
[INFO 2017-06-26 21:16:18,937 main.py:47] epoch 275, training loss: 6084.39, average training loss: 7663.59, base loss: 5602.79
[INFO 2017-06-26 21:16:19,255 main.py:47] epoch 276, training loss: 6665.71, average training loss: 7659.98, base loss: 5606.90
[INFO 2017-06-26 21:16:19,567 main.py:47] epoch 277, training loss: 5713.93, average training loss: 7652.98, base loss: 5607.45
[INFO 2017-06-26 21:16:19,880 main.py:47] epoch 278, training loss: 4894.25, average training loss: 7643.09, base loss: 5604.97
[INFO 2017-06-26 21:16:20,192 main.py:47] epoch 279, training loss: 4489.36, average training loss: 7631.83, base loss: 5600.98
[INFO 2017-06-26 21:16:20,505 main.py:47] epoch 280, training loss: 4184.03, average training loss: 7619.56, base loss: 5595.90
[INFO 2017-06-26 21:16:20,819 main.py:47] epoch 281, training loss: 5315.68, average training loss: 7611.39, base loss: 5595.09
[INFO 2017-06-26 21:16:21,132 main.py:47] epoch 282, training loss: 5364.91, average training loss: 7603.45, base loss: 5594.45
[INFO 2017-06-26 21:16:21,445 main.py:47] epoch 283, training loss: 5575.86, average training loss: 7596.31, base loss: 5594.51
[INFO 2017-06-26 21:16:21,758 main.py:47] epoch 284, training loss: 6170.76, average training loss: 7591.31, base loss: 5596.81
[INFO 2017-06-26 21:16:22,075 main.py:47] epoch 285, training loss: 5000.82, average training loss: 7582.25, base loss: 5594.81
[INFO 2017-06-26 21:16:22,387 main.py:47] epoch 286, training loss: 5331.27, average training loss: 7574.41, base loss: 5594.06
[INFO 2017-06-26 21:16:22,700 main.py:47] epoch 287, training loss: 4788.41, average training loss: 7564.74, base loss: 5591.35
[INFO 2017-06-26 21:16:23,016 main.py:47] epoch 288, training loss: 5249.11, average training loss: 7556.73, base loss: 5590.34
[INFO 2017-06-26 21:16:23,331 main.py:47] epoch 289, training loss: 5257.87, average training loss: 7548.80, base loss: 5589.35
[INFO 2017-06-26 21:16:23,647 main.py:47] epoch 290, training loss: 6399.74, average training loss: 7544.85, base loss: 5592.40
[INFO 2017-06-26 21:16:23,968 main.py:47] epoch 291, training loss: 4752.08, average training loss: 7535.29, base loss: 5589.60
[INFO 2017-06-26 21:16:24,284 main.py:47] epoch 292, training loss: 4218.04, average training loss: 7523.96, base loss: 5584.92
[INFO 2017-06-26 21:16:24,600 main.py:47] epoch 293, training loss: 5904.62, average training loss: 7518.46, base loss: 5586.31
[INFO 2017-06-26 21:16:24,915 main.py:47] epoch 294, training loss: 6177.41, average training loss: 7513.91, base loss: 5588.50
[INFO 2017-06-26 21:16:25,235 main.py:47] epoch 295, training loss: 4810.65, average training loss: 7504.78, base loss: 5585.94
[INFO 2017-06-26 21:16:25,555 main.py:47] epoch 296, training loss: 7256.53, average training loss: 7503.94, base loss: 5591.93
[INFO 2017-06-26 21:16:25,871 main.py:47] epoch 297, training loss: 5861.70, average training loss: 7498.43, base loss: 5593.01
[INFO 2017-06-26 21:16:26,189 main.py:47] epoch 298, training loss: 5521.42, average training loss: 7491.82, base loss: 5592.95
[INFO 2017-06-26 21:16:26,504 main.py:47] epoch 299, training loss: 6460.44, average training loss: 7488.38, base loss: 5596.08
[INFO 2017-06-26 21:16:26,505 main.py:49] epoch 299, testing
[INFO 2017-06-26 21:16:27,685 main.py:100] average testing loss: 5933.07, base loss: 6005.22
[INFO 2017-06-26 21:16:27,686 main.py:73] current best accuracy: 5491.14
[INFO 2017-06-26 21:16:28,002 main.py:47] epoch 300, training loss: 5027.70, average training loss: 7480.21, base loss: 5594.27
[INFO 2017-06-26 21:16:28,316 main.py:47] epoch 301, training loss: 7190.02, average training loss: 7479.24, base loss: 5599.87
[INFO 2017-06-26 21:16:28,636 main.py:47] epoch 302, training loss: 9482.37, average training loss: 7485.86, base loss: 5612.99
[INFO 2017-06-26 21:16:28,950 main.py:47] epoch 303, training loss: 5800.18, average training loss: 7480.31, base loss: 5613.81
[INFO 2017-06-26 21:16:29,266 main.py:47] epoch 304, training loss: 5031.69, average training loss: 7472.28, base loss: 5612.19
[INFO 2017-06-26 21:16:29,579 main.py:47] epoch 305, training loss: 5226.97, average training loss: 7464.94, base loss: 5611.10
[INFO 2017-06-26 21:16:29,894 main.py:47] epoch 306, training loss: 4894.07, average training loss: 7456.57, base loss: 5608.94
[INFO 2017-06-26 21:16:30,209 main.py:47] epoch 307, training loss: 5934.45, average training loss: 7451.63, base loss: 5610.15
[INFO 2017-06-26 21:16:30,525 main.py:47] epoch 308, training loss: 4974.74, average training loss: 7443.61, base loss: 5608.29
[INFO 2017-06-26 21:16:30,840 main.py:47] epoch 309, training loss: 4898.09, average training loss: 7435.40, base loss: 5606.16
[INFO 2017-06-26 21:16:31,156 main.py:47] epoch 310, training loss: 6488.13, average training loss: 7432.36, base loss: 5609.17
[INFO 2017-06-26 21:16:31,471 main.py:47] epoch 311, training loss: 5258.59, average training loss: 7425.39, base loss: 5608.22
[INFO 2017-06-26 21:16:31,789 main.py:47] epoch 312, training loss: 4631.49, average training loss: 7416.46, base loss: 5605.21
[INFO 2017-06-26 21:16:32,103 main.py:47] epoch 313, training loss: 5383.01, average training loss: 7409.99, base loss: 5604.73
[INFO 2017-06-26 21:16:32,419 main.py:47] epoch 314, training loss: 4456.37, average training loss: 7400.61, base loss: 5601.12
[INFO 2017-06-26 21:16:32,736 main.py:47] epoch 315, training loss: 5135.38, average training loss: 7393.44, base loss: 5599.88
[INFO 2017-06-26 21:16:33,051 main.py:47] epoch 316, training loss: 5643.46, average training loss: 7387.92, base loss: 5600.20
[INFO 2017-06-26 21:16:33,369 main.py:47] epoch 317, training loss: 5378.54, average training loss: 7381.60, base loss: 5599.68
[INFO 2017-06-26 21:16:33,687 main.py:47] epoch 318, training loss: 4831.63, average training loss: 7373.61, base loss: 5597.45
[INFO 2017-06-26 21:16:34,005 main.py:47] epoch 319, training loss: 5156.72, average training loss: 7366.68, base loss: 5596.20
[INFO 2017-06-26 21:16:34,323 main.py:47] epoch 320, training loss: 5285.79, average training loss: 7360.20, base loss: 5595.40
[INFO 2017-06-26 21:16:34,641 main.py:47] epoch 321, training loss: 5355.34, average training loss: 7353.97, base loss: 5594.87
[INFO 2017-06-26 21:16:34,958 main.py:47] epoch 322, training loss: 7232.72, average training loss: 7353.60, base loss: 5600.36
[INFO 2017-06-26 21:16:35,278 main.py:47] epoch 323, training loss: 4580.94, average training loss: 7345.04, base loss: 5597.32
[INFO 2017-06-26 21:16:35,596 main.py:47] epoch 324, training loss: 4035.02, average training loss: 7334.85, base loss: 5592.44
[INFO 2017-06-26 21:16:35,918 main.py:47] epoch 325, training loss: 5689.34, average training loss: 7329.81, base loss: 5592.97
[INFO 2017-06-26 21:16:36,237 main.py:47] epoch 326, training loss: 4564.77, average training loss: 7321.35, base loss: 5589.91
[INFO 2017-06-26 21:16:36,556 main.py:47] epoch 327, training loss: 5378.80, average training loss: 7315.43, base loss: 5589.42
[INFO 2017-06-26 21:16:36,873 main.py:47] epoch 328, training loss: 6294.66, average training loss: 7312.33, base loss: 5591.83
[INFO 2017-06-26 21:16:37,193 main.py:47] epoch 329, training loss: 5747.30, average training loss: 7307.58, base loss: 5592.54
[INFO 2017-06-26 21:16:37,512 main.py:47] epoch 330, training loss: 4808.07, average training loss: 7300.03, base loss: 5590.36
[INFO 2017-06-26 21:16:37,829 main.py:47] epoch 331, training loss: 5945.39, average training loss: 7295.95, base loss: 5591.71
[INFO 2017-06-26 21:16:38,147 main.py:47] epoch 332, training loss: 5487.36, average training loss: 7290.52, base loss: 5591.54
[INFO 2017-06-26 21:16:38,465 main.py:47] epoch 333, training loss: 5327.44, average training loss: 7284.64, base loss: 5590.96
[INFO 2017-06-26 21:16:38,784 main.py:47] epoch 334, training loss: 5916.77, average training loss: 7280.56, base loss: 5592.22
[INFO 2017-06-26 21:16:39,102 main.py:47] epoch 335, training loss: 5301.83, average training loss: 7274.67, base loss: 5591.50
[INFO 2017-06-26 21:16:39,424 main.py:47] epoch 336, training loss: 6224.04, average training loss: 7271.55, base loss: 5593.69
[INFO 2017-06-26 21:16:39,743 main.py:47] epoch 337, training loss: 6101.23, average training loss: 7268.09, base loss: 5595.41
[INFO 2017-06-26 21:16:40,063 main.py:47] epoch 338, training loss: 4471.37, average training loss: 7259.84, base loss: 5592.10
[INFO 2017-06-26 21:16:40,386 main.py:47] epoch 339, training loss: 4993.78, average training loss: 7253.18, base loss: 5590.49
[INFO 2017-06-26 21:16:40,711 main.py:47] epoch 340, training loss: 5650.63, average training loss: 7248.48, base loss: 5590.80
[INFO 2017-06-26 21:16:41,034 main.py:47] epoch 341, training loss: 5095.81, average training loss: 7242.18, base loss: 5589.48
[INFO 2017-06-26 21:16:41,360 main.py:47] epoch 342, training loss: 5214.07, average training loss: 7236.27, base loss: 5588.58
[INFO 2017-06-26 21:16:41,689 main.py:47] epoch 343, training loss: 6051.80, average training loss: 7232.83, base loss: 5590.17
[INFO 2017-06-26 21:16:42,015 main.py:47] epoch 344, training loss: 4934.78, average training loss: 7226.16, base loss: 5588.37
[INFO 2017-06-26 21:16:42,341 main.py:47] epoch 345, training loss: 6016.03, average training loss: 7222.67, base loss: 5589.86
[INFO 2017-06-26 21:16:42,666 main.py:47] epoch 346, training loss: 6316.49, average training loss: 7220.06, base loss: 5592.22
[INFO 2017-06-26 21:16:42,996 main.py:47] epoch 347, training loss: 5127.30, average training loss: 7214.04, base loss: 5591.11
[INFO 2017-06-26 21:16:43,327 main.py:47] epoch 348, training loss: 5128.86, average training loss: 7208.07, base loss: 5590.04
[INFO 2017-06-26 21:16:43,655 main.py:47] epoch 349, training loss: 5468.41, average training loss: 7203.10, base loss: 5589.90
[INFO 2017-06-26 21:16:43,983 main.py:47] epoch 350, training loss: 6124.24, average training loss: 7200.02, base loss: 5591.68
[INFO 2017-06-26 21:16:44,313 main.py:47] epoch 351, training loss: 5634.49, average training loss: 7195.58, base loss: 5592.01
[INFO 2017-06-26 21:16:44,642 main.py:47] epoch 352, training loss: 5035.95, average training loss: 7189.46, base loss: 5590.50
[INFO 2017-06-26 21:16:44,969 main.py:47] epoch 353, training loss: 5424.18, average training loss: 7184.47, base loss: 5590.26
[INFO 2017-06-26 21:16:45,326 main.py:47] epoch 354, training loss: 5434.66, average training loss: 7179.54, base loss: 5589.96
[INFO 2017-06-26 21:16:45,659 main.py:47] epoch 355, training loss: 5793.08, average training loss: 7175.65, base loss: 5590.77
[INFO 2017-06-26 21:16:45,991 main.py:47] epoch 356, training loss: 5187.72, average training loss: 7170.08, base loss: 5589.79
[INFO 2017-06-26 21:16:46,320 main.py:47] epoch 357, training loss: 5303.53, average training loss: 7164.87, base loss: 5589.13
[INFO 2017-06-26 21:16:46,655 main.py:47] epoch 358, training loss: 5590.18, average training loss: 7160.48, base loss: 5589.23
[INFO 2017-06-26 21:16:46,988 main.py:47] epoch 359, training loss: 6648.55, average training loss: 7159.06, base loss: 5592.47
[INFO 2017-06-26 21:16:47,408 main.py:47] epoch 360, training loss: 6771.77, average training loss: 7157.98, base loss: 5595.88
[INFO 2017-06-26 21:16:47,791 main.py:47] epoch 361, training loss: 5426.38, average training loss: 7153.20, base loss: 5595.62
[INFO 2017-06-26 21:16:48,179 main.py:47] epoch 362, training loss: 4700.78, average training loss: 7146.44, base loss: 5593.35
[INFO 2017-06-26 21:16:48,568 main.py:47] epoch 363, training loss: 6066.00, average training loss: 7143.48, base loss: 5594.93
[INFO 2017-06-26 21:16:48,959 main.py:47] epoch 364, training loss: 4018.88, average training loss: 7134.92, base loss: 5590.57
[INFO 2017-06-26 21:16:49,311 main.py:47] epoch 365, training loss: 5481.48, average training loss: 7130.40, base loss: 5590.44
[INFO 2017-06-26 21:16:49,657 main.py:47] epoch 366, training loss: 5785.33, average training loss: 7126.73, base loss: 5591.23
[INFO 2017-06-26 21:16:50,063 main.py:47] epoch 367, training loss: 5975.19, average training loss: 7123.60, base loss: 5592.47
[INFO 2017-06-26 21:16:50,473 main.py:47] epoch 368, training loss: 5670.10, average training loss: 7119.66, base loss: 5592.98
[INFO 2017-06-26 21:16:50,813 main.py:47] epoch 369, training loss: 6156.25, average training loss: 7117.06, base loss: 5594.86
[INFO 2017-06-26 21:16:51,161 main.py:47] epoch 370, training loss: 5230.31, average training loss: 7111.98, base loss: 5594.06
[INFO 2017-06-26 21:16:51,489 main.py:47] epoch 371, training loss: 5559.86, average training loss: 7107.80, base loss: 5594.27
[INFO 2017-06-26 21:16:51,817 main.py:47] epoch 372, training loss: 5070.01, average training loss: 7102.34, base loss: 5592.96
[INFO 2017-06-26 21:16:52,144 main.py:47] epoch 373, training loss: 5095.33, average training loss: 7096.97, base loss: 5591.75
[INFO 2017-06-26 21:16:52,471 main.py:47] epoch 374, training loss: 5286.52, average training loss: 7092.15, base loss: 5591.30
[INFO 2017-06-26 21:16:52,800 main.py:47] epoch 375, training loss: 5220.14, average training loss: 7087.17, base loss: 5590.50
[INFO 2017-06-26 21:16:53,129 main.py:47] epoch 376, training loss: 5270.48, average training loss: 7082.35, base loss: 5589.99
[INFO 2017-06-26 21:16:53,456 main.py:47] epoch 377, training loss: 5358.17, average training loss: 7077.79, base loss: 5589.44
[INFO 2017-06-26 21:16:53,781 main.py:47] epoch 378, training loss: 5417.21, average training loss: 7073.41, base loss: 5589.07
[INFO 2017-06-26 21:16:54,101 main.py:47] epoch 379, training loss: 5475.43, average training loss: 7069.20, base loss: 5589.02
[INFO 2017-06-26 21:16:54,429 main.py:47] epoch 380, training loss: 4543.61, average training loss: 7062.57, base loss: 5586.44
[INFO 2017-06-26 21:16:54,761 main.py:47] epoch 381, training loss: 6689.62, average training loss: 7061.59, base loss: 5589.60
[INFO 2017-06-26 21:16:55,089 main.py:47] epoch 382, training loss: 5269.84, average training loss: 7056.92, base loss: 5588.93
[INFO 2017-06-26 21:16:55,417 main.py:47] epoch 383, training loss: 4801.76, average training loss: 7051.04, base loss: 5587.02
[INFO 2017-06-26 21:16:55,744 main.py:47] epoch 384, training loss: 4901.10, average training loss: 7045.46, base loss: 5585.37
[INFO 2017-06-26 21:16:56,074 main.py:47] epoch 385, training loss: 5755.23, average training loss: 7042.12, base loss: 5585.94
[INFO 2017-06-26 21:16:56,402 main.py:47] epoch 386, training loss: 4827.80, average training loss: 7036.40, base loss: 5584.08
[INFO 2017-06-26 21:16:56,730 main.py:47] epoch 387, training loss: 5370.87, average training loss: 7032.10, base loss: 5583.72
[INFO 2017-06-26 21:16:57,059 main.py:47] epoch 388, training loss: 4698.83, average training loss: 7026.10, base loss: 5581.59
[INFO 2017-06-26 21:16:57,386 main.py:47] epoch 389, training loss: 4762.97, average training loss: 7020.30, base loss: 5579.57
[INFO 2017-06-26 21:16:57,724 main.py:47] epoch 390, training loss: 5575.71, average training loss: 7016.61, base loss: 5579.74
[INFO 2017-06-26 21:16:58,086 main.py:47] epoch 391, training loss: 6349.15, average training loss: 7014.90, base loss: 5581.94
[INFO 2017-06-26 21:16:58,414 main.py:47] epoch 392, training loss: 6686.24, average training loss: 7014.07, base loss: 5584.92
[INFO 2017-06-26 21:16:58,744 main.py:47] epoch 393, training loss: 5767.78, average training loss: 7010.90, base loss: 5585.53
[INFO 2017-06-26 21:16:59,072 main.py:47] epoch 394, training loss: 6075.42, average training loss: 7008.54, base loss: 5587.01
[INFO 2017-06-26 21:16:59,488 main.py:47] epoch 395, training loss: 5379.83, average training loss: 7004.42, base loss: 5586.65
[INFO 2017-06-26 21:16:59,824 main.py:47] epoch 396, training loss: 4807.29, average training loss: 6998.89, base loss: 5584.82
[INFO 2017-06-26 21:17:00,239 main.py:47] epoch 397, training loss: 5791.48, average training loss: 6995.86, base loss: 5585.62
[INFO 2017-06-26 21:17:00,598 main.py:47] epoch 398, training loss: 6319.83, average training loss: 6994.16, base loss: 5587.65
[INFO 2017-06-26 21:17:00,933 main.py:47] epoch 399, training loss: 6703.35, average training loss: 6993.43, base loss: 5590.71
[INFO 2017-06-26 21:17:00,933 main.py:49] epoch 399, testing
[INFO 2017-06-26 21:17:02,338 main.py:100] average testing loss: 5727.96, base loss: 5826.66
[INFO 2017-06-26 21:17:02,339 main.py:73] current best accuracy: 5491.14
[INFO 2017-06-26 21:17:02,682 main.py:47] epoch 400, training loss: 5238.82, average training loss: 6989.06, base loss: 5590.05
[INFO 2017-06-26 21:17:03,037 main.py:47] epoch 401, training loss: 5380.98, average training loss: 6985.06, base loss: 5589.74
[INFO 2017-06-26 21:17:03,366 main.py:47] epoch 402, training loss: 5602.13, average training loss: 6981.63, base loss: 5590.00
[INFO 2017-06-26 21:17:03,697 main.py:47] epoch 403, training loss: 4388.64, average training loss: 6975.21, base loss: 5587.12
[INFO 2017-06-26 21:17:04,086 main.py:47] epoch 404, training loss: 6076.56, average training loss: 6972.99, base loss: 5588.50
[INFO 2017-06-26 21:17:04,424 main.py:47] epoch 405, training loss: 4774.44, average training loss: 6967.57, base loss: 5586.67
[INFO 2017-06-26 21:17:04,780 main.py:47] epoch 406, training loss: 5744.09, average training loss: 6964.57, base loss: 5587.24
[INFO 2017-06-26 21:17:05,154 main.py:47] epoch 407, training loss: 6605.77, average training loss: 6963.69, base loss: 5590.00
[INFO 2017-06-26 21:17:05,484 main.py:47] epoch 408, training loss: 6251.63, average training loss: 6961.95, base loss: 5591.92
[INFO 2017-06-26 21:17:05,876 main.py:47] epoch 409, training loss: 6042.32, average training loss: 6959.71, base loss: 5593.29
[INFO 2017-06-26 21:17:06,215 main.py:47] epoch 410, training loss: 5815.38, average training loss: 6956.92, base loss: 5594.05
[INFO 2017-06-26 21:17:06,624 main.py:47] epoch 411, training loss: 5863.86, average training loss: 6954.27, base loss: 5594.96
[INFO 2017-06-26 21:17:06,993 main.py:47] epoch 412, training loss: 6839.86, average training loss: 6953.99, base loss: 5598.35
[INFO 2017-06-26 21:17:07,359 main.py:47] epoch 413, training loss: 6669.49, average training loss: 6953.30, base loss: 5601.36
[INFO 2017-06-26 21:17:07,713 main.py:47] epoch 414, training loss: 7208.90, average training loss: 6953.92, base loss: 5605.68
[INFO 2017-06-26 21:17:08,075 main.py:47] epoch 415, training loss: 4711.16, average training loss: 6948.53, base loss: 5603.63
[INFO 2017-06-26 21:17:08,428 main.py:47] epoch 416, training loss: 5014.94, average training loss: 6943.89, base loss: 5602.35
[INFO 2017-06-26 21:17:08,762 main.py:47] epoch 417, training loss: 5327.67, average training loss: 6940.02, base loss: 5601.84
[INFO 2017-06-26 21:17:09,182 main.py:47] epoch 418, training loss: 4564.42, average training loss: 6934.36, base loss: 5599.56
[INFO 2017-06-26 21:17:09,535 main.py:47] epoch 419, training loss: 7228.48, average training loss: 6935.06, base loss: 5603.75
[INFO 2017-06-26 21:17:09,943 main.py:47] epoch 420, training loss: 6113.47, average training loss: 6933.10, base loss: 5605.16
[INFO 2017-06-26 21:17:10,301 main.py:47] epoch 421, training loss: 5048.08, average training loss: 6928.64, base loss: 5603.98
[INFO 2017-06-26 21:17:10,721 main.py:47] epoch 422, training loss: 5918.92, average training loss: 6926.25, base loss: 5604.97
[INFO 2017-06-26 21:17:11,063 main.py:47] epoch 423, training loss: 4663.93, average training loss: 6920.91, base loss: 5602.87
[INFO 2017-06-26 21:17:11,453 main.py:47] epoch 424, training loss: 7222.27, average training loss: 6921.62, base loss: 5607.05
[INFO 2017-06-26 21:17:11,796 main.py:47] epoch 425, training loss: 6829.88, average training loss: 6921.41, base loss: 5610.20
[INFO 2017-06-26 21:17:12,173 main.py:47] epoch 426, training loss: 4602.82, average training loss: 6915.98, base loss: 5607.89
[INFO 2017-06-26 21:17:12,532 main.py:47] epoch 427, training loss: 9458.04, average training loss: 6921.92, base loss: 5617.14
[INFO 2017-06-26 21:17:12,951 main.py:47] epoch 428, training loss: 4285.02, average training loss: 6915.77, base loss: 5614.05
[INFO 2017-06-26 21:17:13,340 main.py:47] epoch 429, training loss: 4960.04, average training loss: 6911.22, base loss: 5612.65
[INFO 2017-06-26 21:17:13,731 main.py:47] epoch 430, training loss: 5814.36, average training loss: 6908.68, base loss: 5613.41
[INFO 2017-06-26 21:17:14,085 main.py:47] epoch 431, training loss: 5600.85, average training loss: 6905.65, base loss: 5613.61
[INFO 2017-06-26 21:17:14,481 main.py:47] epoch 432, training loss: 7008.08, average training loss: 6905.89, base loss: 5617.12
[INFO 2017-06-26 21:17:14,876 main.py:47] epoch 433, training loss: 7092.53, average training loss: 6906.32, base loss: 5620.77
[INFO 2017-06-26 21:17:15,274 main.py:47] epoch 434, training loss: 4704.96, average training loss: 6901.26, base loss: 5618.74
[INFO 2017-06-26 21:17:15,644 main.py:47] epoch 435, training loss: 9223.79, average training loss: 6906.58, base loss: 5627.22
[INFO 2017-06-26 21:17:16,063 main.py:47] epoch 436, training loss: 4905.38, average training loss: 6902.00, base loss: 5625.76
[INFO 2017-06-26 21:17:16,419 main.py:47] epoch 437, training loss: 7461.77, average training loss: 6903.28, base loss: 5630.22
[INFO 2017-06-26 21:17:16,812 main.py:47] epoch 438, training loss: 5025.29, average training loss: 6899.00, base loss: 5628.98
[INFO 2017-06-26 21:17:17,176 main.py:47] epoch 439, training loss: 6506.73, average training loss: 6898.11, base loss: 5631.15
[INFO 2017-06-26 21:17:17,543 main.py:47] epoch 440, training loss: 4807.00, average training loss: 6893.37, base loss: 5629.38
[INFO 2017-06-26 21:17:17,907 main.py:47] epoch 441, training loss: 4663.62, average training loss: 6888.33, base loss: 5627.15
[INFO 2017-06-26 21:17:18,249 main.py:47] epoch 442, training loss: 4841.99, average training loss: 6883.71, base loss: 5625.58
[INFO 2017-06-26 21:17:18,629 main.py:47] epoch 443, training loss: 5440.54, average training loss: 6880.46, base loss: 5625.39
[INFO 2017-06-26 21:17:18,961 main.py:47] epoch 444, training loss: 5748.31, average training loss: 6877.91, base loss: 5625.87
[INFO 2017-06-26 21:17:19,393 main.py:47] epoch 445, training loss: 4553.56, average training loss: 6872.70, base loss: 5623.57
[INFO 2017-06-26 21:17:19,724 main.py:47] epoch 446, training loss: 5776.08, average training loss: 6870.25, base loss: 5624.15
[INFO 2017-06-26 21:17:20,131 main.py:47] epoch 447, training loss: 5000.12, average training loss: 6866.07, base loss: 5622.93
[INFO 2017-06-26 21:17:20,464 main.py:47] epoch 448, training loss: 5741.04, average training loss: 6863.57, base loss: 5623.46
[INFO 2017-06-26 21:17:20,887 main.py:47] epoch 449, training loss: 5545.14, average training loss: 6860.64, base loss: 5623.48
[INFO 2017-06-26 21:17:21,244 main.py:47] epoch 450, training loss: 5003.43, average training loss: 6856.52, base loss: 5622.31
[INFO 2017-06-26 21:17:21,615 main.py:47] epoch 451, training loss: 5666.31, average training loss: 6853.89, base loss: 5622.73
[INFO 2017-06-26 21:17:21,981 main.py:47] epoch 452, training loss: 4644.38, average training loss: 6849.01, base loss: 5620.76
[INFO 2017-06-26 21:17:22,354 main.py:47] epoch 453, training loss: 5255.48, average training loss: 6845.50, base loss: 5619.98
[INFO 2017-06-26 21:17:22,728 main.py:47] epoch 454, training loss: 5231.92, average training loss: 6841.95, base loss: 5619.47
[INFO 2017-06-26 21:17:23,100 main.py:47] epoch 455, training loss: 5371.91, average training loss: 6838.73, base loss: 5619.09
[INFO 2017-06-26 21:17:23,493 main.py:47] epoch 456, training loss: 4936.72, average training loss: 6834.57, base loss: 5617.65
[INFO 2017-06-26 21:17:23,853 main.py:47] epoch 457, training loss: 5667.70, average training loss: 6832.02, base loss: 5618.00
[INFO 2017-06-26 21:17:24,234 main.py:47] epoch 458, training loss: 5053.73, average training loss: 6828.14, base loss: 5616.90
[INFO 2017-06-26 21:17:24,662 main.py:47] epoch 459, training loss: 5253.19, average training loss: 6824.72, base loss: 5616.23
[INFO 2017-06-26 21:17:25,074 main.py:47] epoch 460, training loss: 4892.38, average training loss: 6820.53, base loss: 5614.79
[INFO 2017-06-26 21:17:25,431 main.py:47] epoch 461, training loss: 5620.90, average training loss: 6817.93, base loss: 5615.00
[INFO 2017-06-26 21:17:25,842 main.py:47] epoch 462, training loss: 5321.85, average training loss: 6814.70, base loss: 5614.53
[INFO 2017-06-26 21:17:26,194 main.py:47] epoch 463, training loss: 5161.97, average training loss: 6811.14, base loss: 5613.72
[INFO 2017-06-26 21:17:26,574 main.py:47] epoch 464, training loss: 6077.02, average training loss: 6809.56, base loss: 5614.91
[INFO 2017-06-26 21:17:26,948 main.py:47] epoch 465, training loss: 5780.21, average training loss: 6807.35, base loss: 5615.42
[INFO 2017-06-26 21:17:27,296 main.py:47] epoch 466, training loss: 4764.50, average training loss: 6802.98, base loss: 5613.69
[INFO 2017-06-26 21:17:27,704 main.py:47] epoch 467, training loss: 6049.00, average training loss: 6801.37, base loss: 5614.90
[INFO 2017-06-26 21:17:28,051 main.py:47] epoch 468, training loss: 6483.53, average training loss: 6800.69, base loss: 5616.98
[INFO 2017-06-26 21:17:28,481 main.py:47] epoch 469, training loss: 5202.99, average training loss: 6797.29, base loss: 5616.28
[INFO 2017-06-26 21:17:28,827 main.py:47] epoch 470, training loss: 5757.70, average training loss: 6795.08, base loss: 5616.84
[INFO 2017-06-26 21:17:29,249 main.py:47] epoch 471, training loss: 5287.38, average training loss: 6791.89, base loss: 5616.32
[INFO 2017-06-26 21:17:29,598 main.py:47] epoch 472, training loss: 4064.99, average training loss: 6786.12, base loss: 5613.05
[INFO 2017-06-26 21:17:30,027 main.py:47] epoch 473, training loss: 6148.80, average training loss: 6784.78, base loss: 5614.39
[INFO 2017-06-26 21:17:30,376 main.py:47] epoch 474, training loss: 5380.58, average training loss: 6781.82, base loss: 5614.12
[INFO 2017-06-26 21:17:30,807 main.py:47] epoch 475, training loss: 5741.77, average training loss: 6779.64, base loss: 5614.60
[INFO 2017-06-26 21:17:31,152 main.py:47] epoch 476, training loss: 5641.09, average training loss: 6777.25, base loss: 5614.77
[INFO 2017-06-26 21:17:31,585 main.py:47] epoch 477, training loss: 5447.68, average training loss: 6774.47, base loss: 5614.60
[INFO 2017-06-26 21:17:31,932 main.py:47] epoch 478, training loss: 5000.95, average training loss: 6770.77, base loss: 5613.42
[INFO 2017-06-26 21:17:32,361 main.py:47] epoch 479, training loss: 4726.65, average training loss: 6766.51, base loss: 5611.73
[INFO 2017-06-26 21:17:32,705 main.py:47] epoch 480, training loss: 5046.81, average training loss: 6762.93, base loss: 5610.68
[INFO 2017-06-26 21:17:33,110 main.py:47] epoch 481, training loss: 5659.62, average training loss: 6760.64, base loss: 5610.98
[INFO 2017-06-26 21:17:33,489 main.py:47] epoch 482, training loss: 7168.16, average training loss: 6761.49, base loss: 5614.48
[INFO 2017-06-26 21:17:33,901 main.py:47] epoch 483, training loss: 5186.06, average training loss: 6758.23, base loss: 5613.83
[INFO 2017-06-26 21:17:34,272 main.py:47] epoch 484, training loss: 5625.74, average training loss: 6755.90, base loss: 5614.08
[INFO 2017-06-26 21:17:34,616 main.py:47] epoch 485, training loss: 6430.86, average training loss: 6755.23, base loss: 5615.99
[INFO 2017-06-26 21:17:35,049 main.py:47] epoch 486, training loss: 5038.45, average training loss: 6751.70, base loss: 5614.91
[INFO 2017-06-26 21:17:35,397 main.py:47] epoch 487, training loss: 4420.10, average training loss: 6746.92, base loss: 5612.52
[INFO 2017-06-26 21:17:35,797 main.py:47] epoch 488, training loss: 5824.92, average training loss: 6745.04, base loss: 5613.24
[INFO 2017-06-26 21:17:36,171 main.py:47] epoch 489, training loss: 4968.00, average training loss: 6741.41, base loss: 5612.06
[INFO 2017-06-26 21:17:36,514 main.py:47] epoch 490, training loss: 5497.94, average training loss: 6738.88, base loss: 5612.08
[INFO 2017-06-26 21:17:36,955 main.py:47] epoch 491, training loss: 5111.53, average training loss: 6735.57, base loss: 5611.25
[INFO 2017-06-26 21:17:37,303 main.py:47] epoch 492, training loss: 4962.74, average training loss: 6731.98, base loss: 5610.13
[INFO 2017-06-26 21:17:37,742 main.py:47] epoch 493, training loss: 5261.52, average training loss: 6729.00, base loss: 5609.66
[INFO 2017-06-26 21:17:38,109 main.py:47] epoch 494, training loss: 5400.91, average training loss: 6726.32, base loss: 5609.50
[INFO 2017-06-26 21:17:38,486 main.py:47] epoch 495, training loss: 5977.31, average training loss: 6724.81, base loss: 5610.40
[INFO 2017-06-26 21:17:38,846 main.py:47] epoch 496, training loss: 5688.98, average training loss: 6722.72, base loss: 5610.86
[INFO 2017-06-26 21:17:39,229 main.py:47] epoch 497, training loss: 6234.29, average training loss: 6721.74, base loss: 5612.43
[INFO 2017-06-26 21:17:39,593 main.py:47] epoch 498, training loss: 4557.46, average training loss: 6717.40, base loss: 5610.45
[INFO 2017-06-26 21:17:39,969 main.py:47] epoch 499, training loss: 6217.90, average training loss: 6716.41, base loss: 5611.87
[INFO 2017-06-26 21:17:39,969 main.py:49] epoch 499, testing
[INFO 2017-06-26 21:17:41,434 main.py:100] average testing loss: 5242.86, base loss: 5326.87
[INFO 2017-06-26 21:17:41,435 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:17:41,448 main.py:73] current best accuracy: 5242.86
[INFO 2017-06-26 21:17:41,788 main.py:47] epoch 500, training loss: 6381.12, average training loss: 6715.74, base loss: 5613.64
[INFO 2017-06-26 21:17:42,217 main.py:47] epoch 501, training loss: 6687.96, average training loss: 6715.68, base loss: 5616.15
[INFO 2017-06-26 21:17:42,562 main.py:47] epoch 502, training loss: 4480.33, average training loss: 6711.24, base loss: 5614.03
[INFO 2017-06-26 21:17:42,909 main.py:47] epoch 503, training loss: 6596.69, average training loss: 6711.01, base loss: 5616.36
[INFO 2017-06-26 21:17:43,287 main.py:47] epoch 504, training loss: 5978.31, average training loss: 6709.56, base loss: 5617.30
[INFO 2017-06-26 21:17:43,633 main.py:47] epoch 505, training loss: 5484.93, average training loss: 6707.14, base loss: 5617.21
[INFO 2017-06-26 21:17:44,047 main.py:47] epoch 506, training loss: 5598.53, average training loss: 6704.95, base loss: 5617.49
[INFO 2017-06-26 21:17:44,399 main.py:47] epoch 507, training loss: 5144.57, average training loss: 6701.88, base loss: 5616.80
[INFO 2017-06-26 21:17:44,831 main.py:47] epoch 508, training loss: 6854.46, average training loss: 6702.18, base loss: 5619.56
[INFO 2017-06-26 21:17:45,186 main.py:47] epoch 509, training loss: 5860.06, average training loss: 6700.53, base loss: 5620.13
[INFO 2017-06-26 21:17:45,528 main.py:47] epoch 510, training loss: 4439.48, average training loss: 6696.10, base loss: 5617.76
[INFO 2017-06-26 21:17:45,871 main.py:47] epoch 511, training loss: 5557.20, average training loss: 6693.88, base loss: 5617.71
[INFO 2017-06-26 21:17:46,212 main.py:47] epoch 512, training loss: 5189.35, average training loss: 6690.95, base loss: 5616.99
[INFO 2017-06-26 21:17:46,560 main.py:47] epoch 513, training loss: 4932.45, average training loss: 6687.53, base loss: 5615.77
[INFO 2017-06-26 21:17:46,920 main.py:47] epoch 514, training loss: 4496.71, average training loss: 6683.27, base loss: 5613.69
[INFO 2017-06-26 21:17:47,264 main.py:47] epoch 515, training loss: 4209.56, average training loss: 6678.48, base loss: 5611.03
[INFO 2017-06-26 21:17:47,610 main.py:47] epoch 516, training loss: 4656.43, average training loss: 6674.57, base loss: 5609.26
[INFO 2017-06-26 21:17:47,953 main.py:47] epoch 517, training loss: 5802.59, average training loss: 6672.88, base loss: 5609.78
[INFO 2017-06-26 21:17:48,299 main.py:47] epoch 518, training loss: 5397.54, average training loss: 6670.43, base loss: 5609.53
[INFO 2017-06-26 21:17:48,647 main.py:47] epoch 519, training loss: 6121.27, average training loss: 6669.37, base loss: 5610.69
[INFO 2017-06-26 21:17:48,998 main.py:47] epoch 520, training loss: 6709.80, average training loss: 6669.45, base loss: 5613.02
[INFO 2017-06-26 21:17:49,346 main.py:47] epoch 521, training loss: 6754.80, average training loss: 6669.61, base loss: 5615.39
[INFO 2017-06-26 21:17:49,702 main.py:47] epoch 522, training loss: 5786.17, average training loss: 6667.92, base loss: 5615.88
[INFO 2017-06-26 21:17:50,056 main.py:47] epoch 523, training loss: 5357.79, average training loss: 6665.42, base loss: 5615.56
[INFO 2017-06-26 21:17:50,415 main.py:47] epoch 524, training loss: 5253.87, average training loss: 6662.73, base loss: 5614.99
[INFO 2017-06-26 21:17:50,771 main.py:47] epoch 525, training loss: 5147.40, average training loss: 6659.85, base loss: 5614.20
[INFO 2017-06-26 21:17:51,124 main.py:47] epoch 526, training loss: 4776.76, average training loss: 6656.28, base loss: 5612.75
[INFO 2017-06-26 21:17:51,476 main.py:47] epoch 527, training loss: 5548.27, average training loss: 6654.18, base loss: 5612.83
[INFO 2017-06-26 21:17:51,839 main.py:47] epoch 528, training loss: 5501.85, average training loss: 6652.00, base loss: 5612.74
[INFO 2017-06-26 21:17:52,271 main.py:47] epoch 529, training loss: 4083.96, average training loss: 6647.16, base loss: 5609.93
[INFO 2017-06-26 21:17:52,687 main.py:47] epoch 530, training loss: 4799.93, average training loss: 6643.68, base loss: 5608.51
[INFO 2017-06-26 21:17:53,115 main.py:47] epoch 531, training loss: 4393.99, average training loss: 6639.45, base loss: 5606.31
[INFO 2017-06-26 21:17:53,527 main.py:47] epoch 532, training loss: 4995.98, average training loss: 6636.37, base loss: 5605.31
[INFO 2017-06-26 21:17:53,946 main.py:47] epoch 533, training loss: 5012.32, average training loss: 6633.32, base loss: 5604.30
[INFO 2017-06-26 21:17:54,313 main.py:47] epoch 534, training loss: 4907.34, average training loss: 6630.10, base loss: 5603.13
[INFO 2017-06-26 21:17:54,716 main.py:47] epoch 535, training loss: 6205.27, average training loss: 6629.31, base loss: 5604.43
[INFO 2017-06-26 21:17:55,179 main.py:47] epoch 536, training loss: 4823.87, average training loss: 6625.94, base loss: 5603.08
[INFO 2017-06-26 21:17:55,553 main.py:47] epoch 537, training loss: 5657.37, average training loss: 6624.14, base loss: 5603.35
[INFO 2017-06-26 21:17:55,905 main.py:47] epoch 538, training loss: 5804.16, average training loss: 6622.62, base loss: 5603.91
[INFO 2017-06-26 21:17:56,255 main.py:47] epoch 539, training loss: 5051.57, average training loss: 6619.71, base loss: 5603.06
[INFO 2017-06-26 21:17:56,604 main.py:47] epoch 540, training loss: 4557.45, average training loss: 6615.90, base loss: 5601.26
[INFO 2017-06-26 21:17:56,955 main.py:47] epoch 541, training loss: 4693.60, average training loss: 6612.35, base loss: 5599.76
[INFO 2017-06-26 21:17:57,350 main.py:47] epoch 542, training loss: 4777.66, average training loss: 6608.98, base loss: 5598.36
[INFO 2017-06-26 21:17:57,748 main.py:47] epoch 543, training loss: 5267.54, average training loss: 6606.51, base loss: 5597.96
[INFO 2017-06-26 21:17:58,120 main.py:47] epoch 544, training loss: 4863.12, average training loss: 6603.31, base loss: 5596.80
[INFO 2017-06-26 21:17:58,568 main.py:47] epoch 545, training loss: 6115.82, average training loss: 6602.42, base loss: 5597.98
[INFO 2017-06-26 21:17:58,961 main.py:47] epoch 546, training loss: 6370.00, average training loss: 6601.99, base loss: 5599.67
[INFO 2017-06-26 21:17:59,401 main.py:47] epoch 547, training loss: 4579.71, average training loss: 6598.30, base loss: 5597.91
[INFO 2017-06-26 21:17:59,788 main.py:47] epoch 548, training loss: 5747.94, average training loss: 6596.75, base loss: 5598.38
[INFO 2017-06-26 21:18:00,253 main.py:47] epoch 549, training loss: 6011.29, average training loss: 6595.69, base loss: 5599.39
[INFO 2017-06-26 21:18:00,647 main.py:47] epoch 550, training loss: 4760.54, average training loss: 6592.36, base loss: 5597.92
[INFO 2017-06-26 21:18:01,083 main.py:47] epoch 551, training loss: 4913.53, average training loss: 6589.32, base loss: 5596.91
[INFO 2017-06-26 21:18:01,464 main.py:47] epoch 552, training loss: 5876.66, average training loss: 6588.03, base loss: 5597.56
[INFO 2017-06-26 21:18:01,931 main.py:47] epoch 553, training loss: 6275.19, average training loss: 6587.46, base loss: 5599.11
[INFO 2017-06-26 21:18:02,346 main.py:47] epoch 554, training loss: 4391.35, average training loss: 6583.51, base loss: 5597.08
[INFO 2017-06-26 21:18:02,778 main.py:47] epoch 555, training loss: 7717.47, average training loss: 6585.55, base loss: 5601.25
[INFO 2017-06-26 21:18:03,217 main.py:47] epoch 556, training loss: 4690.97, average training loss: 6582.14, base loss: 5599.71
[INFO 2017-06-26 21:18:03,617 main.py:47] epoch 557, training loss: 5185.88, average training loss: 6579.64, base loss: 5599.17
[INFO 2017-06-26 21:18:04,055 main.py:47] epoch 558, training loss: 6195.68, average training loss: 6578.96, base loss: 5600.44
[INFO 2017-06-26 21:18:04,469 main.py:47] epoch 559, training loss: 5531.40, average training loss: 6577.09, base loss: 5600.53
[INFO 2017-06-26 21:18:04,954 main.py:47] epoch 560, training loss: 4809.51, average training loss: 6573.93, base loss: 5599.22
[INFO 2017-06-26 21:18:05,341 main.py:47] epoch 561, training loss: 4857.77, average training loss: 6570.88, base loss: 5598.01
[INFO 2017-06-26 21:18:05,804 main.py:47] epoch 562, training loss: 6538.08, average training loss: 6570.82, base loss: 5599.99
[INFO 2017-06-26 21:18:06,231 main.py:47] epoch 563, training loss: 4826.64, average training loss: 6567.73, base loss: 5598.75
[INFO 2017-06-26 21:18:06,635 main.py:47] epoch 564, training loss: 6547.58, average training loss: 6567.69, base loss: 5600.67
[INFO 2017-06-26 21:18:07,009 main.py:47] epoch 565, training loss: 8829.92, average training loss: 6571.69, base loss: 5606.50
[INFO 2017-06-26 21:18:07,423 main.py:47] epoch 566, training loss: 4268.65, average training loss: 6567.63, base loss: 5604.23
[INFO 2017-06-26 21:18:07,837 main.py:47] epoch 567, training loss: 6061.97, average training loss: 6566.74, base loss: 5605.24
[INFO 2017-06-26 21:18:08,238 main.py:47] epoch 568, training loss: 5744.50, average training loss: 6565.29, base loss: 5605.64
[INFO 2017-06-26 21:18:08,701 main.py:47] epoch 569, training loss: 4709.40, average training loss: 6562.04, base loss: 5604.16
[INFO 2017-06-26 21:18:09,099 main.py:47] epoch 570, training loss: 5222.31, average training loss: 6559.69, base loss: 5603.59
[INFO 2017-06-26 21:18:09,559 main.py:47] epoch 571, training loss: 5195.60, average training loss: 6557.31, base loss: 5603.16
[INFO 2017-06-26 21:18:09,984 main.py:47] epoch 572, training loss: 5226.23, average training loss: 6554.98, base loss: 5602.62
[INFO 2017-06-26 21:18:10,399 main.py:47] epoch 573, training loss: 5359.69, average training loss: 6552.90, base loss: 5602.43
[INFO 2017-06-26 21:18:10,815 main.py:47] epoch 574, training loss: 5885.15, average training loss: 6551.74, base loss: 5603.16
[INFO 2017-06-26 21:18:11,207 main.py:47] epoch 575, training loss: 6026.01, average training loss: 6550.83, base loss: 5604.09
[INFO 2017-06-26 21:18:11,647 main.py:47] epoch 576, training loss: 6718.93, average training loss: 6551.12, base loss: 5606.33
[INFO 2017-06-26 21:18:12,112 main.py:47] epoch 577, training loss: 6786.73, average training loss: 6551.53, base loss: 5608.69
[INFO 2017-06-26 21:18:12,494 main.py:47] epoch 578, training loss: 6133.04, average training loss: 6550.80, base loss: 5609.94
[INFO 2017-06-26 21:18:12,880 main.py:47] epoch 579, training loss: 6643.73, average training loss: 6550.96, base loss: 5611.99
[INFO 2017-06-26 21:18:13,287 main.py:47] epoch 580, training loss: 4674.90, average training loss: 6547.73, base loss: 5610.47
[INFO 2017-06-26 21:18:13,660 main.py:47] epoch 581, training loss: 5031.85, average training loss: 6545.13, base loss: 5609.63
[INFO 2017-06-26 21:18:14,131 main.py:47] epoch 582, training loss: 6535.60, average training loss: 6545.11, base loss: 5611.56
[INFO 2017-06-26 21:18:14,513 main.py:47] epoch 583, training loss: 5434.43, average training loss: 6543.21, base loss: 5611.38
[INFO 2017-06-26 21:18:14,960 main.py:47] epoch 584, training loss: 4936.92, average training loss: 6540.47, base loss: 5610.28
[INFO 2017-06-26 21:18:15,390 main.py:47] epoch 585, training loss: 7239.32, average training loss: 6541.66, base loss: 5613.27
[INFO 2017-06-26 21:18:15,850 main.py:47] epoch 586, training loss: 6348.85, average training loss: 6541.33, base loss: 5614.83
[INFO 2017-06-26 21:18:16,232 main.py:47] epoch 587, training loss: 5126.24, average training loss: 6538.92, base loss: 5614.05
[INFO 2017-06-26 21:18:16,672 main.py:47] epoch 588, training loss: 9653.28, average training loss: 6544.21, base loss: 5621.07
[INFO 2017-06-26 21:18:17,080 main.py:47] epoch 589, training loss: 5786.45, average training loss: 6542.93, base loss: 5621.56
[INFO 2017-06-26 21:18:17,510 main.py:47] epoch 590, training loss: 5980.84, average training loss: 6541.98, base loss: 5622.32
[INFO 2017-06-26 21:18:17,927 main.py:47] epoch 591, training loss: 5591.02, average training loss: 6540.37, base loss: 5622.52
[INFO 2017-06-26 21:18:18,352 main.py:47] epoch 592, training loss: 6342.92, average training loss: 6540.04, base loss: 5623.91
[INFO 2017-06-26 21:18:18,802 main.py:47] epoch 593, training loss: 5933.65, average training loss: 6539.02, base loss: 5624.62
[INFO 2017-06-26 21:18:19,236 main.py:47] epoch 594, training loss: 4569.61, average training loss: 6535.71, base loss: 5622.89
[INFO 2017-06-26 21:18:19,688 main.py:47] epoch 595, training loss: 5903.06, average training loss: 6534.64, base loss: 5623.55
[INFO 2017-06-26 21:18:20,102 main.py:47] epoch 596, training loss: 5208.64, average training loss: 6532.42, base loss: 5623.04
[INFO 2017-06-26 21:18:20,526 main.py:47] epoch 597, training loss: 6473.19, average training loss: 6532.32, base loss: 5624.63
[INFO 2017-06-26 21:18:20,977 main.py:47] epoch 598, training loss: 5267.81, average training loss: 6530.21, base loss: 5624.20
[INFO 2017-06-26 21:18:21,364 main.py:47] epoch 599, training loss: 5654.67, average training loss: 6528.75, base loss: 5624.38
[INFO 2017-06-26 21:18:21,365 main.py:49] epoch 599, testing
[INFO 2017-06-26 21:18:22,861 main.py:100] average testing loss: 6389.14, base loss: 6512.16
[INFO 2017-06-26 21:18:22,862 main.py:73] current best accuracy: 5242.86
[INFO 2017-06-26 21:18:23,241 main.py:47] epoch 600, training loss: 5532.20, average training loss: 6527.10, base loss: 5624.40
[INFO 2017-06-26 21:18:23,659 main.py:47] epoch 601, training loss: 4855.16, average training loss: 6524.32, base loss: 5623.24
[INFO 2017-06-26 21:18:24,035 main.py:47] epoch 602, training loss: 6016.72, average training loss: 6523.48, base loss: 5624.15
[INFO 2017-06-26 21:18:24,411 main.py:47] epoch 603, training loss: 4902.31, average training loss: 6520.79, base loss: 5623.10
[INFO 2017-06-26 21:18:24,785 main.py:47] epoch 604, training loss: 6367.99, average training loss: 6520.54, base loss: 5624.60
[INFO 2017-06-26 21:18:25,158 main.py:47] epoch 605, training loss: 6012.59, average training loss: 6519.70, base loss: 5625.44
