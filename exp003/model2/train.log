[INFO 2017-06-26 21:41:16,626 main.py:124] Namespace(batch_size=32, display=False, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=2, num_channel=3, num_inputs=2, save_dir='./model', test=False, test_dir='/home/yi/Downloads/youtube-64', test_epoch=10, test_interval=100, train=True, train_dir='/home/yi/Downloads/youtube-64', train_epoch=10000)
[INFO 2017-06-26 21:41:19,010 main.py:47] epoch 0, training loss: 148093.86, average training loss: 148093.86, base loss: 3830.87
[INFO 2017-06-26 21:41:19,329 main.py:47] epoch 1, training loss: 115820.11, average training loss: 131956.98, base loss: 4267.04
[INFO 2017-06-26 21:41:19,648 main.py:47] epoch 2, training loss: 95462.02, average training loss: 119792.00, base loss: 4330.64
[INFO 2017-06-26 21:41:19,962 main.py:47] epoch 3, training loss: 83514.88, average training loss: 110722.72, base loss: 4469.42
[INFO 2017-06-26 21:41:20,284 main.py:47] epoch 4, training loss: 70220.08, average training loss: 102622.19, base loss: 4509.36
[INFO 2017-06-26 21:41:20,598 main.py:47] epoch 5, training loss: 64551.43, average training loss: 96277.06, base loss: 4425.63
[INFO 2017-06-26 21:41:20,914 main.py:47] epoch 6, training loss: 51473.10, average training loss: 89876.50, base loss: 4323.14
[INFO 2017-06-26 21:41:21,227 main.py:47] epoch 7, training loss: 45485.06, average training loss: 84327.57, base loss: 4325.63
[INFO 2017-06-26 21:41:21,535 main.py:47] epoch 8, training loss: 39845.59, average training loss: 79385.13, base loss: 4378.76
[INFO 2017-06-26 21:41:21,842 main.py:47] epoch 9, training loss: 34024.21, average training loss: 74849.04, base loss: 4450.70
[INFO 2017-06-26 21:41:22,148 main.py:47] epoch 10, training loss: 30172.11, average training loss: 70787.50, base loss: 4396.61
[INFO 2017-06-26 21:41:22,462 main.py:47] epoch 11, training loss: 25745.32, average training loss: 67033.98, base loss: 4429.23
[INFO 2017-06-26 21:41:22,775 main.py:47] epoch 12, training loss: 22202.69, average training loss: 63585.42, base loss: 4399.35
[INFO 2017-06-26 21:41:23,086 main.py:47] epoch 13, training loss: 20277.48, average training loss: 60492.00, base loss: 4430.73
[INFO 2017-06-26 21:41:23,402 main.py:47] epoch 14, training loss: 17668.55, average training loss: 57637.10, base loss: 4454.61
[INFO 2017-06-26 21:41:23,718 main.py:47] epoch 15, training loss: 15749.58, average training loss: 55019.13, base loss: 4433.46
[INFO 2017-06-26 21:41:24,032 main.py:47] epoch 16, training loss: 13900.12, average training loss: 52600.36, base loss: 4440.92
[INFO 2017-06-26 21:41:24,341 main.py:47] epoch 17, training loss: 12685.73, average training loss: 50382.88, base loss: 4477.50
[INFO 2017-06-26 21:41:24,652 main.py:47] epoch 18, training loss: 11212.30, average training loss: 48321.27, base loss: 4501.37
[INFO 2017-06-26 21:41:24,966 main.py:47] epoch 19, training loss: 10606.62, average training loss: 46435.54, base loss: 4508.42
[INFO 2017-06-26 21:41:25,271 main.py:47] epoch 20, training loss: 9117.80, average training loss: 44658.51, base loss: 4473.94
[INFO 2017-06-26 21:41:25,581 main.py:47] epoch 21, training loss: 8554.36, average training loss: 43017.41, base loss: 4471.99
[INFO 2017-06-26 21:41:25,902 main.py:47] epoch 22, training loss: 7426.96, average training loss: 41470.00, base loss: 4433.62
[INFO 2017-06-26 21:41:26,221 main.py:47] epoch 23, training loss: 7562.72, average training loss: 40057.19, base loss: 4438.06
[INFO 2017-06-26 21:41:26,529 main.py:47] epoch 24, training loss: 7666.88, average training loss: 38761.58, base loss: 4459.64
[INFO 2017-06-26 21:41:26,842 main.py:47] epoch 25, training loss: 7007.61, average training loss: 37540.28, base loss: 4462.17
[INFO 2017-06-26 21:41:27,151 main.py:47] epoch 26, training loss: 6533.58, average training loss: 36391.88, base loss: 4455.84
[INFO 2017-06-26 21:41:27,467 main.py:47] epoch 27, training loss: 6615.84, average training loss: 35328.45, base loss: 4472.49
[INFO 2017-06-26 21:41:27,774 main.py:47] epoch 28, training loss: 5588.57, average training loss: 34302.94, base loss: 4454.92
[INFO 2017-06-26 21:41:28,083 main.py:47] epoch 29, training loss: 5518.96, average training loss: 33343.47, base loss: 4440.72
[INFO 2017-06-26 21:41:28,392 main.py:47] epoch 30, training loss: 5837.66, average training loss: 32456.19, base loss: 4447.33
[INFO 2017-06-26 21:41:28,704 main.py:47] epoch 31, training loss: 5784.69, average training loss: 31622.70, base loss: 4454.30
[INFO 2017-06-26 21:41:29,013 main.py:47] epoch 32, training loss: 5111.42, average training loss: 30819.33, base loss: 4447.12
[INFO 2017-06-26 21:41:29,348 main.py:47] epoch 33, training loss: 5107.69, average training loss: 30063.10, base loss: 4440.86
[INFO 2017-06-26 21:41:29,657 main.py:47] epoch 34, training loss: 5354.41, average training loss: 29357.14, base loss: 4445.48
[INFO 2017-06-26 21:41:29,964 main.py:47] epoch 35, training loss: 4767.96, average training loss: 28674.11, base loss: 4436.09
[INFO 2017-06-26 21:41:30,274 main.py:47] epoch 36, training loss: 4212.78, average training loss: 28012.99, base loss: 4414.60
[INFO 2017-06-26 21:41:30,582 main.py:47] epoch 37, training loss: 4967.94, average training loss: 27406.54, base loss: 4411.75
[INFO 2017-06-26 21:41:30,904 main.py:47] epoch 38, training loss: 5558.76, average training loss: 26846.34, base loss: 4428.92
[INFO 2017-06-26 21:41:31,219 main.py:47] epoch 39, training loss: 4686.02, average training loss: 26292.34, base loss: 4424.41
[INFO 2017-06-26 21:41:31,528 main.py:47] epoch 40, training loss: 4555.95, average training loss: 25762.18, base loss: 4416.11
[INFO 2017-06-26 21:41:31,840 main.py:47] epoch 41, training loss: 5457.54, average training loss: 25278.74, base loss: 4431.03
[INFO 2017-06-26 21:41:32,147 main.py:47] epoch 42, training loss: 5262.65, average training loss: 24813.25, base loss: 4441.74
[INFO 2017-06-26 21:41:32,455 main.py:47] epoch 43, training loss: 4538.35, average training loss: 24352.45, base loss: 4434.67
[INFO 2017-06-26 21:41:32,772 main.py:47] epoch 44, training loss: 4564.39, average training loss: 23912.72, base loss: 4430.58
[INFO 2017-06-26 21:41:33,088 main.py:47] epoch 45, training loss: 4749.02, average training loss: 23496.12, base loss: 4430.21
[INFO 2017-06-26 21:41:33,401 main.py:47] epoch 46, training loss: 5557.77, average training loss: 23114.45, base loss: 4447.76
[INFO 2017-06-26 21:41:33,705 main.py:47] epoch 47, training loss: 4831.83, average training loss: 22733.56, base loss: 4449.89
[INFO 2017-06-26 21:41:34,009 main.py:47] epoch 48, training loss: 4859.48, average training loss: 22368.78, base loss: 4452.08
[INFO 2017-06-26 21:41:34,315 main.py:47] epoch 49, training loss: 4214.31, average training loss: 22005.69, base loss: 4440.57
[INFO 2017-06-26 21:41:34,630 main.py:47] epoch 50, training loss: 4497.50, average training loss: 21662.40, base loss: 4435.88
[INFO 2017-06-26 21:41:34,949 main.py:47] epoch 51, training loss: 4589.51, average training loss: 21334.07, base loss: 4434.22
[INFO 2017-06-26 21:41:35,264 main.py:47] epoch 52, training loss: 7821.78, average training loss: 21079.12, base loss: 4493.42
[INFO 2017-06-26 21:41:35,578 main.py:47] epoch 53, training loss: 4664.70, average training loss: 20775.15, base loss: 4491.63
[INFO 2017-06-26 21:41:35,887 main.py:47] epoch 54, training loss: 4344.54, average training loss: 20476.41, base loss: 4484.72
[INFO 2017-06-26 21:41:36,206 main.py:47] epoch 55, training loss: 4743.65, average training loss: 20195.47, base loss: 4485.17
[INFO 2017-06-26 21:41:36,515 main.py:47] epoch 56, training loss: 4469.71, average training loss: 19919.58, base loss: 4480.91
[INFO 2017-06-26 21:41:36,822 main.py:47] epoch 57, training loss: 4668.84, average training loss: 19656.64, base loss: 4480.54
[INFO 2017-06-26 21:41:37,127 main.py:47] epoch 58, training loss: 4222.55, average training loss: 19395.04, base loss: 4472.54
[INFO 2017-06-26 21:41:37,436 main.py:47] epoch 59, training loss: 4621.20, average training loss: 19148.81, base loss: 4471.78
[INFO 2017-06-26 21:41:37,745 main.py:47] epoch 60, training loss: 4382.36, average training loss: 18906.74, base loss: 4466.86
[INFO 2017-06-26 21:41:38,056 main.py:47] epoch 61, training loss: 4189.70, average training loss: 18669.37, base loss: 4458.94
[INFO 2017-06-26 21:41:38,377 main.py:47] epoch 62, training loss: 8001.03, average training loss: 18500.03, base loss: 4512.44
[INFO 2017-06-26 21:41:38,684 main.py:47] epoch 63, training loss: 4463.99, average training loss: 18280.72, base loss: 4508.62
[INFO 2017-06-26 21:41:38,990 main.py:47] epoch 64, training loss: 4417.29, average training loss: 18067.43, base loss: 4504.52
[INFO 2017-06-26 21:41:39,300 main.py:47] epoch 65, training loss: 4740.11, average training loss: 17865.50, base loss: 4505.19
[INFO 2017-06-26 21:41:39,610 main.py:47] epoch 66, training loss: 4390.66, average training loss: 17664.39, base loss: 4500.70
[INFO 2017-06-26 21:41:39,924 main.py:47] epoch 67, training loss: 4901.45, average training loss: 17476.70, base loss: 4504.46
[INFO 2017-06-26 21:41:40,233 main.py:47] epoch 68, training loss: 4849.49, average training loss: 17293.69, base loss: 4507.52
[INFO 2017-06-26 21:41:40,539 main.py:47] epoch 69, training loss: 4448.92, average training loss: 17110.20, base loss: 4504.12
[INFO 2017-06-26 21:41:40,852 main.py:47] epoch 70, training loss: 5213.93, average training loss: 16942.64, base loss: 4512.24
[INFO 2017-06-26 21:41:41,166 main.py:47] epoch 71, training loss: 4119.22, average training loss: 16764.54, base loss: 4504.34
[INFO 2017-06-26 21:41:41,480 main.py:47] epoch 72, training loss: 4220.73, average training loss: 16592.71, base loss: 4498.00
[INFO 2017-06-26 21:41:41,788 main.py:47] epoch 73, training loss: 4654.46, average training loss: 16431.38, base loss: 4497.95
[INFO 2017-06-26 21:41:42,098 main.py:47] epoch 74, training loss: 4711.07, average training loss: 16275.11, base loss: 4498.81
[INFO 2017-06-26 21:41:42,407 main.py:47] epoch 75, training loss: 5055.87, average training loss: 16127.49, base loss: 4504.70
[INFO 2017-06-26 21:41:42,721 main.py:47] epoch 76, training loss: 4914.47, average training loss: 15981.86, base loss: 4508.85
[INFO 2017-06-26 21:41:43,030 main.py:47] epoch 77, training loss: 4507.92, average training loss: 15834.76, base loss: 4507.34
[INFO 2017-06-26 21:41:43,347 main.py:47] epoch 78, training loss: 4394.49, average training loss: 15689.95, base loss: 4504.07
[INFO 2017-06-26 21:41:43,654 main.py:47] epoch 79, training loss: 5000.86, average training loss: 15556.33, base loss: 4508.93
[INFO 2017-06-26 21:41:43,958 main.py:47] epoch 80, training loss: 4525.80, average training loss: 15420.15, base loss: 4507.56
[INFO 2017-06-26 21:41:44,268 main.py:47] epoch 81, training loss: 5103.47, average training loss: 15294.34, base loss: 4513.88
[INFO 2017-06-26 21:41:44,575 main.py:47] epoch 82, training loss: 5018.08, average training loss: 15170.53, base loss: 4519.02
[INFO 2017-06-26 21:41:44,893 main.py:47] epoch 83, training loss: 4386.24, average training loss: 15042.15, base loss: 4516.10
[INFO 2017-06-26 21:41:45,205 main.py:47] epoch 84, training loss: 4598.26, average training loss: 14919.28, base loss: 4516.13
[INFO 2017-06-26 21:41:45,513 main.py:47] epoch 85, training loss: 4418.47, average training loss: 14797.17, base loss: 4513.78
[INFO 2017-06-26 21:41:45,821 main.py:47] epoch 86, training loss: 4049.41, average training loss: 14673.64, base loss: 4507.29
[INFO 2017-06-26 21:41:46,129 main.py:47] epoch 87, training loss: 4510.49, average training loss: 14558.15, base loss: 4506.33
[INFO 2017-06-26 21:41:46,445 main.py:47] epoch 88, training loss: 4618.72, average training loss: 14446.47, base loss: 4506.96
[INFO 2017-06-26 21:41:46,770 main.py:47] epoch 89, training loss: 4025.03, average training loss: 14330.67, base loss: 4500.51
[INFO 2017-06-26 21:41:47,094 main.py:47] epoch 90, training loss: 4264.89, average training loss: 14220.06, base loss: 4496.66
[INFO 2017-06-26 21:41:47,418 main.py:47] epoch 91, training loss: 4380.43, average training loss: 14113.11, base loss: 4494.13
[INFO 2017-06-26 21:41:47,736 main.py:47] epoch 92, training loss: 4458.54, average training loss: 14009.30, base loss: 4492.86
[INFO 2017-06-26 21:41:48,059 main.py:47] epoch 93, training loss: 5288.72, average training loss: 13916.52, base loss: 4501.36
[INFO 2017-06-26 21:41:48,388 main.py:47] epoch 94, training loss: 4797.22, average training loss: 13820.53, base loss: 4504.04
[INFO 2017-06-26 21:41:48,713 main.py:47] epoch 95, training loss: 4853.61, average training loss: 13727.13, base loss: 4507.28
[INFO 2017-06-26 21:41:49,040 main.py:47] epoch 96, training loss: 4953.94, average training loss: 13636.68, base loss: 4511.73
[INFO 2017-06-26 21:41:49,371 main.py:47] epoch 97, training loss: 4947.07, average training loss: 13548.01, base loss: 4516.35
[INFO 2017-06-26 21:41:49,700 main.py:47] epoch 98, training loss: 8017.92, average training loss: 13492.15, base loss: 4550.61
[INFO 2017-06-26 21:41:50,031 main.py:47] epoch 99, training loss: 4310.84, average training loss: 13400.34, base loss: 4548.00
[INFO 2017-06-26 21:41:50,031 main.py:49] epoch 99, testing
[INFO 2017-06-26 21:41:51,374 main.py:101] average testing loss: 4931.77, base loss: 4919.75, improve_loss: -12.02
[INFO 2017-06-26 21:41:51,375 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:41:51,387 main.py:73] current best improved loss: -12.02
[INFO 2017-06-26 21:41:51,720 main.py:47] epoch 100, training loss: 4514.63, average training loss: 13312.36, base loss: 4547.71
[INFO 2017-06-26 21:41:52,059 main.py:47] epoch 101, training loss: 4429.47, average training loss: 13225.27, base loss: 4546.31
[INFO 2017-06-26 21:41:52,398 main.py:47] epoch 102, training loss: 4983.39, average training loss: 13145.26, base loss: 4551.15
[INFO 2017-06-26 21:41:52,739 main.py:47] epoch 103, training loss: 3972.53, average training loss: 13057.06, base loss: 4545.18
[INFO 2017-06-26 21:41:53,078 main.py:47] epoch 104, training loss: 4005.89, average training loss: 12970.85, base loss: 4539.50
[INFO 2017-06-26 21:41:53,421 main.py:47] epoch 105, training loss: 4089.53, average training loss: 12887.07, base loss: 4535.33
[INFO 2017-06-26 21:41:53,757 main.py:47] epoch 106, training loss: 3820.10, average training loss: 12802.33, base loss: 4528.18
[INFO 2017-06-26 21:41:54,092 main.py:47] epoch 107, training loss: 5092.95, average training loss: 12730.95, base loss: 4534.26
[INFO 2017-06-26 21:41:54,442 main.py:47] epoch 108, training loss: 4802.92, average training loss: 12658.21, base loss: 4537.06
[INFO 2017-06-26 21:41:54,794 main.py:47] epoch 109, training loss: 4598.53, average training loss: 12584.94, base loss: 4537.95
[INFO 2017-06-26 21:41:55,145 main.py:47] epoch 110, training loss: 5437.38, average training loss: 12520.55, base loss: 4546.63
[INFO 2017-06-26 21:41:55,497 main.py:47] epoch 111, training loss: 4801.30, average training loss: 12451.63, base loss: 4550.51
[INFO 2017-06-26 21:41:55,850 main.py:47] epoch 112, training loss: 3929.35, average training loss: 12376.21, base loss: 4544.33
[INFO 2017-06-26 21:41:56,211 main.py:47] epoch 113, training loss: 4352.81, average training loss: 12305.83, base loss: 4542.91
[INFO 2017-06-26 21:41:56,580 main.py:47] epoch 114, training loss: 3960.45, average training loss: 12233.26, base loss: 4537.65
[INFO 2017-06-26 21:41:56,946 main.py:47] epoch 115, training loss: 4102.29, average training loss: 12163.17, base loss: 4534.24
[INFO 2017-06-26 21:41:57,303 main.py:47] epoch 116, training loss: 4447.62, average training loss: 12097.22, base loss: 4533.42
[INFO 2017-06-26 21:41:57,664 main.py:47] epoch 117, training loss: 4193.45, average training loss: 12030.24, base loss: 4530.94
[INFO 2017-06-26 21:41:58,027 main.py:47] epoch 118, training loss: 3759.86, average training loss: 11960.74, base loss: 4524.58
[INFO 2017-06-26 21:41:58,391 main.py:47] epoch 119, training loss: 4354.09, average training loss: 11897.35, base loss: 4523.39
[INFO 2017-06-26 21:41:58,762 main.py:47] epoch 120, training loss: 4251.03, average training loss: 11834.16, base loss: 4521.69
[INFO 2017-06-26 21:41:59,139 main.py:47] epoch 121, training loss: 4254.51, average training loss: 11772.03, base loss: 4519.83
[INFO 2017-06-26 21:41:59,525 main.py:47] epoch 122, training loss: 4282.77, average training loss: 11711.14, base loss: 4518.77
[INFO 2017-06-26 21:41:59,909 main.py:47] epoch 123, training loss: 8051.24, average training loss: 11681.63, base loss: 4547.62
[INFO 2017-06-26 21:42:00,294 main.py:47] epoch 124, training loss: 4669.99, average training loss: 11625.54, base loss: 4549.52
[INFO 2017-06-26 21:42:00,673 main.py:47] epoch 125, training loss: 4627.86, average training loss: 11570.00, base loss: 4549.02
[INFO 2017-06-26 21:42:01,057 main.py:47] epoch 126, training loss: 4598.29, average training loss: 11515.10, base loss: 4550.89
[INFO 2017-06-26 21:42:01,442 main.py:47] epoch 127, training loss: 3976.53, average training loss: 11456.21, base loss: 4546.68
[INFO 2017-06-26 21:42:01,827 main.py:47] epoch 128, training loss: 4822.46, average training loss: 11404.78, base loss: 4550.06
[INFO 2017-06-26 21:42:02,207 main.py:47] epoch 129, training loss: 4913.91, average training loss: 11354.85, base loss: 4554.50
[INFO 2017-06-26 21:42:02,586 main.py:47] epoch 130, training loss: 4495.91, average training loss: 11302.50, base loss: 4555.53
[INFO 2017-06-26 21:42:02,966 main.py:47] epoch 131, training loss: 3997.62, average training loss: 11247.16, base loss: 4551.93
[INFO 2017-06-26 21:42:03,346 main.py:47] epoch 132, training loss: 4829.21, average training loss: 11198.90, base loss: 4554.82
[INFO 2017-06-26 21:42:03,725 main.py:47] epoch 133, training loss: 3895.26, average training loss: 11144.40, base loss: 4549.68
[INFO 2017-06-26 21:42:04,103 main.py:47] epoch 134, training loss: 3991.45, average training loss: 11091.41, base loss: 4545.47
[INFO 2017-06-26 21:42:04,486 main.py:47] epoch 135, training loss: 4136.94, average training loss: 11040.27, base loss: 4543.24
[INFO 2017-06-26 21:42:04,869 main.py:47] epoch 136, training loss: 3867.25, average training loss: 10987.92, base loss: 4538.55
[INFO 2017-06-26 21:42:05,255 main.py:47] epoch 137, training loss: 5296.49, average training loss: 10946.67, base loss: 4545.57
[INFO 2017-06-26 21:42:05,636 main.py:47] epoch 138, training loss: 4397.49, average training loss: 10899.56, base loss: 4544.75
[INFO 2017-06-26 21:42:06,017 main.py:47] epoch 139, training loss: 4568.77, average training loss: 10854.34, base loss: 4545.30
[INFO 2017-06-26 21:42:06,397 main.py:47] epoch 140, training loss: 4220.39, average training loss: 10807.29, base loss: 4544.08
[INFO 2017-06-26 21:42:06,783 main.py:47] epoch 141, training loss: 4276.54, average training loss: 10761.30, base loss: 4542.70
[INFO 2017-06-26 21:42:07,168 main.py:47] epoch 142, training loss: 3867.84, average training loss: 10713.09, base loss: 4538.30
[INFO 2017-06-26 21:42:07,551 main.py:47] epoch 143, training loss: 4560.39, average training loss: 10670.36, base loss: 4539.44
[INFO 2017-06-26 21:42:07,934 main.py:47] epoch 144, training loss: 3765.45, average training loss: 10622.74, base loss: 4533.78
[INFO 2017-06-26 21:42:08,312 main.py:47] epoch 145, training loss: 4335.05, average training loss: 10579.68, base loss: 4533.34
[INFO 2017-06-26 21:42:08,691 main.py:47] epoch 146, training loss: 5207.36, average training loss: 10543.13, base loss: 4539.46
[INFO 2017-06-26 21:42:09,071 main.py:47] epoch 147, training loss: 3820.62, average training loss: 10497.71, base loss: 4534.81
[INFO 2017-06-26 21:42:09,457 main.py:47] epoch 148, training loss: 4050.34, average training loss: 10454.44, base loss: 4532.21
[INFO 2017-06-26 21:42:09,836 main.py:47] epoch 149, training loss: 3605.69, average training loss: 10408.78, base loss: 4526.27
[INFO 2017-06-26 21:42:10,231 main.py:47] epoch 150, training loss: 4133.30, average training loss: 10367.22, base loss: 4524.45
[INFO 2017-06-26 21:42:10,616 main.py:47] epoch 151, training loss: 4279.87, average training loss: 10327.17, base loss: 4524.07
[INFO 2017-06-26 21:42:11,000 main.py:47] epoch 152, training loss: 3744.42, average training loss: 10284.15, base loss: 4519.61
[INFO 2017-06-26 21:42:11,385 main.py:47] epoch 153, training loss: 4601.53, average training loss: 10247.25, base loss: 4521.31
[INFO 2017-06-26 21:42:11,790 main.py:47] epoch 154, training loss: 4015.39, average training loss: 10207.04, base loss: 4518.30
[INFO 2017-06-26 21:42:12,174 main.py:47] epoch 155, training loss: 4017.48, average training loss: 10167.37, base loss: 4515.52
[INFO 2017-06-26 21:42:12,553 main.py:47] epoch 156, training loss: 4051.44, average training loss: 10128.41, base loss: 4513.24
[INFO 2017-06-26 21:42:12,932 main.py:47] epoch 157, training loss: 4154.70, average training loss: 10090.60, base loss: 4512.14
[INFO 2017-06-26 21:42:13,311 main.py:47] epoch 158, training loss: 4384.21, average training loss: 10054.71, base loss: 4512.45
[INFO 2017-06-26 21:42:13,699 main.py:47] epoch 159, training loss: 7379.37, average training loss: 10037.99, base loss: 4530.96
[INFO 2017-06-26 21:42:14,080 main.py:47] epoch 160, training loss: 3461.19, average training loss: 9997.14, base loss: 4523.61
[INFO 2017-06-26 21:42:14,459 main.py:47] epoch 161, training loss: 4349.24, average training loss: 9962.28, base loss: 4523.09
[INFO 2017-06-26 21:42:14,844 main.py:47] epoch 162, training loss: 4343.54, average training loss: 9927.81, base loss: 4523.43
[INFO 2017-06-26 21:42:15,222 main.py:47] epoch 163, training loss: 4380.35, average training loss: 9893.98, base loss: 4523.65
[INFO 2017-06-26 21:42:15,601 main.py:47] epoch 164, training loss: 4295.63, average training loss: 9860.05, base loss: 4523.24
[INFO 2017-06-26 21:42:15,980 main.py:47] epoch 165, training loss: 3914.78, average training loss: 9824.24, base loss: 4520.35
[INFO 2017-06-26 21:42:16,359 main.py:47] epoch 166, training loss: 4697.56, average training loss: 9793.54, base loss: 4522.95
[INFO 2017-06-26 21:42:16,737 main.py:47] epoch 167, training loss: 5116.51, average training loss: 9765.70, base loss: 4526.89
[INFO 2017-06-26 21:42:17,117 main.py:47] epoch 168, training loss: 4602.20, average training loss: 9735.15, base loss: 4528.66
[INFO 2017-06-26 21:42:17,500 main.py:47] epoch 169, training loss: 4293.74, average training loss: 9703.14, base loss: 4528.56
[INFO 2017-06-26 21:42:17,879 main.py:47] epoch 170, training loss: 4374.02, average training loss: 9671.97, base loss: 4528.88
[INFO 2017-06-26 21:42:18,259 main.py:47] epoch 171, training loss: 7799.98, average training loss: 9661.09, base loss: 4548.25
[INFO 2017-06-26 21:42:18,644 main.py:47] epoch 172, training loss: 4006.11, average training loss: 9628.40, base loss: 4545.91
[INFO 2017-06-26 21:42:19,024 main.py:47] epoch 173, training loss: 4492.56, average training loss: 9598.89, base loss: 4546.17
[INFO 2017-06-26 21:42:19,410 main.py:47] epoch 174, training loss: 4501.24, average training loss: 9569.76, base loss: 4547.60
[INFO 2017-06-26 21:42:19,794 main.py:47] epoch 175, training loss: 5005.05, average training loss: 9543.82, base loss: 4551.41
[INFO 2017-06-26 21:42:20,182 main.py:47] epoch 176, training loss: 4526.39, average training loss: 9515.47, base loss: 4552.14
[INFO 2017-06-26 21:42:20,562 main.py:47] epoch 177, training loss: 3904.73, average training loss: 9483.95, base loss: 4549.17
[INFO 2017-06-26 21:42:20,946 main.py:47] epoch 178, training loss: 3884.01, average training loss: 9452.67, base loss: 4545.73
[INFO 2017-06-26 21:42:21,331 main.py:47] epoch 179, training loss: 3616.10, average training loss: 9420.24, base loss: 4541.01
[INFO 2017-06-26 21:42:21,720 main.py:47] epoch 180, training loss: 4193.17, average training loss: 9391.36, base loss: 4540.20
[INFO 2017-06-26 21:42:22,107 main.py:47] epoch 181, training loss: 4524.15, average training loss: 9364.62, base loss: 4541.21
[INFO 2017-06-26 21:42:22,491 main.py:47] epoch 182, training loss: 4646.41, average training loss: 9338.84, base loss: 4542.93
[INFO 2017-06-26 21:42:22,876 main.py:47] epoch 183, training loss: 3762.22, average training loss: 9308.53, base loss: 4539.55
[INFO 2017-06-26 21:42:23,264 main.py:47] epoch 184, training loss: 7722.27, average training loss: 9299.96, base loss: 4557.42
[INFO 2017-06-26 21:42:23,648 main.py:47] epoch 185, training loss: 4137.21, average training loss: 9272.20, base loss: 4555.97
[INFO 2017-06-26 21:42:24,031 main.py:47] epoch 186, training loss: 4886.54, average training loss: 9248.75, base loss: 4559.71
[INFO 2017-06-26 21:42:24,417 main.py:47] epoch 187, training loss: 4434.71, average training loss: 9223.14, base loss: 4560.42
[INFO 2017-06-26 21:42:24,802 main.py:47] epoch 188, training loss: 4112.06, average training loss: 9196.10, base loss: 4559.52
[INFO 2017-06-26 21:42:25,190 main.py:47] epoch 189, training loss: 8529.63, average training loss: 9192.59, base loss: 4581.77
[INFO 2017-06-26 21:42:25,577 main.py:47] epoch 190, training loss: 3698.56, average training loss: 9163.83, base loss: 4577.67
[INFO 2017-06-26 21:42:25,962 main.py:47] epoch 191, training loss: 3971.24, average training loss: 9136.78, base loss: 4575.01
[INFO 2017-06-26 21:42:26,346 main.py:47] epoch 192, training loss: 3974.78, average training loss: 9110.03, base loss: 4572.54
[INFO 2017-06-26 21:42:26,731 main.py:47] epoch 193, training loss: 4206.41, average training loss: 9084.76, base loss: 4571.37
[INFO 2017-06-26 21:42:27,115 main.py:47] epoch 194, training loss: 4274.52, average training loss: 9060.09, base loss: 4570.44
[INFO 2017-06-26 21:42:27,501 main.py:47] epoch 195, training loss: 4080.85, average training loss: 9034.69, base loss: 4568.83
[INFO 2017-06-26 21:42:27,892 main.py:47] epoch 196, training loss: 3725.19, average training loss: 9007.73, base loss: 4564.98
[INFO 2017-06-26 21:42:28,277 main.py:47] epoch 197, training loss: 3978.14, average training loss: 8982.33, base loss: 4562.99
[INFO 2017-06-26 21:42:28,669 main.py:47] epoch 198, training loss: 4707.05, average training loss: 8960.85, base loss: 4565.33
[INFO 2017-06-26 21:42:29,052 main.py:47] epoch 199, training loss: 4296.18, average training loss: 8937.52, base loss: 4564.94
[INFO 2017-06-26 21:42:29,053 main.py:49] epoch 199, testing
[INFO 2017-06-26 21:42:30,545 main.py:101] average testing loss: 4390.72, base loss: 4598.84, improve_loss: 208.12
[INFO 2017-06-26 21:42:30,546 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:42:30,558 main.py:73] current best improved loss: 208.12
[INFO 2017-06-26 21:42:30,941 main.py:47] epoch 200, training loss: 4529.36, average training loss: 8915.59, base loss: 4565.88
[INFO 2017-06-26 21:42:31,326 main.py:47] epoch 201, training loss: 3278.85, average training loss: 8887.69, base loss: 4559.45
[INFO 2017-06-26 21:42:31,706 main.py:47] epoch 202, training loss: 3566.86, average training loss: 8861.48, base loss: 4554.88
[INFO 2017-06-26 21:42:32,087 main.py:47] epoch 203, training loss: 4469.05, average training loss: 8839.95, base loss: 4555.72
[INFO 2017-06-26 21:42:32,467 main.py:47] epoch 204, training loss: 4796.41, average training loss: 8820.22, base loss: 4558.18
[INFO 2017-06-26 21:42:32,858 main.py:47] epoch 205, training loss: 5186.22, average training loss: 8802.58, base loss: 4562.68
[INFO 2017-06-26 21:42:33,243 main.py:47] epoch 206, training loss: 3874.77, average training loss: 8778.78, base loss: 4560.36
[INFO 2017-06-26 21:42:33,623 main.py:47] epoch 207, training loss: 4183.88, average training loss: 8756.68, base loss: 4559.25
[INFO 2017-06-26 21:42:34,009 main.py:47] epoch 208, training loss: 4454.70, average training loss: 8736.10, base loss: 4560.61
[INFO 2017-06-26 21:42:34,391 main.py:47] epoch 209, training loss: 3904.07, average training loss: 8713.09, base loss: 4558.34
[INFO 2017-06-26 21:42:34,773 main.py:47] epoch 210, training loss: 3746.57, average training loss: 8689.55, base loss: 4555.22
[INFO 2017-06-26 21:42:35,152 main.py:47] epoch 211, training loss: 4250.12, average training loss: 8668.61, base loss: 4555.06
[INFO 2017-06-26 21:42:35,538 main.py:47] epoch 212, training loss: 4348.26, average training loss: 8648.33, base loss: 4554.75
[INFO 2017-06-26 21:42:35,922 main.py:47] epoch 213, training loss: 3911.11, average training loss: 8626.19, base loss: 4552.66
[INFO 2017-06-26 21:42:36,303 main.py:47] epoch 214, training loss: 3818.57, average training loss: 8603.83, base loss: 4550.12
[INFO 2017-06-26 21:42:36,688 main.py:47] epoch 215, training loss: 4064.12, average training loss: 8582.81, base loss: 4549.04
[INFO 2017-06-26 21:42:37,071 main.py:47] epoch 216, training loss: 4910.95, average training loss: 8565.89, base loss: 4551.52
[INFO 2017-06-26 21:42:37,454 main.py:47] epoch 217, training loss: 7567.76, average training loss: 8561.31, base loss: 4565.86
[INFO 2017-06-26 21:42:37,840 main.py:47] epoch 218, training loss: 4255.23, average training loss: 8541.65, base loss: 4565.77
[INFO 2017-06-26 21:42:38,224 main.py:47] epoch 219, training loss: 4110.64, average training loss: 8521.51, base loss: 4564.72
[INFO 2017-06-26 21:42:38,606 main.py:47] epoch 220, training loss: 4382.20, average training loss: 8502.78, base loss: 4565.10
[INFO 2017-06-26 21:42:38,991 main.py:47] epoch 221, training loss: 4144.92, average training loss: 8483.15, base loss: 4564.24
[INFO 2017-06-26 21:42:39,379 main.py:47] epoch 222, training loss: 3963.40, average training loss: 8462.88, base loss: 4562.52
[INFO 2017-06-26 21:42:39,759 main.py:47] epoch 223, training loss: 3936.71, average training loss: 8442.68, base loss: 4560.72
[INFO 2017-06-26 21:42:40,139 main.py:47] epoch 224, training loss: 4083.48, average training loss: 8423.30, base loss: 4559.85
[INFO 2017-06-26 21:42:40,518 main.py:47] epoch 225, training loss: 3842.74, average training loss: 8403.03, base loss: 4557.15
[INFO 2017-06-26 21:42:40,902 main.py:47] epoch 226, training loss: 4304.40, average training loss: 8384.98, base loss: 4557.08
[INFO 2017-06-26 21:42:41,286 main.py:47] epoch 227, training loss: 4070.17, average training loss: 8366.05, base loss: 4556.15
[INFO 2017-06-26 21:42:41,665 main.py:47] epoch 228, training loss: 4605.58, average training loss: 8349.63, base loss: 4557.40
[INFO 2017-06-26 21:42:42,049 main.py:47] epoch 229, training loss: 4159.71, average training loss: 8331.42, base loss: 4556.49
[INFO 2017-06-26 21:42:42,438 main.py:47] epoch 230, training loss: 3890.07, average training loss: 8312.19, base loss: 4554.41
[INFO 2017-06-26 21:42:42,824 main.py:47] epoch 231, training loss: 4750.21, average training loss: 8296.84, base loss: 4556.70
[INFO 2017-06-26 21:42:43,210 main.py:47] epoch 232, training loss: 4408.71, average training loss: 8280.15, base loss: 4557.94
[INFO 2017-06-26 21:42:43,594 main.py:47] epoch 233, training loss: 3949.16, average training loss: 8261.64, base loss: 4556.27
[INFO 2017-06-26 21:42:43,978 main.py:47] epoch 234, training loss: 4052.85, average training loss: 8243.73, base loss: 4554.67
[INFO 2017-06-26 21:42:44,362 main.py:47] epoch 235, training loss: 4080.69, average training loss: 8226.09, base loss: 4553.66
[INFO 2017-06-26 21:42:44,748 main.py:47] epoch 236, training loss: 4269.18, average training loss: 8209.39, base loss: 4553.50
[INFO 2017-06-26 21:42:45,133 main.py:47] epoch 237, training loss: 3943.61, average training loss: 8191.47, base loss: 4551.86
[INFO 2017-06-26 21:42:45,517 main.py:47] epoch 238, training loss: 4893.53, average training loss: 8177.67, base loss: 4554.84
[INFO 2017-06-26 21:42:45,903 main.py:47] epoch 239, training loss: 3832.59, average training loss: 8159.57, base loss: 4552.74
[INFO 2017-06-26 21:42:46,287 main.py:47] epoch 240, training loss: 4346.80, average training loss: 8143.75, base loss: 4553.07
[INFO 2017-06-26 21:42:46,673 main.py:47] epoch 241, training loss: 4022.39, average training loss: 8126.72, base loss: 4552.03
[INFO 2017-06-26 21:42:47,057 main.py:47] epoch 242, training loss: 4625.03, average training loss: 8112.31, base loss: 4553.68
[INFO 2017-06-26 21:42:47,443 main.py:47] epoch 243, training loss: 4667.53, average training loss: 8098.19, base loss: 4555.21
[INFO 2017-06-26 21:42:47,823 main.py:47] epoch 244, training loss: 4476.04, average training loss: 8083.40, base loss: 4556.03
[INFO 2017-06-26 21:42:48,202 main.py:47] epoch 245, training loss: 3947.80, average training loss: 8066.59, base loss: 4554.98
[INFO 2017-06-26 21:42:48,589 main.py:47] epoch 246, training loss: 5350.81, average training loss: 8055.60, base loss: 4560.45
[INFO 2017-06-26 21:42:48,972 main.py:47] epoch 247, training loss: 3815.86, average training loss: 8038.50, base loss: 4558.50
[INFO 2017-06-26 21:42:49,357 main.py:47] epoch 248, training loss: 4455.24, average training loss: 8024.11, base loss: 4559.84
[INFO 2017-06-26 21:42:49,740 main.py:47] epoch 249, training loss: 5052.33, average training loss: 8012.22, base loss: 4564.06
[INFO 2017-06-26 21:42:50,124 main.py:47] epoch 250, training loss: 4436.43, average training loss: 7997.98, base loss: 4565.03
[INFO 2017-06-26 21:42:50,504 main.py:47] epoch 251, training loss: 3968.33, average training loss: 7981.99, base loss: 4563.32
[INFO 2017-06-26 21:42:50,888 main.py:47] epoch 252, training loss: 4007.30, average training loss: 7966.28, base loss: 4562.05
[INFO 2017-06-26 21:42:51,275 main.py:47] epoch 253, training loss: 4652.45, average training loss: 7953.23, base loss: 4563.92
[INFO 2017-06-26 21:42:51,659 main.py:47] epoch 254, training loss: 4006.57, average training loss: 7937.75, base loss: 4562.92
[INFO 2017-06-26 21:42:52,048 main.py:47] epoch 255, training loss: 4872.59, average training loss: 7925.78, base loss: 4565.64
[INFO 2017-06-26 21:42:52,433 main.py:47] epoch 256, training loss: 4306.48, average training loss: 7911.70, base loss: 4565.65
[INFO 2017-06-26 21:42:52,816 main.py:47] epoch 257, training loss: 3786.02, average training loss: 7895.71, base loss: 4563.61
[INFO 2017-06-26 21:42:53,202 main.py:47] epoch 258, training loss: 3946.06, average training loss: 7880.46, base loss: 4562.35
[INFO 2017-06-26 21:42:53,581 main.py:47] epoch 259, training loss: 4284.35, average training loss: 7866.63, base loss: 4562.13
[INFO 2017-06-26 21:42:53,967 main.py:47] epoch 260, training loss: 3959.43, average training loss: 7851.66, base loss: 4560.66
[INFO 2017-06-26 21:42:54,352 main.py:47] epoch 261, training loss: 4316.21, average training loss: 7838.16, base loss: 4561.09
[INFO 2017-06-26 21:42:54,739 main.py:47] epoch 262, training loss: 3480.38, average training loss: 7821.59, base loss: 4557.41
[INFO 2017-06-26 21:42:55,126 main.py:47] epoch 263, training loss: 4187.77, average training loss: 7807.83, base loss: 4556.94
[INFO 2017-06-26 21:42:55,519 main.py:47] epoch 264, training loss: 4016.21, average training loss: 7793.52, base loss: 4555.91
[INFO 2017-06-26 21:42:55,910 main.py:47] epoch 265, training loss: 4775.79, average training loss: 7782.17, base loss: 4558.62
[INFO 2017-06-26 21:42:56,291 main.py:47] epoch 266, training loss: 4455.83, average training loss: 7769.72, base loss: 4559.71
[INFO 2017-06-26 21:42:56,688 main.py:47] epoch 267, training loss: 4124.50, average training loss: 7756.12, base loss: 4559.23
[INFO 2017-06-26 21:42:57,079 main.py:47] epoch 268, training loss: 4306.78, average training loss: 7743.29, base loss: 4559.46
[INFO 2017-06-26 21:42:57,466 main.py:47] epoch 269, training loss: 4168.69, average training loss: 7730.05, base loss: 4559.60
[INFO 2017-06-26 21:42:57,845 main.py:47] epoch 270, training loss: 4237.27, average training loss: 7717.16, base loss: 4559.46
[INFO 2017-06-26 21:42:58,233 main.py:47] epoch 271, training loss: 4227.11, average training loss: 7704.33, base loss: 4559.44
[INFO 2017-06-26 21:42:58,621 main.py:47] epoch 272, training loss: 3843.47, average training loss: 7690.19, base loss: 4557.77
[INFO 2017-06-26 21:42:59,000 main.py:47] epoch 273, training loss: 4847.79, average training loss: 7679.82, base loss: 4560.06
[INFO 2017-06-26 21:42:59,384 main.py:47] epoch 274, training loss: 4020.06, average training loss: 7666.51, base loss: 4559.52
[INFO 2017-06-26 21:42:59,763 main.py:47] epoch 275, training loss: 4582.27, average training loss: 7655.33, base loss: 4559.89
[INFO 2017-06-26 21:43:00,145 main.py:47] epoch 276, training loss: 4043.27, average training loss: 7642.29, base loss: 4558.75
[INFO 2017-06-26 21:43:00,531 main.py:47] epoch 277, training loss: 3716.53, average training loss: 7628.17, base loss: 4556.23
[INFO 2017-06-26 21:43:00,916 main.py:47] epoch 278, training loss: 4407.10, average training loss: 7616.63, base loss: 4556.88
[INFO 2017-06-26 21:43:01,303 main.py:47] epoch 279, training loss: 3935.67, average training loss: 7603.48, base loss: 4555.49
[INFO 2017-06-26 21:43:01,688 main.py:47] epoch 280, training loss: 4049.59, average training loss: 7590.83, base loss: 4554.73
[INFO 2017-06-26 21:43:02,071 main.py:47] epoch 281, training loss: 4019.59, average training loss: 7578.17, base loss: 4553.21
[INFO 2017-06-26 21:43:02,451 main.py:47] epoch 282, training loss: 5243.80, average training loss: 7569.92, base loss: 4557.66
[INFO 2017-06-26 21:43:02,835 main.py:47] epoch 283, training loss: 4032.97, average training loss: 7557.47, base loss: 4556.73
[INFO 2017-06-26 21:43:03,220 main.py:47] epoch 284, training loss: 3975.84, average training loss: 7544.90, base loss: 4555.68
[INFO 2017-06-26 21:43:03,604 main.py:47] epoch 285, training loss: 4012.55, average training loss: 7532.55, base loss: 4554.95
[INFO 2017-06-26 21:43:03,985 main.py:47] epoch 286, training loss: 3846.98, average training loss: 7519.71, base loss: 4553.07
[INFO 2017-06-26 21:43:04,366 main.py:47] epoch 287, training loss: 3822.74, average training loss: 7506.87, base loss: 4551.61
[INFO 2017-06-26 21:43:04,754 main.py:47] epoch 288, training loss: 4749.15, average training loss: 7497.33, base loss: 4553.85
[INFO 2017-06-26 21:43:05,138 main.py:47] epoch 289, training loss: 4512.94, average training loss: 7487.04, base loss: 4554.89
[INFO 2017-06-26 21:43:05,523 main.py:47] epoch 290, training loss: 4331.60, average training loss: 7476.19, base loss: 4555.43
[INFO 2017-06-26 21:43:05,902 main.py:47] epoch 291, training loss: 4284.37, average training loss: 7465.26, base loss: 4555.93
[INFO 2017-06-26 21:43:06,287 main.py:47] epoch 292, training loss: 4152.08, average training loss: 7453.96, base loss: 4555.21
[INFO 2017-06-26 21:43:06,674 main.py:47] epoch 293, training loss: 4611.52, average training loss: 7444.29, base loss: 4556.90
[INFO 2017-06-26 21:43:07,062 main.py:47] epoch 294, training loss: 3914.43, average training loss: 7432.32, base loss: 4555.97
[INFO 2017-06-26 21:43:07,446 main.py:47] epoch 295, training loss: 3730.57, average training loss: 7419.82, base loss: 4554.20
[INFO 2017-06-26 21:43:07,826 main.py:47] epoch 296, training loss: 4117.82, average training loss: 7408.70, base loss: 4554.05
[INFO 2017-06-26 21:43:08,207 main.py:47] epoch 297, training loss: 3835.27, average training loss: 7396.71, base loss: 4552.68
[INFO 2017-06-26 21:43:08,590 main.py:47] epoch 298, training loss: 4458.87, average training loss: 7386.88, base loss: 4553.75
[INFO 2017-06-26 21:43:08,969 main.py:47] epoch 299, training loss: 4715.50, average training loss: 7377.98, base loss: 4555.69
[INFO 2017-06-26 21:43:08,970 main.py:49] epoch 299, testing
[INFO 2017-06-26 21:43:10,470 main.py:101] average testing loss: 4357.69, base loss: 4698.02, improve_loss: 340.32
[INFO 2017-06-26 21:43:10,470 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:43:10,483 main.py:73] current best improved loss: 340.32
[INFO 2017-06-26 21:43:10,865 main.py:47] epoch 300, training loss: 8002.17, average training loss: 7380.05, base loss: 4568.42
[INFO 2017-06-26 21:43:11,250 main.py:47] epoch 301, training loss: 3379.82, average training loss: 7366.80, base loss: 4565.11
[INFO 2017-06-26 21:43:11,637 main.py:47] epoch 302, training loss: 4597.62, average training loss: 7357.67, base loss: 4566.92
[INFO 2017-06-26 21:43:12,016 main.py:47] epoch 303, training loss: 4959.62, average training loss: 7349.78, base loss: 4569.86
[INFO 2017-06-26 21:43:12,402 main.py:47] epoch 304, training loss: 3870.67, average training loss: 7338.37, base loss: 4568.44
[INFO 2017-06-26 21:43:12,783 main.py:47] epoch 305, training loss: 4391.72, average training loss: 7328.74, base loss: 4569.13
[INFO 2017-06-26 21:43:13,166 main.py:47] epoch 306, training loss: 3814.84, average training loss: 7317.29, base loss: 4567.76
[INFO 2017-06-26 21:43:13,551 main.py:47] epoch 307, training loss: 3690.42, average training loss: 7305.52, base loss: 4565.32
[INFO 2017-06-26 21:43:13,939 main.py:47] epoch 308, training loss: 3254.83, average training loss: 7292.41, base loss: 4561.81
[INFO 2017-06-26 21:43:14,320 main.py:47] epoch 309, training loss: 4155.35, average training loss: 7282.29, base loss: 4561.86
[INFO 2017-06-26 21:43:14,705 main.py:47] epoch 310, training loss: 4242.82, average training loss: 7272.52, base loss: 4561.54
[INFO 2017-06-26 21:43:15,089 main.py:47] epoch 311, training loss: 4360.06, average training loss: 7263.18, base loss: 4561.73
[INFO 2017-06-26 21:43:15,472 main.py:47] epoch 312, training loss: 4360.73, average training loss: 7253.91, base loss: 4562.57
[INFO 2017-06-26 21:43:15,863 main.py:47] epoch 313, training loss: 4683.43, average training loss: 7245.72, base loss: 4564.75
[INFO 2017-06-26 21:43:16,247 main.py:47] epoch 314, training loss: 3496.24, average training loss: 7233.82, base loss: 4561.53
[INFO 2017-06-26 21:43:16,637 main.py:47] epoch 315, training loss: 4026.87, average training loss: 7223.67, base loss: 4560.87
[INFO 2017-06-26 21:43:17,021 main.py:47] epoch 316, training loss: 3643.50, average training loss: 7212.38, base loss: 4558.46
[INFO 2017-06-26 21:43:17,406 main.py:47] epoch 317, training loss: 4439.97, average training loss: 7203.66, base loss: 4559.56
[INFO 2017-06-26 21:43:17,793 main.py:47] epoch 318, training loss: 4605.96, average training loss: 7195.52, base loss: 4561.38
[INFO 2017-06-26 21:43:18,179 main.py:47] epoch 319, training loss: 4175.69, average training loss: 7186.08, base loss: 4561.68
[INFO 2017-06-26 21:43:18,563 main.py:47] epoch 320, training loss: 4146.22, average training loss: 7176.61, base loss: 4561.47
[INFO 2017-06-26 21:43:18,951 main.py:47] epoch 321, training loss: 3798.08, average training loss: 7166.12, base loss: 4559.62
[INFO 2017-06-26 21:43:19,334 main.py:47] epoch 322, training loss: 4123.18, average training loss: 7156.70, base loss: 4559.40
[INFO 2017-06-26 21:43:19,720 main.py:47] epoch 323, training loss: 3981.45, average training loss: 7146.90, base loss: 4558.10
[INFO 2017-06-26 21:43:20,105 main.py:47] epoch 324, training loss: 4617.69, average training loss: 7139.11, base loss: 4559.32
[INFO 2017-06-26 21:43:20,489 main.py:47] epoch 325, training loss: 3514.01, average training loss: 7127.99, base loss: 4557.02
[INFO 2017-06-26 21:43:20,873 main.py:47] epoch 326, training loss: 3725.24, average training loss: 7117.59, base loss: 4555.12
[INFO 2017-06-26 21:43:21,258 main.py:47] epoch 327, training loss: 3748.26, average training loss: 7107.32, base loss: 4553.67
[INFO 2017-06-26 21:43:21,644 main.py:47] epoch 328, training loss: 4143.25, average training loss: 7098.31, base loss: 4553.60
[INFO 2017-06-26 21:43:22,034 main.py:47] epoch 329, training loss: 4334.41, average training loss: 7089.93, base loss: 4554.11
[INFO 2017-06-26 21:43:22,420 main.py:47] epoch 330, training loss: 4041.69, average training loss: 7080.72, base loss: 4553.89
[INFO 2017-06-26 21:43:22,805 main.py:47] epoch 331, training loss: 4228.30, average training loss: 7072.13, base loss: 4554.32
[INFO 2017-06-26 21:43:23,184 main.py:47] epoch 332, training loss: 3538.95, average training loss: 7061.52, base loss: 4551.81
[INFO 2017-06-26 21:43:23,564 main.py:47] epoch 333, training loss: 3900.47, average training loss: 7052.06, base loss: 4550.62
[INFO 2017-06-26 21:43:23,944 main.py:47] epoch 334, training loss: 3806.81, average training loss: 7042.37, base loss: 4549.20
[INFO 2017-06-26 21:43:24,325 main.py:47] epoch 335, training loss: 3542.09, average training loss: 7031.95, base loss: 4546.91
[INFO 2017-06-26 21:43:24,710 main.py:47] epoch 336, training loss: 4069.97, average training loss: 7023.16, base loss: 4546.43
[INFO 2017-06-26 21:43:25,095 main.py:47] epoch 337, training loss: 4304.43, average training loss: 7015.12, base loss: 4546.94
[INFO 2017-06-26 21:43:25,482 main.py:47] epoch 338, training loss: 3729.44, average training loss: 7005.43, base loss: 4545.42
[INFO 2017-06-26 21:43:25,861 main.py:47] epoch 339, training loss: 4352.14, average training loss: 6997.62, base loss: 4546.17
[INFO 2017-06-26 21:43:26,246 main.py:47] epoch 340, training loss: 4233.02, average training loss: 6989.51, base loss: 4546.10
[INFO 2017-06-26 21:43:26,631 main.py:47] epoch 341, training loss: 4256.82, average training loss: 6981.52, base loss: 4546.39
[INFO 2017-06-26 21:43:27,016 main.py:47] epoch 342, training loss: 8065.52, average training loss: 6984.68, base loss: 4557.81
[INFO 2017-06-26 21:43:27,399 main.py:47] epoch 343, training loss: 4589.68, average training loss: 6977.72, base loss: 4559.49
[INFO 2017-06-26 21:43:27,783 main.py:47] epoch 344, training loss: 3865.16, average training loss: 6968.70, base loss: 4558.37
[INFO 2017-06-26 21:43:28,166 main.py:47] epoch 345, training loss: 4030.67, average training loss: 6960.21, base loss: 4557.98
[INFO 2017-06-26 21:43:28,550 main.py:47] epoch 346, training loss: 3746.98, average training loss: 6950.95, base loss: 4556.23
[INFO 2017-06-26 21:43:28,933 main.py:47] epoch 347, training loss: 4015.16, average training loss: 6942.51, base loss: 4555.65
[INFO 2017-06-26 21:43:29,319 main.py:47] epoch 348, training loss: 3809.80, average training loss: 6933.54, base loss: 4554.29
[INFO 2017-06-26 21:43:29,708 main.py:47] epoch 349, training loss: 4534.56, average training loss: 6926.68, base loss: 4555.86
[INFO 2017-06-26 21:43:30,093 main.py:47] epoch 350, training loss: 4313.71, average training loss: 6919.24, base loss: 4556.83
[INFO 2017-06-26 21:43:30,478 main.py:47] epoch 351, training loss: 4374.47, average training loss: 6912.01, base loss: 4557.13
[INFO 2017-06-26 21:43:30,861 main.py:47] epoch 352, training loss: 4239.82, average training loss: 6904.44, base loss: 4557.43
[INFO 2017-06-26 21:43:31,244 main.py:47] epoch 353, training loss: 4229.92, average training loss: 6896.88, base loss: 4557.88
[INFO 2017-06-26 21:43:31,629 main.py:47] epoch 354, training loss: 4661.98, average training loss: 6890.59, base loss: 4560.00
[INFO 2017-06-26 21:43:32,013 main.py:47] epoch 355, training loss: 4144.56, average training loss: 6882.87, base loss: 4560.13
[INFO 2017-06-26 21:43:32,398 main.py:47] epoch 356, training loss: 4100.02, average training loss: 6875.08, base loss: 4559.95
[INFO 2017-06-26 21:43:32,784 main.py:47] epoch 357, training loss: 4373.61, average training loss: 6868.09, base loss: 4560.79
[INFO 2017-06-26 21:43:33,163 main.py:47] epoch 358, training loss: 4126.49, average training loss: 6860.46, base loss: 4560.85
[INFO 2017-06-26 21:43:33,550 main.py:47] epoch 359, training loss: 3895.94, average training loss: 6852.22, base loss: 4559.50
[INFO 2017-06-26 21:43:33,934 main.py:47] epoch 360, training loss: 4620.79, average training loss: 6846.04, base loss: 4561.02
[INFO 2017-06-26 21:43:34,317 main.py:47] epoch 361, training loss: 4133.11, average training loss: 6838.55, base loss: 4561.00
[INFO 2017-06-26 21:43:34,701 main.py:47] epoch 362, training loss: 4015.62, average training loss: 6830.77, base loss: 4560.93
[INFO 2017-06-26 21:43:35,087 main.py:47] epoch 363, training loss: 3548.93, average training loss: 6821.75, base loss: 4559.08
[INFO 2017-06-26 21:43:35,469 main.py:47] epoch 364, training loss: 4068.36, average training loss: 6814.21, base loss: 4559.36
[INFO 2017-06-26 21:43:35,849 main.py:47] epoch 365, training loss: 4284.95, average training loss: 6807.30, base loss: 4559.83
[INFO 2017-06-26 21:43:36,229 main.py:47] epoch 366, training loss: 4775.90, average training loss: 6801.76, base loss: 4562.22
[INFO 2017-06-26 21:43:36,614 main.py:47] epoch 367, training loss: 3710.93, average training loss: 6793.36, base loss: 4561.07
[INFO 2017-06-26 21:43:36,998 main.py:47] epoch 368, training loss: 4382.79, average training loss: 6786.83, base loss: 4561.98
[INFO 2017-06-26 21:43:37,383 main.py:47] epoch 369, training loss: 4308.53, average training loss: 6780.13, base loss: 4562.55
[INFO 2017-06-26 21:43:37,771 main.py:47] epoch 370, training loss: 4500.63, average training loss: 6773.99, base loss: 4563.73
[INFO 2017-06-26 21:43:38,157 main.py:47] epoch 371, training loss: 3907.81, average training loss: 6766.28, base loss: 4563.10
[INFO 2017-06-26 21:43:38,541 main.py:47] epoch 372, training loss: 4193.17, average training loss: 6759.39, base loss: 4562.99
[INFO 2017-06-26 21:43:38,927 main.py:47] epoch 373, training loss: 4153.04, average training loss: 6752.42, base loss: 4563.31
[INFO 2017-06-26 21:43:39,311 main.py:47] epoch 374, training loss: 3868.21, average training loss: 6744.73, base loss: 4562.69
[INFO 2017-06-26 21:43:39,696 main.py:47] epoch 375, training loss: 4074.51, average training loss: 6737.62, base loss: 4562.54
[INFO 2017-06-26 21:43:40,082 main.py:47] epoch 376, training loss: 3528.05, average training loss: 6729.11, base loss: 4560.81
[INFO 2017-06-26 21:43:40,461 main.py:47] epoch 377, training loss: 4104.18, average training loss: 6722.17, base loss: 4560.77
[INFO 2017-06-26 21:43:40,846 main.py:47] epoch 378, training loss: 4030.66, average training loss: 6715.06, base loss: 4560.05
[INFO 2017-06-26 21:43:41,229 main.py:47] epoch 379, training loss: 4073.10, average training loss: 6708.11, base loss: 4559.75
[INFO 2017-06-26 21:43:41,608 main.py:47] epoch 380, training loss: 7716.60, average training loss: 6710.76, base loss: 4569.39
[INFO 2017-06-26 21:43:41,987 main.py:47] epoch 381, training loss: 4164.27, average training loss: 6704.09, base loss: 4569.63
[INFO 2017-06-26 21:43:42,367 main.py:47] epoch 382, training loss: 4381.48, average training loss: 6698.03, base loss: 4570.73
[INFO 2017-06-26 21:43:42,750 main.py:47] epoch 383, training loss: 4633.55, average training loss: 6692.65, base loss: 4572.60
[INFO 2017-06-26 21:43:43,145 main.py:47] epoch 384, training loss: 4352.56, average training loss: 6686.57, base loss: 4573.72
[INFO 2017-06-26 21:43:43,531 main.py:47] epoch 385, training loss: 3815.81, average training loss: 6679.14, base loss: 4572.37
[INFO 2017-06-26 21:43:43,916 main.py:47] epoch 386, training loss: 4047.52, average training loss: 6672.34, base loss: 4571.71
[INFO 2017-06-26 21:43:44,301 main.py:47] epoch 387, training loss: 3876.74, average training loss: 6665.13, base loss: 4571.04
[INFO 2017-06-26 21:43:44,681 main.py:47] epoch 388, training loss: 3873.36, average training loss: 6657.96, base loss: 4570.06
[INFO 2017-06-26 21:43:45,062 main.py:47] epoch 389, training loss: 4538.18, average training loss: 6652.52, base loss: 4571.04
[INFO 2017-06-26 21:43:45,451 main.py:47] epoch 390, training loss: 4629.67, average training loss: 6647.35, base loss: 4572.47
[INFO 2017-06-26 21:43:45,835 main.py:47] epoch 391, training loss: 7384.04, average training loss: 6649.23, base loss: 4580.77
[INFO 2017-06-26 21:43:46,215 main.py:47] epoch 392, training loss: 4122.97, average training loss: 6642.80, base loss: 4580.87
[INFO 2017-06-26 21:43:46,594 main.py:47] epoch 393, training loss: 3994.21, average training loss: 6636.08, base loss: 4580.12
[INFO 2017-06-26 21:43:46,980 main.py:47] epoch 394, training loss: 4327.27, average training loss: 6630.23, base loss: 4581.02
[INFO 2017-06-26 21:43:47,366 main.py:47] epoch 395, training loss: 3884.08, average training loss: 6623.30, base loss: 4580.25
[INFO 2017-06-26 21:43:47,757 main.py:47] epoch 396, training loss: 3630.43, average training loss: 6615.76, base loss: 4578.60
[INFO 2017-06-26 21:43:48,143 main.py:47] epoch 397, training loss: 4701.05, average training loss: 6610.95, base loss: 4580.54
[INFO 2017-06-26 21:43:48,529 main.py:47] epoch 398, training loss: 3442.55, average training loss: 6603.01, base loss: 4578.47
[INFO 2017-06-26 21:43:48,915 main.py:47] epoch 399, training loss: 3616.16, average training loss: 6595.54, base loss: 4576.56
[INFO 2017-06-26 21:43:48,915 main.py:49] epoch 399, testing
[INFO 2017-06-26 21:43:50,402 main.py:101] average testing loss: 4479.44, base loss: 4861.49, improve_loss: 382.05
[INFO 2017-06-26 21:43:50,403 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:43:50,415 main.py:73] current best improved loss: 382.05
[INFO 2017-06-26 21:43:50,804 main.py:47] epoch 400, training loss: 4063.27, average training loss: 6589.22, base loss: 4576.61
[INFO 2017-06-26 21:43:51,190 main.py:47] epoch 401, training loss: 3965.17, average training loss: 6582.70, base loss: 4576.19
[INFO 2017-06-26 21:43:51,577 main.py:47] epoch 402, training loss: 3335.13, average training loss: 6574.64, base loss: 4573.42
[INFO 2017-06-26 21:43:51,968 main.py:47] epoch 403, training loss: 3913.34, average training loss: 6568.05, base loss: 4572.91
[INFO 2017-06-26 21:43:52,353 main.py:47] epoch 404, training loss: 3849.64, average training loss: 6561.34, base loss: 4571.66
[INFO 2017-06-26 21:43:52,744 main.py:47] epoch 405, training loss: 3829.78, average training loss: 6554.61, base loss: 4571.14
[INFO 2017-06-26 21:43:53,130 main.py:47] epoch 406, training loss: 3900.24, average training loss: 6548.09, base loss: 4570.69
[INFO 2017-06-26 21:43:53,515 main.py:47] epoch 407, training loss: 4288.05, average training loss: 6542.55, base loss: 4570.99
[INFO 2017-06-26 21:43:53,902 main.py:47] epoch 408, training loss: 3807.34, average training loss: 6535.86, base loss: 4570.14
[INFO 2017-06-26 21:43:54,288 main.py:47] epoch 409, training loss: 3360.64, average training loss: 6528.12, base loss: 4567.64
[INFO 2017-06-26 21:43:54,678 main.py:47] epoch 410, training loss: 4237.14, average training loss: 6522.54, base loss: 4568.11
[INFO 2017-06-26 21:43:55,065 main.py:47] epoch 411, training loss: 3841.36, average training loss: 6516.03, base loss: 4567.69
[INFO 2017-06-26 21:43:55,455 main.py:47] epoch 412, training loss: 4301.18, average training loss: 6510.67, base loss: 4568.35
[INFO 2017-06-26 21:43:55,843 main.py:47] epoch 413, training loss: 4654.26, average training loss: 6506.19, base loss: 4570.16
[INFO 2017-06-26 21:43:56,229 main.py:47] epoch 414, training loss: 3601.80, average training loss: 6499.19, base loss: 4568.72
[INFO 2017-06-26 21:43:56,607 main.py:47] epoch 415, training loss: 3982.23, average training loss: 6493.14, base loss: 4568.13
[INFO 2017-06-26 21:43:56,993 main.py:47] epoch 416, training loss: 4188.55, average training loss: 6487.61, base loss: 4567.98
[INFO 2017-06-26 21:43:57,372 main.py:47] epoch 417, training loss: 4236.83, average training loss: 6482.23, base loss: 4568.55
[INFO 2017-06-26 21:43:57,752 main.py:47] epoch 418, training loss: 4943.66, average training loss: 6478.56, base loss: 4571.21
[INFO 2017-06-26 21:43:58,138 main.py:47] epoch 419, training loss: 4884.43, average training loss: 6474.76, base loss: 4573.93
[INFO 2017-06-26 21:43:58,519 main.py:47] epoch 420, training loss: 4162.46, average training loss: 6469.27, base loss: 4574.30
[INFO 2017-06-26 21:43:58,911 main.py:47] epoch 421, training loss: 4162.33, average training loss: 6463.80, base loss: 4574.01
[INFO 2017-06-26 21:43:59,298 main.py:47] epoch 422, training loss: 4088.27, average training loss: 6458.18, base loss: 4573.43
[INFO 2017-06-26 21:43:59,682 main.py:47] epoch 423, training loss: 4646.22, average training loss: 6453.91, base loss: 4575.16
[INFO 2017-06-26 21:44:00,069 main.py:47] epoch 424, training loss: 4017.49, average training loss: 6448.18, base loss: 4574.95
[INFO 2017-06-26 21:44:00,458 main.py:47] epoch 425, training loss: 3832.71, average training loss: 6442.04, base loss: 4574.63
[INFO 2017-06-26 21:44:00,845 main.py:47] epoch 426, training loss: 3500.81, average training loss: 6435.15, base loss: 4572.41
[INFO 2017-06-26 21:44:01,231 main.py:47] epoch 427, training loss: 3858.49, average training loss: 6429.13, base loss: 4571.48
[INFO 2017-06-26 21:44:01,612 main.py:47] epoch 428, training loss: 3722.77, average training loss: 6422.82, base loss: 4570.50
[INFO 2017-06-26 21:44:01,993 main.py:47] epoch 429, training loss: 3878.21, average training loss: 6416.90, base loss: 4569.61
[INFO 2017-06-26 21:44:02,382 main.py:47] epoch 430, training loss: 4093.20, average training loss: 6411.51, base loss: 4569.45
[INFO 2017-06-26 21:44:02,769 main.py:47] epoch 431, training loss: 3690.54, average training loss: 6405.21, base loss: 4568.03
[INFO 2017-06-26 21:44:03,160 main.py:47] epoch 432, training loss: 3959.97, average training loss: 6399.57, base loss: 4567.92
[INFO 2017-06-26 21:44:03,546 main.py:47] epoch 433, training loss: 3792.09, average training loss: 6393.56, base loss: 4567.04
[INFO 2017-06-26 21:44:03,934 main.py:47] epoch 434, training loss: 3876.29, average training loss: 6387.77, base loss: 4566.21
[INFO 2017-06-26 21:44:04,319 main.py:47] epoch 435, training loss: 3827.83, average training loss: 6381.90, base loss: 4565.66
[INFO 2017-06-26 21:44:04,704 main.py:47] epoch 436, training loss: 3439.31, average training loss: 6375.17, base loss: 4563.92
[INFO 2017-06-26 21:44:05,090 main.py:47] epoch 437, training loss: 3868.29, average training loss: 6369.44, base loss: 4563.47
[INFO 2017-06-26 21:44:05,477 main.py:47] epoch 438, training loss: 4780.03, average training loss: 6365.82, base loss: 4565.56
[INFO 2017-06-26 21:44:05,856 main.py:47] epoch 439, training loss: 4282.51, average training loss: 6361.09, base loss: 4566.23
[INFO 2017-06-26 21:44:06,235 main.py:47] epoch 440, training loss: 3958.42, average training loss: 6355.64, base loss: 4565.44
[INFO 2017-06-26 21:44:06,615 main.py:47] epoch 441, training loss: 4197.73, average training loss: 6350.76, base loss: 4565.93
[INFO 2017-06-26 21:44:07,001 main.py:47] epoch 442, training loss: 4321.60, average training loss: 6346.18, base loss: 4566.64
[INFO 2017-06-26 21:44:07,381 main.py:47] epoch 443, training loss: 3831.95, average training loss: 6340.52, base loss: 4566.30
[INFO 2017-06-26 21:44:07,760 main.py:47] epoch 444, training loss: 4301.91, average training loss: 6335.93, base loss: 4567.24
[INFO 2017-06-26 21:44:08,146 main.py:47] epoch 445, training loss: 4237.87, average training loss: 6331.23, base loss: 4567.61
[INFO 2017-06-26 21:44:08,530 main.py:47] epoch 446, training loss: 7590.39, average training loss: 6334.05, base loss: 4575.61
[INFO 2017-06-26 21:44:08,915 main.py:47] epoch 447, training loss: 4502.24, average training loss: 6329.96, base loss: 4576.57
[INFO 2017-06-26 21:44:09,299 main.py:47] epoch 448, training loss: 3707.60, average training loss: 6324.12, base loss: 4575.73
[INFO 2017-06-26 21:44:09,678 main.py:47] epoch 449, training loss: 3856.65, average training loss: 6318.63, base loss: 4574.91
[INFO 2017-06-26 21:44:10,063 main.py:47] epoch 450, training loss: 3358.35, average training loss: 6312.07, base loss: 4572.89
[INFO 2017-06-26 21:44:10,446 main.py:47] epoch 451, training loss: 3491.25, average training loss: 6305.83, base loss: 4571.20
[INFO 2017-06-26 21:44:10,829 main.py:47] epoch 452, training loss: 4064.86, average training loss: 6300.88, base loss: 4570.99
[INFO 2017-06-26 21:44:11,214 main.py:47] epoch 453, training loss: 4834.81, average training loss: 6297.65, base loss: 4573.05
[INFO 2017-06-26 21:44:11,592 main.py:47] epoch 454, training loss: 3817.10, average training loss: 6292.20, base loss: 4572.14
[INFO 2017-06-26 21:44:11,971 main.py:47] epoch 455, training loss: 3689.60, average training loss: 6286.49, base loss: 4570.97
[INFO 2017-06-26 21:44:12,355 main.py:47] epoch 456, training loss: 3982.07, average training loss: 6281.45, base loss: 4570.95
[INFO 2017-06-26 21:44:12,741 main.py:47] epoch 457, training loss: 3779.22, average training loss: 6275.99, base loss: 4570.44
[INFO 2017-06-26 21:44:13,121 main.py:47] epoch 458, training loss: 4444.74, average training loss: 6272.00, base loss: 4571.82
[INFO 2017-06-26 21:44:13,505 main.py:47] epoch 459, training loss: 4162.81, average training loss: 6267.41, base loss: 4571.90
[INFO 2017-06-26 21:44:13,890 main.py:47] epoch 460, training loss: 3709.94, average training loss: 6261.87, base loss: 4570.79
[INFO 2017-06-26 21:44:14,274 main.py:47] epoch 461, training loss: 4246.07, average training loss: 6257.50, base loss: 4571.36
[INFO 2017-06-26 21:44:14,654 main.py:47] epoch 462, training loss: 4181.45, average training loss: 6253.02, base loss: 4571.61
[INFO 2017-06-26 21:44:15,041 main.py:47] epoch 463, training loss: 4270.11, average training loss: 6248.75, base loss: 4572.05
[INFO 2017-06-26 21:44:15,427 main.py:47] epoch 464, training loss: 3602.33, average training loss: 6243.05, base loss: 4570.90
[INFO 2017-06-26 21:44:15,807 main.py:47] epoch 465, training loss: 4520.69, average training loss: 6239.36, base loss: 4571.42
[INFO 2017-06-26 21:44:16,187 main.py:47] epoch 466, training loss: 4248.97, average training loss: 6235.10, base loss: 4571.97
[INFO 2017-06-26 21:44:16,567 main.py:47] epoch 467, training loss: 4161.62, average training loss: 6230.67, base loss: 4571.73
[INFO 2017-06-26 21:44:16,951 main.py:47] epoch 468, training loss: 3719.13, average training loss: 6225.31, base loss: 4570.90
[INFO 2017-06-26 21:44:17,331 main.py:47] epoch 469, training loss: 4156.19, average training loss: 6220.91, base loss: 4571.45
[INFO 2017-06-26 21:44:17,712 main.py:47] epoch 470, training loss: 4254.06, average training loss: 6216.73, base loss: 4572.14
[INFO 2017-06-26 21:44:18,091 main.py:47] epoch 471, training loss: 3717.53, average training loss: 6211.44, base loss: 4571.03
[INFO 2017-06-26 21:44:18,471 main.py:47] epoch 472, training loss: 3533.27, average training loss: 6205.77, base loss: 4569.60
[INFO 2017-06-26 21:44:18,854 main.py:47] epoch 473, training loss: 4128.41, average training loss: 6201.39, base loss: 4569.76
[INFO 2017-06-26 21:44:19,234 main.py:47] epoch 474, training loss: 3498.88, average training loss: 6195.70, base loss: 4568.10
[INFO 2017-06-26 21:44:19,620 main.py:47] epoch 475, training loss: 4638.02, average training loss: 6192.43, base loss: 4569.64
[INFO 2017-06-26 21:44:20,005 main.py:47] epoch 476, training loss: 3797.20, average training loss: 6187.41, base loss: 4568.88
[INFO 2017-06-26 21:44:20,385 main.py:47] epoch 477, training loss: 4223.32, average training loss: 6183.30, base loss: 4569.62
[INFO 2017-06-26 21:44:20,765 main.py:47] epoch 478, training loss: 4444.73, average training loss: 6179.67, base loss: 4570.39
[INFO 2017-06-26 21:44:21,146 main.py:47] epoch 479, training loss: 4600.92, average training loss: 6176.38, base loss: 4571.40
[INFO 2017-06-26 21:44:21,530 main.py:47] epoch 480, training loss: 4620.38, average training loss: 6173.15, base loss: 4572.55
[INFO 2017-06-26 21:44:21,913 main.py:47] epoch 481, training loss: 4119.71, average training loss: 6168.89, base loss: 4572.57
[INFO 2017-06-26 21:44:22,300 main.py:47] epoch 482, training loss: 4212.66, average training loss: 6164.84, base loss: 4573.02
[INFO 2017-06-26 21:44:22,686 main.py:47] epoch 483, training loss: 3425.48, average training loss: 6159.18, base loss: 4571.26
[INFO 2017-06-26 21:44:23,065 main.py:47] epoch 484, training loss: 4115.54, average training loss: 6154.96, base loss: 4571.15
[INFO 2017-06-26 21:44:23,444 main.py:47] epoch 485, training loss: 3974.95, average training loss: 6150.48, base loss: 4570.44
[INFO 2017-06-26 21:44:23,823 main.py:47] epoch 486, training loss: 4114.20, average training loss: 6146.30, base loss: 4570.42
[INFO 2017-06-26 21:44:24,203 main.py:47] epoch 487, training loss: 3455.50, average training loss: 6140.78, base loss: 4568.75
[INFO 2017-06-26 21:44:24,590 main.py:47] epoch 488, training loss: 3888.64, average training loss: 6136.18, base loss: 4568.37
[INFO 2017-06-26 21:44:24,970 main.py:47] epoch 489, training loss: 4422.26, average training loss: 6132.68, base loss: 4568.53
[INFO 2017-06-26 21:44:25,355 main.py:47] epoch 490, training loss: 3985.31, average training loss: 6128.30, base loss: 4568.28
[INFO 2017-06-26 21:44:25,735 main.py:47] epoch 491, training loss: 4328.10, average training loss: 6124.65, base loss: 4568.80
[INFO 2017-06-26 21:44:26,115 main.py:47] epoch 492, training loss: 7208.24, average training loss: 6126.84, base loss: 4574.52
[INFO 2017-06-26 21:44:26,495 main.py:47] epoch 493, training loss: 3840.79, average training loss: 6122.22, base loss: 4574.13
[INFO 2017-06-26 21:44:26,875 main.py:47] epoch 494, training loss: 4357.40, average training loss: 6118.65, base loss: 4574.27
[INFO 2017-06-26 21:44:27,259 main.py:47] epoch 495, training loss: 4239.30, average training loss: 6114.86, base loss: 4574.45
[INFO 2017-06-26 21:44:27,640 main.py:47] epoch 496, training loss: 3893.52, average training loss: 6110.39, base loss: 4573.92
[INFO 2017-06-26 21:44:28,020 main.py:47] epoch 497, training loss: 3616.61, average training loss: 6105.38, base loss: 4573.01
[INFO 2017-06-26 21:44:28,398 main.py:47] epoch 498, training loss: 3389.39, average training loss: 6099.94, base loss: 4571.41
[INFO 2017-06-26 21:44:28,781 main.py:47] epoch 499, training loss: 4444.37, average training loss: 6096.63, base loss: 4572.15
[INFO 2017-06-26 21:44:28,782 main.py:49] epoch 499, testing
[INFO 2017-06-26 21:44:30,295 main.py:101] average testing loss: 4547.02, base loss: 4978.18, improve_loss: 431.16
[INFO 2017-06-26 21:44:30,296 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:44:30,308 main.py:73] current best improved loss: 431.16
[INFO 2017-06-26 21:44:30,699 main.py:47] epoch 500, training loss: 3614.72, average training loss: 6091.68, base loss: 4570.89
[INFO 2017-06-26 21:44:31,084 main.py:47] epoch 501, training loss: 3328.55, average training loss: 6086.17, base loss: 4568.68
[INFO 2017-06-26 21:44:31,467 main.py:47] epoch 502, training loss: 4267.76, average training loss: 6082.56, base loss: 4569.31
[INFO 2017-06-26 21:44:31,851 main.py:47] epoch 503, training loss: 3935.71, average training loss: 6078.30, base loss: 4568.93
[INFO 2017-06-26 21:44:32,238 main.py:47] epoch 504, training loss: 4702.95, average training loss: 6075.57, base loss: 4570.41
[INFO 2017-06-26 21:44:32,617 main.py:47] epoch 505, training loss: 4748.61, average training loss: 6072.95, base loss: 4572.08
[INFO 2017-06-26 21:44:33,003 main.py:47] epoch 506, training loss: 4113.18, average training loss: 6069.09, base loss: 4572.13
[INFO 2017-06-26 21:44:33,391 main.py:47] epoch 507, training loss: 4100.06, average training loss: 6065.21, base loss: 4572.18
[INFO 2017-06-26 21:44:33,770 main.py:47] epoch 508, training loss: 3570.35, average training loss: 6060.31, base loss: 4571.12
[INFO 2017-06-26 21:44:34,150 main.py:47] epoch 509, training loss: 4421.62, average training loss: 6057.10, base loss: 4572.63
[INFO 2017-06-26 21:44:34,532 main.py:47] epoch 510, training loss: 3671.19, average training loss: 6052.43, base loss: 4571.59
[INFO 2017-06-26 21:44:34,916 main.py:47] epoch 511, training loss: 4033.89, average training loss: 6048.48, base loss: 4571.87
[INFO 2017-06-26 21:44:35,300 main.py:47] epoch 512, training loss: 4526.84, average training loss: 6045.52, base loss: 4573.77
[INFO 2017-06-26 21:44:35,687 main.py:47] epoch 513, training loss: 3814.40, average training loss: 6041.18, base loss: 4573.29
[INFO 2017-06-26 21:44:36,073 main.py:47] epoch 514, training loss: 3720.32, average training loss: 6036.67, base loss: 4572.49
[INFO 2017-06-26 21:44:36,464 main.py:47] epoch 515, training loss: 4095.43, average training loss: 6032.91, base loss: 4573.00
[INFO 2017-06-26 21:44:36,852 main.py:47] epoch 516, training loss: 3710.97, average training loss: 6028.42, base loss: 4572.48
[INFO 2017-06-26 21:44:37,255 main.py:47] epoch 517, training loss: 3619.89, average training loss: 6023.77, base loss: 4571.42
[INFO 2017-06-26 21:44:37,653 main.py:47] epoch 518, training loss: 3710.65, average training loss: 6019.31, base loss: 4570.39
[INFO 2017-06-26 21:44:38,053 main.py:47] epoch 519, training loss: 4202.52, average training loss: 6015.82, base loss: 4570.75
[INFO 2017-06-26 21:44:38,451 main.py:47] epoch 520, training loss: 3253.29, average training loss: 6010.51, base loss: 4568.97
[INFO 2017-06-26 21:44:38,843 main.py:47] epoch 521, training loss: 4437.73, average training loss: 6007.50, base loss: 4569.89
[INFO 2017-06-26 21:44:39,237 main.py:47] epoch 522, training loss: 8031.15, average training loss: 6011.37, base loss: 4577.40
[INFO 2017-06-26 21:44:39,663 main.py:47] epoch 523, training loss: 3397.13, average training loss: 6006.38, base loss: 4575.75
[INFO 2017-06-26 21:44:40,128 main.py:47] epoch 524, training loss: 3209.41, average training loss: 6001.05, base loss: 4573.57
[INFO 2017-06-26 21:44:40,607 main.py:47] epoch 525, training loss: 3616.49, average training loss: 5996.52, base loss: 4572.76
[INFO 2017-06-26 21:44:41,077 main.py:47] epoch 526, training loss: 4935.73, average training loss: 5994.51, base loss: 4574.75
[INFO 2017-06-26 21:44:41,531 main.py:47] epoch 527, training loss: 7649.67, average training loss: 5997.64, base loss: 4581.40
[INFO 2017-06-26 21:44:41,943 main.py:47] epoch 528, training loss: 3801.48, average training loss: 5993.49, base loss: 4581.12
[INFO 2017-06-26 21:44:42,408 main.py:47] epoch 529, training loss: 4208.11, average training loss: 5990.12, base loss: 4581.75
[INFO 2017-06-26 21:44:42,921 main.py:47] epoch 530, training loss: 5094.76, average training loss: 5988.44, base loss: 4584.37
[INFO 2017-06-26 21:44:43,330 main.py:47] epoch 531, training loss: 4664.86, average training loss: 5985.95, base loss: 4586.10
[INFO 2017-06-26 21:44:43,718 main.py:47] epoch 532, training loss: 3504.92, average training loss: 5981.29, base loss: 4585.08
[INFO 2017-06-26 21:44:44,103 main.py:47] epoch 533, training loss: 3718.99, average training loss: 5977.06, base loss: 4583.84
[INFO 2017-06-26 21:44:44,488 main.py:47] epoch 534, training loss: 4086.01, average training loss: 5973.52, base loss: 4584.29
[INFO 2017-06-26 21:44:44,873 main.py:47] epoch 535, training loss: 4078.64, average training loss: 5969.99, base loss: 4584.97
[INFO 2017-06-26 21:44:45,260 main.py:47] epoch 536, training loss: 3822.65, average training loss: 5965.99, base loss: 4584.67
[INFO 2017-06-26 21:44:45,645 main.py:47] epoch 537, training loss: 4197.55, average training loss: 5962.70, base loss: 4585.04
[INFO 2017-06-26 21:44:46,101 main.py:47] epoch 538, training loss: 4426.14, average training loss: 5959.85, base loss: 4586.11
[INFO 2017-06-26 21:44:46,513 main.py:47] epoch 539, training loss: 3761.47, average training loss: 5955.78, base loss: 4585.62
[INFO 2017-06-26 21:44:46,912 main.py:47] epoch 540, training loss: 4184.46, average training loss: 5952.51, base loss: 4586.43
[INFO 2017-06-26 21:44:47,299 main.py:47] epoch 541, training loss: 4646.30, average training loss: 5950.10, base loss: 4587.79
[INFO 2017-06-26 21:44:47,745 main.py:47] epoch 542, training loss: 3772.19, average training loss: 5946.08, base loss: 4587.35
[INFO 2017-06-26 21:44:48,156 main.py:47] epoch 543, training loss: 3726.28, average training loss: 5942.00, base loss: 4586.39
[INFO 2017-06-26 21:44:48,550 main.py:47] epoch 544, training loss: 3308.00, average training loss: 5937.17, base loss: 4584.50
[INFO 2017-06-26 21:44:48,952 main.py:47] epoch 545, training loss: 4666.31, average training loss: 5934.84, base loss: 4585.67
[INFO 2017-06-26 21:44:49,364 main.py:47] epoch 546, training loss: 4016.47, average training loss: 5931.34, base loss: 4585.61
[INFO 2017-06-26 21:44:49,754 main.py:47] epoch 547, training loss: 5037.63, average training loss: 5929.71, base loss: 4587.46
[INFO 2017-06-26 21:44:50,250 main.py:47] epoch 548, training loss: 3753.78, average training loss: 5925.74, base loss: 4586.70
[INFO 2017-06-26 21:44:50,645 main.py:47] epoch 549, training loss: 4352.53, average training loss: 5922.88, base loss: 4587.47
[INFO 2017-06-26 21:44:51,134 main.py:47] epoch 550, training loss: 3966.14, average training loss: 5919.33, base loss: 4587.26
[INFO 2017-06-26 21:44:51,531 main.py:47] epoch 551, training loss: 4152.49, average training loss: 5916.13, base loss: 4587.33
[INFO 2017-06-26 21:44:51,918 main.py:47] epoch 552, training loss: 4156.91, average training loss: 5912.95, base loss: 4588.02
[INFO 2017-06-26 21:44:52,303 main.py:47] epoch 553, training loss: 3968.69, average training loss: 5909.44, base loss: 4587.82
[INFO 2017-06-26 21:44:52,792 main.py:47] epoch 554, training loss: 3936.68, average training loss: 5905.88, base loss: 4587.84
[INFO 2017-06-26 21:44:53,192 main.py:47] epoch 555, training loss: 3794.40, average training loss: 5902.09, base loss: 4587.51
[INFO 2017-06-26 21:44:53,686 main.py:47] epoch 556, training loss: 4005.58, average training loss: 5898.68, base loss: 4587.81
[INFO 2017-06-26 21:44:54,096 main.py:47] epoch 557, training loss: 3326.53, average training loss: 5894.07, base loss: 4586.08
[INFO 2017-06-26 21:44:54,574 main.py:47] epoch 558, training loss: 4008.20, average training loss: 5890.70, base loss: 4586.12
[INFO 2017-06-26 21:44:54,975 main.py:47] epoch 559, training loss: 4026.77, average training loss: 5887.37, base loss: 4586.19
[INFO 2017-06-26 21:44:55,462 main.py:47] epoch 560, training loss: 3301.46, average training loss: 5882.76, base loss: 4584.71
[INFO 2017-06-26 21:44:55,872 main.py:47] epoch 561, training loss: 6968.07, average training loss: 5884.69, base loss: 4589.51
[INFO 2017-06-26 21:44:56,305 main.py:47] epoch 562, training loss: 3825.29, average training loss: 5881.03, base loss: 4589.22
[INFO 2017-06-26 21:44:56,692 main.py:47] epoch 563, training loss: 4542.75, average training loss: 5878.66, base loss: 4590.31
[INFO 2017-06-26 21:44:57,134 main.py:47] epoch 564, training loss: 4081.27, average training loss: 5875.48, base loss: 4590.34
[INFO 2017-06-26 21:44:57,526 main.py:47] epoch 565, training loss: 4855.16, average training loss: 5873.68, base loss: 4592.60
[INFO 2017-06-26 21:44:57,982 main.py:47] epoch 566, training loss: 4061.91, average training loss: 5870.48, base loss: 4593.01
[INFO 2017-06-26 21:44:58,389 main.py:47] epoch 567, training loss: 3894.75, average training loss: 5867.00, base loss: 4593.26
[INFO 2017-06-26 21:44:58,879 main.py:47] epoch 568, training loss: 3383.09, average training loss: 5862.64, base loss: 4591.34
[INFO 2017-06-26 21:44:59,308 main.py:47] epoch 569, training loss: 3523.01, average training loss: 5858.53, base loss: 4590.33
[INFO 2017-06-26 21:44:59,714 main.py:47] epoch 570, training loss: 3934.21, average training loss: 5855.16, base loss: 4590.03
[INFO 2017-06-26 21:45:00,103 main.py:47] epoch 571, training loss: 3973.15, average training loss: 5851.87, base loss: 4589.87
[INFO 2017-06-26 21:45:00,487 main.py:47] epoch 572, training loss: 3523.45, average training loss: 5847.81, base loss: 4588.65
[INFO 2017-06-26 21:45:00,867 main.py:47] epoch 573, training loss: 3765.07, average training loss: 5844.18, base loss: 4588.03
[INFO 2017-06-26 21:45:01,275 main.py:47] epoch 574, training loss: 3800.74, average training loss: 5840.63, base loss: 4587.57
[INFO 2017-06-26 21:45:01,660 main.py:47] epoch 575, training loss: 3898.49, average training loss: 5837.26, base loss: 4587.34
[INFO 2017-06-26 21:45:02,046 main.py:47] epoch 576, training loss: 3679.42, average training loss: 5833.52, base loss: 4586.66
[INFO 2017-06-26 21:45:02,431 main.py:47] epoch 577, training loss: 4279.57, average training loss: 5830.83, base loss: 4587.56
[INFO 2017-06-26 21:45:02,815 main.py:47] epoch 578, training loss: 3701.18, average training loss: 5827.15, base loss: 4586.95
[INFO 2017-06-26 21:45:03,200 main.py:47] epoch 579, training loss: 4175.86, average training loss: 5824.30, base loss: 4587.40
[INFO 2017-06-26 21:45:03,585 main.py:47] epoch 580, training loss: 3962.70, average training loss: 5821.10, base loss: 4587.31
[INFO 2017-06-26 21:45:03,969 main.py:47] epoch 581, training loss: 3641.49, average training loss: 5817.35, base loss: 4586.42
[INFO 2017-06-26 21:45:04,430 main.py:47] epoch 582, training loss: 3682.73, average training loss: 5813.69, base loss: 4585.41
[INFO 2017-06-26 21:45:04,841 main.py:47] epoch 583, training loss: 4041.24, average training loss: 5810.66, base loss: 4585.36
[INFO 2017-06-26 21:45:05,231 main.py:47] epoch 584, training loss: 3541.28, average training loss: 5806.78, base loss: 4584.13
[INFO 2017-06-26 21:45:05,645 main.py:47] epoch 585, training loss: 3725.78, average training loss: 5803.23, base loss: 4583.46
[INFO 2017-06-26 21:45:06,063 main.py:47] epoch 586, training loss: 6989.62, average training loss: 5805.25, base loss: 4588.23
[INFO 2017-06-26 21:45:06,449 main.py:47] epoch 587, training loss: 3724.23, average training loss: 5801.71, base loss: 4587.51
[INFO 2017-06-26 21:45:06,834 main.py:47] epoch 588, training loss: 4078.44, average training loss: 5798.78, base loss: 4587.65
[INFO 2017-06-26 21:45:07,218 main.py:47] epoch 589, training loss: 4342.57, average training loss: 5796.31, base loss: 4588.49
[INFO 2017-06-26 21:45:07,681 main.py:47] epoch 590, training loss: 4017.10, average training loss: 5793.30, base loss: 4588.49
[INFO 2017-06-26 21:45:08,092 main.py:47] epoch 591, training loss: 3914.42, average training loss: 5790.13, base loss: 4588.25
[INFO 2017-06-26 21:45:08,482 main.py:47] epoch 592, training loss: 3958.10, average training loss: 5787.04, base loss: 4588.33
[INFO 2017-06-26 21:45:08,883 main.py:47] epoch 593, training loss: 3379.16, average training loss: 5782.99, base loss: 4587.17
[INFO 2017-06-26 21:45:09,265 main.py:47] epoch 594, training loss: 3577.59, average training loss: 5779.28, base loss: 4586.49
[INFO 2017-06-26 21:45:09,650 main.py:47] epoch 595, training loss: 3622.35, average training loss: 5775.66, base loss: 4585.56
[INFO 2017-06-26 21:45:10,034 main.py:47] epoch 596, training loss: 4346.55, average training loss: 5773.27, base loss: 4586.21
[INFO 2017-06-26 21:45:10,451 main.py:47] epoch 597, training loss: 3516.46, average training loss: 5769.49, base loss: 4585.22
[INFO 2017-06-26 21:45:10,835 main.py:47] epoch 598, training loss: 7264.78, average training loss: 5771.99, base loss: 4590.33
[INFO 2017-06-26 21:45:11,217 main.py:47] epoch 599, training loss: 3685.00, average training loss: 5768.51, base loss: 4589.64
[INFO 2017-06-26 21:45:11,218 main.py:49] epoch 599, testing
[INFO 2017-06-26 21:45:12,702 main.py:101] average testing loss: 3960.16, base loss: 4627.57, improve_loss: 667.40
[INFO 2017-06-26 21:45:12,703 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:45:12,718 main.py:73] current best improved loss: 667.40
[INFO 2017-06-26 21:45:13,105 main.py:47] epoch 600, training loss: 3405.30, average training loss: 5764.58, base loss: 4588.29
[INFO 2017-06-26 21:45:13,493 main.py:47] epoch 601, training loss: 3334.96, average training loss: 5760.54, base loss: 4586.79
[INFO 2017-06-26 21:45:13,877 main.py:47] epoch 602, training loss: 3282.56, average training loss: 5756.43, base loss: 4585.50
[INFO 2017-06-26 21:45:14,269 main.py:47] epoch 603, training loss: 3691.81, average training loss: 5753.02, base loss: 4584.84
[INFO 2017-06-26 21:45:14,658 main.py:47] epoch 604, training loss: 3602.20, average training loss: 5749.46, base loss: 4584.02
[INFO 2017-06-26 21:45:15,042 main.py:47] epoch 605, training loss: 3745.43, average training loss: 5746.15, base loss: 4583.57
[INFO 2017-06-26 21:45:15,422 main.py:47] epoch 606, training loss: 3785.55, average training loss: 5742.92, base loss: 4583.14
[INFO 2017-06-26 21:45:15,804 main.py:47] epoch 607, training loss: 3290.07, average training loss: 5738.89, base loss: 4581.63
[INFO 2017-06-26 21:45:16,188 main.py:47] epoch 608, training loss: 4458.44, average training loss: 5736.79, base loss: 4582.67
[INFO 2017-06-26 21:45:16,573 main.py:47] epoch 609, training loss: 4014.89, average training loss: 5733.96, base loss: 4582.72
[INFO 2017-06-26 21:45:16,955 main.py:47] epoch 610, training loss: 7434.48, average training loss: 5736.75, base loss: 4588.46
[INFO 2017-06-26 21:45:17,351 main.py:47] epoch 611, training loss: 7641.43, average training loss: 5739.86, base loss: 4594.46
[INFO 2017-06-26 21:45:17,735 main.py:47] epoch 612, training loss: 3614.30, average training loss: 5736.39, base loss: 4593.92
[INFO 2017-06-26 21:45:18,120 main.py:47] epoch 613, training loss: 3521.01, average training loss: 5732.78, base loss: 4593.02
[INFO 2017-06-26 21:45:18,508 main.py:47] epoch 614, training loss: 3512.02, average training loss: 5729.17, base loss: 4592.08
[INFO 2017-06-26 21:45:18,892 main.py:47] epoch 615, training loss: 3566.24, average training loss: 5725.66, base loss: 4591.64
[INFO 2017-06-26 21:45:19,277 main.py:47] epoch 616, training loss: 4073.67, average training loss: 5722.98, base loss: 4592.14
[INFO 2017-06-26 21:45:19,659 main.py:47] epoch 617, training loss: 3870.23, average training loss: 5719.99, base loss: 4591.91
[INFO 2017-06-26 21:45:20,045 main.py:47] epoch 618, training loss: 4152.69, average training loss: 5717.45, base loss: 4592.61
[INFO 2017-06-26 21:45:20,433 main.py:47] epoch 619, training loss: 3401.98, average training loss: 5713.72, base loss: 4591.61
[INFO 2017-06-26 21:45:20,835 main.py:47] epoch 620, training loss: 3740.94, average training loss: 5710.54, base loss: 4591.11
[INFO 2017-06-26 21:45:21,244 main.py:47] epoch 621, training loss: 3708.33, average training loss: 5707.32, base loss: 4590.95
[INFO 2017-06-26 21:45:21,673 main.py:47] epoch 622, training loss: 3630.96, average training loss: 5703.99, base loss: 4590.36
[INFO 2017-06-26 21:45:22,068 main.py:47] epoch 623, training loss: 4016.86, average training loss: 5701.29, base loss: 4590.53
[INFO 2017-06-26 21:45:22,461 main.py:47] epoch 624, training loss: 3885.75, average training loss: 5698.38, base loss: 4590.45
[INFO 2017-06-26 21:45:22,853 main.py:47] epoch 625, training loss: 4078.25, average training loss: 5695.79, base loss: 4590.78
[INFO 2017-06-26 21:45:23,262 main.py:47] epoch 626, training loss: 4081.82, average training loss: 5693.22, base loss: 4590.93
[INFO 2017-06-26 21:45:23,731 main.py:47] epoch 627, training loss: 3946.91, average training loss: 5690.44, base loss: 4590.92
[INFO 2017-06-26 21:45:24,189 main.py:47] epoch 628, training loss: 4196.92, average training loss: 5688.07, base loss: 4591.33
[INFO 2017-06-26 21:45:24,643 main.py:47] epoch 629, training loss: 3931.47, average training loss: 5685.28, base loss: 4591.20
[INFO 2017-06-26 21:45:25,096 main.py:47] epoch 630, training loss: 3915.65, average training loss: 5682.47, base loss: 4591.00
[INFO 2017-06-26 21:45:25,527 main.py:47] epoch 631, training loss: 3434.05, average training loss: 5678.91, base loss: 4589.66
[INFO 2017-06-26 21:45:25,943 main.py:47] epoch 632, training loss: 3606.72, average training loss: 5675.64, base loss: 4588.95
[INFO 2017-06-26 21:45:26,428 main.py:47] epoch 633, training loss: 3910.06, average training loss: 5672.86, base loss: 4588.80
[INFO 2017-06-26 21:45:26,908 main.py:47] epoch 634, training loss: 3227.59, average training loss: 5669.01, base loss: 4587.36
[INFO 2017-06-26 21:45:27,294 main.py:47] epoch 635, training loss: 3401.78, average training loss: 5665.44, base loss: 4586.20
[INFO 2017-06-26 21:45:27,680 main.py:47] epoch 636, training loss: 4242.41, average training loss: 5663.21, base loss: 4586.75
[INFO 2017-06-26 21:45:28,066 main.py:47] epoch 637, training loss: 3690.21, average training loss: 5660.11, base loss: 4586.20
[INFO 2017-06-26 21:45:28,454 main.py:47] epoch 638, training loss: 3325.12, average training loss: 5656.46, base loss: 4585.09
[INFO 2017-06-26 21:45:28,853 main.py:47] epoch 639, training loss: 3799.54, average training loss: 5653.56, base loss: 4584.88
[INFO 2017-06-26 21:45:29,240 main.py:47] epoch 640, training loss: 3634.86, average training loss: 5650.41, base loss: 4583.86
[INFO 2017-06-26 21:45:29,623 main.py:47] epoch 641, training loss: 3717.35, average training loss: 5647.40, base loss: 4583.54
[INFO 2017-06-26 21:45:30,004 main.py:47] epoch 642, training loss: 3462.64, average training loss: 5644.00, base loss: 4582.90
[INFO 2017-06-26 21:45:30,389 main.py:47] epoch 643, training loss: 3722.78, average training loss: 5641.02, base loss: 4582.45
[INFO 2017-06-26 21:45:30,774 main.py:47] epoch 644, training loss: 3409.82, average training loss: 5637.56, base loss: 4581.34
[INFO 2017-06-26 21:45:31,158 main.py:47] epoch 645, training loss: 3951.89, average training loss: 5634.95, base loss: 4581.36
[INFO 2017-06-26 21:45:31,541 main.py:47] epoch 646, training loss: 4403.52, average training loss: 5633.05, base loss: 4582.58
[INFO 2017-06-26 21:45:31,927 main.py:47] epoch 647, training loss: 3744.69, average training loss: 5630.13, base loss: 4582.32
[INFO 2017-06-26 21:45:32,312 main.py:47] epoch 648, training loss: 3375.14, average training loss: 5626.66, base loss: 4580.94
[INFO 2017-06-26 21:45:32,695 main.py:47] epoch 649, training loss: 3972.09, average training loss: 5624.11, base loss: 4581.01
[INFO 2017-06-26 21:45:33,080 main.py:47] epoch 650, training loss: 3754.23, average training loss: 5621.24, base loss: 4580.75
[INFO 2017-06-26 21:45:33,470 main.py:47] epoch 651, training loss: 3629.87, average training loss: 5618.18, base loss: 4580.09
[INFO 2017-06-26 21:45:33,854 main.py:47] epoch 652, training loss: 3710.33, average training loss: 5615.26, base loss: 4579.89
[INFO 2017-06-26 21:45:34,318 main.py:47] epoch 653, training loss: 3951.25, average training loss: 5612.72, base loss: 4579.92
[INFO 2017-06-26 21:45:34,719 main.py:47] epoch 654, training loss: 4196.65, average training loss: 5610.56, base loss: 4580.06
[INFO 2017-06-26 21:45:35,107 main.py:47] epoch 655, training loss: 3899.67, average training loss: 5607.95, base loss: 4580.32
[INFO 2017-06-26 21:45:35,494 main.py:47] epoch 656, training loss: 3453.20, average training loss: 5604.67, base loss: 4579.57
[INFO 2017-06-26 21:45:35,875 main.py:47] epoch 657, training loss: 4311.55, average training loss: 5602.70, base loss: 4580.68
[INFO 2017-06-26 21:45:36,269 main.py:47] epoch 658, training loss: 3533.26, average training loss: 5599.56, base loss: 4579.60
[INFO 2017-06-26 21:45:36,656 main.py:47] epoch 659, training loss: 3825.90, average training loss: 5596.88, base loss: 4579.31
[INFO 2017-06-26 21:45:37,041 main.py:47] epoch 660, training loss: 3885.92, average training loss: 5594.29, base loss: 4579.01
[INFO 2017-06-26 21:45:37,422 main.py:47] epoch 661, training loss: 3753.38, average training loss: 5591.51, base loss: 4578.70
[INFO 2017-06-26 21:45:37,807 main.py:47] epoch 662, training loss: 3737.01, average training loss: 5588.71, base loss: 4578.12
[INFO 2017-06-26 21:45:38,195 main.py:47] epoch 663, training loss: 3924.93, average training loss: 5586.20, base loss: 4578.42
[INFO 2017-06-26 21:45:38,580 main.py:47] epoch 664, training loss: 3486.49, average training loss: 5583.05, base loss: 4577.61
[INFO 2017-06-26 21:45:38,962 main.py:47] epoch 665, training loss: 4119.88, average training loss: 5580.85, base loss: 4577.88
[INFO 2017-06-26 21:45:39,345 main.py:47] epoch 666, training loss: 4061.29, average training loss: 5578.57, base loss: 4578.02
[INFO 2017-06-26 21:45:39,729 main.py:47] epoch 667, training loss: 3158.10, average training loss: 5574.95, base loss: 4576.47
[INFO 2017-06-26 21:45:40,112 main.py:47] epoch 668, training loss: 3857.39, average training loss: 5572.38, base loss: 4576.49
[INFO 2017-06-26 21:45:40,494 main.py:47] epoch 669, training loss: 4031.87, average training loss: 5570.08, base loss: 4576.77
[INFO 2017-06-26 21:45:40,883 main.py:47] epoch 670, training loss: 3405.51, average training loss: 5566.86, base loss: 4575.78
[INFO 2017-06-26 21:45:41,273 main.py:47] epoch 671, training loss: 4345.03, average training loss: 5565.04, base loss: 4576.22
[INFO 2017-06-26 21:45:41,659 main.py:47] epoch 672, training loss: 3857.95, average training loss: 5562.50, base loss: 4576.07
[INFO 2017-06-26 21:45:42,043 main.py:47] epoch 673, training loss: 4262.74, average training loss: 5560.57, base loss: 4576.74
[INFO 2017-06-26 21:45:42,426 main.py:47] epoch 674, training loss: 3602.86, average training loss: 5557.67, base loss: 4575.91
[INFO 2017-06-26 21:45:42,813 main.py:47] epoch 675, training loss: 3725.29, average training loss: 5554.96, base loss: 4575.85
[INFO 2017-06-26 21:45:43,195 main.py:47] epoch 676, training loss: 6967.31, average training loss: 5557.05, base loss: 4579.91
[INFO 2017-06-26 21:45:43,580 main.py:47] epoch 677, training loss: 4188.09, average training loss: 5555.03, base loss: 4580.53
[INFO 2017-06-26 21:45:43,964 main.py:47] epoch 678, training loss: 3905.61, average training loss: 5552.60, base loss: 4580.45
[INFO 2017-06-26 21:45:44,350 main.py:47] epoch 679, training loss: 3966.65, average training loss: 5550.27, base loss: 4580.69
[INFO 2017-06-26 21:45:44,771 main.py:47] epoch 680, training loss: 3874.50, average training loss: 5547.81, base loss: 4580.73
[INFO 2017-06-26 21:45:45,207 main.py:47] epoch 681, training loss: 3845.13, average training loss: 5545.31, base loss: 4580.60
[INFO 2017-06-26 21:45:45,595 main.py:47] epoch 682, training loss: 4223.76, average training loss: 5543.37, base loss: 4580.93
[INFO 2017-06-26 21:45:45,988 main.py:47] epoch 683, training loss: 3665.54, average training loss: 5540.63, base loss: 4580.41
[INFO 2017-06-26 21:45:46,372 main.py:47] epoch 684, training loss: 3314.55, average training loss: 5537.38, base loss: 4579.28
[INFO 2017-06-26 21:45:46,757 main.py:47] epoch 685, training loss: 4092.53, average training loss: 5535.27, base loss: 4579.88
[INFO 2017-06-26 21:45:47,143 main.py:47] epoch 686, training loss: 4168.95, average training loss: 5533.28, base loss: 4580.29
[INFO 2017-06-26 21:45:47,526 main.py:47] epoch 687, training loss: 3643.63, average training loss: 5530.54, base loss: 4579.69
[INFO 2017-06-26 21:45:47,911 main.py:47] epoch 688, training loss: 3822.20, average training loss: 5528.06, base loss: 4579.44
[INFO 2017-06-26 21:45:48,296 main.py:47] epoch 689, training loss: 4234.83, average training loss: 5526.18, base loss: 4580.10
[INFO 2017-06-26 21:45:48,785 main.py:47] epoch 690, training loss: 3770.06, average training loss: 5523.64, base loss: 4579.87
[INFO 2017-06-26 21:45:49,172 main.py:47] epoch 691, training loss: 4261.06, average training loss: 5521.82, base loss: 4580.44
[INFO 2017-06-26 21:45:49,617 main.py:47] epoch 692, training loss: 3351.22, average training loss: 5518.69, base loss: 4579.09
[INFO 2017-06-26 21:45:50,023 main.py:47] epoch 693, training loss: 3987.22, average training loss: 5516.48, base loss: 4579.22
[INFO 2017-06-26 21:45:50,411 main.py:47] epoch 694, training loss: 3939.58, average training loss: 5514.21, base loss: 4579.74
[INFO 2017-06-26 21:45:50,802 main.py:47] epoch 695, training loss: 3547.53, average training loss: 5511.38, base loss: 4578.52
[INFO 2017-06-26 21:45:51,187 main.py:47] epoch 696, training loss: 3207.27, average training loss: 5508.08, base loss: 4577.01
[INFO 2017-06-26 21:45:51,568 main.py:47] epoch 697, training loss: 3761.89, average training loss: 5505.58, base loss: 4576.63
[INFO 2017-06-26 21:45:51,948 main.py:47] epoch 698, training loss: 3178.05, average training loss: 5502.25, base loss: 4575.13
[INFO 2017-06-26 21:45:52,332 main.py:47] epoch 699, training loss: 3649.46, average training loss: 5499.60, base loss: 4574.68
[INFO 2017-06-26 21:45:52,332 main.py:49] epoch 699, testing
[INFO 2017-06-26 21:45:53,829 main.py:101] average testing loss: 3909.27, base loss: 4503.88, improve_loss: 594.61
[INFO 2017-06-26 21:45:53,829 main.py:73] current best improved loss: 667.40
[INFO 2017-06-26 21:45:54,210 main.py:47] epoch 700, training loss: 4096.82, average training loss: 5497.60, base loss: 4574.75
[INFO 2017-06-26 21:45:54,591 main.py:47] epoch 701, training loss: 3959.48, average training loss: 5495.41, base loss: 4575.14
[INFO 2017-06-26 21:45:54,974 main.py:47] epoch 702, training loss: 3640.69, average training loss: 5492.77, base loss: 4574.50
[INFO 2017-06-26 21:45:55,358 main.py:47] epoch 703, training loss: 3948.86, average training loss: 5490.58, base loss: 4574.53
[INFO 2017-06-26 21:45:55,740 main.py:47] epoch 704, training loss: 3557.12, average training loss: 5487.83, base loss: 4573.59
[INFO 2017-06-26 21:45:56,124 main.py:47] epoch 705, training loss: 3880.80, average training loss: 5485.56, base loss: 4573.84
[INFO 2017-06-26 21:45:56,511 main.py:47] epoch 706, training loss: 3920.49, average training loss: 5483.34, base loss: 4573.65
[INFO 2017-06-26 21:45:56,895 main.py:47] epoch 707, training loss: 3478.11, average training loss: 5480.51, base loss: 4572.82
[INFO 2017-06-26 21:45:57,283 main.py:47] epoch 708, training loss: 3616.60, average training loss: 5477.88, base loss: 4572.25
[INFO 2017-06-26 21:45:57,674 main.py:47] epoch 709, training loss: 4162.11, average training loss: 5476.03, base loss: 4572.64
[INFO 2017-06-26 21:45:58,060 main.py:47] epoch 710, training loss: 4495.44, average training loss: 5474.65, base loss: 4573.58
[INFO 2017-06-26 21:45:58,444 main.py:47] epoch 711, training loss: 3650.32, average training loss: 5472.09, base loss: 4573.11
[INFO 2017-06-26 21:45:58,827 main.py:47] epoch 712, training loss: 3013.86, average training loss: 5468.64, base loss: 4571.22
[INFO 2017-06-26 21:45:59,214 main.py:47] epoch 713, training loss: 3741.44, average training loss: 5466.22, base loss: 4570.87
[INFO 2017-06-26 21:45:59,594 main.py:47] epoch 714, training loss: 3689.98, average training loss: 5463.74, base loss: 4570.49
[INFO 2017-06-26 21:45:59,982 main.py:47] epoch 715, training loss: 4365.85, average training loss: 5462.20, base loss: 4571.34
[INFO 2017-06-26 21:46:00,364 main.py:47] epoch 716, training loss: 3941.01, average training loss: 5460.08, base loss: 4571.41
[INFO 2017-06-26 21:46:00,748 main.py:47] epoch 717, training loss: 3897.29, average training loss: 5457.91, base loss: 4571.48
[INFO 2017-06-26 21:46:01,132 main.py:47] epoch 718, training loss: 3469.13, average training loss: 5455.14, base loss: 4570.47
[INFO 2017-06-26 21:46:01,518 main.py:47] epoch 719, training loss: 3752.19, average training loss: 5452.78, base loss: 4570.23
[INFO 2017-06-26 21:46:01,901 main.py:47] epoch 720, training loss: 4706.78, average training loss: 5451.74, base loss: 4571.28
[INFO 2017-06-26 21:46:02,297 main.py:47] epoch 721, training loss: 4060.48, average training loss: 5449.81, base loss: 4571.40
[INFO 2017-06-26 21:46:02,683 main.py:47] epoch 722, training loss: 3688.85, average training loss: 5447.38, base loss: 4570.79
[INFO 2017-06-26 21:46:03,066 main.py:47] epoch 723, training loss: 3561.06, average training loss: 5444.77, base loss: 4570.06
[INFO 2017-06-26 21:46:03,444 main.py:47] epoch 724, training loss: 4404.77, average training loss: 5443.34, base loss: 4571.25
[INFO 2017-06-26 21:46:03,830 main.py:47] epoch 725, training loss: 3397.20, average training loss: 5440.52, base loss: 4570.31
[INFO 2017-06-26 21:46:04,218 main.py:47] epoch 726, training loss: 3444.40, average training loss: 5437.77, base loss: 4569.42
[INFO 2017-06-26 21:46:04,610 main.py:47] epoch 727, training loss: 3452.93, average training loss: 5435.05, base loss: 4568.61
[INFO 2017-06-26 21:46:05,053 main.py:47] epoch 728, training loss: 10843.47, average training loss: 5442.47, base loss: 4577.90
[INFO 2017-06-26 21:46:05,444 main.py:47] epoch 729, training loss: 3491.17, average training loss: 5439.79, base loss: 4577.22
[INFO 2017-06-26 21:46:05,915 main.py:47] epoch 730, training loss: 3559.71, average training loss: 5437.22, base loss: 4576.46
[INFO 2017-06-26 21:46:06,326 main.py:47] epoch 731, training loss: 3391.67, average training loss: 5434.43, base loss: 4575.48
[INFO 2017-06-26 21:46:06,800 main.py:47] epoch 732, training loss: 3058.29, average training loss: 5431.19, base loss: 4573.99
[INFO 2017-06-26 21:46:07,221 main.py:47] epoch 733, training loss: 4976.19, average training loss: 5430.57, base loss: 4576.13
[INFO 2017-06-26 21:46:07,677 main.py:47] epoch 734, training loss: 4460.53, average training loss: 5429.25, base loss: 4577.61
[INFO 2017-06-26 21:46:08,084 main.py:47] epoch 735, training loss: 3731.93, average training loss: 5426.94, base loss: 4577.49
[INFO 2017-06-26 21:46:08,477 main.py:47] epoch 736, training loss: 3579.49, average training loss: 5424.43, base loss: 4577.09
[INFO 2017-06-26 21:46:08,863 main.py:47] epoch 737, training loss: 4053.83, average training loss: 5422.58, base loss: 4577.22
[INFO 2017-06-26 21:46:09,353 main.py:47] epoch 738, training loss: 4151.42, average training loss: 5420.86, base loss: 4577.58
[INFO 2017-06-26 21:46:09,745 main.py:47] epoch 739, training loss: 3718.72, average training loss: 5418.56, base loss: 4577.73
[INFO 2017-06-26 21:46:10,155 main.py:47] epoch 740, training loss: 4001.21, average training loss: 5416.64, base loss: 4578.24
[INFO 2017-06-26 21:46:10,571 main.py:47] epoch 741, training loss: 3444.08, average training loss: 5413.98, base loss: 4577.41
[INFO 2017-06-26 21:46:10,958 main.py:47] epoch 742, training loss: 3797.94, average training loss: 5411.81, base loss: 4577.07
[INFO 2017-06-26 21:46:11,348 main.py:47] epoch 743, training loss: 4193.55, average training loss: 5410.17, base loss: 4577.62
[INFO 2017-06-26 21:46:11,733 main.py:47] epoch 744, training loss: 3915.71, average training loss: 5408.17, base loss: 4577.46
[INFO 2017-06-26 21:46:12,122 main.py:47] epoch 745, training loss: 4200.88, average training loss: 5406.55, base loss: 4577.95
[INFO 2017-06-26 21:46:12,570 main.py:47] epoch 746, training loss: 3787.59, average training loss: 5404.38, base loss: 4577.81
[INFO 2017-06-26 21:46:12,977 main.py:47] epoch 747, training loss: 4075.01, average training loss: 5402.60, base loss: 4577.85
[INFO 2017-06-26 21:46:13,429 main.py:47] epoch 748, training loss: 3917.68, average training loss: 5400.62, base loss: 4577.82
[INFO 2017-06-26 21:46:13,849 main.py:47] epoch 749, training loss: 3865.72, average training loss: 5398.57, base loss: 4577.65
[INFO 2017-06-26 21:46:14,237 main.py:47] epoch 750, training loss: 3451.55, average training loss: 5395.98, base loss: 4576.99
[INFO 2017-06-26 21:46:14,666 main.py:47] epoch 751, training loss: 6980.46, average training loss: 5398.09, base loss: 4580.86
[INFO 2017-06-26 21:46:15,084 main.py:47] epoch 752, training loss: 4303.36, average training loss: 5396.63, base loss: 4581.57
[INFO 2017-06-26 21:46:15,472 main.py:47] epoch 753, training loss: 3360.93, average training loss: 5393.93, base loss: 4580.61
[INFO 2017-06-26 21:46:15,929 main.py:47] epoch 754, training loss: 3774.95, average training loss: 5391.79, base loss: 4580.31
[INFO 2017-06-26 21:46:16,315 main.py:47] epoch 755, training loss: 3324.60, average training loss: 5389.06, base loss: 4579.32
[INFO 2017-06-26 21:46:16,800 main.py:47] epoch 756, training loss: 4363.08, average training loss: 5387.70, base loss: 4580.40
[INFO 2017-06-26 21:46:17,189 main.py:47] epoch 757, training loss: 7045.60, average training loss: 5389.89, base loss: 4584.24
[INFO 2017-06-26 21:46:17,576 main.py:47] epoch 758, training loss: 3951.74, average training loss: 5387.99, base loss: 4584.52
[INFO 2017-06-26 21:46:17,961 main.py:47] epoch 759, training loss: 3666.49, average training loss: 5385.73, base loss: 4584.00
[INFO 2017-06-26 21:46:18,362 main.py:47] epoch 760, training loss: 4363.71, average training loss: 5384.38, base loss: 4584.85
[INFO 2017-06-26 21:46:18,776 main.py:47] epoch 761, training loss: 3550.39, average training loss: 5381.98, base loss: 4583.96
[INFO 2017-06-26 21:46:19,165 main.py:47] epoch 762, training loss: 4026.42, average training loss: 5380.20, base loss: 4584.28
[INFO 2017-06-26 21:46:19,656 main.py:47] epoch 763, training loss: 3423.61, average training loss: 5377.64, base loss: 4583.37
[INFO 2017-06-26 21:46:20,045 main.py:47] epoch 764, training loss: 3865.92, average training loss: 5375.66, base loss: 4583.38
[INFO 2017-06-26 21:46:20,436 main.py:47] epoch 765, training loss: 3328.03, average training loss: 5372.99, base loss: 4582.29
[INFO 2017-06-26 21:46:20,845 main.py:47] epoch 766, training loss: 3723.62, average training loss: 5370.84, base loss: 4582.35
[INFO 2017-06-26 21:46:21,260 main.py:47] epoch 767, training loss: 4317.91, average training loss: 5369.47, base loss: 4582.97
[INFO 2017-06-26 21:46:21,652 main.py:47] epoch 768, training loss: 4122.69, average training loss: 5367.85, base loss: 4583.49
[INFO 2017-06-26 21:46:22,050 main.py:47] epoch 769, training loss: 3265.73, average training loss: 5365.12, base loss: 4582.33
[INFO 2017-06-26 21:46:22,436 main.py:47] epoch 770, training loss: 3729.13, average training loss: 5363.00, base loss: 4581.90
[INFO 2017-06-26 21:46:22,821 main.py:47] epoch 771, training loss: 3657.65, average training loss: 5360.79, base loss: 4581.27
[INFO 2017-06-26 21:46:23,287 main.py:47] epoch 772, training loss: 4388.37, average training loss: 5359.53, base loss: 4582.14
[INFO 2017-06-26 21:46:23,689 main.py:47] epoch 773, training loss: 3712.51, average training loss: 5357.40, base loss: 4581.85
[INFO 2017-06-26 21:46:24,085 main.py:47] epoch 774, training loss: 3578.37, average training loss: 5355.11, base loss: 4581.40
[INFO 2017-06-26 21:46:24,489 main.py:47] epoch 775, training loss: 3930.73, average training loss: 5353.27, base loss: 4581.46
[INFO 2017-06-26 21:46:24,910 main.py:47] epoch 776, training loss: 7527.75, average training loss: 5356.07, base loss: 4586.34
[INFO 2017-06-26 21:46:25,302 main.py:47] epoch 777, training loss: 3767.48, average training loss: 5354.03, base loss: 4586.08
[INFO 2017-06-26 21:46:25,688 main.py:47] epoch 778, training loss: 3500.87, average training loss: 5351.65, base loss: 4585.66
[INFO 2017-06-26 21:46:26,171 main.py:47] epoch 779, training loss: 4176.69, average training loss: 5350.14, base loss: 4586.25
[INFO 2017-06-26 21:46:26,577 main.py:47] epoch 780, training loss: 3872.71, average training loss: 5348.25, base loss: 4586.06
[INFO 2017-06-26 21:46:26,972 main.py:47] epoch 781, training loss: 3824.74, average training loss: 5346.30, base loss: 4585.98
[INFO 2017-06-26 21:46:27,359 main.py:47] epoch 782, training loss: 3335.26, average training loss: 5343.73, base loss: 4585.26
[INFO 2017-06-26 21:46:27,742 main.py:47] epoch 783, training loss: 3617.84, average training loss: 5341.53, base loss: 4585.06
[INFO 2017-06-26 21:46:28,130 main.py:47] epoch 784, training loss: 3857.56, average training loss: 5339.64, base loss: 4585.29
[INFO 2017-06-26 21:46:28,547 main.py:47] epoch 785, training loss: 3759.13, average training loss: 5337.63, base loss: 4585.23
[INFO 2017-06-26 21:46:28,933 main.py:47] epoch 786, training loss: 3649.76, average training loss: 5335.49, base loss: 4584.71
[INFO 2017-06-26 21:46:29,322 main.py:47] epoch 787, training loss: 3615.42, average training loss: 5333.30, base loss: 4584.64
[INFO 2017-06-26 21:46:29,707 main.py:47] epoch 788, training loss: 3789.84, average training loss: 5331.35, base loss: 4584.42
[INFO 2017-06-26 21:46:30,089 main.py:47] epoch 789, training loss: 4053.80, average training loss: 5329.73, base loss: 4584.74
[INFO 2017-06-26 21:46:30,474 main.py:47] epoch 790, training loss: 3639.00, average training loss: 5327.59, base loss: 4584.28
[INFO 2017-06-26 21:46:30,860 main.py:47] epoch 791, training loss: 4067.26, average training loss: 5326.00, base loss: 4584.41
[INFO 2017-06-26 21:46:31,244 main.py:47] epoch 792, training loss: 4231.84, average training loss: 5324.62, base loss: 4585.34
[INFO 2017-06-26 21:46:31,632 main.py:47] epoch 793, training loss: 3943.51, average training loss: 5322.88, base loss: 4585.14
[INFO 2017-06-26 21:46:32,015 main.py:47] epoch 794, training loss: 4020.96, average training loss: 5321.24, base loss: 4585.35
[INFO 2017-06-26 21:46:32,399 main.py:47] epoch 795, training loss: 3103.72, average training loss: 5318.46, base loss: 4584.11
[INFO 2017-06-26 21:46:32,780 main.py:47] epoch 796, training loss: 4044.38, average training loss: 5316.86, base loss: 4584.59
[INFO 2017-06-26 21:46:33,160 main.py:47] epoch 797, training loss: 4023.18, average training loss: 5315.24, base loss: 4585.05
[INFO 2017-06-26 21:46:33,560 main.py:47] epoch 798, training loss: 3703.04, average training loss: 5313.22, base loss: 4584.89
[INFO 2017-06-26 21:46:33,952 main.py:47] epoch 799, training loss: 3585.88, average training loss: 5311.06, base loss: 4584.25
[INFO 2017-06-26 21:46:33,952 main.py:49] epoch 799, testing
[INFO 2017-06-26 21:46:35,458 main.py:101] average testing loss: 3686.63, base loss: 4347.01, improve_loss: 660.38
[INFO 2017-06-26 21:46:35,458 main.py:73] current best improved loss: 667.40
[INFO 2017-06-26 21:46:35,846 main.py:47] epoch 800, training loss: 3940.39, average training loss: 5309.35, base loss: 4584.48
[INFO 2017-06-26 21:46:36,228 main.py:47] epoch 801, training loss: 4033.33, average training loss: 5307.76, base loss: 4584.89
[INFO 2017-06-26 21:46:36,611 main.py:47] epoch 802, training loss: 3171.12, average training loss: 5305.10, base loss: 4583.81
[INFO 2017-06-26 21:46:36,993 main.py:47] epoch 803, training loss: 3329.33, average training loss: 5302.64, base loss: 4582.83
[INFO 2017-06-26 21:46:37,375 main.py:47] epoch 804, training loss: 3896.96, average training loss: 5300.90, base loss: 4583.15
[INFO 2017-06-26 21:46:37,758 main.py:47] epoch 805, training loss: 3848.69, average training loss: 5299.09, base loss: 4583.03
[INFO 2017-06-26 21:46:38,144 main.py:47] epoch 806, training loss: 3984.02, average training loss: 5297.46, base loss: 4583.40
[INFO 2017-06-26 21:46:38,525 main.py:47] epoch 807, training loss: 3505.68, average training loss: 5295.25, base loss: 4582.68
[INFO 2017-06-26 21:46:38,910 main.py:47] epoch 808, training loss: 3306.34, average training loss: 5292.79, base loss: 4581.93
[INFO 2017-06-26 21:46:39,293 main.py:47] epoch 809, training loss: 3599.67, average training loss: 5290.70, base loss: 4581.44
[INFO 2017-06-26 21:46:39,678 main.py:47] epoch 810, training loss: 3314.90, average training loss: 5288.26, base loss: 4580.49
[INFO 2017-06-26 21:46:40,064 main.py:47] epoch 811, training loss: 3276.04, average training loss: 5285.78, base loss: 4579.38
[INFO 2017-06-26 21:46:40,452 main.py:47] epoch 812, training loss: 7276.01, average training loss: 5288.23, base loss: 4583.36
[INFO 2017-06-26 21:46:40,837 main.py:47] epoch 813, training loss: 4071.22, average training loss: 5286.74, base loss: 4583.52
[INFO 2017-06-26 21:46:41,223 main.py:47] epoch 814, training loss: 4101.11, average training loss: 5285.28, base loss: 4583.74
[INFO 2017-06-26 21:46:41,608 main.py:47] epoch 815, training loss: 4409.98, average training loss: 5284.21, base loss: 4584.13
[INFO 2017-06-26 21:46:41,994 main.py:47] epoch 816, training loss: 3764.27, average training loss: 5282.35, base loss: 4583.77
[INFO 2017-06-26 21:46:42,473 main.py:47] epoch 817, training loss: 3190.96, average training loss: 5279.79, base loss: 4582.92
[INFO 2017-06-26 21:46:42,882 main.py:47] epoch 818, training loss: 4059.85, average training loss: 5278.30, base loss: 4583.23
[INFO 2017-06-26 21:46:43,295 main.py:47] epoch 819, training loss: 3925.42, average training loss: 5276.65, base loss: 4583.22
[INFO 2017-06-26 21:46:43,707 main.py:47] epoch 820, training loss: 4396.69, average training loss: 5275.58, base loss: 4584.02
[INFO 2017-06-26 21:46:44,094 main.py:47] epoch 821, training loss: 3672.57, average training loss: 5273.63, base loss: 4583.74
[INFO 2017-06-26 21:46:44,482 main.py:47] epoch 822, training loss: 3708.02, average training loss: 5271.73, base loss: 4583.68
[INFO 2017-06-26 21:46:44,906 main.py:47] epoch 823, training loss: 3369.93, average training loss: 5269.42, base loss: 4582.52
[INFO 2017-06-26 21:46:45,326 main.py:47] epoch 824, training loss: 3724.71, average training loss: 5267.55, base loss: 4582.32
[INFO 2017-06-26 21:46:45,729 main.py:47] epoch 825, training loss: 3461.85, average training loss: 5265.36, base loss: 4581.91
[INFO 2017-06-26 21:46:46,116 main.py:47] epoch 826, training loss: 4361.55, average training loss: 5264.27, base loss: 4582.68
[INFO 2017-06-26 21:46:46,504 main.py:47] epoch 827, training loss: 3958.66, average training loss: 5262.69, base loss: 4582.96
[INFO 2017-06-26 21:46:46,964 main.py:47] epoch 828, training loss: 4052.44, average training loss: 5261.23, base loss: 4583.58
[INFO 2017-06-26 21:46:47,391 main.py:47] epoch 829, training loss: 3827.45, average training loss: 5259.50, base loss: 4583.88
[INFO 2017-06-26 21:46:47,778 main.py:47] epoch 830, training loss: 3841.54, average training loss: 5257.80, base loss: 4583.73
[INFO 2017-06-26 21:46:48,268 main.py:47] epoch 831, training loss: 3684.02, average training loss: 5255.91, base loss: 4583.53
[INFO 2017-06-26 21:46:48,655 main.py:47] epoch 832, training loss: 4086.74, average training loss: 5254.50, base loss: 4584.07
[INFO 2017-06-26 21:46:49,139 main.py:47] epoch 833, training loss: 3587.53, average training loss: 5252.50, base loss: 4583.68
[INFO 2017-06-26 21:46:49,530 main.py:47] epoch 834, training loss: 3545.62, average training loss: 5250.46, base loss: 4583.11
[INFO 2017-06-26 21:46:49,926 main.py:47] epoch 835, training loss: 3780.45, average training loss: 5248.70, base loss: 4582.91
[INFO 2017-06-26 21:46:50,304 main.py:47] epoch 836, training loss: 3647.83, average training loss: 5246.79, base loss: 4582.68
[INFO 2017-06-26 21:46:50,693 main.py:47] epoch 837, training loss: 3909.60, average training loss: 5245.19, base loss: 4582.85
[INFO 2017-06-26 21:46:51,082 main.py:47] epoch 838, training loss: 4357.50, average training loss: 5244.14, base loss: 4583.86
[INFO 2017-06-26 21:46:51,496 main.py:47] epoch 839, training loss: 4019.58, average training loss: 5242.68, base loss: 4584.06
[INFO 2017-06-26 21:46:51,890 main.py:47] epoch 840, training loss: 3791.25, average training loss: 5240.95, base loss: 4584.03
[INFO 2017-06-26 21:46:52,280 main.py:47] epoch 841, training loss: 3848.12, average training loss: 5239.30, base loss: 4583.91
[INFO 2017-06-26 21:46:52,667 main.py:47] epoch 842, training loss: 3683.09, average training loss: 5237.45, base loss: 4583.39
[INFO 2017-06-26 21:46:53,050 main.py:47] epoch 843, training loss: 3696.33, average training loss: 5235.63, base loss: 4583.31
[INFO 2017-06-26 21:46:53,436 main.py:47] epoch 844, training loss: 3573.36, average training loss: 5233.66, base loss: 4582.79
[INFO 2017-06-26 21:46:53,820 main.py:47] epoch 845, training loss: 3490.32, average training loss: 5231.60, base loss: 4582.06
[INFO 2017-06-26 21:46:54,205 main.py:47] epoch 846, training loss: 3334.64, average training loss: 5229.36, base loss: 4581.35
[INFO 2017-06-26 21:46:54,584 main.py:47] epoch 847, training loss: 3374.77, average training loss: 5227.17, base loss: 4580.59
[INFO 2017-06-26 21:46:54,969 main.py:47] epoch 848, training loss: 3914.60, average training loss: 5225.62, base loss: 4580.64
[INFO 2017-06-26 21:46:55,357 main.py:47] epoch 849, training loss: 3556.25, average training loss: 5223.66, base loss: 4580.22
[INFO 2017-06-26 21:46:55,744 main.py:47] epoch 850, training loss: 2975.71, average training loss: 5221.02, base loss: 4578.64
[INFO 2017-06-26 21:46:56,129 main.py:47] epoch 851, training loss: 3398.09, average training loss: 5218.88, base loss: 4578.12
[INFO 2017-06-26 21:46:56,516 main.py:47] epoch 852, training loss: 3936.51, average training loss: 5217.38, base loss: 4578.01
[INFO 2017-06-26 21:46:56,973 main.py:47] epoch 853, training loss: 4318.60, average training loss: 5216.32, base loss: 4578.62
[INFO 2017-06-26 21:46:57,381 main.py:47] epoch 854, training loss: 4311.08, average training loss: 5215.27, base loss: 4579.28
[INFO 2017-06-26 21:46:57,813 main.py:47] epoch 855, training loss: 6738.22, average training loss: 5217.04, base loss: 4582.32
[INFO 2017-06-26 21:46:58,234 main.py:47] epoch 856, training loss: 4255.64, average training loss: 5215.92, base loss: 4582.67
[INFO 2017-06-26 21:46:58,623 main.py:47] epoch 857, training loss: 3356.97, average training loss: 5213.76, base loss: 4581.93
[INFO 2017-06-26 21:46:59,059 main.py:47] epoch 858, training loss: 3718.42, average training loss: 5212.02, base loss: 4581.74
[INFO 2017-06-26 21:46:59,483 main.py:47] epoch 859, training loss: 4021.86, average training loss: 5210.63, base loss: 4582.22
[INFO 2017-06-26 21:46:59,870 main.py:47] epoch 860, training loss: 3889.36, average training loss: 5209.10, base loss: 4582.58
[INFO 2017-06-26 21:47:00,256 main.py:47] epoch 861, training loss: 3473.05, average training loss: 5207.08, base loss: 4582.07
[INFO 2017-06-26 21:47:00,644 main.py:47] epoch 862, training loss: 3713.40, average training loss: 5205.35, base loss: 4582.12
[INFO 2017-06-26 21:47:01,064 main.py:47] epoch 863, training loss: 3778.42, average training loss: 5203.70, base loss: 4582.24
[INFO 2017-06-26 21:47:01,446 main.py:47] epoch 864, training loss: 3726.75, average training loss: 5201.99, base loss: 4581.94
[INFO 2017-06-26 21:47:01,832 main.py:47] epoch 865, training loss: 4016.01, average training loss: 5200.62, base loss: 4582.15
[INFO 2017-06-26 21:47:02,220 main.py:47] epoch 866, training loss: 3939.19, average training loss: 5199.17, base loss: 4582.55
[INFO 2017-06-26 21:47:02,605 main.py:47] epoch 867, training loss: 3800.69, average training loss: 5197.56, base loss: 4582.89
[INFO 2017-06-26 21:47:02,985 main.py:47] epoch 868, training loss: 3869.33, average training loss: 5196.03, base loss: 4582.80
[INFO 2017-06-26 21:47:03,365 main.py:47] epoch 869, training loss: 4426.95, average training loss: 5195.14, base loss: 4583.99
[INFO 2017-06-26 21:47:03,745 main.py:47] epoch 870, training loss: 4028.13, average training loss: 5193.81, base loss: 4584.30
[INFO 2017-06-26 21:47:04,126 main.py:47] epoch 871, training loss: 3508.89, average training loss: 5191.87, base loss: 4584.01
[INFO 2017-06-26 21:47:04,512 main.py:47] epoch 872, training loss: 3123.75, average training loss: 5189.50, base loss: 4582.55
[INFO 2017-06-26 21:47:04,895 main.py:47] epoch 873, training loss: 4086.35, average training loss: 5188.24, base loss: 4582.64
[INFO 2017-06-26 21:47:05,278 main.py:47] epoch 874, training loss: 3893.61, average training loss: 5186.76, base loss: 4582.70
[INFO 2017-06-26 21:47:05,664 main.py:47] epoch 875, training loss: 3667.88, average training loss: 5185.03, base loss: 4582.19
[INFO 2017-06-26 21:47:06,047 main.py:47] epoch 876, training loss: 3247.46, average training loss: 5182.82, base loss: 4581.25
[INFO 2017-06-26 21:47:06,430 main.py:47] epoch 877, training loss: 4306.04, average training loss: 5181.82, base loss: 4581.70
[INFO 2017-06-26 21:47:06,815 main.py:47] epoch 878, training loss: 4086.51, average training loss: 5180.57, base loss: 4582.28
[INFO 2017-06-26 21:47:07,202 main.py:47] epoch 879, training loss: 3474.63, average training loss: 5178.64, base loss: 4581.93
[INFO 2017-06-26 21:47:07,588 main.py:47] epoch 880, training loss: 3397.84, average training loss: 5176.61, base loss: 4581.22
[INFO 2017-06-26 21:47:07,980 main.py:47] epoch 881, training loss: 3667.99, average training loss: 5174.90, base loss: 4580.95
[INFO 2017-06-26 21:47:08,368 main.py:47] epoch 882, training loss: 3498.57, average training loss: 5173.01, base loss: 4580.33
[INFO 2017-06-26 21:47:08,752 main.py:47] epoch 883, training loss: 3710.19, average training loss: 5171.35, base loss: 4580.16
[INFO 2017-06-26 21:47:09,220 main.py:47] epoch 884, training loss: 3645.97, average training loss: 5169.63, base loss: 4579.93
[INFO 2017-06-26 21:47:09,626 main.py:47] epoch 885, training loss: 3870.00, average training loss: 5168.16, base loss: 4580.33
[INFO 2017-06-26 21:47:10,017 main.py:47] epoch 886, training loss: 3694.32, average training loss: 5166.50, base loss: 4580.29
[INFO 2017-06-26 21:47:10,484 main.py:47] epoch 887, training loss: 4250.77, average training loss: 5165.47, base loss: 4580.87
[INFO 2017-06-26 21:47:10,883 main.py:47] epoch 888, training loss: 4322.76, average training loss: 5164.52, base loss: 4581.37
[INFO 2017-06-26 21:47:11,277 main.py:47] epoch 889, training loss: 3679.76, average training loss: 5162.85, base loss: 4581.19
[INFO 2017-06-26 21:47:11,669 main.py:47] epoch 890, training loss: 3676.33, average training loss: 5161.18, base loss: 4580.96
[INFO 2017-06-26 21:47:12,053 main.py:47] epoch 891, training loss: 4407.67, average training loss: 5160.34, base loss: 4581.89
[INFO 2017-06-26 21:47:12,463 main.py:47] epoch 892, training loss: 3657.61, average training loss: 5158.66, base loss: 4581.60
[INFO 2017-06-26 21:47:12,848 main.py:47] epoch 893, training loss: 3269.35, average training loss: 5156.54, base loss: 4580.46
[INFO 2017-06-26 21:47:13,236 main.py:47] epoch 894, training loss: 3882.83, average training loss: 5155.12, base loss: 4580.60
[INFO 2017-06-26 21:47:13,619 main.py:47] epoch 895, training loss: 3577.52, average training loss: 5153.36, base loss: 4580.15
[INFO 2017-06-26 21:47:14,004 main.py:47] epoch 896, training loss: 3288.30, average training loss: 5151.28, base loss: 4579.20
[INFO 2017-06-26 21:47:14,388 main.py:47] epoch 897, training loss: 3635.05, average training loss: 5149.59, base loss: 4578.87
[INFO 2017-06-26 21:47:14,769 main.py:47] epoch 898, training loss: 3252.64, average training loss: 5147.48, base loss: 4578.13
[INFO 2017-06-26 21:47:15,152 main.py:47] epoch 899, training loss: 4493.38, average training loss: 5146.75, base loss: 4579.10
[INFO 2017-06-26 21:47:15,153 main.py:49] epoch 899, testing
[INFO 2017-06-26 21:47:16,649 main.py:101] average testing loss: 3589.38, base loss: 4195.61, improve_loss: 606.23
[INFO 2017-06-26 21:47:16,650 main.py:73] current best improved loss: 667.40
[INFO 2017-06-26 21:47:17,033 main.py:47] epoch 900, training loss: 3529.54, average training loss: 5144.96, base loss: 4578.67
[INFO 2017-06-26 21:47:17,416 main.py:47] epoch 901, training loss: 3640.51, average training loss: 5143.29, base loss: 4578.40
[INFO 2017-06-26 21:47:17,800 main.py:47] epoch 902, training loss: 3290.29, average training loss: 5141.24, base loss: 4577.52
[INFO 2017-06-26 21:47:18,183 main.py:47] epoch 903, training loss: 3893.61, average training loss: 5139.86, base loss: 4577.61
[INFO 2017-06-26 21:47:18,570 main.py:47] epoch 904, training loss: 4595.26, average training loss: 5139.26, base loss: 4578.86
[INFO 2017-06-26 21:47:18,953 main.py:47] epoch 905, training loss: 3366.45, average training loss: 5137.30, base loss: 4577.71
[INFO 2017-06-26 21:47:19,415 main.py:47] epoch 906, training loss: 3672.92, average training loss: 5135.69, base loss: 4577.54
[INFO 2017-06-26 21:47:19,815 main.py:47] epoch 907, training loss: 3628.10, average training loss: 5134.03, base loss: 4577.42
[INFO 2017-06-26 21:47:20,204 main.py:47] epoch 908, training loss: 3983.17, average training loss: 5132.76, base loss: 4577.93
[INFO 2017-06-26 21:47:20,594 main.py:47] epoch 909, training loss: 3699.57, average training loss: 5131.18, base loss: 4577.59
[INFO 2017-06-26 21:47:20,981 main.py:47] epoch 910, training loss: 3131.15, average training loss: 5128.99, base loss: 4576.43
[INFO 2017-06-26 21:47:21,366 main.py:47] epoch 911, training loss: 3181.95, average training loss: 5126.85, base loss: 4575.56
[INFO 2017-06-26 21:47:21,746 main.py:47] epoch 912, training loss: 3446.83, average training loss: 5125.01, base loss: 4574.85
[INFO 2017-06-26 21:47:22,136 main.py:47] epoch 913, training loss: 3640.71, average training loss: 5123.39, base loss: 4574.51
[INFO 2017-06-26 21:47:22,519 main.py:47] epoch 914, training loss: 3905.76, average training loss: 5122.06, base loss: 4574.67
[INFO 2017-06-26 21:47:22,907 main.py:47] epoch 915, training loss: 3559.71, average training loss: 5120.35, base loss: 4574.42
[INFO 2017-06-26 21:47:23,293 main.py:47] epoch 916, training loss: 4225.99, average training loss: 5119.38, base loss: 4574.77
[INFO 2017-06-26 21:47:23,676 main.py:47] epoch 917, training loss: 4435.48, average training loss: 5118.63, base loss: 4575.53
[INFO 2017-06-26 21:47:24,060 main.py:47] epoch 918, training loss: 3167.09, average training loss: 5116.51, base loss: 4574.50
[INFO 2017-06-26 21:47:24,444 main.py:47] epoch 919, training loss: 3794.18, average training loss: 5115.07, base loss: 4574.39
[INFO 2017-06-26 21:47:24,824 main.py:47] epoch 920, training loss: 3722.46, average training loss: 5113.56, base loss: 4574.43
[INFO 2017-06-26 21:47:25,214 main.py:47] epoch 921, training loss: 3576.42, average training loss: 5111.89, base loss: 4573.80
[INFO 2017-06-26 21:47:25,601 main.py:47] epoch 922, training loss: 3628.69, average training loss: 5110.29, base loss: 4573.42
[INFO 2017-06-26 21:47:25,987 main.py:47] epoch 923, training loss: 3347.19, average training loss: 5108.38, base loss: 4572.67
[INFO 2017-06-26 21:47:26,373 main.py:47] epoch 924, training loss: 7229.54, average training loss: 5110.67, base loss: 4576.39
[INFO 2017-06-26 21:47:26,761 main.py:47] epoch 925, training loss: 3409.42, average training loss: 5108.83, base loss: 4575.96
[INFO 2017-06-26 21:47:27,150 main.py:47] epoch 926, training loss: 3345.17, average training loss: 5106.93, base loss: 4575.38
[INFO 2017-06-26 21:47:27,535 main.py:47] epoch 927, training loss: 3629.83, average training loss: 5105.34, base loss: 4575.04
[INFO 2017-06-26 21:47:27,920 main.py:47] epoch 928, training loss: 3117.13, average training loss: 5103.20, base loss: 4574.02
[INFO 2017-06-26 21:47:28,305 main.py:47] epoch 929, training loss: 4220.03, average training loss: 5102.25, base loss: 4574.78
[INFO 2017-06-26 21:47:28,779 main.py:47] epoch 930, training loss: 3797.08, average training loss: 5100.85, base loss: 4574.81
[INFO 2017-06-26 21:47:29,188 main.py:47] epoch 931, training loss: 4037.97, average training loss: 5099.71, base loss: 4575.17
[INFO 2017-06-26 21:47:29,581 main.py:47] epoch 932, training loss: 3354.50, average training loss: 5097.84, base loss: 4574.34
[INFO 2017-06-26 21:47:29,967 main.py:47] epoch 933, training loss: 4093.62, average training loss: 5096.76, base loss: 4574.78
[INFO 2017-06-26 21:47:30,361 main.py:47] epoch 934, training loss: 3736.00, average training loss: 5095.31, base loss: 4574.39
[INFO 2017-06-26 21:47:30,754 main.py:47] epoch 935, training loss: 3766.64, average training loss: 5093.89, base loss: 4574.37
[INFO 2017-06-26 21:47:31,139 main.py:47] epoch 936, training loss: 4024.70, average training loss: 5092.75, base loss: 4574.76
[INFO 2017-06-26 21:47:31,523 main.py:47] epoch 937, training loss: 3620.28, average training loss: 5091.18, base loss: 4574.75
[INFO 2017-06-26 21:47:31,910 main.py:47] epoch 938, training loss: 4016.79, average training loss: 5090.03, base loss: 4575.43
[INFO 2017-06-26 21:47:32,293 main.py:47] epoch 939, training loss: 3565.69, average training loss: 5088.41, base loss: 4575.44
[INFO 2017-06-26 21:47:32,679 main.py:47] epoch 940, training loss: 3943.11, average training loss: 5087.19, base loss: 4575.96
[INFO 2017-06-26 21:47:33,063 main.py:47] epoch 941, training loss: 3772.09, average training loss: 5085.80, base loss: 4576.23
[INFO 2017-06-26 21:47:33,449 main.py:47] epoch 942, training loss: 3540.07, average training loss: 5084.16, base loss: 4575.74
[INFO 2017-06-26 21:47:33,834 main.py:47] epoch 943, training loss: 3550.92, average training loss: 5082.53, base loss: 4575.31
[INFO 2017-06-26 21:47:34,219 main.py:47] epoch 944, training loss: 3522.14, average training loss: 5080.88, base loss: 4574.87
[INFO 2017-06-26 21:47:34,605 main.py:47] epoch 945, training loss: 4820.88, average training loss: 5080.61, base loss: 4576.38
[INFO 2017-06-26 21:47:34,991 main.py:47] epoch 946, training loss: 3695.69, average training loss: 5079.15, base loss: 4576.22
[INFO 2017-06-26 21:47:35,374 main.py:47] epoch 947, training loss: 3705.13, average training loss: 5077.70, base loss: 4576.18
[INFO 2017-06-26 21:47:35,759 main.py:47] epoch 948, training loss: 3662.58, average training loss: 5076.20, base loss: 4576.11
[INFO 2017-06-26 21:47:36,141 main.py:47] epoch 949, training loss: 3716.46, average training loss: 5074.77, base loss: 4576.26
[INFO 2017-06-26 21:47:36,527 main.py:47] epoch 950, training loss: 3744.23, average training loss: 5073.37, base loss: 4576.19
[INFO 2017-06-26 21:47:36,906 main.py:47] epoch 951, training loss: 3419.85, average training loss: 5071.64, base loss: 4575.62
[INFO 2017-06-26 21:47:37,294 main.py:47] epoch 952, training loss: 3804.86, average training loss: 5070.31, base loss: 4575.87
[INFO 2017-06-26 21:47:37,679 main.py:47] epoch 953, training loss: 3226.95, average training loss: 5068.38, base loss: 4575.06
[INFO 2017-06-26 21:47:38,064 main.py:47] epoch 954, training loss: 3337.00, average training loss: 5066.56, base loss: 4574.47
[INFO 2017-06-26 21:47:38,452 main.py:47] epoch 955, training loss: 4094.60, average training loss: 5065.55, base loss: 4574.80
[INFO 2017-06-26 21:47:38,838 main.py:47] epoch 956, training loss: 3938.56, average training loss: 5064.37, base loss: 4574.85
[INFO 2017-06-26 21:47:39,234 main.py:47] epoch 957, training loss: 3830.83, average training loss: 5063.08, base loss: 4575.10
[INFO 2017-06-26 21:47:39,619 main.py:47] epoch 958, training loss: 3642.81, average training loss: 5061.60, base loss: 4574.89
[INFO 2017-06-26 21:47:40,004 main.py:47] epoch 959, training loss: 3664.61, average training loss: 5060.14, base loss: 4574.64
[INFO 2017-06-26 21:47:40,390 main.py:47] epoch 960, training loss: 3569.37, average training loss: 5058.59, base loss: 4574.62
[INFO 2017-06-26 21:47:40,776 main.py:47] epoch 961, training loss: 3702.14, average training loss: 5057.18, base loss: 4574.65
[INFO 2017-06-26 21:47:41,162 main.py:47] epoch 962, training loss: 3867.94, average training loss: 5055.95, base loss: 4574.89
[INFO 2017-06-26 21:47:41,547 main.py:47] epoch 963, training loss: 3732.23, average training loss: 5054.58, base loss: 4574.83
[INFO 2017-06-26 21:47:41,932 main.py:47] epoch 964, training loss: 3893.17, average training loss: 5053.37, base loss: 4574.99
[INFO 2017-06-26 21:47:42,313 main.py:47] epoch 965, training loss: 4631.95, average training loss: 5052.94, base loss: 4576.22
[INFO 2017-06-26 21:47:42,693 main.py:47] epoch 966, training loss: 3527.07, average training loss: 5051.36, base loss: 4575.79
[INFO 2017-06-26 21:47:43,078 main.py:47] epoch 967, training loss: 3639.17, average training loss: 5049.90, base loss: 4575.39
[INFO 2017-06-26 21:47:43,463 main.py:47] epoch 968, training loss: 3612.54, average training loss: 5048.42, base loss: 4575.11
[INFO 2017-06-26 21:47:43,847 main.py:47] epoch 969, training loss: 3478.73, average training loss: 5046.80, base loss: 4574.64
[INFO 2017-06-26 21:47:44,232 main.py:47] epoch 970, training loss: 3633.49, average training loss: 5045.34, base loss: 4574.48
[INFO 2017-06-26 21:47:44,701 main.py:47] epoch 971, training loss: 3523.42, average training loss: 5043.78, base loss: 4574.13
[INFO 2017-06-26 21:47:45,091 main.py:47] epoch 972, training loss: 7266.82, average training loss: 5046.06, base loss: 4577.51
[INFO 2017-06-26 21:47:45,551 main.py:47] epoch 973, training loss: 3909.50, average training loss: 5044.89, base loss: 4577.83
[INFO 2017-06-26 21:47:45,959 main.py:47] epoch 974, training loss: 4323.92, average training loss: 5044.15, base loss: 4578.61
[INFO 2017-06-26 21:47:46,346 main.py:47] epoch 975, training loss: 3965.31, average training loss: 5043.05, base loss: 4578.86
[INFO 2017-06-26 21:47:46,733 main.py:47] epoch 976, training loss: 3549.92, average training loss: 5041.52, base loss: 4578.58
[INFO 2017-06-26 21:47:47,119 main.py:47] epoch 977, training loss: 4157.67, average training loss: 5040.62, base loss: 4578.84
[INFO 2017-06-26 21:47:47,522 main.py:47] epoch 978, training loss: 3056.81, average training loss: 5038.59, base loss: 4577.61
[INFO 2017-06-26 21:47:47,908 main.py:47] epoch 979, training loss: 7546.87, average training loss: 5041.15, base loss: 4581.36
[INFO 2017-06-26 21:47:48,296 main.py:47] epoch 980, training loss: 3753.54, average training loss: 5039.84, base loss: 4581.35
[INFO 2017-06-26 21:47:48,681 main.py:47] epoch 981, training loss: 4007.20, average training loss: 5038.79, base loss: 4581.68
[INFO 2017-06-26 21:47:49,068 main.py:47] epoch 982, training loss: 3656.42, average training loss: 5037.38, base loss: 4581.35
[INFO 2017-06-26 21:47:49,454 main.py:47] epoch 983, training loss: 3732.54, average training loss: 5036.05, base loss: 4581.04
[INFO 2017-06-26 21:47:49,839 main.py:47] epoch 984, training loss: 3987.33, average training loss: 5034.99, base loss: 4581.31
[INFO 2017-06-26 21:47:50,225 main.py:47] epoch 985, training loss: 5079.31, average training loss: 5035.03, base loss: 4582.89
[INFO 2017-06-26 21:47:50,614 main.py:47] epoch 986, training loss: 3428.19, average training loss: 5033.41, base loss: 4582.38
[INFO 2017-06-26 21:47:51,005 main.py:47] epoch 987, training loss: 3220.92, average training loss: 5031.57, base loss: 4581.42
[INFO 2017-06-26 21:47:51,392 main.py:47] epoch 988, training loss: 3218.53, average training loss: 5029.74, base loss: 4580.70
[INFO 2017-06-26 21:47:51,778 main.py:47] epoch 989, training loss: 3922.93, average training loss: 5028.62, base loss: 4580.79
[INFO 2017-06-26 21:47:52,166 main.py:47] epoch 990, training loss: 3719.04, average training loss: 5027.30, base loss: 4580.86
[INFO 2017-06-26 21:47:52,553 main.py:47] epoch 991, training loss: 3342.11, average training loss: 5025.60, base loss: 4580.19
[INFO 2017-06-26 21:47:52,941 main.py:47] epoch 992, training loss: 3664.31, average training loss: 5024.23, base loss: 4580.25
[INFO 2017-06-26 21:47:53,330 main.py:47] epoch 993, training loss: 3807.95, average training loss: 5023.01, base loss: 4580.45
[INFO 2017-06-26 21:47:53,716 main.py:47] epoch 994, training loss: 3663.47, average training loss: 5021.64, base loss: 4580.28
[INFO 2017-06-26 21:47:54,104 main.py:47] epoch 995, training loss: 3663.46, average training loss: 5020.28, base loss: 4579.98
[INFO 2017-06-26 21:47:54,491 main.py:47] epoch 996, training loss: 4019.45, average training loss: 5019.27, base loss: 4580.33
[INFO 2017-06-26 21:47:54,878 main.py:47] epoch 997, training loss: 3853.55, average training loss: 5018.10, base loss: 4580.65
[INFO 2017-06-26 21:47:55,264 main.py:47] epoch 998, training loss: 4417.15, average training loss: 5017.50, base loss: 4581.51
[INFO 2017-06-26 21:47:55,651 main.py:47] epoch 999, training loss: 3938.76, average training loss: 5016.42, base loss: 4581.76
[INFO 2017-06-26 21:47:55,651 main.py:49] epoch 999, testing
[INFO 2017-06-26 21:47:57,232 main.py:101] average testing loss: 4055.69, base loss: 4772.98, improve_loss: 717.29
[INFO 2017-06-26 21:47:57,232 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:47:57,246 main.py:73] current best improved loss: 717.29
[INFO 2017-06-26 21:47:57,640 main.py:47] epoch 1000, training loss: 4101.18, average training loss: 4872.43, base loss: 4582.98
[INFO 2017-06-26 21:47:58,028 main.py:47] epoch 1001, training loss: 3803.64, average training loss: 4760.41, base loss: 4583.05
[INFO 2017-06-26 21:47:58,415 main.py:47] epoch 1002, training loss: 3725.09, average training loss: 4668.68, base loss: 4582.98
[INFO 2017-06-26 21:47:58,801 main.py:47] epoch 1003, training loss: 3496.26, average training loss: 4588.66, base loss: 4582.46
[INFO 2017-06-26 21:47:59,187 main.py:47] epoch 1004, training loss: 3738.91, average training loss: 4522.18, base loss: 4582.16
[INFO 2017-06-26 21:47:59,575 main.py:47] epoch 1005, training loss: 3623.19, average training loss: 4461.25, base loss: 4582.45
[INFO 2017-06-26 21:47:59,961 main.py:47] epoch 1006, training loss: 3756.47, average training loss: 4413.53, base loss: 4583.25
[INFO 2017-06-26 21:48:00,348 main.py:47] epoch 1007, training loss: 3768.79, average training loss: 4371.82, base loss: 4583.37
[INFO 2017-06-26 21:48:00,739 main.py:47] epoch 1008, training loss: 4027.02, average training loss: 4336.00, base loss: 4583.41
[INFO 2017-06-26 21:48:01,144 main.py:47] epoch 1009, training loss: 3991.95, average training loss: 4305.97, base loss: 4583.33
[INFO 2017-06-26 21:48:01,534 main.py:47] epoch 1010, training loss: 3619.01, average training loss: 4279.41, base loss: 4583.95
[INFO 2017-06-26 21:48:01,923 main.py:47] epoch 1011, training loss: 3767.36, average training loss: 4257.43, base loss: 4583.84
[INFO 2017-06-26 21:48:02,315 main.py:47] epoch 1012, training loss: 3585.90, average training loss: 4238.82, base loss: 4584.08
[INFO 2017-06-26 21:48:02,704 main.py:47] epoch 1013, training loss: 3550.90, average training loss: 4222.09, base loss: 4583.27
[INFO 2017-06-26 21:48:03,096 main.py:47] epoch 1014, training loss: 3754.31, average training loss: 4208.18, base loss: 4583.03
[INFO 2017-06-26 21:48:03,491 main.py:47] epoch 1015, training loss: 3386.45, average training loss: 4195.81, base loss: 4582.91
[INFO 2017-06-26 21:48:03,884 main.py:47] epoch 1016, training loss: 7721.81, average training loss: 4189.64, base loss: 4586.92
[INFO 2017-06-26 21:48:04,275 main.py:47] epoch 1017, training loss: 4205.53, average training loss: 4181.15, base loss: 4587.20
[INFO 2017-06-26 21:48:04,673 main.py:47] epoch 1018, training loss: 4269.19, average training loss: 4174.21, base loss: 4587.42
[INFO 2017-06-26 21:48:05,111 main.py:47] epoch 1019, training loss: 3660.77, average training loss: 4167.27, base loss: 4587.25
[INFO 2017-06-26 21:48:05,561 main.py:47] epoch 1020, training loss: 3439.56, average training loss: 4161.59, base loss: 4587.55
[INFO 2017-06-26 21:48:06,023 main.py:47] epoch 1021, training loss: 3355.99, average training loss: 4156.39, base loss: 4586.87
[INFO 2017-06-26 21:48:06,474 main.py:47] epoch 1022, training loss: 3799.04, average training loss: 4152.76, base loss: 4587.96
[INFO 2017-06-26 21:48:06,937 main.py:47] epoch 1023, training loss: 3423.30, average training loss: 4148.62, base loss: 4587.47
[INFO 2017-06-26 21:48:07,375 main.py:47] epoch 1024, training loss: 3972.61, average training loss: 4144.93, base loss: 4587.29
[INFO 2017-06-26 21:48:07,803 main.py:47] epoch 1025, training loss: 3930.59, average training loss: 4141.85, base loss: 4587.60
[INFO 2017-06-26 21:48:08,285 main.py:47] epoch 1026, training loss: 3276.24, average training loss: 4138.59, base loss: 4587.10
[INFO 2017-06-26 21:48:08,748 main.py:47] epoch 1027, training loss: 3707.12, average training loss: 4135.68, base loss: 4586.83
[INFO 2017-06-26 21:48:09,142 main.py:47] epoch 1028, training loss: 3570.04, average training loss: 4133.67, base loss: 4587.10
[INFO 2017-06-26 21:48:09,530 main.py:47] epoch 1029, training loss: 3597.44, average training loss: 4131.74, base loss: 4587.54
[INFO 2017-06-26 21:48:09,917 main.py:47] epoch 1030, training loss: 3753.22, average training loss: 4129.66, base loss: 4587.53
[INFO 2017-06-26 21:48:10,303 main.py:47] epoch 1031, training loss: 3421.70, average training loss: 4127.30, base loss: 4587.02
[INFO 2017-06-26 21:48:10,690 main.py:47] epoch 1032, training loss: 3445.53, average training loss: 4125.63, base loss: 4587.05
[INFO 2017-06-26 21:48:11,090 main.py:47] epoch 1033, training loss: 3579.72, average training loss: 4124.10, base loss: 4587.10
[INFO 2017-06-26 21:48:11,476 main.py:47] epoch 1034, training loss: 3478.43, average training loss: 4122.23, base loss: 4586.65
[INFO 2017-06-26 21:48:11,862 main.py:47] epoch 1035, training loss: 3647.57, average training loss: 4121.11, base loss: 4586.92
[INFO 2017-06-26 21:48:12,248 main.py:47] epoch 1036, training loss: 3733.25, average training loss: 4120.63, base loss: 4587.81
[INFO 2017-06-26 21:48:12,636 main.py:47] epoch 1037, training loss: 3878.71, average training loss: 4119.54, base loss: 4588.40
[INFO 2017-06-26 21:48:13,023 main.py:47] epoch 1038, training loss: 3470.09, average training loss: 4117.45, base loss: 4587.38
[INFO 2017-06-26 21:48:13,409 main.py:47] epoch 1039, training loss: 3835.71, average training loss: 4116.60, base loss: 4587.95
[INFO 2017-06-26 21:48:13,796 main.py:47] epoch 1040, training loss: 3481.89, average training loss: 4115.53, base loss: 4587.83
[INFO 2017-06-26 21:48:14,183 main.py:47] epoch 1041, training loss: 3744.75, average training loss: 4113.81, base loss: 4587.38
[INFO 2017-06-26 21:48:14,569 main.py:47] epoch 1042, training loss: 3655.15, average training loss: 4112.20, base loss: 4586.94
[INFO 2017-06-26 21:48:14,956 main.py:47] epoch 1043, training loss: 3045.78, average training loss: 4110.71, base loss: 4586.48
[INFO 2017-06-26 21:48:15,343 main.py:47] epoch 1044, training loss: 3662.12, average training loss: 4109.81, base loss: 4586.79
[INFO 2017-06-26 21:48:15,801 main.py:47] epoch 1045, training loss: 3463.23, average training loss: 4108.52, base loss: 4586.38
[INFO 2017-06-26 21:48:16,205 main.py:47] epoch 1046, training loss: 3787.46, average training loss: 4106.75, base loss: 4585.64
[INFO 2017-06-26 21:48:16,595 main.py:47] epoch 1047, training loss: 3683.14, average training loss: 4105.61, base loss: 4585.40
[INFO 2017-06-26 21:48:17,001 main.py:47] epoch 1048, training loss: 3564.18, average training loss: 4104.31, base loss: 4585.04
[INFO 2017-06-26 21:48:17,394 main.py:47] epoch 1049, training loss: 4083.11, average training loss: 4104.18, base loss: 4586.29
[INFO 2017-06-26 21:48:17,782 main.py:47] epoch 1050, training loss: 3615.09, average training loss: 4103.30, base loss: 4586.65
[INFO 2017-06-26 21:48:18,169 main.py:47] epoch 1051, training loss: 3924.81, average training loss: 4102.63, base loss: 4587.10
[INFO 2017-06-26 21:48:18,559 main.py:47] epoch 1052, training loss: 3635.17, average training loss: 4098.45, base loss: 4584.07
[INFO 2017-06-26 21:48:18,947 main.py:47] epoch 1053, training loss: 3736.80, average training loss: 4097.52, base loss: 4584.36
[INFO 2017-06-26 21:48:19,332 main.py:47] epoch 1054, training loss: 4095.46, average training loss: 4097.27, base loss: 4585.57
[INFO 2017-06-26 21:48:19,719 main.py:47] epoch 1055, training loss: 3384.70, average training loss: 4095.91, base loss: 4585.50
[INFO 2017-06-26 21:48:20,105 main.py:47] epoch 1056, training loss: 4169.66, average training loss: 4095.61, base loss: 4586.36
[INFO 2017-06-26 21:48:20,501 main.py:47] epoch 1057, training loss: 3726.81, average training loss: 4094.67, base loss: 4586.54
[INFO 2017-06-26 21:48:20,891 main.py:47] epoch 1058, training loss: 3902.29, average training loss: 4094.35, base loss: 4587.44
[INFO 2017-06-26 21:48:21,282 main.py:47] epoch 1059, training loss: 3626.94, average training loss: 4093.35, base loss: 4587.53
[INFO 2017-06-26 21:48:21,670 main.py:47] epoch 1060, training loss: 3653.99, average training loss: 4092.62, base loss: 4587.99
[INFO 2017-06-26 21:48:22,059 main.py:47] epoch 1061, training loss: 3681.37, average training loss: 4092.12, base loss: 4588.68
[INFO 2017-06-26 21:48:22,449 main.py:47] epoch 1062, training loss: 3646.97, average training loss: 4087.76, base loss: 4585.20
[INFO 2017-06-26 21:48:22,836 main.py:47] epoch 1063, training loss: 3807.77, average training loss: 4087.11, base loss: 4585.49
[INFO 2017-06-26 21:48:23,222 main.py:47] epoch 1064, training loss: 4026.93, average training loss: 4086.72, base loss: 4586.45
[INFO 2017-06-26 21:48:23,611 main.py:47] epoch 1065, training loss: 3562.00, average training loss: 4085.54, base loss: 4586.22
[INFO 2017-06-26 21:48:23,998 main.py:47] epoch 1066, training loss: 3510.88, average training loss: 4084.66, base loss: 4586.47
[INFO 2017-06-26 21:48:24,387 main.py:47] epoch 1067, training loss: 3427.20, average training loss: 4083.18, base loss: 4585.89
[INFO 2017-06-26 21:48:24,774 main.py:47] epoch 1068, training loss: 4164.74, average training loss: 4082.50, base loss: 4586.17
[INFO 2017-06-26 21:48:25,165 main.py:47] epoch 1069, training loss: 4267.03, average training loss: 4082.32, base loss: 4587.25
[INFO 2017-06-26 21:48:25,552 main.py:47] epoch 1070, training loss: 4196.37, average training loss: 4081.30, base loss: 4587.00
[INFO 2017-06-26 21:48:25,943 main.py:47] epoch 1071, training loss: 3965.16, average training loss: 4081.14, base loss: 4587.97
[INFO 2017-06-26 21:48:26,386 main.py:47] epoch 1072, training loss: 3672.61, average training loss: 4080.60, base loss: 4588.22
[INFO 2017-06-26 21:48:26,798 main.py:47] epoch 1073, training loss: 3503.80, average training loss: 4079.45, base loss: 4587.91
[INFO 2017-06-26 21:48:27,201 main.py:47] epoch 1074, training loss: 3622.03, average training loss: 4078.36, base loss: 4587.59
[INFO 2017-06-26 21:48:27,590 main.py:47] epoch 1075, training loss: 3764.25, average training loss: 4077.07, base loss: 4587.39
[INFO 2017-06-26 21:48:27,978 main.py:47] epoch 1076, training loss: 4106.63, average training loss: 4076.26, base loss: 4587.53
[INFO 2017-06-26 21:48:28,365 main.py:47] epoch 1077, training loss: 3025.36, average training loss: 4074.78, base loss: 4586.72
[INFO 2017-06-26 21:48:28,750 main.py:47] epoch 1078, training loss: 3971.99, average training loss: 4074.35, base loss: 4587.36
[INFO 2017-06-26 21:48:29,130 main.py:47] epoch 1079, training loss: 3492.50, average training loss: 4072.84, base loss: 4586.54
[INFO 2017-06-26 21:48:29,514 main.py:47] epoch 1080, training loss: 3533.10, average training loss: 4071.85, base loss: 4586.55
[INFO 2017-06-26 21:48:29,908 main.py:47] epoch 1081, training loss: 7257.72, average training loss: 4074.01, base loss: 4589.55
[INFO 2017-06-26 21:48:30,290 main.py:47] epoch 1082, training loss: 4009.63, average training loss: 4073.00, base loss: 4589.42
[INFO 2017-06-26 21:48:30,677 main.py:47] epoch 1083, training loss: 3921.59, average training loss: 4072.53, base loss: 4590.18
[INFO 2017-06-26 21:48:31,066 main.py:47] epoch 1084, training loss: 3572.27, average training loss: 4071.51, base loss: 4589.80
[INFO 2017-06-26 21:48:31,451 main.py:47] epoch 1085, training loss: 3706.62, average training loss: 4070.79, base loss: 4590.16
[INFO 2017-06-26 21:48:31,836 main.py:47] epoch 1086, training loss: 3791.95, average training loss: 4070.54, base loss: 4590.72
[INFO 2017-06-26 21:48:32,224 main.py:47] epoch 1087, training loss: 3446.50, average training loss: 4069.47, base loss: 4590.51
[INFO 2017-06-26 21:48:32,609 main.py:47] epoch 1088, training loss: 3720.31, average training loss: 4068.57, base loss: 4590.42
[INFO 2017-06-26 21:48:32,998 main.py:47] epoch 1089, training loss: 3689.08, average training loss: 4068.24, base loss: 4591.14
[INFO 2017-06-26 21:48:33,381 main.py:47] epoch 1090, training loss: 3735.68, average training loss: 4067.71, base loss: 4591.39
[INFO 2017-06-26 21:48:33,766 main.py:47] epoch 1091, training loss: 3471.15, average training loss: 4066.80, base loss: 4591.51
[INFO 2017-06-26 21:48:34,154 main.py:47] epoch 1092, training loss: 3497.10, average training loss: 4065.84, base loss: 4591.48
[INFO 2017-06-26 21:48:34,542 main.py:47] epoch 1093, training loss: 3653.46, average training loss: 4064.20, base loss: 4590.25
[INFO 2017-06-26 21:48:34,928 main.py:47] epoch 1094, training loss: 3446.93, average training loss: 4062.85, base loss: 4589.67
[INFO 2017-06-26 21:48:35,313 main.py:47] epoch 1095, training loss: 2974.41, average training loss: 4060.97, base loss: 4588.45
[INFO 2017-06-26 21:48:35,780 main.py:47] epoch 1096, training loss: 3680.90, average training loss: 4059.70, base loss: 4587.91
[INFO 2017-06-26 21:48:36,187 main.py:47] epoch 1097, training loss: 3740.06, average training loss: 4058.49, base loss: 4587.70
[INFO 2017-06-26 21:48:36,588 main.py:47] epoch 1098, training loss: 3948.63, average training loss: 4054.42, base loss: 4584.60
[INFO 2017-06-26 21:48:36,974 main.py:47] epoch 1099, training loss: 3715.49, average training loss: 4053.83, base loss: 4584.97
[INFO 2017-06-26 21:48:36,975 main.py:49] epoch 1099, testing
[INFO 2017-06-26 21:48:38,542 main.py:101] average testing loss: 3688.57, base loss: 4432.24, improve_loss: 743.68
[INFO 2017-06-26 21:48:38,543 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:48:38,557 main.py:73] current best improved loss: 743.68
[INFO 2017-06-26 21:48:38,997 main.py:47] epoch 1100, training loss: 3696.82, average training loss: 4053.01, base loss: 4584.87
[INFO 2017-06-26 21:48:39,423 main.py:47] epoch 1101, training loss: 4000.15, average training loss: 4052.58, base loss: 4585.49
[INFO 2017-06-26 21:48:39,816 main.py:47] epoch 1102, training loss: 3850.55, average training loss: 4051.45, base loss: 4585.32
[INFO 2017-06-26 21:48:40,209 main.py:47] epoch 1103, training loss: 3950.41, average training loss: 4051.43, base loss: 4586.64
[INFO 2017-06-26 21:48:40,597 main.py:47] epoch 1104, training loss: 3501.30, average training loss: 4050.92, base loss: 4587.29
[INFO 2017-06-26 21:48:40,987 main.py:47] epoch 1105, training loss: 3622.53, average training loss: 4050.46, base loss: 4587.49
[INFO 2017-06-26 21:48:41,372 main.py:47] epoch 1106, training loss: 4016.80, average training loss: 4050.65, base loss: 4588.86
[INFO 2017-06-26 21:48:41,758 main.py:47] epoch 1107, training loss: 3526.00, average training loss: 4049.09, base loss: 4587.75
[INFO 2017-06-26 21:48:42,143 main.py:47] epoch 1108, training loss: 3166.63, average training loss: 4047.45, base loss: 4586.69
[INFO 2017-06-26 21:48:42,528 main.py:47] epoch 1109, training loss: 4003.77, average training loss: 4046.85, base loss: 4586.95
[INFO 2017-06-26 21:48:42,913 main.py:47] epoch 1110, training loss: 3945.81, average training loss: 4045.36, base loss: 4586.33
[INFO 2017-06-26 21:48:43,299 main.py:47] epoch 1111, training loss: 7522.06, average training loss: 4048.08, base loss: 4590.00
[INFO 2017-06-26 21:48:43,688 main.py:47] epoch 1112, training loss: 3560.26, average training loss: 4047.71, base loss: 4590.37
[INFO 2017-06-26 21:48:44,079 main.py:47] epoch 1113, training loss: 4088.99, average training loss: 4047.45, base loss: 4591.21
[INFO 2017-06-26 21:48:44,480 main.py:47] epoch 1114, training loss: 3403.22, average training loss: 4046.89, base loss: 4591.05
[INFO 2017-06-26 21:48:44,900 main.py:47] epoch 1115, training loss: 3576.51, average training loss: 4046.37, base loss: 4591.17
[INFO 2017-06-26 21:48:45,288 main.py:47] epoch 1116, training loss: 3936.45, average training loss: 4045.86, base loss: 4591.53
[INFO 2017-06-26 21:48:45,679 main.py:47] epoch 1117, training loss: 4017.79, average training loss: 4045.68, base loss: 4592.36
[INFO 2017-06-26 21:48:46,138 main.py:47] epoch 1118, training loss: 3173.45, average training loss: 4045.09, base loss: 4592.21
[INFO 2017-06-26 21:48:46,548 main.py:47] epoch 1119, training loss: 3521.20, average training loss: 4044.26, base loss: 4592.14
[INFO 2017-06-26 21:48:47,008 main.py:47] epoch 1120, training loss: 3347.95, average training loss: 4043.36, base loss: 4591.71
[INFO 2017-06-26 21:48:47,419 main.py:47] epoch 1121, training loss: 4236.71, average training loss: 4043.34, base loss: 4592.76
[INFO 2017-06-26 21:48:47,810 main.py:47] epoch 1122, training loss: 3421.44, average training loss: 4042.48, base loss: 4592.44
[INFO 2017-06-26 21:48:48,253 main.py:47] epoch 1123, training loss: 3484.84, average training loss: 4037.91, base loss: 4588.52
[INFO 2017-06-26 21:48:48,642 main.py:47] epoch 1124, training loss: 4158.26, average training loss: 4037.40, base loss: 4588.79
[INFO 2017-06-26 21:48:49,041 main.py:47] epoch 1125, training loss: 3557.05, average training loss: 4036.33, base loss: 4588.63
[INFO 2017-06-26 21:48:49,428 main.py:47] epoch 1126, training loss: 3475.12, average training loss: 4035.21, base loss: 4587.91
[INFO 2017-06-26 21:48:49,814 main.py:47] epoch 1127, training loss: 3534.88, average training loss: 4034.77, base loss: 4588.18
[INFO 2017-06-26 21:48:50,195 main.py:47] epoch 1128, training loss: 3507.04, average training loss: 4033.45, base loss: 4587.67
[INFO 2017-06-26 21:48:50,576 main.py:47] epoch 1129, training loss: 3142.24, average training loss: 4031.68, base loss: 4586.43
[INFO 2017-06-26 21:48:50,957 main.py:47] epoch 1130, training loss: 3937.80, average training loss: 4031.12, base loss: 4586.76
[INFO 2017-06-26 21:48:51,344 main.py:47] epoch 1131, training loss: 3679.47, average training loss: 4030.80, base loss: 4587.11
[INFO 2017-06-26 21:48:51,731 main.py:47] epoch 1132, training loss: 3154.94, average training loss: 4029.13, base loss: 4585.79
[INFO 2017-06-26 21:48:52,115 main.py:47] epoch 1133, training loss: 3646.77, average training loss: 4028.88, base loss: 4586.21
[INFO 2017-06-26 21:48:52,499 main.py:47] epoch 1134, training loss: 3411.24, average training loss: 4028.30, base loss: 4586.33
[INFO 2017-06-26 21:48:52,882 main.py:47] epoch 1135, training loss: 4297.67, average training loss: 4028.46, base loss: 4587.45
[INFO 2017-06-26 21:48:53,263 main.py:47] epoch 1136, training loss: 3299.24, average training loss: 4027.89, base loss: 4587.21
[INFO 2017-06-26 21:48:53,649 main.py:47] epoch 1137, training loss: 3389.29, average training loss: 4025.99, base loss: 4585.60
[INFO 2017-06-26 21:48:54,036 main.py:47] epoch 1138, training loss: 3618.86, average training loss: 4025.21, base loss: 4585.46
[INFO 2017-06-26 21:48:54,420 main.py:47] epoch 1139, training loss: 3962.10, average training loss: 4024.60, base loss: 4585.69
[INFO 2017-06-26 21:48:54,805 main.py:47] epoch 1140, training loss: 3645.84, average training loss: 4024.03, base loss: 4585.59
[INFO 2017-06-26 21:48:55,189 main.py:47] epoch 1141, training loss: 3500.88, average training loss: 4023.25, base loss: 4585.35
[INFO 2017-06-26 21:48:55,575 main.py:47] epoch 1142, training loss: 3930.21, average training loss: 4023.31, base loss: 4586.45
[INFO 2017-06-26 21:48:55,958 main.py:47] epoch 1143, training loss: 3380.26, average training loss: 4022.13, base loss: 4585.77
[INFO 2017-06-26 21:48:56,340 main.py:47] epoch 1144, training loss: 3631.48, average training loss: 4022.00, base loss: 4586.57
[INFO 2017-06-26 21:48:56,765 main.py:47] epoch 1145, training loss: 3670.45, average training loss: 4021.33, base loss: 4586.59
[INFO 2017-06-26 21:48:57,197 main.py:47] epoch 1146, training loss: 4350.40, average training loss: 4020.48, base loss: 4586.36
[INFO 2017-06-26 21:48:57,612 main.py:47] epoch 1147, training loss: 3716.27, average training loss: 4020.37, base loss: 4587.28
[INFO 2017-06-26 21:48:58,034 main.py:47] epoch 1148, training loss: 3694.84, average training loss: 4020.02, base loss: 4587.62
[INFO 2017-06-26 21:48:58,425 main.py:47] epoch 1149, training loss: 4295.93, average training loss: 4020.71, base loss: 4589.42
[INFO 2017-06-26 21:48:58,814 main.py:47] epoch 1150, training loss: 4355.23, average training loss: 4020.93, base loss: 4590.56
[INFO 2017-06-26 21:48:59,204 main.py:47] epoch 1151, training loss: 3884.03, average training loss: 4020.53, base loss: 4590.77
[INFO 2017-06-26 21:48:59,591 main.py:47] epoch 1152, training loss: 3799.12, average training loss: 4020.59, base loss: 4591.78
[INFO 2017-06-26 21:48:59,990 main.py:47] epoch 1153, training loss: 3528.53, average training loss: 4019.51, base loss: 4591.26
[INFO 2017-06-26 21:49:00,381 main.py:47] epoch 1154, training loss: 3690.52, average training loss: 4019.19, base loss: 4591.88
[INFO 2017-06-26 21:49:00,766 main.py:47] epoch 1155, training loss: 3456.85, average training loss: 4018.63, base loss: 4591.90
[INFO 2017-06-26 21:49:01,153 main.py:47] epoch 1156, training loss: 3437.46, average training loss: 4018.01, base loss: 4591.88
[INFO 2017-06-26 21:49:01,538 main.py:47] epoch 1157, training loss: 3955.20, average training loss: 4017.82, base loss: 4592.23
[INFO 2017-06-26 21:49:01,922 main.py:47] epoch 1158, training loss: 3338.05, average training loss: 4016.77, base loss: 4591.88
[INFO 2017-06-26 21:49:02,307 main.py:47] epoch 1159, training loss: 3637.73, average training loss: 4013.03, base loss: 4589.02
[INFO 2017-06-26 21:49:02,694 main.py:47] epoch 1160, training loss: 3673.80, average training loss: 4013.24, base loss: 4590.05
[INFO 2017-06-26 21:49:03,090 main.py:47] epoch 1161, training loss: 3654.57, average training loss: 4012.55, base loss: 4589.79
[INFO 2017-06-26 21:49:03,473 main.py:47] epoch 1162, training loss: 3600.39, average training loss: 4011.80, base loss: 4589.32
[INFO 2017-06-26 21:49:03,860 main.py:47] epoch 1163, training loss: 3873.51, average training loss: 4011.30, base loss: 4589.72
[INFO 2017-06-26 21:49:04,336 main.py:47] epoch 1164, training loss: 3707.18, average training loss: 4010.71, base loss: 4589.84
[INFO 2017-06-26 21:49:04,738 main.py:47] epoch 1165, training loss: 4131.83, average training loss: 4010.92, base loss: 4590.99
[INFO 2017-06-26 21:49:05,125 main.py:47] epoch 1166, training loss: 4439.01, average training loss: 4010.67, base loss: 4591.74
[INFO 2017-06-26 21:49:05,508 main.py:47] epoch 1167, training loss: 3721.64, average training loss: 4009.27, base loss: 4591.41
[INFO 2017-06-26 21:49:05,893 main.py:47] epoch 1168, training loss: 3400.42, average training loss: 4008.07, base loss: 4590.64
[INFO 2017-06-26 21:49:06,371 main.py:47] epoch 1169, training loss: 3243.81, average training loss: 4007.02, base loss: 4589.70
[INFO 2017-06-26 21:49:06,773 main.py:47] epoch 1170, training loss: 3861.82, average training loss: 4006.51, base loss: 4590.00
[INFO 2017-06-26 21:49:07,170 main.py:47] epoch 1171, training loss: 3213.04, average training loss: 4001.92, base loss: 4585.89
[INFO 2017-06-26 21:49:07,566 main.py:47] epoch 1172, training loss: 4267.60, average training loss: 4002.18, base loss: 4587.40
[INFO 2017-06-26 21:49:07,950 main.py:47] epoch 1173, training loss: 4031.52, average training loss: 4001.72, base loss: 4587.91
[INFO 2017-06-26 21:49:08,337 main.py:47] epoch 1174, training loss: 3805.49, average training loss: 4001.02, base loss: 4587.56
[INFO 2017-06-26 21:49:08,723 main.py:47] epoch 1175, training loss: 3260.53, average training loss: 3999.28, base loss: 4586.22
[INFO 2017-06-26 21:49:09,107 main.py:47] epoch 1176, training loss: 3948.96, average training loss: 3998.70, base loss: 4586.73
[INFO 2017-06-26 21:49:09,494 main.py:47] epoch 1177, training loss: 3581.29, average training loss: 3998.38, base loss: 4587.08
[INFO 2017-06-26 21:49:09,881 main.py:47] epoch 1178, training loss: 3914.64, average training loss: 3998.41, base loss: 4587.90
[INFO 2017-06-26 21:49:10,265 main.py:47] epoch 1179, training loss: 3845.20, average training loss: 3998.64, base loss: 4588.77
[INFO 2017-06-26 21:49:10,651 main.py:47] epoch 1180, training loss: 4474.35, average training loss: 3998.92, base loss: 4590.21
[INFO 2017-06-26 21:49:11,036 main.py:47] epoch 1181, training loss: 7486.00, average training loss: 4001.88, base loss: 4593.70
[INFO 2017-06-26 21:49:11,418 main.py:47] epoch 1182, training loss: 4256.79, average training loss: 4001.49, base loss: 4594.43
[INFO 2017-06-26 21:49:11,798 main.py:47] epoch 1183, training loss: 3637.44, average training loss: 4001.37, base loss: 4594.77
[INFO 2017-06-26 21:49:12,177 main.py:47] epoch 1184, training loss: 3662.74, average training loss: 3997.31, base loss: 4591.15
[INFO 2017-06-26 21:49:12,556 main.py:47] epoch 1185, training loss: 3941.80, average training loss: 3997.11, base loss: 4591.92
[INFO 2017-06-26 21:49:12,936 main.py:47] epoch 1186, training loss: 3530.89, average training loss: 3995.76, base loss: 4590.75
[INFO 2017-06-26 21:49:13,315 main.py:47] epoch 1187, training loss: 4142.09, average training loss: 3995.46, base loss: 4591.47
[INFO 2017-06-26 21:49:13,703 main.py:47] epoch 1188, training loss: 3686.83, average training loss: 3995.04, base loss: 4591.66
[INFO 2017-06-26 21:49:14,139 main.py:47] epoch 1189, training loss: 3524.05, average training loss: 3990.03, base loss: 4587.27
[INFO 2017-06-26 21:49:14,527 main.py:47] epoch 1190, training loss: 3910.36, average training loss: 3990.25, base loss: 4588.26
[INFO 2017-06-26 21:49:14,929 main.py:47] epoch 1191, training loss: 3398.93, average training loss: 3989.67, base loss: 4588.22
[INFO 2017-06-26 21:49:15,321 main.py:47] epoch 1192, training loss: 4323.95, average training loss: 3990.02, base loss: 4589.63
[INFO 2017-06-26 21:49:15,707 main.py:47] epoch 1193, training loss: 4177.66, average training loss: 3989.99, base loss: 4590.20
[INFO 2017-06-26 21:49:16,094 main.py:47] epoch 1194, training loss: 3477.49, average training loss: 3989.20, base loss: 4590.04
[INFO 2017-06-26 21:49:16,483 main.py:47] epoch 1195, training loss: 3501.40, average training loss: 3988.62, base loss: 4590.10
[INFO 2017-06-26 21:49:16,876 main.py:47] epoch 1196, training loss: 3471.92, average training loss: 3988.36, base loss: 4590.66
[INFO 2017-06-26 21:49:17,270 main.py:47] epoch 1197, training loss: 3765.73, average training loss: 3988.15, base loss: 4591.16
[INFO 2017-06-26 21:49:17,668 main.py:47] epoch 1198, training loss: 3260.09, average training loss: 3986.70, base loss: 4590.04
[INFO 2017-06-26 21:49:18,065 main.py:47] epoch 1199, training loss: 4238.50, average training loss: 3986.65, base loss: 4590.85
[INFO 2017-06-26 21:49:18,066 main.py:49] epoch 1199, testing
[INFO 2017-06-26 21:49:19,791 main.py:101] average testing loss: 3848.95, base loss: 4529.91, improve_loss: 680.96
[INFO 2017-06-26 21:49:19,792 main.py:73] current best improved loss: 743.68
[INFO 2017-06-26 21:49:20,257 main.py:47] epoch 1200, training loss: 3007.95, average training loss: 3985.13, base loss: 4589.72
[INFO 2017-06-26 21:49:20,660 main.py:47] epoch 1201, training loss: 3631.29, average training loss: 3985.48, base loss: 4590.53
[INFO 2017-06-26 21:49:21,114 main.py:47] epoch 1202, training loss: 3653.43, average training loss: 3985.56, base loss: 4591.37
[INFO 2017-06-26 21:49:21,609 main.py:47] epoch 1203, training loss: 3695.74, average training loss: 3984.79, base loss: 4590.91
[INFO 2017-06-26 21:49:22,019 main.py:47] epoch 1204, training loss: 3306.20, average training loss: 3983.30, base loss: 4589.58
[INFO 2017-06-26 21:49:22,406 main.py:47] epoch 1205, training loss: 3529.22, average training loss: 3981.64, base loss: 4588.21
[INFO 2017-06-26 21:49:22,795 main.py:47] epoch 1206, training loss: 3590.41, average training loss: 3981.36, base loss: 4588.53
[INFO 2017-06-26 21:49:23,182 main.py:47] epoch 1207, training loss: 3172.66, average training loss: 3980.35, base loss: 4587.85
[INFO 2017-06-26 21:49:23,567 main.py:47] epoch 1208, training loss: 3908.20, average training loss: 3979.80, base loss: 4587.96
[INFO 2017-06-26 21:49:23,952 main.py:47] epoch 1209, training loss: 3143.26, average training loss: 3979.04, base loss: 4587.52
[INFO 2017-06-26 21:49:24,343 main.py:47] epoch 1210, training loss: 3484.39, average training loss: 3978.78, base loss: 4587.74
[INFO 2017-06-26 21:49:24,730 main.py:47] epoch 1211, training loss: 3180.20, average training loss: 3977.71, base loss: 4587.00
[INFO 2017-06-26 21:49:25,114 main.py:47] epoch 1212, training loss: 4308.41, average training loss: 3977.67, base loss: 4588.26
[INFO 2017-06-26 21:49:25,493 main.py:47] epoch 1213, training loss: 3381.91, average training loss: 3977.14, base loss: 4588.25
[INFO 2017-06-26 21:49:25,876 main.py:47] epoch 1214, training loss: 3365.38, average training loss: 3976.69, base loss: 4588.31
[INFO 2017-06-26 21:49:26,263 main.py:47] epoch 1215, training loss: 3813.48, average training loss: 3976.44, base loss: 4588.81
[INFO 2017-06-26 21:49:26,646 main.py:47] epoch 1216, training loss: 3799.60, average training loss: 3975.32, base loss: 4588.49
[INFO 2017-06-26 21:49:27,028 main.py:47] epoch 1217, training loss: 3104.00, average training loss: 3970.86, base loss: 4584.50
[INFO 2017-06-26 21:49:27,412 main.py:47] epoch 1218, training loss: 3594.21, average training loss: 3970.20, base loss: 4584.26
[INFO 2017-06-26 21:49:27,791 main.py:47] epoch 1219, training loss: 3593.01, average training loss: 3969.68, base loss: 4584.36
[INFO 2017-06-26 21:49:28,175 main.py:47] epoch 1220, training loss: 3429.83, average training loss: 3968.73, base loss: 4584.17
[INFO 2017-06-26 21:49:28,559 main.py:47] epoch 1221, training loss: 3023.38, average training loss: 3967.61, base loss: 4583.06
[INFO 2017-06-26 21:49:28,949 main.py:47] epoch 1222, training loss: 3891.99, average training loss: 3967.54, base loss: 4583.74
[INFO 2017-06-26 21:49:29,359 main.py:47] epoch 1223, training loss: 3742.70, average training loss: 3967.34, base loss: 4584.29
[INFO 2017-06-26 21:49:29,744 main.py:47] epoch 1224, training loss: 3377.99, average training loss: 3966.64, base loss: 4583.94
[INFO 2017-06-26 21:49:30,210 main.py:47] epoch 1225, training loss: 3458.00, average training loss: 3966.25, base loss: 4584.43
[INFO 2017-06-26 21:49:30,598 main.py:47] epoch 1226, training loss: 3709.88, average training loss: 3965.66, base loss: 4584.59
[INFO 2017-06-26 21:49:30,987 main.py:47] epoch 1227, training loss: 3345.62, average training loss: 3964.93, base loss: 4584.16
[INFO 2017-06-26 21:49:31,371 main.py:47] epoch 1228, training loss: 3995.95, average training loss: 3964.32, base loss: 4584.42
[INFO 2017-06-26 21:49:31,755 main.py:47] epoch 1229, training loss: 3842.07, average training loss: 3964.01, base loss: 4584.93
[INFO 2017-06-26 21:49:32,136 main.py:47] epoch 1230, training loss: 3721.13, average training loss: 3963.84, base loss: 4585.41
[INFO 2017-06-26 21:49:32,549 main.py:47] epoch 1231, training loss: 4100.66, average training loss: 3963.19, base loss: 4585.94
[INFO 2017-06-26 21:49:32,962 main.py:47] epoch 1232, training loss: 4061.00, average training loss: 3962.84, base loss: 4586.49
[INFO 2017-06-26 21:49:33,349 main.py:47] epoch 1233, training loss: 3464.66, average training loss: 3962.36, base loss: 4586.57
[INFO 2017-06-26 21:49:33,839 main.py:47] epoch 1234, training loss: 3436.86, average training loss: 3961.74, base loss: 4586.76
[INFO 2017-06-26 21:49:34,231 main.py:47] epoch 1235, training loss: 3575.01, average training loss: 3961.23, base loss: 4586.66
[INFO 2017-06-26 21:49:34,661 main.py:47] epoch 1236, training loss: 3953.82, average training loss: 3960.92, base loss: 4587.05
[INFO 2017-06-26 21:49:35,082 main.py:47] epoch 1237, training loss: 3631.83, average training loss: 3960.61, base loss: 4587.33
[INFO 2017-06-26 21:49:35,476 main.py:47] epoch 1238, training loss: 3903.82, average training loss: 3959.62, base loss: 4586.72
[INFO 2017-06-26 21:49:35,873 main.py:47] epoch 1239, training loss: 3636.47, average training loss: 3959.42, base loss: 4587.44
[INFO 2017-06-26 21:49:36,257 main.py:47] epoch 1240, training loss: 3711.01, average training loss: 3958.79, base loss: 4587.50
[INFO 2017-06-26 21:49:36,649 main.py:47] epoch 1241, training loss: 3576.47, average training loss: 3958.34, base loss: 4587.66
[INFO 2017-06-26 21:49:37,035 main.py:47] epoch 1242, training loss: 6974.68, average training loss: 3960.69, base loss: 4590.20
[INFO 2017-06-26 21:49:37,420 main.py:47] epoch 1243, training loss: 3155.50, average training loss: 3959.18, base loss: 4589.08
[INFO 2017-06-26 21:49:37,803 main.py:47] epoch 1244, training loss: 3076.59, average training loss: 3957.78, base loss: 4587.94
[INFO 2017-06-26 21:49:38,188 main.py:47] epoch 1245, training loss: 3708.13, average training loss: 3957.54, base loss: 4588.17
[INFO 2017-06-26 21:49:38,586 main.py:47] epoch 1246, training loss: 2975.23, average training loss: 3955.16, base loss: 4585.80
[INFO 2017-06-26 21:49:38,971 main.py:47] epoch 1247, training loss: 3546.55, average training loss: 3954.89, base loss: 4586.07
[INFO 2017-06-26 21:49:39,356 main.py:47] epoch 1248, training loss: 3198.98, average training loss: 3953.64, base loss: 4585.22
[INFO 2017-06-26 21:49:39,736 main.py:47] epoch 1249, training loss: 7977.61, average training loss: 3956.56, base loss: 4588.78
[INFO 2017-06-26 21:49:40,117 main.py:47] epoch 1250, training loss: 3469.22, average training loss: 3955.59, base loss: 4588.25
[INFO 2017-06-26 21:49:40,500 main.py:47] epoch 1251, training loss: 3351.37, average training loss: 3954.98, base loss: 4587.95
[INFO 2017-06-26 21:49:40,905 main.py:47] epoch 1252, training loss: 3049.56, average training loss: 3954.02, base loss: 4587.47
[INFO 2017-06-26 21:49:41,323 main.py:47] epoch 1253, training loss: 3874.72, average training loss: 3953.24, base loss: 4587.05
[INFO 2017-06-26 21:49:41,710 main.py:47] epoch 1254, training loss: 3501.68, average training loss: 3952.74, base loss: 4587.09
[INFO 2017-06-26 21:49:42,097 main.py:47] epoch 1255, training loss: 3511.19, average training loss: 3951.38, base loss: 4586.16
[INFO 2017-06-26 21:49:42,482 main.py:47] epoch 1256, training loss: 3552.91, average training loss: 3950.62, base loss: 4585.86
[INFO 2017-06-26 21:49:42,869 main.py:47] epoch 1257, training loss: 4422.94, average training loss: 3951.26, base loss: 4587.49
[INFO 2017-06-26 21:49:43,327 main.py:47] epoch 1258, training loss: 3401.89, average training loss: 3950.72, base loss: 4587.20
[INFO 2017-06-26 21:49:43,727 main.py:47] epoch 1259, training loss: 7001.50, average training loss: 3953.43, base loss: 4590.15
[INFO 2017-06-26 21:49:44,142 main.py:47] epoch 1260, training loss: 3650.53, average training loss: 3953.12, base loss: 4590.43
[INFO 2017-06-26 21:49:44,558 main.py:47] epoch 1261, training loss: 4288.69, average training loss: 3953.10, base loss: 4591.31
[INFO 2017-06-26 21:49:44,945 main.py:47] epoch 1262, training loss: 3512.60, average training loss: 3953.13, base loss: 4592.14
[INFO 2017-06-26 21:49:45,333 main.py:47] epoch 1263, training loss: 3631.93, average training loss: 3952.57, base loss: 4592.46
[INFO 2017-06-26 21:49:45,722 main.py:47] epoch 1264, training loss: 3433.97, average training loss: 3951.99, base loss: 4592.42
[INFO 2017-06-26 21:49:46,120 main.py:47] epoch 1265, training loss: 4092.72, average training loss: 3951.31, base loss: 4592.65
[INFO 2017-06-26 21:49:46,511 main.py:47] epoch 1266, training loss: 3454.83, average training loss: 3950.31, base loss: 4591.92
[INFO 2017-06-26 21:49:46,893 main.py:47] epoch 1267, training loss: 3606.84, average training loss: 3949.79, base loss: 4591.91
[INFO 2017-06-26 21:49:47,278 main.py:47] epoch 1268, training loss: 3338.54, average training loss: 3948.82, base loss: 4591.35
[INFO 2017-06-26 21:49:47,662 main.py:47] epoch 1269, training loss: 3454.41, average training loss: 3948.11, base loss: 4591.25
[INFO 2017-06-26 21:49:48,048 main.py:47] epoch 1270, training loss: 4032.44, average training loss: 3947.90, base loss: 4591.79
[INFO 2017-06-26 21:49:48,433 main.py:47] epoch 1271, training loss: 3042.85, average training loss: 3946.72, base loss: 4590.82
[INFO 2017-06-26 21:49:48,820 main.py:47] epoch 1272, training loss: 3564.38, average training loss: 3946.44, base loss: 4590.90
[INFO 2017-06-26 21:49:49,207 main.py:47] epoch 1273, training loss: 3441.57, average training loss: 3945.03, base loss: 4589.90
[INFO 2017-06-26 21:49:49,593 main.py:47] epoch 1274, training loss: 3096.09, average training loss: 3944.11, base loss: 4589.22
[INFO 2017-06-26 21:49:49,981 main.py:47] epoch 1275, training loss: 3145.41, average training loss: 3942.67, base loss: 4588.31
[INFO 2017-06-26 21:49:50,370 main.py:47] epoch 1276, training loss: 3447.36, average training loss: 3942.07, base loss: 4588.16
[INFO 2017-06-26 21:49:50,760 main.py:47] epoch 1277, training loss: 3451.97, average training loss: 3941.81, base loss: 4588.77
[INFO 2017-06-26 21:49:51,147 main.py:47] epoch 1278, training loss: 3661.22, average training loss: 3941.06, base loss: 4588.45
[INFO 2017-06-26 21:49:51,533 main.py:47] epoch 1279, training loss: 3502.72, average training loss: 3940.63, base loss: 4588.52
[INFO 2017-06-26 21:49:51,917 main.py:47] epoch 1280, training loss: 3682.19, average training loss: 3940.26, base loss: 4588.67
[INFO 2017-06-26 21:49:52,298 main.py:47] epoch 1281, training loss: 3870.64, average training loss: 3940.11, base loss: 4589.51
[INFO 2017-06-26 21:49:52,684 main.py:47] epoch 1282, training loss: 3123.00, average training loss: 3937.99, base loss: 4587.10
[INFO 2017-06-26 21:49:53,071 main.py:47] epoch 1283, training loss: 3139.54, average training loss: 3937.10, base loss: 4586.70
[INFO 2017-06-26 21:49:53,460 main.py:47] epoch 1284, training loss: 3859.71, average training loss: 3936.98, base loss: 4587.48
[INFO 2017-06-26 21:49:53,841 main.py:47] epoch 1285, training loss: 4319.24, average training loss: 3937.29, base loss: 4588.77
[INFO 2017-06-26 21:49:54,221 main.py:47] epoch 1286, training loss: 3688.05, average training loss: 3937.13, base loss: 4589.56
[INFO 2017-06-26 21:49:54,606 main.py:47] epoch 1287, training loss: 3622.73, average training loss: 3936.93, base loss: 4590.20
[INFO 2017-06-26 21:49:54,988 main.py:47] epoch 1288, training loss: 3693.02, average training loss: 3935.88, base loss: 4589.58
[INFO 2017-06-26 21:49:55,467 main.py:47] epoch 1289, training loss: 3351.72, average training loss: 3934.71, base loss: 4588.64
[INFO 2017-06-26 21:49:55,854 main.py:47] epoch 1290, training loss: 3754.26, average training loss: 3934.14, base loss: 4588.71
[INFO 2017-06-26 21:49:56,242 main.py:47] epoch 1291, training loss: 3747.24, average training loss: 3933.60, base loss: 4588.57
[INFO 2017-06-26 21:49:56,630 main.py:47] epoch 1292, training loss: 3465.90, average training loss: 3932.91, base loss: 4588.50
[INFO 2017-06-26 21:49:57,081 main.py:47] epoch 1293, training loss: 3630.26, average training loss: 3931.93, base loss: 4587.89
[INFO 2017-06-26 21:49:57,494 main.py:47] epoch 1294, training loss: 3808.80, average training loss: 3931.83, base loss: 4588.36
[INFO 2017-06-26 21:49:57,905 main.py:47] epoch 1295, training loss: 3279.79, average training loss: 3931.38, base loss: 4588.27
[INFO 2017-06-26 21:49:58,319 main.py:47] epoch 1296, training loss: 3498.85, average training loss: 3930.76, base loss: 4588.40
[INFO 2017-06-26 21:49:58,706 main.py:47] epoch 1297, training loss: 3785.00, average training loss: 3930.71, base loss: 4589.07
[INFO 2017-06-26 21:49:59,099 main.py:47] epoch 1298, training loss: 3355.75, average training loss: 3929.60, base loss: 4588.29
[INFO 2017-06-26 21:49:59,575 main.py:47] epoch 1299, training loss: 3593.84, average training loss: 3928.48, base loss: 4587.36
[INFO 2017-06-26 21:49:59,576 main.py:49] epoch 1299, testing
[INFO 2017-06-26 21:50:01,109 main.py:101] average testing loss: 3548.12, base loss: 4452.61, improve_loss: 904.49
[INFO 2017-06-26 21:50:01,110 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:50:01,122 main.py:73] current best improved loss: 904.49
[INFO 2017-06-26 21:50:01,507 main.py:47] epoch 1300, training loss: 3559.03, average training loss: 3924.04, base loss: 4583.59
[INFO 2017-06-26 21:50:01,888 main.py:47] epoch 1301, training loss: 3963.80, average training loss: 3924.62, base loss: 4585.14
[INFO 2017-06-26 21:50:02,268 main.py:47] epoch 1302, training loss: 3742.33, average training loss: 3923.77, base loss: 4584.56
[INFO 2017-06-26 21:50:02,654 main.py:47] epoch 1303, training loss: 3686.43, average training loss: 3922.49, base loss: 4583.76
[INFO 2017-06-26 21:50:03,042 main.py:47] epoch 1304, training loss: 3199.44, average training loss: 3921.82, base loss: 4583.49
[INFO 2017-06-26 21:50:03,430 main.py:47] epoch 1305, training loss: 4283.69, average training loss: 3921.72, base loss: 4584.22
[INFO 2017-06-26 21:50:03,818 main.py:47] epoch 1306, training loss: 4021.85, average training loss: 3921.92, base loss: 4585.21
[INFO 2017-06-26 21:50:04,208 main.py:47] epoch 1307, training loss: 3402.19, average training loss: 3921.63, base loss: 4585.54
[INFO 2017-06-26 21:50:04,599 main.py:47] epoch 1308, training loss: 4208.49, average training loss: 3922.59, base loss: 4587.25
[INFO 2017-06-26 21:50:04,985 main.py:47] epoch 1309, training loss: 3696.96, average training loss: 3922.13, base loss: 4587.43
[INFO 2017-06-26 21:50:05,371 main.py:47] epoch 1310, training loss: 6713.68, average training loss: 3924.60, base loss: 4590.28
[INFO 2017-06-26 21:50:05,763 main.py:47] epoch 1311, training loss: 3128.85, average training loss: 3923.37, base loss: 4589.24
[INFO 2017-06-26 21:50:06,151 main.py:47] epoch 1312, training loss: 3198.38, average training loss: 3922.21, base loss: 4588.28
[INFO 2017-06-26 21:50:06,540 main.py:47] epoch 1313, training loss: 3307.73, average training loss: 3920.83, base loss: 4587.02
[INFO 2017-06-26 21:50:06,926 main.py:47] epoch 1314, training loss: 3948.02, average training loss: 3921.28, base loss: 4588.50
[INFO 2017-06-26 21:50:07,344 main.py:47] epoch 1315, training loss: 3303.81, average training loss: 3920.56, base loss: 4588.21
[INFO 2017-06-26 21:50:07,757 main.py:47] epoch 1316, training loss: 3779.12, average training loss: 3920.70, base loss: 4589.31
[INFO 2017-06-26 21:50:08,157 main.py:47] epoch 1317, training loss: 3718.13, average training loss: 3919.97, base loss: 4588.81
[INFO 2017-06-26 21:50:08,549 main.py:47] epoch 1318, training loss: 3507.71, average training loss: 3918.88, base loss: 4588.01
[INFO 2017-06-26 21:50:08,966 main.py:47] epoch 1319, training loss: 3404.40, average training loss: 3918.10, base loss: 4587.60
[INFO 2017-06-26 21:50:09,426 main.py:47] epoch 1320, training loss: 3698.19, average training loss: 3917.66, base loss: 4587.73
[INFO 2017-06-26 21:50:09,897 main.py:47] epoch 1321, training loss: 3454.25, average training loss: 3917.31, base loss: 4588.02
[INFO 2017-06-26 21:50:10,351 main.py:47] epoch 1322, training loss: 3040.27, average training loss: 3916.23, base loss: 4587.17
[INFO 2017-06-26 21:50:10,813 main.py:47] epoch 1323, training loss: 3683.35, average training loss: 3915.93, base loss: 4587.68
[INFO 2017-06-26 21:50:11,240 main.py:47] epoch 1324, training loss: 3816.93, average training loss: 3915.13, base loss: 4587.43
[INFO 2017-06-26 21:50:11,679 main.py:47] epoch 1325, training loss: 3560.84, average training loss: 3915.18, base loss: 4588.16
[INFO 2017-06-26 21:50:12,165 main.py:47] epoch 1326, training loss: 3409.98, average training loss: 3914.86, base loss: 4588.53
[INFO 2017-06-26 21:50:12,592 main.py:47] epoch 1327, training loss: 3572.73, average training loss: 3914.69, base loss: 4589.20
[INFO 2017-06-26 21:50:12,979 main.py:47] epoch 1328, training loss: 3897.29, average training loss: 3914.44, base loss: 4589.38
[INFO 2017-06-26 21:50:13,368 main.py:47] epoch 1329, training loss: 3495.56, average training loss: 3913.60, base loss: 4588.93
[INFO 2017-06-26 21:50:13,753 main.py:47] epoch 1330, training loss: 3060.13, average training loss: 3912.62, base loss: 4588.27
[INFO 2017-06-26 21:50:14,138 main.py:47] epoch 1331, training loss: 3296.43, average training loss: 3911.69, base loss: 4587.57
[INFO 2017-06-26 21:50:14,530 main.py:47] epoch 1332, training loss: 3276.09, average training loss: 3911.43, base loss: 4587.56
[INFO 2017-06-26 21:50:14,993 main.py:47] epoch 1333, training loss: 7179.96, average training loss: 3914.71, base loss: 4591.53
[INFO 2017-06-26 21:50:15,396 main.py:47] epoch 1334, training loss: 3343.51, average training loss: 3914.24, base loss: 4591.46
[INFO 2017-06-26 21:50:15,846 main.py:47] epoch 1335, training loss: 7738.71, average training loss: 3918.44, base loss: 4596.52
[INFO 2017-06-26 21:50:16,322 main.py:47] epoch 1336, training loss: 3650.04, average training loss: 3918.02, base loss: 4596.68
[INFO 2017-06-26 21:50:16,806 main.py:47] epoch 1337, training loss: 3334.83, average training loss: 3917.05, base loss: 4596.01
[INFO 2017-06-26 21:50:17,196 main.py:47] epoch 1338, training loss: 3756.05, average training loss: 3917.08, base loss: 4596.49
[INFO 2017-06-26 21:50:17,634 main.py:47] epoch 1339, training loss: 4049.64, average training loss: 3916.77, base loss: 4596.99
[INFO 2017-06-26 21:50:18,054 main.py:47] epoch 1340, training loss: 3222.22, average training loss: 3915.76, base loss: 4596.52
[INFO 2017-06-26 21:50:18,445 main.py:47] epoch 1341, training loss: 3290.87, average training loss: 3914.80, base loss: 4595.89
[INFO 2017-06-26 21:50:18,909 main.py:47] epoch 1342, training loss: 3533.87, average training loss: 3910.26, base loss: 4592.11
[INFO 2017-06-26 21:50:19,318 main.py:47] epoch 1343, training loss: 3636.52, average training loss: 3909.31, base loss: 4591.53
[INFO 2017-06-26 21:50:19,710 main.py:47] epoch 1344, training loss: 3199.82, average training loss: 3908.65, base loss: 4590.99
[INFO 2017-06-26 21:50:20,097 main.py:47] epoch 1345, training loss: 3661.60, average training loss: 3908.28, base loss: 4591.19
[INFO 2017-06-26 21:50:20,493 main.py:47] epoch 1346, training loss: 3575.06, average training loss: 3908.11, base loss: 4591.51
[INFO 2017-06-26 21:50:20,878 main.py:47] epoch 1347, training loss: 3610.81, average training loss: 3907.70, base loss: 4591.74
[INFO 2017-06-26 21:50:21,265 main.py:47] epoch 1348, training loss: 3677.75, average training loss: 3907.57, base loss: 4592.05
[INFO 2017-06-26 21:50:21,644 main.py:47] epoch 1349, training loss: 3663.54, average training loss: 3906.70, base loss: 4591.54
[INFO 2017-06-26 21:50:22,025 main.py:47] epoch 1350, training loss: 3613.56, average training loss: 3906.00, base loss: 4591.24
[INFO 2017-06-26 21:50:22,408 main.py:47] epoch 1351, training loss: 3504.93, average training loss: 3905.13, base loss: 4591.04
[INFO 2017-06-26 21:50:22,789 main.py:47] epoch 1352, training loss: 3838.07, average training loss: 3904.73, base loss: 4591.30
[INFO 2017-06-26 21:50:23,173 main.py:47] epoch 1353, training loss: 3552.22, average training loss: 3904.05, base loss: 4590.90
[INFO 2017-06-26 21:50:23,556 main.py:47] epoch 1354, training loss: 3528.30, average training loss: 3902.91, base loss: 4590.19
[INFO 2017-06-26 21:50:23,938 main.py:47] epoch 1355, training loss: 3411.12, average training loss: 3902.18, base loss: 4589.94
[INFO 2017-06-26 21:50:24,320 main.py:47] epoch 1356, training loss: 3758.95, average training loss: 3901.84, base loss: 4590.39
[INFO 2017-06-26 21:50:24,703 main.py:47] epoch 1357, training loss: 4068.07, average training loss: 3901.53, base loss: 4590.74
[INFO 2017-06-26 21:50:25,087 main.py:47] epoch 1358, training loss: 3482.67, average training loss: 3900.89, base loss: 4590.44
[INFO 2017-06-26 21:50:25,473 main.py:47] epoch 1359, training loss: 3355.78, average training loss: 3900.35, base loss: 4590.30
[INFO 2017-06-26 21:50:25,860 main.py:47] epoch 1360, training loss: 3917.47, average training loss: 3899.65, base loss: 4589.98
[INFO 2017-06-26 21:50:26,249 main.py:47] epoch 1361, training loss: 3457.02, average training loss: 3898.97, base loss: 4589.70
[INFO 2017-06-26 21:50:26,634 main.py:47] epoch 1362, training loss: 3366.99, average training loss: 3898.32, base loss: 4589.59
[INFO 2017-06-26 21:50:27,018 main.py:47] epoch 1363, training loss: 3933.44, average training loss: 3898.71, base loss: 4590.78
[INFO 2017-06-26 21:50:27,402 main.py:47] epoch 1364, training loss: 3614.11, average training loss: 3898.25, base loss: 4590.72
[INFO 2017-06-26 21:50:27,900 main.py:47] epoch 1365, training loss: 2902.41, average training loss: 3896.87, base loss: 4589.72
[INFO 2017-06-26 21:50:28,294 main.py:47] epoch 1366, training loss: 3685.56, average training loss: 3895.78, base loss: 4588.94
[INFO 2017-06-26 21:50:28,688 main.py:47] epoch 1367, training loss: 3212.53, average training loss: 3895.28, base loss: 4588.62
[INFO 2017-06-26 21:50:29,077 main.py:47] epoch 1368, training loss: 3464.06, average training loss: 3894.36, base loss: 4587.96
[INFO 2017-06-26 21:50:29,470 main.py:47] epoch 1369, training loss: 6950.15, average training loss: 3897.00, base loss: 4590.76
[INFO 2017-06-26 21:50:29,915 main.py:47] epoch 1370, training loss: 3537.85, average training loss: 3896.04, base loss: 4590.42
[INFO 2017-06-26 21:50:30,307 main.py:47] epoch 1371, training loss: 3595.10, average training loss: 3895.73, base loss: 4590.54
[INFO 2017-06-26 21:50:30,699 main.py:47] epoch 1372, training loss: 3761.12, average training loss: 3895.30, base loss: 4590.76
[INFO 2017-06-26 21:50:31,085 main.py:47] epoch 1373, training loss: 3270.41, average training loss: 3894.41, base loss: 4590.07
[INFO 2017-06-26 21:50:31,471 main.py:47] epoch 1374, training loss: 3551.49, average training loss: 3894.10, base loss: 4590.32
[INFO 2017-06-26 21:50:31,854 main.py:47] epoch 1375, training loss: 2969.91, average training loss: 3892.99, base loss: 4589.36
[INFO 2017-06-26 21:50:32,239 main.py:47] epoch 1376, training loss: 3541.25, average training loss: 3893.01, base loss: 4590.02
[INFO 2017-06-26 21:50:32,623 main.py:47] epoch 1377, training loss: 3152.78, average training loss: 3892.05, base loss: 4589.28
[INFO 2017-06-26 21:50:33,003 main.py:47] epoch 1378, training loss: 7104.83, average training loss: 3895.13, base loss: 4593.08
[INFO 2017-06-26 21:50:33,384 main.py:47] epoch 1379, training loss: 3105.29, average training loss: 3894.16, base loss: 4592.32
[INFO 2017-06-26 21:50:33,766 main.py:47] epoch 1380, training loss: 2967.38, average training loss: 3889.41, base loss: 4587.58
[INFO 2017-06-26 21:50:34,145 main.py:47] epoch 1381, training loss: 4048.14, average training loss: 3889.30, base loss: 4587.82
[INFO 2017-06-26 21:50:34,529 main.py:47] epoch 1382, training loss: 3786.32, average training loss: 3888.70, base loss: 4587.58
[INFO 2017-06-26 21:50:34,922 main.py:47] epoch 1383, training loss: 3656.56, average training loss: 3887.72, base loss: 4586.85
[INFO 2017-06-26 21:50:35,303 main.py:47] epoch 1384, training loss: 3849.80, average training loss: 3887.22, base loss: 4586.55
[INFO 2017-06-26 21:50:35,686 main.py:47] epoch 1385, training loss: 4046.48, average training loss: 3887.45, base loss: 4587.53
[INFO 2017-06-26 21:50:36,070 main.py:47] epoch 1386, training loss: 3719.84, average training loss: 3887.12, base loss: 4587.69
[INFO 2017-06-26 21:50:36,448 main.py:47] epoch 1387, training loss: 3344.93, average training loss: 3886.59, base loss: 4587.63
[INFO 2017-06-26 21:50:36,830 main.py:47] epoch 1388, training loss: 3735.19, average training loss: 3886.45, base loss: 4588.14
[INFO 2017-06-26 21:50:37,209 main.py:47] epoch 1389, training loss: 4308.70, average training loss: 3886.22, base loss: 4588.86
[INFO 2017-06-26 21:50:37,593 main.py:47] epoch 1390, training loss: 3675.16, average training loss: 3885.27, base loss: 4588.42
[INFO 2017-06-26 21:50:37,970 main.py:47] epoch 1391, training loss: 3343.87, average training loss: 3881.23, base loss: 4584.68
[INFO 2017-06-26 21:50:38,349 main.py:47] epoch 1392, training loss: 3563.57, average training loss: 3880.67, base loss: 4584.72
[INFO 2017-06-26 21:50:38,733 main.py:47] epoch 1393, training loss: 7070.49, average training loss: 3883.75, base loss: 4588.32
[INFO 2017-06-26 21:50:39,112 main.py:47] epoch 1394, training loss: 2995.06, average training loss: 3882.41, base loss: 4586.88
[INFO 2017-06-26 21:50:39,492 main.py:47] epoch 1395, training loss: 7392.55, average training loss: 3885.92, base loss: 4591.37
[INFO 2017-06-26 21:50:39,873 main.py:47] epoch 1396, training loss: 3748.05, average training loss: 3886.04, base loss: 4591.97
[INFO 2017-06-26 21:50:40,253 main.py:47] epoch 1397, training loss: 3082.14, average training loss: 3884.42, base loss: 4590.29
[INFO 2017-06-26 21:50:40,689 main.py:47] epoch 1398, training loss: 4061.88, average training loss: 3885.04, base loss: 4591.59
[INFO 2017-06-26 21:50:41,111 main.py:47] epoch 1399, training loss: 3747.06, average training loss: 3885.17, base loss: 4592.35
[INFO 2017-06-26 21:50:41,111 main.py:49] epoch 1399, testing
[INFO 2017-06-26 21:50:42,700 main.py:101] average testing loss: 3871.18, base loss: 4851.66, improve_loss: 980.48
[INFO 2017-06-26 21:50:42,701 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:50:42,714 main.py:73] current best improved loss: 980.48
[INFO 2017-06-26 21:50:43,101 main.py:47] epoch 1400, training loss: 3839.85, average training loss: 3884.95, base loss: 4592.70
[INFO 2017-06-26 21:50:43,483 main.py:47] epoch 1401, training loss: 7202.74, average training loss: 3888.19, base loss: 4596.65
[INFO 2017-06-26 21:50:43,864 main.py:47] epoch 1402, training loss: 3564.01, average training loss: 3888.41, base loss: 4597.91
[INFO 2017-06-26 21:50:44,252 main.py:47] epoch 1403, training loss: 3756.70, average training loss: 3888.26, base loss: 4598.24
[INFO 2017-06-26 21:50:44,639 main.py:47] epoch 1404, training loss: 3477.21, average training loss: 3887.89, base loss: 4598.11
[INFO 2017-06-26 21:50:45,023 main.py:47] epoch 1405, training loss: 3388.34, average training loss: 3887.44, base loss: 4597.97
[INFO 2017-06-26 21:50:45,413 main.py:47] epoch 1406, training loss: 6823.79, average training loss: 3890.37, base loss: 4601.17
[INFO 2017-06-26 21:50:45,838 main.py:47] epoch 1407, training loss: 3296.22, average training loss: 3889.38, base loss: 4600.48
[INFO 2017-06-26 21:50:46,259 main.py:47] epoch 1408, training loss: 3883.92, average training loss: 3889.45, base loss: 4601.15
[INFO 2017-06-26 21:50:46,652 main.py:47] epoch 1409, training loss: 3534.03, average training loss: 3889.63, base loss: 4602.11
[INFO 2017-06-26 21:50:47,054 main.py:47] epoch 1410, training loss: 3815.40, average training loss: 3889.20, base loss: 4602.16
[INFO 2017-06-26 21:50:47,441 main.py:47] epoch 1411, training loss: 3769.05, average training loss: 3889.13, base loss: 4602.33
[INFO 2017-06-26 21:50:47,829 main.py:47] epoch 1412, training loss: 4103.52, average training loss: 3888.93, base loss: 4602.53
[INFO 2017-06-26 21:50:48,218 main.py:47] epoch 1413, training loss: 3203.85, average training loss: 3887.48, base loss: 4600.88
[INFO 2017-06-26 21:50:48,612 main.py:47] epoch 1414, training loss: 3526.40, average training loss: 3887.41, base loss: 4601.16
[INFO 2017-06-26 21:50:48,999 main.py:47] epoch 1415, training loss: 3798.51, average training loss: 3887.22, base loss: 4601.61
[INFO 2017-06-26 21:50:49,390 main.py:47] epoch 1416, training loss: 3511.27, average training loss: 3886.55, base loss: 4601.61
[INFO 2017-06-26 21:50:49,776 main.py:47] epoch 1417, training loss: 4189.24, average training loss: 3886.50, base loss: 4602.16
[INFO 2017-06-26 21:50:50,163 main.py:47] epoch 1418, training loss: 3541.49, average training loss: 3885.10, base loss: 4600.77
[INFO 2017-06-26 21:50:50,554 main.py:47] epoch 1419, training loss: 3791.20, average training loss: 3884.00, base loss: 4599.98
[INFO 2017-06-26 21:50:50,947 main.py:47] epoch 1420, training loss: 3106.72, average training loss: 3882.95, base loss: 4598.85
[INFO 2017-06-26 21:50:51,353 main.py:47] epoch 1421, training loss: 3206.44, average training loss: 3881.99, base loss: 4598.16
[INFO 2017-06-26 21:50:51,746 main.py:47] epoch 1422, training loss: 3521.13, average training loss: 3881.43, base loss: 4598.32
[INFO 2017-06-26 21:50:52,138 main.py:47] epoch 1423, training loss: 3243.01, average training loss: 3880.02, base loss: 4596.99
[INFO 2017-06-26 21:50:52,573 main.py:47] epoch 1424, training loss: 3657.41, average training loss: 3879.66, base loss: 4597.04
[INFO 2017-06-26 21:50:53,030 main.py:47] epoch 1425, training loss: 3174.73, average training loss: 3879.00, base loss: 4596.52
[INFO 2017-06-26 21:50:53,496 main.py:47] epoch 1426, training loss: 3644.03, average training loss: 3879.15, base loss: 4597.18
[INFO 2017-06-26 21:50:53,956 main.py:47] epoch 1427, training loss: 3903.24, average training loss: 3879.19, base loss: 4597.66
[INFO 2017-06-26 21:50:54,410 main.py:47] epoch 1428, training loss: 3834.23, average training loss: 3879.30, base loss: 4598.33
[INFO 2017-06-26 21:50:54,835 main.py:47] epoch 1429, training loss: 3328.82, average training loss: 3878.75, base loss: 4598.35
[INFO 2017-06-26 21:50:55,282 main.py:47] epoch 1430, training loss: 4443.95, average training loss: 3879.11, base loss: 4599.91
[INFO 2017-06-26 21:50:55,781 main.py:47] epoch 1431, training loss: 3655.16, average training loss: 3879.07, base loss: 4600.36
[INFO 2017-06-26 21:50:56,185 main.py:47] epoch 1432, training loss: 4456.86, average training loss: 3879.57, base loss: 4601.36
[INFO 2017-06-26 21:50:56,573 main.py:47] epoch 1433, training loss: 3292.09, average training loss: 3879.07, base loss: 4601.22
[INFO 2017-06-26 21:50:56,958 main.py:47] epoch 1434, training loss: 3213.15, average training loss: 3878.40, base loss: 4601.06
[INFO 2017-06-26 21:50:57,346 main.py:47] epoch 1435, training loss: 3728.28, average training loss: 3878.30, base loss: 4601.18
[INFO 2017-06-26 21:50:57,733 main.py:47] epoch 1436, training loss: 3349.79, average training loss: 3878.21, base loss: 4601.53
[INFO 2017-06-26 21:50:58,121 main.py:47] epoch 1437, training loss: 3193.14, average training loss: 3877.54, base loss: 4601.12
[INFO 2017-06-26 21:50:58,516 main.py:47] epoch 1438, training loss: 3833.78, average training loss: 3876.59, base loss: 4600.40
[INFO 2017-06-26 21:50:58,930 main.py:47] epoch 1439, training loss: 3325.25, average training loss: 3875.64, base loss: 4599.52
[INFO 2017-06-26 21:50:59,323 main.py:47] epoch 1440, training loss: 3148.06, average training loss: 3874.83, base loss: 4599.10
[INFO 2017-06-26 21:50:59,711 main.py:47] epoch 1441, training loss: 3337.80, average training loss: 3873.97, base loss: 4598.36
[INFO 2017-06-26 21:51:00,098 main.py:47] epoch 1442, training loss: 3556.96, average training loss: 3873.20, base loss: 4597.98
[INFO 2017-06-26 21:51:00,558 main.py:47] epoch 1443, training loss: 3907.84, average training loss: 3873.28, base loss: 4598.67
[INFO 2017-06-26 21:51:00,962 main.py:47] epoch 1444, training loss: 3997.10, average training loss: 3872.97, base loss: 4598.98
[INFO 2017-06-26 21:51:01,357 main.py:47] epoch 1445, training loss: 3940.79, average training loss: 3872.68, base loss: 4599.25
[INFO 2017-06-26 21:51:01,744 main.py:47] epoch 1446, training loss: 6884.64, average training loss: 3871.97, base loss: 4598.78
[INFO 2017-06-26 21:51:02,128 main.py:47] epoch 1447, training loss: 3642.30, average training loss: 3871.11, base loss: 4598.44
[INFO 2017-06-26 21:51:02,594 main.py:47] epoch 1448, training loss: 3671.53, average training loss: 3871.07, base loss: 4598.83
[INFO 2017-06-26 21:51:03,000 main.py:47] epoch 1449, training loss: 3594.72, average training loss: 3870.81, base loss: 4599.10
[INFO 2017-06-26 21:51:03,399 main.py:47] epoch 1450, training loss: 3358.87, average training loss: 3870.81, base loss: 4599.73
[INFO 2017-06-26 21:51:03,848 main.py:47] epoch 1451, training loss: 3591.33, average training loss: 3870.91, base loss: 4600.18
[INFO 2017-06-26 21:51:04,251 main.py:47] epoch 1452, training loss: 3892.70, average training loss: 3870.74, base loss: 4600.69
[INFO 2017-06-26 21:51:04,639 main.py:47] epoch 1453, training loss: 3589.72, average training loss: 3869.49, base loss: 4599.69
[INFO 2017-06-26 21:51:05,038 main.py:47] epoch 1454, training loss: 3732.29, average training loss: 3869.41, base loss: 4600.33
[INFO 2017-06-26 21:51:05,426 main.py:47] epoch 1455, training loss: 3576.28, average training loss: 3869.30, base loss: 4600.67
[INFO 2017-06-26 21:51:05,812 main.py:47] epoch 1456, training loss: 3571.81, average training loss: 3868.89, base loss: 4600.33
[INFO 2017-06-26 21:51:06,191 main.py:47] epoch 1457, training loss: 3785.97, average training loss: 3868.89, base loss: 4600.37
[INFO 2017-06-26 21:51:06,666 main.py:47] epoch 1458, training loss: 3814.33, average training loss: 3868.26, base loss: 4599.94
[INFO 2017-06-26 21:51:07,069 main.py:47] epoch 1459, training loss: 3505.90, average training loss: 3867.61, base loss: 4599.62
[INFO 2017-06-26 21:51:07,455 main.py:47] epoch 1460, training loss: 3838.50, average training loss: 3867.73, base loss: 4600.51
[INFO 2017-06-26 21:51:07,847 main.py:47] epoch 1461, training loss: 3614.18, average training loss: 3867.10, base loss: 4600.15
[INFO 2017-06-26 21:51:08,230 main.py:47] epoch 1462, training loss: 7219.71, average training loss: 3870.14, base loss: 4603.59
[INFO 2017-06-26 21:51:08,618 main.py:47] epoch 1463, training loss: 4101.99, average training loss: 3869.97, base loss: 4604.11
[INFO 2017-06-26 21:51:09,006 main.py:47] epoch 1464, training loss: 3869.00, average training loss: 3870.24, base loss: 4605.02
[INFO 2017-06-26 21:51:09,391 main.py:47] epoch 1465, training loss: 4010.82, average training loss: 3869.73, base loss: 4605.27
[INFO 2017-06-26 21:51:09,848 main.py:47] epoch 1466, training loss: 3297.21, average training loss: 3868.78, base loss: 4604.32
[INFO 2017-06-26 21:51:10,251 main.py:47] epoch 1467, training loss: 3525.27, average training loss: 3868.14, base loss: 4604.24
[INFO 2017-06-26 21:51:10,650 main.py:47] epoch 1468, training loss: 3268.01, average training loss: 3867.69, base loss: 4604.13
[INFO 2017-06-26 21:51:11,042 main.py:47] epoch 1469, training loss: 3642.45, average training loss: 3867.18, base loss: 4604.04
[INFO 2017-06-26 21:51:11,428 main.py:47] epoch 1470, training loss: 3189.55, average training loss: 3866.11, base loss: 4603.03
[INFO 2017-06-26 21:51:11,814 main.py:47] epoch 1471, training loss: 3310.96, average training loss: 3865.71, base loss: 4602.93
[INFO 2017-06-26 21:51:12,199 main.py:47] epoch 1472, training loss: 3486.75, average training loss: 3865.66, base loss: 4603.17
[INFO 2017-06-26 21:51:12,585 main.py:47] epoch 1473, training loss: 3708.39, average training loss: 3865.24, base loss: 4603.07
[INFO 2017-06-26 21:51:12,972 main.py:47] epoch 1474, training loss: 3973.57, average training loss: 3865.71, base loss: 4604.14
[INFO 2017-06-26 21:51:13,443 main.py:47] epoch 1475, training loss: 3274.62, average training loss: 3864.35, base loss: 4602.92
[INFO 2017-06-26 21:51:13,834 main.py:47] epoch 1476, training loss: 3859.98, average training loss: 3864.41, base loss: 4603.21
[INFO 2017-06-26 21:51:14,228 main.py:47] epoch 1477, training loss: 4103.13, average training loss: 3864.29, base loss: 4603.37
[INFO 2017-06-26 21:51:14,615 main.py:47] epoch 1478, training loss: 3400.50, average training loss: 3863.25, base loss: 4602.60
[INFO 2017-06-26 21:51:15,070 main.py:47] epoch 1479, training loss: 3531.79, average training loss: 3862.18, base loss: 4601.91
[INFO 2017-06-26 21:51:15,456 main.py:47] epoch 1480, training loss: 3615.85, average training loss: 3861.17, base loss: 4600.96
[INFO 2017-06-26 21:51:15,843 main.py:47] epoch 1481, training loss: 3188.59, average training loss: 3860.24, base loss: 4600.30
[INFO 2017-06-26 21:51:16,300 main.py:47] epoch 1482, training loss: 3587.68, average training loss: 3859.62, base loss: 4600.20
[INFO 2017-06-26 21:51:16,724 main.py:47] epoch 1483, training loss: 3194.90, average training loss: 3859.39, base loss: 4600.21
[INFO 2017-06-26 21:51:17,201 main.py:47] epoch 1484, training loss: 3438.30, average training loss: 3858.71, base loss: 4600.17
[INFO 2017-06-26 21:51:17,622 main.py:47] epoch 1485, training loss: 3331.39, average training loss: 3858.07, base loss: 4600.20
[INFO 2017-06-26 21:51:18,046 main.py:47] epoch 1486, training loss: 3288.76, average training loss: 3857.24, base loss: 4599.73
[INFO 2017-06-26 21:51:18,473 main.py:47] epoch 1487, training loss: 3647.17, average training loss: 3857.43, base loss: 4600.52
[INFO 2017-06-26 21:51:18,862 main.py:47] epoch 1488, training loss: 3544.06, average training loss: 3857.09, base loss: 4600.30
[INFO 2017-06-26 21:51:19,250 main.py:47] epoch 1489, training loss: 7264.30, average training loss: 3859.93, base loss: 4603.80
[INFO 2017-06-26 21:51:19,689 main.py:47] epoch 1490, training loss: 3585.55, average training loss: 3859.53, base loss: 4603.85
[INFO 2017-06-26 21:51:20,101 main.py:47] epoch 1491, training loss: 3257.16, average training loss: 3858.46, base loss: 4603.16
[INFO 2017-06-26 21:51:20,519 main.py:47] epoch 1492, training loss: 3672.05, average training loss: 3854.92, base loss: 4600.40
[INFO 2017-06-26 21:51:20,931 main.py:47] epoch 1493, training loss: 3830.63, average training loss: 3854.91, base loss: 4601.02
[INFO 2017-06-26 21:51:21,320 main.py:47] epoch 1494, training loss: 3510.71, average training loss: 3854.07, base loss: 4600.96
[INFO 2017-06-26 21:51:21,761 main.py:47] epoch 1495, training loss: 3245.67, average training loss: 3853.07, base loss: 4600.24
[INFO 2017-06-26 21:51:22,155 main.py:47] epoch 1496, training loss: 3384.20, average training loss: 3852.56, base loss: 4600.24
[INFO 2017-06-26 21:51:22,634 main.py:47] epoch 1497, training loss: 3700.14, average training loss: 3852.65, base loss: 4600.78
[INFO 2017-06-26 21:51:23,040 main.py:47] epoch 1498, training loss: 3838.17, average training loss: 3853.10, base loss: 4601.58
[INFO 2017-06-26 21:51:23,428 main.py:47] epoch 1499, training loss: 3198.88, average training loss: 3851.85, base loss: 4600.28
[INFO 2017-06-26 21:51:23,428 main.py:49] epoch 1499, testing
[INFO 2017-06-26 21:51:24,993 main.py:101] average testing loss: 4095.10, base loss: 5153.46, improve_loss: 1058.36
[INFO 2017-06-26 21:51:24,994 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:51:25,009 main.py:73] current best improved loss: 1058.36
[INFO 2017-06-26 21:51:25,414 main.py:47] epoch 1500, training loss: 3585.08, average training loss: 3851.82, base loss: 4600.91
[INFO 2017-06-26 21:51:25,801 main.py:47] epoch 1501, training loss: 4082.96, average training loss: 3852.58, base loss: 4602.40
[INFO 2017-06-26 21:51:26,183 main.py:47] epoch 1502, training loss: 3380.81, average training loss: 3851.69, base loss: 4601.73
[INFO 2017-06-26 21:51:26,570 main.py:47] epoch 1503, training loss: 3350.79, average training loss: 3851.10, base loss: 4601.39
[INFO 2017-06-26 21:51:26,956 main.py:47] epoch 1504, training loss: 3870.42, average training loss: 3850.27, base loss: 4600.83
[INFO 2017-06-26 21:51:27,341 main.py:47] epoch 1505, training loss: 3395.71, average training loss: 3848.92, base loss: 4599.67
[INFO 2017-06-26 21:51:27,726 main.py:47] epoch 1506, training loss: 3937.47, average training loss: 3848.74, base loss: 4600.02
[INFO 2017-06-26 21:51:28,110 main.py:47] epoch 1507, training loss: 7043.37, average training loss: 3851.69, base loss: 4603.44
[INFO 2017-06-26 21:51:28,497 main.py:47] epoch 1508, training loss: 3726.62, average training loss: 3851.84, base loss: 4604.58
[INFO 2017-06-26 21:51:28,879 main.py:47] epoch 1509, training loss: 3599.02, average training loss: 3851.02, base loss: 4603.90
[INFO 2017-06-26 21:51:29,265 main.py:47] epoch 1510, training loss: 6596.08, average training loss: 3853.94, base loss: 4607.08
[INFO 2017-06-26 21:51:29,651 main.py:47] epoch 1511, training loss: 3214.45, average training loss: 3853.13, base loss: 4606.20
[INFO 2017-06-26 21:51:30,040 main.py:47] epoch 1512, training loss: 3401.58, average training loss: 3852.00, base loss: 4604.96
[INFO 2017-06-26 21:51:30,427 main.py:47] epoch 1513, training loss: 3746.69, average training loss: 3851.93, base loss: 4605.25
[INFO 2017-06-26 21:51:30,817 main.py:47] epoch 1514, training loss: 3810.20, average training loss: 3852.02, base loss: 4605.88
[INFO 2017-06-26 21:51:31,208 main.py:47] epoch 1515, training loss: 2829.41, average training loss: 3850.76, base loss: 4604.28
[INFO 2017-06-26 21:51:31,598 main.py:47] epoch 1516, training loss: 6999.60, average training loss: 3854.04, base loss: 4608.01
[INFO 2017-06-26 21:51:31,986 main.py:47] epoch 1517, training loss: 4388.51, average training loss: 3854.81, base loss: 4610.10
[INFO 2017-06-26 21:51:32,379 main.py:47] epoch 1518, training loss: 3660.02, average training loss: 3854.76, base loss: 4610.47
[INFO 2017-06-26 21:51:32,782 main.py:47] epoch 1519, training loss: 3782.15, average training loss: 3854.34, base loss: 4610.75
[INFO 2017-06-26 21:51:33,174 main.py:47] epoch 1520, training loss: 3452.86, average training loss: 3854.54, base loss: 4611.48
[INFO 2017-06-26 21:51:33,565 main.py:47] epoch 1521, training loss: 3880.82, average training loss: 3853.99, base loss: 4611.44
[INFO 2017-06-26 21:51:33,962 main.py:47] epoch 1522, training loss: 3500.39, average training loss: 3849.45, base loss: 4607.38
[INFO 2017-06-26 21:51:34,395 main.py:47] epoch 1523, training loss: 3245.28, average training loss: 3849.30, base loss: 4607.60
[INFO 2017-06-26 21:51:34,858 main.py:47] epoch 1524, training loss: 3091.07, average training loss: 3849.18, base loss: 4607.77
[INFO 2017-06-26 21:51:35,324 main.py:47] epoch 1525, training loss: 3573.38, average training loss: 3849.14, base loss: 4608.23
[INFO 2017-06-26 21:51:35,772 main.py:47] epoch 1526, training loss: 3245.07, average training loss: 3847.45, base loss: 4606.73
[INFO 2017-06-26 21:51:36,249 main.py:47] epoch 1527, training loss: 4125.86, average training loss: 3843.93, base loss: 4604.02
[INFO 2017-06-26 21:51:36,658 main.py:47] epoch 1528, training loss: 4056.98, average training loss: 3844.18, base loss: 4604.57
[INFO 2017-06-26 21:51:37,144 main.py:47] epoch 1529, training loss: 3688.72, average training loss: 3843.66, base loss: 4604.54
[INFO 2017-06-26 21:51:37,612 main.py:47] epoch 1530, training loss: 3967.10, average training loss: 3842.54, base loss: 4603.64
[INFO 2017-06-26 21:51:38,021 main.py:47] epoch 1531, training loss: 3700.30, average training loss: 3841.57, base loss: 4602.74
[INFO 2017-06-26 21:51:38,416 main.py:47] epoch 1532, training loss: 3389.14, average training loss: 3841.45, base loss: 4602.66
[INFO 2017-06-26 21:51:38,799 main.py:47] epoch 1533, training loss: 3850.22, average training loss: 3841.59, base loss: 4603.70
[INFO 2017-06-26 21:51:39,183 main.py:47] epoch 1534, training loss: 3155.47, average training loss: 3840.66, base loss: 4602.77
[INFO 2017-06-26 21:51:39,576 main.py:47] epoch 1535, training loss: 3444.26, average training loss: 3840.02, base loss: 4602.01
[INFO 2017-06-26 21:51:40,063 main.py:47] epoch 1536, training loss: 3644.30, average training loss: 3839.84, base loss: 4602.25
[INFO 2017-06-26 21:51:40,450 main.py:47] epoch 1537, training loss: 3181.53, average training loss: 3838.83, base loss: 4601.45
[INFO 2017-06-26 21:51:40,917 main.py:47] epoch 1538, training loss: 3978.97, average training loss: 3838.38, base loss: 4601.01
[INFO 2017-06-26 21:51:41,324 main.py:47] epoch 1539, training loss: 3998.07, average training loss: 3838.62, base loss: 4602.06
[INFO 2017-06-26 21:51:41,800 main.py:47] epoch 1540, training loss: 3545.02, average training loss: 3837.98, base loss: 4601.42
[INFO 2017-06-26 21:51:42,218 main.py:47] epoch 1541, training loss: 3115.99, average training loss: 3836.45, base loss: 4599.94
[INFO 2017-06-26 21:51:42,607 main.py:47] epoch 1542, training loss: 3237.77, average training loss: 3835.91, base loss: 4599.57
[INFO 2017-06-26 21:51:42,999 main.py:47] epoch 1543, training loss: 4020.46, average training loss: 3836.21, base loss: 4600.75
[INFO 2017-06-26 21:51:43,391 main.py:47] epoch 1544, training loss: 3394.92, average training loss: 3836.29, base loss: 4601.29
[INFO 2017-06-26 21:51:43,781 main.py:47] epoch 1545, training loss: 3140.23, average training loss: 3834.77, base loss: 4600.26
[INFO 2017-06-26 21:51:44,170 main.py:47] epoch 1546, training loss: 3284.22, average training loss: 3834.03, base loss: 4599.85
[INFO 2017-06-26 21:51:44,558 main.py:47] epoch 1547, training loss: 3340.06, average training loss: 3832.34, base loss: 4598.31
[INFO 2017-06-26 21:51:44,956 main.py:47] epoch 1548, training loss: 3536.84, average training loss: 3832.12, base loss: 4598.55
[INFO 2017-06-26 21:51:45,344 main.py:47] epoch 1549, training loss: 3420.24, average training loss: 3831.19, base loss: 4597.85
[INFO 2017-06-26 21:51:45,735 main.py:47] epoch 1550, training loss: 4593.05, average training loss: 3831.81, base loss: 4599.15
[INFO 2017-06-26 21:51:46,119 main.py:47] epoch 1551, training loss: 3850.24, average training loss: 3831.51, base loss: 4599.40
[INFO 2017-06-26 21:51:46,498 main.py:47] epoch 1552, training loss: 3322.78, average training loss: 3830.68, base loss: 4598.72
[INFO 2017-06-26 21:51:46,887 main.py:47] epoch 1553, training loss: 3725.92, average training loss: 3830.44, base loss: 4599.08
[INFO 2017-06-26 21:51:47,271 main.py:47] epoch 1554, training loss: 3439.90, average training loss: 3829.94, base loss: 4598.76
[INFO 2017-06-26 21:51:47,650 main.py:47] epoch 1555, training loss: 3604.27, average training loss: 3829.75, base loss: 4598.88
[INFO 2017-06-26 21:51:48,037 main.py:47] epoch 1556, training loss: 3424.38, average training loss: 3829.17, base loss: 4598.37
[INFO 2017-06-26 21:51:48,428 main.py:47] epoch 1557, training loss: 3207.68, average training loss: 3829.05, base loss: 4598.58
[INFO 2017-06-26 21:51:48,812 main.py:47] epoch 1558, training loss: 3291.25, average training loss: 3828.33, base loss: 4598.26
[INFO 2017-06-26 21:51:49,202 main.py:47] epoch 1559, training loss: 3721.78, average training loss: 3828.03, base loss: 4598.28
[INFO 2017-06-26 21:51:49,587 main.py:47] epoch 1560, training loss: 3724.28, average training loss: 3828.45, base loss: 4599.18
[INFO 2017-06-26 21:51:49,971 main.py:47] epoch 1561, training loss: 3865.93, average training loss: 3825.35, base loss: 4596.94
[INFO 2017-06-26 21:51:50,356 main.py:47] epoch 1562, training loss: 6695.07, average training loss: 3828.22, base loss: 4599.87
[INFO 2017-06-26 21:51:50,736 main.py:47] epoch 1563, training loss: 3794.78, average training loss: 3827.47, base loss: 4599.54
[INFO 2017-06-26 21:51:51,117 main.py:47] epoch 1564, training loss: 3649.05, average training loss: 3827.04, base loss: 4599.86
[INFO 2017-06-26 21:51:51,500 main.py:47] epoch 1565, training loss: 3472.55, average training loss: 3825.65, base loss: 4598.23
[INFO 2017-06-26 21:51:51,881 main.py:47] epoch 1566, training loss: 3471.97, average training loss: 3825.06, base loss: 4597.63
[INFO 2017-06-26 21:51:52,261 main.py:47] epoch 1567, training loss: 3795.31, average training loss: 3824.97, base loss: 4598.11
[INFO 2017-06-26 21:51:52,643 main.py:47] epoch 1568, training loss: 3318.24, average training loss: 3824.90, base loss: 4598.68
[INFO 2017-06-26 21:51:53,029 main.py:47] epoch 1569, training loss: 3325.48, average training loss: 3824.70, base loss: 4599.08
[INFO 2017-06-26 21:51:53,417 main.py:47] epoch 1570, training loss: 3526.66, average training loss: 3824.30, base loss: 4599.07
[INFO 2017-06-26 21:51:53,803 main.py:47] epoch 1571, training loss: 4062.25, average training loss: 3824.38, base loss: 4600.07
[INFO 2017-06-26 21:51:54,188 main.py:47] epoch 1572, training loss: 3517.46, average training loss: 3824.38, base loss: 4600.84
[INFO 2017-06-26 21:51:54,568 main.py:47] epoch 1573, training loss: 7056.02, average training loss: 3827.67, base loss: 4604.57
[INFO 2017-06-26 21:51:54,952 main.py:47] epoch 1574, training loss: 4254.06, average training loss: 3828.12, base loss: 4605.94
[INFO 2017-06-26 21:51:55,336 main.py:47] epoch 1575, training loss: 7485.99, average training loss: 3831.71, base loss: 4610.20
[INFO 2017-06-26 21:51:55,720 main.py:47] epoch 1576, training loss: 3885.31, average training loss: 3831.92, base loss: 4610.93
[INFO 2017-06-26 21:51:56,102 main.py:47] epoch 1577, training loss: 3116.26, average training loss: 3830.75, base loss: 4609.51
[INFO 2017-06-26 21:51:56,482 main.py:47] epoch 1578, training loss: 3599.91, average training loss: 3830.65, base loss: 4609.88
[INFO 2017-06-26 21:51:56,866 main.py:47] epoch 1579, training loss: 3589.38, average training loss: 3830.06, base loss: 4609.57
[INFO 2017-06-26 21:51:57,253 main.py:47] epoch 1580, training loss: 3522.51, average training loss: 3829.62, base loss: 4609.69
[INFO 2017-06-26 21:51:57,638 main.py:47] epoch 1581, training loss: 3606.34, average training loss: 3829.59, base loss: 4610.23
[INFO 2017-06-26 21:51:58,025 main.py:47] epoch 1582, training loss: 3517.83, average training loss: 3829.42, base loss: 4610.95
[INFO 2017-06-26 21:51:58,407 main.py:47] epoch 1583, training loss: 3192.91, average training loss: 3828.58, base loss: 4610.62
[INFO 2017-06-26 21:51:58,792 main.py:47] epoch 1584, training loss: 4048.60, average training loss: 3829.08, base loss: 4612.04
[INFO 2017-06-26 21:51:59,179 main.py:47] epoch 1585, training loss: 3580.41, average training loss: 3828.94, base loss: 4612.26
[INFO 2017-06-26 21:51:59,564 main.py:47] epoch 1586, training loss: 3747.03, average training loss: 3825.70, base loss: 4609.80
[INFO 2017-06-26 21:51:59,949 main.py:47] epoch 1587, training loss: 3476.43, average training loss: 3825.45, base loss: 4610.28
[INFO 2017-06-26 21:52:00,334 main.py:47] epoch 1588, training loss: 3543.45, average training loss: 3824.91, base loss: 4609.95
[INFO 2017-06-26 21:52:00,716 main.py:47] epoch 1589, training loss: 3175.81, average training loss: 3823.75, base loss: 4608.86
[INFO 2017-06-26 21:52:01,103 main.py:47] epoch 1590, training loss: 3634.50, average training loss: 3823.36, base loss: 4608.79
[INFO 2017-06-26 21:52:01,488 main.py:47] epoch 1591, training loss: 3499.05, average training loss: 3822.95, base loss: 4608.74
[INFO 2017-06-26 21:52:01,873 main.py:47] epoch 1592, training loss: 3034.82, average training loss: 3822.02, base loss: 4608.01
[INFO 2017-06-26 21:52:02,254 main.py:47] epoch 1593, training loss: 3309.32, average training loss: 3821.95, base loss: 4608.42
[INFO 2017-06-26 21:52:02,640 main.py:47] epoch 1594, training loss: 2973.94, average training loss: 3821.35, base loss: 4607.92
[INFO 2017-06-26 21:52:03,028 main.py:47] epoch 1595, training loss: 3464.60, average training loss: 3821.19, base loss: 4608.09
[INFO 2017-06-26 21:52:03,412 main.py:47] epoch 1596, training loss: 3636.13, average training loss: 3820.48, base loss: 4607.68
[INFO 2017-06-26 21:52:03,806 main.py:47] epoch 1597, training loss: 3773.77, average training loss: 3820.74, base loss: 4608.47
[INFO 2017-06-26 21:52:04,191 main.py:47] epoch 1598, training loss: 3307.17, average training loss: 3816.78, base loss: 4604.84
[INFO 2017-06-26 21:52:04,576 main.py:47] epoch 1599, training loss: 3495.52, average training loss: 3816.59, base loss: 4605.17
[INFO 2017-06-26 21:52:04,576 main.py:49] epoch 1599, testing
[INFO 2017-06-26 21:52:06,070 main.py:101] average testing loss: 3504.22, base loss: 4494.47, improve_loss: 990.25
[INFO 2017-06-26 21:52:06,071 main.py:73] current best improved loss: 1058.36
[INFO 2017-06-26 21:52:06,453 main.py:47] epoch 1600, training loss: 6478.81, average training loss: 3819.67, base loss: 4608.70
[INFO 2017-06-26 21:52:06,838 main.py:47] epoch 1601, training loss: 3127.15, average training loss: 3819.46, base loss: 4609.07
[INFO 2017-06-26 21:52:07,229 main.py:47] epoch 1602, training loss: 3663.50, average training loss: 3819.84, base loss: 4610.07
[INFO 2017-06-26 21:52:07,611 main.py:47] epoch 1603, training loss: 3298.26, average training loss: 3819.45, base loss: 4610.07
[INFO 2017-06-26 21:52:07,992 main.py:47] epoch 1604, training loss: 3088.02, average training loss: 3818.93, base loss: 4609.83
[INFO 2017-06-26 21:52:08,379 main.py:47] epoch 1605, training loss: 3230.24, average training loss: 3818.42, base loss: 4609.50
[INFO 2017-06-26 21:52:08,764 main.py:47] epoch 1606, training loss: 3190.11, average training loss: 3817.82, base loss: 4609.26
[INFO 2017-06-26 21:52:09,143 main.py:47] epoch 1607, training loss: 3328.18, average training loss: 3817.86, base loss: 4609.82
[INFO 2017-06-26 21:52:09,526 main.py:47] epoch 1608, training loss: 3215.08, average training loss: 3816.62, base loss: 4608.71
[INFO 2017-06-26 21:52:09,909 main.py:47] epoch 1609, training loss: 3054.56, average training loss: 3815.66, base loss: 4607.78
[INFO 2017-06-26 21:52:10,294 main.py:47] epoch 1610, training loss: 2956.53, average training loss: 3811.18, base loss: 4603.19
[INFO 2017-06-26 21:52:10,686 main.py:47] epoch 1611, training loss: 4245.53, average training loss: 3807.78, base loss: 4600.32
[INFO 2017-06-26 21:52:11,069 main.py:47] epoch 1612, training loss: 3336.40, average training loss: 3807.50, base loss: 4600.20
[INFO 2017-06-26 21:52:11,455 main.py:47] epoch 1613, training loss: 3935.84, average training loss: 3807.92, base loss: 4601.27
[INFO 2017-06-26 21:52:11,837 main.py:47] epoch 1614, training loss: 3688.71, average training loss: 3808.10, base loss: 4602.14
[INFO 2017-06-26 21:52:12,220 main.py:47] epoch 1615, training loss: 3169.53, average training loss: 3807.70, base loss: 4601.49
[INFO 2017-06-26 21:52:12,604 main.py:47] epoch 1616, training loss: 3500.75, average training loss: 3807.13, base loss: 4601.18
[INFO 2017-06-26 21:52:12,989 main.py:47] epoch 1617, training loss: 2946.75, average training loss: 3806.20, base loss: 4600.53
[INFO 2017-06-26 21:52:13,375 main.py:47] epoch 1618, training loss: 3625.73, average training loss: 3805.68, base loss: 4600.36
[INFO 2017-06-26 21:52:13,759 main.py:47] epoch 1619, training loss: 3921.98, average training loss: 3806.20, base loss: 4601.51
[INFO 2017-06-26 21:52:14,148 main.py:47] epoch 1620, training loss: 3286.76, average training loss: 3805.74, base loss: 4601.25
[INFO 2017-06-26 21:52:14,537 main.py:47] epoch 1621, training loss: 3778.39, average training loss: 3805.81, base loss: 4601.66
[INFO 2017-06-26 21:52:14,925 main.py:47] epoch 1622, training loss: 3334.57, average training loss: 3805.52, base loss: 4601.56
[INFO 2017-06-26 21:52:15,314 main.py:47] epoch 1623, training loss: 3359.54, average training loss: 3804.86, base loss: 4601.23
[INFO 2017-06-26 21:52:15,696 main.py:47] epoch 1624, training loss: 3589.11, average training loss: 3804.56, base loss: 4601.29
[INFO 2017-06-26 21:52:16,083 main.py:47] epoch 1625, training loss: 3690.52, average training loss: 3804.17, base loss: 4601.28
[INFO 2017-06-26 21:52:16,470 main.py:47] epoch 1626, training loss: 2863.29, average training loss: 3802.96, base loss: 4599.96
[INFO 2017-06-26 21:52:16,857 main.py:47] epoch 1627, training loss: 3358.98, average training loss: 3802.37, base loss: 4599.70
[INFO 2017-06-26 21:52:17,243 main.py:47] epoch 1628, training loss: 3552.88, average training loss: 3801.72, base loss: 4599.36
[INFO 2017-06-26 21:52:17,627 main.py:47] epoch 1629, training loss: 3571.68, average training loss: 3801.36, base loss: 4599.50
[INFO 2017-06-26 21:52:18,015 main.py:47] epoch 1630, training loss: 6846.29, average training loss: 3804.29, base loss: 4602.70
[INFO 2017-06-26 21:52:18,400 main.py:47] epoch 1631, training loss: 3576.48, average training loss: 3804.44, base loss: 4603.59
[INFO 2017-06-26 21:52:18,787 main.py:47] epoch 1632, training loss: 3585.61, average training loss: 3804.42, base loss: 4604.08
[INFO 2017-06-26 21:52:19,181 main.py:47] epoch 1633, training loss: 3106.63, average training loss: 3803.61, base loss: 4603.46
[INFO 2017-06-26 21:52:19,567 main.py:47] epoch 1634, training loss: 3658.51, average training loss: 3804.04, base loss: 4604.51
[INFO 2017-06-26 21:52:19,956 main.py:47] epoch 1635, training loss: 3640.90, average training loss: 3804.28, base loss: 4605.21
[INFO 2017-06-26 21:52:20,355 main.py:47] epoch 1636, training loss: 3445.29, average training loss: 3803.48, base loss: 4604.57
[INFO 2017-06-26 21:52:20,746 main.py:47] epoch 1637, training loss: 3246.03, average training loss: 3803.04, base loss: 4604.33
[INFO 2017-06-26 21:52:21,140 main.py:47] epoch 1638, training loss: 3186.18, average training loss: 3802.90, base loss: 4604.34
[INFO 2017-06-26 21:52:21,542 main.py:47] epoch 1639, training loss: 3115.07, average training loss: 3802.22, base loss: 4603.85
[INFO 2017-06-26 21:52:21,929 main.py:47] epoch 1640, training loss: 3892.46, average training loss: 3802.47, base loss: 4605.11
[INFO 2017-06-26 21:52:22,315 main.py:47] epoch 1641, training loss: 3483.15, average training loss: 3802.24, base loss: 4605.00
[INFO 2017-06-26 21:52:22,706 main.py:47] epoch 1642, training loss: 3543.39, average training loss: 3802.32, base loss: 4605.37
[INFO 2017-06-26 21:52:23,092 main.py:47] epoch 1643, training loss: 3411.18, average training loss: 3802.01, base loss: 4605.49
[INFO 2017-06-26 21:52:23,484 main.py:47] epoch 1644, training loss: 3727.63, average training loss: 3802.33, base loss: 4606.79
[INFO 2017-06-26 21:52:23,888 main.py:47] epoch 1645, training loss: 3440.24, average training loss: 3801.82, base loss: 4606.57
[INFO 2017-06-26 21:52:24,274 main.py:47] epoch 1646, training loss: 3726.04, average training loss: 3801.14, base loss: 4605.85
[INFO 2017-06-26 21:52:24,665 main.py:47] epoch 1647, training loss: 3394.60, average training loss: 3800.79, base loss: 4605.97
[INFO 2017-06-26 21:52:25,053 main.py:47] epoch 1648, training loss: 3538.06, average training loss: 3800.95, base loss: 4606.67
[INFO 2017-06-26 21:52:25,440 main.py:47] epoch 1649, training loss: 3269.05, average training loss: 3800.25, base loss: 4606.23
[INFO 2017-06-26 21:52:25,827 main.py:47] epoch 1650, training loss: 4031.26, average training loss: 3800.53, base loss: 4607.34
[INFO 2017-06-26 21:52:26,216 main.py:47] epoch 1651, training loss: 3110.56, average training loss: 3800.01, base loss: 4606.89
[INFO 2017-06-26 21:52:26,603 main.py:47] epoch 1652, training loss: 3762.48, average training loss: 3800.06, base loss: 4607.16
[INFO 2017-06-26 21:52:26,992 main.py:47] epoch 1653, training loss: 3492.26, average training loss: 3799.60, base loss: 4607.16
[INFO 2017-06-26 21:52:27,384 main.py:47] epoch 1654, training loss: 3375.79, average training loss: 3798.78, base loss: 4606.87
[INFO 2017-06-26 21:52:27,775 main.py:47] epoch 1655, training loss: 3328.81, average training loss: 3798.21, base loss: 4606.52
[INFO 2017-06-26 21:52:28,164 main.py:47] epoch 1656, training loss: 2962.46, average training loss: 3797.72, base loss: 4606.20
[INFO 2017-06-26 21:52:28,552 main.py:47] epoch 1657, training loss: 3540.13, average training loss: 3796.95, base loss: 4605.40
[INFO 2017-06-26 21:52:28,944 main.py:47] epoch 1658, training loss: 3427.44, average training loss: 3796.84, base loss: 4605.84
[INFO 2017-06-26 21:52:29,333 main.py:47] epoch 1659, training loss: 2867.63, average training loss: 3795.88, base loss: 4604.98
[INFO 2017-06-26 21:52:29,722 main.py:47] epoch 1660, training loss: 3833.66, average training loss: 3795.83, base loss: 4605.41
[INFO 2017-06-26 21:52:30,114 main.py:47] epoch 1661, training loss: 3504.74, average training loss: 3795.58, base loss: 4605.30
[INFO 2017-06-26 21:52:30,508 main.py:47] epoch 1662, training loss: 3916.91, average training loss: 3795.76, base loss: 4606.24
[INFO 2017-06-26 21:52:30,897 main.py:47] epoch 1663, training loss: 3447.74, average training loss: 3795.28, base loss: 4605.78
[INFO 2017-06-26 21:52:31,288 main.py:47] epoch 1664, training loss: 3280.61, average training loss: 3795.08, base loss: 4605.85
[INFO 2017-06-26 21:52:31,677 main.py:47] epoch 1665, training loss: 3886.99, average training loss: 3794.84, base loss: 4606.10
[INFO 2017-06-26 21:52:32,065 main.py:47] epoch 1666, training loss: 3645.22, average training loss: 3794.43, base loss: 4605.98
[INFO 2017-06-26 21:52:32,453 main.py:47] epoch 1667, training loss: 2948.43, average training loss: 3794.22, base loss: 4605.88
[INFO 2017-06-26 21:52:32,847 main.py:47] epoch 1668, training loss: 3742.52, average training loss: 3794.10, base loss: 4606.09
[INFO 2017-06-26 21:52:33,236 main.py:47] epoch 1669, training loss: 3995.79, average training loss: 3794.07, base loss: 4606.63
[INFO 2017-06-26 21:52:33,628 main.py:47] epoch 1670, training loss: 3588.65, average training loss: 3794.25, base loss: 4607.22
[INFO 2017-06-26 21:52:34,016 main.py:47] epoch 1671, training loss: 3238.43, average training loss: 3793.14, base loss: 4606.43
[INFO 2017-06-26 21:52:34,405 main.py:47] epoch 1672, training loss: 2965.15, average training loss: 3792.25, base loss: 4605.69
[INFO 2017-06-26 21:52:34,795 main.py:47] epoch 1673, training loss: 3441.24, average training loss: 3791.43, base loss: 4604.86
[INFO 2017-06-26 21:52:35,184 main.py:47] epoch 1674, training loss: 3466.91, average training loss: 3791.29, base loss: 4605.39
[INFO 2017-06-26 21:52:35,572 main.py:47] epoch 1675, training loss: 3239.97, average training loss: 3790.81, base loss: 4605.03
[INFO 2017-06-26 21:52:35,961 main.py:47] epoch 1676, training loss: 3450.87, average training loss: 3787.29, base loss: 4602.07
[INFO 2017-06-26 21:52:36,351 main.py:47] epoch 1677, training loss: 3652.83, average training loss: 3786.76, base loss: 4601.66
[INFO 2017-06-26 21:52:36,740 main.py:47] epoch 1678, training loss: 3186.59, average training loss: 3786.04, base loss: 4601.13
[INFO 2017-06-26 21:52:37,131 main.py:47] epoch 1679, training loss: 3173.78, average training loss: 3785.24, base loss: 4600.69
[INFO 2017-06-26 21:52:37,523 main.py:47] epoch 1680, training loss: 3733.87, average training loss: 3785.10, base loss: 4600.98
[INFO 2017-06-26 21:52:37,914 main.py:47] epoch 1681, training loss: 3520.95, average training loss: 3784.78, base loss: 4601.14
[INFO 2017-06-26 21:52:38,305 main.py:47] epoch 1682, training loss: 3248.09, average training loss: 3783.80, base loss: 4600.47
[INFO 2017-06-26 21:52:38,692 main.py:47] epoch 1683, training loss: 3093.61, average training loss: 3783.23, base loss: 4600.11
[INFO 2017-06-26 21:52:39,080 main.py:47] epoch 1684, training loss: 3938.14, average training loss: 3783.86, base loss: 4601.54
[INFO 2017-06-26 21:52:39,468 main.py:47] epoch 1685, training loss: 3730.47, average training loss: 3783.49, base loss: 4601.53
[INFO 2017-06-26 21:52:39,860 main.py:47] epoch 1686, training loss: 3652.27, average training loss: 3782.98, base loss: 4601.41
[INFO 2017-06-26 21:52:40,248 main.py:47] epoch 1687, training loss: 3751.29, average training loss: 3783.09, base loss: 4602.29
[INFO 2017-06-26 21:52:40,636 main.py:47] epoch 1688, training loss: 3487.89, average training loss: 3782.75, base loss: 4602.18
[INFO 2017-06-26 21:52:41,023 main.py:47] epoch 1689, training loss: 3588.59, average training loss: 3782.10, base loss: 4601.63
[INFO 2017-06-26 21:52:41,414 main.py:47] epoch 1690, training loss: 3058.07, average training loss: 3781.39, base loss: 4600.95
[INFO 2017-06-26 21:52:41,806 main.py:47] epoch 1691, training loss: 3212.72, average training loss: 3780.34, base loss: 4599.87
[INFO 2017-06-26 21:52:42,195 main.py:47] epoch 1692, training loss: 3647.33, average training loss: 3780.64, base loss: 4601.08
[INFO 2017-06-26 21:52:42,587 main.py:47] epoch 1693, training loss: 3677.49, average training loss: 3780.33, base loss: 4601.13
[INFO 2017-06-26 21:52:42,977 main.py:47] epoch 1694, training loss: 3300.56, average training loss: 3779.69, base loss: 4600.28
[INFO 2017-06-26 21:52:43,372 main.py:47] epoch 1695, training loss: 4169.94, average training loss: 3780.31, base loss: 4602.29
[INFO 2017-06-26 21:52:43,765 main.py:47] epoch 1696, training loss: 3498.37, average training loss: 3780.60, base loss: 4603.09
[INFO 2017-06-26 21:52:44,158 main.py:47] epoch 1697, training loss: 3359.55, average training loss: 3780.20, base loss: 4603.01
[INFO 2017-06-26 21:52:44,550 main.py:47] epoch 1698, training loss: 3877.45, average training loss: 3780.90, base loss: 4604.88
[INFO 2017-06-26 21:52:44,940 main.py:47] epoch 1699, training loss: 3319.64, average training loss: 3780.57, base loss: 4604.81
[INFO 2017-06-26 21:52:44,941 main.py:49] epoch 1699, testing
[INFO 2017-06-26 21:52:46,439 main.py:101] average testing loss: 3394.22, base loss: 4308.49, improve_loss: 914.27
[INFO 2017-06-26 21:52:46,439 main.py:73] current best improved loss: 1058.36
[INFO 2017-06-26 21:52:46,826 main.py:47] epoch 1700, training loss: 3210.04, average training loss: 3779.69, base loss: 4604.23
[INFO 2017-06-26 21:52:47,218 main.py:47] epoch 1701, training loss: 3753.43, average training loss: 3779.48, base loss: 4604.22
[INFO 2017-06-26 21:52:47,605 main.py:47] epoch 1702, training loss: 3157.70, average training loss: 3779.00, base loss: 4604.12
[INFO 2017-06-26 21:52:47,997 main.py:47] epoch 1703, training loss: 3697.30, average training loss: 3778.74, base loss: 4604.25
[INFO 2017-06-26 21:52:48,384 main.py:47] epoch 1704, training loss: 6945.50, average training loss: 3782.13, base loss: 4608.39
[INFO 2017-06-26 21:52:48,774 main.py:47] epoch 1705, training loss: 3569.22, average training loss: 3781.82, base loss: 4608.32
[INFO 2017-06-26 21:52:49,168 main.py:47] epoch 1706, training loss: 3392.68, average training loss: 3781.29, base loss: 4608.13
[INFO 2017-06-26 21:52:49,555 main.py:47] epoch 1707, training loss: 3524.23, average training loss: 3781.34, base loss: 4608.64
[INFO 2017-06-26 21:52:49,941 main.py:47] epoch 1708, training loss: 3462.83, average training loss: 3781.19, base loss: 4609.05
[INFO 2017-06-26 21:52:50,329 main.py:47] epoch 1709, training loss: 7163.92, average training loss: 3784.19, base loss: 4612.35
[INFO 2017-06-26 21:52:50,715 main.py:47] epoch 1710, training loss: 3640.31, average training loss: 3783.33, base loss: 4611.80
[INFO 2017-06-26 21:52:51,102 main.py:47] epoch 1711, training loss: 3432.91, average training loss: 3783.12, base loss: 4612.12
[INFO 2017-06-26 21:52:51,489 main.py:47] epoch 1712, training loss: 3545.83, average training loss: 3783.65, base loss: 4613.34
[INFO 2017-06-26 21:52:51,877 main.py:47] epoch 1713, training loss: 3391.52, average training loss: 3783.30, base loss: 4613.39
[INFO 2017-06-26 21:52:52,265 main.py:47] epoch 1714, training loss: 3224.47, average training loss: 3782.83, base loss: 4613.04
[INFO 2017-06-26 21:52:52,660 main.py:47] epoch 1715, training loss: 3559.75, average training loss: 3782.03, base loss: 4612.51
[INFO 2017-06-26 21:52:53,047 main.py:47] epoch 1716, training loss: 3207.45, average training loss: 3781.29, base loss: 4611.96
[INFO 2017-06-26 21:52:53,439 main.py:47] epoch 1717, training loss: 3914.10, average training loss: 3781.31, base loss: 4612.75
[INFO 2017-06-26 21:52:53,832 main.py:47] epoch 1718, training loss: 3220.35, average training loss: 3781.06, base loss: 4612.81
[INFO 2017-06-26 21:52:54,220 main.py:47] epoch 1719, training loss: 3431.55, average training loss: 3780.74, base loss: 4613.07
[INFO 2017-06-26 21:52:54,609 main.py:47] epoch 1720, training loss: 3552.80, average training loss: 3779.59, base loss: 4612.11
[INFO 2017-06-26 21:52:55,001 main.py:47] epoch 1721, training loss: 3754.41, average training loss: 3779.28, base loss: 4612.41
[INFO 2017-06-26 21:52:55,394 main.py:47] epoch 1722, training loss: 3684.75, average training loss: 3779.28, base loss: 4612.91
[INFO 2017-06-26 21:52:55,783 main.py:47] epoch 1723, training loss: 3992.01, average training loss: 3779.71, base loss: 4614.45
[INFO 2017-06-26 21:52:56,171 main.py:47] epoch 1724, training loss: 2932.49, average training loss: 3778.23, base loss: 4612.83
[INFO 2017-06-26 21:52:56,559 main.py:47] epoch 1725, training loss: 3472.44, average training loss: 3778.31, base loss: 4613.28
[INFO 2017-06-26 21:52:56,951 main.py:47] epoch 1726, training loss: 3131.11, average training loss: 3778.00, base loss: 4613.54
[INFO 2017-06-26 21:52:57,338 main.py:47] epoch 1727, training loss: 3351.73, average training loss: 3777.90, base loss: 4613.78
[INFO 2017-06-26 21:52:57,725 main.py:47] epoch 1728, training loss: 3361.17, average training loss: 3770.41, base loss: 4606.72
[INFO 2017-06-26 21:52:58,112 main.py:47] epoch 1729, training loss: 3330.59, average training loss: 3770.25, base loss: 4606.87
[INFO 2017-06-26 21:52:58,501 main.py:47] epoch 1730, training loss: 3315.75, average training loss: 3770.01, base loss: 4607.18
[INFO 2017-06-26 21:52:58,890 main.py:47] epoch 1731, training loss: 3062.82, average training loss: 3769.68, base loss: 4607.20
[INFO 2017-06-26 21:52:59,283 main.py:47] epoch 1732, training loss: 3594.18, average training loss: 3770.22, base loss: 4608.40
[INFO 2017-06-26 21:52:59,674 main.py:47] epoch 1733, training loss: 3411.18, average training loss: 3768.65, base loss: 4606.55
[INFO 2017-06-26 21:53:00,069 main.py:47] epoch 1734, training loss: 3437.45, average training loss: 3767.63, base loss: 4605.40
[INFO 2017-06-26 21:53:00,457 main.py:47] epoch 1735, training loss: 3398.50, average training loss: 3767.29, base loss: 4605.35
[INFO 2017-06-26 21:53:00,845 main.py:47] epoch 1736, training loss: 3510.89, average training loss: 3767.23, base loss: 4605.79
[INFO 2017-06-26 21:53:01,233 main.py:47] epoch 1737, training loss: 3272.35, average training loss: 3766.44, base loss: 4605.26
[INFO 2017-06-26 21:53:01,620 main.py:47] epoch 1738, training loss: 3301.65, average training loss: 3765.59, base loss: 4604.63
[INFO 2017-06-26 21:53:02,008 main.py:47] epoch 1739, training loss: 3714.63, average training loss: 3765.59, base loss: 4604.70
[INFO 2017-06-26 21:53:02,398 main.py:47] epoch 1740, training loss: 3016.92, average training loss: 3764.61, base loss: 4603.45
[INFO 2017-06-26 21:53:02,786 main.py:47] epoch 1741, training loss: 3513.64, average training loss: 3764.68, base loss: 4603.74
[INFO 2017-06-26 21:53:03,186 main.py:47] epoch 1742, training loss: 2976.08, average training loss: 3763.85, base loss: 4602.87
[INFO 2017-06-26 21:53:03,580 main.py:47] epoch 1743, training loss: 3804.08, average training loss: 3763.46, base loss: 4602.97
[INFO 2017-06-26 21:53:03,973 main.py:47] epoch 1744, training loss: 3890.03, average training loss: 3763.44, base loss: 4603.63
[INFO 2017-06-26 21:53:04,361 main.py:47] epoch 1745, training loss: 3112.87, average training loss: 3762.35, base loss: 4602.63
[INFO 2017-06-26 21:53:04,748 main.py:47] epoch 1746, training loss: 3363.61, average training loss: 3761.93, base loss: 4602.12
[INFO 2017-06-26 21:53:05,137 main.py:47] epoch 1747, training loss: 3772.76, average training loss: 3761.62, base loss: 4602.24
[INFO 2017-06-26 21:53:05,524 main.py:47] epoch 1748, training loss: 3672.31, average training loss: 3761.38, base loss: 4602.46
[INFO 2017-06-26 21:53:05,911 main.py:47] epoch 1749, training loss: 3601.85, average training loss: 3761.11, base loss: 4602.64
[INFO 2017-06-26 21:53:06,298 main.py:47] epoch 1750, training loss: 3591.98, average training loss: 3761.25, base loss: 4602.93
[INFO 2017-06-26 21:53:06,684 main.py:47] epoch 1751, training loss: 3543.04, average training loss: 3757.82, base loss: 4600.11
[INFO 2017-06-26 21:53:07,076 main.py:47] epoch 1752, training loss: 3279.32, average training loss: 3756.79, base loss: 4599.11
[INFO 2017-06-26 21:53:07,463 main.py:47] epoch 1753, training loss: 3357.47, average training loss: 3756.79, base loss: 4599.52
[INFO 2017-06-26 21:53:07,849 main.py:47] epoch 1754, training loss: 3782.97, average training loss: 3756.80, base loss: 4600.21
[INFO 2017-06-26 21:53:08,239 main.py:47] epoch 1755, training loss: 3431.62, average training loss: 3756.91, base loss: 4600.83
[INFO 2017-06-26 21:53:08,635 main.py:47] epoch 1756, training loss: 3250.17, average training loss: 3755.79, base loss: 4599.58
[INFO 2017-06-26 21:53:09,024 main.py:47] epoch 1757, training loss: 3868.59, average training loss: 3752.62, base loss: 4597.14
[INFO 2017-06-26 21:53:09,412 main.py:47] epoch 1758, training loss: 3597.66, average training loss: 3752.26, base loss: 4597.08
[INFO 2017-06-26 21:53:09,800 main.py:47] epoch 1759, training loss: 3787.21, average training loss: 3752.38, base loss: 4597.84
[INFO 2017-06-26 21:53:10,188 main.py:47] epoch 1760, training loss: 3330.39, average training loss: 3751.35, base loss: 4596.61
[INFO 2017-06-26 21:53:10,580 main.py:47] epoch 1761, training loss: 3827.18, average training loss: 3751.63, base loss: 4597.97
[INFO 2017-06-26 21:53:10,968 main.py:47] epoch 1762, training loss: 3320.21, average training loss: 3750.92, base loss: 4597.31
[INFO 2017-06-26 21:53:11,366 main.py:47] epoch 1763, training loss: 3807.53, average training loss: 3751.30, base loss: 4598.26
[INFO 2017-06-26 21:53:11,756 main.py:47] epoch 1764, training loss: 3817.07, average training loss: 3751.25, base loss: 4598.65
[INFO 2017-06-26 21:53:12,142 main.py:47] epoch 1765, training loss: 3891.63, average training loss: 3751.82, base loss: 4600.07
[INFO 2017-06-26 21:53:12,531 main.py:47] epoch 1766, training loss: 3521.60, average training loss: 3751.62, base loss: 4600.01
[INFO 2017-06-26 21:53:12,923 main.py:47] epoch 1767, training loss: 3401.23, average training loss: 3750.70, base loss: 4599.33
[INFO 2017-06-26 21:53:13,310 main.py:47] epoch 1768, training loss: 3631.38, average training loss: 3750.21, base loss: 4599.09
[INFO 2017-06-26 21:53:13,697 main.py:47] epoch 1769, training loss: 3833.70, average training loss: 3750.78, base loss: 4600.65
[INFO 2017-06-26 21:53:14,084 main.py:47] epoch 1770, training loss: 3099.12, average training loss: 3750.15, base loss: 4600.25
[INFO 2017-06-26 21:53:14,473 main.py:47] epoch 1771, training loss: 3589.49, average training loss: 3750.08, base loss: 4600.84
[INFO 2017-06-26 21:53:14,868 main.py:47] epoch 1772, training loss: 3292.95, average training loss: 3748.98, base loss: 4599.70
[INFO 2017-06-26 21:53:15,269 main.py:47] epoch 1773, training loss: 3416.17, average training loss: 3748.69, base loss: 4599.82
[INFO 2017-06-26 21:53:15,659 main.py:47] epoch 1774, training loss: 3170.08, average training loss: 3748.28, base loss: 4599.81
[INFO 2017-06-26 21:53:16,054 main.py:47] epoch 1775, training loss: 2825.60, average training loss: 3747.17, base loss: 4598.44
[INFO 2017-06-26 21:53:16,434 main.py:47] epoch 1776, training loss: 2918.58, average training loss: 3742.56, base loss: 4593.48
[INFO 2017-06-26 21:53:16,820 main.py:47] epoch 1777, training loss: 3479.89, average training loss: 3742.28, base loss: 4593.43
[INFO 2017-06-26 21:53:17,206 main.py:47] epoch 1778, training loss: 3378.52, average training loss: 3742.15, base loss: 4593.64
[INFO 2017-06-26 21:53:17,595 main.py:47] epoch 1779, training loss: 3061.52, average training loss: 3741.04, base loss: 4592.40
[INFO 2017-06-26 21:53:17,980 main.py:47] epoch 1780, training loss: 3141.66, average training loss: 3740.31, base loss: 4591.64
[INFO 2017-06-26 21:53:18,368 main.py:47] epoch 1781, training loss: 3341.12, average training loss: 3739.82, base loss: 4591.22
[INFO 2017-06-26 21:53:18,757 main.py:47] epoch 1782, training loss: 2978.17, average training loss: 3739.47, base loss: 4590.78
[INFO 2017-06-26 21:53:19,146 main.py:47] epoch 1783, training loss: 3817.83, average training loss: 3739.67, base loss: 4591.35
[INFO 2017-06-26 21:53:19,536 main.py:47] epoch 1784, training loss: 3801.92, average training loss: 3739.61, base loss: 4592.01
[INFO 2017-06-26 21:53:19,924 main.py:47] epoch 1785, training loss: 3620.05, average training loss: 3739.47, base loss: 4592.19
[INFO 2017-06-26 21:53:20,311 main.py:47] epoch 1786, training loss: 3671.49, average training loss: 3739.49, base loss: 4592.99
[INFO 2017-06-26 21:53:20,700 main.py:47] epoch 1787, training loss: 3906.77, average training loss: 3739.78, base loss: 4593.29
[INFO 2017-06-26 21:53:21,086 main.py:47] epoch 1788, training loss: 3574.13, average training loss: 3739.57, base loss: 4593.68
[INFO 2017-06-26 21:53:21,472 main.py:47] epoch 1789, training loss: 3480.77, average training loss: 3739.00, base loss: 4593.36
[INFO 2017-06-26 21:53:21,861 main.py:47] epoch 1790, training loss: 3603.89, average training loss: 3738.96, base loss: 4593.79
[INFO 2017-06-26 21:53:22,259 main.py:47] epoch 1791, training loss: 3475.20, average training loss: 3738.37, base loss: 4593.80
[INFO 2017-06-26 21:53:22,647 main.py:47] epoch 1792, training loss: 3250.02, average training loss: 3737.39, base loss: 4592.33
[INFO 2017-06-26 21:53:23,030 main.py:47] epoch 1793, training loss: 3342.94, average training loss: 3736.79, base loss: 4592.20
[INFO 2017-06-26 21:53:23,422 main.py:47] epoch 1794, training loss: 3791.97, average training loss: 3736.56, base loss: 4592.34
[INFO 2017-06-26 21:53:23,809 main.py:47] epoch 1795, training loss: 3455.46, average training loss: 3736.91, base loss: 4593.08
[INFO 2017-06-26 21:53:24,197 main.py:47] epoch 1796, training loss: 3486.38, average training loss: 3736.35, base loss: 4592.78
[INFO 2017-06-26 21:53:24,587 main.py:47] epoch 1797, training loss: 3338.24, average training loss: 3735.67, base loss: 4591.96
[INFO 2017-06-26 21:53:24,976 main.py:47] epoch 1798, training loss: 3860.34, average training loss: 3735.82, base loss: 4592.67
[INFO 2017-06-26 21:53:25,364 main.py:47] epoch 1799, training loss: 3365.75, average training loss: 3735.60, base loss: 4592.83
[INFO 2017-06-26 21:53:25,364 main.py:49] epoch 1799, testing
[INFO 2017-06-26 21:53:26,900 main.py:101] average testing loss: 3850.41, base loss: 4850.83, improve_loss: 1000.42
[INFO 2017-06-26 21:53:26,901 main.py:73] current best improved loss: 1058.36
[INFO 2017-06-26 21:53:27,292 main.py:47] epoch 1800, training loss: 3233.15, average training loss: 3734.90, base loss: 4592.32
[INFO 2017-06-26 21:53:27,686 main.py:47] epoch 1801, training loss: 4139.03, average training loss: 3735.00, base loss: 4592.98
[INFO 2017-06-26 21:53:28,071 main.py:47] epoch 1802, training loss: 3277.01, average training loss: 3735.11, base loss: 4593.36
[INFO 2017-06-26 21:53:28,454 main.py:47] epoch 1803, training loss: 3097.05, average training loss: 3734.88, base loss: 4593.32
[INFO 2017-06-26 21:53:28,843 main.py:47] epoch 1804, training loss: 3506.97, average training loss: 3734.49, base loss: 4593.13
[INFO 2017-06-26 21:53:29,231 main.py:47] epoch 1805, training loss: 3113.70, average training loss: 3733.75, base loss: 4592.55
[INFO 2017-06-26 21:53:29,621 main.py:47] epoch 1806, training loss: 3918.29, average training loss: 3733.68, base loss: 4593.01
[INFO 2017-06-26 21:53:30,006 main.py:47] epoch 1807, training loss: 3453.75, average training loss: 3733.63, base loss: 4593.31
[INFO 2017-06-26 21:53:30,388 main.py:47] epoch 1808, training loss: 3566.07, average training loss: 3733.89, base loss: 4594.01
[INFO 2017-06-26 21:53:30,775 main.py:47] epoch 1809, training loss: 3556.00, average training loss: 3733.85, base loss: 4594.29
[INFO 2017-06-26 21:53:31,161 main.py:47] epoch 1810, training loss: 3630.09, average training loss: 3734.16, base loss: 4595.42
[INFO 2017-06-26 21:53:31,546 main.py:47] epoch 1811, training loss: 3452.76, average training loss: 3734.34, base loss: 4596.03
[INFO 2017-06-26 21:53:31,931 main.py:47] epoch 1812, training loss: 3432.85, average training loss: 3730.50, base loss: 4592.93
[INFO 2017-06-26 21:53:32,317 main.py:47] epoch 1813, training loss: 3883.20, average training loss: 3730.31, base loss: 4593.10
[INFO 2017-06-26 21:53:32,698 main.py:47] epoch 1814, training loss: 10212.23, average training loss: 3736.42, base loss: 4599.37
[INFO 2017-06-26 21:53:33,087 main.py:47] epoch 1815, training loss: 3657.92, average training loss: 3735.67, base loss: 4599.52
[INFO 2017-06-26 21:53:33,479 main.py:47] epoch 1816, training loss: 3278.40, average training loss: 3735.18, base loss: 4599.50
[INFO 2017-06-26 21:53:33,861 main.py:47] epoch 1817, training loss: 3238.64, average training loss: 3735.23, base loss: 4599.56
[INFO 2017-06-26 21:53:34,244 main.py:47] epoch 1818, training loss: 3856.54, average training loss: 3735.03, base loss: 4599.84
[INFO 2017-06-26 21:53:34,629 main.py:47] epoch 1819, training loss: 2923.19, average training loss: 3734.02, base loss: 4598.75
[INFO 2017-06-26 21:53:35,009 main.py:47] epoch 1820, training loss: 3330.81, average training loss: 3732.96, base loss: 4597.57
[INFO 2017-06-26 21:53:35,391 main.py:47] epoch 1821, training loss: 3793.52, average training loss: 3733.08, base loss: 4598.43
[INFO 2017-06-26 21:53:35,780 main.py:47] epoch 1822, training loss: 3521.85, average training loss: 3732.89, base loss: 4598.60
[INFO 2017-06-26 21:53:36,170 main.py:47] epoch 1823, training loss: 3428.21, average training loss: 3732.95, base loss: 4599.64
[INFO 2017-06-26 21:53:36,559 main.py:47] epoch 1824, training loss: 3519.43, average training loss: 3732.75, base loss: 4599.92
[INFO 2017-06-26 21:53:36,946 main.py:47] epoch 1825, training loss: 3019.90, average training loss: 3732.30, base loss: 4599.38
[INFO 2017-06-26 21:53:37,331 main.py:47] epoch 1826, training loss: 3488.86, average training loss: 3731.43, base loss: 4598.42
[INFO 2017-06-26 21:53:37,716 main.py:47] epoch 1827, training loss: 3132.40, average training loss: 3730.61, base loss: 4597.34
[INFO 2017-06-26 21:53:38,097 main.py:47] epoch 1828, training loss: 3635.36, average training loss: 3730.19, base loss: 4596.80
[INFO 2017-06-26 21:53:38,483 main.py:47] epoch 1829, training loss: 3736.92, average training loss: 3730.10, base loss: 4596.79
[INFO 2017-06-26 21:53:38,869 main.py:47] epoch 1830, training loss: 3330.75, average training loss: 3729.59, base loss: 4596.70
[INFO 2017-06-26 21:53:39,257 main.py:47] epoch 1831, training loss: 3251.18, average training loss: 3729.15, base loss: 4596.28
[INFO 2017-06-26 21:53:39,642 main.py:47] epoch 1832, training loss: 3582.50, average training loss: 3728.65, base loss: 4596.25
[INFO 2017-06-26 21:53:40,027 main.py:47] epoch 1833, training loss: 3348.31, average training loss: 3728.41, base loss: 4596.49
[INFO 2017-06-26 21:53:40,412 main.py:47] epoch 1834, training loss: 3615.17, average training loss: 3728.48, base loss: 4597.20
[INFO 2017-06-26 21:53:40,798 main.py:47] epoch 1835, training loss: 3749.38, average training loss: 3728.45, base loss: 4597.69
[INFO 2017-06-26 21:53:41,185 main.py:47] epoch 1836, training loss: 3302.32, average training loss: 3728.10, base loss: 4597.32
[INFO 2017-06-26 21:53:41,566 main.py:47] epoch 1837, training loss: 3348.62, average training loss: 3727.54, base loss: 4596.96
[INFO 2017-06-26 21:53:41,951 main.py:47] epoch 1838, training loss: 3354.59, average training loss: 3726.54, base loss: 4595.75
[INFO 2017-06-26 21:53:42,338 main.py:47] epoch 1839, training loss: 3300.67, average training loss: 3725.82, base loss: 4595.06
[INFO 2017-06-26 21:53:42,725 main.py:47] epoch 1840, training loss: 3573.30, average training loss: 3725.60, base loss: 4594.79
[INFO 2017-06-26 21:53:43,117 main.py:47] epoch 1841, training loss: 3542.29, average training loss: 3725.30, base loss: 4594.90
[INFO 2017-06-26 21:53:43,498 main.py:47] epoch 1842, training loss: 3802.88, average training loss: 3725.42, base loss: 4595.88
[INFO 2017-06-26 21:53:43,878 main.py:47] epoch 1843, training loss: 3375.96, average training loss: 3725.10, base loss: 4595.89
[INFO 2017-06-26 21:53:44,268 main.py:47] epoch 1844, training loss: 3204.70, average training loss: 3724.73, base loss: 4595.62
[INFO 2017-06-26 21:53:44,659 main.py:47] epoch 1845, training loss: 3280.92, average training loss: 3724.52, base loss: 4595.68
[INFO 2017-06-26 21:53:45,047 main.py:47] epoch 1846, training loss: 3475.49, average training loss: 3724.66, base loss: 4596.46
[INFO 2017-06-26 21:53:45,433 main.py:47] epoch 1847, training loss: 3571.35, average training loss: 3724.86, base loss: 4597.10
[INFO 2017-06-26 21:53:45,817 main.py:47] epoch 1848, training loss: 3221.75, average training loss: 3724.16, base loss: 4596.63
[INFO 2017-06-26 21:53:46,204 main.py:47] epoch 1849, training loss: 3474.45, average training loss: 3724.08, base loss: 4596.88
[INFO 2017-06-26 21:53:46,588 main.py:47] epoch 1850, training loss: 3325.17, average training loss: 3724.43, base loss: 4597.85
[INFO 2017-06-26 21:53:46,973 main.py:47] epoch 1851, training loss: 3589.31, average training loss: 3724.62, base loss: 4598.22
[INFO 2017-06-26 21:53:47,357 main.py:47] epoch 1852, training loss: 3497.43, average training loss: 3724.18, base loss: 4598.40
[INFO 2017-06-26 21:53:47,744 main.py:47] epoch 1853, training loss: 3217.31, average training loss: 3723.08, base loss: 4597.26
[INFO 2017-06-26 21:53:48,134 main.py:47] epoch 1854, training loss: 3778.31, average training loss: 3722.55, base loss: 4597.19
[INFO 2017-06-26 21:53:48,523 main.py:47] epoch 1855, training loss: 3823.62, average training loss: 3719.63, base loss: 4595.17
[INFO 2017-06-26 21:53:48,910 main.py:47] epoch 1856, training loss: 3681.34, average training loss: 3719.06, base loss: 4595.16
[INFO 2017-06-26 21:53:49,303 main.py:47] epoch 1857, training loss: 3558.99, average training loss: 3719.26, base loss: 4595.89
[INFO 2017-06-26 21:53:49,695 main.py:47] epoch 1858, training loss: 3206.12, average training loss: 3718.75, base loss: 4595.56
[INFO 2017-06-26 21:53:50,081 main.py:47] epoch 1859, training loss: 3960.75, average training loss: 3718.69, base loss: 4595.71
[INFO 2017-06-26 21:53:50,468 main.py:47] epoch 1860, training loss: 3428.47, average training loss: 3718.23, base loss: 4595.15
[INFO 2017-06-26 21:53:50,864 main.py:47] epoch 1861, training loss: 3555.39, average training loss: 3718.31, base loss: 4595.24
[INFO 2017-06-26 21:53:51,254 main.py:47] epoch 1862, training loss: 3470.55, average training loss: 3718.07, base loss: 4595.24
[INFO 2017-06-26 21:53:51,640 main.py:47] epoch 1863, training loss: 6658.29, average training loss: 3720.95, base loss: 4598.15
[INFO 2017-06-26 21:53:52,028 main.py:47] epoch 1864, training loss: 3547.40, average training loss: 3720.77, base loss: 4598.25
[INFO 2017-06-26 21:53:52,415 main.py:47] epoch 1865, training loss: 3980.12, average training loss: 3720.73, base loss: 4598.97
[INFO 2017-06-26 21:53:52,802 main.py:47] epoch 1866, training loss: 3535.78, average training loss: 3720.33, base loss: 4598.72
[INFO 2017-06-26 21:53:53,193 main.py:47] epoch 1867, training loss: 3382.40, average training loss: 3719.91, base loss: 4598.52
[INFO 2017-06-26 21:53:53,588 main.py:47] epoch 1868, training loss: 3021.59, average training loss: 3719.06, base loss: 4597.87
[INFO 2017-06-26 21:53:53,969 main.py:47] epoch 1869, training loss: 3479.52, average training loss: 3718.12, base loss: 4596.91
[INFO 2017-06-26 21:53:54,351 main.py:47] epoch 1870, training loss: 3321.43, average training loss: 3717.41, base loss: 4596.42
[INFO 2017-06-26 21:53:54,741 main.py:47] epoch 1871, training loss: 3183.84, average training loss: 3717.08, base loss: 4596.30
[INFO 2017-06-26 21:53:55,129 main.py:47] epoch 1872, training loss: 3551.14, average training loss: 3717.51, base loss: 4597.80
[INFO 2017-06-26 21:53:55,515 main.py:47] epoch 1873, training loss: 3319.02, average training loss: 3716.74, base loss: 4597.24
[INFO 2017-06-26 21:53:55,899 main.py:47] epoch 1874, training loss: 3545.37, average training loss: 3716.40, base loss: 4597.26
[INFO 2017-06-26 21:53:56,294 main.py:47] epoch 1875, training loss: 3134.10, average training loss: 3715.86, base loss: 4597.03
[INFO 2017-06-26 21:53:56,687 main.py:47] epoch 1876, training loss: 4036.87, average training loss: 3716.65, base loss: 4598.87
[INFO 2017-06-26 21:53:57,073 main.py:47] epoch 1877, training loss: 3438.74, average training loss: 3715.78, base loss: 4598.40
[INFO 2017-06-26 21:53:57,464 main.py:47] epoch 1878, training loss: 3090.79, average training loss: 3714.79, base loss: 4596.98
[INFO 2017-06-26 21:53:57,858 main.py:47] epoch 1879, training loss: 3241.06, average training loss: 3714.55, base loss: 4596.71
[INFO 2017-06-26 21:53:58,253 main.py:47] epoch 1880, training loss: 3519.74, average training loss: 3714.68, base loss: 4597.58
[INFO 2017-06-26 21:53:58,657 main.py:47] epoch 1881, training loss: 3297.77, average training loss: 3714.31, base loss: 4597.48
[INFO 2017-06-26 21:53:59,046 main.py:47] epoch 1882, training loss: 3550.36, average training loss: 3714.36, base loss: 4598.50
[INFO 2017-06-26 21:53:59,437 main.py:47] epoch 1883, training loss: 3610.90, average training loss: 3714.26, base loss: 4598.98
[INFO 2017-06-26 21:53:59,822 main.py:47] epoch 1884, training loss: 2939.98, average training loss: 3713.55, base loss: 4598.26
[INFO 2017-06-26 21:54:00,214 main.py:47] epoch 1885, training loss: 3494.30, average training loss: 3713.18, base loss: 4598.05
[INFO 2017-06-26 21:54:00,604 main.py:47] epoch 1886, training loss: 3492.65, average training loss: 3712.98, base loss: 4597.80
[INFO 2017-06-26 21:54:00,989 main.py:47] epoch 1887, training loss: 3222.11, average training loss: 3711.95, base loss: 4597.15
[INFO 2017-06-26 21:54:01,371 main.py:47] epoch 1888, training loss: 3537.26, average training loss: 3711.16, base loss: 4596.52
[INFO 2017-06-26 21:54:01,756 main.py:47] epoch 1889, training loss: 3408.28, average training loss: 3710.89, base loss: 4596.53
[INFO 2017-06-26 21:54:02,141 main.py:47] epoch 1890, training loss: 3861.65, average training loss: 3711.07, base loss: 4597.67
[INFO 2017-06-26 21:54:02,528 main.py:47] epoch 1891, training loss: 3511.32, average training loss: 3710.18, base loss: 4596.68
[INFO 2017-06-26 21:54:02,915 main.py:47] epoch 1892, training loss: 3538.51, average training loss: 3710.06, base loss: 4597.16
[INFO 2017-06-26 21:54:03,300 main.py:47] epoch 1893, training loss: 3226.68, average training loss: 3710.02, base loss: 4597.73
[INFO 2017-06-26 21:54:03,689 main.py:47] epoch 1894, training loss: 3487.32, average training loss: 3709.62, base loss: 4597.50
[INFO 2017-06-26 21:54:04,070 main.py:47] epoch 1895, training loss: 3347.13, average training loss: 3709.39, base loss: 4597.50
[INFO 2017-06-26 21:54:04,452 main.py:47] epoch 1896, training loss: 3581.45, average training loss: 3709.68, base loss: 4598.42
[INFO 2017-06-26 21:54:04,834 main.py:47] epoch 1897, training loss: 3545.41, average training loss: 3709.59, base loss: 4598.99
[INFO 2017-06-26 21:54:05,219 main.py:47] epoch 1898, training loss: 3230.12, average training loss: 3709.57, base loss: 4599.18
[INFO 2017-06-26 21:54:05,607 main.py:47] epoch 1899, training loss: 3326.40, average training loss: 3708.40, base loss: 4598.05
[INFO 2017-06-26 21:54:05,608 main.py:49] epoch 1899, testing
[INFO 2017-06-26 21:54:07,108 main.py:101] average testing loss: 3813.70, base loss: 4907.45, improve_loss: 1093.76
[INFO 2017-06-26 21:54:07,109 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:54:07,126 main.py:73] current best improved loss: 1093.76
[INFO 2017-06-26 21:54:07,535 main.py:47] epoch 1900, training loss: 3624.10, average training loss: 3708.50, base loss: 4598.53
[INFO 2017-06-26 21:54:07,921 main.py:47] epoch 1901, training loss: 3429.34, average training loss: 3708.29, base loss: 4598.92
[INFO 2017-06-26 21:54:08,311 main.py:47] epoch 1902, training loss: 3098.19, average training loss: 3708.10, base loss: 4598.92
[INFO 2017-06-26 21:54:08,698 main.py:47] epoch 1903, training loss: 3594.16, average training loss: 3707.80, base loss: 4599.14
[INFO 2017-06-26 21:54:09,083 main.py:47] epoch 1904, training loss: 3778.35, average training loss: 3706.98, base loss: 4598.61
[INFO 2017-06-26 21:54:09,472 main.py:47] epoch 1905, training loss: 3468.42, average training loss: 3707.08, base loss: 4599.47
[INFO 2017-06-26 21:54:09,859 main.py:47] epoch 1906, training loss: 3830.94, average training loss: 3707.24, base loss: 4600.16
[INFO 2017-06-26 21:54:10,248 main.py:47] epoch 1907, training loss: 3447.81, average training loss: 3707.06, base loss: 4600.04
[INFO 2017-06-26 21:54:10,633 main.py:47] epoch 1908, training loss: 3216.17, average training loss: 3706.29, base loss: 4599.15
[INFO 2017-06-26 21:54:11,022 main.py:47] epoch 1909, training loss: 3834.08, average training loss: 3706.43, base loss: 4600.03
[INFO 2017-06-26 21:54:11,409 main.py:47] epoch 1910, training loss: 3416.20, average training loss: 3706.71, base loss: 4601.01
[INFO 2017-06-26 21:54:11,807 main.py:47] epoch 1911, training loss: 3330.45, average training loss: 3706.86, base loss: 4601.52
[INFO 2017-06-26 21:54:12,196 main.py:47] epoch 1912, training loss: 3548.50, average training loss: 3706.96, base loss: 4602.19
[INFO 2017-06-26 21:54:12,586 main.py:47] epoch 1913, training loss: 2892.58, average training loss: 3706.21, base loss: 4601.44
[INFO 2017-06-26 21:54:12,988 main.py:47] epoch 1914, training loss: 3611.78, average training loss: 3705.92, base loss: 4601.63
[INFO 2017-06-26 21:54:13,375 main.py:47] epoch 1915, training loss: 3111.02, average training loss: 3705.47, base loss: 4601.45
[INFO 2017-06-26 21:54:13,762 main.py:47] epoch 1916, training loss: 3358.38, average training loss: 3704.60, base loss: 4601.04
[INFO 2017-06-26 21:54:14,147 main.py:47] epoch 1917, training loss: 3354.30, average training loss: 3703.52, base loss: 4600.01
[INFO 2017-06-26 21:54:14,531 main.py:47] epoch 1918, training loss: 6944.68, average training loss: 3707.30, base loss: 4604.10
[INFO 2017-06-26 21:54:14,919 main.py:47] epoch 1919, training loss: 3818.08, average training loss: 3707.32, base loss: 4604.57
[INFO 2017-06-26 21:54:15,307 main.py:47] epoch 1920, training loss: 3139.99, average training loss: 3706.74, base loss: 4604.03
[INFO 2017-06-26 21:54:15,696 main.py:47] epoch 1921, training loss: 2961.85, average training loss: 3706.13, base loss: 4603.72
[INFO 2017-06-26 21:54:16,084 main.py:47] epoch 1922, training loss: 3202.66, average training loss: 3705.70, base loss: 4603.56
[INFO 2017-06-26 21:54:16,470 main.py:47] epoch 1923, training loss: 3459.72, average training loss: 3705.81, base loss: 4604.42
[INFO 2017-06-26 21:54:16,855 main.py:47] epoch 1924, training loss: 3854.88, average training loss: 3702.44, base loss: 4601.38
[INFO 2017-06-26 21:54:17,251 main.py:47] epoch 1925, training loss: 3629.38, average training loss: 3702.66, base loss: 4602.25
[INFO 2017-06-26 21:54:17,639 main.py:47] epoch 1926, training loss: 3581.88, average training loss: 3702.90, base loss: 4602.78
[INFO 2017-06-26 21:54:18,031 main.py:47] epoch 1927, training loss: 3691.64, average training loss: 3702.96, base loss: 4603.45
[INFO 2017-06-26 21:54:18,418 main.py:47] epoch 1928, training loss: 3919.94, average training loss: 3703.76, base loss: 4605.07
[INFO 2017-06-26 21:54:18,817 main.py:47] epoch 1929, training loss: 3353.49, average training loss: 3702.89, base loss: 4604.13
[INFO 2017-06-26 21:54:19,205 main.py:47] epoch 1930, training loss: 3358.61, average training loss: 3702.46, base loss: 4603.70
[INFO 2017-06-26 21:54:19,591 main.py:47] epoch 1931, training loss: 3970.09, average training loss: 3702.39, base loss: 4603.87
[INFO 2017-06-26 21:54:19,978 main.py:47] epoch 1932, training loss: 3665.76, average training loss: 3702.70, base loss: 4604.98
[INFO 2017-06-26 21:54:20,365 main.py:47] epoch 1933, training loss: 3636.38, average training loss: 3702.24, base loss: 4604.58
[INFO 2017-06-26 21:54:20,752 main.py:47] epoch 1934, training loss: 3193.40, average training loss: 3701.70, base loss: 4604.28
[INFO 2017-06-26 21:54:21,140 main.py:47] epoch 1935, training loss: 3277.78, average training loss: 3701.21, base loss: 4604.00
[INFO 2017-06-26 21:54:21,532 main.py:47] epoch 1936, training loss: 3095.76, average training loss: 3700.28, base loss: 4602.91
[INFO 2017-06-26 21:54:21,922 main.py:47] epoch 1937, training loss: 3279.81, average training loss: 3699.94, base loss: 4603.07
[INFO 2017-06-26 21:54:22,310 main.py:47] epoch 1938, training loss: 3120.49, average training loss: 3699.04, base loss: 4601.94
[INFO 2017-06-26 21:54:22,698 main.py:47] epoch 1939, training loss: 3383.54, average training loss: 3698.86, base loss: 4601.77
[INFO 2017-06-26 21:54:23,090 main.py:47] epoch 1940, training loss: 3185.58, average training loss: 3698.10, base loss: 4601.02
[INFO 2017-06-26 21:54:23,478 main.py:47] epoch 1941, training loss: 3817.90, average training loss: 3698.15, base loss: 4601.52
[INFO 2017-06-26 21:54:23,870 main.py:47] epoch 1942, training loss: 3439.86, average training loss: 3698.05, base loss: 4601.91
[INFO 2017-06-26 21:54:24,258 main.py:47] epoch 1943, training loss: 3626.70, average training loss: 3698.13, base loss: 4602.43
[INFO 2017-06-26 21:54:24,648 main.py:47] epoch 1944, training loss: 3754.50, average training loss: 3698.36, base loss: 4603.20
[INFO 2017-06-26 21:54:25,041 main.py:47] epoch 1945, training loss: 3365.00, average training loss: 3696.90, base loss: 4601.50
[INFO 2017-06-26 21:54:25,431 main.py:47] epoch 1946, training loss: 3804.42, average training loss: 3697.01, base loss: 4602.39
[INFO 2017-06-26 21:54:25,820 main.py:47] epoch 1947, training loss: 3258.67, average training loss: 3696.56, base loss: 4602.09
[INFO 2017-06-26 21:54:26,208 main.py:47] epoch 1948, training loss: 3461.91, average training loss: 3696.36, base loss: 4601.91
[INFO 2017-06-26 21:54:26,595 main.py:47] epoch 1949, training loss: 2932.37, average training loss: 3695.58, base loss: 4600.82
[INFO 2017-06-26 21:54:26,979 main.py:47] epoch 1950, training loss: 3768.57, average training loss: 3695.60, base loss: 4601.25
[INFO 2017-06-26 21:54:27,370 main.py:47] epoch 1951, training loss: 3590.25, average training loss: 3695.77, base loss: 4601.86
[INFO 2017-06-26 21:54:27,763 main.py:47] epoch 1952, training loss: 3027.39, average training loss: 3695.00, base loss: 4600.75
[INFO 2017-06-26 21:54:28,152 main.py:47] epoch 1953, training loss: 3651.75, average training loss: 3695.42, base loss: 4601.79
[INFO 2017-06-26 21:54:28,545 main.py:47] epoch 1954, training loss: 3271.63, average training loss: 3695.36, base loss: 4602.23
[INFO 2017-06-26 21:54:28,931 main.py:47] epoch 1955, training loss: 3160.95, average training loss: 3694.42, base loss: 4601.04
[INFO 2017-06-26 21:54:29,325 main.py:47] epoch 1956, training loss: 3701.24, average training loss: 3694.19, base loss: 4601.33
[INFO 2017-06-26 21:54:29,713 main.py:47] epoch 1957, training loss: 3777.17, average training loss: 3694.13, base loss: 4601.52
[INFO 2017-06-26 21:54:30,104 main.py:47] epoch 1958, training loss: 3191.96, average training loss: 3693.68, base loss: 4601.27
[INFO 2017-06-26 21:54:30,493 main.py:47] epoch 1959, training loss: 3553.74, average training loss: 3693.57, base loss: 4601.61
[INFO 2017-06-26 21:54:30,881 main.py:47] epoch 1960, training loss: 3898.51, average training loss: 3693.90, base loss: 4602.02
[INFO 2017-06-26 21:54:31,268 main.py:47] epoch 1961, training loss: 2910.00, average training loss: 3693.11, base loss: 4601.02
[INFO 2017-06-26 21:54:31,657 main.py:47] epoch 1962, training loss: 3571.27, average training loss: 3692.81, base loss: 4600.94
[INFO 2017-06-26 21:54:32,048 main.py:47] epoch 1963, training loss: 4024.43, average training loss: 3693.10, base loss: 4602.02
[INFO 2017-06-26 21:54:32,442 main.py:47] epoch 1964, training loss: 3341.00, average training loss: 3692.55, base loss: 4601.51
[INFO 2017-06-26 21:54:32,830 main.py:47] epoch 1965, training loss: 3350.43, average training loss: 3691.27, base loss: 4600.27
[INFO 2017-06-26 21:54:33,222 main.py:47] epoch 1966, training loss: 3469.95, average training loss: 3691.21, base loss: 4600.85
[INFO 2017-06-26 21:54:33,614 main.py:47] epoch 1967, training loss: 3294.18, average training loss: 3690.87, base loss: 4600.78
[INFO 2017-06-26 21:54:34,002 main.py:47] epoch 1968, training loss: 3336.59, average training loss: 3690.59, base loss: 4600.59
[INFO 2017-06-26 21:54:34,393 main.py:47] epoch 1969, training loss: 3606.63, average training loss: 3690.72, base loss: 4601.39
[INFO 2017-06-26 21:54:34,783 main.py:47] epoch 1970, training loss: 3076.97, average training loss: 3690.16, base loss: 4600.80
[INFO 2017-06-26 21:54:35,170 main.py:47] epoch 1971, training loss: 3315.24, average training loss: 3689.95, base loss: 4600.77
[INFO 2017-06-26 21:54:35,564 main.py:47] epoch 1972, training loss: 3151.44, average training loss: 3685.84, base loss: 4596.91
[INFO 2017-06-26 21:54:35,956 main.py:47] epoch 1973, training loss: 3287.30, average training loss: 3685.22, base loss: 4596.46
[INFO 2017-06-26 21:54:36,349 main.py:47] epoch 1974, training loss: 3292.63, average training loss: 3684.19, base loss: 4595.34
[INFO 2017-06-26 21:54:36,738 main.py:47] epoch 1975, training loss: 3037.72, average training loss: 3683.26, base loss: 4594.54
[INFO 2017-06-26 21:54:37,128 main.py:47] epoch 1976, training loss: 3434.09, average training loss: 3683.14, base loss: 4594.77
[INFO 2017-06-26 21:54:37,518 main.py:47] epoch 1977, training loss: 3384.87, average training loss: 3682.37, base loss: 4594.36
[INFO 2017-06-26 21:54:37,906 main.py:47] epoch 1978, training loss: 3606.74, average training loss: 3682.92, base loss: 4596.09
[INFO 2017-06-26 21:54:38,296 main.py:47] epoch 1979, training loss: 3336.75, average training loss: 3678.71, base loss: 4591.90
[INFO 2017-06-26 21:54:38,692 main.py:47] epoch 1980, training loss: 3559.86, average training loss: 3678.52, base loss: 4591.96
[INFO 2017-06-26 21:54:39,085 main.py:47] epoch 1981, training loss: 3371.95, average training loss: 3677.88, base loss: 4591.49
[INFO 2017-06-26 21:54:39,479 main.py:47] epoch 1982, training loss: 3978.69, average training loss: 3678.20, base loss: 4592.60
[INFO 2017-06-26 21:54:39,878 main.py:47] epoch 1983, training loss: 3764.32, average training loss: 3678.23, base loss: 4593.27
[INFO 2017-06-26 21:54:40,271 main.py:47] epoch 1984, training loss: 3605.88, average training loss: 3677.85, base loss: 4593.25
[INFO 2017-06-26 21:54:40,664 main.py:47] epoch 1985, training loss: 3420.35, average training loss: 3676.19, base loss: 4591.59
[INFO 2017-06-26 21:54:41,054 main.py:47] epoch 1986, training loss: 3819.07, average training loss: 3676.58, base loss: 4592.65
[INFO 2017-06-26 21:54:41,447 main.py:47] epoch 1987, training loss: 2939.77, average training loss: 3676.30, base loss: 4592.84
[INFO 2017-06-26 21:54:41,840 main.py:47] epoch 1988, training loss: 3641.17, average training loss: 3676.73, base loss: 4593.61
[INFO 2017-06-26 21:54:42,230 main.py:47] epoch 1989, training loss: 3732.60, average training loss: 3676.54, base loss: 4593.73
[INFO 2017-06-26 21:54:42,623 main.py:47] epoch 1990, training loss: 3116.11, average training loss: 3675.93, base loss: 4593.21
[INFO 2017-06-26 21:54:43,016 main.py:47] epoch 1991, training loss: 2960.53, average training loss: 3675.55, base loss: 4593.12
[INFO 2017-06-26 21:54:43,410 main.py:47] epoch 1992, training loss: 2969.84, average training loss: 3674.86, base loss: 4592.17
[INFO 2017-06-26 21:54:43,798 main.py:47] epoch 1993, training loss: 3269.82, average training loss: 3674.32, base loss: 4591.24
[INFO 2017-06-26 21:54:44,191 main.py:47] epoch 1994, training loss: 3689.58, average training loss: 3674.34, base loss: 4591.89
[INFO 2017-06-26 21:54:44,579 main.py:47] epoch 1995, training loss: 3739.88, average training loss: 3674.42, base loss: 4592.78
[INFO 2017-06-26 21:54:44,967 main.py:47] epoch 1996, training loss: 3002.70, average training loss: 3673.40, base loss: 4591.60
[INFO 2017-06-26 21:54:45,355 main.py:47] epoch 1997, training loss: 3243.29, average training loss: 3672.79, base loss: 4590.66
[INFO 2017-06-26 21:54:45,755 main.py:47] epoch 1998, training loss: 7317.50, average training loss: 3675.69, base loss: 4593.81
[INFO 2017-06-26 21:54:46,148 main.py:47] epoch 1999, training loss: 4135.31, average training loss: 3675.89, base loss: 4594.47
[INFO 2017-06-26 21:54:46,148 main.py:49] epoch 1999, testing
[INFO 2017-06-26 21:54:47,660 main.py:101] average testing loss: 3892.69, base loss: 5077.02, improve_loss: 1184.33
[INFO 2017-06-26 21:54:47,661 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 21:54:47,674 main.py:73] current best improved loss: 1184.33
[INFO 2017-06-26 21:54:48,076 main.py:47] epoch 2000, training loss: 3328.70, average training loss: 3675.12, base loss: 4593.81
[INFO 2017-06-26 21:54:48,468 main.py:47] epoch 2001, training loss: 3752.30, average training loss: 3675.07, base loss: 4594.20
[INFO 2017-06-26 21:54:48,870 main.py:47] epoch 2002, training loss: 3120.09, average training loss: 3674.46, base loss: 4593.74
[INFO 2017-06-26 21:54:49,265 main.py:47] epoch 2003, training loss: 3019.90, average training loss: 3673.99, base loss: 4593.27
[INFO 2017-06-26 21:54:49,650 main.py:47] epoch 2004, training loss: 3025.33, average training loss: 3673.27, base loss: 4592.93
[INFO 2017-06-26 21:54:50,038 main.py:47] epoch 2005, training loss: 3585.40, average training loss: 3673.23, base loss: 4593.27
[INFO 2017-06-26 21:54:50,424 main.py:47] epoch 2006, training loss: 3212.70, average training loss: 3672.69, base loss: 4592.95
[INFO 2017-06-26 21:54:50,813 main.py:47] epoch 2007, training loss: 3167.90, average training loss: 3672.09, base loss: 4592.40
[INFO 2017-06-26 21:54:51,202 main.py:47] epoch 2008, training loss: 3225.79, average training loss: 3671.29, base loss: 4591.61
[INFO 2017-06-26 21:54:51,591 main.py:47] epoch 2009, training loss: 3210.64, average training loss: 3670.51, base loss: 4590.77
[INFO 2017-06-26 21:54:51,982 main.py:47] epoch 2010, training loss: 3042.57, average training loss: 3669.93, base loss: 4590.08
[INFO 2017-06-26 21:54:52,363 main.py:47] epoch 2011, training loss: 2908.43, average training loss: 3669.07, base loss: 4588.85
[INFO 2017-06-26 21:54:52,747 main.py:47] epoch 2012, training loss: 3255.85, average training loss: 3668.74, base loss: 4588.72
[INFO 2017-06-26 21:54:53,134 main.py:47] epoch 2013, training loss: 3375.77, average training loss: 3668.57, base loss: 4588.95
[INFO 2017-06-26 21:54:53,517 main.py:47] epoch 2014, training loss: 3951.99, average training loss: 3668.76, base loss: 4589.77
[INFO 2017-06-26 21:54:53,900 main.py:47] epoch 2015, training loss: 3785.85, average training loss: 3669.16, base loss: 4591.12
[INFO 2017-06-26 21:54:54,282 main.py:47] epoch 2016, training loss: 3227.23, average training loss: 3664.67, base loss: 4586.63
[INFO 2017-06-26 21:54:54,669 main.py:47] epoch 2017, training loss: 3428.29, average training loss: 3663.89, base loss: 4585.74
[INFO 2017-06-26 21:54:55,054 main.py:47] epoch 2018, training loss: 3586.71, average training loss: 3663.21, base loss: 4585.31
[INFO 2017-06-26 21:54:55,439 main.py:47] epoch 2019, training loss: 2996.50, average training loss: 3662.55, base loss: 4584.41
[INFO 2017-06-26 21:54:55,820 main.py:47] epoch 2020, training loss: 3263.81, average training loss: 3662.37, base loss: 4584.62
[INFO 2017-06-26 21:54:56,204 main.py:47] epoch 2021, training loss: 3697.39, average training loss: 3662.71, base loss: 4585.51
[INFO 2017-06-26 21:54:56,585 main.py:47] epoch 2022, training loss: 3399.25, average training loss: 3662.31, base loss: 4585.29
[INFO 2017-06-26 21:54:56,969 main.py:47] epoch 2023, training loss: 3666.18, average training loss: 3662.55, base loss: 4586.26
[INFO 2017-06-26 21:54:57,350 main.py:47] epoch 2024, training loss: 3800.63, average training loss: 3662.38, base loss: 4586.54
[INFO 2017-06-26 21:54:57,730 main.py:47] epoch 2025, training loss: 3369.24, average training loss: 3661.82, base loss: 4586.09
[INFO 2017-06-26 21:54:58,116 main.py:47] epoch 2026, training loss: 4289.61, average training loss: 3662.83, base loss: 4588.00
[INFO 2017-06-26 21:54:58,506 main.py:47] epoch 2027, training loss: 3717.81, average training loss: 3662.84, base loss: 4588.29
[INFO 2017-06-26 21:54:58,889 main.py:47] epoch 2028, training loss: 3320.92, average training loss: 3662.60, base loss: 4588.55
[INFO 2017-06-26 21:54:59,268 main.py:47] epoch 2029, training loss: 3284.02, average training loss: 3662.28, base loss: 4588.23
[INFO 2017-06-26 21:54:59,652 main.py:47] epoch 2030, training loss: 3443.77, average training loss: 3661.97, base loss: 4588.37
[INFO 2017-06-26 21:55:00,041 main.py:47] epoch 2031, training loss: 6721.97, average training loss: 3665.27, base loss: 4591.75
[INFO 2017-06-26 21:55:00,433 main.py:47] epoch 2032, training loss: 3091.20, average training loss: 3664.92, base loss: 4591.39
[INFO 2017-06-26 21:55:00,823 main.py:47] epoch 2033, training loss: 3790.23, average training loss: 3665.13, base loss: 4591.96
[INFO 2017-06-26 21:55:01,207 main.py:47] epoch 2034, training loss: 3623.70, average training loss: 3665.27, base loss: 4592.87
[INFO 2017-06-26 21:55:01,595 main.py:47] epoch 2035, training loss: 2997.54, average training loss: 3664.62, base loss: 4592.33
[INFO 2017-06-26 21:55:01,980 main.py:47] epoch 2036, training loss: 3435.65, average training loss: 3664.33, base loss: 4592.31
[INFO 2017-06-26 21:55:02,362 main.py:47] epoch 2037, training loss: 3563.39, average training loss: 3664.01, base loss: 4592.20
[INFO 2017-06-26 21:55:02,749 main.py:47] epoch 2038, training loss: 3406.13, average training loss: 3663.95, base loss: 4592.49
[INFO 2017-06-26 21:55:03,133 main.py:47] epoch 2039, training loss: 3230.51, average training loss: 3663.34, base loss: 4592.09
[INFO 2017-06-26 21:55:03,513 main.py:47] epoch 2040, training loss: 3368.40, average training loss: 3663.23, base loss: 4592.56
[INFO 2017-06-26 21:55:03,897 main.py:47] epoch 2041, training loss: 3320.24, average training loss: 3662.80, base loss: 4592.18
[INFO 2017-06-26 21:55:04,279 main.py:47] epoch 2042, training loss: 3375.99, average training loss: 3662.53, base loss: 4592.33
[INFO 2017-06-26 21:55:04,666 main.py:47] epoch 2043, training loss: 3636.24, average training loss: 3663.12, base loss: 4593.62
[INFO 2017-06-26 21:55:05,045 main.py:47] epoch 2044, training loss: 3057.93, average training loss: 3662.51, base loss: 4592.83
[INFO 2017-06-26 21:55:05,426 main.py:47] epoch 2045, training loss: 3759.29, average training loss: 3662.81, base loss: 4593.74
[INFO 2017-06-26 21:55:05,813 main.py:47] epoch 2046, training loss: 3312.62, average training loss: 3662.33, base loss: 4593.57
[INFO 2017-06-26 21:55:06,203 main.py:47] epoch 2047, training loss: 3465.51, average training loss: 3662.12, base loss: 4593.92
[INFO 2017-06-26 21:55:06,584 main.py:47] epoch 2048, training loss: 3444.25, average training loss: 3662.00, base loss: 4594.03
[INFO 2017-06-26 21:55:06,968 main.py:47] epoch 2049, training loss: 2699.87, average training loss: 3660.61, base loss: 4592.16
[INFO 2017-06-26 21:55:07,349 main.py:47] epoch 2050, training loss: 3292.93, average training loss: 3660.29, base loss: 4592.03
[INFO 2017-06-26 21:55:07,736 main.py:47] epoch 2051, training loss: 3077.38, average training loss: 3659.44, base loss: 4591.01
[INFO 2017-06-26 21:55:08,121 main.py:47] epoch 2052, training loss: 3607.05, average training loss: 3659.41, base loss: 4591.24
[INFO 2017-06-26 21:55:08,510 main.py:47] epoch 2053, training loss: 3107.31, average training loss: 3658.78, base loss: 4590.32
[INFO 2017-06-26 21:55:08,897 main.py:47] epoch 2054, training loss: 3387.16, average training loss: 3658.08, base loss: 4589.47
[INFO 2017-06-26 21:55:09,287 main.py:47] epoch 2055, training loss: 3641.09, average training loss: 3658.33, base loss: 4590.04
[INFO 2017-06-26 21:55:09,675 main.py:47] epoch 2056, training loss: 3200.88, average training loss: 3657.36, base loss: 4589.17
[INFO 2017-06-26 21:55:10,061 main.py:47] epoch 2057, training loss: 3283.39, average training loss: 3656.92, base loss: 4588.85
[INFO 2017-06-26 21:55:10,459 main.py:47] epoch 2058, training loss: 3470.37, average training loss: 3656.49, base loss: 4588.59
[INFO 2017-06-26 21:55:10,848 main.py:47] epoch 2059, training loss: 3647.42, average training loss: 3656.51, base loss: 4588.96
[INFO 2017-06-26 21:55:11,237 main.py:47] epoch 2060, training loss: 6715.51, average training loss: 3659.57, base loss: 4591.73
[INFO 2017-06-26 21:55:11,625 main.py:47] epoch 2061, training loss: 3358.32, average training loss: 3659.25, base loss: 4591.43
[INFO 2017-06-26 21:55:12,012 main.py:47] epoch 2062, training loss: 3574.37, average training loss: 3659.17, base loss: 4592.12
[INFO 2017-06-26 21:55:12,398 main.py:47] epoch 2063, training loss: 3149.42, average training loss: 3658.52, base loss: 4591.54
[INFO 2017-06-26 21:55:12,790 main.py:47] epoch 2064, training loss: 3547.72, average training loss: 3658.04, base loss: 4591.06
[INFO 2017-06-26 21:55:13,175 main.py:47] epoch 2065, training loss: 3115.21, average training loss: 3657.59, base loss: 4590.89
[INFO 2017-06-26 21:55:13,562 main.py:47] epoch 2066, training loss: 3598.49, average training loss: 3657.68, base loss: 4590.91
[INFO 2017-06-26 21:55:13,951 main.py:47] epoch 2067, training loss: 3488.75, average training loss: 3657.74, base loss: 4591.42
[INFO 2017-06-26 21:55:14,344 main.py:47] epoch 2068, training loss: 3046.83, average training loss: 3656.62, base loss: 4590.54
[INFO 2017-06-26 21:55:14,740 main.py:47] epoch 2069, training loss: 3259.20, average training loss: 3655.61, base loss: 4589.54
[INFO 2017-06-26 21:55:15,136 main.py:47] epoch 2070, training loss: 3149.39, average training loss: 3654.57, base loss: 4588.60
[INFO 2017-06-26 21:55:15,533 main.py:47] epoch 2071, training loss: 3403.79, average training loss: 3654.01, base loss: 4588.19
[INFO 2017-06-26 21:55:15,923 main.py:47] epoch 2072, training loss: 3613.02, average training loss: 3653.95, base loss: 4588.71
[INFO 2017-06-26 21:55:16,341 main.py:47] epoch 2073, training loss: 3700.43, average training loss: 3654.14, base loss: 4589.59
[INFO 2017-06-26 21:55:16,802 main.py:47] epoch 2074, training loss: 3260.70, average training loss: 3653.78, base loss: 4589.72
[INFO 2017-06-26 21:55:17,257 main.py:47] epoch 2075, training loss: 3486.70, average training loss: 3653.50, base loss: 4589.60
[INFO 2017-06-26 21:55:17,730 main.py:47] epoch 2076, training loss: 3460.63, average training loss: 3652.86, base loss: 4589.33
[INFO 2017-06-26 21:55:18,181 main.py:47] epoch 2077, training loss: 3730.83, average training loss: 3653.56, base loss: 4590.69
[INFO 2017-06-26 21:55:18,597 main.py:47] epoch 2078, training loss: 3451.80, average training loss: 3653.04, base loss: 4590.42
[INFO 2017-06-26 21:55:19,036 main.py:47] epoch 2079, training loss: 3364.89, average training loss: 3652.92, base loss: 4590.78
[INFO 2017-06-26 21:55:19,509 main.py:47] epoch 2080, training loss: 3570.48, average training loss: 3652.95, base loss: 4591.30
[INFO 2017-06-26 21:55:19,928 main.py:47] epoch 2081, training loss: 3759.65, average training loss: 3649.45, base loss: 4588.28
[INFO 2017-06-26 21:55:20,321 main.py:47] epoch 2082, training loss: 3782.57, average training loss: 3649.23, base loss: 4588.37
[INFO 2017-06-26 21:55:20,713 main.py:47] epoch 2083, training loss: 3317.93, average training loss: 3648.62, base loss: 4587.51
[INFO 2017-06-26 21:55:21,099 main.py:47] epoch 2084, training loss: 3682.85, average training loss: 3648.73, base loss: 4588.25
[INFO 2017-06-26 21:55:21,490 main.py:47] epoch 2085, training loss: 3384.28, average training loss: 3648.41, base loss: 4588.04
[INFO 2017-06-26 21:55:21,873 main.py:47] epoch 2086, training loss: 3076.56, average training loss: 3647.70, base loss: 4587.31
[INFO 2017-06-26 21:55:22,259 main.py:47] epoch 2087, training loss: 3203.54, average training loss: 3647.45, base loss: 4587.01
[INFO 2017-06-26 21:55:22,716 main.py:47] epoch 2088, training loss: 3278.38, average training loss: 3647.01, base loss: 4586.52
[INFO 2017-06-26 21:55:23,124 main.py:47] epoch 2089, training loss: 3475.08, average training loss: 3646.80, base loss: 4586.35
[INFO 2017-06-26 21:55:23,528 main.py:47] epoch 2090, training loss: 3210.73, average training loss: 3646.27, base loss: 4586.09
[INFO 2017-06-26 21:55:23,919 main.py:47] epoch 2091, training loss: 3595.07, average training loss: 3646.40, base loss: 4586.50
[INFO 2017-06-26 21:55:24,309 main.py:47] epoch 2092, training loss: 3685.41, average training loss: 3646.59, base loss: 4587.18
[INFO 2017-06-26 21:55:24,723 main.py:47] epoch 2093, training loss: 3494.71, average training loss: 3646.43, base loss: 4587.63
[INFO 2017-06-26 21:55:25,109 main.py:47] epoch 2094, training loss: 4043.50, average training loss: 3647.02, base loss: 4588.71
[INFO 2017-06-26 21:55:25,500 main.py:47] epoch 2095, training loss: 3442.26, average training loss: 3647.49, base loss: 4589.79
[INFO 2017-06-26 21:55:25,919 main.py:47] epoch 2096, training loss: 3430.07, average training loss: 3647.24, base loss: 4589.79
[INFO 2017-06-26 21:55:26,331 main.py:47] epoch 2097, training loss: 3737.26, average training loss: 3647.24, base loss: 4590.03
[INFO 2017-06-26 21:55:26,717 main.py:47] epoch 2098, training loss: 3287.27, average training loss: 3646.58, base loss: 4589.39
[INFO 2017-06-26 21:55:27,103 main.py:47] epoch 2099, training loss: 3461.39, average training loss: 3646.32, base loss: 4589.24
[INFO 2017-06-26 21:55:27,103 main.py:49] epoch 2099, testing
[INFO 2017-06-26 21:55:28,590 main.py:101] average testing loss: 3360.09, base loss: 4464.77, improve_loss: 1104.68
[INFO 2017-06-26 21:55:28,591 main.py:73] current best improved loss: 1184.33
[INFO 2017-06-26 21:55:28,978 main.py:47] epoch 2100, training loss: 2885.92, average training loss: 3645.51, base loss: 4588.59
[INFO 2017-06-26 21:55:29,373 main.py:47] epoch 2101, training loss: 3748.25, average training loss: 3645.26, base loss: 4588.44
[INFO 2017-06-26 21:55:29,759 main.py:47] epoch 2102, training loss: 3246.78, average training loss: 3644.66, base loss: 4587.81
[INFO 2017-06-26 21:55:30,145 main.py:47] epoch 2103, training loss: 3301.52, average training loss: 3644.01, base loss: 4586.82
[INFO 2017-06-26 21:55:30,525 main.py:47] epoch 2104, training loss: 3165.21, average training loss: 3643.67, base loss: 4586.33
[INFO 2017-06-26 21:55:30,905 main.py:47] epoch 2105, training loss: 3523.26, average training loss: 3643.57, base loss: 4586.44
[INFO 2017-06-26 21:55:31,284 main.py:47] epoch 2106, training loss: 3138.08, average training loss: 3642.69, base loss: 4585.25
[INFO 2017-06-26 21:55:31,777 main.py:47] epoch 2107, training loss: 3628.93, average training loss: 3642.80, base loss: 4586.10
[INFO 2017-06-26 21:55:32,169 main.py:47] epoch 2108, training loss: 3151.49, average training loss: 3642.78, base loss: 4586.25
[INFO 2017-06-26 21:55:32,556 main.py:47] epoch 2109, training loss: 3353.17, average training loss: 3642.13, base loss: 4585.81
[INFO 2017-06-26 21:55:33,037 main.py:47] epoch 2110, training loss: 3503.00, average training loss: 3641.69, base loss: 4585.70
[INFO 2017-06-26 21:55:33,424 main.py:47] epoch 2111, training loss: 3279.97, average training loss: 3637.44, base loss: 4581.36
[INFO 2017-06-26 21:55:33,812 main.py:47] epoch 2112, training loss: 3206.47, average training loss: 3637.09, base loss: 4581.36
[INFO 2017-06-26 21:55:34,194 main.py:47] epoch 2113, training loss: 3144.07, average training loss: 3636.15, base loss: 4580.29
[INFO 2017-06-26 21:55:34,574 main.py:47] epoch 2114, training loss: 3773.57, average training loss: 3636.52, base loss: 4581.82
[INFO 2017-06-26 21:55:34,955 main.py:47] epoch 2115, training loss: 3242.78, average training loss: 3636.18, base loss: 4581.99
[INFO 2017-06-26 21:55:35,341 main.py:47] epoch 2116, training loss: 3637.37, average training loss: 3635.88, base loss: 4582.26
[INFO 2017-06-26 21:55:35,726 main.py:47] epoch 2117, training loss: 3294.37, average training loss: 3635.16, base loss: 4581.71
[INFO 2017-06-26 21:55:36,111 main.py:47] epoch 2118, training loss: 3374.19, average training loss: 3635.36, base loss: 4582.63
[INFO 2017-06-26 21:55:36,490 main.py:47] epoch 2119, training loss: 3895.23, average training loss: 3635.73, base loss: 4583.76
[INFO 2017-06-26 21:55:36,893 main.py:47] epoch 2120, training loss: 3204.06, average training loss: 3635.59, base loss: 4584.03
[INFO 2017-06-26 21:55:37,304 main.py:47] epoch 2121, training loss: 3671.30, average training loss: 3635.03, base loss: 4583.71
[INFO 2017-06-26 21:55:37,691 main.py:47] epoch 2122, training loss: 3438.47, average training loss: 3635.04, base loss: 4583.88
[INFO 2017-06-26 21:55:38,082 main.py:47] epoch 2123, training loss: 3711.57, average training loss: 3635.27, base loss: 4584.83
[INFO 2017-06-26 21:55:38,462 main.py:47] epoch 2124, training loss: 3800.70, average training loss: 3634.91, base loss: 4584.78
[INFO 2017-06-26 21:55:38,845 main.py:47] epoch 2125, training loss: 3466.70, average training loss: 3634.82, base loss: 4584.93
[INFO 2017-06-26 21:55:39,229 main.py:47] epoch 2126, training loss: 3562.44, average training loss: 3634.91, base loss: 4585.63
[INFO 2017-06-26 21:55:39,613 main.py:47] epoch 2127, training loss: 3394.06, average training loss: 3634.77, base loss: 4585.75
[INFO 2017-06-26 21:55:39,994 main.py:47] epoch 2128, training loss: 3336.56, average training loss: 3634.60, base loss: 4585.91
[INFO 2017-06-26 21:55:40,451 main.py:47] epoch 2129, training loss: 3424.65, average training loss: 3634.88, base loss: 4586.66
[INFO 2017-06-26 21:55:40,854 main.py:47] epoch 2130, training loss: 6696.90, average training loss: 3637.64, base loss: 4589.55
[INFO 2017-06-26 21:55:41,242 main.py:47] epoch 2131, training loss: 3117.19, average training loss: 3637.08, base loss: 4589.10
[INFO 2017-06-26 21:55:41,629 main.py:47] epoch 2132, training loss: 3449.41, average training loss: 3637.37, base loss: 4589.88
[INFO 2017-06-26 21:55:42,073 main.py:47] epoch 2133, training loss: 3445.60, average training loss: 3637.17, base loss: 4590.33
[INFO 2017-06-26 21:55:42,469 main.py:47] epoch 2134, training loss: 6775.90, average training loss: 3640.53, base loss: 4593.40
[INFO 2017-06-26 21:55:42,854 main.py:47] epoch 2135, training loss: 3314.76, average training loss: 3639.55, base loss: 4592.33
[INFO 2017-06-26 21:55:43,239 main.py:47] epoch 2136, training loss: 3277.83, average training loss: 3639.53, base loss: 4592.78
[INFO 2017-06-26 21:55:43,620 main.py:47] epoch 2137, training loss: 3541.37, average training loss: 3639.68, base loss: 4593.74
[INFO 2017-06-26 21:55:44,005 main.py:47] epoch 2138, training loss: 3898.81, average training loss: 3639.96, base loss: 4594.80
[INFO 2017-06-26 21:55:44,384 main.py:47] epoch 2139, training loss: 3438.32, average training loss: 3639.44, base loss: 4594.34
[INFO 2017-06-26 21:55:44,765 main.py:47] epoch 2140, training loss: 3690.69, average training loss: 3639.48, base loss: 4594.70
[INFO 2017-06-26 21:55:45,222 main.py:47] epoch 2141, training loss: 3345.04, average training loss: 3639.33, base loss: 4594.96
[INFO 2017-06-26 21:55:45,628 main.py:47] epoch 2142, training loss: 3274.59, average training loss: 3638.67, base loss: 4594.15
[INFO 2017-06-26 21:55:46,020 main.py:47] epoch 2143, training loss: 3472.98, average training loss: 3638.76, base loss: 4594.51
[INFO 2017-06-26 21:55:46,407 main.py:47] epoch 2144, training loss: 3504.60, average training loss: 3638.64, base loss: 4594.76
[INFO 2017-06-26 21:55:46,793 main.py:47] epoch 2145, training loss: 3178.10, average training loss: 3638.15, base loss: 4594.46
[INFO 2017-06-26 21:55:47,212 main.py:47] epoch 2146, training loss: 3062.15, average training loss: 3636.86, base loss: 4593.14
[INFO 2017-06-26 21:55:47,621 main.py:47] epoch 2147, training loss: 3031.93, average training loss: 3636.17, base loss: 4592.19
[INFO 2017-06-26 21:55:48,011 main.py:47] epoch 2148, training loss: 3254.07, average training loss: 3635.73, base loss: 4592.14
[INFO 2017-06-26 21:55:48,491 main.py:47] epoch 2149, training loss: 3271.89, average training loss: 3634.71, base loss: 4590.97
[INFO 2017-06-26 21:55:48,893 main.py:47] epoch 2150, training loss: 3266.10, average training loss: 3633.62, base loss: 4590.10
[INFO 2017-06-26 21:55:49,367 main.py:47] epoch 2151, training loss: 3133.58, average training loss: 3632.87, base loss: 4589.14
[INFO 2017-06-26 21:55:49,838 main.py:47] epoch 2152, training loss: 3691.95, average training loss: 3632.76, base loss: 4589.29
[INFO 2017-06-26 21:55:50,232 main.py:47] epoch 2153, training loss: 3112.79, average training loss: 3632.35, base loss: 4589.15
[INFO 2017-06-26 21:55:50,621 main.py:47] epoch 2154, training loss: 2782.50, average training loss: 3631.44, base loss: 4587.92
[INFO 2017-06-26 21:55:51,112 main.py:47] epoch 2155, training loss: 6339.12, average training loss: 3634.32, base loss: 4590.74
[INFO 2017-06-26 21:55:51,512 main.py:47] epoch 2156, training loss: 3475.03, average training loss: 3634.36, base loss: 4591.44
[INFO 2017-06-26 21:55:51,901 main.py:47] epoch 2157, training loss: 3009.90, average training loss: 3633.41, base loss: 4590.67
[INFO 2017-06-26 21:55:52,353 main.py:47] epoch 2158, training loss: 3343.20, average training loss: 3633.42, base loss: 4591.11
[INFO 2017-06-26 21:55:52,761 main.py:47] epoch 2159, training loss: 3565.64, average training loss: 3633.35, base loss: 4591.29
[INFO 2017-06-26 21:55:53,146 main.py:47] epoch 2160, training loss: 3413.66, average training loss: 3633.08, base loss: 4591.58
[INFO 2017-06-26 21:55:53,536 main.py:47] epoch 2161, training loss: 3897.14, average training loss: 3633.33, base loss: 4592.82
[INFO 2017-06-26 21:55:53,920 main.py:47] epoch 2162, training loss: 4017.86, average training loss: 3633.75, base loss: 4594.32
[INFO 2017-06-26 21:55:54,310 main.py:47] epoch 2163, training loss: 3541.72, average training loss: 3633.41, base loss: 4593.95
[INFO 2017-06-26 21:55:54,699 main.py:47] epoch 2164, training loss: 3197.55, average training loss: 3632.90, base loss: 4593.39
[INFO 2017-06-26 21:55:55,078 main.py:47] epoch 2165, training loss: 3093.18, average training loss: 3631.86, base loss: 4592.23
[INFO 2017-06-26 21:55:55,459 main.py:47] epoch 2166, training loss: 3137.95, average training loss: 3630.56, base loss: 4590.55
[INFO 2017-06-26 21:55:55,943 main.py:47] epoch 2167, training loss: 2871.92, average training loss: 3629.71, base loss: 4589.21
[INFO 2017-06-26 21:55:56,333 main.py:47] epoch 2168, training loss: 3418.79, average training loss: 3629.73, base loss: 4589.82
[INFO 2017-06-26 21:55:56,732 main.py:47] epoch 2169, training loss: 3076.03, average training loss: 3629.56, base loss: 4590.28
[INFO 2017-06-26 21:55:57,117 main.py:47] epoch 2170, training loss: 6983.23, average training loss: 3632.69, base loss: 4593.42
[INFO 2017-06-26 21:55:57,498 main.py:47] epoch 2171, training loss: 3647.93, average training loss: 3633.12, base loss: 4594.79
[INFO 2017-06-26 21:55:57,877 main.py:47] epoch 2172, training loss: 3227.46, average training loss: 3632.08, base loss: 4593.14
[INFO 2017-06-26 21:55:58,256 main.py:47] epoch 2173, training loss: 3139.15, average training loss: 3631.19, base loss: 4591.86
[INFO 2017-06-26 21:55:58,716 main.py:47] epoch 2174, training loss: 3393.41, average training loss: 3630.78, base loss: 4592.16
[INFO 2017-06-26 21:55:59,120 main.py:47] epoch 2175, training loss: 3386.54, average training loss: 3630.90, base loss: 4592.75
[INFO 2017-06-26 21:55:59,508 main.py:47] epoch 2176, training loss: 3254.92, average training loss: 3630.21, base loss: 4592.04
[INFO 2017-06-26 21:55:59,895 main.py:47] epoch 2177, training loss: 3135.20, average training loss: 3629.76, base loss: 4591.78
[INFO 2017-06-26 21:56:00,348 main.py:47] epoch 2178, training loss: 3085.72, average training loss: 3628.93, base loss: 4590.97
[INFO 2017-06-26 21:56:00,760 main.py:47] epoch 2179, training loss: 2888.96, average training loss: 3627.98, base loss: 4589.96
[INFO 2017-06-26 21:56:01,150 main.py:47] epoch 2180, training loss: 3696.09, average training loss: 3627.20, base loss: 4589.05
[INFO 2017-06-26 21:56:01,639 main.py:47] epoch 2181, training loss: 3674.02, average training loss: 3623.39, base loss: 4585.90
[INFO 2017-06-26 21:56:02,026 main.py:47] epoch 2182, training loss: 3644.03, average training loss: 3622.77, base loss: 4585.10
[INFO 2017-06-26 21:56:02,484 main.py:47] epoch 2183, training loss: 3294.97, average training loss: 3622.43, base loss: 4584.79
[INFO 2017-06-26 21:56:02,889 main.py:47] epoch 2184, training loss: 3390.65, average training loss: 3622.16, base loss: 4584.85
[INFO 2017-06-26 21:56:03,345 main.py:47] epoch 2185, training loss: 3458.20, average training loss: 3621.68, base loss: 4584.50
[INFO 2017-06-26 21:56:03,755 main.py:47] epoch 2186, training loss: 3624.21, average training loss: 3621.77, base loss: 4585.52
[INFO 2017-06-26 21:56:04,142 main.py:47] epoch 2187, training loss: 3551.36, average training loss: 3621.18, base loss: 4585.03
[INFO 2017-06-26 21:56:04,535 main.py:47] epoch 2188, training loss: 3264.08, average training loss: 3620.76, base loss: 4584.37
[INFO 2017-06-26 21:56:04,922 main.py:47] epoch 2189, training loss: 3471.45, average training loss: 3620.70, base loss: 4584.49
[INFO 2017-06-26 21:56:05,333 main.py:47] epoch 2190, training loss: 3521.62, average training loss: 3620.31, base loss: 4584.40
[INFO 2017-06-26 21:56:05,717 main.py:47] epoch 2191, training loss: 3077.07, average training loss: 3619.99, base loss: 4584.27
[INFO 2017-06-26 21:56:06,097 main.py:47] epoch 2192, training loss: 3543.81, average training loss: 3619.21, base loss: 4583.75
[INFO 2017-06-26 21:56:06,480 main.py:47] epoch 2193, training loss: 3493.97, average training loss: 3618.53, base loss: 4583.50
[INFO 2017-06-26 21:56:06,862 main.py:47] epoch 2194, training loss: 3712.36, average training loss: 3618.76, base loss: 4584.42
[INFO 2017-06-26 21:56:07,247 main.py:47] epoch 2195, training loss: 3977.07, average training loss: 3619.24, base loss: 4585.60
[INFO 2017-06-26 21:56:07,635 main.py:47] epoch 2196, training loss: 3241.32, average training loss: 3619.01, base loss: 4585.29
[INFO 2017-06-26 21:56:08,015 main.py:47] epoch 2197, training loss: 3206.11, average training loss: 3618.45, base loss: 4584.85
[INFO 2017-06-26 21:56:08,396 main.py:47] epoch 2198, training loss: 3478.85, average training loss: 3618.67, base loss: 4585.62
[INFO 2017-06-26 21:56:08,778 main.py:47] epoch 2199, training loss: 3013.82, average training loss: 3617.44, base loss: 4584.28
[INFO 2017-06-26 21:56:08,778 main.py:49] epoch 2199, testing
[INFO 2017-06-26 21:56:10,263 main.py:101] average testing loss: 4088.96, base loss: 5053.31, improve_loss: 964.35
[INFO 2017-06-26 21:56:10,264 main.py:73] current best improved loss: 1184.33
[INFO 2017-06-26 21:56:10,650 main.py:47] epoch 2200, training loss: 3232.67, average training loss: 3617.67, base loss: 4584.94
[INFO 2017-06-26 21:56:11,033 main.py:47] epoch 2201, training loss: 3344.41, average training loss: 3617.38, base loss: 4585.34
[INFO 2017-06-26 21:56:11,423 main.py:47] epoch 2202, training loss: 3195.86, average training loss: 3616.92, base loss: 4585.06
[INFO 2017-06-26 21:56:11,808 main.py:47] epoch 2203, training loss: 3155.05, average training loss: 3616.38, base loss: 4584.73
[INFO 2017-06-26 21:56:12,194 main.py:47] epoch 2204, training loss: 3393.27, average training loss: 3616.47, base loss: 4585.49
[INFO 2017-06-26 21:56:12,580 main.py:47] epoch 2205, training loss: 3413.00, average training loss: 3616.35, base loss: 4585.96
[INFO 2017-06-26 21:56:12,966 main.py:47] epoch 2206, training loss: 3112.23, average training loss: 3615.88, base loss: 4585.61
[INFO 2017-06-26 21:56:13,347 main.py:47] epoch 2207, training loss: 3508.17, average training loss: 3616.21, base loss: 4586.82
[INFO 2017-06-26 21:56:13,731 main.py:47] epoch 2208, training loss: 3281.59, average training loss: 3615.58, base loss: 4586.24
[INFO 2017-06-26 21:56:14,121 main.py:47] epoch 2209, training loss: 3058.63, average training loss: 3615.50, base loss: 4586.26
[INFO 2017-06-26 21:56:14,504 main.py:47] epoch 2210, training loss: 3528.46, average training loss: 3615.54, base loss: 4586.95
[INFO 2017-06-26 21:56:14,947 main.py:47] epoch 2211, training loss: 3534.03, average training loss: 3615.90, base loss: 4588.03
[INFO 2017-06-26 21:56:15,333 main.py:47] epoch 2212, training loss: 3563.41, average training loss: 3615.15, base loss: 4587.01
[INFO 2017-06-26 21:56:15,731 main.py:47] epoch 2213, training loss: 6733.67, average training loss: 3618.50, base loss: 4590.67
[INFO 2017-06-26 21:56:16,137 main.py:47] epoch 2214, training loss: 3790.70, average training loss: 3618.93, base loss: 4591.70
[INFO 2017-06-26 21:56:16,550 main.py:47] epoch 2215, training loss: 3241.66, average training loss: 3618.36, base loss: 4591.33
[INFO 2017-06-26 21:56:16,950 main.py:47] epoch 2216, training loss: 3672.88, average training loss: 3618.23, base loss: 4591.61
[INFO 2017-06-26 21:56:17,412 main.py:47] epoch 2217, training loss: 3013.61, average training loss: 3618.14, base loss: 4591.34
[INFO 2017-06-26 21:56:17,831 main.py:47] epoch 2218, training loss: 3407.04, average training loss: 3617.95, base loss: 4591.58
[INFO 2017-06-26 21:56:18,231 main.py:47] epoch 2219, training loss: 3331.91, average training loss: 3617.69, base loss: 4591.51
[INFO 2017-06-26 21:56:18,618 main.py:47] epoch 2220, training loss: 3548.40, average training loss: 3617.81, base loss: 4592.11
[INFO 2017-06-26 21:56:19,004 main.py:47] epoch 2221, training loss: 3305.01, average training loss: 3618.09, base loss: 4593.29
