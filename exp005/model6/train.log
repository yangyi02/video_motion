[INFO 2017-07-01 16:03:10,032 main.py:168] Namespace(batch_size=32, display=False, flow_dir='flow', flow_video_dir='flow-video', flow_video_fps=1, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=4, num_channel=3, num_inputs=2, save_dir='./model', test=False, test_dir='/home/yi/Downloads/mpii-test-64', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='/home/yi/Downloads/mpii-test-64', train_epoch=100000)
[INFO 2017-07-01 16:03:14,432 main.py:52] epoch 0, training loss: 38418.50, average training loss: 38418.50, base loss: 15335.18
[INFO 2017-07-01 16:03:16,700 main.py:52] epoch 1, training loss: 35602.57, average training loss: 37010.54, base loss: 15688.17
[INFO 2017-07-01 16:03:18,878 main.py:52] epoch 2, training loss: 32891.62, average training loss: 35637.57, base loss: 16238.30
[INFO 2017-07-01 16:03:21,068 main.py:52] epoch 3, training loss: 29220.73, average training loss: 34033.36, base loss: 16330.43
[INFO 2017-07-01 16:03:23,279 main.py:52] epoch 4, training loss: 25923.97, average training loss: 32411.48, base loss: 15995.77
[INFO 2017-07-01 16:03:25,453 main.py:52] epoch 5, training loss: 24743.95, average training loss: 31133.56, base loss: 16050.30
[INFO 2017-07-01 16:03:27,621 main.py:52] epoch 6, training loss: 22709.96, average training loss: 29930.19, base loss: 16154.19
[INFO 2017-07-01 16:03:29,849 main.py:52] epoch 7, training loss: 22095.69, average training loss: 28950.87, base loss: 16158.21
[INFO 2017-07-01 16:03:32,045 main.py:52] epoch 8, training loss: 20460.86, average training loss: 28007.54, base loss: 16250.61
[INFO 2017-07-01 16:03:34,211 main.py:52] epoch 9, training loss: 19601.43, average training loss: 27166.93, base loss: 16207.45
[INFO 2017-07-01 16:03:36,430 main.py:52] epoch 10, training loss: 17327.73, average training loss: 26272.46, base loss: 16133.25
[INFO 2017-07-01 16:03:38,620 main.py:52] epoch 11, training loss: 17140.27, average training loss: 25511.44, base loss: 16123.03
[INFO 2017-07-01 16:03:40,861 main.py:52] epoch 12, training loss: 16931.69, average training loss: 24851.46, base loss: 16114.80
[INFO 2017-07-01 16:03:43,006 main.py:52] epoch 13, training loss: 15547.03, average training loss: 24186.86, base loss: 16059.79
[INFO 2017-07-01 16:03:45,231 main.py:52] epoch 14, training loss: 13915.89, average training loss: 23502.13, base loss: 15964.82
[INFO 2017-07-01 16:03:47,409 main.py:52] epoch 15, training loss: 15691.26, average training loss: 23013.95, base loss: 16042.88
[INFO 2017-07-01 16:03:49,669 main.py:52] epoch 16, training loss: 14881.70, average training loss: 22535.58, base loss: 16103.48
[INFO 2017-07-01 16:03:51,935 main.py:52] epoch 17, training loss: 14381.68, average training loss: 22082.59, base loss: 16173.67
[INFO 2017-07-01 16:03:54,106 main.py:52] epoch 18, training loss: 13595.74, average training loss: 21635.91, base loss: 16217.81
[INFO 2017-07-01 16:03:56,325 main.py:52] epoch 19, training loss: 13855.47, average training loss: 21246.89, base loss: 16330.65
[INFO 2017-07-01 16:03:58,550 main.py:52] epoch 20, training loss: 11516.63, average training loss: 20783.54, base loss: 16253.80
[INFO 2017-07-01 16:04:00,736 main.py:52] epoch 21, training loss: 11342.43, average training loss: 20354.40, base loss: 16211.25
[INFO 2017-07-01 16:04:02,939 main.py:52] epoch 22, training loss: 12406.33, average training loss: 20008.83, base loss: 16249.05
[INFO 2017-07-01 16:04:05,142 main.py:52] epoch 23, training loss: 10649.52, average training loss: 19618.86, base loss: 16184.72
[INFO 2017-07-01 16:04:07,344 main.py:52] epoch 24, training loss: 11600.04, average training loss: 19298.11, base loss: 16186.00
[INFO 2017-07-01 16:04:09,556 main.py:52] epoch 25, training loss: 12037.57, average training loss: 19018.86, base loss: 16221.49
[INFO 2017-07-01 16:04:11,799 main.py:52] epoch 26, training loss: 11154.17, average training loss: 18727.57, base loss: 16200.17
[INFO 2017-07-01 16:04:14,049 main.py:52] epoch 27, training loss: 11119.51, average training loss: 18455.86, base loss: 16190.33
[INFO 2017-07-01 16:04:16,441 main.py:52] epoch 28, training loss: 10561.01, average training loss: 18183.62, base loss: 16154.51
[INFO 2017-07-01 16:04:18,885 main.py:52] epoch 29, training loss: 11476.36, average training loss: 17960.04, base loss: 16173.98
[INFO 2017-07-01 16:04:21,327 main.py:52] epoch 30, training loss: 10126.87, average training loss: 17707.36, base loss: 16130.04
[INFO 2017-07-01 16:04:23,781 main.py:52] epoch 31, training loss: 10452.02, average training loss: 17480.63, base loss: 16114.30
[INFO 2017-07-01 16:04:26,235 main.py:52] epoch 32, training loss: 11787.81, average training loss: 17308.12, base loss: 16145.33
[INFO 2017-07-01 16:04:28,679 main.py:52] epoch 33, training loss: 10665.64, average training loss: 17112.76, base loss: 16131.35
[INFO 2017-07-01 16:04:31,248 main.py:52] epoch 34, training loss: 11924.21, average training loss: 16964.51, base loss: 16162.53
[INFO 2017-07-01 16:04:33,821 main.py:52] epoch 35, training loss: 10986.00, average training loss: 16798.44, base loss: 16158.55
[INFO 2017-07-01 16:04:36,406 main.py:52] epoch 36, training loss: 11398.70, average training loss: 16652.50, base loss: 16175.55
[INFO 2017-07-01 16:04:38,979 main.py:52] epoch 37, training loss: 11098.39, average training loss: 16506.34, base loss: 16181.43
[INFO 2017-07-01 16:04:41,553 main.py:52] epoch 38, training loss: 10779.12, average training loss: 16359.49, base loss: 16189.54
[INFO 2017-07-01 16:04:44,148 main.py:52] epoch 39, training loss: 10748.43, average training loss: 16219.21, base loss: 16182.52
[INFO 2017-07-01 16:04:46,735 main.py:52] epoch 40, training loss: 9773.14, average training loss: 16061.99, base loss: 16147.86
[INFO 2017-07-01 16:04:49,335 main.py:52] epoch 41, training loss: 9853.62, average training loss: 15914.17, base loss: 16121.39
[INFO 2017-07-01 16:04:52,081 main.py:52] epoch 42, training loss: 12363.50, average training loss: 15831.60, base loss: 16157.00
[INFO 2017-07-01 16:04:54,765 main.py:52] epoch 43, training loss: 10608.42, average training loss: 15712.89, base loss: 16142.90
[INFO 2017-07-01 16:04:57,527 main.py:52] epoch 44, training loss: 10177.15, average training loss: 15589.87, base loss: 16120.76
[INFO 2017-07-01 16:05:00,394 main.py:52] epoch 45, training loss: 9762.96, average training loss: 15463.20, base loss: 16083.48
[INFO 2017-07-01 16:05:03,252 main.py:52] epoch 46, training loss: 11164.43, average training loss: 15371.74, base loss: 16094.92
[INFO 2017-07-01 16:05:06,104 main.py:52] epoch 47, training loss: 11311.47, average training loss: 15287.15, base loss: 16104.07
[INFO 2017-07-01 16:05:08,949 main.py:52] epoch 48, training loss: 10931.90, average training loss: 15198.27, base loss: 16106.80
[INFO 2017-07-01 16:05:11,803 main.py:52] epoch 49, training loss: 9466.82, average training loss: 15083.64, base loss: 16065.79
[INFO 2017-07-01 16:05:14,657 main.py:52] epoch 50, training loss: 12209.74, average training loss: 15027.29, base loss: 16108.73
[INFO 2017-07-01 16:05:17,510 main.py:52] epoch 51, training loss: 12432.33, average training loss: 14977.38, base loss: 16148.77
[INFO 2017-07-01 16:05:20,336 main.py:52] epoch 52, training loss: 11112.51, average training loss: 14904.46, base loss: 16161.47
[INFO 2017-07-01 16:05:23,222 main.py:52] epoch 53, training loss: 12561.78, average training loss: 14861.08, base loss: 16207.22
[INFO 2017-07-01 16:05:26,087 main.py:52] epoch 54, training loss: 10357.35, average training loss: 14779.19, base loss: 16196.91
[INFO 2017-07-01 16:05:28,936 main.py:52] epoch 55, training loss: 10264.00, average training loss: 14698.56, base loss: 16186.20
[INFO 2017-07-01 16:05:31,787 main.py:52] epoch 56, training loss: 10988.85, average training loss: 14633.48, base loss: 16194.81
[INFO 2017-07-01 16:05:34,688 main.py:52] epoch 57, training loss: 10928.33, average training loss: 14569.60, base loss: 16200.39
[INFO 2017-07-01 16:05:37,550 main.py:52] epoch 58, training loss: 11533.88, average training loss: 14518.15, base loss: 16225.01
[INFO 2017-07-01 16:05:40,405 main.py:52] epoch 59, training loss: 10486.97, average training loss: 14450.96, base loss: 16214.31
[INFO 2017-07-01 16:05:43,242 main.py:52] epoch 60, training loss: 10655.32, average training loss: 14388.74, base loss: 16212.70
[INFO 2017-07-01 16:05:46,116 main.py:52] epoch 61, training loss: 9990.95, average training loss: 14317.81, base loss: 16194.23
[INFO 2017-07-01 16:05:48,958 main.py:52] epoch 62, training loss: 9799.50, average training loss: 14246.09, base loss: 16179.00
[INFO 2017-07-01 16:05:51,786 main.py:52] epoch 63, training loss: 9628.21, average training loss: 14173.93, base loss: 16162.78
[INFO 2017-07-01 16:05:54,653 main.py:52] epoch 64, training loss: 11117.24, average training loss: 14126.91, base loss: 16170.19
[INFO 2017-07-01 16:05:57,530 main.py:52] epoch 65, training loss: 11071.17, average training loss: 14080.61, base loss: 16179.95
[INFO 2017-07-01 16:06:00,399 main.py:52] epoch 66, training loss: 11634.32, average training loss: 14044.09, base loss: 16195.53
[INFO 2017-07-01 16:06:03,270 main.py:52] epoch 67, training loss: 10491.30, average training loss: 13991.85, base loss: 16196.29
[INFO 2017-07-01 16:06:06,192 main.py:52] epoch 68, training loss: 9890.53, average training loss: 13932.41, base loss: 16184.29
[INFO 2017-07-01 16:06:09,107 main.py:52] epoch 69, training loss: 8280.15, average training loss: 13851.66, base loss: 16133.50
[INFO 2017-07-01 16:06:11,993 main.py:52] epoch 70, training loss: 9702.04, average training loss: 13793.22, base loss: 16115.19
[INFO 2017-07-01 16:06:14,814 main.py:52] epoch 71, training loss: 10793.48, average training loss: 13751.55, base loss: 16123.56
[INFO 2017-07-01 16:06:17,700 main.py:52] epoch 72, training loss: 10307.56, average training loss: 13704.38, base loss: 16116.78
[INFO 2017-07-01 16:06:20,573 main.py:52] epoch 73, training loss: 9215.87, average training loss: 13643.72, base loss: 16090.57
[INFO 2017-07-01 16:06:23,436 main.py:52] epoch 74, training loss: 10282.19, average training loss: 13598.90, base loss: 16085.08
[INFO 2017-07-01 16:06:26,309 main.py:52] epoch 75, training loss: 12339.51, average training loss: 13582.33, base loss: 16123.68
[INFO 2017-07-01 16:06:29,216 main.py:52] epoch 76, training loss: 11367.54, average training loss: 13553.56, base loss: 16146.06
[INFO 2017-07-01 16:06:32,078 main.py:52] epoch 77, training loss: 9916.89, average training loss: 13506.94, base loss: 16142.07
[INFO 2017-07-01 16:06:34,920 main.py:52] epoch 78, training loss: 11061.78, average training loss: 13475.99, base loss: 16153.85
[INFO 2017-07-01 16:06:37,784 main.py:52] epoch 79, training loss: 10849.20, average training loss: 13443.15, base loss: 16161.80
[INFO 2017-07-01 16:06:40,641 main.py:52] epoch 80, training loss: 8535.96, average training loss: 13382.57, base loss: 16127.88
[INFO 2017-07-01 16:06:43,530 main.py:52] epoch 81, training loss: 9182.68, average training loss: 13331.35, base loss: 16104.51
[INFO 2017-07-01 16:06:46,434 main.py:52] epoch 82, training loss: 10357.29, average training loss: 13295.52, base loss: 16111.86
[INFO 2017-07-01 16:06:49,318 main.py:52] epoch 83, training loss: 9789.83, average training loss: 13253.79, base loss: 16106.00
[INFO 2017-07-01 16:06:52,137 main.py:52] epoch 84, training loss: 10716.60, average training loss: 13223.94, base loss: 16111.46
[INFO 2017-07-01 16:06:55,007 main.py:52] epoch 85, training loss: 9727.01, average training loss: 13183.28, base loss: 16107.00
[INFO 2017-07-01 16:06:57,872 main.py:52] epoch 86, training loss: 10925.61, average training loss: 13157.33, base loss: 16122.36
[INFO 2017-07-01 16:07:00,752 main.py:52] epoch 87, training loss: 11302.62, average training loss: 13136.25, base loss: 16139.68
[INFO 2017-07-01 16:07:03,632 main.py:52] epoch 88, training loss: 10338.25, average training loss: 13104.81, base loss: 16147.50
[INFO 2017-07-01 16:07:06,516 main.py:52] epoch 89, training loss: 10348.11, average training loss: 13074.18, base loss: 16156.25
[INFO 2017-07-01 16:07:09,361 main.py:52] epoch 90, training loss: 9839.25, average training loss: 13038.63, base loss: 16163.81
[INFO 2017-07-01 16:07:12,201 main.py:52] epoch 91, training loss: 10245.37, average training loss: 13008.27, base loss: 16164.84
[INFO 2017-07-01 16:07:15,029 main.py:52] epoch 92, training loss: 9523.11, average training loss: 12970.80, base loss: 16148.57
[INFO 2017-07-01 16:07:17,893 main.py:52] epoch 93, training loss: 10907.14, average training loss: 12948.84, base loss: 16157.99
[INFO 2017-07-01 16:07:20,771 main.py:52] epoch 94, training loss: 10005.33, average training loss: 12917.86, base loss: 16163.32
[INFO 2017-07-01 16:07:23,623 main.py:52] epoch 95, training loss: 10139.21, average training loss: 12888.91, base loss: 16162.29
[INFO 2017-07-01 16:07:26,476 main.py:52] epoch 96, training loss: 9011.96, average training loss: 12848.95, base loss: 16147.42
[INFO 2017-07-01 16:07:29,364 main.py:52] epoch 97, training loss: 10352.22, average training loss: 12823.47, base loss: 16160.32
[INFO 2017-07-01 16:07:32,242 main.py:52] epoch 98, training loss: 10554.36, average training loss: 12800.55, base loss: 16171.00
[INFO 2017-07-01 16:07:35,116 main.py:52] epoch 99, training loss: 9712.75, average training loss: 12769.67, base loss: 16171.58
[INFO 2017-07-01 16:07:35,116 main.py:54] epoch 99, testing
[INFO 2017-07-01 16:07:47,410 main.py:97] average testing loss: 9805.05, base loss: 15832.94
[INFO 2017-07-01 16:07:47,411 main.py:98] improve_loss: 6027.89, improve_percent: 0.38
[INFO 2017-07-01 16:07:47,412 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 16:07:47,436 main.py:66] current best improved percent: 0.38
[INFO 2017-07-01 16:07:50,308 main.py:52] epoch 100, training loss: 9672.81, average training loss: 12739.01, base loss: 16165.20
[INFO 2017-07-01 16:07:53,158 main.py:52] epoch 101, training loss: 9966.97, average training loss: 12711.83, base loss: 16168.10
[INFO 2017-07-01 16:07:56,034 main.py:52] epoch 102, training loss: 10536.47, average training loss: 12690.71, base loss: 16175.11
[INFO 2017-07-01 16:07:58,859 main.py:52] epoch 103, training loss: 10329.15, average training loss: 12668.00, base loss: 16179.02
[INFO 2017-07-01 16:08:01,719 main.py:52] epoch 104, training loss: 9787.09, average training loss: 12640.57, base loss: 16178.60
[INFO 2017-07-01 16:08:04,586 main.py:52] epoch 105, training loss: 8633.31, average training loss: 12602.76, base loss: 16155.89
[INFO 2017-07-01 16:08:07,431 main.py:52] epoch 106, training loss: 9346.94, average training loss: 12572.33, base loss: 16149.46
[INFO 2017-07-01 16:08:10,316 main.py:52] epoch 107, training loss: 9530.84, average training loss: 12544.17, base loss: 16149.38
[INFO 2017-07-01 16:08:13,163 main.py:52] epoch 108, training loss: 9523.13, average training loss: 12516.46, base loss: 16149.85
[INFO 2017-07-01 16:08:16,060 main.py:52] epoch 109, training loss: 10876.76, average training loss: 12501.55, base loss: 16165.94
[INFO 2017-07-01 16:08:18,925 main.py:52] epoch 110, training loss: 10906.05, average training loss: 12487.18, base loss: 16175.09
[INFO 2017-07-01 16:08:21,772 main.py:52] epoch 111, training loss: 9581.95, average training loss: 12461.24, base loss: 16167.98
[INFO 2017-07-01 16:08:24,689 main.py:52] epoch 112, training loss: 8995.89, average training loss: 12430.57, base loss: 16155.02
[INFO 2017-07-01 16:08:27,559 main.py:52] epoch 113, training loss: 8790.60, average training loss: 12398.64, base loss: 16147.69
[INFO 2017-07-01 16:08:30,389 main.py:52] epoch 114, training loss: 9568.00, average training loss: 12374.03, base loss: 16149.37
[INFO 2017-07-01 16:08:33,271 main.py:52] epoch 115, training loss: 9558.44, average training loss: 12349.75, base loss: 16148.35
[INFO 2017-07-01 16:08:36,137 main.py:52] epoch 116, training loss: 8570.82, average training loss: 12317.46, base loss: 16137.14
[INFO 2017-07-01 16:08:39,027 main.py:52] epoch 117, training loss: 11103.42, average training loss: 12307.17, base loss: 16159.16
[INFO 2017-07-01 16:08:41,910 main.py:52] epoch 118, training loss: 9461.00, average training loss: 12283.25, base loss: 16162.99
[INFO 2017-07-01 16:08:44,751 main.py:52] epoch 119, training loss: 8532.91, average training loss: 12252.00, base loss: 16144.59
[INFO 2017-07-01 16:08:47,645 main.py:52] epoch 120, training loss: 10004.39, average training loss: 12233.42, base loss: 16154.40
[INFO 2017-07-01 16:08:50,509 main.py:52] epoch 121, training loss: 9492.54, average training loss: 12210.96, base loss: 16152.37
[INFO 2017-07-01 16:08:53,416 main.py:52] epoch 122, training loss: 9262.52, average training loss: 12186.98, base loss: 16146.75
[INFO 2017-07-01 16:08:56,268 main.py:52] epoch 123, training loss: 9326.48, average training loss: 12163.92, base loss: 16145.07
[INFO 2017-07-01 16:08:59,153 main.py:52] epoch 124, training loss: 9190.57, average training loss: 12140.13, base loss: 16140.00
[INFO 2017-07-01 16:09:02,008 main.py:52] epoch 125, training loss: 10601.16, average training loss: 12127.91, base loss: 16146.21
[INFO 2017-07-01 16:09:04,879 main.py:52] epoch 126, training loss: 10311.35, average training loss: 12113.61, base loss: 16155.76
[INFO 2017-07-01 16:09:07,750 main.py:52] epoch 127, training loss: 10252.83, average training loss: 12099.07, base loss: 16165.12
[INFO 2017-07-01 16:09:10,625 main.py:52] epoch 128, training loss: 8888.52, average training loss: 12074.19, base loss: 16158.03
[INFO 2017-07-01 16:09:13,487 main.py:52] epoch 129, training loss: 8688.37, average training loss: 12048.14, base loss: 16149.32
[INFO 2017-07-01 16:09:16,417 main.py:52] epoch 130, training loss: 9215.22, average training loss: 12026.52, base loss: 16137.60
[INFO 2017-07-01 16:09:19,290 main.py:52] epoch 131, training loss: 9740.41, average training loss: 12009.20, base loss: 16136.47
[INFO 2017-07-01 16:09:22,167 main.py:52] epoch 132, training loss: 9508.03, average training loss: 11990.39, base loss: 16133.37
[INFO 2017-07-01 16:09:25,015 main.py:52] epoch 133, training loss: 8320.06, average training loss: 11963.00, base loss: 16122.03
[INFO 2017-07-01 16:09:27,869 main.py:52] epoch 134, training loss: 9348.50, average training loss: 11943.63, base loss: 16118.34
[INFO 2017-07-01 16:09:30,723 main.py:52] epoch 135, training loss: 10330.50, average training loss: 11931.77, base loss: 16128.83
[INFO 2017-07-01 16:09:33,587 main.py:52] epoch 136, training loss: 9461.44, average training loss: 11913.74, base loss: 16126.66
[INFO 2017-07-01 16:09:36,489 main.py:52] epoch 137, training loss: 9714.51, average training loss: 11897.80, base loss: 16131.88
[INFO 2017-07-01 16:09:39,399 main.py:52] epoch 138, training loss: 9761.04, average training loss: 11882.43, base loss: 16127.30
[INFO 2017-07-01 16:09:42,297 main.py:52] epoch 139, training loss: 9087.80, average training loss: 11862.47, base loss: 16120.70
[INFO 2017-07-01 16:09:45,142 main.py:52] epoch 140, training loss: 8734.20, average training loss: 11840.28, base loss: 16108.84
[INFO 2017-07-01 16:09:48,071 main.py:52] epoch 141, training loss: 9276.44, average training loss: 11822.23, base loss: 16104.66
[INFO 2017-07-01 16:09:50,935 main.py:52] epoch 142, training loss: 9300.14, average training loss: 11804.59, base loss: 16102.08
[INFO 2017-07-01 16:09:53,826 main.py:52] epoch 143, training loss: 9018.65, average training loss: 11785.24, base loss: 16098.42
[INFO 2017-07-01 16:09:57,025 main.py:52] epoch 144, training loss: 8383.26, average training loss: 11761.78, base loss: 16084.85
[INFO 2017-07-01 16:09:59,905 main.py:52] epoch 145, training loss: 10317.81, average training loss: 11751.89, base loss: 16092.07
[INFO 2017-07-01 16:10:02,801 main.py:52] epoch 146, training loss: 10180.49, average training loss: 11741.20, base loss: 16099.73
[INFO 2017-07-01 16:10:05,699 main.py:52] epoch 147, training loss: 9651.82, average training loss: 11727.09, base loss: 16104.20
[INFO 2017-07-01 16:10:08,530 main.py:52] epoch 148, training loss: 9011.14, average training loss: 11708.86, base loss: 16097.11
[INFO 2017-07-01 16:10:11,428 main.py:52] epoch 149, training loss: 9417.83, average training loss: 11693.58, base loss: 16101.13
[INFO 2017-07-01 16:10:14,281 main.py:52] epoch 150, training loss: 9150.94, average training loss: 11676.75, base loss: 16098.93
[INFO 2017-07-01 16:10:17,146 main.py:52] epoch 151, training loss: 8863.45, average training loss: 11658.24, base loss: 16093.19
[INFO 2017-07-01 16:10:20,021 main.py:52] epoch 152, training loss: 9510.50, average training loss: 11644.20, base loss: 16092.04
[INFO 2017-07-01 16:10:22,918 main.py:52] epoch 153, training loss: 9220.84, average training loss: 11628.46, base loss: 16084.50
[INFO 2017-07-01 16:10:25,781 main.py:52] epoch 154, training loss: 9752.17, average training loss: 11616.36, base loss: 16086.59
[INFO 2017-07-01 16:10:28,656 main.py:52] epoch 155, training loss: 9428.66, average training loss: 11602.33, base loss: 16086.16
[INFO 2017-07-01 16:10:31,555 main.py:52] epoch 156, training loss: 9137.63, average training loss: 11586.64, base loss: 16079.25
[INFO 2017-07-01 16:10:34,443 main.py:52] epoch 157, training loss: 9203.62, average training loss: 11571.55, base loss: 16079.38
[INFO 2017-07-01 16:10:37,350 main.py:52] epoch 158, training loss: 9071.09, average training loss: 11555.83, base loss: 16076.98
[INFO 2017-07-01 16:10:40,211 main.py:52] epoch 159, training loss: 9413.84, average training loss: 11542.44, base loss: 16082.40
[INFO 2017-07-01 16:10:43,041 main.py:52] epoch 160, training loss: 9892.60, average training loss: 11532.19, base loss: 16088.14
[INFO 2017-07-01 16:10:45,938 main.py:52] epoch 161, training loss: 9246.88, average training loss: 11518.09, base loss: 16088.18
[INFO 2017-07-01 16:10:48,843 main.py:52] epoch 162, training loss: 9003.45, average training loss: 11502.66, base loss: 16079.00
[INFO 2017-07-01 16:10:51,718 main.py:52] epoch 163, training loss: 9367.54, average training loss: 11489.64, base loss: 16079.79
[INFO 2017-07-01 16:10:54,605 main.py:52] epoch 164, training loss: 9419.77, average training loss: 11477.09, base loss: 16083.15
[INFO 2017-07-01 16:10:57,520 main.py:52] epoch 165, training loss: 10665.39, average training loss: 11472.20, base loss: 16098.13
[INFO 2017-07-01 16:11:00,419 main.py:52] epoch 166, training loss: 8889.36, average training loss: 11456.74, base loss: 16096.33
[INFO 2017-07-01 16:11:03,275 main.py:52] epoch 167, training loss: 9711.88, average training loss: 11446.35, base loss: 16101.57
[INFO 2017-07-01 16:11:06,209 main.py:52] epoch 168, training loss: 10473.89, average training loss: 11440.60, base loss: 16119.71
[INFO 2017-07-01 16:11:09,093 main.py:52] epoch 169, training loss: 9436.63, average training loss: 11428.81, base loss: 16121.94
[INFO 2017-07-01 16:11:11,950 main.py:52] epoch 170, training loss: 9490.71, average training loss: 11417.48, base loss: 16128.40
[INFO 2017-07-01 16:11:14,844 main.py:52] epoch 171, training loss: 9494.13, average training loss: 11406.29, base loss: 16129.33
[INFO 2017-07-01 16:11:17,736 main.py:52] epoch 172, training loss: 9935.54, average training loss: 11397.79, base loss: 16135.14
[INFO 2017-07-01 16:11:20,589 main.py:52] epoch 173, training loss: 9361.19, average training loss: 11386.09, base loss: 16139.84
[INFO 2017-07-01 16:11:23,457 main.py:52] epoch 174, training loss: 7855.01, average training loss: 11365.91, base loss: 16128.77
[INFO 2017-07-01 16:11:26,302 main.py:52] epoch 175, training loss: 9394.79, average training loss: 11354.71, base loss: 16128.00
[INFO 2017-07-01 16:11:29,175 main.py:52] epoch 176, training loss: 9241.68, average training loss: 11342.77, base loss: 16127.76
[INFO 2017-07-01 16:11:32,078 main.py:52] epoch 177, training loss: 9939.26, average training loss: 11334.89, base loss: 16133.61
[INFO 2017-07-01 16:11:34,962 main.py:52] epoch 178, training loss: 9002.61, average training loss: 11321.86, base loss: 16126.99
[INFO 2017-07-01 16:11:37,902 main.py:52] epoch 179, training loss: 9950.94, average training loss: 11314.24, base loss: 16132.74
[INFO 2017-07-01 16:11:40,765 main.py:52] epoch 180, training loss: 9104.35, average training loss: 11302.03, base loss: 16128.81
[INFO 2017-07-01 16:11:43,655 main.py:52] epoch 181, training loss: 8788.69, average training loss: 11288.22, base loss: 16128.14
[INFO 2017-07-01 16:11:46,539 main.py:52] epoch 182, training loss: 9022.31, average training loss: 11275.84, base loss: 16124.36
[INFO 2017-07-01 16:11:49,412 main.py:52] epoch 183, training loss: 8438.72, average training loss: 11260.42, base loss: 16116.21
[INFO 2017-07-01 16:11:52,281 main.py:52] epoch 184, training loss: 9778.69, average training loss: 11252.41, base loss: 16118.18
[INFO 2017-07-01 16:11:55,118 main.py:52] epoch 185, training loss: 10033.89, average training loss: 11245.86, base loss: 16128.07
[INFO 2017-07-01 16:11:57,983 main.py:52] epoch 186, training loss: 8787.67, average training loss: 11232.72, base loss: 16123.09
[INFO 2017-07-01 16:12:00,839 main.py:52] epoch 187, training loss: 9379.07, average training loss: 11222.86, base loss: 16125.45
[INFO 2017-07-01 16:12:03,683 main.py:52] epoch 188, training loss: 8998.55, average training loss: 11211.09, base loss: 16127.29
[INFO 2017-07-01 16:12:06,616 main.py:52] epoch 189, training loss: 8388.98, average training loss: 11196.23, base loss: 16119.37
[INFO 2017-07-01 16:12:09,468 main.py:52] epoch 190, training loss: 9563.55, average training loss: 11187.69, base loss: 16124.53
[INFO 2017-07-01 16:12:12,337 main.py:52] epoch 191, training loss: 9151.22, average training loss: 11177.08, base loss: 16117.73
[INFO 2017-07-01 16:12:15,210 main.py:52] epoch 192, training loss: 8330.88, average training loss: 11162.33, base loss: 16109.86
[INFO 2017-07-01 16:12:18,068 main.py:52] epoch 193, training loss: 9346.52, average training loss: 11152.97, base loss: 16108.94
[INFO 2017-07-01 16:12:20,965 main.py:52] epoch 194, training loss: 9002.06, average training loss: 11141.94, base loss: 16105.22
[INFO 2017-07-01 16:12:23,853 main.py:52] epoch 195, training loss: 9634.15, average training loss: 11134.25, base loss: 16110.86
[INFO 2017-07-01 16:12:26,714 main.py:52] epoch 196, training loss: 9806.61, average training loss: 11127.51, base loss: 16111.59
[INFO 2017-07-01 16:12:29,574 main.py:52] epoch 197, training loss: 9345.05, average training loss: 11118.51, base loss: 16111.06
[INFO 2017-07-01 16:12:32,420 main.py:52] epoch 198, training loss: 9362.37, average training loss: 11109.68, base loss: 16112.68
[INFO 2017-07-01 16:12:35,287 main.py:52] epoch 199, training loss: 8993.45, average training loss: 11099.10, base loss: 16110.34
[INFO 2017-07-01 16:12:35,287 main.py:54] epoch 199, testing
[INFO 2017-07-01 16:12:47,721 main.py:97] average testing loss: 9243.27, base loss: 16311.99
[INFO 2017-07-01 16:12:47,722 main.py:98] improve_loss: 7068.72, improve_percent: 0.43
[INFO 2017-07-01 16:12:47,724 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 16:12:47,749 main.py:66] current best improved percent: 0.43
[INFO 2017-07-01 16:12:50,631 main.py:52] epoch 200, training loss: 9823.93, average training loss: 11092.76, base loss: 16113.78
[INFO 2017-07-01 16:12:53,492 main.py:52] epoch 201, training loss: 8856.71, average training loss: 11081.69, base loss: 16114.13
[INFO 2017-07-01 16:12:56,363 main.py:52] epoch 202, training loss: 8988.75, average training loss: 11071.38, base loss: 16110.67
[INFO 2017-07-01 16:12:59,239 main.py:52] epoch 203, training loss: 9293.38, average training loss: 11062.66, base loss: 16107.49
[INFO 2017-07-01 16:13:02,102 main.py:52] epoch 204, training loss: 8963.58, average training loss: 11052.42, base loss: 16103.59
[INFO 2017-07-01 16:13:04,985 main.py:52] epoch 205, training loss: 9165.82, average training loss: 11043.26, base loss: 16098.95
[INFO 2017-07-01 16:13:07,861 main.py:52] epoch 206, training loss: 8476.19, average training loss: 11030.86, base loss: 16089.97
[INFO 2017-07-01 16:13:10,732 main.py:52] epoch 207, training loss: 9232.77, average training loss: 11022.22, base loss: 16089.04
[INFO 2017-07-01 16:13:13,628 main.py:52] epoch 208, training loss: 8248.83, average training loss: 11008.95, base loss: 16081.12
[INFO 2017-07-01 16:13:16,469 main.py:52] epoch 209, training loss: 8718.93, average training loss: 10998.04, base loss: 16078.22
[INFO 2017-07-01 16:13:19,342 main.py:52] epoch 210, training loss: 8340.66, average training loss: 10985.45, base loss: 16071.05
[INFO 2017-07-01 16:13:22,201 main.py:52] epoch 211, training loss: 9031.81, average training loss: 10976.23, base loss: 16070.71
[INFO 2017-07-01 16:13:25,086 main.py:52] epoch 212, training loss: 9790.32, average training loss: 10970.67, base loss: 16076.28
[INFO 2017-07-01 16:13:27,995 main.py:52] epoch 213, training loss: 9167.38, average training loss: 10962.24, base loss: 16076.27
[INFO 2017-07-01 16:13:30,895 main.py:52] epoch 214, training loss: 8439.29, average training loss: 10950.51, base loss: 16069.13
[INFO 2017-07-01 16:13:33,749 main.py:52] epoch 215, training loss: 8904.36, average training loss: 10941.03, base loss: 16065.42
[INFO 2017-07-01 16:13:36,605 main.py:52] epoch 216, training loss: 9133.94, average training loss: 10932.71, base loss: 16065.29
[INFO 2017-07-01 16:13:39,453 main.py:52] epoch 217, training loss: 8176.42, average training loss: 10920.06, base loss: 16058.67
[INFO 2017-07-01 16:13:42,357 main.py:52] epoch 218, training loss: 8357.74, average training loss: 10908.36, base loss: 16054.81
[INFO 2017-07-01 16:13:45,283 main.py:52] epoch 219, training loss: 8587.24, average training loss: 10897.81, base loss: 16048.36
[INFO 2017-07-01 16:13:48,151 main.py:52] epoch 220, training loss: 8916.03, average training loss: 10888.84, base loss: 16046.76
[INFO 2017-07-01 16:13:51,065 main.py:52] epoch 221, training loss: 9314.38, average training loss: 10881.75, base loss: 16050.76
[INFO 2017-07-01 16:13:53,948 main.py:52] epoch 222, training loss: 9787.08, average training loss: 10876.84, base loss: 16055.65
[INFO 2017-07-01 16:13:56,832 main.py:52] epoch 223, training loss: 7804.45, average training loss: 10863.13, base loss: 16046.93
[INFO 2017-07-01 16:13:59,710 main.py:52] epoch 224, training loss: 9329.94, average training loss: 10856.31, base loss: 16050.33
[INFO 2017-07-01 16:14:02,582 main.py:52] epoch 225, training loss: 9165.44, average training loss: 10848.83, base loss: 16047.87
[INFO 2017-07-01 16:14:05,470 main.py:52] epoch 226, training loss: 10093.99, average training loss: 10845.51, base loss: 16061.22
[INFO 2017-07-01 16:14:08,360 main.py:52] epoch 227, training loss: 8987.01, average training loss: 10837.35, base loss: 16059.70
[INFO 2017-07-01 16:14:11,315 main.py:52] epoch 228, training loss: 8946.31, average training loss: 10829.10, base loss: 16057.55
[INFO 2017-07-01 16:14:14,204 main.py:52] epoch 229, training loss: 9094.56, average training loss: 10821.55, base loss: 16058.86
[INFO 2017-07-01 16:14:17,071 main.py:52] epoch 230, training loss: 8575.92, average training loss: 10811.83, base loss: 16053.41
[INFO 2017-07-01 16:14:19,961 main.py:52] epoch 231, training loss: 9352.93, average training loss: 10805.55, base loss: 16056.27
[INFO 2017-07-01 16:14:22,814 main.py:52] epoch 232, training loss: 8598.95, average training loss: 10796.07, base loss: 16052.59
[INFO 2017-07-01 16:14:25,754 main.py:52] epoch 233, training loss: 8249.96, average training loss: 10785.19, base loss: 16046.24
[INFO 2017-07-01 16:14:28,654 main.py:52] epoch 234, training loss: 8998.50, average training loss: 10777.59, base loss: 16049.40
[INFO 2017-07-01 16:14:31,519 main.py:52] epoch 235, training loss: 9191.29, average training loss: 10770.87, base loss: 16050.48
[INFO 2017-07-01 16:14:34,400 main.py:52] epoch 236, training loss: 9494.05, average training loss: 10765.48, base loss: 16060.86
[INFO 2017-07-01 16:14:37,471 main.py:52] epoch 237, training loss: 8998.82, average training loss: 10758.06, base loss: 16058.93
[INFO 2017-07-01 16:14:40,525 main.py:52] epoch 238, training loss: 9129.93, average training loss: 10751.25, base loss: 16055.94
[INFO 2017-07-01 16:14:43,445 main.py:52] epoch 239, training loss: 9568.15, average training loss: 10746.32, base loss: 16060.96
[INFO 2017-07-01 16:14:46,317 main.py:52] epoch 240, training loss: 9687.63, average training loss: 10741.92, base loss: 16063.85
[INFO 2017-07-01 16:14:49,233 main.py:52] epoch 241, training loss: 9581.43, average training loss: 10737.13, base loss: 16068.75
[INFO 2017-07-01 16:14:52,174 main.py:52] epoch 242, training loss: 7885.88, average training loss: 10725.40, base loss: 16056.31
[INFO 2017-07-01 16:14:55,038 main.py:52] epoch 243, training loss: 9286.12, average training loss: 10719.50, base loss: 16059.55
[INFO 2017-07-01 16:14:57,904 main.py:52] epoch 244, training loss: 8808.81, average training loss: 10711.70, base loss: 16054.96
[INFO 2017-07-01 16:15:00,806 main.py:52] epoch 245, training loss: 9029.73, average training loss: 10704.86, base loss: 16052.50
[INFO 2017-07-01 16:15:03,660 main.py:52] epoch 246, training loss: 9795.83, average training loss: 10701.18, base loss: 16057.18
[INFO 2017-07-01 16:15:06,502 main.py:52] epoch 247, training loss: 8840.59, average training loss: 10693.68, base loss: 16056.86
[INFO 2017-07-01 16:15:09,353 main.py:52] epoch 248, training loss: 9945.71, average training loss: 10690.67, base loss: 16064.69
[INFO 2017-07-01 16:15:12,219 main.py:52] epoch 249, training loss: 8172.70, average training loss: 10680.60, base loss: 16058.23
[INFO 2017-07-01 16:15:15,068 main.py:52] epoch 250, training loss: 9043.03, average training loss: 10674.08, base loss: 16055.41
[INFO 2017-07-01 16:15:17,944 main.py:52] epoch 251, training loss: 8682.29, average training loss: 10666.17, base loss: 16055.25
[INFO 2017-07-01 16:15:20,828 main.py:52] epoch 252, training loss: 8541.59, average training loss: 10657.78, base loss: 16048.62
[INFO 2017-07-01 16:15:23,721 main.py:52] epoch 253, training loss: 9005.66, average training loss: 10651.27, base loss: 16048.61
[INFO 2017-07-01 16:15:26,622 main.py:52] epoch 254, training loss: 9047.55, average training loss: 10644.98, base loss: 16044.35
[INFO 2017-07-01 16:15:29,488 main.py:52] epoch 255, training loss: 9194.16, average training loss: 10639.32, base loss: 16047.23
[INFO 2017-07-01 16:15:32,375 main.py:52] epoch 256, training loss: 8332.83, average training loss: 10630.34, base loss: 16044.17
[INFO 2017-07-01 16:15:35,255 main.py:52] epoch 257, training loss: 8653.90, average training loss: 10622.68, base loss: 16042.86
[INFO 2017-07-01 16:15:38,127 main.py:52] epoch 258, training loss: 8591.09, average training loss: 10614.84, base loss: 16038.42
[INFO 2017-07-01 16:15:41,015 main.py:52] epoch 259, training loss: 9691.54, average training loss: 10611.29, base loss: 16040.84
[INFO 2017-07-01 16:15:43,906 main.py:52] epoch 260, training loss: 7880.66, average training loss: 10600.82, base loss: 16032.63
[INFO 2017-07-01 16:15:46,823 main.py:52] epoch 261, training loss: 9787.54, average training loss: 10597.72, base loss: 16040.83
[INFO 2017-07-01 16:15:49,704 main.py:52] epoch 262, training loss: 8174.87, average training loss: 10588.51, base loss: 16036.83
[INFO 2017-07-01 16:15:52,640 main.py:52] epoch 263, training loss: 9904.13, average training loss: 10585.91, base loss: 16045.04
[INFO 2017-07-01 16:15:55,528 main.py:52] epoch 264, training loss: 8494.03, average training loss: 10578.02, base loss: 16043.81
[INFO 2017-07-01 16:15:58,415 main.py:52] epoch 265, training loss: 9422.70, average training loss: 10573.68, base loss: 16046.47
[INFO 2017-07-01 16:16:01,250 main.py:52] epoch 266, training loss: 8824.17, average training loss: 10567.12, base loss: 16043.13
[INFO 2017-07-01 16:16:04,090 main.py:52] epoch 267, training loss: 8847.24, average training loss: 10560.71, base loss: 16040.11
[INFO 2017-07-01 16:16:06,970 main.py:52] epoch 268, training loss: 8786.37, average training loss: 10554.11, base loss: 16039.76
[INFO 2017-07-01 16:16:09,882 main.py:52] epoch 269, training loss: 8746.36, average training loss: 10547.42, base loss: 16038.77
[INFO 2017-07-01 16:16:12,753 main.py:52] epoch 270, training loss: 8858.07, average training loss: 10541.18, base loss: 16036.91
[INFO 2017-07-01 16:16:15,615 main.py:52] epoch 271, training loss: 8846.94, average training loss: 10534.95, base loss: 16033.83
[INFO 2017-07-01 16:16:18,476 main.py:52] epoch 272, training loss: 9882.87, average training loss: 10532.56, base loss: 16038.58
[INFO 2017-07-01 16:16:21,332 main.py:52] epoch 273, training loss: 8485.77, average training loss: 10525.09, base loss: 16037.97
[INFO 2017-07-01 16:16:24,204 main.py:52] epoch 274, training loss: 9994.92, average training loss: 10523.17, base loss: 16045.72
[INFO 2017-07-01 16:16:27,090 main.py:52] epoch 275, training loss: 9250.89, average training loss: 10518.56, base loss: 16047.20
[INFO 2017-07-01 16:16:29,945 main.py:52] epoch 276, training loss: 8946.40, average training loss: 10512.88, base loss: 16049.18
[INFO 2017-07-01 16:16:32,799 main.py:52] epoch 277, training loss: 8452.29, average training loss: 10505.47, base loss: 16047.67
[INFO 2017-07-01 16:16:35,677 main.py:52] epoch 278, training loss: 9673.36, average training loss: 10502.49, base loss: 16052.47
[INFO 2017-07-01 16:16:38,579 main.py:52] epoch 279, training loss: 9045.70, average training loss: 10497.28, base loss: 16051.08
[INFO 2017-07-01 16:16:41,465 main.py:52] epoch 280, training loss: 8220.37, average training loss: 10489.18, base loss: 16045.24
[INFO 2017-07-01 16:16:44,352 main.py:52] epoch 281, training loss: 9363.51, average training loss: 10485.19, base loss: 16047.80
[INFO 2017-07-01 16:16:47,174 main.py:52] epoch 282, training loss: 9675.44, average training loss: 10482.33, base loss: 16050.09
[INFO 2017-07-01 16:16:50,045 main.py:52] epoch 283, training loss: 8595.99, average training loss: 10475.69, base loss: 16046.00
[INFO 2017-07-01 16:16:52,923 main.py:52] epoch 284, training loss: 9806.09, average training loss: 10473.34, base loss: 16048.85
[INFO 2017-07-01 16:16:55,793 main.py:52] epoch 285, training loss: 8649.26, average training loss: 10466.96, base loss: 16045.04
[INFO 2017-07-01 16:16:58,644 main.py:52] epoch 286, training loss: 10116.92, average training loss: 10465.74, base loss: 16053.96
[INFO 2017-07-01 16:17:01,557 main.py:52] epoch 287, training loss: 9306.79, average training loss: 10461.71, base loss: 16053.43
[INFO 2017-07-01 16:17:04,417 main.py:52] epoch 288, training loss: 9400.11, average training loss: 10458.04, base loss: 16057.40
[INFO 2017-07-01 16:17:07,347 main.py:52] epoch 289, training loss: 8539.53, average training loss: 10451.43, base loss: 16052.56
[INFO 2017-07-01 16:17:10,239 main.py:52] epoch 290, training loss: 8290.91, average training loss: 10444.00, base loss: 16049.13
[INFO 2017-07-01 16:17:13,097 main.py:52] epoch 291, training loss: 8736.04, average training loss: 10438.15, base loss: 16048.26
[INFO 2017-07-01 16:17:15,999 main.py:52] epoch 292, training loss: 9506.40, average training loss: 10434.97, base loss: 16057.70
[INFO 2017-07-01 16:17:18,868 main.py:52] epoch 293, training loss: 7989.52, average training loss: 10426.65, base loss: 16049.26
[INFO 2017-07-01 16:17:21,725 main.py:52] epoch 294, training loss: 9409.03, average training loss: 10423.20, base loss: 16054.28
[INFO 2017-07-01 16:17:24,588 main.py:52] epoch 295, training loss: 8298.38, average training loss: 10416.03, base loss: 16054.09
[INFO 2017-07-01 16:17:27,472 main.py:52] epoch 296, training loss: 8193.47, average training loss: 10408.54, base loss: 16049.22
[INFO 2017-07-01 16:17:30,392 main.py:52] epoch 297, training loss: 8413.26, average training loss: 10401.85, base loss: 16044.39
[INFO 2017-07-01 16:17:33,270 main.py:52] epoch 298, training loss: 8619.88, average training loss: 10395.89, base loss: 16041.61
[INFO 2017-07-01 16:17:36,155 main.py:52] epoch 299, training loss: 8467.50, average training loss: 10389.46, base loss: 16039.24
[INFO 2017-07-01 16:17:36,155 main.py:54] epoch 299, testing
[INFO 2017-07-01 16:17:48,512 main.py:97] average testing loss: 9085.13, base loss: 16687.85
[INFO 2017-07-01 16:17:48,512 main.py:98] improve_loss: 7602.72, improve_percent: 0.46
[INFO 2017-07-01 16:17:48,513 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 16:17:48,538 main.py:66] current best improved percent: 0.46
[INFO 2017-07-01 16:17:51,404 main.py:52] epoch 300, training loss: 8009.70, average training loss: 10381.55, base loss: 16031.29
[INFO 2017-07-01 16:17:54,320 main.py:52] epoch 301, training loss: 8866.85, average training loss: 10376.54, base loss: 16033.46
[INFO 2017-07-01 16:17:57,172 main.py:52] epoch 302, training loss: 8363.58, average training loss: 10369.89, base loss: 16029.84
[INFO 2017-07-01 16:18:00,011 main.py:52] epoch 303, training loss: 9391.78, average training loss: 10366.68, base loss: 16033.77
[INFO 2017-07-01 16:18:02,891 main.py:52] epoch 304, training loss: 9709.85, average training loss: 10364.52, base loss: 16039.89
[INFO 2017-07-01 16:18:05,757 main.py:52] epoch 305, training loss: 8111.45, average training loss: 10357.16, base loss: 16036.36
[INFO 2017-07-01 16:18:08,628 main.py:52] epoch 306, training loss: 8854.54, average training loss: 10352.27, base loss: 16036.00
[INFO 2017-07-01 16:18:11,489 main.py:52] epoch 307, training loss: 9383.85, average training loss: 10349.12, base loss: 16036.57
[INFO 2017-07-01 16:18:14,336 main.py:52] epoch 308, training loss: 8862.74, average training loss: 10344.31, base loss: 16037.05
[INFO 2017-07-01 16:18:17,226 main.py:52] epoch 309, training loss: 9493.65, average training loss: 10341.57, base loss: 16040.45
[INFO 2017-07-01 16:18:20,097 main.py:52] epoch 310, training loss: 8149.04, average training loss: 10334.52, base loss: 16036.51
[INFO 2017-07-01 16:18:22,949 main.py:52] epoch 311, training loss: 8525.11, average training loss: 10328.72, base loss: 16034.58
[INFO 2017-07-01 16:18:25,817 main.py:52] epoch 312, training loss: 7669.22, average training loss: 10320.22, base loss: 16027.16
[INFO 2017-07-01 16:18:28,719 main.py:52] epoch 313, training loss: 8742.13, average training loss: 10315.20, base loss: 16028.62
[INFO 2017-07-01 16:18:31,644 main.py:52] epoch 314, training loss: 8322.41, average training loss: 10308.87, base loss: 16025.05
[INFO 2017-07-01 16:18:34,510 main.py:52] epoch 315, training loss: 8276.79, average training loss: 10302.44, base loss: 16021.95
[INFO 2017-07-01 16:18:37,417 main.py:52] epoch 316, training loss: 9390.04, average training loss: 10299.56, base loss: 16024.72
[INFO 2017-07-01 16:18:40,282 main.py:52] epoch 317, training loss: 8707.41, average training loss: 10294.55, base loss: 16023.31
[INFO 2017-07-01 16:18:43,153 main.py:52] epoch 318, training loss: 8300.00, average training loss: 10288.30, base loss: 16018.12
[INFO 2017-07-01 16:18:46,039 main.py:52] epoch 319, training loss: 8601.14, average training loss: 10283.03, base loss: 16018.86
[INFO 2017-07-01 16:18:48,974 main.py:52] epoch 320, training loss: 8262.47, average training loss: 10276.73, base loss: 16017.09
[INFO 2017-07-01 16:18:51,824 main.py:52] epoch 321, training loss: 8630.25, average training loss: 10271.62, base loss: 16016.02
[INFO 2017-07-01 16:18:54,710 main.py:52] epoch 322, training loss: 8712.89, average training loss: 10266.79, base loss: 16018.47
[INFO 2017-07-01 16:18:57,603 main.py:52] epoch 323, training loss: 9032.98, average training loss: 10262.99, base loss: 16021.09
[INFO 2017-07-01 16:19:00,455 main.py:52] epoch 324, training loss: 8962.35, average training loss: 10258.98, base loss: 16024.87
[INFO 2017-07-01 16:19:03,311 main.py:52] epoch 325, training loss: 9009.70, average training loss: 10255.15, base loss: 16027.85
[INFO 2017-07-01 16:19:06,194 main.py:52] epoch 326, training loss: 8079.61, average training loss: 10248.50, base loss: 16023.73
[INFO 2017-07-01 16:19:09,049 main.py:52] epoch 327, training loss: 8038.23, average training loss: 10241.76, base loss: 16022.39
[INFO 2017-07-01 16:19:11,947 main.py:52] epoch 328, training loss: 8810.58, average training loss: 10237.41, base loss: 16025.90
[INFO 2017-07-01 16:19:14,833 main.py:52] epoch 329, training loss: 8752.85, average training loss: 10232.91, base loss: 16025.23
[INFO 2017-07-01 16:19:17,665 main.py:52] epoch 330, training loss: 9182.87, average training loss: 10229.74, base loss: 16031.01
[INFO 2017-07-01 16:19:20,542 main.py:52] epoch 331, training loss: 7963.37, average training loss: 10222.91, base loss: 16025.74
[INFO 2017-07-01 16:19:23,423 main.py:52] epoch 332, training loss: 8290.54, average training loss: 10217.11, base loss: 16022.21
[INFO 2017-07-01 16:19:26,312 main.py:52] epoch 333, training loss: 8619.81, average training loss: 10212.33, base loss: 16020.44
[INFO 2017-07-01 16:19:29,215 main.py:52] epoch 334, training loss: 7611.19, average training loss: 10204.56, base loss: 16014.79
[INFO 2017-07-01 16:19:32,091 main.py:52] epoch 335, training loss: 8521.67, average training loss: 10199.55, base loss: 16013.62
[INFO 2017-07-01 16:19:34,973 main.py:52] epoch 336, training loss: 8822.24, average training loss: 10195.47, base loss: 16013.44
[INFO 2017-07-01 16:19:37,859 main.py:52] epoch 337, training loss: 8181.17, average training loss: 10189.51, base loss: 16011.59
[INFO 2017-07-01 16:19:41,027 main.py:52] epoch 338, training loss: 8314.37, average training loss: 10183.98, base loss: 16010.29
[INFO 2017-07-01 16:19:43,905 main.py:52] epoch 339, training loss: 9187.20, average training loss: 10181.05, base loss: 16010.90
[INFO 2017-07-01 16:19:46,781 main.py:52] epoch 340, training loss: 8357.10, average training loss: 10175.70, base loss: 16009.93
[INFO 2017-07-01 16:19:49,712 main.py:52] epoch 341, training loss: 8433.42, average training loss: 10170.60, base loss: 16009.90
[INFO 2017-07-01 16:19:52,577 main.py:52] epoch 342, training loss: 8348.16, average training loss: 10165.29, base loss: 16008.65
[INFO 2017-07-01 16:19:55,467 main.py:52] epoch 343, training loss: 8644.17, average training loss: 10160.87, base loss: 16010.90
[INFO 2017-07-01 16:19:58,332 main.py:52] epoch 344, training loss: 8648.83, average training loss: 10156.48, base loss: 16010.98
[INFO 2017-07-01 16:20:01,254 main.py:52] epoch 345, training loss: 7853.73, average training loss: 10149.83, base loss: 16004.84
[INFO 2017-07-01 16:20:04,147 main.py:52] epoch 346, training loss: 8911.75, average training loss: 10146.26, base loss: 16007.62
[INFO 2017-07-01 16:20:07,036 main.py:52] epoch 347, training loss: 9450.88, average training loss: 10144.26, base loss: 16011.07
[INFO 2017-07-01 16:20:09,967 main.py:52] epoch 348, training loss: 7745.30, average training loss: 10137.39, base loss: 16007.54
[INFO 2017-07-01 16:20:12,819 main.py:52] epoch 349, training loss: 8324.45, average training loss: 10132.21, base loss: 16006.08
[INFO 2017-07-01 16:20:15,681 main.py:52] epoch 350, training loss: 8141.88, average training loss: 10126.54, base loss: 16002.68
[INFO 2017-07-01 16:20:18,575 main.py:52] epoch 351, training loss: 8180.28, average training loss: 10121.01, base loss: 16001.11
[INFO 2017-07-01 16:20:21,484 main.py:52] epoch 352, training loss: 9469.16, average training loss: 10119.16, base loss: 16007.24
[INFO 2017-07-01 16:20:24,424 main.py:52] epoch 353, training loss: 8310.36, average training loss: 10114.05, base loss: 16006.33
[INFO 2017-07-01 16:20:27,474 main.py:52] epoch 354, training loss: 8377.04, average training loss: 10109.16, base loss: 16005.37
[INFO 2017-07-01 16:20:30,456 main.py:52] epoch 355, training loss: 9308.16, average training loss: 10106.91, base loss: 16008.07
[INFO 2017-07-01 16:20:33,304 main.py:52] epoch 356, training loss: 8547.01, average training loss: 10102.54, base loss: 16006.32
[INFO 2017-07-01 16:20:36,166 main.py:52] epoch 357, training loss: 9065.00, average training loss: 10099.64, base loss: 16008.92
[INFO 2017-07-01 16:20:39,018 main.py:52] epoch 358, training loss: 8670.20, average training loss: 10095.66, base loss: 16011.66
[INFO 2017-07-01 16:20:41,907 main.py:52] epoch 359, training loss: 8144.08, average training loss: 10090.24, base loss: 16009.11
[INFO 2017-07-01 16:20:44,762 main.py:52] epoch 360, training loss: 8476.43, average training loss: 10085.77, base loss: 16008.99
[INFO 2017-07-01 16:20:47,639 main.py:52] epoch 361, training loss: 9304.11, average training loss: 10083.61, base loss: 16012.64
[INFO 2017-07-01 16:20:50,538 main.py:52] epoch 362, training loss: 9363.86, average training loss: 10081.63, base loss: 16019.55
[INFO 2017-07-01 16:20:53,453 main.py:52] epoch 363, training loss: 8765.84, average training loss: 10078.01, base loss: 16022.10
[INFO 2017-07-01 16:20:56,337 main.py:52] epoch 364, training loss: 8114.39, average training loss: 10072.63, base loss: 16020.49
[INFO 2017-07-01 16:20:59,213 main.py:52] epoch 365, training loss: 8161.26, average training loss: 10067.41, base loss: 16016.75
[INFO 2017-07-01 16:21:02,105 main.py:52] epoch 366, training loss: 9005.58, average training loss: 10064.52, base loss: 16020.19
[INFO 2017-07-01 16:21:05,001 main.py:52] epoch 367, training loss: 8417.80, average training loss: 10060.04, base loss: 16021.42
[INFO 2017-07-01 16:21:07,913 main.py:52] epoch 368, training loss: 8241.86, average training loss: 10055.12, base loss: 16020.47
[INFO 2017-07-01 16:21:10,784 main.py:52] epoch 369, training loss: 8398.40, average training loss: 10050.64, base loss: 16020.44
[INFO 2017-07-01 16:21:13,640 main.py:52] epoch 370, training loss: 8663.31, average training loss: 10046.90, base loss: 16018.72
[INFO 2017-07-01 16:21:16,473 main.py:52] epoch 371, training loss: 8573.89, average training loss: 10042.94, base loss: 16017.68
[INFO 2017-07-01 16:21:19,354 main.py:52] epoch 372, training loss: 8895.24, average training loss: 10039.86, base loss: 16020.72
[INFO 2017-07-01 16:21:22,239 main.py:52] epoch 373, training loss: 7881.57, average training loss: 10034.09, base loss: 16015.53
[INFO 2017-07-01 16:21:25,074 main.py:52] epoch 374, training loss: 8829.87, average training loss: 10030.88, base loss: 16017.53
[INFO 2017-07-01 16:21:27,911 main.py:52] epoch 375, training loss: 8603.88, average training loss: 10027.08, base loss: 16020.35
[INFO 2017-07-01 16:21:30,839 main.py:52] epoch 376, training loss: 10001.14, average training loss: 10027.02, base loss: 16027.04
[INFO 2017-07-01 16:21:33,751 main.py:52] epoch 377, training loss: 8596.83, average training loss: 10023.23, base loss: 16027.21
[INFO 2017-07-01 16:21:36,618 main.py:52] epoch 378, training loss: 9107.11, average training loss: 10020.81, base loss: 16028.91
[INFO 2017-07-01 16:21:39,532 main.py:52] epoch 379, training loss: 8484.93, average training loss: 10016.77, base loss: 16029.86
[INFO 2017-07-01 16:21:42,381 main.py:52] epoch 380, training loss: 9491.95, average training loss: 10015.40, base loss: 16032.17
[INFO 2017-07-01 16:21:45,272 main.py:52] epoch 381, training loss: 8452.46, average training loss: 10011.30, base loss: 16032.35
[INFO 2017-07-01 16:21:48,192 main.py:52] epoch 382, training loss: 8686.95, average training loss: 10007.85, base loss: 16034.88
[INFO 2017-07-01 16:21:51,068 main.py:52] epoch 383, training loss: 7921.23, average training loss: 10002.41, base loss: 16031.02
[INFO 2017-07-01 16:21:53,963 main.py:52] epoch 384, training loss: 9188.85, average training loss: 10000.30, base loss: 16035.10
[INFO 2017-07-01 16:21:56,833 main.py:52] epoch 385, training loss: 9202.22, average training loss: 9998.23, base loss: 16039.60
[INFO 2017-07-01 16:21:59,660 main.py:52] epoch 386, training loss: 9162.86, average training loss: 9996.07, base loss: 16043.15
[INFO 2017-07-01 16:22:02,543 main.py:52] epoch 387, training loss: 8642.78, average training loss: 9992.59, base loss: 16044.15
[INFO 2017-07-01 16:22:05,414 main.py:52] epoch 388, training loss: 8049.36, average training loss: 9987.59, base loss: 16044.79
[INFO 2017-07-01 16:22:08,285 main.py:52] epoch 389, training loss: 8367.82, average training loss: 9983.44, base loss: 16042.06
[INFO 2017-07-01 16:22:11,160 main.py:52] epoch 390, training loss: 8317.10, average training loss: 9979.17, base loss: 16040.25
[INFO 2017-07-01 16:22:14,030 main.py:52] epoch 391, training loss: 8578.74, average training loss: 9975.60, base loss: 16041.22
[INFO 2017-07-01 16:22:16,916 main.py:52] epoch 392, training loss: 8730.69, average training loss: 9972.43, base loss: 16042.46
[INFO 2017-07-01 16:22:19,786 main.py:52] epoch 393, training loss: 8124.59, average training loss: 9967.74, base loss: 16038.40
[INFO 2017-07-01 16:22:22,645 main.py:52] epoch 394, training loss: 7868.88, average training loss: 9962.43, base loss: 16034.87
[INFO 2017-07-01 16:22:25,551 main.py:52] epoch 395, training loss: 8967.96, average training loss: 9959.92, base loss: 16037.27
[INFO 2017-07-01 16:22:28,458 main.py:52] epoch 396, training loss: 8885.17, average training loss: 9957.21, base loss: 16040.24
[INFO 2017-07-01 16:22:31,386 main.py:52] epoch 397, training loss: 8730.38, average training loss: 9954.13, base loss: 16041.07
[INFO 2017-07-01 16:22:34,221 main.py:52] epoch 398, training loss: 8344.57, average training loss: 9950.10, base loss: 16041.00
[INFO 2017-07-01 16:22:37,102 main.py:52] epoch 399, training loss: 8256.44, average training loss: 9945.86, base loss: 16039.40
[INFO 2017-07-01 16:22:37,103 main.py:54] epoch 399, testing
[INFO 2017-07-01 16:22:49,535 main.py:97] average testing loss: 8297.51, base loss: 15755.37
[INFO 2017-07-01 16:22:49,535 main.py:98] improve_loss: 7457.86, improve_percent: 0.47
[INFO 2017-07-01 16:22:49,536 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 16:22:49,562 main.py:66] current best improved percent: 0.47
[INFO 2017-07-01 16:22:52,411 main.py:52] epoch 400, training loss: 8384.86, average training loss: 9941.97, base loss: 16037.68
[INFO 2017-07-01 16:22:55,270 main.py:52] epoch 401, training loss: 8638.64, average training loss: 9938.73, base loss: 16040.23
[INFO 2017-07-01 16:22:58,112 main.py:52] epoch 402, training loss: 8495.35, average training loss: 9935.15, base loss: 16042.18
[INFO 2017-07-01 16:23:00,985 main.py:52] epoch 403, training loss: 8483.78, average training loss: 9931.55, base loss: 16042.03
[INFO 2017-07-01 16:23:03,835 main.py:52] epoch 404, training loss: 8457.35, average training loss: 9927.91, base loss: 16042.25
[INFO 2017-07-01 16:23:06,742 main.py:52] epoch 405, training loss: 8363.82, average training loss: 9924.06, base loss: 16040.63
[INFO 2017-07-01 16:23:09,610 main.py:52] epoch 406, training loss: 8517.59, average training loss: 9920.60, base loss: 16039.30
[INFO 2017-07-01 16:23:12,500 main.py:52] epoch 407, training loss: 8128.99, average training loss: 9916.21, base loss: 16038.28
[INFO 2017-07-01 16:23:15,342 main.py:52] epoch 408, training loss: 8552.42, average training loss: 9912.88, base loss: 16040.71
[INFO 2017-07-01 16:23:18,203 main.py:52] epoch 409, training loss: 8830.11, average training loss: 9910.24, base loss: 16043.09
[INFO 2017-07-01 16:23:21,091 main.py:52] epoch 410, training loss: 8671.18, average training loss: 9907.22, base loss: 16044.75
[INFO 2017-07-01 16:23:23,973 main.py:52] epoch 411, training loss: 8357.68, average training loss: 9903.46, base loss: 16043.88
[INFO 2017-07-01 16:23:26,865 main.py:52] epoch 412, training loss: 7928.95, average training loss: 9898.68, base loss: 16039.12
[INFO 2017-07-01 16:23:29,859 main.py:52] epoch 413, training loss: 8048.33, average training loss: 9894.21, base loss: 16037.98
[INFO 2017-07-01 16:23:32,703 main.py:52] epoch 414, training loss: 8925.20, average training loss: 9891.88, base loss: 16042.48
[INFO 2017-07-01 16:23:35,601 main.py:52] epoch 415, training loss: 9414.12, average training loss: 9890.73, base loss: 16047.56
[INFO 2017-07-01 16:23:38,451 main.py:52] epoch 416, training loss: 8877.75, average training loss: 9888.30, base loss: 16051.45
[INFO 2017-07-01 16:23:41,325 main.py:52] epoch 417, training loss: 9030.76, average training loss: 9886.25, base loss: 16054.54
[INFO 2017-07-01 16:23:44,180 main.py:52] epoch 418, training loss: 8747.42, average training loss: 9883.53, base loss: 16054.72
[INFO 2017-07-01 16:23:47,052 main.py:52] epoch 419, training loss: 8448.65, average training loss: 9880.11, base loss: 16053.86
[INFO 2017-07-01 16:23:49,988 main.py:52] epoch 420, training loss: 8394.33, average training loss: 9876.58, base loss: 16053.66
[INFO 2017-07-01 16:23:52,879 main.py:52] epoch 421, training loss: 8455.89, average training loss: 9873.22, base loss: 16052.93
[INFO 2017-07-01 16:23:55,793 main.py:52] epoch 422, training loss: 7923.56, average training loss: 9868.61, base loss: 16048.71
[INFO 2017-07-01 16:23:58,654 main.py:52] epoch 423, training loss: 9125.49, average training loss: 9866.86, base loss: 16053.13
[INFO 2017-07-01 16:24:01,517 main.py:52] epoch 424, training loss: 8511.50, average training loss: 9863.67, base loss: 16052.91
[INFO 2017-07-01 16:24:04,418 main.py:52] epoch 425, training loss: 8451.76, average training loss: 9860.35, base loss: 16051.87
[INFO 2017-07-01 16:24:07,354 main.py:52] epoch 426, training loss: 8041.78, average training loss: 9856.09, base loss: 16051.26
[INFO 2017-07-01 16:24:10,205 main.py:52] epoch 427, training loss: 8029.87, average training loss: 9851.83, base loss: 16048.03
[INFO 2017-07-01 16:24:13,131 main.py:52] epoch 428, training loss: 8348.81, average training loss: 9848.32, base loss: 16047.56
[INFO 2017-07-01 16:24:16,076 main.py:52] epoch 429, training loss: 8898.35, average training loss: 9846.11, base loss: 16051.16
[INFO 2017-07-01 16:24:18,928 main.py:52] epoch 430, training loss: 7619.18, average training loss: 9840.95, base loss: 16045.66
[INFO 2017-07-01 16:24:21,807 main.py:52] epoch 431, training loss: 8832.39, average training loss: 9838.61, base loss: 16046.83
[INFO 2017-07-01 16:24:24,708 main.py:52] epoch 432, training loss: 9274.15, average training loss: 9837.31, base loss: 16050.85
[INFO 2017-07-01 16:24:27,615 main.py:52] epoch 433, training loss: 9066.22, average training loss: 9835.53, base loss: 16053.28
[INFO 2017-07-01 16:24:30,487 main.py:52] epoch 434, training loss: 8461.80, average training loss: 9832.37, base loss: 16053.05
[INFO 2017-07-01 16:24:33,341 main.py:52] epoch 435, training loss: 7806.30, average training loss: 9827.73, base loss: 16050.04
[INFO 2017-07-01 16:24:36,205 main.py:52] epoch 436, training loss: 8452.58, average training loss: 9824.58, base loss: 16050.38
[INFO 2017-07-01 16:24:39,120 main.py:52] epoch 437, training loss: 7925.92, average training loss: 9820.25, base loss: 16047.71
[INFO 2017-07-01 16:24:42,017 main.py:52] epoch 438, training loss: 8222.14, average training loss: 9816.61, base loss: 16046.12
[INFO 2017-07-01 16:24:44,878 main.py:52] epoch 439, training loss: 8534.04, average training loss: 9813.69, base loss: 16045.58
[INFO 2017-07-01 16:24:47,757 main.py:52] epoch 440, training loss: 8335.33, average training loss: 9810.34, base loss: 16045.70
[INFO 2017-07-01 16:24:50,657 main.py:52] epoch 441, training loss: 9042.12, average training loss: 9808.60, base loss: 16047.68
[INFO 2017-07-01 16:24:53,500 main.py:52] epoch 442, training loss: 8359.66, average training loss: 9805.33, base loss: 16045.20
[INFO 2017-07-01 16:24:56,407 main.py:52] epoch 443, training loss: 8765.24, average training loss: 9802.99, base loss: 16046.70
[INFO 2017-07-01 16:24:59,276 main.py:52] epoch 444, training loss: 9095.87, average training loss: 9801.40, base loss: 16049.61
[INFO 2017-07-01 16:25:02,140 main.py:52] epoch 445, training loss: 8973.94, average training loss: 9799.54, base loss: 16052.38
[INFO 2017-07-01 16:25:05,023 main.py:52] epoch 446, training loss: 8549.65, average training loss: 9796.75, base loss: 16052.02
[INFO 2017-07-01 16:25:07,917 main.py:52] epoch 447, training loss: 8041.37, average training loss: 9792.83, base loss: 16050.45
[INFO 2017-07-01 16:25:10,786 main.py:52] epoch 448, training loss: 7910.45, average training loss: 9788.64, base loss: 16047.14
[INFO 2017-07-01 16:25:13,651 main.py:52] epoch 449, training loss: 9240.08, average training loss: 9787.42, base loss: 16050.98
[INFO 2017-07-01 16:25:16,534 main.py:52] epoch 450, training loss: 8312.71, average training loss: 9784.15, base loss: 16050.59
[INFO 2017-07-01 16:25:19,438 main.py:52] epoch 451, training loss: 8612.88, average training loss: 9781.56, base loss: 16052.03
[INFO 2017-07-01 16:25:22,312 main.py:52] epoch 452, training loss: 7492.78, average training loss: 9776.50, base loss: 16048.07
[INFO 2017-07-01 16:25:25,166 main.py:52] epoch 453, training loss: 8652.17, average training loss: 9774.03, base loss: 16050.05
[INFO 2017-07-01 16:25:28,038 main.py:52] epoch 454, training loss: 8925.28, average training loss: 9772.16, base loss: 16052.24
[INFO 2017-07-01 16:25:30,896 main.py:52] epoch 455, training loss: 7925.61, average training loss: 9768.11, base loss: 16050.07
[INFO 2017-07-01 16:25:33,806 main.py:52] epoch 456, training loss: 8113.37, average training loss: 9764.49, base loss: 16048.99
[INFO 2017-07-01 16:25:36,661 main.py:52] epoch 457, training loss: 8932.91, average training loss: 9762.67, base loss: 16051.20
[INFO 2017-07-01 16:25:39,533 main.py:52] epoch 458, training loss: 8125.89, average training loss: 9759.11, base loss: 16050.50
[INFO 2017-07-01 16:25:42,393 main.py:52] epoch 459, training loss: 8202.42, average training loss: 9755.72, base loss: 16050.63
[INFO 2017-07-01 16:25:45,274 main.py:52] epoch 460, training loss: 8186.61, average training loss: 9752.32, base loss: 16046.66
[INFO 2017-07-01 16:25:48,141 main.py:52] epoch 461, training loss: 8608.09, average training loss: 9749.84, base loss: 16048.20
[INFO 2017-07-01 16:25:51,044 main.py:52] epoch 462, training loss: 8138.40, average training loss: 9746.36, base loss: 16046.10
[INFO 2017-07-01 16:25:53,940 main.py:52] epoch 463, training loss: 7991.83, average training loss: 9742.58, base loss: 16042.68
[INFO 2017-07-01 16:25:56,832 main.py:52] epoch 464, training loss: 7852.35, average training loss: 9738.52, base loss: 16038.94
[INFO 2017-07-01 16:25:59,679 main.py:52] epoch 465, training loss: 9420.06, average training loss: 9737.83, base loss: 16042.91
[INFO 2017-07-01 16:26:02,585 main.py:52] epoch 466, training loss: 9243.69, average training loss: 9736.78, base loss: 16046.14
[INFO 2017-07-01 16:26:05,480 main.py:52] epoch 467, training loss: 8419.75, average training loss: 9733.96, base loss: 16045.21
[INFO 2017-07-01 16:26:08,368 main.py:52] epoch 468, training loss: 9286.37, average training loss: 9733.01, base loss: 16049.02
[INFO 2017-07-01 16:26:11,288 main.py:52] epoch 469, training loss: 8529.34, average training loss: 9730.45, base loss: 16047.72
[INFO 2017-07-01 16:26:14,144 main.py:52] epoch 470, training loss: 8309.22, average training loss: 9727.43, base loss: 16046.39
[INFO 2017-07-01 16:26:17,062 main.py:52] epoch 471, training loss: 8366.97, average training loss: 9724.55, base loss: 16043.97
[INFO 2017-07-01 16:26:19,973 main.py:52] epoch 472, training loss: 8914.82, average training loss: 9722.83, base loss: 16046.82
[INFO 2017-07-01 16:26:22,822 main.py:52] epoch 473, training loss: 7806.01, average training loss: 9718.79, base loss: 16044.61
[INFO 2017-07-01 16:26:25,695 main.py:52] epoch 474, training loss: 7833.94, average training loss: 9714.82, base loss: 16041.38
[INFO 2017-07-01 16:26:28,552 main.py:52] epoch 475, training loss: 8463.52, average training loss: 9712.19, base loss: 16041.85
[INFO 2017-07-01 16:26:31,444 main.py:52] epoch 476, training loss: 8545.60, average training loss: 9709.75, base loss: 16041.98
[INFO 2017-07-01 16:26:34,335 main.py:52] epoch 477, training loss: 9495.45, average training loss: 9709.30, base loss: 16047.85
[INFO 2017-07-01 16:26:37,207 main.py:52] epoch 478, training loss: 8652.64, average training loss: 9707.09, base loss: 16048.37
[INFO 2017-07-01 16:26:40,054 main.py:52] epoch 479, training loss: 8301.58, average training loss: 9704.17, base loss: 16047.75
[INFO 2017-07-01 16:26:42,980 main.py:52] epoch 480, training loss: 8229.10, average training loss: 9701.10, base loss: 16046.65
[INFO 2017-07-01 16:26:45,856 main.py:52] epoch 481, training loss: 8249.96, average training loss: 9698.09, base loss: 16045.30
[INFO 2017-07-01 16:26:48,748 main.py:52] epoch 482, training loss: 8065.63, average training loss: 9694.71, base loss: 16043.99
[INFO 2017-07-01 16:26:51,626 main.py:52] epoch 483, training loss: 8091.10, average training loss: 9691.40, base loss: 16041.60
[INFO 2017-07-01 16:26:54,507 main.py:52] epoch 484, training loss: 7550.23, average training loss: 9686.98, base loss: 16037.10
[INFO 2017-07-01 16:26:57,385 main.py:52] epoch 485, training loss: 8733.79, average training loss: 9685.02, base loss: 16037.10
[INFO 2017-07-01 16:27:00,252 main.py:52] epoch 486, training loss: 7940.06, average training loss: 9681.44, base loss: 16035.64
[INFO 2017-07-01 16:27:03,111 main.py:52] epoch 487, training loss: 8592.44, average training loss: 9679.20, base loss: 16036.08
[INFO 2017-07-01 16:27:06,002 main.py:52] epoch 488, training loss: 9257.78, average training loss: 9678.34, base loss: 16036.72
[INFO 2017-07-01 16:27:08,960 main.py:52] epoch 489, training loss: 8569.46, average training loss: 9676.08, base loss: 16037.24
[INFO 2017-07-01 16:27:11,819 main.py:52] epoch 490, training loss: 7821.76, average training loss: 9672.30, base loss: 16034.86
[INFO 2017-07-01 16:27:14,713 main.py:52] epoch 491, training loss: 7620.01, average training loss: 9668.13, base loss: 16031.80
[INFO 2017-07-01 16:27:17,575 main.py:52] epoch 492, training loss: 8718.47, average training loss: 9666.21, base loss: 16031.62
[INFO 2017-07-01 16:27:20,476 main.py:52] epoch 493, training loss: 7721.68, average training loss: 9662.27, base loss: 16028.54
[INFO 2017-07-01 16:27:23,375 main.py:52] epoch 494, training loss: 7826.59, average training loss: 9658.56, base loss: 16027.18
[INFO 2017-07-01 16:27:26,273 main.py:52] epoch 495, training loss: 9013.00, average training loss: 9657.26, base loss: 16031.53
[INFO 2017-07-01 16:27:29,168 main.py:52] epoch 496, training loss: 8377.34, average training loss: 9654.68, base loss: 16032.78
[INFO 2017-07-01 16:27:32,034 main.py:52] epoch 497, training loss: 9065.02, average training loss: 9653.50, base loss: 16035.07
[INFO 2017-07-01 16:27:34,935 main.py:52] epoch 498, training loss: 8589.62, average training loss: 9651.37, base loss: 16035.22
[INFO 2017-07-01 16:27:37,817 main.py:52] epoch 499, training loss: 7526.31, average training loss: 9647.12, base loss: 16031.22
[INFO 2017-07-01 16:27:37,817 main.py:54] epoch 499, testing
[INFO 2017-07-01 16:27:50,294 main.py:97] average testing loss: 8449.11, base loss: 16236.89
[INFO 2017-07-01 16:27:50,295 main.py:98] improve_loss: 7787.78, improve_percent: 0.48
[INFO 2017-07-01 16:27:50,296 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 16:27:50,321 main.py:66] current best improved percent: 0.48
[INFO 2017-07-01 16:27:53,195 main.py:52] epoch 500, training loss: 9250.55, average training loss: 9646.33, base loss: 16035.46
[INFO 2017-07-01 16:27:56,067 main.py:52] epoch 501, training loss: 8369.03, average training loss: 9643.78, base loss: 16036.04
[INFO 2017-07-01 16:27:58,943 main.py:52] epoch 502, training loss: 8953.40, average training loss: 9642.41, base loss: 16036.69
[INFO 2017-07-01 16:28:01,794 main.py:52] epoch 503, training loss: 9667.77, average training loss: 9642.46, base loss: 16040.31
[INFO 2017-07-01 16:28:04,623 main.py:52] epoch 504, training loss: 8611.47, average training loss: 9640.42, base loss: 16041.01
[INFO 2017-07-01 16:28:07,483 main.py:52] epoch 505, training loss: 8019.59, average training loss: 9637.22, base loss: 16037.99
[INFO 2017-07-01 16:28:10,306 main.py:52] epoch 506, training loss: 8368.74, average training loss: 9634.71, base loss: 16036.29
[INFO 2017-07-01 16:28:13,199 main.py:52] epoch 507, training loss: 8450.62, average training loss: 9632.38, base loss: 16035.07
[INFO 2017-07-01 16:28:16,115 main.py:52] epoch 508, training loss: 8329.54, average training loss: 9629.82, base loss: 16036.19
[INFO 2017-07-01 16:28:19,024 main.py:52] epoch 509, training loss: 7859.70, average training loss: 9626.35, base loss: 16032.79
[INFO 2017-07-01 16:28:21,893 main.py:52] epoch 510, training loss: 8680.77, average training loss: 9624.50, base loss: 16034.02
[INFO 2017-07-01 16:28:24,779 main.py:52] epoch 511, training loss: 8806.35, average training loss: 9622.90, base loss: 16034.85
[INFO 2017-07-01 16:28:27,941 main.py:52] epoch 512, training loss: 8332.49, average training loss: 9620.39, base loss: 16033.99
[INFO 2017-07-01 16:28:30,821 main.py:52] epoch 513, training loss: 8264.54, average training loss: 9617.75, base loss: 16030.82
[INFO 2017-07-01 16:28:33,715 main.py:52] epoch 514, training loss: 7929.10, average training loss: 9614.47, base loss: 16028.24
[INFO 2017-07-01 16:28:36,583 main.py:52] epoch 515, training loss: 8126.15, average training loss: 9611.59, base loss: 16027.18
[INFO 2017-07-01 16:28:39,455 main.py:52] epoch 516, training loss: 8443.91, average training loss: 9609.33, base loss: 16027.70
[INFO 2017-07-01 16:28:42,379 main.py:52] epoch 517, training loss: 7974.93, average training loss: 9606.17, base loss: 16027.07
[INFO 2017-07-01 16:28:45,302 main.py:52] epoch 518, training loss: 8252.79, average training loss: 9603.57, base loss: 16026.21
[INFO 2017-07-01 16:28:48,154 main.py:52] epoch 519, training loss: 8461.59, average training loss: 9601.37, base loss: 16026.76
[INFO 2017-07-01 16:28:51,059 main.py:52] epoch 520, training loss: 8244.39, average training loss: 9598.76, base loss: 16026.33
[INFO 2017-07-01 16:28:53,983 main.py:52] epoch 521, training loss: 8705.86, average training loss: 9597.05, base loss: 16026.89
[INFO 2017-07-01 16:28:56,826 main.py:52] epoch 522, training loss: 8325.60, average training loss: 9594.62, base loss: 16025.28
[INFO 2017-07-01 16:28:59,693 main.py:52] epoch 523, training loss: 8710.98, average training loss: 9592.94, base loss: 16026.32
[INFO 2017-07-01 16:29:02,556 main.py:52] epoch 524, training loss: 7709.38, average training loss: 9589.35, base loss: 16023.65
[INFO 2017-07-01 16:29:05,405 main.py:52] epoch 525, training loss: 8770.17, average training loss: 9587.79, base loss: 16024.82
[INFO 2017-07-01 16:29:08,261 main.py:52] epoch 526, training loss: 8022.51, average training loss: 9584.82, base loss: 16026.00
[INFO 2017-07-01 16:29:11,134 main.py:52] epoch 527, training loss: 8557.26, average training loss: 9582.88, base loss: 16029.05
[INFO 2017-07-01 16:29:14,029 main.py:52] epoch 528, training loss: 7976.65, average training loss: 9579.84, base loss: 16029.09
[INFO 2017-07-01 16:29:16,928 main.py:52] epoch 529, training loss: 7752.59, average training loss: 9576.39, base loss: 16029.00
[INFO 2017-07-01 16:29:19,817 main.py:52] epoch 530, training loss: 8181.76, average training loss: 9573.76, base loss: 16028.16
[INFO 2017-07-01 16:29:22,684 main.py:52] epoch 531, training loss: 8062.38, average training loss: 9570.92, base loss: 16025.06
[INFO 2017-07-01 16:29:25,579 main.py:52] epoch 532, training loss: 8404.66, average training loss: 9568.74, base loss: 16022.55
[INFO 2017-07-01 16:29:28,447 main.py:52] epoch 533, training loss: 8559.74, average training loss: 9566.85, base loss: 16023.72
[INFO 2017-07-01 16:29:31,310 main.py:52] epoch 534, training loss: 8066.19, average training loss: 9564.04, base loss: 16022.19
[INFO 2017-07-01 16:29:34,179 main.py:52] epoch 535, training loss: 8778.79, average training loss: 9562.58, base loss: 16020.91
[INFO 2017-07-01 16:29:37,099 main.py:52] epoch 536, training loss: 7415.68, average training loss: 9558.58, base loss: 16017.14
[INFO 2017-07-01 16:29:39,965 main.py:52] epoch 537, training loss: 9044.32, average training loss: 9557.62, base loss: 16019.25
[INFO 2017-07-01 16:29:42,836 main.py:52] epoch 538, training loss: 7774.13, average training loss: 9554.31, base loss: 16015.22
[INFO 2017-07-01 16:29:45,672 main.py:52] epoch 539, training loss: 8130.55, average training loss: 9551.68, base loss: 16011.35
[INFO 2017-07-01 16:29:48,542 main.py:52] epoch 540, training loss: 8914.43, average training loss: 9550.50, base loss: 16015.28
[INFO 2017-07-01 16:29:51,431 main.py:52] epoch 541, training loss: 8774.81, average training loss: 9549.07, base loss: 16017.52
[INFO 2017-07-01 16:29:54,311 main.py:52] epoch 542, training loss: 8683.81, average training loss: 9547.47, base loss: 16019.41
[INFO 2017-07-01 16:29:57,184 main.py:52] epoch 543, training loss: 8486.43, average training loss: 9545.52, base loss: 16020.66
[INFO 2017-07-01 16:30:00,028 main.py:52] epoch 544, training loss: 7681.10, average training loss: 9542.10, base loss: 16016.60
[INFO 2017-07-01 16:30:02,884 main.py:52] epoch 545, training loss: 8735.85, average training loss: 9540.63, base loss: 16018.60
[INFO 2017-07-01 16:30:05,761 main.py:52] epoch 546, training loss: 7889.49, average training loss: 9537.61, base loss: 16018.33
[INFO 2017-07-01 16:30:08,642 main.py:52] epoch 547, training loss: 7958.91, average training loss: 9534.73, base loss: 16020.74
[INFO 2017-07-01 16:30:11,492 main.py:52] epoch 548, training loss: 8453.36, average training loss: 9532.76, base loss: 16022.03
[INFO 2017-07-01 16:30:14,378 main.py:52] epoch 549, training loss: 7933.05, average training loss: 9529.85, base loss: 16019.20
[INFO 2017-07-01 16:30:17,256 main.py:52] epoch 550, training loss: 8140.15, average training loss: 9527.33, base loss: 16017.62
[INFO 2017-07-01 16:30:20,095 main.py:52] epoch 551, training loss: 8094.62, average training loss: 9524.73, base loss: 16014.89
[INFO 2017-07-01 16:30:22,945 main.py:52] epoch 552, training loss: 8672.03, average training loss: 9523.19, base loss: 16017.49
[INFO 2017-07-01 16:30:25,794 main.py:52] epoch 553, training loss: 8525.47, average training loss: 9521.39, base loss: 16018.67
[INFO 2017-07-01 16:30:28,675 main.py:52] epoch 554, training loss: 7860.69, average training loss: 9518.40, base loss: 16017.44
[INFO 2017-07-01 16:30:31,549 main.py:52] epoch 555, training loss: 7465.00, average training loss: 9514.70, base loss: 16013.91
[INFO 2017-07-01 16:30:34,393 main.py:52] epoch 556, training loss: 8506.18, average training loss: 9512.89, base loss: 16016.33
[INFO 2017-07-01 16:30:37,248 main.py:52] epoch 557, training loss: 8608.87, average training loss: 9511.27, base loss: 16019.86
[INFO 2017-07-01 16:30:40,126 main.py:52] epoch 558, training loss: 9107.51, average training loss: 9510.55, base loss: 16020.24
[INFO 2017-07-01 16:30:43,040 main.py:52] epoch 559, training loss: 7873.27, average training loss: 9507.63, base loss: 16018.44
[INFO 2017-07-01 16:30:45,961 main.py:52] epoch 560, training loss: 8530.48, average training loss: 9505.88, base loss: 16020.74
[INFO 2017-07-01 16:30:48,840 main.py:52] epoch 561, training loss: 7869.29, average training loss: 9502.97, base loss: 16020.91
[INFO 2017-07-01 16:30:51,708 main.py:52] epoch 562, training loss: 7854.32, average training loss: 9500.04, base loss: 16017.65
[INFO 2017-07-01 16:30:54,583 main.py:52] epoch 563, training loss: 7580.33, average training loss: 9496.64, base loss: 16014.87
[INFO 2017-07-01 16:30:57,470 main.py:52] epoch 564, training loss: 8458.04, average training loss: 9494.80, base loss: 16014.55
[INFO 2017-07-01 16:31:00,403 main.py:52] epoch 565, training loss: 8735.88, average training loss: 9493.46, base loss: 16015.17
[INFO 2017-07-01 16:31:03,293 main.py:52] epoch 566, training loss: 8698.89, average training loss: 9492.06, base loss: 16017.80
[INFO 2017-07-01 16:31:06,149 main.py:52] epoch 567, training loss: 8378.74, average training loss: 9490.10, base loss: 16017.54
[INFO 2017-07-01 16:31:09,059 main.py:52] epoch 568, training loss: 7626.31, average training loss: 9486.82, base loss: 16013.23
[INFO 2017-07-01 16:31:11,957 main.py:52] epoch 569, training loss: 8627.79, average training loss: 9485.32, base loss: 16015.12
[INFO 2017-07-01 16:31:14,873 main.py:52] epoch 570, training loss: 8328.11, average training loss: 9483.29, base loss: 16015.51
[INFO 2017-07-01 16:31:17,734 main.py:52] epoch 571, training loss: 7245.69, average training loss: 9479.38, base loss: 16011.64
[INFO 2017-07-01 16:31:20,599 main.py:52] epoch 572, training loss: 8129.49, average training loss: 9477.02, base loss: 16010.15
[INFO 2017-07-01 16:31:23,494 main.py:52] epoch 573, training loss: 8848.72, average training loss: 9475.93, base loss: 16011.56
[INFO 2017-07-01 16:31:26,368 main.py:52] epoch 574, training loss: 9104.87, average training loss: 9475.28, base loss: 16014.26
[INFO 2017-07-01 16:31:29,296 main.py:52] epoch 575, training loss: 8297.24, average training loss: 9473.24, base loss: 16014.29
[INFO 2017-07-01 16:31:32,182 main.py:52] epoch 576, training loss: 8430.56, average training loss: 9471.43, base loss: 16015.93
[INFO 2017-07-01 16:31:35,061 main.py:52] epoch 577, training loss: 8283.79, average training loss: 9469.38, base loss: 16015.08
[INFO 2017-07-01 16:31:37,936 main.py:52] epoch 578, training loss: 7595.97, average training loss: 9466.14, base loss: 16012.45
[INFO 2017-07-01 16:31:40,818 main.py:52] epoch 579, training loss: 8107.05, average training loss: 9463.80, base loss: 16012.98
[INFO 2017-07-01 16:31:43,732 main.py:52] epoch 580, training loss: 7890.86, average training loss: 9461.09, base loss: 16011.96
[INFO 2017-07-01 16:31:46,559 main.py:52] epoch 581, training loss: 8312.34, average training loss: 9459.12, base loss: 16013.25
[INFO 2017-07-01 16:31:49,415 main.py:52] epoch 582, training loss: 8123.76, average training loss: 9456.83, base loss: 16014.04
[INFO 2017-07-01 16:31:52,333 main.py:52] epoch 583, training loss: 8178.74, average training loss: 9454.64, base loss: 16015.62
[INFO 2017-07-01 16:31:55,203 main.py:52] epoch 584, training loss: 7493.26, average training loss: 9451.28, base loss: 16012.32
[INFO 2017-07-01 16:31:58,085 main.py:52] epoch 585, training loss: 9424.48, average training loss: 9451.24, base loss: 16014.61
[INFO 2017-07-01 16:32:00,986 main.py:52] epoch 586, training loss: 8089.93, average training loss: 9448.92, base loss: 16013.73
[INFO 2017-07-01 16:32:03,825 main.py:52] epoch 587, training loss: 7792.67, average training loss: 9446.10, base loss: 16011.49
[INFO 2017-07-01 16:32:06,729 main.py:52] epoch 588, training loss: 8359.07, average training loss: 9444.26, base loss: 16012.74
[INFO 2017-07-01 16:32:09,586 main.py:52] epoch 589, training loss: 8449.47, average training loss: 9442.57, base loss: 16014.73
[INFO 2017-07-01 16:32:12,472 main.py:52] epoch 590, training loss: 8135.00, average training loss: 9440.36, base loss: 16016.16
[INFO 2017-07-01 16:32:15,315 main.py:52] epoch 591, training loss: 8163.29, average training loss: 9438.20, base loss: 16018.36
[INFO 2017-07-01 16:32:18,180 main.py:52] epoch 592, training loss: 7811.62, average training loss: 9435.46, base loss: 16016.36
[INFO 2017-07-01 16:32:21,054 main.py:52] epoch 593, training loss: 8309.18, average training loss: 9433.56, base loss: 16017.69
[INFO 2017-07-01 16:32:23,914 main.py:52] epoch 594, training loss: 8130.76, average training loss: 9431.37, base loss: 16015.93
[INFO 2017-07-01 16:32:26,779 main.py:52] epoch 595, training loss: 8381.28, average training loss: 9429.61, base loss: 16015.53
[INFO 2017-07-01 16:32:29,667 main.py:52] epoch 596, training loss: 8521.32, average training loss: 9428.09, base loss: 16015.84
[INFO 2017-07-01 16:32:32,502 main.py:52] epoch 597, training loss: 9493.20, average training loss: 9428.20, base loss: 16020.99
[INFO 2017-07-01 16:32:35,401 main.py:52] epoch 598, training loss: 7430.07, average training loss: 9424.86, base loss: 16019.82
[INFO 2017-07-01 16:32:38,291 main.py:52] epoch 599, training loss: 8181.07, average training loss: 9422.79, base loss: 16022.01
[INFO 2017-07-01 16:32:38,292 main.py:54] epoch 599, testing
[INFO 2017-07-01 16:32:50,508 main.py:97] average testing loss: 8286.59, base loss: 16197.18
[INFO 2017-07-01 16:32:50,508 main.py:98] improve_loss: 7910.59, improve_percent: 0.49
[INFO 2017-07-01 16:32:50,509 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 16:32:50,534 main.py:66] current best improved percent: 0.49
[INFO 2017-07-01 16:32:53,421 main.py:52] epoch 600, training loss: 8307.52, average training loss: 9420.93, base loss: 16021.55
[INFO 2017-07-01 16:32:56,326 main.py:52] epoch 601, training loss: 8234.57, average training loss: 9418.96, base loss: 16021.23
[INFO 2017-07-01 16:32:59,165 main.py:52] epoch 602, training loss: 7930.38, average training loss: 9416.49, base loss: 16017.82
[INFO 2017-07-01 16:33:02,100 main.py:52] epoch 603, training loss: 8411.42, average training loss: 9414.83, base loss: 16016.78
[INFO 2017-07-01 16:33:04,966 main.py:52] epoch 604, training loss: 7159.14, average training loss: 9411.10, base loss: 16012.01
[INFO 2017-07-01 16:33:07,836 main.py:52] epoch 605, training loss: 7645.39, average training loss: 9408.19, base loss: 16008.57
[INFO 2017-07-01 16:33:10,734 main.py:52] epoch 606, training loss: 8331.33, average training loss: 9406.41, base loss: 16007.51
[INFO 2017-07-01 16:33:13,640 main.py:52] epoch 607, training loss: 8628.47, average training loss: 9405.13, base loss: 16006.51
[INFO 2017-07-01 16:33:16,593 main.py:52] epoch 608, training loss: 7610.46, average training loss: 9402.19, base loss: 16005.06
[INFO 2017-07-01 16:33:19,508 main.py:52] epoch 609, training loss: 8117.17, average training loss: 9400.08, base loss: 16003.73
[INFO 2017-07-01 16:33:22,370 main.py:52] epoch 610, training loss: 7275.66, average training loss: 9396.60, base loss: 16000.34
[INFO 2017-07-01 16:33:25,242 main.py:52] epoch 611, training loss: 8803.55, average training loss: 9395.63, base loss: 16004.56
[INFO 2017-07-01 16:33:28,129 main.py:52] epoch 612, training loss: 7633.17, average training loss: 9392.76, base loss: 16000.57
[INFO 2017-07-01 16:33:31,001 main.py:52] epoch 613, training loss: 8415.99, average training loss: 9391.17, base loss: 15999.55
[INFO 2017-07-01 16:33:33,853 main.py:52] epoch 614, training loss: 7661.36, average training loss: 9388.36, base loss: 15998.10
[INFO 2017-07-01 16:33:36,762 main.py:52] epoch 615, training loss: 7848.86, average training loss: 9385.86, base loss: 15996.35
[INFO 2017-07-01 16:33:39,963 main.py:52] epoch 616, training loss: 7878.31, average training loss: 9383.41, base loss: 15993.22
[INFO 2017-07-01 16:33:42,828 main.py:52] epoch 617, training loss: 8162.73, average training loss: 9381.44, base loss: 15993.00
[INFO 2017-07-01 16:33:45,678 main.py:52] epoch 618, training loss: 9264.97, average training loss: 9381.25, base loss: 15997.44
[INFO 2017-07-01 16:33:48,587 main.py:52] epoch 619, training loss: 8448.80, average training loss: 9379.75, base loss: 15998.15
[INFO 2017-07-01 16:33:51,446 main.py:52] epoch 620, training loss: 7268.60, average training loss: 9376.35, base loss: 15992.62
[INFO 2017-07-01 16:33:54,286 main.py:52] epoch 621, training loss: 7686.45, average training loss: 9373.63, base loss: 15991.49
[INFO 2017-07-01 16:33:57,179 main.py:52] epoch 622, training loss: 8168.10, average training loss: 9371.69, base loss: 15992.62
[INFO 2017-07-01 16:34:00,044 main.py:52] epoch 623, training loss: 7535.36, average training loss: 9368.75, base loss: 15987.45
[INFO 2017-07-01 16:34:02,943 main.py:52] epoch 624, training loss: 7866.91, average training loss: 9366.35, base loss: 15987.22
[INFO 2017-07-01 16:34:05,808 main.py:52] epoch 625, training loss: 8733.37, average training loss: 9365.34, base loss: 15989.24
[INFO 2017-07-01 16:34:08,681 main.py:52] epoch 626, training loss: 8138.11, average training loss: 9363.38, base loss: 15989.09
[INFO 2017-07-01 16:34:11,556 main.py:52] epoch 627, training loss: 8389.24, average training loss: 9361.83, base loss: 15990.27
[INFO 2017-07-01 16:34:14,450 main.py:52] epoch 628, training loss: 8432.08, average training loss: 9360.35, base loss: 15991.05
[INFO 2017-07-01 16:34:17,336 main.py:52] epoch 629, training loss: 8227.55, average training loss: 9358.55, base loss: 15990.01
[INFO 2017-07-01 16:34:20,165 main.py:52] epoch 630, training loss: 8376.54, average training loss: 9357.00, base loss: 15988.99
[INFO 2017-07-01 16:34:23,045 main.py:52] epoch 631, training loss: 8429.79, average training loss: 9355.53, base loss: 15989.23
[INFO 2017-07-01 16:34:25,885 main.py:52] epoch 632, training loss: 8929.84, average training loss: 9354.86, base loss: 15991.20
[INFO 2017-07-01 16:34:28,777 main.py:52] epoch 633, training loss: 8107.17, average training loss: 9352.89, base loss: 15990.30
[INFO 2017-07-01 16:34:31,966 main.py:52] epoch 634, training loss: 7585.72, average training loss: 9350.11, base loss: 15988.51
[INFO 2017-07-01 16:34:34,921 main.py:52] epoch 635, training loss: 7718.16, average training loss: 9347.54, base loss: 15985.70
[INFO 2017-07-01 16:34:37,748 main.py:52] epoch 636, training loss: 8228.85, average training loss: 9345.78, base loss: 15986.38
[INFO 2017-07-01 16:34:40,627 main.py:52] epoch 637, training loss: 9149.97, average training loss: 9345.48, base loss: 15992.41
[INFO 2017-07-01 16:34:43,491 main.py:52] epoch 638, training loss: 7923.96, average training loss: 9343.25, base loss: 15994.64
[INFO 2017-07-01 16:34:46,350 main.py:52] epoch 639, training loss: 7836.01, average training loss: 9340.90, base loss: 15997.14
[INFO 2017-07-01 16:34:49,247 main.py:52] epoch 640, training loss: 7812.12, average training loss: 9338.51, base loss: 15996.34
[INFO 2017-07-01 16:34:52,129 main.py:52] epoch 641, training loss: 8639.57, average training loss: 9337.42, base loss: 15998.38
[INFO 2017-07-01 16:34:55,049 main.py:52] epoch 642, training loss: 7548.92, average training loss: 9334.64, base loss: 15995.47
[INFO 2017-07-01 16:34:57,971 main.py:52] epoch 643, training loss: 8060.14, average training loss: 9332.66, base loss: 15995.02
[INFO 2017-07-01 16:35:00,838 main.py:52] epoch 644, training loss: 8411.27, average training loss: 9331.24, base loss: 15996.72
[INFO 2017-07-01 16:35:03,675 main.py:52] epoch 645, training loss: 7942.48, average training loss: 9329.09, base loss: 15996.88
[INFO 2017-07-01 16:35:06,583 main.py:52] epoch 646, training loss: 8374.05, average training loss: 9327.61, base loss: 15999.95
[INFO 2017-07-01 16:35:09,449 main.py:52] epoch 647, training loss: 7744.11, average training loss: 9325.17, base loss: 16000.02
[INFO 2017-07-01 16:35:12,370 main.py:52] epoch 648, training loss: 8215.13, average training loss: 9323.46, base loss: 16001.19
[INFO 2017-07-01 16:35:15,278 main.py:52] epoch 649, training loss: 7604.99, average training loss: 9320.81, base loss: 15998.63
[INFO 2017-07-01 16:35:18,204 main.py:52] epoch 650, training loss: 8078.18, average training loss: 9318.90, base loss: 15996.54
[INFO 2017-07-01 16:35:21,424 main.py:52] epoch 651, training loss: 8080.66, average training loss: 9317.00, base loss: 15994.50
[INFO 2017-07-01 16:35:24,390 main.py:52] epoch 652, training loss: 8569.74, average training loss: 9315.86, base loss: 15996.27
[INFO 2017-07-01 16:35:27,263 main.py:52] epoch 653, training loss: 8142.58, average training loss: 9314.07, base loss: 15995.41
[INFO 2017-07-01 16:35:30,148 main.py:52] epoch 654, training loss: 8526.92, average training loss: 9312.86, base loss: 15998.86
[INFO 2017-07-01 16:35:33,011 main.py:52] epoch 655, training loss: 7822.85, average training loss: 9310.59, base loss: 15997.07
[INFO 2017-07-01 16:35:35,876 main.py:52] epoch 656, training loss: 7506.63, average training loss: 9307.85, base loss: 15993.71
[INFO 2017-07-01 16:35:38,775 main.py:52] epoch 657, training loss: 8446.32, average training loss: 9306.54, base loss: 15994.24
[INFO 2017-07-01 16:35:41,643 main.py:52] epoch 658, training loss: 7963.88, average training loss: 9304.50, base loss: 15993.86
[INFO 2017-07-01 16:35:44,563 main.py:52] epoch 659, training loss: 7836.72, average training loss: 9302.28, base loss: 15991.35
[INFO 2017-07-01 16:35:47,416 main.py:52] epoch 660, training loss: 8061.81, average training loss: 9300.40, base loss: 15992.32
[INFO 2017-07-01 16:35:50,300 main.py:52] epoch 661, training loss: 8625.53, average training loss: 9299.38, base loss: 15996.86
[INFO 2017-07-01 16:35:53,134 main.py:52] epoch 662, training loss: 7807.82, average training loss: 9297.13, base loss: 15997.39
[INFO 2017-07-01 16:35:56,008 main.py:52] epoch 663, training loss: 7877.55, average training loss: 9294.99, base loss: 15997.30
[INFO 2017-07-01 16:35:58,867 main.py:52] epoch 664, training loss: 8053.99, average training loss: 9293.13, base loss: 15995.74
[INFO 2017-07-01 16:36:01,779 main.py:52] epoch 665, training loss: 8099.48, average training loss: 9291.33, base loss: 15995.35
[INFO 2017-07-01 16:36:04,638 main.py:52] epoch 666, training loss: 8358.85, average training loss: 9289.94, base loss: 15997.00
[INFO 2017-07-01 16:36:07,497 main.py:52] epoch 667, training loss: 8126.71, average training loss: 9288.19, base loss: 15998.15
[INFO 2017-07-01 16:36:10,398 main.py:52] epoch 668, training loss: 8037.82, average training loss: 9286.32, base loss: 15996.24
[INFO 2017-07-01 16:36:13,278 main.py:52] epoch 669, training loss: 8627.41, average training loss: 9285.34, base loss: 15996.98
[INFO 2017-07-01 16:36:16,185 main.py:52] epoch 670, training loss: 7913.85, average training loss: 9283.30, base loss: 15996.57
[INFO 2017-07-01 16:36:19,062 main.py:52] epoch 671, training loss: 8559.46, average training loss: 9282.22, base loss: 15997.37
[INFO 2017-07-01 16:36:21,944 main.py:52] epoch 672, training loss: 8230.81, average training loss: 9280.66, base loss: 15996.85
[INFO 2017-07-01 16:36:24,831 main.py:52] epoch 673, training loss: 8530.45, average training loss: 9279.55, base loss: 15998.01
[INFO 2017-07-01 16:36:27,703 main.py:52] epoch 674, training loss: 7819.14, average training loss: 9277.38, base loss: 15994.84
[INFO 2017-07-01 16:36:30,585 main.py:52] epoch 675, training loss: 7452.12, average training loss: 9274.68, base loss: 15989.79
[INFO 2017-07-01 16:36:33,452 main.py:52] epoch 676, training loss: 8012.13, average training loss: 9272.82, base loss: 15987.84
[INFO 2017-07-01 16:36:36,345 main.py:52] epoch 677, training loss: 8488.74, average training loss: 9271.66, base loss: 15988.74
[INFO 2017-07-01 16:36:39,225 main.py:52] epoch 678, training loss: 8551.90, average training loss: 9270.60, base loss: 15989.18
[INFO 2017-07-01 16:36:42,105 main.py:52] epoch 679, training loss: 7826.61, average training loss: 9268.48, base loss: 15985.96
[INFO 2017-07-01 16:36:45,047 main.py:52] epoch 680, training loss: 7833.55, average training loss: 9266.37, base loss: 15984.15
[INFO 2017-07-01 16:36:47,898 main.py:52] epoch 681, training loss: 7532.13, average training loss: 9263.83, base loss: 15981.86
[INFO 2017-07-01 16:36:50,748 main.py:52] epoch 682, training loss: 8133.71, average training loss: 9262.17, base loss: 15983.30
[INFO 2017-07-01 16:36:53,666 main.py:52] epoch 683, training loss: 8312.48, average training loss: 9260.78, base loss: 15983.02
[INFO 2017-07-01 16:36:56,544 main.py:52] epoch 684, training loss: 8403.77, average training loss: 9259.53, base loss: 15984.45
[INFO 2017-07-01 16:36:59,418 main.py:52] epoch 685, training loss: 8716.92, average training loss: 9258.74, base loss: 15988.25
[INFO 2017-07-01 16:37:02,349 main.py:52] epoch 686, training loss: 7158.59, average training loss: 9255.68, base loss: 15983.41
[INFO 2017-07-01 16:37:05,266 main.py:52] epoch 687, training loss: 8713.56, average training loss: 9254.90, base loss: 15984.52
[INFO 2017-07-01 16:37:08,187 main.py:52] epoch 688, training loss: 8287.20, average training loss: 9253.49, base loss: 15984.70
[INFO 2017-07-01 16:37:11,057 main.py:52] epoch 689, training loss: 8951.60, average training loss: 9253.05, base loss: 15986.27
[INFO 2017-07-01 16:37:13,940 main.py:52] epoch 690, training loss: 8357.86, average training loss: 9251.76, base loss: 15986.50
[INFO 2017-07-01 16:37:16,781 main.py:52] epoch 691, training loss: 7651.20, average training loss: 9249.45, base loss: 15984.95
[INFO 2017-07-01 16:37:19,645 main.py:52] epoch 692, training loss: 7509.01, average training loss: 9246.93, base loss: 15984.75
[INFO 2017-07-01 16:37:22,507 main.py:52] epoch 693, training loss: 8363.00, average training loss: 9245.66, base loss: 15987.71
[INFO 2017-07-01 16:37:25,370 main.py:52] epoch 694, training loss: 8137.03, average training loss: 9244.07, base loss: 15987.20
[INFO 2017-07-01 16:37:28,214 main.py:52] epoch 695, training loss: 7872.54, average training loss: 9242.10, base loss: 15985.05
[INFO 2017-07-01 16:37:31,117 main.py:52] epoch 696, training loss: 7828.83, average training loss: 9240.07, base loss: 15980.63
[INFO 2017-07-01 16:37:33,990 main.py:52] epoch 697, training loss: 8304.00, average training loss: 9238.73, base loss: 15979.61
[INFO 2017-07-01 16:37:36,931 main.py:52] epoch 698, training loss: 7024.56, average training loss: 9235.56, base loss: 15973.62
[INFO 2017-07-01 16:37:39,856 main.py:52] epoch 699, training loss: 8799.03, average training loss: 9234.94, base loss: 15974.88
[INFO 2017-07-01 16:37:39,857 main.py:54] epoch 699, testing
[INFO 2017-07-01 16:37:52,092 main.py:97] average testing loss: 8457.71, base loss: 16265.39
[INFO 2017-07-01 16:37:52,092 main.py:98] improve_loss: 7807.68, improve_percent: 0.48
[INFO 2017-07-01 16:37:52,093 main.py:66] current best improved percent: 0.49
[INFO 2017-07-01 16:37:54,964 main.py:52] epoch 700, training loss: 8330.13, average training loss: 9233.64, base loss: 15975.49
[INFO 2017-07-01 16:37:57,863 main.py:52] epoch 701, training loss: 7931.42, average training loss: 9231.79, base loss: 15974.65
[INFO 2017-07-01 16:38:00,736 main.py:52] epoch 702, training loss: 8103.21, average training loss: 9230.18, base loss: 15972.67
[INFO 2017-07-01 16:38:03,628 main.py:52] epoch 703, training loss: 8447.30, average training loss: 9229.07, base loss: 15973.54
[INFO 2017-07-01 16:38:06,562 main.py:52] epoch 704, training loss: 8519.89, average training loss: 9228.07, base loss: 15974.38
[INFO 2017-07-01 16:38:09,391 main.py:52] epoch 705, training loss: 8445.43, average training loss: 9226.96, base loss: 15972.82
[INFO 2017-07-01 16:38:12,282 main.py:52] epoch 706, training loss: 7909.73, average training loss: 9225.09, base loss: 15970.30
[INFO 2017-07-01 16:38:15,180 main.py:52] epoch 707, training loss: 7712.28, average training loss: 9222.96, base loss: 15967.24
[INFO 2017-07-01 16:38:18,088 main.py:52] epoch 708, training loss: 7958.02, average training loss: 9221.17, base loss: 15967.05
[INFO 2017-07-01 16:38:20,941 main.py:52] epoch 709, training loss: 9084.46, average training loss: 9220.98, base loss: 15970.69
[INFO 2017-07-01 16:38:23,838 main.py:52] epoch 710, training loss: 8118.27, average training loss: 9219.43, base loss: 15972.05
[INFO 2017-07-01 16:38:26,729 main.py:52] epoch 711, training loss: 7786.07, average training loss: 9217.42, base loss: 15972.48
[INFO 2017-07-01 16:38:29,609 main.py:52] epoch 712, training loss: 8334.60, average training loss: 9216.18, base loss: 15972.34
[INFO 2017-07-01 16:38:32,501 main.py:52] epoch 713, training loss: 8074.45, average training loss: 9214.58, base loss: 15972.56
[INFO 2017-07-01 16:38:35,378 main.py:52] epoch 714, training loss: 7237.33, average training loss: 9211.81, base loss: 15969.17
[INFO 2017-07-01 16:38:38,250 main.py:52] epoch 715, training loss: 8067.24, average training loss: 9210.22, base loss: 15967.88
[INFO 2017-07-01 16:38:41,144 main.py:52] epoch 716, training loss: 8122.38, average training loss: 9208.70, base loss: 15967.92
[INFO 2017-07-01 16:38:44,035 main.py:52] epoch 717, training loss: 7947.78, average training loss: 9206.94, base loss: 15968.09
[INFO 2017-07-01 16:38:46,866 main.py:52] epoch 718, training loss: 7720.63, average training loss: 9204.88, base loss: 15965.22
[INFO 2017-07-01 16:38:49,719 main.py:52] epoch 719, training loss: 7461.10, average training loss: 9202.45, base loss: 15962.64
[INFO 2017-07-01 16:38:52,587 main.py:52] epoch 720, training loss: 8154.21, average training loss: 9201.00, base loss: 15961.93
[INFO 2017-07-01 16:38:55,482 main.py:52] epoch 721, training loss: 8043.60, average training loss: 9199.40, base loss: 15961.91
[INFO 2017-07-01 16:38:58,358 main.py:52] epoch 722, training loss: 8192.30, average training loss: 9198.00, base loss: 15962.59
[INFO 2017-07-01 16:39:01,231 main.py:52] epoch 723, training loss: 8302.66, average training loss: 9196.77, base loss: 15963.84
[INFO 2017-07-01 16:39:04,114 main.py:52] epoch 724, training loss: 7648.86, average training loss: 9194.63, base loss: 15962.79
[INFO 2017-07-01 16:39:07,009 main.py:52] epoch 725, training loss: 7625.98, average training loss: 9192.47, base loss: 15962.77
[INFO 2017-07-01 16:39:09,909 main.py:52] epoch 726, training loss: 8369.15, average training loss: 9191.34, base loss: 15966.37
[INFO 2017-07-01 16:39:12,797 main.py:52] epoch 727, training loss: 8407.99, average training loss: 9190.26, base loss: 15968.40
[INFO 2017-07-01 16:39:15,647 main.py:52] epoch 728, training loss: 7929.07, average training loss: 9188.53, base loss: 15967.99
[INFO 2017-07-01 16:39:18,551 main.py:52] epoch 729, training loss: 7470.22, average training loss: 9186.18, base loss: 15965.68
[INFO 2017-07-01 16:39:21,448 main.py:52] epoch 730, training loss: 7650.63, average training loss: 9184.08, base loss: 15964.22
[INFO 2017-07-01 16:39:24,296 main.py:52] epoch 731, training loss: 7360.65, average training loss: 9181.59, base loss: 15961.94
[INFO 2017-07-01 16:39:27,129 main.py:52] epoch 732, training loss: 8261.59, average training loss: 9180.33, base loss: 15962.93
[INFO 2017-07-01 16:39:30,008 main.py:52] epoch 733, training loss: 7844.73, average training loss: 9178.51, base loss: 15961.73
[INFO 2017-07-01 16:39:32,880 main.py:52] epoch 734, training loss: 8136.35, average training loss: 9177.09, base loss: 15959.39
[INFO 2017-07-01 16:39:35,788 main.py:52] epoch 735, training loss: 8066.81, average training loss: 9175.59, base loss: 15956.46
[INFO 2017-07-01 16:39:38,658 main.py:52] epoch 736, training loss: 7766.83, average training loss: 9173.67, base loss: 15955.50
[INFO 2017-07-01 16:39:41,539 main.py:52] epoch 737, training loss: 8062.22, average training loss: 9172.17, base loss: 15955.90
[INFO 2017-07-01 16:39:44,442 main.py:52] epoch 738, training loss: 7896.79, average training loss: 9170.44, base loss: 15956.79
[INFO 2017-07-01 16:39:47,350 main.py:52] epoch 739, training loss: 7708.86, average training loss: 9168.47, base loss: 15956.59
[INFO 2017-07-01 16:39:50,252 main.py:52] epoch 740, training loss: 8625.95, average training loss: 9167.74, base loss: 15957.64
[INFO 2017-07-01 16:39:53,091 main.py:52] epoch 741, training loss: 7688.34, average training loss: 9165.74, base loss: 15955.41
[INFO 2017-07-01 16:39:55,990 main.py:52] epoch 742, training loss: 7713.22, average training loss: 9163.79, base loss: 15951.84
[INFO 2017-07-01 16:39:58,923 main.py:52] epoch 743, training loss: 8483.91, average training loss: 9162.87, base loss: 15954.90
[INFO 2017-07-01 16:40:01,774 main.py:52] epoch 744, training loss: 7885.69, average training loss: 9161.16, base loss: 15953.82
[INFO 2017-07-01 16:40:04,689 main.py:52] epoch 745, training loss: 7772.19, average training loss: 9159.30, base loss: 15952.97
[INFO 2017-07-01 16:40:07,571 main.py:52] epoch 746, training loss: 8054.75, average training loss: 9157.82, base loss: 15952.90
[INFO 2017-07-01 16:40:10,463 main.py:52] epoch 747, training loss: 7576.78, average training loss: 9155.70, base loss: 15951.94
[INFO 2017-07-01 16:40:13,340 main.py:52] epoch 748, training loss: 8495.07, average training loss: 9154.82, base loss: 15952.24
[INFO 2017-07-01 16:40:16,267 main.py:52] epoch 749, training loss: 7386.33, average training loss: 9152.46, base loss: 15948.87
[INFO 2017-07-01 16:40:19,152 main.py:52] epoch 750, training loss: 7661.21, average training loss: 9150.48, base loss: 15946.92
[INFO 2017-07-01 16:40:22,039 main.py:52] epoch 751, training loss: 7527.00, average training loss: 9148.32, base loss: 15945.00
[INFO 2017-07-01 16:40:24,887 main.py:52] epoch 752, training loss: 7096.67, average training loss: 9145.59, base loss: 15939.92
[INFO 2017-07-01 16:40:27,779 main.py:52] epoch 753, training loss: 7386.03, average training loss: 9143.26, base loss: 15936.15
[INFO 2017-07-01 16:40:30,629 main.py:52] epoch 754, training loss: 8549.22, average training loss: 9142.47, base loss: 15936.72
[INFO 2017-07-01 16:40:33,498 main.py:52] epoch 755, training loss: 8479.01, average training loss: 9141.60, base loss: 15937.19
[INFO 2017-07-01 16:40:36,393 main.py:52] epoch 756, training loss: 7787.83, average training loss: 9139.81, base loss: 15937.82
[INFO 2017-07-01 16:40:39,259 main.py:52] epoch 757, training loss: 8293.03, average training loss: 9138.69, base loss: 15938.27
[INFO 2017-07-01 16:40:42,127 main.py:52] epoch 758, training loss: 7418.84, average training loss: 9136.43, base loss: 15937.59
[INFO 2017-07-01 16:40:45,013 main.py:52] epoch 759, training loss: 8147.74, average training loss: 9135.12, base loss: 15940.38
[INFO 2017-07-01 16:40:47,877 main.py:52] epoch 760, training loss: 7871.73, average training loss: 9133.46, base loss: 15941.20
[INFO 2017-07-01 16:40:50,765 main.py:52] epoch 761, training loss: 7395.52, average training loss: 9131.18, base loss: 15939.18
[INFO 2017-07-01 16:40:53,609 main.py:52] epoch 762, training loss: 8339.38, average training loss: 9130.15, base loss: 15938.59
[INFO 2017-07-01 16:40:56,499 main.py:52] epoch 763, training loss: 8291.14, average training loss: 9129.05, base loss: 15939.53
[INFO 2017-07-01 16:40:59,372 main.py:52] epoch 764, training loss: 7655.63, average training loss: 9127.12, base loss: 15939.18
[INFO 2017-07-01 16:41:02,247 main.py:52] epoch 765, training loss: 7702.80, average training loss: 9125.26, base loss: 15938.90
[INFO 2017-07-01 16:41:05,110 main.py:52] epoch 766, training loss: 7521.18, average training loss: 9123.17, base loss: 15937.92
[INFO 2017-07-01 16:41:08,018 main.py:52] epoch 767, training loss: 7911.27, average training loss: 9121.59, base loss: 15939.74
[INFO 2017-07-01 16:41:10,924 main.py:52] epoch 768, training loss: 8257.33, average training loss: 9120.47, base loss: 15941.46
[INFO 2017-07-01 16:41:13,788 main.py:52] epoch 769, training loss: 9016.67, average training loss: 9120.33, base loss: 15945.13
[INFO 2017-07-01 16:41:16,652 main.py:52] epoch 770, training loss: 7793.70, average training loss: 9118.61, base loss: 15942.60
[INFO 2017-07-01 16:41:19,520 main.py:52] epoch 771, training loss: 7809.25, average training loss: 9116.92, base loss: 15940.18
[INFO 2017-07-01 16:41:22,431 main.py:52] epoch 772, training loss: 8290.30, average training loss: 9115.85, base loss: 15940.28
[INFO 2017-07-01 16:41:25,324 main.py:52] epoch 773, training loss: 8068.92, average training loss: 9114.50, base loss: 15939.76
[INFO 2017-07-01 16:41:28,232 main.py:52] epoch 774, training loss: 8218.68, average training loss: 9113.34, base loss: 15939.26
[INFO 2017-07-01 16:41:31,134 main.py:52] epoch 775, training loss: 8436.07, average training loss: 9112.47, base loss: 15941.50
[INFO 2017-07-01 16:41:34,066 main.py:52] epoch 776, training loss: 7604.39, average training loss: 9110.53, base loss: 15940.11
[INFO 2017-07-01 16:41:36,938 main.py:52] epoch 777, training loss: 8013.99, average training loss: 9109.12, base loss: 15940.19
[INFO 2017-07-01 16:41:39,855 main.py:52] epoch 778, training loss: 8073.04, average training loss: 9107.79, base loss: 15941.70
[INFO 2017-07-01 16:41:42,745 main.py:52] epoch 779, training loss: 7780.60, average training loss: 9106.08, base loss: 15941.68
[INFO 2017-07-01 16:41:45,643 main.py:52] epoch 780, training loss: 8645.65, average training loss: 9105.50, base loss: 15943.96
[INFO 2017-07-01 16:41:48,495 main.py:52] epoch 781, training loss: 8113.27, average training loss: 9104.23, base loss: 15946.46
[INFO 2017-07-01 16:41:51,424 main.py:52] epoch 782, training loss: 7701.61, average training loss: 9102.44, base loss: 15944.94
[INFO 2017-07-01 16:41:54,285 main.py:52] epoch 783, training loss: 7627.92, average training loss: 9100.55, base loss: 15944.86
[INFO 2017-07-01 16:41:57,154 main.py:52] epoch 784, training loss: 7993.05, average training loss: 9099.14, base loss: 15945.03
[INFO 2017-07-01 16:42:00,055 main.py:52] epoch 785, training loss: 8344.50, average training loss: 9098.18, base loss: 15946.79
[INFO 2017-07-01 16:42:02,915 main.py:52] epoch 786, training loss: 7463.97, average training loss: 9096.11, base loss: 15946.08
[INFO 2017-07-01 16:42:05,787 main.py:52] epoch 787, training loss: 7895.69, average training loss: 9094.58, base loss: 15944.96
[INFO 2017-07-01 16:42:08,659 main.py:52] epoch 788, training loss: 8287.47, average training loss: 9093.56, base loss: 15947.75
[INFO 2017-07-01 16:42:11,541 main.py:52] epoch 789, training loss: 8210.07, average training loss: 9092.44, base loss: 15950.14
[INFO 2017-07-01 16:42:14,375 main.py:52] epoch 790, training loss: 7954.99, average training loss: 9091.00, base loss: 15950.22
[INFO 2017-07-01 16:42:17,254 main.py:52] epoch 791, training loss: 7789.05, average training loss: 9089.36, base loss: 15948.70
[INFO 2017-07-01 16:42:20,186 main.py:52] epoch 792, training loss: 8514.22, average training loss: 9088.64, base loss: 15949.45
[INFO 2017-07-01 16:42:23,056 main.py:52] epoch 793, training loss: 8126.97, average training loss: 9087.42, base loss: 15949.36
[INFO 2017-07-01 16:42:25,916 main.py:52] epoch 794, training loss: 8235.17, average training loss: 9086.35, base loss: 15949.43
[INFO 2017-07-01 16:42:28,815 main.py:52] epoch 795, training loss: 8093.11, average training loss: 9085.10, base loss: 15948.47
[INFO 2017-07-01 16:42:31,675 main.py:52] epoch 796, training loss: 7757.35, average training loss: 9083.44, base loss: 15949.46
[INFO 2017-07-01 16:42:34,522 main.py:52] epoch 797, training loss: 7951.51, average training loss: 9082.02, base loss: 15948.91
[INFO 2017-07-01 16:42:37,366 main.py:52] epoch 798, training loss: 8266.56, average training loss: 9081.00, base loss: 15949.13
[INFO 2017-07-01 16:42:40,232 main.py:52] epoch 799, training loss: 8243.30, average training loss: 9079.95, base loss: 15948.67
[INFO 2017-07-01 16:42:40,232 main.py:54] epoch 799, testing
[INFO 2017-07-01 16:42:52,506 main.py:97] average testing loss: 7959.24, base loss: 15816.93
[INFO 2017-07-01 16:42:52,506 main.py:98] improve_loss: 7857.69, improve_percent: 0.50
[INFO 2017-07-01 16:42:52,508 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 16:42:52,533 main.py:66] current best improved percent: 0.50
[INFO 2017-07-01 16:42:55,457 main.py:52] epoch 800, training loss: 8300.25, average training loss: 9078.98, base loss: 15949.76
[INFO 2017-07-01 16:42:58,373 main.py:52] epoch 801, training loss: 8324.42, average training loss: 9078.04, base loss: 15952.62
[INFO 2017-07-01 16:43:01,230 main.py:52] epoch 802, training loss: 8089.11, average training loss: 9076.81, base loss: 15953.22
[INFO 2017-07-01 16:43:04,055 main.py:52] epoch 803, training loss: 8396.67, average training loss: 9075.96, base loss: 15955.05
[INFO 2017-07-01 16:43:06,924 main.py:52] epoch 804, training loss: 7793.41, average training loss: 9074.37, base loss: 15954.58
[INFO 2017-07-01 16:43:09,841 main.py:52] epoch 805, training loss: 8654.65, average training loss: 9073.85, base loss: 15957.59
[INFO 2017-07-01 16:43:12,771 main.py:52] epoch 806, training loss: 8427.12, average training loss: 9073.04, base loss: 15960.54
[INFO 2017-07-01 16:43:15,626 main.py:52] epoch 807, training loss: 7779.17, average training loss: 9071.44, base loss: 15961.26
[INFO 2017-07-01 16:43:18,494 main.py:52] epoch 808, training loss: 8942.69, average training loss: 9071.28, base loss: 15964.41
[INFO 2017-07-01 16:43:21,349 main.py:52] epoch 809, training loss: 8081.86, average training loss: 9070.06, base loss: 15963.22
[INFO 2017-07-01 16:43:24,255 main.py:52] epoch 810, training loss: 7813.45, average training loss: 9068.51, base loss: 15962.44
[INFO 2017-07-01 16:43:27,113 main.py:52] epoch 811, training loss: 8052.11, average training loss: 9067.26, base loss: 15962.43
[INFO 2017-07-01 16:43:29,987 main.py:52] epoch 812, training loss: 8104.75, average training loss: 9066.08, base loss: 15962.77
[INFO 2017-07-01 16:43:32,841 main.py:52] epoch 813, training loss: 7578.66, average training loss: 9064.25, base loss: 15961.18
[INFO 2017-07-01 16:43:35,712 main.py:52] epoch 814, training loss: 7724.56, average training loss: 9062.61, base loss: 15960.00
[INFO 2017-07-01 16:43:38,560 main.py:52] epoch 815, training loss: 8960.31, average training loss: 9062.48, base loss: 15961.06
[INFO 2017-07-01 16:43:41,409 main.py:52] epoch 816, training loss: 8186.61, average training loss: 9061.41, base loss: 15962.23
[INFO 2017-07-01 16:43:44,304 main.py:52] epoch 817, training loss: 8127.96, average training loss: 9060.27, base loss: 15963.41
[INFO 2017-07-01 16:43:47,128 main.py:52] epoch 818, training loss: 7829.04, average training loss: 9058.76, base loss: 15962.91
[INFO 2017-07-01 16:43:49,996 main.py:52] epoch 819, training loss: 7813.52, average training loss: 9057.25, base loss: 15961.72
[INFO 2017-07-01 16:43:52,867 main.py:52] epoch 820, training loss: 9022.61, average training loss: 9057.20, base loss: 15964.48
[INFO 2017-07-01 16:43:55,750 main.py:52] epoch 821, training loss: 7920.36, average training loss: 9055.82, base loss: 15965.11
[INFO 2017-07-01 16:43:58,676 main.py:52] epoch 822, training loss: 7987.86, average training loss: 9054.52, base loss: 15965.18
[INFO 2017-07-01 16:44:01,556 main.py:52] epoch 823, training loss: 8460.40, average training loss: 9053.80, base loss: 15967.13
[INFO 2017-07-01 16:44:04,809 main.py:52] epoch 824, training loss: 7793.85, average training loss: 9052.28, base loss: 15966.97
[INFO 2017-07-01 16:44:07,871 main.py:52] epoch 825, training loss: 8280.19, average training loss: 9051.34, base loss: 15969.04
[INFO 2017-07-01 16:44:10,755 main.py:52] epoch 826, training loss: 8348.85, average training loss: 9050.49, base loss: 15969.79
[INFO 2017-07-01 16:44:13,633 main.py:52] epoch 827, training loss: 7895.13, average training loss: 9049.10, base loss: 15969.55
[INFO 2017-07-01 16:44:16,558 main.py:52] epoch 828, training loss: 7386.75, average training loss: 9047.09, base loss: 15965.06
[INFO 2017-07-01 16:44:19,430 main.py:52] epoch 829, training loss: 7459.52, average training loss: 9045.18, base loss: 15963.21
[INFO 2017-07-01 16:44:22,323 main.py:52] epoch 830, training loss: 7259.42, average training loss: 9043.03, base loss: 15959.96
[INFO 2017-07-01 16:44:25,196 main.py:52] epoch 831, training loss: 8055.20, average training loss: 9041.84, base loss: 15957.83
[INFO 2017-07-01 16:44:28,043 main.py:52] epoch 832, training loss: 8097.35, average training loss: 9040.71, base loss: 15957.95
[INFO 2017-07-01 16:44:30,900 main.py:52] epoch 833, training loss: 7875.35, average training loss: 9039.31, base loss: 15958.35
[INFO 2017-07-01 16:44:33,766 main.py:52] epoch 834, training loss: 8073.60, average training loss: 9038.15, base loss: 15958.85
[INFO 2017-07-01 16:44:36,659 main.py:52] epoch 835, training loss: 7931.13, average training loss: 9036.83, base loss: 15958.65
[INFO 2017-07-01 16:44:39,571 main.py:52] epoch 836, training loss: 7447.32, average training loss: 9034.93, base loss: 15955.52
[INFO 2017-07-01 16:44:42,436 main.py:52] epoch 837, training loss: 8885.60, average training loss: 9034.75, base loss: 15956.66
[INFO 2017-07-01 16:44:45,348 main.py:52] epoch 838, training loss: 7778.56, average training loss: 9033.26, base loss: 15957.35
[INFO 2017-07-01 16:44:48,203 main.py:52] epoch 839, training loss: 8911.78, average training loss: 9033.11, base loss: 15958.66
[INFO 2017-07-01 16:44:51,077 main.py:52] epoch 840, training loss: 8166.99, average training loss: 9032.08, base loss: 15958.91
[INFO 2017-07-01 16:44:53,964 main.py:52] epoch 841, training loss: 8457.39, average training loss: 9031.40, base loss: 15959.55
[INFO 2017-07-01 16:44:56,817 main.py:52] epoch 842, training loss: 8320.93, average training loss: 9030.56, base loss: 15958.68
[INFO 2017-07-01 16:44:59,668 main.py:52] epoch 843, training loss: 8734.86, average training loss: 9030.20, base loss: 15961.92
[INFO 2017-07-01 16:45:02,572 main.py:52] epoch 844, training loss: 8151.08, average training loss: 9029.16, base loss: 15961.72
[INFO 2017-07-01 16:45:05,460 main.py:52] epoch 845, training loss: 7549.20, average training loss: 9027.42, base loss: 15959.88
[INFO 2017-07-01 16:45:08,268 main.py:52] epoch 846, training loss: 7742.00, average training loss: 9025.90, base loss: 15958.32
[INFO 2017-07-01 16:45:11,153 main.py:52] epoch 847, training loss: 7500.05, average training loss: 9024.10, base loss: 15956.82
[INFO 2017-07-01 16:45:14,048 main.py:52] epoch 848, training loss: 8366.90, average training loss: 9023.32, base loss: 15959.84
[INFO 2017-07-01 16:45:16,922 main.py:52] epoch 849, training loss: 8219.10, average training loss: 9022.38, base loss: 15961.93
[INFO 2017-07-01 16:45:19,814 main.py:52] epoch 850, training loss: 8129.05, average training loss: 9021.33, base loss: 15962.95
[INFO 2017-07-01 16:45:22,703 main.py:52] epoch 851, training loss: 8502.92, average training loss: 9020.72, base loss: 15964.72
[INFO 2017-07-01 16:45:25,558 main.py:52] epoch 852, training loss: 8179.28, average training loss: 9019.73, base loss: 15964.70
[INFO 2017-07-01 16:45:28,449 main.py:52] epoch 853, training loss: 7930.56, average training loss: 9018.46, base loss: 15964.43
[INFO 2017-07-01 16:45:31,313 main.py:52] epoch 854, training loss: 7318.83, average training loss: 9016.47, base loss: 15960.77
[INFO 2017-07-01 16:45:34,221 main.py:52] epoch 855, training loss: 8096.13, average training loss: 9015.39, base loss: 15961.90
[INFO 2017-07-01 16:45:37,138 main.py:52] epoch 856, training loss: 8063.26, average training loss: 9014.28, base loss: 15961.56
[INFO 2017-07-01 16:45:39,995 main.py:52] epoch 857, training loss: 7523.97, average training loss: 9012.55, base loss: 15960.10
[INFO 2017-07-01 16:45:42,893 main.py:52] epoch 858, training loss: 8294.31, average training loss: 9011.71, base loss: 15960.40
[INFO 2017-07-01 16:45:45,746 main.py:52] epoch 859, training loss: 7604.98, average training loss: 9010.08, base loss: 15958.60
[INFO 2017-07-01 16:45:48,667 main.py:52] epoch 860, training loss: 8276.61, average training loss: 9009.22, base loss: 15959.78
[INFO 2017-07-01 16:45:51,511 main.py:52] epoch 861, training loss: 7825.12, average training loss: 9007.85, base loss: 15960.05
[INFO 2017-07-01 16:45:54,357 main.py:52] epoch 862, training loss: 8056.45, average training loss: 9006.75, base loss: 15961.20
[INFO 2017-07-01 16:45:57,231 main.py:52] epoch 863, training loss: 8424.94, average training loss: 9006.07, base loss: 15962.76
[INFO 2017-07-01 16:46:00,068 main.py:52] epoch 864, training loss: 7840.89, average training loss: 9004.73, base loss: 15963.04
[INFO 2017-07-01 16:46:02,948 main.py:52] epoch 865, training loss: 7401.51, average training loss: 9002.88, base loss: 15962.06
[INFO 2017-07-01 16:46:05,824 main.py:52] epoch 866, training loss: 7743.47, average training loss: 9001.42, base loss: 15963.01
[INFO 2017-07-01 16:46:08,677 main.py:52] epoch 867, training loss: 7599.24, average training loss: 8999.81, base loss: 15963.47
[INFO 2017-07-01 16:46:11,589 main.py:52] epoch 868, training loss: 7550.69, average training loss: 8998.14, base loss: 15961.02
[INFO 2017-07-01 16:46:14,470 main.py:52] epoch 869, training loss: 8411.21, average training loss: 8997.47, base loss: 15962.53
[INFO 2017-07-01 16:46:17,417 main.py:52] epoch 870, training loss: 8409.23, average training loss: 8996.79, base loss: 15961.94
[INFO 2017-07-01 16:46:20,337 main.py:52] epoch 871, training loss: 7769.44, average training loss: 8995.38, base loss: 15959.95
[INFO 2017-07-01 16:46:23,161 main.py:52] epoch 872, training loss: 7647.94, average training loss: 8993.84, base loss: 15959.52
[INFO 2017-07-01 16:46:26,079 main.py:52] epoch 873, training loss: 7772.04, average training loss: 8992.44, base loss: 15959.73
[INFO 2017-07-01 16:46:28,925 main.py:52] epoch 874, training loss: 7143.69, average training loss: 8990.33, base loss: 15957.37
[INFO 2017-07-01 16:46:31,782 main.py:52] epoch 875, training loss: 7960.37, average training loss: 8989.15, base loss: 15956.03
[INFO 2017-07-01 16:46:34,640 main.py:52] epoch 876, training loss: 7384.40, average training loss: 8987.32, base loss: 15954.35
[INFO 2017-07-01 16:46:37,549 main.py:52] epoch 877, training loss: 7824.18, average training loss: 8986.00, base loss: 15952.68
[INFO 2017-07-01 16:46:40,435 main.py:52] epoch 878, training loss: 8236.85, average training loss: 8985.15, base loss: 15955.37
[INFO 2017-07-01 16:46:43,306 main.py:52] epoch 879, training loss: 8628.83, average training loss: 8984.74, base loss: 15958.04
[INFO 2017-07-01 16:46:46,160 main.py:52] epoch 880, training loss: 7989.89, average training loss: 8983.61, base loss: 15958.63
[INFO 2017-07-01 16:46:49,086 main.py:52] epoch 881, training loss: 8383.11, average training loss: 8982.93, base loss: 15958.87
[INFO 2017-07-01 16:46:51,966 main.py:52] epoch 882, training loss: 8042.30, average training loss: 8981.87, base loss: 15960.71
[INFO 2017-07-01 16:46:54,878 main.py:52] epoch 883, training loss: 7417.19, average training loss: 8980.10, base loss: 15959.45
[INFO 2017-07-01 16:46:57,750 main.py:52] epoch 884, training loss: 8268.25, average training loss: 8979.29, base loss: 15960.28
[INFO 2017-07-01 16:47:00,642 main.py:52] epoch 885, training loss: 7365.29, average training loss: 8977.47, base loss: 15959.30
[INFO 2017-07-01 16:47:03,537 main.py:52] epoch 886, training loss: 7855.65, average training loss: 8976.20, base loss: 15960.02
[INFO 2017-07-01 16:47:06,410 main.py:52] epoch 887, training loss: 8104.15, average training loss: 8975.22, base loss: 15961.10
[INFO 2017-07-01 16:47:09,303 main.py:52] epoch 888, training loss: 8516.50, average training loss: 8974.71, base loss: 15963.08
[INFO 2017-07-01 16:47:12,228 main.py:52] epoch 889, training loss: 7993.80, average training loss: 8973.60, base loss: 15963.50
[INFO 2017-07-01 16:47:15,120 main.py:52] epoch 890, training loss: 7971.47, average training loss: 8972.48, base loss: 15962.93
[INFO 2017-07-01 16:47:17,954 main.py:52] epoch 891, training loss: 7315.24, average training loss: 8970.62, base loss: 15958.39
[INFO 2017-07-01 16:47:20,822 main.py:52] epoch 892, training loss: 7532.49, average training loss: 8969.01, base loss: 15957.10
[INFO 2017-07-01 16:47:23,724 main.py:52] epoch 893, training loss: 8460.73, average training loss: 8968.44, base loss: 15958.36
[INFO 2017-07-01 16:47:26,577 main.py:52] epoch 894, training loss: 8204.14, average training loss: 8967.59, base loss: 15960.10
[INFO 2017-07-01 16:47:29,439 main.py:52] epoch 895, training loss: 8433.57, average training loss: 8966.99, base loss: 15961.83
[INFO 2017-07-01 16:47:32,323 main.py:52] epoch 896, training loss: 8089.62, average training loss: 8966.01, base loss: 15961.65
[INFO 2017-07-01 16:47:35,238 main.py:52] epoch 897, training loss: 7934.17, average training loss: 8964.87, base loss: 15960.19
[INFO 2017-07-01 16:47:38,107 main.py:52] epoch 898, training loss: 8316.90, average training loss: 8964.14, base loss: 15961.37
[INFO 2017-07-01 16:47:40,997 main.py:52] epoch 899, training loss: 7845.73, average training loss: 8962.90, base loss: 15962.06
[INFO 2017-07-01 16:47:40,998 main.py:54] epoch 899, testing
[INFO 2017-07-01 16:47:53,316 main.py:97] average testing loss: 7934.58, base loss: 16195.72
[INFO 2017-07-01 16:47:53,316 main.py:98] improve_loss: 8261.14, improve_percent: 0.51
[INFO 2017-07-01 16:47:53,317 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 16:47:53,342 main.py:66] current best improved percent: 0.51
[INFO 2017-07-01 16:47:56,203 main.py:52] epoch 900, training loss: 8060.95, average training loss: 8961.90, base loss: 15961.22
[INFO 2017-07-01 16:47:59,062 main.py:52] epoch 901, training loss: 8451.12, average training loss: 8961.33, base loss: 15962.99
[INFO 2017-07-01 16:48:01,956 main.py:52] epoch 902, training loss: 8056.05, average training loss: 8960.33, base loss: 15963.24
[INFO 2017-07-01 16:48:04,841 main.py:52] epoch 903, training loss: 8423.89, average training loss: 8959.74, base loss: 15964.53
[INFO 2017-07-01 16:48:07,808 main.py:52] epoch 904, training loss: 7982.56, average training loss: 8958.66, base loss: 15965.80
[INFO 2017-07-01 16:48:10,661 main.py:52] epoch 905, training loss: 7320.71, average training loss: 8956.85, base loss: 15964.17
[INFO 2017-07-01 16:48:13,534 main.py:52] epoch 906, training loss: 7971.42, average training loss: 8955.76, base loss: 15965.34
[INFO 2017-07-01 16:48:16,425 main.py:52] epoch 907, training loss: 7726.40, average training loss: 8954.41, base loss: 15964.95
[INFO 2017-07-01 16:48:19,309 main.py:52] epoch 908, training loss: 7871.81, average training loss: 8953.22, base loss: 15964.68
[INFO 2017-07-01 16:48:22,184 main.py:52] epoch 909, training loss: 7252.36, average training loss: 8951.35, base loss: 15962.54
[INFO 2017-07-01 16:48:25,063 main.py:52] epoch 910, training loss: 7814.10, average training loss: 8950.10, base loss: 15963.70
[INFO 2017-07-01 16:48:27,918 main.py:52] epoch 911, training loss: 7948.52, average training loss: 8949.00, base loss: 15963.64
[INFO 2017-07-01 16:48:30,769 main.py:52] epoch 912, training loss: 8641.41, average training loss: 8948.67, base loss: 15967.15
[INFO 2017-07-01 16:48:33,704 main.py:52] epoch 913, training loss: 7782.02, average training loss: 8947.39, base loss: 15969.63
[INFO 2017-07-01 16:48:36,606 main.py:52] epoch 914, training loss: 7836.21, average training loss: 8946.18, base loss: 15968.67
[INFO 2017-07-01 16:48:39,497 main.py:52] epoch 915, training loss: 7877.78, average training loss: 8945.01, base loss: 15970.00
[INFO 2017-07-01 16:48:42,404 main.py:52] epoch 916, training loss: 8259.62, average training loss: 8944.26, base loss: 15971.36
[INFO 2017-07-01 16:48:45,263 main.py:52] epoch 917, training loss: 8286.64, average training loss: 8943.55, base loss: 15973.20
[INFO 2017-07-01 16:48:48,110 main.py:52] epoch 918, training loss: 7422.94, average training loss: 8941.89, base loss: 15971.86
[INFO 2017-07-01 16:48:50,982 main.py:52] epoch 919, training loss: 8224.87, average training loss: 8941.11, base loss: 15972.76
[INFO 2017-07-01 16:48:53,839 main.py:52] epoch 920, training loss: 7875.60, average training loss: 8939.96, base loss: 15973.90
[INFO 2017-07-01 16:48:56,726 main.py:52] epoch 921, training loss: 7912.40, average training loss: 8938.84, base loss: 15975.28
[INFO 2017-07-01 16:48:59,604 main.py:52] epoch 922, training loss: 7065.01, average training loss: 8936.81, base loss: 15971.23
[INFO 2017-07-01 16:49:02,496 main.py:52] epoch 923, training loss: 7752.02, average training loss: 8935.53, base loss: 15971.88
[INFO 2017-07-01 16:49:05,327 main.py:52] epoch 924, training loss: 7937.63, average training loss: 8934.45, base loss: 15969.22
[INFO 2017-07-01 16:49:08,225 main.py:52] epoch 925, training loss: 7488.78, average training loss: 8932.89, base loss: 15967.58
[INFO 2017-07-01 16:49:11,105 main.py:52] epoch 926, training loss: 8378.55, average training loss: 8932.29, base loss: 15968.90
[INFO 2017-07-01 16:49:13,978 main.py:52] epoch 927, training loss: 7825.65, average training loss: 8931.10, base loss: 15969.17
[INFO 2017-07-01 16:49:16,863 main.py:52] epoch 928, training loss: 7858.71, average training loss: 8929.94, base loss: 15970.29
[INFO 2017-07-01 16:49:19,745 main.py:52] epoch 929, training loss: 7619.40, average training loss: 8928.53, base loss: 15970.35
[INFO 2017-07-01 16:49:22,589 main.py:52] epoch 930, training loss: 8018.53, average training loss: 8927.56, base loss: 15971.37
[INFO 2017-07-01 16:49:25,452 main.py:52] epoch 931, training loss: 7900.46, average training loss: 8926.45, base loss: 15972.69
[INFO 2017-07-01 16:49:28,361 main.py:52] epoch 932, training loss: 7750.01, average training loss: 8925.19, base loss: 15972.61
[INFO 2017-07-01 16:49:31,232 main.py:52] epoch 933, training loss: 7579.71, average training loss: 8923.75, base loss: 15971.95
[INFO 2017-07-01 16:49:34,088 main.py:52] epoch 934, training loss: 8111.80, average training loss: 8922.88, base loss: 15973.70
[INFO 2017-07-01 16:49:36,938 main.py:52] epoch 935, training loss: 7981.54, average training loss: 8921.88, base loss: 15975.55
[INFO 2017-07-01 16:49:39,800 main.py:52] epoch 936, training loss: 7014.33, average training loss: 8919.84, base loss: 15973.04
[INFO 2017-07-01 16:49:42,695 main.py:52] epoch 937, training loss: 7828.00, average training loss: 8918.68, base loss: 15971.84
[INFO 2017-07-01 16:49:45,600 main.py:52] epoch 938, training loss: 8881.70, average training loss: 8918.64, base loss: 15975.29
[INFO 2017-07-01 16:49:48,509 main.py:52] epoch 939, training loss: 8939.90, average training loss: 8918.66, base loss: 15979.80
[INFO 2017-07-01 16:49:51,369 main.py:52] epoch 940, training loss: 8114.69, average training loss: 8917.81, base loss: 15979.98
[INFO 2017-07-01 16:49:54,271 main.py:52] epoch 941, training loss: 7529.82, average training loss: 8916.33, base loss: 15978.33
[INFO 2017-07-01 16:49:57,176 main.py:52] epoch 942, training loss: 7974.23, average training loss: 8915.34, base loss: 15977.78
[INFO 2017-07-01 16:50:00,073 main.py:52] epoch 943, training loss: 8206.73, average training loss: 8914.59, base loss: 15978.88
[INFO 2017-07-01 16:50:02,936 main.py:52] epoch 944, training loss: 7892.66, average training loss: 8913.50, base loss: 15978.26
[INFO 2017-07-01 16:50:05,795 main.py:52] epoch 945, training loss: 7772.67, average training loss: 8912.30, base loss: 15977.64
[INFO 2017-07-01 16:50:08,658 main.py:52] epoch 946, training loss: 8317.20, average training loss: 8911.67, base loss: 15980.59
[INFO 2017-07-01 16:50:11,524 main.py:52] epoch 947, training loss: 8585.23, average training loss: 8911.33, base loss: 15984.81
[INFO 2017-07-01 16:50:14,425 main.py:52] epoch 948, training loss: 7935.01, average training loss: 8910.30, base loss: 15984.41
[INFO 2017-07-01 16:50:17,270 main.py:52] epoch 949, training loss: 7609.32, average training loss: 8908.93, base loss: 15981.59
[INFO 2017-07-01 16:50:20,133 main.py:52] epoch 950, training loss: 7877.05, average training loss: 8907.84, base loss: 15982.35
[INFO 2017-07-01 16:50:23,025 main.py:52] epoch 951, training loss: 8447.46, average training loss: 8907.36, base loss: 15984.13
[INFO 2017-07-01 16:50:25,897 main.py:52] epoch 952, training loss: 8458.38, average training loss: 8906.89, base loss: 15983.65
[INFO 2017-07-01 16:50:28,750 main.py:52] epoch 953, training loss: 7674.07, average training loss: 8905.59, base loss: 15981.53
[INFO 2017-07-01 16:50:31,580 main.py:52] epoch 954, training loss: 8380.90, average training loss: 8905.05, base loss: 15984.06
[INFO 2017-07-01 16:50:34,483 main.py:52] epoch 955, training loss: 8509.90, average training loss: 8904.63, base loss: 15986.62
[INFO 2017-07-01 16:50:37,374 main.py:52] epoch 956, training loss: 7502.22, average training loss: 8903.17, base loss: 15986.70
[INFO 2017-07-01 16:50:40,247 main.py:52] epoch 957, training loss: 7489.94, average training loss: 8901.69, base loss: 15986.58
[INFO 2017-07-01 16:50:43,114 main.py:52] epoch 958, training loss: 8149.72, average training loss: 8900.91, base loss: 15987.06
[INFO 2017-07-01 16:50:46,039 main.py:52] epoch 959, training loss: 8682.16, average training loss: 8900.68, base loss: 15988.43
[INFO 2017-07-01 16:50:48,906 main.py:52] epoch 960, training loss: 7574.18, average training loss: 8899.30, base loss: 15987.13
[INFO 2017-07-01 16:50:51,803 main.py:52] epoch 961, training loss: 7595.02, average training loss: 8897.94, base loss: 15986.89
[INFO 2017-07-01 16:50:54,660 main.py:52] epoch 962, training loss: 7539.30, average training loss: 8896.53, base loss: 15985.44
[INFO 2017-07-01 16:50:57,508 main.py:52] epoch 963, training loss: 8755.14, average training loss: 8896.39, base loss: 15986.47
[INFO 2017-07-01 16:51:00,382 main.py:52] epoch 964, training loss: 7638.83, average training loss: 8895.08, base loss: 15986.59
[INFO 2017-07-01 16:51:03,231 main.py:52] epoch 965, training loss: 7823.04, average training loss: 8893.97, base loss: 15987.88
[INFO 2017-07-01 16:51:06,094 main.py:52] epoch 966, training loss: 8633.61, average training loss: 8893.70, base loss: 15991.18
[INFO 2017-07-01 16:51:08,951 main.py:52] epoch 967, training loss: 7780.44, average training loss: 8892.55, base loss: 15991.67
[INFO 2017-07-01 16:51:11,816 main.py:52] epoch 968, training loss: 7296.00, average training loss: 8890.91, base loss: 15989.60
[INFO 2017-07-01 16:51:14,705 main.py:52] epoch 969, training loss: 8031.55, average training loss: 8890.02, base loss: 15990.12
[INFO 2017-07-01 16:51:17,578 main.py:52] epoch 970, training loss: 7907.02, average training loss: 8889.01, base loss: 15989.76
[INFO 2017-07-01 16:51:20,440 main.py:52] epoch 971, training loss: 8036.33, average training loss: 8888.13, base loss: 15989.85
[INFO 2017-07-01 16:51:23,308 main.py:52] epoch 972, training loss: 7822.13, average training loss: 8887.03, base loss: 15987.69
[INFO 2017-07-01 16:51:26,210 main.py:52] epoch 973, training loss: 7651.73, average training loss: 8885.77, base loss: 15985.76
[INFO 2017-07-01 16:51:29,061 main.py:52] epoch 974, training loss: 8175.38, average training loss: 8885.04, base loss: 15987.24
[INFO 2017-07-01 16:51:31,949 main.py:52] epoch 975, training loss: 8387.96, average training loss: 8884.53, base loss: 15990.36
[INFO 2017-07-01 16:51:34,866 main.py:52] epoch 976, training loss: 7744.46, average training loss: 8883.36, base loss: 15991.29
[INFO 2017-07-01 16:51:37,776 main.py:52] epoch 977, training loss: 8685.51, average training loss: 8883.16, base loss: 15994.20
[INFO 2017-07-01 16:51:40,617 main.py:52] epoch 978, training loss: 7922.42, average training loss: 8882.18, base loss: 15993.17
[INFO 2017-07-01 16:51:43,469 main.py:52] epoch 979, training loss: 7521.83, average training loss: 8880.79, base loss: 15990.74
[INFO 2017-07-01 16:51:46,318 main.py:52] epoch 980, training loss: 8065.69, average training loss: 8879.96, base loss: 15991.48
[INFO 2017-07-01 16:51:49,159 main.py:52] epoch 981, training loss: 7867.25, average training loss: 8878.93, base loss: 15990.52
[INFO 2017-07-01 16:51:52,038 main.py:52] epoch 982, training loss: 7543.30, average training loss: 8877.57, base loss: 15988.38
[INFO 2017-07-01 16:51:54,941 main.py:52] epoch 983, training loss: 7566.66, average training loss: 8876.24, base loss: 15987.18
[INFO 2017-07-01 16:51:57,800 main.py:52] epoch 984, training loss: 8325.79, average training loss: 8875.68, base loss: 15991.22
[INFO 2017-07-01 16:52:00,692 main.py:52] epoch 985, training loss: 8403.84, average training loss: 8875.20, base loss: 15995.17
[INFO 2017-07-01 16:52:03,596 main.py:52] epoch 986, training loss: 7703.09, average training loss: 8874.01, base loss: 15994.14
[INFO 2017-07-01 16:52:06,484 main.py:52] epoch 987, training loss: 7393.53, average training loss: 8872.51, base loss: 15990.93
[INFO 2017-07-01 16:52:09,343 main.py:52] epoch 988, training loss: 8067.61, average training loss: 8871.70, base loss: 15992.29
[INFO 2017-07-01 16:52:12,215 main.py:52] epoch 989, training loss: 7386.57, average training loss: 8870.20, base loss: 15991.87
[INFO 2017-07-01 16:52:15,070 main.py:52] epoch 990, training loss: 7559.06, average training loss: 8868.88, base loss: 15991.13
[INFO 2017-07-01 16:52:17,930 main.py:52] epoch 991, training loss: 8328.42, average training loss: 8868.33, base loss: 15993.02
[INFO 2017-07-01 16:52:20,810 main.py:52] epoch 992, training loss: 8088.36, average training loss: 8867.55, base loss: 15993.01
[INFO 2017-07-01 16:52:23,680 main.py:52] epoch 993, training loss: 7890.39, average training loss: 8866.56, base loss: 15991.75
[INFO 2017-07-01 16:52:26,571 main.py:52] epoch 994, training loss: 8145.86, average training loss: 8865.84, base loss: 15991.98
[INFO 2017-07-01 16:52:29,464 main.py:52] epoch 995, training loss: 7404.42, average training loss: 8864.37, base loss: 15991.19
[INFO 2017-07-01 16:52:32,330 main.py:52] epoch 996, training loss: 8303.71, average training loss: 8863.81, base loss: 15990.74
[INFO 2017-07-01 16:52:35,235 main.py:52] epoch 997, training loss: 7361.30, average training loss: 8862.30, base loss: 15987.98
[INFO 2017-07-01 16:52:38,128 main.py:52] epoch 998, training loss: 7207.07, average training loss: 8860.65, base loss: 15987.81
[INFO 2017-07-01 16:52:40,991 main.py:52] epoch 999, training loss: 7182.83, average training loss: 8858.97, base loss: 15988.12
[INFO 2017-07-01 16:52:40,992 main.py:54] epoch 999, testing
[INFO 2017-07-01 16:52:53,349 main.py:97] average testing loss: 7952.97, base loss: 16021.65
[INFO 2017-07-01 16:52:53,350 main.py:98] improve_loss: 8068.68, improve_percent: 0.50
[INFO 2017-07-01 16:52:53,351 main.py:66] current best improved percent: 0.51
[INFO 2017-07-01 16:52:56,193 main.py:52] epoch 1000, training loss: 7922.59, average training loss: 8828.47, base loss: 15989.02
[INFO 2017-07-01 16:52:59,108 main.py:52] epoch 1001, training loss: 7880.50, average training loss: 8800.75, base loss: 15988.69
[INFO 2017-07-01 16:53:01,962 main.py:52] epoch 1002, training loss: 7109.17, average training loss: 8774.97, base loss: 15986.36
[INFO 2017-07-01 16:53:04,820 main.py:52] epoch 1003, training loss: 7233.93, average training loss: 8752.98, base loss: 15984.49
[INFO 2017-07-01 16:53:07,661 main.py:52] epoch 1004, training loss: 8296.21, average training loss: 8735.35, base loss: 15987.88
[INFO 2017-07-01 16:53:10,573 main.py:52] epoch 1005, training loss: 7928.36, average training loss: 8718.54, base loss: 15989.10
[INFO 2017-07-01 16:53:13,519 main.py:52] epoch 1006, training loss: 7726.95, average training loss: 8703.56, base loss: 15988.18
[INFO 2017-07-01 16:53:16,480 main.py:52] epoch 1007, training loss: 7429.01, average training loss: 8688.89, base loss: 15986.09
[INFO 2017-07-01 16:53:19,346 main.py:52] epoch 1008, training loss: 8120.24, average training loss: 8676.55, base loss: 15988.05
[INFO 2017-07-01 16:53:22,223 main.py:52] epoch 1009, training loss: 7565.61, average training loss: 8664.51, base loss: 15988.04
[INFO 2017-07-01 16:53:25,103 main.py:52] epoch 1010, training loss: 8764.25, average training loss: 8655.95, base loss: 15991.67
[INFO 2017-07-01 16:53:27,987 main.py:52] epoch 1011, training loss: 8242.23, average training loss: 8647.05, base loss: 15992.22
[INFO 2017-07-01 16:53:30,852 main.py:52] epoch 1012, training loss: 8149.64, average training loss: 8638.27, base loss: 15992.63
[INFO 2017-07-01 16:53:33,734 main.py:52] epoch 1013, training loss: 7554.70, average training loss: 8630.28, base loss: 15993.15
[INFO 2017-07-01 16:53:36,618 main.py:52] epoch 1014, training loss: 8353.22, average training loss: 8624.71, base loss: 15992.96
[INFO 2017-07-01 16:53:39,505 main.py:52] epoch 1015, training loss: 8485.61, average training loss: 8617.51, base loss: 15995.92
[INFO 2017-07-01 16:53:42,371 main.py:52] epoch 1016, training loss: 7927.96, average training loss: 8610.55, base loss: 15996.99
[INFO 2017-07-01 16:53:45,261 main.py:52] epoch 1017, training loss: 7986.04, average training loss: 8604.16, base loss: 15997.91
[INFO 2017-07-01 16:53:48,191 main.py:52] epoch 1018, training loss: 7429.13, average training loss: 8597.99, base loss: 15996.12
[INFO 2017-07-01 16:53:51,089 main.py:52] epoch 1019, training loss: 8208.79, average training loss: 8592.35, base loss: 15996.64
[INFO 2017-07-01 16:53:54,022 main.py:52] epoch 1020, training loss: 8183.31, average training loss: 8589.01, base loss: 15998.22
[INFO 2017-07-01 16:53:57,181 main.py:52] epoch 1021, training loss: 9130.35, average training loss: 8586.80, base loss: 16001.72
[INFO 2017-07-01 16:54:00,106 main.py:52] epoch 1022, training loss: 7678.34, average training loss: 8582.07, base loss: 15999.96
[INFO 2017-07-01 16:54:02,960 main.py:52] epoch 1023, training loss: 7478.21, average training loss: 8578.90, base loss: 15998.28
[INFO 2017-07-01 16:54:05,859 main.py:52] epoch 1024, training loss: 9140.33, average training loss: 8576.44, base loss: 16003.55
[INFO 2017-07-01 16:54:08,791 main.py:52] epoch 1025, training loss: 7521.13, average training loss: 8571.92, base loss: 16002.71
[INFO 2017-07-01 16:54:11,726 main.py:52] epoch 1026, training loss: 7318.45, average training loss: 8568.09, base loss: 15999.84
[INFO 2017-07-01 16:54:14,613 main.py:52] epoch 1027, training loss: 7796.55, average training loss: 8564.77, base loss: 15998.17
[INFO 2017-07-01 16:54:17,482 main.py:52] epoch 1028, training loss: 8022.72, average training loss: 8562.23, base loss: 15997.72
[INFO 2017-07-01 16:54:20,354 main.py:52] epoch 1029, training loss: 7849.36, average training loss: 8558.60, base loss: 15997.15
[INFO 2017-07-01 16:54:23,266 main.py:52] epoch 1030, training loss: 7796.91, average training loss: 8556.27, base loss: 15996.57
[INFO 2017-07-01 16:54:26,134 main.py:52] epoch 1031, training loss: 7465.98, average training loss: 8553.28, base loss: 15994.54
[INFO 2017-07-01 16:54:28,975 main.py:52] epoch 1032, training loss: 7365.94, average training loss: 8548.86, base loss: 15993.08
[INFO 2017-07-01 16:54:31,873 main.py:52] epoch 1033, training loss: 7921.68, average training loss: 8546.12, base loss: 15995.01
[INFO 2017-07-01 16:54:34,785 main.py:52] epoch 1034, training loss: 7684.75, average training loss: 8541.88, base loss: 15995.41
[INFO 2017-07-01 16:54:37,676 main.py:52] epoch 1035, training loss: 8109.57, average training loss: 8539.00, base loss: 15997.03
[INFO 2017-07-01 16:54:40,567 main.py:52] epoch 1036, training loss: 7644.04, average training loss: 8535.25, base loss: 15995.96
[INFO 2017-07-01 16:54:43,444 main.py:52] epoch 1037, training loss: 8236.18, average training loss: 8532.39, base loss: 15997.46
[INFO 2017-07-01 16:54:46,283 main.py:52] epoch 1038, training loss: 8087.77, average training loss: 8529.69, base loss: 15998.66
[INFO 2017-07-01 16:54:49,241 main.py:52] epoch 1039, training loss: 7591.37, average training loss: 8526.54, base loss: 15997.11
[INFO 2017-07-01 16:54:52,095 main.py:52] epoch 1040, training loss: 7607.67, average training loss: 8524.37, base loss: 15995.59
[INFO 2017-07-01 16:54:54,920 main.py:52] epoch 1041, training loss: 7864.29, average training loss: 8522.38, base loss: 15995.44
[INFO 2017-07-01 16:54:57,831 main.py:52] epoch 1042, training loss: 7424.33, average training loss: 8517.44, base loss: 15994.61
[INFO 2017-07-01 16:55:00,673 main.py:52] epoch 1043, training loss: 7464.10, average training loss: 8514.30, base loss: 15992.81
[INFO 2017-07-01 16:55:03,531 main.py:52] epoch 1044, training loss: 7376.89, average training loss: 8511.50, base loss: 15989.04
[INFO 2017-07-01 16:55:06,436 main.py:52] epoch 1045, training loss: 7897.28, average training loss: 8509.63, base loss: 15987.00
[INFO 2017-07-01 16:55:09,291 main.py:52] epoch 1046, training loss: 7164.16, average training loss: 8505.63, base loss: 15984.50
[INFO 2017-07-01 16:55:12,202 main.py:52] epoch 1047, training loss: 7532.40, average training loss: 8501.85, base loss: 15982.98
[INFO 2017-07-01 16:55:15,074 main.py:52] epoch 1048, training loss: 8491.07, average training loss: 8499.41, base loss: 15982.89
[INFO 2017-07-01 16:55:17,930 main.py:52] epoch 1049, training loss: 7973.14, average training loss: 8497.92, base loss: 15980.57
[INFO 2017-07-01 16:55:20,776 main.py:52] epoch 1050, training loss: 8027.83, average training loss: 8493.74, base loss: 15980.75
[INFO 2017-07-01 16:55:23,655 main.py:52] epoch 1051, training loss: 7970.12, average training loss: 8489.28, base loss: 15979.90
[INFO 2017-07-01 16:55:26,517 main.py:52] epoch 1052, training loss: 8137.61, average training loss: 8486.30, base loss: 15980.91
[INFO 2017-07-01 16:55:29,389 main.py:52] epoch 1053, training loss: 8734.27, average training loss: 8482.47, base loss: 15983.64
[INFO 2017-07-01 16:55:32,260 main.py:52] epoch 1054, training loss: 9049.96, average training loss: 8481.17, base loss: 15985.89
[INFO 2017-07-01 16:55:35,139 main.py:52] epoch 1055, training loss: 7100.71, average training loss: 8478.00, base loss: 15984.09
[INFO 2017-07-01 16:55:38,005 main.py:52] epoch 1056, training loss: 7489.47, average training loss: 8474.50, base loss: 15982.66
[INFO 2017-07-01 16:55:40,891 main.py:52] epoch 1057, training loss: 8096.67, average training loss: 8471.67, base loss: 15981.95
[INFO 2017-07-01 16:55:43,761 main.py:52] epoch 1058, training loss: 8099.15, average training loss: 8468.24, base loss: 15982.51
[INFO 2017-07-01 16:55:46,646 main.py:52] epoch 1059, training loss: 7714.18, average training loss: 8465.46, base loss: 15980.48
[INFO 2017-07-01 16:55:49,529 main.py:52] epoch 1060, training loss: 7966.56, average training loss: 8462.77, base loss: 15981.87
[INFO 2017-07-01 16:55:52,432 main.py:52] epoch 1061, training loss: 8485.42, average training loss: 8461.27, base loss: 15985.47
[INFO 2017-07-01 16:55:55,333 main.py:52] epoch 1062, training loss: 7904.64, average training loss: 8459.37, base loss: 15985.53
[INFO 2017-07-01 16:55:58,207 main.py:52] epoch 1063, training loss: 7177.93, average training loss: 8456.92, base loss: 15983.85
[INFO 2017-07-01 16:56:01,131 main.py:52] epoch 1064, training loss: 8219.08, average training loss: 8454.03, base loss: 15986.17
[INFO 2017-07-01 16:56:04,017 main.py:52] epoch 1065, training loss: 7904.30, average training loss: 8450.86, base loss: 15985.52
[INFO 2017-07-01 16:56:06,875 main.py:52] epoch 1066, training loss: 7865.54, average training loss: 8447.09, base loss: 15987.04
[INFO 2017-07-01 16:56:09,761 main.py:52] epoch 1067, training loss: 8233.92, average training loss: 8444.83, base loss: 15988.34
[INFO 2017-07-01 16:56:12,640 main.py:52] epoch 1068, training loss: 7631.96, average training loss: 8442.57, base loss: 15986.03
[INFO 2017-07-01 16:56:15,505 main.py:52] epoch 1069, training loss: 7769.92, average training loss: 8442.06, base loss: 15984.35
[INFO 2017-07-01 16:56:18,382 main.py:52] epoch 1070, training loss: 7028.15, average training loss: 8439.39, base loss: 15982.65
[INFO 2017-07-01 16:56:21,240 main.py:52] epoch 1071, training loss: 8661.52, average training loss: 8437.26, base loss: 15985.37
[INFO 2017-07-01 16:56:24,088 main.py:52] epoch 1072, training loss: 8371.55, average training loss: 8435.32, base loss: 15985.00
[INFO 2017-07-01 16:56:26,940 main.py:52] epoch 1073, training loss: 7676.42, average training loss: 8433.78, base loss: 15982.07
[INFO 2017-07-01 16:56:29,801 main.py:52] epoch 1074, training loss: 7913.42, average training loss: 8431.41, base loss: 15982.74
[INFO 2017-07-01 16:56:32,656 main.py:52] epoch 1075, training loss: 7619.00, average training loss: 8426.69, base loss: 15982.23
[INFO 2017-07-01 16:56:35,539 main.py:52] epoch 1076, training loss: 7829.44, average training loss: 8423.16, base loss: 15980.51
[INFO 2017-07-01 16:56:38,416 main.py:52] epoch 1077, training loss: 7619.14, average training loss: 8420.86, base loss: 15980.00
[INFO 2017-07-01 16:56:41,313 main.py:52] epoch 1078, training loss: 7702.01, average training loss: 8417.50, base loss: 15980.28
[INFO 2017-07-01 16:56:44,199 main.py:52] epoch 1079, training loss: 7784.33, average training loss: 8414.43, base loss: 15980.97
[INFO 2017-07-01 16:56:47,087 main.py:52] epoch 1080, training loss: 7791.71, average training loss: 8413.69, base loss: 15981.75
[INFO 2017-07-01 16:56:49,999 main.py:52] epoch 1081, training loss: 7386.74, average training loss: 8411.89, base loss: 15979.88
[INFO 2017-07-01 16:56:52,884 main.py:52] epoch 1082, training loss: 8053.41, average training loss: 8409.59, base loss: 15980.60
[INFO 2017-07-01 16:56:55,768 main.py:52] epoch 1083, training loss: 7754.70, average training loss: 8407.55, base loss: 15979.78
[INFO 2017-07-01 16:56:58,642 main.py:52] epoch 1084, training loss: 7619.35, average training loss: 8404.46, base loss: 15977.81
[INFO 2017-07-01 16:57:01,533 main.py:52] epoch 1085, training loss: 7843.90, average training loss: 8402.57, base loss: 15976.63
[INFO 2017-07-01 16:57:04,389 main.py:52] epoch 1086, training loss: 8113.79, average training loss: 8399.76, base loss: 15979.11
[INFO 2017-07-01 16:57:07,278 main.py:52] epoch 1087, training loss: 7759.02, average training loss: 8396.22, base loss: 15981.18
[INFO 2017-07-01 16:57:10,113 main.py:52] epoch 1088, training loss: 7473.34, average training loss: 8393.35, base loss: 15978.35
[INFO 2017-07-01 16:57:12,942 main.py:52] epoch 1089, training loss: 7476.75, average training loss: 8390.48, base loss: 15977.19
[INFO 2017-07-01 16:57:15,805 main.py:52] epoch 1090, training loss: 8345.40, average training loss: 8388.99, base loss: 15978.60
[INFO 2017-07-01 16:57:18,654 main.py:52] epoch 1091, training loss: 8557.29, average training loss: 8387.30, base loss: 15980.61
[INFO 2017-07-01 16:57:21,545 main.py:52] epoch 1092, training loss: 7737.58, average training loss: 8385.51, base loss: 15982.01
[INFO 2017-07-01 16:57:24,431 main.py:52] epoch 1093, training loss: 8281.57, average training loss: 8382.89, base loss: 15983.90
[INFO 2017-07-01 16:57:27,301 main.py:52] epoch 1094, training loss: 8009.00, average training loss: 8380.89, base loss: 15985.29
[INFO 2017-07-01 16:57:30,159 main.py:52] epoch 1095, training loss: 8051.47, average training loss: 8378.80, base loss: 15986.88
[INFO 2017-07-01 16:57:33,030 main.py:52] epoch 1096, training loss: 7331.17, average training loss: 8377.12, base loss: 15987.05
[INFO 2017-07-01 16:57:35,873 main.py:52] epoch 1097, training loss: 7750.81, average training loss: 8374.52, base loss: 15987.52
[INFO 2017-07-01 16:57:38,763 main.py:52] epoch 1098, training loss: 7475.78, average training loss: 8371.44, base loss: 15987.20
[INFO 2017-07-01 16:57:41,683 main.py:52] epoch 1099, training loss: 9063.15, average training loss: 8370.79, base loss: 15991.10
[INFO 2017-07-01 16:57:41,683 main.py:54] epoch 1099, testing
[INFO 2017-07-01 16:57:54,036 main.py:97] average testing loss: 7575.92, base loss: 15695.55
[INFO 2017-07-01 16:57:54,036 main.py:98] improve_loss: 8119.63, improve_percent: 0.52
[INFO 2017-07-01 16:57:54,038 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 16:57:54,064 main.py:66] current best improved percent: 0.52
[INFO 2017-07-01 16:57:56,938 main.py:52] epoch 1100, training loss: 7461.93, average training loss: 8368.58, base loss: 15991.55
[INFO 2017-07-01 16:57:59,813 main.py:52] epoch 1101, training loss: 8266.47, average training loss: 8366.88, base loss: 15993.87
[INFO 2017-07-01 16:58:02,668 main.py:52] epoch 1102, training loss: 7711.28, average training loss: 8364.06, base loss: 15992.95
[INFO 2017-07-01 16:58:05,525 main.py:52] epoch 1103, training loss: 7744.51, average training loss: 8361.47, base loss: 15992.69
[INFO 2017-07-01 16:58:08,413 main.py:52] epoch 1104, training loss: 7592.33, average training loss: 8359.28, base loss: 15992.70
[INFO 2017-07-01 16:58:11,302 main.py:52] epoch 1105, training loss: 7520.84, average training loss: 8358.17, base loss: 15991.66
[INFO 2017-07-01 16:58:14,168 main.py:52] epoch 1106, training loss: 8473.37, average training loss: 8357.29, base loss: 15992.57
[INFO 2017-07-01 16:58:17,054 main.py:52] epoch 1107, training loss: 7556.21, average training loss: 8355.32, base loss: 15991.29
[INFO 2017-07-01 16:58:19,883 main.py:52] epoch 1108, training loss: 8163.38, average training loss: 8353.96, base loss: 15991.55
[INFO 2017-07-01 16:58:22,795 main.py:52] epoch 1109, training loss: 7495.49, average training loss: 8350.58, base loss: 15988.92
[INFO 2017-07-01 16:58:25,657 main.py:52] epoch 1110, training loss: 8409.64, average training loss: 8348.08, base loss: 15991.44
[INFO 2017-07-01 16:58:28,509 main.py:52] epoch 1111, training loss: 8430.74, average training loss: 8346.93, base loss: 15994.04
[INFO 2017-07-01 16:58:31,360 main.py:52] epoch 1112, training loss: 7307.69, average training loss: 8345.24, base loss: 15993.05
[INFO 2017-07-01 16:58:34,259 main.py:52] epoch 1113, training loss: 7681.53, average training loss: 8344.13, base loss: 15992.72
[INFO 2017-07-01 16:58:37,167 main.py:52] epoch 1114, training loss: 7769.75, average training loss: 8342.33, base loss: 15993.12
[INFO 2017-07-01 16:58:40,008 main.py:52] epoch 1115, training loss: 7249.87, average training loss: 8340.02, base loss: 15992.36
[INFO 2017-07-01 16:58:42,868 main.py:52] epoch 1116, training loss: 7627.36, average training loss: 8339.08, base loss: 15992.74
[INFO 2017-07-01 16:58:45,732 main.py:52] epoch 1117, training loss: 8284.90, average training loss: 8336.26, base loss: 15993.90
[INFO 2017-07-01 16:58:48,567 main.py:52] epoch 1118, training loss: 7344.55, average training loss: 8334.15, base loss: 15992.34
[INFO 2017-07-01 16:58:51,453 main.py:52] epoch 1119, training loss: 8270.21, average training loss: 8333.88, base loss: 15993.32
[INFO 2017-07-01 16:58:54,308 main.py:52] epoch 1120, training loss: 8734.91, average training loss: 8332.61, base loss: 15996.62
[INFO 2017-07-01 16:58:57,197 main.py:52] epoch 1121, training loss: 7842.66, average training loss: 8330.96, base loss: 15997.99
[INFO 2017-07-01 16:59:00,059 main.py:52] epoch 1122, training loss: 7862.21, average training loss: 8329.56, base loss: 15998.70
[INFO 2017-07-01 16:59:02,934 main.py:52] epoch 1123, training loss: 7473.91, average training loss: 8327.71, base loss: 15998.16
[INFO 2017-07-01 16:59:05,872 main.py:52] epoch 1124, training loss: 8075.27, average training loss: 8326.60, base loss: 16001.97
[INFO 2017-07-01 16:59:08,740 main.py:52] epoch 1125, training loss: 7787.01, average training loss: 8323.78, base loss: 16003.62
[INFO 2017-07-01 16:59:11,598 main.py:52] epoch 1126, training loss: 7958.58, average training loss: 8321.43, base loss: 16003.71
[INFO 2017-07-01 16:59:14,479 main.py:52] epoch 1127, training loss: 7792.52, average training loss: 8318.97, base loss: 16003.39
[INFO 2017-07-01 16:59:17,326 main.py:52] epoch 1128, training loss: 7700.63, average training loss: 8317.78, base loss: 16004.07
[INFO 2017-07-01 16:59:20,183 main.py:52] epoch 1129, training loss: 8164.05, average training loss: 8317.26, base loss: 16006.32
[INFO 2017-07-01 16:59:23,050 main.py:52] epoch 1130, training loss: 8033.92, average training loss: 8316.08, base loss: 16009.02
[INFO 2017-07-01 16:59:25,945 main.py:52] epoch 1131, training loss: 7536.67, average training loss: 8313.87, base loss: 16007.86
[INFO 2017-07-01 16:59:28,837 main.py:52] epoch 1132, training loss: 7366.90, average training loss: 8311.73, base loss: 16006.32
[INFO 2017-07-01 16:59:31,742 main.py:52] epoch 1133, training loss: 7537.87, average training loss: 8310.95, base loss: 16004.07
[INFO 2017-07-01 16:59:34,858 main.py:52] epoch 1134, training loss: 8733.30, average training loss: 8310.33, base loss: 16006.77
[INFO 2017-07-01 16:59:37,912 main.py:52] epoch 1135, training loss: 7763.94, average training loss: 8307.77, base loss: 16006.62
[INFO 2017-07-01 16:59:40,805 main.py:52] epoch 1136, training loss: 7825.87, average training loss: 8306.13, base loss: 16008.53
[INFO 2017-07-01 16:59:43,684 main.py:52] epoch 1137, training loss: 7706.35, average training loss: 8304.12, base loss: 16009.75
[INFO 2017-07-01 16:59:46,562 main.py:52] epoch 1138, training loss: 7090.96, average training loss: 8301.45, base loss: 16007.23
[INFO 2017-07-01 16:59:49,432 main.py:52] epoch 1139, training loss: 7721.38, average training loss: 8300.09, base loss: 16005.76
[INFO 2017-07-01 16:59:52,312 main.py:52] epoch 1140, training loss: 8279.86, average training loss: 8299.63, base loss: 16006.44
[INFO 2017-07-01 16:59:55,193 main.py:52] epoch 1141, training loss: 7770.14, average training loss: 8298.13, base loss: 16006.66
[INFO 2017-07-01 16:59:58,035 main.py:52] epoch 1142, training loss: 8449.35, average training loss: 8297.28, base loss: 16007.63
[INFO 2017-07-01 17:00:00,864 main.py:52] epoch 1143, training loss: 7519.99, average training loss: 8295.78, base loss: 16006.77
[INFO 2017-07-01 17:00:03,740 main.py:52] epoch 1144, training loss: 7634.91, average training loss: 8295.03, base loss: 16005.23
[INFO 2017-07-01 17:00:06,591 main.py:52] epoch 1145, training loss: 7494.12, average training loss: 8292.20, base loss: 16004.09
[INFO 2017-07-01 17:00:09,524 main.py:52] epoch 1146, training loss: 7841.76, average training loss: 8289.87, base loss: 16003.42
[INFO 2017-07-01 17:00:12,425 main.py:52] epoch 1147, training loss: 7300.34, average training loss: 8287.51, base loss: 16001.34
[INFO 2017-07-01 17:00:15,293 main.py:52] epoch 1148, training loss: 7394.93, average training loss: 8285.90, base loss: 15998.76
[INFO 2017-07-01 17:00:18,153 main.py:52] epoch 1149, training loss: 8081.88, average training loss: 8284.56, base loss: 15999.16
[INFO 2017-07-01 17:00:21,040 main.py:52] epoch 1150, training loss: 7476.47, average training loss: 8282.89, base loss: 15997.83
[INFO 2017-07-01 17:00:23,883 main.py:52] epoch 1151, training loss: 7660.60, average training loss: 8281.68, base loss: 15996.90
[INFO 2017-07-01 17:00:26,742 main.py:52] epoch 1152, training loss: 6982.55, average training loss: 8279.16, base loss: 15995.76
[INFO 2017-07-01 17:00:29,673 main.py:52] epoch 1153, training loss: 7109.00, average training loss: 8277.04, base loss: 15993.98
[INFO 2017-07-01 17:00:32,549 main.py:52] epoch 1154, training loss: 7722.11, average training loss: 8275.01, base loss: 15995.16
[INFO 2017-07-01 17:00:35,469 main.py:52] epoch 1155, training loss: 8227.57, average training loss: 8273.81, base loss: 15995.58
[INFO 2017-07-01 17:00:38,354 main.py:52] epoch 1156, training loss: 7948.98, average training loss: 8272.63, base loss: 15995.92
[INFO 2017-07-01 17:00:41,225 main.py:52] epoch 1157, training loss: 7416.03, average training loss: 8270.84, base loss: 15993.59
[INFO 2017-07-01 17:00:44,112 main.py:52] epoch 1158, training loss: 8014.74, average training loss: 8269.78, base loss: 15994.88
[INFO 2017-07-01 17:00:46,987 main.py:52] epoch 1159, training loss: 7866.55, average training loss: 8268.23, base loss: 15995.89
[INFO 2017-07-01 17:00:49,824 main.py:52] epoch 1160, training loss: 7209.05, average training loss: 8265.55, base loss: 15992.59
[INFO 2017-07-01 17:00:52,680 main.py:52] epoch 1161, training loss: 7537.58, average training loss: 8263.84, base loss: 15990.87
[INFO 2017-07-01 17:00:55,553 main.py:52] epoch 1162, training loss: 7151.30, average training loss: 8261.99, base loss: 15989.66
[INFO 2017-07-01 17:00:58,425 main.py:52] epoch 1163, training loss: 7588.13, average training loss: 8260.21, base loss: 15990.22
[INFO 2017-07-01 17:01:01,285 main.py:52] epoch 1164, training loss: 8032.46, average training loss: 8258.82, base loss: 15992.16
[INFO 2017-07-01 17:01:04,119 main.py:52] epoch 1165, training loss: 7885.67, average training loss: 8256.04, base loss: 15993.35
[INFO 2017-07-01 17:01:06,988 main.py:52] epoch 1166, training loss: 8383.88, average training loss: 8255.54, base loss: 15995.55
[INFO 2017-07-01 17:01:09,868 main.py:52] epoch 1167, training loss: 7526.49, average training loss: 8253.35, base loss: 15995.40
[INFO 2017-07-01 17:01:12,707 main.py:52] epoch 1168, training loss: 7612.68, average training loss: 8250.49, base loss: 15996.44
[INFO 2017-07-01 17:01:15,562 main.py:52] epoch 1169, training loss: 8104.29, average training loss: 8249.16, base loss: 15997.86
[INFO 2017-07-01 17:01:18,407 main.py:52] epoch 1170, training loss: 7165.21, average training loss: 8246.83, base loss: 15996.45
[INFO 2017-07-01 17:01:21,261 main.py:52] epoch 1171, training loss: 9158.31, average training loss: 8246.50, base loss: 16001.55
[INFO 2017-07-01 17:01:24,141 main.py:52] epoch 1172, training loss: 7009.02, average training loss: 8243.57, base loss: 15998.97
[INFO 2017-07-01 17:01:27,014 main.py:52] epoch 1173, training loss: 8240.51, average training loss: 8242.45, base loss: 16000.78
[INFO 2017-07-01 17:01:29,879 main.py:52] epoch 1174, training loss: 7487.53, average training loss: 8242.08, base loss: 16000.98
[INFO 2017-07-01 17:01:32,797 main.py:52] epoch 1175, training loss: 7859.33, average training loss: 8240.55, base loss: 16000.71
[INFO 2017-07-01 17:01:35,691 main.py:52] epoch 1176, training loss: 7625.53, average training loss: 8238.93, base loss: 15999.88
[INFO 2017-07-01 17:01:38,569 main.py:52] epoch 1177, training loss: 8315.23, average training loss: 8237.31, base loss: 16002.61
[INFO 2017-07-01 17:01:41,407 main.py:52] epoch 1178, training loss: 7752.32, average training loss: 8236.06, base loss: 16002.11
[INFO 2017-07-01 17:01:44,307 main.py:52] epoch 1179, training loss: 8692.03, average training loss: 8234.80, base loss: 16004.70
[INFO 2017-07-01 17:01:47,158 main.py:52] epoch 1180, training loss: 7437.41, average training loss: 8233.13, base loss: 16004.28
[INFO 2017-07-01 17:01:50,026 main.py:52] epoch 1181, training loss: 7773.93, average training loss: 8232.12, base loss: 16004.69
[INFO 2017-07-01 17:01:52,900 main.py:52] epoch 1182, training loss: 7598.60, average training loss: 8230.69, base loss: 16005.63
[INFO 2017-07-01 17:01:55,774 main.py:52] epoch 1183, training loss: 8541.06, average training loss: 8230.79, base loss: 16008.11
[INFO 2017-07-01 17:01:58,642 main.py:52] epoch 1184, training loss: 7623.44, average training loss: 8228.64, base loss: 16008.99
[INFO 2017-07-01 17:02:01,532 main.py:52] epoch 1185, training loss: 7999.22, average training loss: 8226.60, base loss: 16010.41
[INFO 2017-07-01 17:02:04,445 main.py:52] epoch 1186, training loss: 7960.73, average training loss: 8225.78, base loss: 16011.77
[INFO 2017-07-01 17:02:07,289 main.py:52] epoch 1187, training loss: 8272.23, average training loss: 8224.67, base loss: 16011.95
[INFO 2017-07-01 17:02:10,177 main.py:52] epoch 1188, training loss: 7857.95, average training loss: 8223.53, base loss: 16012.90
[INFO 2017-07-01 17:02:13,049 main.py:52] epoch 1189, training loss: 7809.00, average training loss: 8222.95, base loss: 16012.42
[INFO 2017-07-01 17:02:15,965 main.py:52] epoch 1190, training loss: 8669.45, average training loss: 8222.06, base loss: 16015.75
[INFO 2017-07-01 17:02:18,851 main.py:52] epoch 1191, training loss: 7767.74, average training loss: 8220.67, base loss: 16017.97
[INFO 2017-07-01 17:02:21,743 main.py:52] epoch 1192, training loss: 7641.59, average training loss: 8219.98, base loss: 16017.70
[INFO 2017-07-01 17:02:24,652 main.py:52] epoch 1193, training loss: 7189.44, average training loss: 8217.83, base loss: 16015.25
[INFO 2017-07-01 17:02:27,629 main.py:52] epoch 1194, training loss: 7272.90, average training loss: 8216.10, base loss: 16013.58
[INFO 2017-07-01 17:02:30,507 main.py:52] epoch 1195, training loss: 7685.13, average training loss: 8214.15, base loss: 16012.58
[INFO 2017-07-01 17:02:33,408 main.py:52] epoch 1196, training loss: 7335.49, average training loss: 8211.68, base loss: 16012.37
[INFO 2017-07-01 17:02:36,363 main.py:52] epoch 1197, training loss: 7353.19, average training loss: 8209.68, base loss: 16011.56
[INFO 2017-07-01 17:02:39,192 main.py:52] epoch 1198, training loss: 8135.15, average training loss: 8208.46, base loss: 16013.29
[INFO 2017-07-01 17:02:42,107 main.py:52] epoch 1199, training loss: 8382.53, average training loss: 8207.85, base loss: 16015.57
[INFO 2017-07-01 17:02:42,107 main.py:54] epoch 1199, testing
[INFO 2017-07-01 17:02:54,400 main.py:97] average testing loss: 7912.94, base loss: 16541.92
[INFO 2017-07-01 17:02:54,400 main.py:98] improve_loss: 8628.98, improve_percent: 0.52
[INFO 2017-07-01 17:02:54,402 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 17:02:54,427 main.py:66] current best improved percent: 0.52
[INFO 2017-07-01 17:02:57,308 main.py:52] epoch 1200, training loss: 7842.67, average training loss: 8205.87, base loss: 16016.28
[INFO 2017-07-01 17:03:00,173 main.py:52] epoch 1201, training loss: 8234.30, average training loss: 8205.24, base loss: 16018.51
[INFO 2017-07-01 17:03:03,075 main.py:52] epoch 1202, training loss: 7921.99, average training loss: 8204.18, base loss: 16018.65
[INFO 2017-07-01 17:03:05,957 main.py:52] epoch 1203, training loss: 7829.48, average training loss: 8202.71, base loss: 16018.95
[INFO 2017-07-01 17:03:08,855 main.py:52] epoch 1204, training loss: 7160.00, average training loss: 8200.91, base loss: 16016.08
[INFO 2017-07-01 17:03:11,735 main.py:52] epoch 1205, training loss: 7503.58, average training loss: 8199.25, base loss: 16015.04
[INFO 2017-07-01 17:03:14,619 main.py:52] epoch 1206, training loss: 7185.28, average training loss: 8197.96, base loss: 16013.51
[INFO 2017-07-01 17:03:17,553 main.py:52] epoch 1207, training loss: 8594.71, average training loss: 8197.32, base loss: 16015.75
[INFO 2017-07-01 17:03:20,436 main.py:52] epoch 1208, training loss: 7744.12, average training loss: 8196.81, base loss: 16015.90
[INFO 2017-07-01 17:03:23,314 main.py:52] epoch 1209, training loss: 7429.16, average training loss: 8195.52, base loss: 16016.52
[INFO 2017-07-01 17:03:26,175 main.py:52] epoch 1210, training loss: 7363.45, average training loss: 8194.55, base loss: 16014.88
[INFO 2017-07-01 17:03:29,044 main.py:52] epoch 1211, training loss: 7291.52, average training loss: 8192.81, base loss: 16013.27
[INFO 2017-07-01 17:03:31,904 main.py:52] epoch 1212, training loss: 8296.66, average training loss: 8191.31, base loss: 16015.58
[INFO 2017-07-01 17:03:34,775 main.py:52] epoch 1213, training loss: 7429.00, average training loss: 8189.57, base loss: 16014.02
[INFO 2017-07-01 17:03:37,664 main.py:52] epoch 1214, training loss: 7741.16, average training loss: 8188.88, base loss: 16012.72
[INFO 2017-07-01 17:03:40,568 main.py:52] epoch 1215, training loss: 7429.48, average training loss: 8187.40, base loss: 16011.65
[INFO 2017-07-01 17:03:43,417 main.py:52] epoch 1216, training loss: 7279.30, average training loss: 8185.55, base loss: 16008.75
[INFO 2017-07-01 17:03:46,332 main.py:52] epoch 1217, training loss: 7469.39, average training loss: 8184.84, base loss: 16007.06
[INFO 2017-07-01 17:03:49,240 main.py:52] epoch 1218, training loss: 7830.41, average training loss: 8184.31, base loss: 16006.93
[INFO 2017-07-01 17:03:52,117 main.py:52] epoch 1219, training loss: 7625.43, average training loss: 8183.35, base loss: 16006.85
[INFO 2017-07-01 17:03:54,962 main.py:52] epoch 1220, training loss: 7636.40, average training loss: 8182.07, base loss: 16005.87
[INFO 2017-07-01 17:03:57,830 main.py:52] epoch 1221, training loss: 8329.94, average training loss: 8181.09, base loss: 16007.77
[INFO 2017-07-01 17:04:00,687 main.py:52] epoch 1222, training loss: 7478.79, average training loss: 8178.78, base loss: 16007.26
[INFO 2017-07-01 17:04:03,542 main.py:52] epoch 1223, training loss: 7221.46, average training loss: 8178.19, base loss: 16005.09
[INFO 2017-07-01 17:04:06,423 main.py:52] epoch 1224, training loss: 7534.98, average training loss: 8176.40, base loss: 16003.73
[INFO 2017-07-01 17:04:09,305 main.py:52] epoch 1225, training loss: 8293.91, average training loss: 8175.53, base loss: 16003.20
[INFO 2017-07-01 17:04:12,191 main.py:52] epoch 1226, training loss: 7621.66, average training loss: 8173.06, base loss: 16002.99
[INFO 2017-07-01 17:04:15,051 main.py:52] epoch 1227, training loss: 7901.94, average training loss: 8171.97, base loss: 16003.60
[INFO 2017-07-01 17:04:17,957 main.py:52] epoch 1228, training loss: 7202.36, average training loss: 8170.23, base loss: 16002.64
[INFO 2017-07-01 17:04:20,836 main.py:52] epoch 1229, training loss: 7920.73, average training loss: 8169.05, base loss: 16002.99
[INFO 2017-07-01 17:04:23,699 main.py:52] epoch 1230, training loss: 7215.46, average training loss: 8167.69, base loss: 16002.82
[INFO 2017-07-01 17:04:26,596 main.py:52] epoch 1231, training loss: 7528.69, average training loss: 8165.87, base loss: 16001.46
[INFO 2017-07-01 17:04:29,478 main.py:52] epoch 1232, training loss: 7724.74, average training loss: 8164.99, base loss: 15999.89
[INFO 2017-07-01 17:04:32,351 main.py:52] epoch 1233, training loss: 8076.18, average training loss: 8164.82, base loss: 15999.99
[INFO 2017-07-01 17:04:35,226 main.py:52] epoch 1234, training loss: 8024.32, average training loss: 8163.85, base loss: 16001.35
[INFO 2017-07-01 17:04:38,075 main.py:52] epoch 1235, training loss: 7499.63, average training loss: 8162.15, base loss: 16000.22
[INFO 2017-07-01 17:04:40,939 main.py:52] epoch 1236, training loss: 8208.87, average training loss: 8160.87, base loss: 16002.47
[INFO 2017-07-01 17:04:43,829 main.py:52] epoch 1237, training loss: 7073.35, average training loss: 8158.94, base loss: 16001.12
[INFO 2017-07-01 17:04:46,725 main.py:52] epoch 1238, training loss: 7684.78, average training loss: 8157.50, base loss: 16000.71
[INFO 2017-07-01 17:04:49,594 main.py:52] epoch 1239, training loss: 7218.37, average training loss: 8155.15, base loss: 15999.98
[INFO 2017-07-01 17:04:52,498 main.py:52] epoch 1240, training loss: 7572.41, average training loss: 8153.03, base loss: 16000.02
[INFO 2017-07-01 17:04:55,377 main.py:52] epoch 1241, training loss: 7405.24, average training loss: 8150.86, base loss: 15999.61
[INFO 2017-07-01 17:04:58,262 main.py:52] epoch 1242, training loss: 7624.71, average training loss: 8150.60, base loss: 15999.94
[INFO 2017-07-01 17:05:01,118 main.py:52] epoch 1243, training loss: 8314.48, average training loss: 8149.62, base loss: 16002.92
[INFO 2017-07-01 17:05:03,998 main.py:52] epoch 1244, training loss: 7795.20, average training loss: 8148.61, base loss: 16002.95
[INFO 2017-07-01 17:05:06,923 main.py:52] epoch 1245, training loss: 7417.77, average training loss: 8147.00, base loss: 16002.21
[INFO 2017-07-01 17:05:09,788 main.py:52] epoch 1246, training loss: 7757.08, average training loss: 8144.96, base loss: 16003.30
[INFO 2017-07-01 17:05:12,660 main.py:52] epoch 1247, training loss: 7725.30, average training loss: 8143.84, base loss: 16004.73
[INFO 2017-07-01 17:05:15,519 main.py:52] epoch 1248, training loss: 8154.47, average training loss: 8142.05, base loss: 16004.09
[INFO 2017-07-01 17:05:18,376 main.py:52] epoch 1249, training loss: 8039.99, average training loss: 8141.92, base loss: 16004.76
[INFO 2017-07-01 17:05:21,245 main.py:52] epoch 1250, training loss: 8265.12, average training loss: 8141.14, base loss: 16005.37
[INFO 2017-07-01 17:05:24,119 main.py:52] epoch 1251, training loss: 8081.35, average training loss: 8140.54, base loss: 16006.54
[INFO 2017-07-01 17:05:26,983 main.py:52] epoch 1252, training loss: 8150.78, average training loss: 8140.15, base loss: 16006.58
[INFO 2017-07-01 17:05:29,855 main.py:52] epoch 1253, training loss: 7603.26, average training loss: 8138.75, base loss: 16004.76
[INFO 2017-07-01 17:05:32,762 main.py:52] epoch 1254, training loss: 7305.33, average training loss: 8137.01, base loss: 16005.00
[INFO 2017-07-01 17:05:35,658 main.py:52] epoch 1255, training loss: 8221.62, average training loss: 8136.03, base loss: 16006.96
[INFO 2017-07-01 17:05:38,527 main.py:52] epoch 1256, training loss: 7164.83, average training loss: 8134.87, base loss: 16004.51
[INFO 2017-07-01 17:05:41,436 main.py:52] epoch 1257, training loss: 8230.08, average training loss: 8134.44, base loss: 16005.10
[INFO 2017-07-01 17:05:44,355 main.py:52] epoch 1258, training loss: 8307.94, average training loss: 8134.16, base loss: 16008.00
[INFO 2017-07-01 17:05:47,242 main.py:52] epoch 1259, training loss: 7282.81, average training loss: 8131.75, base loss: 16006.51
[INFO 2017-07-01 17:05:50,175 main.py:52] epoch 1260, training loss: 7402.79, average training loss: 8131.27, base loss: 16005.56
[INFO 2017-07-01 17:05:53,049 main.py:52] epoch 1261, training loss: 8324.99, average training loss: 8129.81, base loss: 16007.47
[INFO 2017-07-01 17:05:55,948 main.py:52] epoch 1262, training loss: 7983.81, average training loss: 8129.62, base loss: 16008.77
[INFO 2017-07-01 17:05:58,824 main.py:52] epoch 1263, training loss: 7385.17, average training loss: 8127.10, base loss: 16007.99
[INFO 2017-07-01 17:06:01,765 main.py:52] epoch 1264, training loss: 7790.74, average training loss: 8126.40, base loss: 16007.15
[INFO 2017-07-01 17:06:04,647 main.py:52] epoch 1265, training loss: 8006.34, average training loss: 8124.98, base loss: 16006.76
[INFO 2017-07-01 17:06:07,537 main.py:52] epoch 1266, training loss: 7387.74, average training loss: 8123.54, base loss: 16005.97
[INFO 2017-07-01 17:06:10,406 main.py:52] epoch 1267, training loss: 7256.58, average training loss: 8121.95, base loss: 16005.32
[INFO 2017-07-01 17:06:13,290 main.py:52] epoch 1268, training loss: 7917.24, average training loss: 8121.08, base loss: 16005.18
[INFO 2017-07-01 17:06:16,174 main.py:52] epoch 1269, training loss: 7626.84, average training loss: 8119.96, base loss: 16003.72
[INFO 2017-07-01 17:06:19,022 main.py:52] epoch 1270, training loss: 7193.01, average training loss: 8118.30, base loss: 16001.54
[INFO 2017-07-01 17:06:21,946 main.py:52] epoch 1271, training loss: 7465.38, average training loss: 8116.92, base loss: 15999.34
[INFO 2017-07-01 17:06:24,794 main.py:52] epoch 1272, training loss: 8044.86, average training loss: 8115.08, base loss: 16000.24
[INFO 2017-07-01 17:06:27,683 main.py:52] epoch 1273, training loss: 8129.53, average training loss: 8114.72, base loss: 16000.62
[INFO 2017-07-01 17:06:30,643 main.py:52] epoch 1274, training loss: 7058.95, average training loss: 8111.79, base loss: 15998.45
[INFO 2017-07-01 17:06:33,542 main.py:52] epoch 1275, training loss: 7965.30, average training loss: 8110.50, base loss: 15998.34
[INFO 2017-07-01 17:06:36,429 main.py:52] epoch 1276, training loss: 7599.17, average training loss: 8109.15, base loss: 15998.67
[INFO 2017-07-01 17:06:39,315 main.py:52] epoch 1277, training loss: 7459.02, average training loss: 8108.16, base loss: 15998.30
[INFO 2017-07-01 17:06:42,259 main.py:52] epoch 1278, training loss: 7684.64, average training loss: 8106.17, base loss: 15999.60
[INFO 2017-07-01 17:06:45,143 main.py:52] epoch 1279, training loss: 8266.42, average training loss: 8105.39, base loss: 16002.95
[INFO 2017-07-01 17:06:48,028 main.py:52] epoch 1280, training loss: 7877.74, average training loss: 8105.05, base loss: 16002.75
[INFO 2017-07-01 17:06:50,894 main.py:52] epoch 1281, training loss: 7446.33, average training loss: 8103.13, base loss: 16002.92
[INFO 2017-07-01 17:06:53,771 main.py:52] epoch 1282, training loss: 7715.23, average training loss: 8101.17, base loss: 16002.26
[INFO 2017-07-01 17:06:56,631 main.py:52] epoch 1283, training loss: 7510.87, average training loss: 8100.09, base loss: 16001.35
[INFO 2017-07-01 17:06:59,554 main.py:52] epoch 1284, training loss: 7765.49, average training loss: 8098.05, base loss: 16001.94
[INFO 2017-07-01 17:07:02,409 main.py:52] epoch 1285, training loss: 8254.64, average training loss: 8097.65, base loss: 16003.45
[INFO 2017-07-01 17:07:05,300 main.py:52] epoch 1286, training loss: 7768.93, average training loss: 8095.31, base loss: 16004.14
[INFO 2017-07-01 17:07:08,227 main.py:52] epoch 1287, training loss: 7982.98, average training loss: 8093.98, base loss: 16006.50
[INFO 2017-07-01 17:07:11,072 main.py:52] epoch 1288, training loss: 7167.81, average training loss: 8091.75, base loss: 16005.44
[INFO 2017-07-01 17:07:13,925 main.py:52] epoch 1289, training loss: 7170.33, average training loss: 8090.38, base loss: 16003.91
[INFO 2017-07-01 17:07:16,798 main.py:52] epoch 1290, training loss: 7631.36, average training loss: 8089.72, base loss: 16003.71
[INFO 2017-07-01 17:07:19,689 main.py:52] epoch 1291, training loss: 7562.04, average training loss: 8088.55, base loss: 16003.46
[INFO 2017-07-01 17:07:22,591 main.py:52] epoch 1292, training loss: 7442.42, average training loss: 8086.48, base loss: 16002.52
[INFO 2017-07-01 17:07:25,451 main.py:52] epoch 1293, training loss: 7926.62, average training loss: 8086.42, base loss: 16001.08
[INFO 2017-07-01 17:07:28,323 main.py:52] epoch 1294, training loss: 7066.83, average training loss: 8084.08, base loss: 15999.41
[INFO 2017-07-01 17:07:31,211 main.py:52] epoch 1295, training loss: 7107.66, average training loss: 8082.89, base loss: 15997.70
[INFO 2017-07-01 17:07:34,078 main.py:52] epoch 1296, training loss: 7367.04, average training loss: 8082.06, base loss: 15996.82
[INFO 2017-07-01 17:07:37,015 main.py:52] epoch 1297, training loss: 7681.39, average training loss: 8081.33, base loss: 15996.37
[INFO 2017-07-01 17:07:39,888 main.py:52] epoch 1298, training loss: 7549.84, average training loss: 8080.26, base loss: 15996.35
[INFO 2017-07-01 17:07:42,779 main.py:52] epoch 1299, training loss: 8062.62, average training loss: 8079.85, base loss: 15997.81
[INFO 2017-07-01 17:07:42,779 main.py:54] epoch 1299, testing
[INFO 2017-07-01 17:07:55,174 main.py:97] average testing loss: 7575.54, base loss: 15901.87
[INFO 2017-07-01 17:07:55,175 main.py:98] improve_loss: 8326.33, improve_percent: 0.52
[INFO 2017-07-01 17:07:55,177 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 17:07:55,203 main.py:66] current best improved percent: 0.52
[INFO 2017-07-01 17:07:58,090 main.py:52] epoch 1300, training loss: 7446.16, average training loss: 8079.29, base loss: 15997.86
[INFO 2017-07-01 17:08:00,928 main.py:52] epoch 1301, training loss: 7517.94, average training loss: 8077.94, base loss: 15998.39
[INFO 2017-07-01 17:08:03,820 main.py:52] epoch 1302, training loss: 6850.00, average training loss: 8076.43, base loss: 15995.47
[INFO 2017-07-01 17:08:06,674 main.py:52] epoch 1303, training loss: 8257.01, average training loss: 8075.29, base loss: 15997.35
[INFO 2017-07-01 17:08:09,537 main.py:52] epoch 1304, training loss: 7099.85, average training loss: 8072.68, base loss: 15995.09
[INFO 2017-07-01 17:08:12,410 main.py:52] epoch 1305, training loss: 7705.03, average training loss: 8072.28, base loss: 15994.92
[INFO 2017-07-01 17:08:15,243 main.py:52] epoch 1306, training loss: 6818.03, average training loss: 8070.24, base loss: 15991.89
[INFO 2017-07-01 17:08:18,093 main.py:52] epoch 1307, training loss: 7467.15, average training loss: 8068.32, base loss: 15991.40
[INFO 2017-07-01 17:08:20,952 main.py:52] epoch 1308, training loss: 8107.32, average training loss: 8067.57, base loss: 15991.09
[INFO 2017-07-01 17:08:23,850 main.py:52] epoch 1309, training loss: 7756.35, average training loss: 8065.83, base loss: 15990.65
[INFO 2017-07-01 17:08:26,734 main.py:52] epoch 1310, training loss: 8330.57, average training loss: 8066.01, base loss: 15993.08
[INFO 2017-07-01 17:08:29,643 main.py:52] epoch 1311, training loss: 7812.43, average training loss: 8065.30, base loss: 15994.04
[INFO 2017-07-01 17:08:32,525 main.py:52] epoch 1312, training loss: 7777.35, average training loss: 8065.41, base loss: 15994.44
[INFO 2017-07-01 17:08:35,409 main.py:52] epoch 1313, training loss: 7454.47, average training loss: 8064.12, base loss: 15993.61
[INFO 2017-07-01 17:08:38,295 main.py:52] epoch 1314, training loss: 7555.70, average training loss: 8063.35, base loss: 15993.10
[INFO 2017-07-01 17:08:41,155 main.py:52] epoch 1315, training loss: 7257.10, average training loss: 8062.33, base loss: 15993.10
[INFO 2017-07-01 17:08:44,036 main.py:52] epoch 1316, training loss: 7160.55, average training loss: 8060.10, base loss: 15990.65
[INFO 2017-07-01 17:08:46,934 main.py:52] epoch 1317, training loss: 8866.30, average training loss: 8060.26, base loss: 15992.15
[INFO 2017-07-01 17:08:49,814 main.py:52] epoch 1318, training loss: 7574.19, average training loss: 8059.54, base loss: 15990.31
[INFO 2017-07-01 17:08:52,657 main.py:52] epoch 1319, training loss: 7636.04, average training loss: 8058.57, base loss: 15989.01
[INFO 2017-07-01 17:08:55,566 main.py:52] epoch 1320, training loss: 7037.29, average training loss: 8057.35, base loss: 15987.55
[INFO 2017-07-01 17:08:58,477 main.py:52] epoch 1321, training loss: 7563.27, average training loss: 8056.28, base loss: 15988.09
[INFO 2017-07-01 17:09:01,346 main.py:52] epoch 1322, training loss: 8274.81, average training loss: 8055.84, base loss: 15989.58
[INFO 2017-07-01 17:09:04,240 main.py:52] epoch 1323, training loss: 8331.22, average training loss: 8055.14, base loss: 15991.94
[INFO 2017-07-01 17:09:07,116 main.py:52] epoch 1324, training loss: 7782.85, average training loss: 8053.96, base loss: 15993.39
[INFO 2017-07-01 17:09:10,020 main.py:52] epoch 1325, training loss: 7963.14, average training loss: 8052.91, base loss: 15993.37
[INFO 2017-07-01 17:09:12,896 main.py:52] epoch 1326, training loss: 7702.79, average training loss: 8052.54, base loss: 15994.32
[INFO 2017-07-01 17:09:15,794 main.py:52] epoch 1327, training loss: 7846.43, average training loss: 8052.34, base loss: 15995.77
[INFO 2017-07-01 17:09:18,718 main.py:52] epoch 1328, training loss: 7268.67, average training loss: 8050.80, base loss: 15994.24
[INFO 2017-07-01 17:09:21,598 main.py:52] epoch 1329, training loss: 7661.71, average training loss: 8049.71, base loss: 15992.42
[INFO 2017-07-01 17:09:24,472 main.py:52] epoch 1330, training loss: 7861.39, average training loss: 8048.39, base loss: 15991.38
[INFO 2017-07-01 17:09:27,327 main.py:52] epoch 1331, training loss: 6858.39, average training loss: 8047.29, base loss: 15987.21
[INFO 2017-07-01 17:09:30,214 main.py:52] epoch 1332, training loss: 7645.12, average training loss: 8046.64, base loss: 15985.50
[INFO 2017-07-01 17:09:33,095 main.py:52] epoch 1333, training loss: 8191.14, average training loss: 8046.21, base loss: 15985.28
[INFO 2017-07-01 17:09:35,998 main.py:52] epoch 1334, training loss: 7517.84, average training loss: 8046.12, base loss: 15983.62
[INFO 2017-07-01 17:09:38,852 main.py:52] epoch 1335, training loss: 7795.30, average training loss: 8045.39, base loss: 15982.98
[INFO 2017-07-01 17:09:41,710 main.py:52] epoch 1336, training loss: 7724.78, average training loss: 8044.29, base loss: 15983.31
[INFO 2017-07-01 17:09:44,612 main.py:52] epoch 1337, training loss: 7309.59, average training loss: 8043.42, base loss: 15982.65
[INFO 2017-07-01 17:09:47,509 main.py:52] epoch 1338, training loss: 7795.63, average training loss: 8042.90, base loss: 15983.00
[INFO 2017-07-01 17:09:50,394 main.py:52] epoch 1339, training loss: 8111.90, average training loss: 8041.83, base loss: 15984.27
[INFO 2017-07-01 17:09:53,234 main.py:52] epoch 1340, training loss: 8004.97, average training loss: 8041.48, base loss: 15984.23
[INFO 2017-07-01 17:09:56,129 main.py:52] epoch 1341, training loss: 7476.26, average training loss: 8040.52, base loss: 15983.28
[INFO 2017-07-01 17:09:58,975 main.py:52] epoch 1342, training loss: 7459.23, average training loss: 8039.63, base loss: 15982.82
[INFO 2017-07-01 17:10:01,838 main.py:52] epoch 1343, training loss: 7628.08, average training loss: 8038.61, base loss: 15982.94
[INFO 2017-07-01 17:10:04,736 main.py:52] epoch 1344, training loss: 7480.65, average training loss: 8037.45, base loss: 15983.57
[INFO 2017-07-01 17:10:07,654 main.py:52] epoch 1345, training loss: 7759.55, average training loss: 8037.35, base loss: 15985.09
[INFO 2017-07-01 17:10:10,555 main.py:52] epoch 1346, training loss: 7771.21, average training loss: 8036.21, base loss: 15984.69
[INFO 2017-07-01 17:10:13,415 main.py:52] epoch 1347, training loss: 7475.64, average training loss: 8034.24, base loss: 15984.03
[INFO 2017-07-01 17:10:16,288 main.py:52] epoch 1348, training loss: 7118.94, average training loss: 8033.61, base loss: 15982.99
[INFO 2017-07-01 17:10:19,126 main.py:52] epoch 1349, training loss: 7933.17, average training loss: 8033.22, base loss: 15984.66
[INFO 2017-07-01 17:10:22,012 main.py:52] epoch 1350, training loss: 7625.11, average training loss: 8032.70, base loss: 15985.88
[INFO 2017-07-01 17:10:24,903 main.py:52] epoch 1351, training loss: 7153.18, average training loss: 8031.67, base loss: 15985.00
[INFO 2017-07-01 17:10:27,739 main.py:52] epoch 1352, training loss: 8056.33, average training loss: 8030.26, base loss: 15986.05
[INFO 2017-07-01 17:10:30,650 main.py:52] epoch 1353, training loss: 8127.00, average training loss: 8030.08, base loss: 15987.49
[INFO 2017-07-01 17:10:33,505 main.py:52] epoch 1354, training loss: 7115.87, average training loss: 8028.82, base loss: 15987.71
[INFO 2017-07-01 17:10:36,423 main.py:52] epoch 1355, training loss: 7688.34, average training loss: 8027.20, base loss: 15987.79
[INFO 2017-07-01 17:10:39,325 main.py:52] epoch 1356, training loss: 7700.93, average training loss: 8026.35, base loss: 15988.26
[INFO 2017-07-01 17:10:42,178 main.py:52] epoch 1357, training loss: 7361.93, average training loss: 8024.65, base loss: 15987.19
[INFO 2017-07-01 17:10:45,035 main.py:52] epoch 1358, training loss: 7526.18, average training loss: 8023.50, base loss: 15985.96
[INFO 2017-07-01 17:10:47,866 main.py:52] epoch 1359, training loss: 7252.97, average training loss: 8022.61, base loss: 15983.66
[INFO 2017-07-01 17:10:50,774 main.py:52] epoch 1360, training loss: 7850.84, average training loss: 8021.99, base loss: 15986.52
[INFO 2017-07-01 17:10:53,657 main.py:52] epoch 1361, training loss: 7614.48, average training loss: 8020.30, base loss: 15987.92
[INFO 2017-07-01 17:10:56,530 main.py:52] epoch 1362, training loss: 7675.14, average training loss: 8018.61, base loss: 15987.90
[INFO 2017-07-01 17:10:59,457 main.py:52] epoch 1363, training loss: 7775.95, average training loss: 8017.62, base loss: 15988.12
[INFO 2017-07-01 17:11:02,339 main.py:52] epoch 1364, training loss: 8035.39, average training loss: 8017.54, base loss: 15987.87
[INFO 2017-07-01 17:11:05,243 main.py:52] epoch 1365, training loss: 7457.14, average training loss: 8016.84, base loss: 15986.96
[INFO 2017-07-01 17:11:08,122 main.py:52] epoch 1366, training loss: 7557.30, average training loss: 8015.39, base loss: 15986.24
[INFO 2017-07-01 17:11:10,949 main.py:52] epoch 1367, training loss: 7596.97, average training loss: 8014.57, base loss: 15985.32
[INFO 2017-07-01 17:11:13,850 main.py:52] epoch 1368, training loss: 7603.28, average training loss: 8013.93, base loss: 15985.85
[INFO 2017-07-01 17:11:16,756 main.py:52] epoch 1369, training loss: 7536.61, average training loss: 8013.07, base loss: 15985.98
[INFO 2017-07-01 17:11:19,650 main.py:52] epoch 1370, training loss: 7836.55, average training loss: 8012.24, base loss: 15987.21
[INFO 2017-07-01 17:11:22,527 main.py:52] epoch 1371, training loss: 7691.43, average training loss: 8011.36, base loss: 15986.94
[INFO 2017-07-01 17:11:25,418 main.py:52] epoch 1372, training loss: 7720.74, average training loss: 8010.18, base loss: 15987.14
[INFO 2017-07-01 17:11:28,293 main.py:52] epoch 1373, training loss: 7475.12, average training loss: 8009.78, base loss: 15985.90
[INFO 2017-07-01 17:11:31,158 main.py:52] epoch 1374, training loss: 7947.82, average training loss: 8008.89, base loss: 15988.79
[INFO 2017-07-01 17:11:34,058 main.py:52] epoch 1375, training loss: 7686.64, average training loss: 8007.98, base loss: 15989.86
[INFO 2017-07-01 17:11:36,894 main.py:52] epoch 1376, training loss: 7543.28, average training loss: 8005.52, base loss: 15991.17
[INFO 2017-07-01 17:11:39,754 main.py:52] epoch 1377, training loss: 7550.15, average training loss: 8004.47, base loss: 15991.48
[INFO 2017-07-01 17:11:42,627 main.py:52] epoch 1378, training loss: 7488.42, average training loss: 8002.85, base loss: 15992.19
[INFO 2017-07-01 17:11:45,512 main.py:52] epoch 1379, training loss: 7741.26, average training loss: 8002.11, base loss: 15993.00
[INFO 2017-07-01 17:11:48,408 main.py:52] epoch 1380, training loss: 7652.31, average training loss: 8000.27, base loss: 15992.80
[INFO 2017-07-01 17:11:51,271 main.py:52] epoch 1381, training loss: 7780.16, average training loss: 7999.60, base loss: 15992.64
[INFO 2017-07-01 17:11:54,140 main.py:52] epoch 1382, training loss: 7065.52, average training loss: 7997.98, base loss: 15990.14
[INFO 2017-07-01 17:11:57,000 main.py:52] epoch 1383, training loss: 8037.01, average training loss: 7998.09, base loss: 15990.53
[INFO 2017-07-01 17:11:59,900 main.py:52] epoch 1384, training loss: 7698.76, average training loss: 7996.60, base loss: 15991.44
[INFO 2017-07-01 17:12:02,758 main.py:52] epoch 1385, training loss: 8190.32, average training loss: 7995.59, base loss: 15993.52
[INFO 2017-07-01 17:12:05,642 main.py:52] epoch 1386, training loss: 7464.08, average training loss: 7993.89, base loss: 15992.57
[INFO 2017-07-01 17:12:08,529 main.py:52] epoch 1387, training loss: 7189.51, average training loss: 7992.44, base loss: 15991.71
[INFO 2017-07-01 17:12:11,423 main.py:52] epoch 1388, training loss: 7857.10, average training loss: 7992.25, base loss: 15991.61
[INFO 2017-07-01 17:12:14,299 main.py:52] epoch 1389, training loss: 6961.58, average training loss: 7990.84, base loss: 15989.85
[INFO 2017-07-01 17:12:17,162 main.py:52] epoch 1390, training loss: 7541.18, average training loss: 7990.06, base loss: 15989.31
[INFO 2017-07-01 17:12:20,046 main.py:52] epoch 1391, training loss: 7883.08, average training loss: 7989.37, base loss: 15988.68
[INFO 2017-07-01 17:12:22,937 main.py:52] epoch 1392, training loss: 7307.97, average training loss: 7987.95, base loss: 15987.82
[INFO 2017-07-01 17:12:25,826 main.py:52] epoch 1393, training loss: 7703.50, average training loss: 7987.52, base loss: 15988.27
[INFO 2017-07-01 17:12:28,670 main.py:52] epoch 1394, training loss: 7566.86, average training loss: 7987.22, base loss: 15989.11
[INFO 2017-07-01 17:12:31,545 main.py:52] epoch 1395, training loss: 6984.81, average training loss: 7985.24, base loss: 15988.15
[INFO 2017-07-01 17:12:34,423 main.py:52] epoch 1396, training loss: 7793.10, average training loss: 7984.15, base loss: 15990.98
[INFO 2017-07-01 17:12:37,353 main.py:52] epoch 1397, training loss: 7476.82, average training loss: 7982.89, base loss: 15991.55
[INFO 2017-07-01 17:12:40,262 main.py:52] epoch 1398, training loss: 7749.49, average training loss: 7982.30, base loss: 15989.61
[INFO 2017-07-01 17:12:43,146 main.py:52] epoch 1399, training loss: 7427.02, average training loss: 7981.47, base loss: 15987.85
[INFO 2017-07-01 17:12:43,146 main.py:54] epoch 1399, testing
[INFO 2017-07-01 17:12:55,536 main.py:97] average testing loss: 7521.68, base loss: 16063.72
[INFO 2017-07-01 17:12:55,536 main.py:98] improve_loss: 8542.04, improve_percent: 0.53
[INFO 2017-07-01 17:12:55,537 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 17:12:55,563 main.py:66] current best improved percent: 0.53
[INFO 2017-07-01 17:12:58,471 main.py:52] epoch 1400, training loss: 7622.72, average training loss: 7980.71, base loss: 15987.40
[INFO 2017-07-01 17:13:01,329 main.py:52] epoch 1401, training loss: 7812.95, average training loss: 7979.88, base loss: 15988.78
[INFO 2017-07-01 17:13:04,174 main.py:52] epoch 1402, training loss: 7000.17, average training loss: 7978.39, base loss: 15987.06
[INFO 2017-07-01 17:13:07,034 main.py:52] epoch 1403, training loss: 7493.22, average training loss: 7977.40, base loss: 15987.24
[INFO 2017-07-01 17:13:09,858 main.py:52] epoch 1404, training loss: 7229.15, average training loss: 7976.17, base loss: 15986.71
[INFO 2017-07-01 17:13:12,739 main.py:52] epoch 1405, training loss: 7973.14, average training loss: 7975.78, base loss: 15988.53
[INFO 2017-07-01 17:13:15,569 main.py:52] epoch 1406, training loss: 7230.31, average training loss: 7974.49, base loss: 15985.78
[INFO 2017-07-01 17:13:18,436 main.py:52] epoch 1407, training loss: 7835.50, average training loss: 7974.20, base loss: 15986.02
[INFO 2017-07-01 17:13:21,325 main.py:52] epoch 1408, training loss: 7906.95, average training loss: 7973.55, base loss: 15985.94
[INFO 2017-07-01 17:13:24,173 main.py:52] epoch 1409, training loss: 7940.73, average training loss: 7972.66, base loss: 15986.45
[INFO 2017-07-01 17:13:27,080 main.py:52] epoch 1410, training loss: 7830.51, average training loss: 7971.82, base loss: 15987.08
[INFO 2017-07-01 17:13:30,003 main.py:52] epoch 1411, training loss: 8048.83, average training loss: 7971.51, base loss: 15989.11
[INFO 2017-07-01 17:13:32,866 main.py:52] epoch 1412, training loss: 7539.11, average training loss: 7971.12, base loss: 15989.94
[INFO 2017-07-01 17:13:35,697 main.py:52] epoch 1413, training loss: 7873.76, average training loss: 7970.95, base loss: 15989.85
[INFO 2017-07-01 17:13:38,596 main.py:52] epoch 1414, training loss: 7010.77, average training loss: 7969.03, base loss: 15988.32
[INFO 2017-07-01 17:13:41,490 main.py:52] epoch 1415, training loss: 7763.61, average training loss: 7967.38, base loss: 15988.89
[INFO 2017-07-01 17:13:44,363 main.py:52] epoch 1416, training loss: 7962.87, average training loss: 7966.47, base loss: 15990.15
[INFO 2017-07-01 17:13:47,206 main.py:52] epoch 1417, training loss: 7251.14, average training loss: 7964.69, base loss: 15989.81
[INFO 2017-07-01 17:13:50,082 main.py:52] epoch 1418, training loss: 7413.62, average training loss: 7963.35, base loss: 15989.46
[INFO 2017-07-01 17:13:52,953 main.py:52] epoch 1419, training loss: 7557.95, average training loss: 7962.46, base loss: 15989.60
[INFO 2017-07-01 17:13:55,780 main.py:52] epoch 1420, training loss: 7631.69, average training loss: 7961.70, base loss: 15990.45
[INFO 2017-07-01 17:13:58,675 main.py:52] epoch 1421, training loss: 7596.91, average training loss: 7960.84, base loss: 15991.58
[INFO 2017-07-01 17:14:01,575 main.py:52] epoch 1422, training loss: 7169.12, average training loss: 7960.09, base loss: 15990.03
[INFO 2017-07-01 17:14:04,466 main.py:52] epoch 1423, training loss: 7075.35, average training loss: 7958.04, base loss: 15988.98
[INFO 2017-07-01 17:14:07,349 main.py:52] epoch 1424, training loss: 7736.43, average training loss: 7957.26, base loss: 15990.23
[INFO 2017-07-01 17:14:10,219 main.py:52] epoch 1425, training loss: 7515.35, average training loss: 7956.33, base loss: 15991.85
[INFO 2017-07-01 17:14:13,272 main.py:52] epoch 1426, training loss: 7504.13, average training loss: 7955.79, base loss: 15992.35
[INFO 2017-07-01 17:14:16,250 main.py:52] epoch 1427, training loss: 7705.28, average training loss: 7955.46, base loss: 15992.98
[INFO 2017-07-01 17:14:19,102 main.py:52] epoch 1428, training loss: 7314.16, average training loss: 7954.43, base loss: 15992.88
[INFO 2017-07-01 17:14:21,974 main.py:52] epoch 1429, training loss: 7365.15, average training loss: 7952.90, base loss: 15993.42
[INFO 2017-07-01 17:14:24,859 main.py:52] epoch 1430, training loss: 8595.32, average training loss: 7953.87, base loss: 15994.93
[INFO 2017-07-01 17:14:27,713 main.py:52] epoch 1431, training loss: 7558.69, average training loss: 7952.60, base loss: 15993.15
[INFO 2017-07-01 17:14:30,579 main.py:52] epoch 1432, training loss: 7549.04, average training loss: 7950.87, base loss: 15993.05
[INFO 2017-07-01 17:14:33,476 main.py:52] epoch 1433, training loss: 7195.50, average training loss: 7949.00, base loss: 15990.79
[INFO 2017-07-01 17:14:36,390 main.py:52] epoch 1434, training loss: 8333.62, average training loss: 7948.87, base loss: 15993.23
[INFO 2017-07-01 17:14:39,282 main.py:52] epoch 1435, training loss: 7597.08, average training loss: 7948.66, base loss: 15993.69
[INFO 2017-07-01 17:14:42,177 main.py:52] epoch 1436, training loss: 7195.31, average training loss: 7947.41, base loss: 15992.25
[INFO 2017-07-01 17:14:45,007 main.py:52] epoch 1437, training loss: 7593.55, average training loss: 7947.08, base loss: 15990.09
[INFO 2017-07-01 17:14:47,903 main.py:52] epoch 1438, training loss: 7464.95, average training loss: 7946.32, base loss: 15990.23
[INFO 2017-07-01 17:14:50,797 main.py:52] epoch 1439, training loss: 7956.08, average training loss: 7945.74, base loss: 15990.77
[INFO 2017-07-01 17:14:53,687 main.py:52] epoch 1440, training loss: 8678.94, average training loss: 7946.08, base loss: 15993.38
[INFO 2017-07-01 17:14:56,814 main.py:52] epoch 1441, training loss: 7833.25, average training loss: 7944.87, base loss: 15994.30
[INFO 2017-07-01 17:14:59,677 main.py:52] epoch 1442, training loss: 7310.61, average training loss: 7943.83, base loss: 15993.77
[INFO 2017-07-01 17:15:02,652 main.py:52] epoch 1443, training loss: 7906.96, average training loss: 7942.97, base loss: 15995.14
[INFO 2017-07-01 17:15:05,490 main.py:52] epoch 1444, training loss: 7702.90, average training loss: 7941.57, base loss: 15994.31
[INFO 2017-07-01 17:15:08,397 main.py:52] epoch 1445, training loss: 8117.78, average training loss: 7940.72, base loss: 15994.73
[INFO 2017-07-01 17:15:11,269 main.py:52] epoch 1446, training loss: 7987.52, average training loss: 7940.16, base loss: 15995.80
[INFO 2017-07-01 17:15:14,148 main.py:52] epoch 1447, training loss: 7655.16, average training loss: 7939.77, base loss: 15995.96
[INFO 2017-07-01 17:15:17,061 main.py:52] epoch 1448, training loss: 7741.87, average training loss: 7939.60, base loss: 15997.67
[INFO 2017-07-01 17:15:19,987 main.py:52] epoch 1449, training loss: 7152.68, average training loss: 7937.51, base loss: 15997.27
[INFO 2017-07-01 17:15:22,837 main.py:52] epoch 1450, training loss: 7322.66, average training loss: 7936.52, base loss: 15995.27
[INFO 2017-07-01 17:15:25,693 main.py:52] epoch 1451, training loss: 6725.40, average training loss: 7934.64, base loss: 15992.77
[INFO 2017-07-01 17:15:28,572 main.py:52] epoch 1452, training loss: 8167.31, average training loss: 7935.31, base loss: 15994.50
[INFO 2017-07-01 17:15:31,434 main.py:52] epoch 1453, training loss: 7903.09, average training loss: 7934.56, base loss: 15995.69
[INFO 2017-07-01 17:15:34,329 main.py:52] epoch 1454, training loss: 7393.83, average training loss: 7933.03, base loss: 15992.97
[INFO 2017-07-01 17:15:37,185 main.py:52] epoch 1455, training loss: 6973.52, average training loss: 7932.08, base loss: 15989.53
[INFO 2017-07-01 17:15:40,096 main.py:52] epoch 1456, training loss: 7250.64, average training loss: 7931.22, base loss: 15988.28
[INFO 2017-07-01 17:15:42,991 main.py:52] epoch 1457, training loss: 7726.24, average training loss: 7930.01, base loss: 15988.97
[INFO 2017-07-01 17:15:45,863 main.py:52] epoch 1458, training loss: 8107.45, average training loss: 7929.99, base loss: 15990.92
[INFO 2017-07-01 17:15:48,758 main.py:52] epoch 1459, training loss: 8835.84, average training loss: 7930.62, base loss: 15994.80
[INFO 2017-07-01 17:15:51,646 main.py:52] epoch 1460, training loss: 7395.29, average training loss: 7929.83, base loss: 15994.54
[INFO 2017-07-01 17:15:54,506 main.py:52] epoch 1461, training loss: 8199.32, average training loss: 7929.42, base loss: 15997.42
[INFO 2017-07-01 17:15:57,388 main.py:52] epoch 1462, training loss: 7652.16, average training loss: 7928.94, base loss: 15998.77
[INFO 2017-07-01 17:16:00,253 main.py:52] epoch 1463, training loss: 7371.80, average training loss: 7928.32, base loss: 15997.50
[INFO 2017-07-01 17:16:03,147 main.py:52] epoch 1464, training loss: 7698.65, average training loss: 7928.16, base loss: 15998.16
[INFO 2017-07-01 17:16:05,979 main.py:52] epoch 1465, training loss: 7166.69, average training loss: 7925.91, base loss: 15997.91
[INFO 2017-07-01 17:16:08,847 main.py:52] epoch 1466, training loss: 7232.05, average training loss: 7923.90, base loss: 15997.77
[INFO 2017-07-01 17:16:11,755 main.py:52] epoch 1467, training loss: 7731.93, average training loss: 7923.21, base loss: 15998.95
[INFO 2017-07-01 17:16:14,662 main.py:52] epoch 1468, training loss: 8225.63, average training loss: 7922.15, base loss: 16001.85
[INFO 2017-07-01 17:16:17,563 main.py:52] epoch 1469, training loss: 8010.77, average training loss: 7921.63, base loss: 16004.07
[INFO 2017-07-01 17:16:20,452 main.py:52] epoch 1470, training loss: 8265.53, average training loss: 7921.59, base loss: 16005.86
[INFO 2017-07-01 17:16:23,345 main.py:52] epoch 1471, training loss: 7562.13, average training loss: 7920.78, base loss: 16005.43
[INFO 2017-07-01 17:16:26,320 main.py:52] epoch 1472, training loss: 7798.67, average training loss: 7919.67, base loss: 16006.82
[INFO 2017-07-01 17:16:29,168 main.py:52] epoch 1473, training loss: 8272.78, average training loss: 7920.13, base loss: 16009.70
[INFO 2017-07-01 17:16:32,072 main.py:52] epoch 1474, training loss: 6821.68, average training loss: 7919.12, base loss: 16008.11
[INFO 2017-07-01 17:16:34,965 main.py:52] epoch 1475, training loss: 7459.68, average training loss: 7918.12, base loss: 16007.44
[INFO 2017-07-01 17:16:37,868 main.py:52] epoch 1476, training loss: 7545.66, average training loss: 7917.12, base loss: 16006.73
[INFO 2017-07-01 17:16:40,730 main.py:52] epoch 1477, training loss: 7681.12, average training loss: 7915.30, base loss: 16006.57
[INFO 2017-07-01 17:16:43,601 main.py:52] epoch 1478, training loss: 7311.96, average training loss: 7913.96, base loss: 16005.79
[INFO 2017-07-01 17:16:46,472 main.py:52] epoch 1479, training loss: 7564.70, average training loss: 7913.23, base loss: 16005.08
[INFO 2017-07-01 17:16:49,350 main.py:52] epoch 1480, training loss: 7607.11, average training loss: 7912.60, base loss: 16006.10
[INFO 2017-07-01 17:16:52,199 main.py:52] epoch 1481, training loss: 7103.38, average training loss: 7911.46, base loss: 16006.16
[INFO 2017-07-01 17:16:55,079 main.py:52] epoch 1482, training loss: 7753.09, average training loss: 7911.15, base loss: 16008.02
[INFO 2017-07-01 17:16:57,950 main.py:52] epoch 1483, training loss: 7728.55, average training loss: 7910.78, base loss: 16008.52
[INFO 2017-07-01 17:17:00,812 main.py:52] epoch 1484, training loss: 7725.50, average training loss: 7910.96, base loss: 16009.63
[INFO 2017-07-01 17:17:03,646 main.py:52] epoch 1485, training loss: 7016.70, average training loss: 7909.24, base loss: 16008.72
[INFO 2017-07-01 17:17:06,550 main.py:52] epoch 1486, training loss: 7430.71, average training loss: 7908.73, base loss: 16009.65
[INFO 2017-07-01 17:17:09,427 main.py:52] epoch 1487, training loss: 7491.11, average training loss: 7907.63, base loss: 16010.29
[INFO 2017-07-01 17:17:12,295 main.py:52] epoch 1488, training loss: 8414.86, average training loss: 7906.79, base loss: 16013.87
[INFO 2017-07-01 17:17:15,177 main.py:52] epoch 1489, training loss: 7247.68, average training loss: 7905.47, base loss: 16013.50
[INFO 2017-07-01 17:17:18,073 main.py:52] epoch 1490, training loss: 7489.93, average training loss: 7905.13, base loss: 16012.92
[INFO 2017-07-01 17:17:20,943 main.py:52] epoch 1491, training loss: 7724.09, average training loss: 7905.24, base loss: 16010.85
[INFO 2017-07-01 17:17:23,788 main.py:52] epoch 1492, training loss: 7136.88, average training loss: 7903.66, base loss: 16008.89
[INFO 2017-07-01 17:17:26,674 main.py:52] epoch 1493, training loss: 7361.66, average training loss: 7903.30, base loss: 16007.99
[INFO 2017-07-01 17:17:29,539 main.py:52] epoch 1494, training loss: 7488.99, average training loss: 7902.96, base loss: 16007.33
[INFO 2017-07-01 17:17:32,421 main.py:52] epoch 1495, training loss: 7391.32, average training loss: 7901.34, base loss: 16006.88
[INFO 2017-07-01 17:17:35,322 main.py:52] epoch 1496, training loss: 7127.63, average training loss: 7900.09, base loss: 16005.17
[INFO 2017-07-01 17:17:38,177 main.py:52] epoch 1497, training loss: 7210.04, average training loss: 7898.23, base loss: 16004.07
[INFO 2017-07-01 17:17:41,057 main.py:52] epoch 1498, training loss: 7800.05, average training loss: 7897.44, base loss: 16006.42
[INFO 2017-07-01 17:17:43,991 main.py:52] epoch 1499, training loss: 7311.07, average training loss: 7897.23, base loss: 16007.31
[INFO 2017-07-01 17:17:43,991 main.py:54] epoch 1499, testing
[INFO 2017-07-01 17:17:56,250 main.py:97] average testing loss: 7374.59, base loss: 15758.68
[INFO 2017-07-01 17:17:56,250 main.py:98] improve_loss: 8384.09, improve_percent: 0.53
[INFO 2017-07-01 17:17:56,252 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 17:17:56,294 main.py:66] current best improved percent: 0.53
[INFO 2017-07-01 17:17:59,225 main.py:52] epoch 1500, training loss: 7471.76, average training loss: 7895.45, base loss: 16005.60
[INFO 2017-07-01 17:18:02,106 main.py:52] epoch 1501, training loss: 7574.38, average training loss: 7894.65, base loss: 16005.33
[INFO 2017-07-01 17:18:05,020 main.py:52] epoch 1502, training loss: 7017.27, average training loss: 7892.72, base loss: 16003.18
[INFO 2017-07-01 17:18:07,900 main.py:52] epoch 1503, training loss: 7966.93, average training loss: 7891.02, base loss: 16004.93
[INFO 2017-07-01 17:18:10,789 main.py:52] epoch 1504, training loss: 8054.96, average training loss: 7890.46, base loss: 16005.26
[INFO 2017-07-01 17:18:13,673 main.py:52] epoch 1505, training loss: 7631.99, average training loss: 7890.07, base loss: 16004.66
[INFO 2017-07-01 17:18:16,497 main.py:52] epoch 1506, training loss: 7145.56, average training loss: 7888.85, base loss: 16003.65
[INFO 2017-07-01 17:18:19,352 main.py:52] epoch 1507, training loss: 7342.36, average training loss: 7887.74, base loss: 16001.98
[INFO 2017-07-01 17:18:22,223 main.py:52] epoch 1508, training loss: 7408.58, average training loss: 7886.82, base loss: 16000.58
[INFO 2017-07-01 17:18:25,081 main.py:52] epoch 1509, training loss: 7026.16, average training loss: 7885.99, base loss: 15998.73
[INFO 2017-07-01 17:18:27,972 main.py:52] epoch 1510, training loss: 7823.18, average training loss: 7885.13, base loss: 15999.70
[INFO 2017-07-01 17:18:30,854 main.py:52] epoch 1511, training loss: 7153.39, average training loss: 7883.48, base loss: 15998.37
[INFO 2017-07-01 17:18:33,707 main.py:52] epoch 1512, training loss: 7021.50, average training loss: 7882.17, base loss: 15997.30
[INFO 2017-07-01 17:18:36,568 main.py:52] epoch 1513, training loss: 7878.14, average training loss: 7881.78, base loss: 15999.04
[INFO 2017-07-01 17:18:39,420 main.py:52] epoch 1514, training loss: 7675.11, average training loss: 7881.52, base loss: 15999.48
[INFO 2017-07-01 17:18:42,305 main.py:52] epoch 1515, training loss: 8234.10, average training loss: 7881.63, base loss: 16001.89
[INFO 2017-07-01 17:18:45,201 main.py:52] epoch 1516, training loss: 7838.25, average training loss: 7881.03, base loss: 16002.36
[INFO 2017-07-01 17:18:48,106 main.py:52] epoch 1517, training loss: 7583.02, average training loss: 7880.64, base loss: 16003.18
[INFO 2017-07-01 17:18:50,935 main.py:52] epoch 1518, training loss: 7351.55, average training loss: 7879.73, base loss: 16003.53
[INFO 2017-07-01 17:18:53,852 main.py:52] epoch 1519, training loss: 7578.46, average training loss: 7878.85, base loss: 16004.39
[INFO 2017-07-01 17:18:56,747 main.py:52] epoch 1520, training loss: 7741.93, average training loss: 7878.35, base loss: 16004.44
[INFO 2017-07-01 17:18:59,582 main.py:52] epoch 1521, training loss: 7453.93, average training loss: 7877.10, base loss: 16004.81
[INFO 2017-07-01 17:19:02,479 main.py:52] epoch 1522, training loss: 7160.12, average training loss: 7875.93, base loss: 16002.70
[INFO 2017-07-01 17:19:05,371 main.py:52] epoch 1523, training loss: 7902.55, average training loss: 7875.12, base loss: 16003.33
[INFO 2017-07-01 17:19:08,279 main.py:52] epoch 1524, training loss: 7705.97, average training loss: 7875.12, base loss: 16004.01
[INFO 2017-07-01 17:19:11,153 main.py:52] epoch 1525, training loss: 7240.50, average training loss: 7873.59, base loss: 16003.65
[INFO 2017-07-01 17:19:14,023 main.py:52] epoch 1526, training loss: 7302.40, average training loss: 7872.87, base loss: 16003.46
[INFO 2017-07-01 17:19:16,917 main.py:52] epoch 1527, training loss: 7926.86, average training loss: 7872.24, base loss: 16005.90
[INFO 2017-07-01 17:19:19,819 main.py:52] epoch 1528, training loss: 7808.65, average training loss: 7872.07, base loss: 16006.55
[INFO 2017-07-01 17:19:22,668 main.py:52] epoch 1529, training loss: 7208.30, average training loss: 7871.53, base loss: 16005.38
[INFO 2017-07-01 17:19:25,554 main.py:52] epoch 1530, training loss: 7344.16, average training loss: 7870.69, base loss: 16005.80
[INFO 2017-07-01 17:19:28,418 main.py:52] epoch 1531, training loss: 7588.15, average training loss: 7870.21, base loss: 16006.81
[INFO 2017-07-01 17:19:31,285 main.py:52] epoch 1532, training loss: 7927.82, average training loss: 7869.74, base loss: 16007.25
[INFO 2017-07-01 17:19:34,146 main.py:52] epoch 1533, training loss: 8031.40, average training loss: 7869.21, base loss: 16008.75
[INFO 2017-07-01 17:19:37,047 main.py:52] epoch 1534, training loss: 7556.06, average training loss: 7868.70, base loss: 16009.68
[INFO 2017-07-01 17:19:39,928 main.py:52] epoch 1535, training loss: 6988.58, average training loss: 7866.91, base loss: 16008.68
[INFO 2017-07-01 17:19:42,810 main.py:52] epoch 1536, training loss: 7561.25, average training loss: 7867.05, base loss: 16009.77
[INFO 2017-07-01 17:19:45,689 main.py:52] epoch 1537, training loss: 7449.11, average training loss: 7865.46, base loss: 16010.95
[INFO 2017-07-01 17:19:48,578 main.py:52] epoch 1538, training loss: 7680.54, average training loss: 7865.37, base loss: 16011.55
[INFO 2017-07-01 17:19:51,515 main.py:52] epoch 1539, training loss: 7623.15, average training loss: 7864.86, base loss: 16010.63
[INFO 2017-07-01 17:19:54,383 main.py:52] epoch 1540, training loss: 7235.18, average training loss: 7863.18, base loss: 16009.78
[INFO 2017-07-01 17:19:57,283 main.py:52] epoch 1541, training loss: 7170.64, average training loss: 7861.58, base loss: 16009.43
[INFO 2017-07-01 17:20:00,135 main.py:52] epoch 1542, training loss: 7113.76, average training loss: 7860.01, base loss: 16008.32
[INFO 2017-07-01 17:20:03,025 main.py:52] epoch 1543, training loss: 7121.65, average training loss: 7858.64, base loss: 16006.23
[INFO 2017-07-01 17:20:05,914 main.py:52] epoch 1544, training loss: 7960.85, average training loss: 7858.92, base loss: 16007.03
[INFO 2017-07-01 17:20:08,816 main.py:52] epoch 1545, training loss: 7053.51, average training loss: 7857.24, base loss: 16006.58
[INFO 2017-07-01 17:20:11,704 main.py:52] epoch 1546, training loss: 8125.43, average training loss: 7857.47, base loss: 16007.43
[INFO 2017-07-01 17:20:14,568 main.py:52] epoch 1547, training loss: 7670.96, average training loss: 7857.19, base loss: 16007.81
[INFO 2017-07-01 17:20:17,412 main.py:52] epoch 1548, training loss: 7277.12, average training loss: 7856.01, base loss: 16007.84
[INFO 2017-07-01 17:20:20,318 main.py:52] epoch 1549, training loss: 7821.46, average training loss: 7855.90, base loss: 16009.06
[INFO 2017-07-01 17:20:23,227 main.py:52] epoch 1550, training loss: 7782.76, average training loss: 7855.54, base loss: 16009.13
[INFO 2017-07-01 17:20:26,119 main.py:52] epoch 1551, training loss: 7806.52, average training loss: 7855.25, base loss: 16009.14
[INFO 2017-07-01 17:20:29,031 main.py:52] epoch 1552, training loss: 7504.17, average training loss: 7854.08, base loss: 16008.78
[INFO 2017-07-01 17:20:31,934 main.py:52] epoch 1553, training loss: 7536.29, average training loss: 7853.10, base loss: 16008.90
[INFO 2017-07-01 17:20:34,796 main.py:52] epoch 1554, training loss: 7760.04, average training loss: 7852.99, base loss: 16008.21
[INFO 2017-07-01 17:20:37,697 main.py:52] epoch 1555, training loss: 7289.05, average training loss: 7852.82, base loss: 16007.15
[INFO 2017-07-01 17:20:40,579 main.py:52] epoch 1556, training loss: 7073.98, average training loss: 7851.39, base loss: 16005.76
[INFO 2017-07-01 17:20:43,456 main.py:52] epoch 1557, training loss: 7310.59, average training loss: 7850.09, base loss: 16005.54
[INFO 2017-07-01 17:20:46,329 main.py:52] epoch 1558, training loss: 7821.09, average training loss: 7848.80, base loss: 16007.36
[INFO 2017-07-01 17:20:49,216 main.py:52] epoch 1559, training loss: 7110.48, average training loss: 7848.04, base loss: 16007.21
[INFO 2017-07-01 17:20:52,082 main.py:52] epoch 1560, training loss: 6886.80, average training loss: 7846.40, base loss: 16005.81
[INFO 2017-07-01 17:20:54,944 main.py:52] epoch 1561, training loss: 7772.70, average training loss: 7846.30, base loss: 16006.52
[INFO 2017-07-01 17:20:57,778 main.py:52] epoch 1562, training loss: 7147.32, average training loss: 7845.59, base loss: 16007.24
[INFO 2017-07-01 17:21:00,636 main.py:52] epoch 1563, training loss: 7684.81, average training loss: 7845.70, base loss: 16007.74
[INFO 2017-07-01 17:21:03,470 main.py:52] epoch 1564, training loss: 7587.22, average training loss: 7844.83, base loss: 16008.45
[INFO 2017-07-01 17:21:06,353 main.py:52] epoch 1565, training loss: 7728.77, average training loss: 7843.82, base loss: 16009.39
[INFO 2017-07-01 17:21:09,247 main.py:52] epoch 1566, training loss: 7486.51, average training loss: 7842.61, base loss: 16008.70
[INFO 2017-07-01 17:21:12,139 main.py:52] epoch 1567, training loss: 7230.48, average training loss: 7841.46, base loss: 16007.57
[INFO 2017-07-01 17:21:14,997 main.py:52] epoch 1568, training loss: 6870.35, average training loss: 7840.70, base loss: 16006.49
[INFO 2017-07-01 17:21:17,861 main.py:52] epoch 1569, training loss: 7304.07, average training loss: 7839.38, base loss: 16006.68
[INFO 2017-07-01 17:21:20,744 main.py:52] epoch 1570, training loss: 7770.95, average training loss: 7838.82, base loss: 16007.59
[INFO 2017-07-01 17:21:23,607 main.py:52] epoch 1571, training loss: 7594.45, average training loss: 7839.17, base loss: 16007.61
[INFO 2017-07-01 17:21:26,476 main.py:52] epoch 1572, training loss: 7737.64, average training loss: 7838.78, base loss: 16009.28
[INFO 2017-07-01 17:21:29,308 main.py:52] epoch 1573, training loss: 7449.05, average training loss: 7837.38, base loss: 16009.60
[INFO 2017-07-01 17:21:32,212 main.py:52] epoch 1574, training loss: 7269.21, average training loss: 7835.54, base loss: 16008.49
[INFO 2017-07-01 17:21:35,054 main.py:52] epoch 1575, training loss: 7226.10, average training loss: 7834.47, base loss: 16008.36
[INFO 2017-07-01 17:21:37,913 main.py:52] epoch 1576, training loss: 7096.64, average training loss: 7833.14, base loss: 16007.70
[INFO 2017-07-01 17:21:40,827 main.py:52] epoch 1577, training loss: 7414.04, average training loss: 7832.27, base loss: 16008.23
[INFO 2017-07-01 17:21:43,687 main.py:52] epoch 1578, training loss: 7486.07, average training loss: 7832.16, base loss: 16008.97
[INFO 2017-07-01 17:21:46,574 main.py:52] epoch 1579, training loss: 7887.19, average training loss: 7831.94, base loss: 16010.09
[INFO 2017-07-01 17:21:49,482 main.py:52] epoch 1580, training loss: 7238.93, average training loss: 7831.29, base loss: 16009.04
[INFO 2017-07-01 17:21:52,442 main.py:52] epoch 1581, training loss: 7821.65, average training loss: 7830.80, base loss: 16008.06
[INFO 2017-07-01 17:21:55,306 main.py:52] epoch 1582, training loss: 7003.25, average training loss: 7829.67, base loss: 16006.25
[INFO 2017-07-01 17:21:58,162 main.py:52] epoch 1583, training loss: 7998.18, average training loss: 7829.49, base loss: 16007.82
[INFO 2017-07-01 17:22:01,006 main.py:52] epoch 1584, training loss: 7417.46, average training loss: 7829.42, base loss: 16007.07
[INFO 2017-07-01 17:22:03,906 main.py:52] epoch 1585, training loss: 7636.57, average training loss: 7827.63, base loss: 16006.14
[INFO 2017-07-01 17:22:06,761 main.py:52] epoch 1586, training loss: 8484.14, average training loss: 7828.02, base loss: 16008.24
[INFO 2017-07-01 17:22:09,605 main.py:52] epoch 1587, training loss: 7850.07, average training loss: 7828.08, base loss: 16008.65
[INFO 2017-07-01 17:22:12,463 main.py:52] epoch 1588, training loss: 7205.96, average training loss: 7826.93, base loss: 16008.13
[INFO 2017-07-01 17:22:15,309 main.py:52] epoch 1589, training loss: 7702.07, average training loss: 7826.18, base loss: 16010.40
[INFO 2017-07-01 17:22:18,157 main.py:52] epoch 1590, training loss: 7616.02, average training loss: 7825.66, base loss: 16009.93
[INFO 2017-07-01 17:22:21,004 main.py:52] epoch 1591, training loss: 7517.61, average training loss: 7825.02, base loss: 16008.86
[INFO 2017-07-01 17:22:23,870 main.py:52] epoch 1592, training loss: 7228.34, average training loss: 7824.43, base loss: 16008.30
[INFO 2017-07-01 17:22:26,786 main.py:52] epoch 1593, training loss: 7715.21, average training loss: 7823.84, base loss: 16008.98
[INFO 2017-07-01 17:22:29,669 main.py:52] epoch 1594, training loss: 7916.26, average training loss: 7823.63, base loss: 16009.73
[INFO 2017-07-01 17:22:32,516 main.py:52] epoch 1595, training loss: 7215.27, average training loss: 7822.46, base loss: 16007.90
[INFO 2017-07-01 17:22:35,339 main.py:52] epoch 1596, training loss: 7268.36, average training loss: 7821.21, base loss: 16006.47
[INFO 2017-07-01 17:22:38,193 main.py:52] epoch 1597, training loss: 7185.78, average training loss: 7818.90, base loss: 16006.07
[INFO 2017-07-01 17:22:41,040 main.py:52] epoch 1598, training loss: 7070.15, average training loss: 7818.54, base loss: 16005.86
[INFO 2017-07-01 17:22:43,895 main.py:52] epoch 1599, training loss: 8183.64, average training loss: 7818.54, base loss: 16009.52
[INFO 2017-07-01 17:22:43,895 main.py:54] epoch 1599, testing
[INFO 2017-07-01 17:22:56,247 main.py:97] average testing loss: 7518.62, base loss: 16237.69
[INFO 2017-07-01 17:22:56,248 main.py:98] improve_loss: 8719.07, improve_percent: 0.54
[INFO 2017-07-01 17:22:56,249 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 17:22:56,274 main.py:66] current best improved percent: 0.54
[INFO 2017-07-01 17:22:59,173 main.py:52] epoch 1600, training loss: 7361.34, average training loss: 7817.60, base loss: 16009.16
[INFO 2017-07-01 17:23:02,089 main.py:52] epoch 1601, training loss: 7729.91, average training loss: 7817.09, base loss: 16009.70
[INFO 2017-07-01 17:23:04,968 main.py:52] epoch 1602, training loss: 7380.21, average training loss: 7816.54, base loss: 16011.05
[INFO 2017-07-01 17:23:07,834 main.py:52] epoch 1603, training loss: 7140.91, average training loss: 7815.27, base loss: 16010.77
[INFO 2017-07-01 17:23:10,688 main.py:52] epoch 1604, training loss: 7752.94, average training loss: 7815.86, base loss: 16010.58
[INFO 2017-07-01 17:23:13,552 main.py:52] epoch 1605, training loss: 7623.81, average training loss: 7815.84, base loss: 16009.77
[INFO 2017-07-01 17:23:16,419 main.py:52] epoch 1606, training loss: 7493.61, average training loss: 7815.00, base loss: 16009.67
[INFO 2017-07-01 17:23:19,269 main.py:52] epoch 1607, training loss: 7465.26, average training loss: 7813.84, base loss: 16008.61
[INFO 2017-07-01 17:23:22,162 main.py:52] epoch 1608, training loss: 8509.55, average training loss: 7814.74, base loss: 16011.57
[INFO 2017-07-01 17:23:25,016 main.py:52] epoch 1609, training loss: 7143.50, average training loss: 7813.77, base loss: 16010.61
[INFO 2017-07-01 17:23:27,880 main.py:52] epoch 1610, training loss: 7000.56, average training loss: 7813.49, base loss: 16010.42
[INFO 2017-07-01 17:23:30,731 main.py:52] epoch 1611, training loss: 7652.31, average training loss: 7812.34, base loss: 16011.61
[INFO 2017-07-01 17:23:33,565 main.py:52] epoch 1612, training loss: 7245.47, average training loss: 7811.95, base loss: 16011.36
[INFO 2017-07-01 17:23:36,441 main.py:52] epoch 1613, training loss: 7553.69, average training loss: 7811.09, base loss: 16010.61
[INFO 2017-07-01 17:23:39,296 main.py:52] epoch 1614, training loss: 7145.41, average training loss: 7810.57, base loss: 16008.81
[INFO 2017-07-01 17:23:42,227 main.py:52] epoch 1615, training loss: 7056.53, average training loss: 7809.78, base loss: 16007.47
[INFO 2017-07-01 17:23:45,069 main.py:52] epoch 1616, training loss: 7567.41, average training loss: 7809.47, base loss: 16007.19
[INFO 2017-07-01 17:23:47,951 main.py:52] epoch 1617, training loss: 6942.84, average training loss: 7808.25, base loss: 16006.04
[INFO 2017-07-01 17:23:50,816 main.py:52] epoch 1618, training loss: 8050.56, average training loss: 7807.04, base loss: 16007.80
[INFO 2017-07-01 17:23:53,719 main.py:52] epoch 1619, training loss: 7854.88, average training loss: 7806.44, base loss: 16009.76
[INFO 2017-07-01 17:23:56,562 main.py:52] epoch 1620, training loss: 7909.63, average training loss: 7807.08, base loss: 16010.58
[INFO 2017-07-01 17:23:59,416 main.py:52] epoch 1621, training loss: 6891.90, average training loss: 7806.29, base loss: 16009.54
[INFO 2017-07-01 17:24:02,330 main.py:52] epoch 1622, training loss: 7178.21, average training loss: 7805.30, base loss: 16009.27
[INFO 2017-07-01 17:24:05,221 main.py:52] epoch 1623, training loss: 7163.98, average training loss: 7804.93, base loss: 16008.79
[INFO 2017-07-01 17:24:08,116 main.py:52] epoch 1624, training loss: 8119.83, average training loss: 7805.18, base loss: 16010.74
[INFO 2017-07-01 17:24:10,938 main.py:52] epoch 1625, training loss: 7182.36, average training loss: 7803.63, base loss: 16011.15
[INFO 2017-07-01 17:24:13,791 main.py:52] epoch 1626, training loss: 7957.57, average training loss: 7803.45, base loss: 16013.35
[INFO 2017-07-01 17:24:16,661 main.py:52] epoch 1627, training loss: 7540.83, average training loss: 7802.60, base loss: 16013.48
[INFO 2017-07-01 17:24:19,618 main.py:52] epoch 1628, training loss: 7195.80, average training loss: 7801.36, base loss: 16012.61
[INFO 2017-07-01 17:24:22,533 main.py:52] epoch 1629, training loss: 7365.17, average training loss: 7800.50, base loss: 16011.39
[INFO 2017-07-01 17:24:25,384 main.py:52] epoch 1630, training loss: 7520.75, average training loss: 7799.65, base loss: 16011.69
[INFO 2017-07-01 17:24:28,240 main.py:52] epoch 1631, training loss: 7341.85, average training loss: 7798.56, base loss: 16010.29
[INFO 2017-07-01 17:24:31,110 main.py:52] epoch 1632, training loss: 7581.68, average training loss: 7797.21, base loss: 16009.91
[INFO 2017-07-01 17:24:33,998 main.py:52] epoch 1633, training loss: 7569.55, average training loss: 7796.67, base loss: 16008.98
[INFO 2017-07-01 17:24:36,877 main.py:52] epoch 1634, training loss: 8129.82, average training loss: 7797.22, base loss: 16011.54
[INFO 2017-07-01 17:24:39,759 main.py:52] epoch 1635, training loss: 7638.36, average training loss: 7797.14, base loss: 16011.37
[INFO 2017-07-01 17:24:42,626 main.py:52] epoch 1636, training loss: 6897.58, average training loss: 7795.81, base loss: 16010.56
[INFO 2017-07-01 17:24:45,583 main.py:52] epoch 1637, training loss: 7707.51, average training loss: 7794.36, base loss: 16012.89
[INFO 2017-07-01 17:24:48,595 main.py:52] epoch 1638, training loss: 7713.65, average training loss: 7794.15, base loss: 16013.22
[INFO 2017-07-01 17:24:51,436 main.py:52] epoch 1639, training loss: 7563.43, average training loss: 7793.88, base loss: 16013.26
[INFO 2017-07-01 17:24:54,297 main.py:52] epoch 1640, training loss: 8254.76, average training loss: 7794.32, base loss: 16013.86
[INFO 2017-07-01 17:24:57,177 main.py:52] epoch 1641, training loss: 7517.84, average training loss: 7793.20, base loss: 16014.03
[INFO 2017-07-01 17:25:00,024 main.py:52] epoch 1642, training loss: 7736.25, average training loss: 7793.39, base loss: 16016.61
[INFO 2017-07-01 17:25:02,934 main.py:52] epoch 1643, training loss: 7760.44, average training loss: 7793.09, base loss: 16018.53
[INFO 2017-07-01 17:25:05,832 main.py:52] epoch 1644, training loss: 7164.97, average training loss: 7791.84, base loss: 16016.98
[INFO 2017-07-01 17:25:08,718 main.py:52] epoch 1645, training loss: 6959.40, average training loss: 7790.86, base loss: 16015.25
[INFO 2017-07-01 17:25:11,648 main.py:52] epoch 1646, training loss: 7428.72, average training loss: 7789.91, base loss: 16014.64
[INFO 2017-07-01 17:25:14,488 main.py:52] epoch 1647, training loss: 8502.70, average training loss: 7790.67, base loss: 16015.77
[INFO 2017-07-01 17:25:17,349 main.py:52] epoch 1648, training loss: 7462.96, average training loss: 7789.92, base loss: 16013.70
[INFO 2017-07-01 17:25:20,220 main.py:52] epoch 1649, training loss: 7124.39, average training loss: 7789.44, base loss: 16012.31
[INFO 2017-07-01 17:25:23,082 main.py:52] epoch 1650, training loss: 7566.43, average training loss: 7788.93, base loss: 16011.67
[INFO 2017-07-01 17:25:25,924 main.py:52] epoch 1651, training loss: 7581.23, average training loss: 7788.43, base loss: 16012.24
[INFO 2017-07-01 17:25:28,809 main.py:52] epoch 1652, training loss: 7021.04, average training loss: 7786.88, base loss: 16010.52
[INFO 2017-07-01 17:25:31,713 main.py:52] epoch 1653, training loss: 7680.00, average training loss: 7786.42, base loss: 16011.17
[INFO 2017-07-01 17:25:34,601 main.py:52] epoch 1654, training loss: 7259.46, average training loss: 7785.15, base loss: 16010.68
[INFO 2017-07-01 17:25:37,435 main.py:52] epoch 1655, training loss: 7936.18, average training loss: 7785.26, base loss: 16011.51
[INFO 2017-07-01 17:25:40,292 main.py:52] epoch 1656, training loss: 8595.00, average training loss: 7786.35, base loss: 16015.26
[INFO 2017-07-01 17:25:43,159 main.py:52] epoch 1657, training loss: 6698.96, average training loss: 7784.60, base loss: 16013.38
[INFO 2017-07-01 17:25:45,993 main.py:52] epoch 1658, training loss: 7632.27, average training loss: 7784.27, base loss: 16013.40
[INFO 2017-07-01 17:25:48,835 main.py:52] epoch 1659, training loss: 7524.60, average training loss: 7783.96, base loss: 16012.52
[INFO 2017-07-01 17:25:51,730 main.py:52] epoch 1660, training loss: 7499.27, average training loss: 7783.40, base loss: 16013.42
[INFO 2017-07-01 17:25:54,612 main.py:52] epoch 1661, training loss: 7568.33, average training loss: 7782.34, base loss: 16014.01
[INFO 2017-07-01 17:25:57,445 main.py:52] epoch 1662, training loss: 7714.54, average training loss: 7782.25, base loss: 16014.23
[INFO 2017-07-01 17:26:00,300 main.py:52] epoch 1663, training loss: 7141.33, average training loss: 7781.51, base loss: 16013.34
[INFO 2017-07-01 17:26:03,197 main.py:52] epoch 1664, training loss: 7784.79, average training loss: 7781.24, base loss: 16013.30
[INFO 2017-07-01 17:26:06,039 main.py:52] epoch 1665, training loss: 7697.74, average training loss: 7780.84, base loss: 16013.42
[INFO 2017-07-01 17:26:08,921 main.py:52] epoch 1666, training loss: 7852.99, average training loss: 7780.33, base loss: 16014.77
[INFO 2017-07-01 17:26:11,789 main.py:52] epoch 1667, training loss: 6827.80, average training loss: 7779.04, base loss: 16013.63
[INFO 2017-07-01 17:26:14,646 main.py:52] epoch 1668, training loss: 7636.88, average training loss: 7778.64, base loss: 16014.28
[INFO 2017-07-01 17:26:17,488 main.py:52] epoch 1669, training loss: 7808.48, average training loss: 7777.82, base loss: 16016.14
[INFO 2017-07-01 17:26:20,394 main.py:52] epoch 1670, training loss: 7888.91, average training loss: 7777.79, base loss: 16016.97
[INFO 2017-07-01 17:26:23,309 main.py:52] epoch 1671, training loss: 7821.49, average training loss: 7777.05, base loss: 16016.81
[INFO 2017-07-01 17:26:26,155 main.py:52] epoch 1672, training loss: 7960.00, average training loss: 7776.78, base loss: 16018.36
[INFO 2017-07-01 17:26:29,014 main.py:52] epoch 1673, training loss: 7669.80, average training loss: 7775.92, base loss: 16020.18
[INFO 2017-07-01 17:26:31,957 main.py:52] epoch 1674, training loss: 7739.18, average training loss: 7775.84, base loss: 16021.90
[INFO 2017-07-01 17:26:35,061 main.py:52] epoch 1675, training loss: 7204.93, average training loss: 7775.59, base loss: 16022.19
[INFO 2017-07-01 17:26:37,915 main.py:52] epoch 1676, training loss: 7288.97, average training loss: 7774.87, base loss: 16021.46
[INFO 2017-07-01 17:26:40,791 main.py:52] epoch 1677, training loss: 7603.33, average training loss: 7773.99, base loss: 16021.27
[INFO 2017-07-01 17:26:43,669 main.py:52] epoch 1678, training loss: 7379.82, average training loss: 7772.81, base loss: 16020.93
[INFO 2017-07-01 17:26:46,562 main.py:52] epoch 1679, training loss: 7124.10, average training loss: 7772.11, base loss: 16019.45
[INFO 2017-07-01 17:26:49,429 main.py:52] epoch 1680, training loss: 6909.03, average training loss: 7771.19, base loss: 16017.09
[INFO 2017-07-01 17:26:52,334 main.py:52] epoch 1681, training loss: 7220.78, average training loss: 7770.88, base loss: 16015.59
[INFO 2017-07-01 17:26:55,220 main.py:52] epoch 1682, training loss: 7568.97, average training loss: 7770.31, base loss: 16014.90
[INFO 2017-07-01 17:26:58,140 main.py:52] epoch 1683, training loss: 8329.01, average training loss: 7770.33, base loss: 16016.86
[INFO 2017-07-01 17:27:01,037 main.py:52] epoch 1684, training loss: 7717.92, average training loss: 7769.64, base loss: 16016.59
[INFO 2017-07-01 17:27:03,886 main.py:52] epoch 1685, training loss: 7686.44, average training loss: 7768.61, base loss: 16016.51
[INFO 2017-07-01 17:27:06,779 main.py:52] epoch 1686, training loss: 7658.15, average training loss: 7769.11, base loss: 16015.97
[INFO 2017-07-01 17:27:09,624 main.py:52] epoch 1687, training loss: 8541.46, average training loss: 7768.94, base loss: 16015.88
[INFO 2017-07-01 17:27:12,500 main.py:52] epoch 1688, training loss: 8251.49, average training loss: 7768.90, base loss: 16016.92
[INFO 2017-07-01 17:27:15,357 main.py:52] epoch 1689, training loss: 7921.19, average training loss: 7767.87, base loss: 16017.73
[INFO 2017-07-01 17:27:18,218 main.py:52] epoch 1690, training loss: 7304.03, average training loss: 7766.82, base loss: 16016.72
[INFO 2017-07-01 17:27:21,096 main.py:52] epoch 1691, training loss: 7662.53, average training loss: 7766.83, base loss: 16016.15
[INFO 2017-07-01 17:27:23,972 main.py:52] epoch 1692, training loss: 7136.48, average training loss: 7766.46, base loss: 16015.02
[INFO 2017-07-01 17:27:26,855 main.py:52] epoch 1693, training loss: 8297.25, average training loss: 7766.39, base loss: 16016.16
[INFO 2017-07-01 17:27:29,756 main.py:52] epoch 1694, training loss: 8244.03, average training loss: 7766.50, base loss: 16014.86
[INFO 2017-07-01 17:27:32,635 main.py:52] epoch 1695, training loss: 7395.57, average training loss: 7766.02, base loss: 16012.60
[INFO 2017-07-01 17:27:35,519 main.py:52] epoch 1696, training loss: 7416.35, average training loss: 7765.61, base loss: 16013.91
[INFO 2017-07-01 17:27:38,381 main.py:52] epoch 1697, training loss: 6886.70, average training loss: 7764.19, base loss: 16013.42
[INFO 2017-07-01 17:27:41,239 main.py:52] epoch 1698, training loss: 7866.81, average training loss: 7765.03, base loss: 16014.30
[INFO 2017-07-01 17:27:44,053 main.py:52] epoch 1699, training loss: 8267.55, average training loss: 7764.50, base loss: 16015.82
[INFO 2017-07-01 17:27:44,053 main.py:54] epoch 1699, testing
[INFO 2017-07-01 17:27:56,281 main.py:97] average testing loss: 7749.32, base loss: 16117.64
[INFO 2017-07-01 17:27:56,281 main.py:98] improve_loss: 8368.32, improve_percent: 0.52
[INFO 2017-07-01 17:27:56,284 main.py:66] current best improved percent: 0.54
[INFO 2017-07-01 17:27:59,215 main.py:52] epoch 1700, training loss: 7546.81, average training loss: 7763.72, base loss: 16014.80
[INFO 2017-07-01 17:28:02,371 main.py:52] epoch 1701, training loss: 8115.08, average training loss: 7763.90, base loss: 16015.77
[INFO 2017-07-01 17:28:05,244 main.py:52] epoch 1702, training loss: 6633.27, average training loss: 7762.43, base loss: 16012.91
[INFO 2017-07-01 17:28:08,115 main.py:52] epoch 1703, training loss: 7312.96, average training loss: 7761.30, base loss: 16011.40
[INFO 2017-07-01 17:28:10,982 main.py:52] epoch 1704, training loss: 7858.91, average training loss: 7760.64, base loss: 16012.18
[INFO 2017-07-01 17:28:13,840 main.py:52] epoch 1705, training loss: 8044.89, average training loss: 7760.24, base loss: 16013.64
[INFO 2017-07-01 17:28:16,705 main.py:52] epoch 1706, training loss: 7811.60, average training loss: 7760.14, base loss: 16013.00
[INFO 2017-07-01 17:28:19,585 main.py:52] epoch 1707, training loss: 7624.26, average training loss: 7760.05, base loss: 16012.78
[INFO 2017-07-01 17:28:22,481 main.py:52] epoch 1708, training loss: 8007.80, average training loss: 7760.10, base loss: 16014.59
[INFO 2017-07-01 17:28:25,368 main.py:52] epoch 1709, training loss: 8126.43, average training loss: 7759.14, base loss: 16016.32
[INFO 2017-07-01 17:28:28,241 main.py:52] epoch 1710, training loss: 7271.62, average training loss: 7758.30, base loss: 16016.01
[INFO 2017-07-01 17:28:31,100 main.py:52] epoch 1711, training loss: 7454.71, average training loss: 7757.96, base loss: 16016.44
[INFO 2017-07-01 17:28:34,165 main.py:52] epoch 1712, training loss: 8572.15, average training loss: 7758.20, base loss: 16017.19
[INFO 2017-07-01 17:28:37,085 main.py:52] epoch 1713, training loss: 8095.50, average training loss: 7758.22, base loss: 16018.30
[INFO 2017-07-01 17:28:39,925 main.py:52] epoch 1714, training loss: 8233.24, average training loss: 7759.22, base loss: 16019.52
[INFO 2017-07-01 17:28:42,787 main.py:52] epoch 1715, training loss: 7863.73, average training loss: 7759.02, base loss: 16019.21
[INFO 2017-07-01 17:28:45,636 main.py:52] epoch 1716, training loss: 7065.11, average training loss: 7757.96, base loss: 16018.83
[INFO 2017-07-01 17:28:48,509 main.py:52] epoch 1717, training loss: 7442.84, average training loss: 7757.45, base loss: 16019.49
[INFO 2017-07-01 17:28:51,344 main.py:52] epoch 1718, training loss: 7611.19, average training loss: 7757.34, base loss: 16019.89
[INFO 2017-07-01 17:28:54,203 main.py:52] epoch 1719, training loss: 7232.88, average training loss: 7757.12, base loss: 16019.82
[INFO 2017-07-01 17:28:57,045 main.py:52] epoch 1720, training loss: 7176.62, average training loss: 7756.14, base loss: 16018.96
[INFO 2017-07-01 17:28:59,925 main.py:52] epoch 1721, training loss: 7461.21, average training loss: 7755.56, base loss: 16020.07
[INFO 2017-07-01 17:29:02,780 main.py:52] epoch 1722, training loss: 8410.35, average training loss: 7755.77, base loss: 16021.07
[INFO 2017-07-01 17:29:05,669 main.py:52] epoch 1723, training loss: 7681.78, average training loss: 7755.15, base loss: 16019.78
[INFO 2017-07-01 17:29:08,577 main.py:52] epoch 1724, training loss: 7239.98, average training loss: 7754.74, base loss: 16019.98
[INFO 2017-07-01 17:29:11,433 main.py:52] epoch 1725, training loss: 7131.62, average training loss: 7754.25, base loss: 16019.00
[INFO 2017-07-01 17:29:14,311 main.py:52] epoch 1726, training loss: 7523.87, average training loss: 7753.40, base loss: 16018.54
[INFO 2017-07-01 17:29:17,198 main.py:52] epoch 1727, training loss: 6880.35, average training loss: 7751.88, base loss: 16017.89
[INFO 2017-07-01 17:29:20,070 main.py:52] epoch 1728, training loss: 7864.23, average training loss: 7751.81, base loss: 16017.52
[INFO 2017-07-01 17:29:22,943 main.py:52] epoch 1729, training loss: 8389.78, average training loss: 7752.73, base loss: 16019.89
[INFO 2017-07-01 17:29:25,854 main.py:52] epoch 1730, training loss: 7244.78, average training loss: 7752.33, base loss: 16019.58
[INFO 2017-07-01 17:29:29,046 main.py:52] epoch 1731, training loss: 7686.34, average training loss: 7752.65, base loss: 16019.52
[INFO 2017-07-01 17:29:32,059 main.py:52] epoch 1732, training loss: 7037.42, average training loss: 7751.43, base loss: 16018.80
[INFO 2017-07-01 17:29:34,961 main.py:52] epoch 1733, training loss: 7698.03, average training loss: 7751.28, base loss: 16019.86
[INFO 2017-07-01 17:29:37,843 main.py:52] epoch 1734, training loss: 7642.60, average training loss: 7750.79, base loss: 16019.30
[INFO 2017-07-01 17:29:40,750 main.py:52] epoch 1735, training loss: 7223.57, average training loss: 7749.94, base loss: 16018.25
[INFO 2017-07-01 17:29:43,627 main.py:52] epoch 1736, training loss: 8621.80, average training loss: 7750.80, base loss: 16020.20
[INFO 2017-07-01 17:29:46,484 main.py:52] epoch 1737, training loss: 7510.12, average training loss: 7750.25, base loss: 16019.82
[INFO 2017-07-01 17:29:49,404 main.py:52] epoch 1738, training loss: 7580.61, average training loss: 7749.93, base loss: 16020.53
[INFO 2017-07-01 17:29:52,289 main.py:52] epoch 1739, training loss: 7890.45, average training loss: 7750.11, base loss: 16021.28
[INFO 2017-07-01 17:29:55,201 main.py:52] epoch 1740, training loss: 7519.99, average training loss: 7749.01, base loss: 16022.03
[INFO 2017-07-01 17:29:58,097 main.py:52] epoch 1741, training loss: 7820.64, average training loss: 7749.14, base loss: 16024.04
