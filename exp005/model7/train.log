[INFO 2017-07-01 17:31:33,194 main.py:168] Namespace(batch_size=32, display=False, flow_dir='flow', flow_video_dir='flow-video', flow_video_fps=1, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=4, num_channel=3, num_inputs=2, save_dir='./model', test=False, test_dir='/home/yi/Downloads/mpii-test-64', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='/home/yi/Downloads/mpii-test-64', train_epoch=100000)
[INFO 2017-07-01 17:31:37,686 main.py:52] epoch 0, training loss: 35556.10, average training loss: 35556.10, base loss: 10524.81
[INFO 2017-07-01 17:31:39,976 main.py:52] epoch 1, training loss: 36273.34, average training loss: 35914.72, base loss: 11259.20
[INFO 2017-07-01 17:31:42,231 main.py:52] epoch 2, training loss: 29913.95, average training loss: 33914.46, base loss: 11441.59
[INFO 2017-07-01 17:31:44,451 main.py:52] epoch 3, training loss: 25965.62, average training loss: 31927.25, base loss: 11330.21
[INFO 2017-07-01 17:31:46,670 main.py:52] epoch 4, training loss: 24767.37, average training loss: 30495.28, base loss: 11331.26
[INFO 2017-07-01 17:31:48,893 main.py:52] epoch 5, training loss: 25323.96, average training loss: 29633.39, base loss: 11696.55
[INFO 2017-07-01 17:31:51,103 main.py:52] epoch 6, training loss: 19877.21, average training loss: 28239.65, base loss: 11706.55
[INFO 2017-07-01 17:31:53,328 main.py:52] epoch 7, training loss: 20242.40, average training loss: 27239.99, base loss: 11815.96
[INFO 2017-07-01 17:31:55,558 main.py:52] epoch 8, training loss: 17408.57, average training loss: 26147.61, base loss: 11623.74
[INFO 2017-07-01 17:31:57,874 main.py:52] epoch 9, training loss: 18469.02, average training loss: 25379.75, base loss: 11604.26
[INFO 2017-07-01 17:32:00,553 main.py:52] epoch 10, training loss: 16566.15, average training loss: 24578.52, base loss: 11578.68
[INFO 2017-07-01 17:32:03,417 main.py:52] epoch 11, training loss: 15623.45, average training loss: 23832.26, base loss: 11568.52
[INFO 2017-07-01 17:32:06,275 main.py:52] epoch 12, training loss: 14334.95, average training loss: 23101.70, base loss: 11513.97
[INFO 2017-07-01 17:32:09,146 main.py:52] epoch 13, training loss: 14966.92, average training loss: 22520.64, base loss: 11539.06
[INFO 2017-07-01 17:32:12,010 main.py:52] epoch 14, training loss: 15784.40, average training loss: 22071.56, base loss: 11751.54
[INFO 2017-07-01 17:32:14,894 main.py:52] epoch 15, training loss: 13342.78, average training loss: 21526.01, base loss: 11785.85
[INFO 2017-07-01 17:32:17,771 main.py:52] epoch 16, training loss: 12500.20, average training loss: 20995.08, base loss: 11837.98
[INFO 2017-07-01 17:32:20,609 main.py:52] epoch 17, training loss: 12676.67, average training loss: 20532.95, base loss: 11958.13
[INFO 2017-07-01 17:32:23,472 main.py:52] epoch 18, training loss: 11575.45, average training loss: 20061.50, base loss: 11993.31
[INFO 2017-07-01 17:32:26,346 main.py:52] epoch 19, training loss: 12072.27, average training loss: 19662.04, base loss: 12138.20
[INFO 2017-07-01 17:32:29,207 main.py:52] epoch 20, training loss: 11645.85, average training loss: 19280.32, base loss: 12224.47
[INFO 2017-07-01 17:32:32,095 main.py:52] epoch 21, training loss: 9916.11, average training loss: 18854.67, base loss: 12231.55
[INFO 2017-07-01 17:32:34,979 main.py:52] epoch 22, training loss: 7739.86, average training loss: 18371.42, base loss: 12097.30
[INFO 2017-07-01 17:32:37,875 main.py:52] epoch 23, training loss: 10107.21, average training loss: 18027.08, base loss: 12131.41
[INFO 2017-07-01 17:32:40,778 main.py:52] epoch 24, training loss: 8065.18, average training loss: 17628.60, base loss: 12077.51
[INFO 2017-07-01 17:32:43,634 main.py:52] epoch 25, training loss: 8989.69, average training loss: 17296.33, base loss: 12076.81
[INFO 2017-07-01 17:32:46,529 main.py:52] epoch 26, training loss: 8862.96, average training loss: 16983.99, base loss: 12077.60
[INFO 2017-07-01 17:32:49,391 main.py:52] epoch 27, training loss: 9488.42, average training loss: 16716.29, base loss: 12109.60
[INFO 2017-07-01 17:32:52,237 main.py:52] epoch 28, training loss: 6985.82, average training loss: 16380.75, base loss: 12035.04
[INFO 2017-07-01 17:32:55,111 main.py:52] epoch 29, training loss: 9147.36, average training loss: 16139.64, base loss: 12057.73
[INFO 2017-07-01 17:32:57,982 main.py:52] epoch 30, training loss: 10045.33, average training loss: 15943.05, base loss: 12128.77
[INFO 2017-07-01 17:33:00,840 main.py:52] epoch 31, training loss: 8201.46, average training loss: 15701.13, base loss: 12119.81
[INFO 2017-07-01 17:33:03,713 main.py:52] epoch 32, training loss: 6525.20, average training loss: 15423.07, base loss: 12042.81
[INFO 2017-07-01 17:33:06,574 main.py:52] epoch 33, training loss: 7387.64, average training loss: 15186.73, base loss: 12005.73
[INFO 2017-07-01 17:33:09,437 main.py:52] epoch 34, training loss: 8517.17, average training loss: 14996.17, base loss: 12001.44
[INFO 2017-07-01 17:33:12,316 main.py:52] epoch 35, training loss: 6959.91, average training loss: 14772.94, base loss: 11956.84
[INFO 2017-07-01 17:33:15,221 main.py:52] epoch 36, training loss: 8969.90, average training loss: 14616.10, base loss: 11975.90
[INFO 2017-07-01 17:33:18,096 main.py:52] epoch 37, training loss: 8997.15, average training loss: 14468.24, base loss: 12001.04
[INFO 2017-07-01 17:33:20,956 main.py:52] epoch 38, training loss: 7539.86, average training loss: 14290.59, base loss: 11963.67
[INFO 2017-07-01 17:33:23,822 main.py:52] epoch 39, training loss: 8661.89, average training loss: 14149.87, base loss: 11974.64
[INFO 2017-07-01 17:33:26,705 main.py:52] epoch 40, training loss: 7457.27, average training loss: 13986.63, base loss: 11946.04
[INFO 2017-07-01 17:33:29,553 main.py:52] epoch 41, training loss: 10000.62, average training loss: 13891.73, base loss: 12004.58
[INFO 2017-07-01 17:33:32,418 main.py:52] epoch 42, training loss: 8109.95, average training loss: 13757.27, base loss: 11997.01
[INFO 2017-07-01 17:33:35,301 main.py:52] epoch 43, training loss: 7478.81, average training loss: 13614.58, base loss: 11968.17
[INFO 2017-07-01 17:33:38,187 main.py:52] epoch 44, training loss: 9999.00, average training loss: 13534.23, base loss: 12029.56
[INFO 2017-07-01 17:33:41,082 main.py:52] epoch 45, training loss: 8416.16, average training loss: 13422.97, base loss: 12025.03
[INFO 2017-07-01 17:33:43,972 main.py:52] epoch 46, training loss: 7459.34, average training loss: 13296.08, base loss: 12007.89
[INFO 2017-07-01 17:33:46,843 main.py:52] epoch 47, training loss: 9045.35, average training loss: 13207.53, base loss: 12031.31
[INFO 2017-07-01 17:33:49,702 main.py:52] epoch 48, training loss: 8116.02, average training loss: 13103.62, base loss: 12031.10
[INFO 2017-07-01 17:33:52,602 main.py:52] epoch 49, training loss: 7908.86, average training loss: 12999.72, base loss: 12022.90
[INFO 2017-07-01 17:33:55,504 main.py:52] epoch 50, training loss: 7479.94, average training loss: 12891.49, base loss: 12008.05
[INFO 2017-07-01 17:33:58,384 main.py:52] epoch 51, training loss: 6496.67, average training loss: 12768.51, base loss: 11954.30
[INFO 2017-07-01 17:34:01,264 main.py:52] epoch 52, training loss: 8523.22, average training loss: 12688.41, base loss: 11954.93
[INFO 2017-07-01 17:34:04,135 main.py:52] epoch 53, training loss: 7969.06, average training loss: 12601.02, base loss: 11952.43
[INFO 2017-07-01 17:34:06,999 main.py:52] epoch 54, training loss: 8732.33, average training loss: 12530.68, base loss: 11968.45
[INFO 2017-07-01 17:34:09,856 main.py:52] epoch 55, training loss: 7530.53, average training loss: 12441.39, base loss: 11955.79
[INFO 2017-07-01 17:34:12,692 main.py:52] epoch 56, training loss: 6709.88, average training loss: 12340.84, base loss: 11918.66
[INFO 2017-07-01 17:34:15,541 main.py:52] epoch 57, training loss: 8816.97, average training loss: 12280.08, base loss: 11930.87
[INFO 2017-07-01 17:34:18,463 main.py:52] epoch 58, training loss: 7653.10, average training loss: 12201.66, base loss: 11923.64
[INFO 2017-07-01 17:34:21,343 main.py:52] epoch 59, training loss: 7831.21, average training loss: 12128.82, base loss: 11912.53
[INFO 2017-07-01 17:34:24,222 main.py:52] epoch 60, training loss: 7520.59, average training loss: 12053.27, base loss: 11899.45
[INFO 2017-07-01 17:34:27,125 main.py:52] epoch 61, training loss: 7026.84, average training loss: 11972.20, base loss: 11871.14
[INFO 2017-07-01 17:34:30,079 main.py:52] epoch 62, training loss: 6785.53, average training loss: 11889.87, base loss: 11835.77
[INFO 2017-07-01 17:34:32,947 main.py:52] epoch 63, training loss: 8759.24, average training loss: 11840.96, base loss: 11847.93
[INFO 2017-07-01 17:34:35,839 main.py:52] epoch 64, training loss: 7680.60, average training loss: 11776.95, base loss: 11837.82
[INFO 2017-07-01 17:34:38,746 main.py:52] epoch 65, training loss: 8869.01, average training loss: 11732.89, base loss: 11858.76
[INFO 2017-07-01 17:34:41,639 main.py:52] epoch 66, training loss: 7497.97, average training loss: 11669.68, base loss: 11843.95
[INFO 2017-07-01 17:34:44,503 main.py:52] epoch 67, training loss: 7457.53, average training loss: 11607.74, base loss: 11829.72
[INFO 2017-07-01 17:34:47,409 main.py:52] epoch 68, training loss: 8363.75, average training loss: 11560.73, base loss: 11847.70
[INFO 2017-07-01 17:34:50,242 main.py:52] epoch 69, training loss: 7926.07, average training loss: 11508.80, base loss: 11844.51
[INFO 2017-07-01 17:34:53,114 main.py:52] epoch 70, training loss: 8088.35, average training loss: 11460.63, base loss: 11846.80
[INFO 2017-07-01 17:34:56,017 main.py:52] epoch 71, training loss: 8126.11, average training loss: 11414.31, base loss: 11847.68
[INFO 2017-07-01 17:34:58,872 main.py:52] epoch 72, training loss: 8896.66, average training loss: 11379.83, base loss: 11864.99
[INFO 2017-07-01 17:35:01,749 main.py:52] epoch 73, training loss: 8535.31, average training loss: 11341.39, base loss: 11872.37
[INFO 2017-07-01 17:35:04,626 main.py:52] epoch 74, training loss: 7759.21, average training loss: 11293.62, base loss: 11870.23
[INFO 2017-07-01 17:35:07,478 main.py:52] epoch 75, training loss: 8742.11, average training loss: 11260.05, base loss: 11881.33
[INFO 2017-07-01 17:35:10,359 main.py:52] epoch 76, training loss: 6585.09, average training loss: 11199.34, base loss: 11853.96
[INFO 2017-07-01 17:35:13,264 main.py:52] epoch 77, training loss: 6409.64, average training loss: 11137.93, base loss: 11829.15
[INFO 2017-07-01 17:35:16,117 main.py:52] epoch 78, training loss: 8442.05, average training loss: 11103.81, base loss: 11838.89
[INFO 2017-07-01 17:35:18,967 main.py:52] epoch 79, training loss: 10109.82, average training loss: 11091.38, base loss: 11875.88
[INFO 2017-07-01 17:35:21,837 main.py:52] epoch 80, training loss: 7339.15, average training loss: 11045.06, base loss: 11866.04
[INFO 2017-07-01 17:35:24,710 main.py:52] epoch 81, training loss: 6765.90, average training loss: 10992.87, base loss: 11846.85
[INFO 2017-07-01 17:35:27,584 main.py:52] epoch 82, training loss: 7116.03, average training loss: 10946.16, base loss: 11832.02
[INFO 2017-07-01 17:35:30,477 main.py:52] epoch 83, training loss: 8419.13, average training loss: 10916.08, base loss: 11841.11
[INFO 2017-07-01 17:35:33,372 main.py:52] epoch 84, training loss: 8200.17, average training loss: 10884.13, base loss: 11846.55
[INFO 2017-07-01 17:35:36,264 main.py:52] epoch 85, training loss: 8607.40, average training loss: 10857.65, base loss: 11860.78
[INFO 2017-07-01 17:35:39,127 main.py:52] epoch 86, training loss: 8432.10, average training loss: 10829.77, base loss: 11872.68
[INFO 2017-07-01 17:35:42,048 main.py:52] epoch 87, training loss: 7204.86, average training loss: 10788.58, base loss: 11861.15
[INFO 2017-07-01 17:35:44,906 main.py:52] epoch 88, training loss: 8739.33, average training loss: 10765.56, base loss: 11875.46
[INFO 2017-07-01 17:35:47,791 main.py:52] epoch 89, training loss: 6998.87, average training loss: 10723.70, base loss: 11861.00
[INFO 2017-07-01 17:35:50,686 main.py:52] epoch 90, training loss: 8054.68, average training loss: 10694.38, base loss: 11861.85
[INFO 2017-07-01 17:35:53,576 main.py:52] epoch 91, training loss: 8479.34, average training loss: 10670.30, base loss: 11870.85
[INFO 2017-07-01 17:35:56,468 main.py:52] epoch 92, training loss: 8853.88, average training loss: 10650.77, base loss: 11888.74
[INFO 2017-07-01 17:35:59,371 main.py:52] epoch 93, training loss: 7593.88, average training loss: 10618.25, base loss: 11884.99
[INFO 2017-07-01 17:36:02,233 main.py:52] epoch 94, training loss: 6925.59, average training loss: 10579.38, base loss: 11870.23
[INFO 2017-07-01 17:36:05,154 main.py:52] epoch 95, training loss: 9405.78, average training loss: 10567.15, base loss: 11894.49
[INFO 2017-07-01 17:36:08,058 main.py:52] epoch 96, training loss: 6560.02, average training loss: 10525.84, base loss: 11874.85
[INFO 2017-07-01 17:36:10,916 main.py:52] epoch 97, training loss: 8407.37, average training loss: 10504.22, base loss: 11883.78
[INFO 2017-07-01 17:36:13,799 main.py:52] epoch 98, training loss: 6529.61, average training loss: 10464.08, base loss: 11864.57
[INFO 2017-07-01 17:36:16,689 main.py:52] epoch 99, training loss: 7816.53, average training loss: 10437.60, base loss: 11868.03
[INFO 2017-07-01 17:36:16,689 main.py:54] epoch 99, testing
[INFO 2017-07-01 17:36:28,895 main.py:97] average testing loss: 8127.53, base loss: 12430.80
[INFO 2017-07-01 17:36:28,895 main.py:98] improve_loss: 4303.27, improve_percent: 0.35
[INFO 2017-07-01 17:36:28,897 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 17:36:28,921 main.py:66] current best improved percent: 0.35
[INFO 2017-07-01 17:36:31,792 main.py:52] epoch 100, training loss: 7067.55, average training loss: 10404.23, base loss: 11857.76
[INFO 2017-07-01 17:36:34,669 main.py:52] epoch 101, training loss: 9160.11, average training loss: 10392.04, base loss: 11876.82
[INFO 2017-07-01 17:36:37,569 main.py:52] epoch 102, training loss: 8776.29, average training loss: 10376.35, base loss: 11895.52
[INFO 2017-07-01 17:36:40,419 main.py:52] epoch 103, training loss: 7165.71, average training loss: 10345.48, base loss: 11886.81
[INFO 2017-07-01 17:36:43,280 main.py:52] epoch 104, training loss: 7630.15, average training loss: 10319.62, base loss: 11886.04
[INFO 2017-07-01 17:36:46,173 main.py:52] epoch 105, training loss: 7320.21, average training loss: 10291.32, base loss: 11883.96
[INFO 2017-07-01 17:36:49,087 main.py:52] epoch 106, training loss: 7725.93, average training loss: 10267.35, base loss: 11889.43
[INFO 2017-07-01 17:36:52,062 main.py:52] epoch 107, training loss: 7501.88, average training loss: 10241.74, base loss: 11888.93
[INFO 2017-07-01 17:36:55,107 main.py:52] epoch 108, training loss: 7236.37, average training loss: 10214.17, base loss: 11887.27
[INFO 2017-07-01 17:36:57,943 main.py:52] epoch 109, training loss: 8053.59, average training loss: 10194.53, base loss: 11896.45
[INFO 2017-07-01 17:37:00,849 main.py:52] epoch 110, training loss: 7490.73, average training loss: 10170.17, base loss: 11895.53
[INFO 2017-07-01 17:37:03,740 main.py:52] epoch 111, training loss: 8095.84, average training loss: 10151.65, base loss: 11899.88
[INFO 2017-07-01 17:37:06,607 main.py:52] epoch 112, training loss: 7967.88, average training loss: 10132.32, base loss: 11910.96
[INFO 2017-07-01 17:37:09,503 main.py:52] epoch 113, training loss: 6397.98, average training loss: 10099.56, base loss: 11892.76
[INFO 2017-07-01 17:37:12,420 main.py:52] epoch 114, training loss: 6735.19, average training loss: 10070.31, base loss: 11878.18
[INFO 2017-07-01 17:37:15,283 main.py:52] epoch 115, training loss: 5817.59, average training loss: 10033.65, base loss: 11850.53
[INFO 2017-07-01 17:37:18,178 main.py:52] epoch 116, training loss: 8241.00, average training loss: 10018.33, base loss: 11855.92
[INFO 2017-07-01 17:37:21,032 main.py:52] epoch 117, training loss: 7719.75, average training loss: 9998.85, base loss: 11855.23
[INFO 2017-07-01 17:37:23,926 main.py:52] epoch 118, training loss: 9401.36, average training loss: 9993.83, base loss: 11877.73
[INFO 2017-07-01 17:37:26,834 main.py:52] epoch 119, training loss: 8267.62, average training loss: 9979.44, base loss: 11888.75
[INFO 2017-07-01 17:37:29,705 main.py:52] epoch 120, training loss: 7226.55, average training loss: 9956.69, base loss: 11885.51
[INFO 2017-07-01 17:37:32,590 main.py:52] epoch 121, training loss: 5547.11, average training loss: 9920.55, base loss: 11854.14
[INFO 2017-07-01 17:37:35,437 main.py:52] epoch 122, training loss: 7434.63, average training loss: 9900.33, base loss: 11845.46
[INFO 2017-07-01 17:37:38,297 main.py:52] epoch 123, training loss: 5946.36, average training loss: 9868.45, base loss: 11822.93
[INFO 2017-07-01 17:37:41,162 main.py:52] epoch 124, training loss: 7921.63, average training loss: 9852.87, base loss: 11831.26
[INFO 2017-07-01 17:37:44,046 main.py:52] epoch 125, training loss: 7332.20, average training loss: 9832.87, base loss: 11830.25
[INFO 2017-07-01 17:37:46,944 main.py:52] epoch 126, training loss: 7104.22, average training loss: 9811.38, base loss: 11825.40
[INFO 2017-07-01 17:37:49,845 main.py:52] epoch 127, training loss: 6512.23, average training loss: 9785.61, base loss: 11813.35
[INFO 2017-07-01 17:37:52,719 main.py:52] epoch 128, training loss: 7029.71, average training loss: 9764.24, base loss: 11808.58
[INFO 2017-07-01 17:37:55,586 main.py:52] epoch 129, training loss: 7414.24, average training loss: 9746.17, base loss: 11812.63
[INFO 2017-07-01 17:37:58,477 main.py:52] epoch 130, training loss: 7947.73, average training loss: 9732.44, base loss: 11817.05
[INFO 2017-07-01 17:38:01,336 main.py:52] epoch 131, training loss: 7684.27, average training loss: 9716.92, base loss: 11822.65
[INFO 2017-07-01 17:38:04,200 main.py:52] epoch 132, training loss: 6564.08, average training loss: 9693.22, base loss: 11813.67
[INFO 2017-07-01 17:38:07,080 main.py:52] epoch 133, training loss: 8030.53, average training loss: 9680.81, base loss: 11822.26
[INFO 2017-07-01 17:38:09,984 main.py:52] epoch 134, training loss: 6691.56, average training loss: 9658.67, base loss: 11821.09
[INFO 2017-07-01 17:38:12,827 main.py:52] epoch 135, training loss: 6783.09, average training loss: 9637.52, base loss: 11809.63
[INFO 2017-07-01 17:38:15,735 main.py:52] epoch 136, training loss: 7660.95, average training loss: 9623.09, base loss: 11810.92
[INFO 2017-07-01 17:38:18,591 main.py:52] epoch 137, training loss: 8785.23, average training loss: 9617.02, base loss: 11830.13
[INFO 2017-07-01 17:38:21,467 main.py:52] epoch 138, training loss: 7934.73, average training loss: 9604.92, base loss: 11836.80
[INFO 2017-07-01 17:38:24,338 main.py:52] epoch 139, training loss: 6807.52, average training loss: 9584.94, base loss: 11835.30
[INFO 2017-07-01 17:38:27,210 main.py:52] epoch 140, training loss: 7915.05, average training loss: 9573.10, base loss: 11844.58
[INFO 2017-07-01 17:38:30,103 main.py:52] epoch 141, training loss: 6803.96, average training loss: 9553.59, base loss: 11842.60
[INFO 2017-07-01 17:38:32,964 main.py:52] epoch 142, training loss: 7745.51, average training loss: 9540.95, base loss: 11852.54
[INFO 2017-07-01 17:38:35,823 main.py:52] epoch 143, training loss: 7163.83, average training loss: 9524.44, base loss: 11853.04
[INFO 2017-07-01 17:38:38,724 main.py:52] epoch 144, training loss: 6292.00, average training loss: 9502.15, base loss: 11845.33
[INFO 2017-07-01 17:38:41,607 main.py:52] epoch 145, training loss: 6998.09, average training loss: 9485.00, base loss: 11845.48
[INFO 2017-07-01 17:38:44,454 main.py:52] epoch 146, training loss: 7319.62, average training loss: 9470.27, base loss: 11848.13
[INFO 2017-07-01 17:38:47,305 main.py:52] epoch 147, training loss: 6457.21, average training loss: 9449.91, base loss: 11836.81
[INFO 2017-07-01 17:38:50,156 main.py:52] epoch 148, training loss: 7538.20, average training loss: 9437.08, base loss: 11838.51
[INFO 2017-07-01 17:38:53,053 main.py:52] epoch 149, training loss: 7586.30, average training loss: 9424.74, base loss: 11844.40
[INFO 2017-07-01 17:38:55,977 main.py:52] epoch 150, training loss: 6836.96, average training loss: 9407.60, base loss: 11840.29
[INFO 2017-07-01 17:38:58,894 main.py:52] epoch 151, training loss: 5800.19, average training loss: 9383.87, base loss: 11818.96
[INFO 2017-07-01 17:39:01,768 main.py:52] epoch 152, training loss: 6451.49, average training loss: 9364.70, base loss: 11811.87
[INFO 2017-07-01 17:39:04,706 main.py:52] epoch 153, training loss: 6658.46, average training loss: 9347.13, base loss: 11811.75
[INFO 2017-07-01 17:39:07,575 main.py:52] epoch 154, training loss: 10075.45, average training loss: 9351.83, base loss: 11835.72
[INFO 2017-07-01 17:39:10,487 main.py:52] epoch 155, training loss: 5707.87, average training loss: 9328.47, base loss: 11821.19
[INFO 2017-07-01 17:39:13,343 main.py:52] epoch 156, training loss: 7569.81, average training loss: 9317.27, base loss: 11828.01
[INFO 2017-07-01 17:39:16,225 main.py:52] epoch 157, training loss: 7689.73, average training loss: 9306.97, base loss: 11831.84
[INFO 2017-07-01 17:39:19,118 main.py:52] epoch 158, training loss: 7608.79, average training loss: 9296.29, base loss: 11837.21
[INFO 2017-07-01 17:39:21,961 main.py:52] epoch 159, training loss: 9504.52, average training loss: 9297.59, base loss: 11862.91
[INFO 2017-07-01 17:39:24,837 main.py:52] epoch 160, training loss: 6965.47, average training loss: 9283.10, base loss: 11863.66
[INFO 2017-07-01 17:39:27,703 main.py:52] epoch 161, training loss: 6920.55, average training loss: 9268.52, base loss: 11857.44
[INFO 2017-07-01 17:39:30,591 main.py:52] epoch 162, training loss: 6947.87, average training loss: 9254.28, base loss: 11861.28
[INFO 2017-07-01 17:39:33,454 main.py:52] epoch 163, training loss: 7179.59, average training loss: 9241.63, base loss: 11861.01
[INFO 2017-07-01 17:39:36,313 main.py:52] epoch 164, training loss: 6618.40, average training loss: 9225.74, base loss: 11854.84
[INFO 2017-07-01 17:39:39,155 main.py:52] epoch 165, training loss: 7522.08, average training loss: 9215.47, base loss: 11855.88
[INFO 2017-07-01 17:39:42,060 main.py:52] epoch 166, training loss: 7420.59, average training loss: 9204.72, base loss: 11859.02
[INFO 2017-07-01 17:39:44,920 main.py:52] epoch 167, training loss: 7469.53, average training loss: 9194.40, base loss: 11860.71
[INFO 2017-07-01 17:39:47,841 main.py:52] epoch 168, training loss: 8146.06, average training loss: 9188.19, base loss: 11873.81
[INFO 2017-07-01 17:39:50,718 main.py:52] epoch 169, training loss: 8237.22, average training loss: 9182.60, base loss: 11888.91
[INFO 2017-07-01 17:39:53,583 main.py:52] epoch 170, training loss: 6773.00, average training loss: 9168.51, base loss: 11886.21
[INFO 2017-07-01 17:39:56,474 main.py:52] epoch 171, training loss: 8087.34, average training loss: 9162.22, base loss: 11899.02
[INFO 2017-07-01 17:39:59,314 main.py:52] epoch 172, training loss: 8962.17, average training loss: 9161.07, base loss: 11917.64
[INFO 2017-07-01 17:40:02,173 main.py:52] epoch 173, training loss: 5953.00, average training loss: 9142.63, base loss: 11904.85
[INFO 2017-07-01 17:40:05,066 main.py:52] epoch 174, training loss: 7449.37, average training loss: 9132.95, base loss: 11907.08
[INFO 2017-07-01 17:40:07,940 main.py:52] epoch 175, training loss: 7923.21, average training loss: 9126.08, base loss: 11918.72
[INFO 2017-07-01 17:40:10,844 main.py:52] epoch 176, training loss: 7442.48, average training loss: 9116.57, base loss: 11918.16
[INFO 2017-07-01 17:40:13,736 main.py:52] epoch 177, training loss: 6999.26, average training loss: 9104.67, base loss: 11915.94
[INFO 2017-07-01 17:40:16,617 main.py:52] epoch 178, training loss: 7440.79, average training loss: 9095.38, base loss: 11914.46
[INFO 2017-07-01 17:40:19,509 main.py:52] epoch 179, training loss: 7528.89, average training loss: 9086.67, base loss: 11920.08
[INFO 2017-07-01 17:40:22,318 main.py:52] epoch 180, training loss: 6932.51, average training loss: 9074.77, base loss: 11915.04
[INFO 2017-07-01 17:40:25,270 main.py:52] epoch 181, training loss: 7525.62, average training loss: 9066.26, base loss: 11921.36
[INFO 2017-07-01 17:40:28,166 main.py:52] epoch 182, training loss: 6119.86, average training loss: 9050.16, base loss: 11908.86
[INFO 2017-07-01 17:40:31,023 main.py:52] epoch 183, training loss: 6351.21, average training loss: 9035.49, base loss: 11899.99
[INFO 2017-07-01 17:40:33,925 main.py:52] epoch 184, training loss: 6804.91, average training loss: 9023.43, base loss: 11899.90
[INFO 2017-07-01 17:40:36,796 main.py:52] epoch 185, training loss: 6682.64, average training loss: 9010.85, base loss: 11893.67
[INFO 2017-07-01 17:40:39,671 main.py:52] epoch 186, training loss: 6501.21, average training loss: 8997.43, base loss: 11887.72
[INFO 2017-07-01 17:40:42,572 main.py:52] epoch 187, training loss: 6020.54, average training loss: 8981.59, base loss: 11876.43
[INFO 2017-07-01 17:40:45,405 main.py:52] epoch 188, training loss: 6347.58, average training loss: 8967.66, base loss: 11868.83
[INFO 2017-07-01 17:40:48,239 main.py:52] epoch 189, training loss: 7002.25, average training loss: 8957.31, base loss: 11869.23
[INFO 2017-07-01 17:40:51,138 main.py:52] epoch 190, training loss: 6526.00, average training loss: 8944.58, base loss: 11863.07
[INFO 2017-07-01 17:40:53,981 main.py:52] epoch 191, training loss: 7619.96, average training loss: 8937.69, base loss: 11868.78
[INFO 2017-07-01 17:40:56,856 main.py:52] epoch 192, training loss: 8631.58, average training loss: 8936.10, base loss: 11883.96
[INFO 2017-07-01 17:40:59,743 main.py:52] epoch 193, training loss: 6649.95, average training loss: 8924.32, base loss: 11880.18
[INFO 2017-07-01 17:41:02,628 main.py:52] epoch 194, training loss: 6769.35, average training loss: 8913.26, base loss: 11879.06
[INFO 2017-07-01 17:41:05,505 main.py:52] epoch 195, training loss: 6760.61, average training loss: 8902.28, base loss: 11878.96
[INFO 2017-07-01 17:41:08,375 main.py:52] epoch 196, training loss: 7221.28, average training loss: 8893.75, base loss: 11879.72
[INFO 2017-07-01 17:41:11,256 main.py:52] epoch 197, training loss: 5871.61, average training loss: 8878.48, base loss: 11871.77
[INFO 2017-07-01 17:41:14,129 main.py:52] epoch 198, training loss: 8091.70, average training loss: 8874.53, base loss: 11879.39
[INFO 2017-07-01 17:41:17,024 main.py:52] epoch 199, training loss: 6919.06, average training loss: 8864.75, base loss: 11881.33
[INFO 2017-07-01 17:41:17,024 main.py:54] epoch 199, testing
[INFO 2017-07-01 17:41:29,390 main.py:97] average testing loss: 6680.46, base loss: 11496.28
[INFO 2017-07-01 17:41:29,390 main.py:98] improve_loss: 4815.83, improve_percent: 0.42
[INFO 2017-07-01 17:41:29,393 main.py:62] model save to ./model/final.pth
[INFO 2017-07-01 17:41:29,418 main.py:66] current best improved percent: 0.42
[INFO 2017-07-01 17:41:32,323 main.py:52] epoch 200, training loss: 8098.90, average training loss: 8860.94, base loss: 11889.16
[INFO 2017-07-01 17:41:35,211 main.py:52] epoch 201, training loss: 8325.15, average training loss: 8858.29, base loss: 11899.40
[INFO 2017-07-01 17:41:38,078 main.py:52] epoch 202, training loss: 6808.30, average training loss: 8848.19, base loss: 11893.54
[INFO 2017-07-01 17:41:40,930 main.py:52] epoch 203, training loss: 6215.10, average training loss: 8835.29, base loss: 11886.17
[INFO 2017-07-01 17:41:43,802 main.py:52] epoch 204, training loss: 7458.39, average training loss: 8828.57, base loss: 11892.03
[INFO 2017-07-01 17:41:46,735 main.py:52] epoch 205, training loss: 9137.63, average training loss: 8830.07, base loss: 11914.67
[INFO 2017-07-01 17:41:49,709 main.py:52] epoch 206, training loss: 6515.55, average training loss: 8818.89, base loss: 11912.28
[INFO 2017-07-01 17:41:52,620 main.py:52] epoch 207, training loss: 6212.32, average training loss: 8806.36, base loss: 11905.21
[INFO 2017-07-01 17:41:55,524 main.py:52] epoch 208, training loss: 5988.53, average training loss: 8792.87, base loss: 11898.23
[INFO 2017-07-01 17:41:58,349 main.py:52] epoch 209, training loss: 7250.09, average training loss: 8785.53, base loss: 11899.45
[INFO 2017-07-01 17:42:01,250 main.py:52] epoch 210, training loss: 8986.48, average training loss: 8786.48, base loss: 11912.56
[INFO 2017-07-01 17:42:04,143 main.py:52] epoch 211, training loss: 6459.34, average training loss: 8775.50, base loss: 11908.19
[INFO 2017-07-01 17:42:06,992 main.py:52] epoch 212, training loss: 7958.96, average training loss: 8771.67, base loss: 11917.04
[INFO 2017-07-01 17:42:09,896 main.py:52] epoch 213, training loss: 6448.66, average training loss: 8760.81, base loss: 11910.73
[INFO 2017-07-01 17:42:12,824 main.py:52] epoch 214, training loss: 5499.89, average training loss: 8745.65, base loss: 11894.56
[INFO 2017-07-01 17:42:15,799 main.py:52] epoch 215, training loss: 5434.65, average training loss: 8730.32, base loss: 11882.02
[INFO 2017-07-01 17:42:18,799 main.py:52] epoch 216, training loss: 7540.21, average training loss: 8724.83, base loss: 11886.11
[INFO 2017-07-01 17:42:21,707 main.py:52] epoch 217, training loss: 8372.91, average training loss: 8723.22, base loss: 11898.92
[INFO 2017-07-01 17:42:24,565 main.py:52] epoch 218, training loss: 7590.77, average training loss: 8718.05, base loss: 11907.32
[INFO 2017-07-01 17:42:27,427 main.py:52] epoch 219, training loss: 6048.64, average training loss: 8705.91, base loss: 11895.92
[INFO 2017-07-01 17:42:30,266 main.py:52] epoch 220, training loss: 6017.22, average training loss: 8693.75, base loss: 11888.03
[INFO 2017-07-01 17:42:33,142 main.py:52] epoch 221, training loss: 7735.71, average training loss: 8689.43, base loss: 11895.31
[INFO 2017-07-01 17:42:36,036 main.py:52] epoch 222, training loss: 6154.67, average training loss: 8678.07, base loss: 11886.19
[INFO 2017-07-01 17:42:38,911 main.py:52] epoch 223, training loss: 6385.31, average training loss: 8667.83, base loss: 11878.10
[INFO 2017-07-01 17:42:41,807 main.py:52] epoch 224, training loss: 5365.53, average training loss: 8653.15, base loss: 11862.41
[INFO 2017-07-01 17:42:44,731 main.py:52] epoch 225, training loss: 7247.52, average training loss: 8646.93, base loss: 11866.14
[INFO 2017-07-01 17:42:47,601 main.py:52] epoch 226, training loss: 6567.74, average training loss: 8637.77, base loss: 11865.39
[INFO 2017-07-01 17:42:50,460 main.py:52] epoch 227, training loss: 6749.96, average training loss: 8629.49, base loss: 11863.51
[INFO 2017-07-01 17:42:53,346 main.py:52] epoch 228, training loss: 5336.55, average training loss: 8615.12, base loss: 11849.80
[INFO 2017-07-01 17:42:56,237 main.py:52] epoch 229, training loss: 7141.48, average training loss: 8608.71, base loss: 11852.28
[INFO 2017-07-01 17:42:59,133 main.py:52] epoch 230, training loss: 6554.89, average training loss: 8599.82, base loss: 11851.63
[INFO 2017-07-01 17:43:02,000 main.py:52] epoch 231, training loss: 8126.24, average training loss: 8597.78, base loss: 11854.68
[INFO 2017-07-01 17:43:04,916 main.py:52] epoch 232, training loss: 8055.77, average training loss: 8595.45, base loss: 11860.77
[INFO 2017-07-01 17:43:07,812 main.py:52] epoch 233, training loss: 7107.43, average training loss: 8589.09, base loss: 11861.29
[INFO 2017-07-01 17:43:10,684 main.py:52] epoch 234, training loss: 5955.51, average training loss: 8577.88, base loss: 11851.46
[INFO 2017-07-01 17:43:13,539 main.py:52] epoch 235, training loss: 7162.51, average training loss: 8571.89, base loss: 11854.94
[INFO 2017-07-01 17:43:16,363 main.py:52] epoch 236, training loss: 7985.12, average training loss: 8569.41, base loss: 11864.90
[INFO 2017-07-01 17:43:19,198 main.py:52] epoch 237, training loss: 7652.23, average training loss: 8565.56, base loss: 11870.55
[INFO 2017-07-01 17:43:22,096 main.py:52] epoch 238, training loss: 5761.00, average training loss: 8553.82, base loss: 11862.78
[INFO 2017-07-01 17:43:24,994 main.py:52] epoch 239, training loss: 6939.59, average training loss: 8547.10, base loss: 11862.08
[INFO 2017-07-01 17:43:27,903 main.py:52] epoch 240, training loss: 6854.15, average training loss: 8540.07, base loss: 11862.53
[INFO 2017-07-01 17:43:30,751 main.py:52] epoch 241, training loss: 7868.79, average training loss: 8537.30, base loss: 11867.00
[INFO 2017-07-01 17:43:33,602 main.py:52] epoch 242, training loss: 6990.24, average training loss: 8530.93, base loss: 11867.53
[INFO 2017-07-01 17:43:36,446 main.py:52] epoch 243, training loss: 4782.39, average training loss: 8515.57, base loss: 11849.36
[INFO 2017-07-01 17:43:39,390 main.py:52] epoch 244, training loss: 7161.73, average training loss: 8510.04, base loss: 11850.94
[INFO 2017-07-01 17:43:42,272 main.py:52] epoch 245, training loss: 6856.98, average training loss: 8503.32, base loss: 11849.73
[INFO 2017-07-01 17:43:45,159 main.py:52] epoch 246, training loss: 8727.63, average training loss: 8504.23, base loss: 11860.80
[INFO 2017-07-01 17:43:47,994 main.py:52] epoch 247, training loss: 5682.80, average training loss: 8492.85, base loss: 11850.41
[INFO 2017-07-01 17:43:50,869 main.py:52] epoch 248, training loss: 6850.22, average training loss: 8486.26, base loss: 11848.83
[INFO 2017-07-01 17:43:53,755 main.py:52] epoch 249, training loss: 7541.05, average training loss: 8482.48, base loss: 11855.75
[INFO 2017-07-01 17:43:56,700 main.py:52] epoch 250, training loss: 6330.66, average training loss: 8473.90, base loss: 11852.06
[INFO 2017-07-01 17:43:59,562 main.py:52] epoch 251, training loss: 7028.04, average training loss: 8468.17, base loss: 11852.46
[INFO 2017-07-01 17:44:02,443 main.py:52] epoch 252, training loss: 5572.11, average training loss: 8456.72, base loss: 11842.16
[INFO 2017-07-01 17:44:05,358 main.py:52] epoch 253, training loss: 6185.02, average training loss: 8447.78, base loss: 11835.55
[INFO 2017-07-01 17:44:08,241 main.py:52] epoch 254, training loss: 6581.40, average training loss: 8440.46, base loss: 11832.38
[INFO 2017-07-01 17:44:11,127 main.py:52] epoch 255, training loss: 7957.40, average training loss: 8438.57, base loss: 11840.64
[INFO 2017-07-01 17:44:14,024 main.py:52] epoch 256, training loss: 6188.83, average training loss: 8429.82, base loss: 11834.22
[INFO 2017-07-01 17:44:16,867 main.py:52] epoch 257, training loss: 7343.74, average training loss: 8425.61, base loss: 11834.29
[INFO 2017-07-01 17:44:19,790 main.py:52] epoch 258, training loss: 6211.00, average training loss: 8417.06, base loss: 11828.58
[INFO 2017-07-01 17:44:22,678 main.py:52] epoch 259, training loss: 7472.27, average training loss: 8413.42, base loss: 11835.37
[INFO 2017-07-01 17:44:25,530 main.py:52] epoch 260, training loss: 7103.63, average training loss: 8408.40, base loss: 11837.64
[INFO 2017-07-01 17:44:28,397 main.py:52] epoch 261, training loss: 6669.69, average training loss: 8401.77, base loss: 11833.57
[INFO 2017-07-01 17:44:31,259 main.py:52] epoch 262, training loss: 7878.47, average training loss: 8399.78, base loss: 11839.65
[INFO 2017-07-01 17:44:34,116 main.py:52] epoch 263, training loss: 7036.13, average training loss: 8394.61, base loss: 11840.70
[INFO 2017-07-01 17:44:37,000 main.py:52] epoch 264, training loss: 7679.42, average training loss: 8391.91, base loss: 11848.16
[INFO 2017-07-01 17:44:39,904 main.py:52] epoch 265, training loss: 7490.27, average training loss: 8388.52, base loss: 11852.15
[INFO 2017-07-01 17:44:42,787 main.py:52] epoch 266, training loss: 5839.20, average training loss: 8378.98, base loss: 11844.74
[INFO 2017-07-01 17:44:45,653 main.py:52] epoch 267, training loss: 6448.82, average training loss: 8371.77, base loss: 11842.18
[INFO 2017-07-01 17:44:48,561 main.py:52] epoch 268, training loss: 5744.73, average training loss: 8362.01, base loss: 11831.84
[INFO 2017-07-01 17:44:51,483 main.py:52] epoch 269, training loss: 6760.88, average training loss: 8356.08, base loss: 11830.96
[INFO 2017-07-01 17:44:54,368 main.py:52] epoch 270, training loss: 6608.18, average training loss: 8349.63, base loss: 11829.53
[INFO 2017-07-01 17:44:57,215 main.py:52] epoch 271, training loss: 7068.99, average training loss: 8344.92, base loss: 11830.79
[INFO 2017-07-01 17:45:00,101 main.py:52] epoch 272, training loss: 6634.00, average training loss: 8338.65, base loss: 11830.32
[INFO 2017-07-01 17:45:02,968 main.py:52] epoch 273, training loss: 5958.79, average training loss: 8329.97, base loss: 11824.70
[INFO 2017-07-01 17:45:05,814 main.py:52] epoch 274, training loss: 7109.68, average training loss: 8325.53, base loss: 11826.97
[INFO 2017-07-01 17:45:08,685 main.py:52] epoch 275, training loss: 7431.61, average training loss: 8322.29, base loss: 11829.06
