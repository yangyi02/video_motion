[INFO 2017-07-01 17:56:47,764 main.py:175] Namespace(batch_size=32, display=False, flow_dir='flow', flow_video_dir='flow-video', flow_video_fps=1, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=4, num_channel=3, num_inputs=2, save_dir='./model', test=False, test_dir='/home/yi/Downloads/mpii-test-64', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='/home/yi/Downloads/mpii-test-64', train_epoch=100000)
[INFO 2017-07-01 17:56:53,449 main.py:52] epoch 0, training loss: 36971.21, average training loss: 36971.21, base loss: 14543.01
[INFO 2017-07-01 17:56:56,871 main.py:52] epoch 1, training loss: 34208.36, average training loss: 35589.78, base loss: 16656.24
[INFO 2017-07-01 17:57:00,348 main.py:52] epoch 2, training loss: 28005.36, average training loss: 33061.64, base loss: 16391.69
[INFO 2017-07-01 17:57:03,742 main.py:52] epoch 3, training loss: 25507.83, average training loss: 31173.19, base loss: 16744.77
[INFO 2017-07-01 17:57:07,141 main.py:52] epoch 4, training loss: 24065.40, average training loss: 29751.63, base loss: 17147.34
[INFO 2017-07-01 17:57:11,197 main.py:52] epoch 5, training loss: 21272.24, average training loss: 28338.40, base loss: 17146.39
[INFO 2017-07-01 17:57:15,390 main.py:52] epoch 6, training loss: 20427.09, average training loss: 27208.21, base loss: 17371.03
[INFO 2017-07-01 17:57:19,690 main.py:52] epoch 7, training loss: 18618.12, average training loss: 26134.45, base loss: 17426.15
[INFO 2017-07-01 17:57:23,842 main.py:52] epoch 8, training loss: 15288.64, average training loss: 24929.36, base loss: 17114.38
[INFO 2017-07-01 17:57:27,969 main.py:52] epoch 9, training loss: 15451.41, average training loss: 23981.57, base loss: 17088.65
[INFO 2017-07-01 17:57:32,170 main.py:52] epoch 10, training loss: 14528.90, average training loss: 23122.23, base loss: 17065.58
[INFO 2017-07-01 17:57:36,326 main.py:52] epoch 11, training loss: 13611.47, average training loss: 22329.67, base loss: 17037.86
[INFO 2017-07-01 17:57:40,475 main.py:52] epoch 12, training loss: 14517.23, average training loss: 21728.71, base loss: 17117.93
[INFO 2017-07-01 17:57:44,679 main.py:52] epoch 13, training loss: 12584.51, average training loss: 21075.56, base loss: 17069.10
[INFO 2017-07-01 17:57:48,829 main.py:52] epoch 14, training loss: 14453.53, average training loss: 20634.09, base loss: 17248.89
[INFO 2017-07-01 17:57:53,076 main.py:52] epoch 15, training loss: 13318.34, average training loss: 20176.85, base loss: 17312.87
[INFO 2017-07-01 17:57:57,264 main.py:52] epoch 16, training loss: 11858.24, average training loss: 19687.52, base loss: 17275.16
[INFO 2017-07-01 17:58:01,454 main.py:52] epoch 17, training loss: 10255.06, average training loss: 19163.50, base loss: 17110.94
[INFO 2017-07-01 17:58:05,617 main.py:52] epoch 18, training loss: 9778.94, average training loss: 18669.57, base loss: 16945.47
[INFO 2017-07-01 17:58:09,792 main.py:52] epoch 19, training loss: 11804.51, average training loss: 18326.32, base loss: 16953.02
[INFO 2017-07-01 17:58:13,973 main.py:52] epoch 20, training loss: 12706.16, average training loss: 18058.69, base loss: 16992.69
[INFO 2017-07-01 17:58:18,194 main.py:52] epoch 21, training loss: 12179.36, average training loss: 17791.45, base loss: 16997.11
[INFO 2017-07-01 17:58:22,325 main.py:52] epoch 22, training loss: 11879.64, average training loss: 17534.42, base loss: 17003.61
[INFO 2017-07-01 17:58:26,481 main.py:52] epoch 23, training loss: 11248.29, average training loss: 17272.49, base loss: 16975.85
[INFO 2017-07-01 17:58:30,642 main.py:52] epoch 24, training loss: 11163.38, average training loss: 17028.13, base loss: 16959.45
[INFO 2017-07-01 17:58:34,800 main.py:52] epoch 25, training loss: 10168.96, average training loss: 16764.31, base loss: 16868.22
[INFO 2017-07-01 17:58:38,921 main.py:52] epoch 26, training loss: 12030.92, average training loss: 16589.00, base loss: 16874.76
[INFO 2017-07-01 17:58:43,105 main.py:52] epoch 27, training loss: 12794.94, average training loss: 16453.50, base loss: 16938.80
[INFO 2017-07-01 17:58:47,261 main.py:52] epoch 28, training loss: 11031.68, average training loss: 16266.54, base loss: 16918.64
[INFO 2017-07-01 17:58:51,390 main.py:52] epoch 29, training loss: 11964.21, average training loss: 16123.13, base loss: 16931.88
[INFO 2017-07-01 17:58:55,588 main.py:52] epoch 30, training loss: 11300.82, average training loss: 15967.57, base loss: 16931.84
[INFO 2017-07-01 17:58:59,701 main.py:52] epoch 31, training loss: 10768.31, average training loss: 15805.10, base loss: 16890.50
[INFO 2017-07-01 17:59:03,844 main.py:52] epoch 32, training loss: 12622.80, average training loss: 15708.66, base loss: 16940.74
[INFO 2017-07-01 17:59:07,992 main.py:52] epoch 33, training loss: 11274.96, average training loss: 15578.26, base loss: 16941.37
[INFO 2017-07-01 17:59:12,244 main.py:52] epoch 34, training loss: 10538.51, average training loss: 15434.27, base loss: 16902.97
[INFO 2017-07-01 17:59:16,376 main.py:52] epoch 35, training loss: 12755.70, average training loss: 15359.86, base loss: 16956.23
[INFO 2017-07-01 17:59:20,574 main.py:52] epoch 36, training loss: 11105.40, average training loss: 15244.88, base loss: 16952.85
[INFO 2017-07-01 17:59:24,743 main.py:52] epoch 37, training loss: 13004.76, average training loss: 15185.93, base loss: 17004.89
[INFO 2017-07-01 17:59:28,924 main.py:52] epoch 38, training loss: 10842.85, average training loss: 15074.57, base loss: 16995.10
[INFO 2017-07-01 17:59:33,136 main.py:52] epoch 39, training loss: 10913.48, average training loss: 14970.54, base loss: 16989.03
[INFO 2017-07-01 17:59:37,246 main.py:52] epoch 40, training loss: 10266.69, average training loss: 14855.81, base loss: 16942.01
[INFO 2017-07-01 17:59:41,456 main.py:52] epoch 41, training loss: 10269.14, average training loss: 14746.60, base loss: 16920.24
[INFO 2017-07-01 17:59:45,735 main.py:52] epoch 42, training loss: 11405.48, average training loss: 14668.90, base loss: 16937.83
[INFO 2017-07-01 17:59:49,947 main.py:52] epoch 43, training loss: 10731.38, average training loss: 14579.41, base loss: 16931.69
[INFO 2017-07-01 17:59:54,154 main.py:52] epoch 44, training loss: 10426.55, average training loss: 14487.13, base loss: 16898.71
[INFO 2017-07-01 17:59:58,371 main.py:52] epoch 45, training loss: 12173.53, average training loss: 14436.83, base loss: 16935.07
[INFO 2017-07-01 18:00:02,553 main.py:52] epoch 46, training loss: 10312.87, average training loss: 14349.09, base loss: 16926.66
[INFO 2017-07-01 18:00:06,770 main.py:52] epoch 47, training loss: 11119.54, average training loss: 14281.81, base loss: 16924.53
[INFO 2017-07-01 18:00:11,026 main.py:52] epoch 48, training loss: 10154.71, average training loss: 14197.58, base loss: 16917.92
[INFO 2017-07-01 18:00:15,193 main.py:52] epoch 49, training loss: 12636.44, average training loss: 14166.36, base loss: 16959.02
[INFO 2017-07-01 18:00:19,362 main.py:52] epoch 50, training loss: 11208.68, average training loss: 14108.36, base loss: 16956.47
[INFO 2017-07-01 18:00:23,602 main.py:52] epoch 51, training loss: 11588.63, average training loss: 14059.91, base loss: 16970.86
[INFO 2017-07-01 18:00:27,795 main.py:52] epoch 52, training loss: 11396.14, average training loss: 14009.65, base loss: 16953.91
[INFO 2017-07-01 18:00:31,988 main.py:52] epoch 53, training loss: 9444.70, average training loss: 13925.11, base loss: 16914.14
[INFO 2017-07-01 18:00:36,150 main.py:52] epoch 54, training loss: 9745.15, average training loss: 13849.11, base loss: 16892.96
[INFO 2017-07-01 18:00:40,284 main.py:52] epoch 55, training loss: 8546.92, average training loss: 13754.43, base loss: 16823.43
[INFO 2017-07-01 18:00:44,425 main.py:52] epoch 56, training loss: 10869.69, average training loss: 13703.82, base loss: 16827.27
[INFO 2017-07-01 18:00:48,674 main.py:52] epoch 57, training loss: 11530.98, average training loss: 13666.36, base loss: 16852.83
[INFO 2017-07-01 18:00:52,848 main.py:52] epoch 58, training loss: 12089.41, average training loss: 13639.63, base loss: 16880.96
[INFO 2017-07-01 18:00:57,015 main.py:52] epoch 59, training loss: 12280.08, average training loss: 13616.97, base loss: 16928.38
[INFO 2017-07-01 18:01:01,199 main.py:52] epoch 60, training loss: 11784.52, average training loss: 13586.93, base loss: 16950.85
[INFO 2017-07-01 18:01:05,320 main.py:52] epoch 61, training loss: 12802.79, average training loss: 13574.28, base loss: 16991.43
[INFO 2017-07-01 18:01:09,534 main.py:52] epoch 62, training loss: 9703.29, average training loss: 13512.84, base loss: 16954.80
[INFO 2017-07-01 18:01:13,777 main.py:52] epoch 63, training loss: 10658.80, average training loss: 13468.24, base loss: 16973.15
[INFO 2017-07-01 18:01:17,947 main.py:52] epoch 64, training loss: 10077.47, average training loss: 13416.08, base loss: 16969.38
[INFO 2017-07-01 18:01:22,152 main.py:52] epoch 65, training loss: 9310.07, average training loss: 13353.87, base loss: 16939.85
[INFO 2017-07-01 18:01:26,302 main.py:52] epoch 66, training loss: 12630.48, average training loss: 13343.07, base loss: 16979.89
[INFO 2017-07-01 18:01:30,404 main.py:52] epoch 67, training loss: 9961.92, average training loss: 13293.35, base loss: 16976.14
[INFO 2017-07-01 18:01:34,542 main.py:52] epoch 68, training loss: 10477.83, average training loss: 13252.54, base loss: 16985.25
[INFO 2017-07-01 18:01:38,657 main.py:52] epoch 69, training loss: 9833.57, average training loss: 13203.70, base loss: 16969.49
[INFO 2017-07-01 18:01:42,777 main.py:52] epoch 70, training loss: 9354.93, average training loss: 13149.49, base loss: 16939.54
[INFO 2017-07-01 18:01:46,970 main.py:52] epoch 71, training loss: 10488.83, average training loss: 13112.54, base loss: 16946.82
[INFO 2017-07-01 18:01:51,137 main.py:52] epoch 72, training loss: 11052.25, average training loss: 13084.31, base loss: 16964.42
[INFO 2017-07-01 18:01:55,313 main.py:52] epoch 73, training loss: 9527.04, average training loss: 13036.24, base loss: 16940.63
[INFO 2017-07-01 18:01:59,485 main.py:52] epoch 74, training loss: 11195.11, average training loss: 13011.69, base loss: 16967.58
[INFO 2017-07-01 18:02:03,622 main.py:52] epoch 75, training loss: 11707.04, average training loss: 12994.53, base loss: 16994.62
[INFO 2017-07-01 18:02:07,810 main.py:52] epoch 76, training loss: 8801.50, average training loss: 12940.07, base loss: 16961.28
[INFO 2017-07-01 18:02:11,978 main.py:52] epoch 77, training loss: 10118.13, average training loss: 12903.89, base loss: 16962.30
[INFO 2017-07-01 18:02:16,191 main.py:52] epoch 78, training loss: 10886.63, average training loss: 12878.36, base loss: 16963.64
[INFO 2017-07-01 18:02:20,424 main.py:52] epoch 79, training loss: 9665.48, average training loss: 12838.20, base loss: 16950.45
[INFO 2017-07-01 18:02:24,657 main.py:52] epoch 80, training loss: 8618.88, average training loss: 12786.11, base loss: 16921.62
[INFO 2017-07-01 18:02:28,910 main.py:52] epoch 81, training loss: 10167.30, average training loss: 12754.17, base loss: 16914.95
[INFO 2017-07-01 18:02:33,022 main.py:52] epoch 82, training loss: 10403.21, average training loss: 12725.85, base loss: 16919.42
[INFO 2017-07-01 18:02:37,256 main.py:52] epoch 83, training loss: 9491.51, average training loss: 12687.34, base loss: 16910.65
[INFO 2017-07-01 18:02:41,540 main.py:52] epoch 84, training loss: 9671.39, average training loss: 12651.86, base loss: 16904.75
[INFO 2017-07-01 18:02:45,762 main.py:52] epoch 85, training loss: 10092.34, average training loss: 12622.10, base loss: 16900.39
[INFO 2017-07-01 18:02:49,979 main.py:52] epoch 86, training loss: 11154.43, average training loss: 12605.23, base loss: 16918.35
[INFO 2017-07-01 18:02:54,144 main.py:52] epoch 87, training loss: 9591.95, average training loss: 12570.99, base loss: 16910.87
[INFO 2017-07-01 18:02:58,271 main.py:52] epoch 88, training loss: 10086.08, average training loss: 12543.07, base loss: 16910.45
[INFO 2017-07-01 18:03:02,476 main.py:52] epoch 89, training loss: 9293.66, average training loss: 12506.96, base loss: 16909.89
[INFO 2017-07-01 18:03:06,658 main.py:52] epoch 90, training loss: 10023.55, average training loss: 12479.67, base loss: 16911.72
[INFO 2017-07-01 18:03:10,887 main.py:52] epoch 91, training loss: 10356.05, average training loss: 12456.59, base loss: 16923.71
[INFO 2017-07-01 18:03:14,998 main.py:52] epoch 92, training loss: 10812.39, average training loss: 12438.91, base loss: 16929.87
[INFO 2017-07-01 18:03:19,300 main.py:52] epoch 93, training loss: 8768.69, average training loss: 12399.86, base loss: 16902.00
[INFO 2017-07-01 18:03:23,476 main.py:52] epoch 94, training loss: 10085.74, average training loss: 12375.51, base loss: 16908.47
[INFO 2017-07-01 18:03:27,665 main.py:52] epoch 95, training loss: 9616.13, average training loss: 12346.76, base loss: 16900.29
[INFO 2017-07-01 18:03:31,821 main.py:52] epoch 96, training loss: 9174.55, average training loss: 12314.06, base loss: 16884.60
[INFO 2017-07-01 18:03:36,005 main.py:52] epoch 97, training loss: 9425.25, average training loss: 12284.58, base loss: 16882.25
[INFO 2017-07-01 18:03:40,197 main.py:52] epoch 98, training loss: 10299.72, average training loss: 12264.53, base loss: 16894.52
[INFO 2017-07-01 18:03:44,413 main.py:52] epoch 99, training loss: 10012.20, average training loss: 12242.01, base loss: 16894.62
[INFO 2017-07-01 18:03:44,413 main.py:54] epoch 99, testing
[INFO 2017-07-01 18:03:44,413 main.py:61] model save to ./model/final.pth
[INFO 2017-07-01 18:03:48,743 main.py:52] epoch 100, training loss: 9722.88, average training loss: 12217.07, base loss: 16888.78
[INFO 2017-07-01 18:03:52,851 main.py:52] epoch 101, training loss: 9979.13, average training loss: 12195.13, base loss: 16900.46
[INFO 2017-07-01 18:03:57,064 main.py:52] epoch 102, training loss: 9730.52, average training loss: 12171.20, base loss: 16896.57
[INFO 2017-07-01 18:04:01,194 main.py:52] epoch 103, training loss: 10546.88, average training loss: 12155.58, base loss: 16900.73
[INFO 2017-07-01 18:04:05,359 main.py:52] epoch 104, training loss: 9964.65, average training loss: 12134.71, base loss: 16893.47
[INFO 2017-07-01 18:04:09,538 main.py:52] epoch 105, training loss: 9817.62, average training loss: 12112.85, base loss: 16894.22
[INFO 2017-07-01 18:04:13,691 main.py:52] epoch 106, training loss: 8986.02, average training loss: 12083.63, base loss: 16890.48
[INFO 2017-07-01 18:04:17,859 main.py:52] epoch 107, training loss: 9632.35, average training loss: 12060.93, base loss: 16892.71
[INFO 2017-07-01 18:04:22,067 main.py:52] epoch 108, training loss: 8536.99, average training loss: 12028.60, base loss: 16869.55
[INFO 2017-07-01 18:04:26,330 main.py:52] epoch 109, training loss: 8970.25, average training loss: 12000.80, base loss: 16857.12
[INFO 2017-07-01 18:04:30,494 main.py:52] epoch 110, training loss: 8936.78, average training loss: 11973.20, base loss: 16849.10
[INFO 2017-07-01 18:04:34,626 main.py:52] epoch 111, training loss: 9421.04, average training loss: 11950.41, base loss: 16851.03
[INFO 2017-07-01 18:04:38,804 main.py:52] epoch 112, training loss: 9684.73, average training loss: 11930.36, base loss: 16854.86
[INFO 2017-07-01 18:04:43,085 main.py:52] epoch 113, training loss: 10786.05, average training loss: 11920.32, base loss: 16875.62
[INFO 2017-07-01 18:04:47,221 main.py:52] epoch 114, training loss: 8562.61, average training loss: 11891.13, base loss: 16858.88
[INFO 2017-07-01 18:04:51,384 main.py:52] epoch 115, training loss: 8805.46, average training loss: 11864.52, base loss: 16845.12
[INFO 2017-07-01 18:04:55,603 main.py:52] epoch 116, training loss: 9426.57, average training loss: 11843.69, base loss: 16845.21
[INFO 2017-07-01 18:04:59,786 main.py:52] epoch 117, training loss: 9882.15, average training loss: 11827.06, base loss: 16848.54
[INFO 2017-07-01 18:05:03,964 main.py:52] epoch 118, training loss: 9915.13, average training loss: 11811.00, base loss: 16850.72
[INFO 2017-07-01 18:05:08,118 main.py:52] epoch 119, training loss: 8985.54, average training loss: 11787.45, base loss: 16840.26
[INFO 2017-07-01 18:05:12,452 main.py:52] epoch 120, training loss: 8912.90, average training loss: 11763.70, base loss: 16831.73
[INFO 2017-07-01 18:05:16,606 main.py:52] epoch 121, training loss: 8950.56, average training loss: 11740.64, base loss: 16824.62
[INFO 2017-07-01 18:05:20,852 main.py:52] epoch 122, training loss: 9354.93, average training loss: 11721.24, base loss: 16822.71
[INFO 2017-07-01 18:05:24,955 main.py:52] epoch 123, training loss: 9620.67, average training loss: 11704.30, base loss: 16814.67
[INFO 2017-07-01 18:05:29,202 main.py:52] epoch 124, training loss: 9094.32, average training loss: 11683.42, base loss: 16801.86
[INFO 2017-07-01 18:05:33,394 main.py:52] epoch 125, training loss: 9469.35, average training loss: 11665.85, base loss: 16799.87
[INFO 2017-07-01 18:05:37,603 main.py:52] epoch 126, training loss: 9482.48, average training loss: 11648.66, base loss: 16800.74
[INFO 2017-07-01 18:05:41,746 main.py:52] epoch 127, training loss: 8895.13, average training loss: 11627.15, base loss: 16796.39
[INFO 2017-07-01 18:05:46,005 main.py:52] epoch 128, training loss: 10022.80, average training loss: 11614.71, base loss: 16791.54
[INFO 2017-07-01 18:05:50,188 main.py:52] epoch 129, training loss: 10143.27, average training loss: 11603.39, base loss: 16795.24
[INFO 2017-07-01 18:05:54,473 main.py:52] epoch 130, training loss: 8933.06, average training loss: 11583.01, base loss: 16788.03
[INFO 2017-07-01 18:05:58,609 main.py:52] epoch 131, training loss: 8730.54, average training loss: 11561.40, base loss: 16772.07
[INFO 2017-07-01 18:06:02,764 main.py:52] epoch 132, training loss: 8808.53, average training loss: 11540.70, base loss: 16763.34
[INFO 2017-07-01 18:06:06,941 main.py:52] epoch 133, training loss: 9117.45, average training loss: 11522.61, base loss: 16760.84
[INFO 2017-07-01 18:06:11,095 main.py:52] epoch 134, training loss: 10236.66, average training loss: 11513.09, base loss: 16769.21
[INFO 2017-07-01 18:06:15,263 main.py:52] epoch 135, training loss: 8828.84, average training loss: 11493.35, base loss: 16756.24
[INFO 2017-07-01 18:06:19,497 main.py:52] epoch 136, training loss: 8887.68, average training loss: 11474.33, base loss: 16749.47
[INFO 2017-07-01 18:06:23,640 main.py:52] epoch 137, training loss: 8425.48, average training loss: 11452.24, base loss: 16735.68
[INFO 2017-07-01 18:06:27,819 main.py:52] epoch 138, training loss: 10764.53, average training loss: 11447.29, base loss: 16740.61
[INFO 2017-07-01 18:06:32,125 main.py:52] epoch 139, training loss: 9159.68, average training loss: 11430.95, base loss: 16734.54
[INFO 2017-07-01 18:06:36,359 main.py:52] epoch 140, training loss: 9100.25, average training loss: 11414.42, base loss: 16738.74
[INFO 2017-07-01 18:06:40,485 main.py:52] epoch 141, training loss: 10136.23, average training loss: 11405.42, base loss: 16743.32
[INFO 2017-07-01 18:06:44,688 main.py:52] epoch 142, training loss: 9578.86, average training loss: 11392.65, base loss: 16744.86
[INFO 2017-07-01 18:06:48,861 main.py:52] epoch 143, training loss: 9412.95, average training loss: 11378.90, base loss: 16737.71
[INFO 2017-07-01 18:06:53,050 main.py:52] epoch 144, training loss: 8804.76, average training loss: 11361.15, base loss: 16727.83
[INFO 2017-07-01 18:06:57,189 main.py:52] epoch 145, training loss: 10635.04, average training loss: 11356.17, base loss: 16745.71
[INFO 2017-07-01 18:07:01,363 main.py:52] epoch 146, training loss: 8549.16, average training loss: 11337.08, base loss: 16734.07
[INFO 2017-07-01 18:07:05,557 main.py:52] epoch 147, training loss: 8593.14, average training loss: 11318.54, base loss: 16722.60
[INFO 2017-07-01 18:07:09,783 main.py:52] epoch 148, training loss: 9069.11, average training loss: 11303.44, base loss: 16717.30
[INFO 2017-07-01 18:07:13,905 main.py:52] epoch 149, training loss: 8615.99, average training loss: 11285.52, base loss: 16705.60
[INFO 2017-07-01 18:07:18,074 main.py:52] epoch 150, training loss: 9738.34, average training loss: 11275.28, base loss: 16707.36
[INFO 2017-07-01 18:07:22,423 main.py:52] epoch 151, training loss: 8995.70, average training loss: 11260.28, base loss: 16701.03
[INFO 2017-07-01 18:07:26,609 main.py:52] epoch 152, training loss: 11082.63, average training loss: 11259.12, base loss: 16719.59
[INFO 2017-07-01 18:07:30,782 main.py:52] epoch 153, training loss: 9213.53, average training loss: 11245.84, base loss: 16718.42
[INFO 2017-07-01 18:07:34,985 main.py:52] epoch 154, training loss: 9383.03, average training loss: 11233.82, base loss: 16714.05
[INFO 2017-07-01 18:07:39,132 main.py:52] epoch 155, training loss: 9547.58, average training loss: 11223.01, base loss: 16711.61
[INFO 2017-07-01 18:07:43,315 main.py:52] epoch 156, training loss: 10537.26, average training loss: 11218.64, base loss: 16719.54
[INFO 2017-07-01 18:07:47,546 main.py:52] epoch 157, training loss: 11723.95, average training loss: 11221.84, base loss: 16738.43
[INFO 2017-07-01 18:07:51,711 main.py:52] epoch 158, training loss: 11201.51, average training loss: 11221.71, base loss: 16756.04
[INFO 2017-07-01 18:07:55,857 main.py:52] epoch 159, training loss: 9433.46, average training loss: 11210.54, base loss: 16763.04
[INFO 2017-07-01 18:07:59,990 main.py:52] epoch 160, training loss: 9805.09, average training loss: 11201.81, base loss: 16766.20
[INFO 2017-07-01 18:08:04,198 main.py:52] epoch 161, training loss: 9425.85, average training loss: 11190.84, base loss: 16766.40
[INFO 2017-07-01 18:08:08,381 main.py:52] epoch 162, training loss: 9495.83, average training loss: 11180.44, base loss: 16765.49
[INFO 2017-07-01 18:08:12,558 main.py:52] epoch 163, training loss: 10181.54, average training loss: 11174.35, base loss: 16779.18
[INFO 2017-07-01 18:08:16,739 main.py:52] epoch 164, training loss: 9466.49, average training loss: 11164.00, base loss: 16787.94
[INFO 2017-07-01 18:08:20,961 main.py:52] epoch 165, training loss: 8714.31, average training loss: 11149.25, base loss: 16783.20
[INFO 2017-07-01 18:08:25,186 main.py:52] epoch 166, training loss: 8407.13, average training loss: 11132.83, base loss: 16774.71
[INFO 2017-07-01 18:08:29,364 main.py:52] epoch 167, training loss: 9228.18, average training loss: 11121.49, base loss: 16768.18
[INFO 2017-07-01 18:08:33,587 main.py:52] epoch 168, training loss: 8371.30, average training loss: 11105.21, base loss: 16757.32
[INFO 2017-07-01 18:08:37,689 main.py:52] epoch 169, training loss: 9490.17, average training loss: 11095.71, base loss: 16760.13
[INFO 2017-07-01 18:08:41,820 main.py:52] epoch 170, training loss: 9607.30, average training loss: 11087.01, base loss: 16756.87
[INFO 2017-07-01 18:08:45,985 main.py:52] epoch 171, training loss: 10912.51, average training loss: 11086.00, base loss: 16776.60
[INFO 2017-07-01 18:08:50,179 main.py:52] epoch 172, training loss: 8755.25, average training loss: 11072.52, base loss: 16771.13
[INFO 2017-07-01 18:08:54,354 main.py:52] epoch 173, training loss: 9338.96, average training loss: 11062.56, base loss: 16770.69
[INFO 2017-07-01 18:08:58,581 main.py:52] epoch 174, training loss: 8927.55, average training loss: 11050.36, base loss: 16758.67
[INFO 2017-07-01 18:09:02,767 main.py:52] epoch 175, training loss: 9047.38, average training loss: 11038.98, base loss: 16758.91
[INFO 2017-07-01 18:09:07,000 main.py:52] epoch 176, training loss: 8760.26, average training loss: 11026.11, base loss: 16753.82
[INFO 2017-07-01 18:09:11,206 main.py:52] epoch 177, training loss: 8794.33, average training loss: 11013.57, base loss: 16744.66
[INFO 2017-07-01 18:09:15,496 main.py:52] epoch 178, training loss: 9877.31, average training loss: 11007.22, base loss: 16750.18
[INFO 2017-07-01 18:09:19,611 main.py:52] epoch 179, training loss: 8631.51, average training loss: 10994.02, base loss: 16743.75
[INFO 2017-07-01 18:09:23,803 main.py:52] epoch 180, training loss: 9288.54, average training loss: 10984.60, base loss: 16741.56
[INFO 2017-07-01 18:09:27,952 main.py:52] epoch 181, training loss: 8947.06, average training loss: 10973.40, base loss: 16738.30
[INFO 2017-07-01 18:09:32,101 main.py:52] epoch 182, training loss: 9924.35, average training loss: 10967.67, base loss: 16750.96
[INFO 2017-07-01 18:09:36,306 main.py:52] epoch 183, training loss: 9295.40, average training loss: 10958.58, base loss: 16745.07
[INFO 2017-07-01 18:09:40,459 main.py:52] epoch 184, training loss: 8813.40, average training loss: 10946.99, base loss: 16742.91
[INFO 2017-07-01 18:09:44,639 main.py:52] epoch 185, training loss: 8972.53, average training loss: 10936.37, base loss: 16734.48
[INFO 2017-07-01 18:09:48,740 main.py:52] epoch 186, training loss: 9344.14, average training loss: 10927.86, base loss: 16735.99
[INFO 2017-07-01 18:09:52,866 main.py:52] epoch 187, training loss: 9175.52, average training loss: 10918.54, base loss: 16735.22
[INFO 2017-07-01 18:09:57,109 main.py:52] epoch 188, training loss: 8377.38, average training loss: 10905.09, base loss: 16727.53
[INFO 2017-07-01 18:10:01,305 main.py:52] epoch 189, training loss: 8062.39, average training loss: 10890.13, base loss: 16715.48
[INFO 2017-07-01 18:10:05,560 main.py:52] epoch 190, training loss: 9807.53, average training loss: 10884.46, base loss: 16715.60
[INFO 2017-07-01 18:10:09,779 main.py:52] epoch 191, training loss: 9763.80, average training loss: 10878.62, base loss: 16721.98
[INFO 2017-07-01 18:10:13,945 main.py:52] epoch 192, training loss: 9348.98, average training loss: 10870.70, base loss: 16727.39
[INFO 2017-07-01 18:10:18,148 main.py:52] epoch 193, training loss: 10321.93, average training loss: 10867.87, base loss: 16740.41
[INFO 2017-07-01 18:10:22,297 main.py:52] epoch 194, training loss: 8581.22, average training loss: 10856.14, base loss: 16728.04
[INFO 2017-07-01 18:10:26,491 main.py:52] epoch 195, training loss: 10248.45, average training loss: 10853.04, base loss: 16732.51
[INFO 2017-07-01 18:10:30,732 main.py:52] epoch 196, training loss: 9564.10, average training loss: 10846.50, base loss: 16736.36
[INFO 2017-07-01 18:10:34,967 main.py:52] epoch 197, training loss: 8057.73, average training loss: 10832.42, base loss: 16723.56
[INFO 2017-07-01 18:10:39,147 main.py:52] epoch 198, training loss: 8970.96, average training loss: 10823.06, base loss: 16725.61
[INFO 2017-07-01 18:10:43,343 main.py:52] epoch 199, training loss: 8562.84, average training loss: 10811.76, base loss: 16717.83
[INFO 2017-07-01 18:10:43,343 main.py:54] epoch 199, testing
[INFO 2017-07-01 18:10:43,343 main.py:61] model save to ./model/final.pth
[INFO 2017-07-01 18:10:47,586 main.py:52] epoch 200, training loss: 8459.77, average training loss: 10800.06, base loss: 16708.39
[INFO 2017-07-01 18:10:51,812 main.py:52] epoch 201, training loss: 8705.02, average training loss: 10789.69, base loss: 16702.87
[INFO 2017-07-01 18:10:55,997 main.py:52] epoch 202, training loss: 9857.56, average training loss: 10785.10, base loss: 16705.97
[INFO 2017-07-01 18:11:00,223 main.py:52] epoch 203, training loss: 9356.06, average training loss: 10778.09, base loss: 16712.24
[INFO 2017-07-01 18:11:04,371 main.py:52] epoch 204, training loss: 9207.60, average training loss: 10770.43, base loss: 16710.87
[INFO 2017-07-01 18:11:08,568 main.py:52] epoch 205, training loss: 10034.07, average training loss: 10766.86, base loss: 16717.67
[INFO 2017-07-01 18:11:12,706 main.py:52] epoch 206, training loss: 9284.47, average training loss: 10759.69, base loss: 16724.08
[INFO 2017-07-01 18:11:16,807 main.py:52] epoch 207, training loss: 8995.22, average training loss: 10751.21, base loss: 16721.27
[INFO 2017-07-01 18:11:21,024 main.py:52] epoch 208, training loss: 9500.37, average training loss: 10745.23, base loss: 16723.80
[INFO 2017-07-01 18:11:25,271 main.py:52] epoch 209, training loss: 8663.56, average training loss: 10735.31, base loss: 16716.52
[INFO 2017-07-01 18:11:29,328 main.py:52] epoch 210, training loss: 8551.97, average training loss: 10724.97, base loss: 16709.89
[INFO 2017-07-01 18:11:33,534 main.py:52] epoch 211, training loss: 8484.36, average training loss: 10714.40, base loss: 16703.89
[INFO 2017-07-01 18:11:37,712 main.py:52] epoch 212, training loss: 9344.80, average training loss: 10707.97, base loss: 16705.74
[INFO 2017-07-01 18:11:41,929 main.py:52] epoch 213, training loss: 8318.33, average training loss: 10696.80, base loss: 16700.04
[INFO 2017-07-01 18:11:46,082 main.py:52] epoch 214, training loss: 8805.69, average training loss: 10688.00, base loss: 16697.82
[INFO 2017-07-01 18:11:50,249 main.py:52] epoch 215, training loss: 11071.72, average training loss: 10689.78, base loss: 16711.89
[INFO 2017-07-01 18:11:54,484 main.py:52] epoch 216, training loss: 8383.39, average training loss: 10679.15, base loss: 16707.05
[INFO 2017-07-01 18:11:58,675 main.py:52] epoch 217, training loss: 9138.38, average training loss: 10672.08, base loss: 16707.40
[INFO 2017-07-01 18:12:02,822 main.py:52] epoch 218, training loss: 9257.16, average training loss: 10665.62, base loss: 16708.66
[INFO 2017-07-01 18:12:07,036 main.py:52] epoch 219, training loss: 8926.64, average training loss: 10657.72, base loss: 16709.85
[INFO 2017-07-01 18:12:11,200 main.py:52] epoch 220, training loss: 10082.83, average training loss: 10655.12, base loss: 16716.81
[INFO 2017-07-01 18:12:15,447 main.py:52] epoch 221, training loss: 9117.42, average training loss: 10648.19, base loss: 16715.26
[INFO 2017-07-01 18:12:19,610 main.py:52] epoch 222, training loss: 9194.19, average training loss: 10641.67, base loss: 16719.61
[INFO 2017-07-01 18:12:23,815 main.py:52] epoch 223, training loss: 8637.78, average training loss: 10632.73, base loss: 16715.23
[INFO 2017-07-01 18:12:28,017 main.py:52] epoch 224, training loss: 9459.19, average training loss: 10627.51, base loss: 16720.12
[INFO 2017-07-01 18:12:32,164 main.py:52] epoch 225, training loss: 8600.59, average training loss: 10618.54, base loss: 16714.98
[INFO 2017-07-01 18:12:36,335 main.py:52] epoch 226, training loss: 8521.94, average training loss: 10609.30, base loss: 16712.68
[INFO 2017-07-01 18:12:40,510 main.py:52] epoch 227, training loss: 9201.40, average training loss: 10603.13, base loss: 16718.97
[INFO 2017-07-01 18:12:44,703 main.py:52] epoch 228, training loss: 8437.64, average training loss: 10593.67, base loss: 16716.28
[INFO 2017-07-01 18:12:48,867 main.py:52] epoch 229, training loss: 8581.71, average training loss: 10584.93, base loss: 16714.99
[INFO 2017-07-01 18:12:53,101 main.py:52] epoch 230, training loss: 9068.21, average training loss: 10578.36, base loss: 16715.05
[INFO 2017-07-01 18:12:57,218 main.py:52] epoch 231, training loss: 9580.98, average training loss: 10574.06, base loss: 16717.55
[INFO 2017-07-01 18:13:01,479 main.py:52] epoch 232, training loss: 8241.77, average training loss: 10564.05, base loss: 16713.11
[INFO 2017-07-01 18:13:05,603 main.py:52] epoch 233, training loss: 8308.92, average training loss: 10554.41, base loss: 16705.47
[INFO 2017-07-01 18:13:09,763 main.py:52] epoch 234, training loss: 8616.33, average training loss: 10546.17, base loss: 16703.85
[INFO 2017-07-01 18:13:13,990 main.py:52] epoch 235, training loss: 7864.85, average training loss: 10534.81, base loss: 16696.27
[INFO 2017-07-01 18:13:18,153 main.py:52] epoch 236, training loss: 9339.79, average training loss: 10529.76, base loss: 16694.79
[INFO 2017-07-01 18:13:22,512 main.py:52] epoch 237, training loss: 8660.30, average training loss: 10521.91, base loss: 16685.58
[INFO 2017-07-01 18:13:26,886 main.py:52] epoch 238, training loss: 9361.11, average training loss: 10517.05, base loss: 16688.83
[INFO 2017-07-01 18:13:31,111 main.py:52] epoch 239, training loss: 8879.99, average training loss: 10510.23, base loss: 16689.80
[INFO 2017-07-01 18:13:35,363 main.py:52] epoch 240, training loss: 8997.75, average training loss: 10503.95, base loss: 16689.89
[INFO 2017-07-01 18:13:39,610 main.py:52] epoch 241, training loss: 8846.87, average training loss: 10497.11, base loss: 16689.40
[INFO 2017-07-01 18:13:43,782 main.py:52] epoch 242, training loss: 9130.37, average training loss: 10491.48, base loss: 16693.27
[INFO 2017-07-01 18:13:47,943 main.py:52] epoch 243, training loss: 8991.10, average training loss: 10485.33, base loss: 16696.16
[INFO 2017-07-01 18:13:51,996 main.py:52] epoch 244, training loss: 8616.84, average training loss: 10477.71, base loss: 16694.20
[INFO 2017-07-01 18:13:56,106 main.py:52] epoch 245, training loss: 9135.86, average training loss: 10472.25, base loss: 16693.40
[INFO 2017-07-01 18:14:00,302 main.py:52] epoch 246, training loss: 8341.08, average training loss: 10463.62, base loss: 16690.27
[INFO 2017-07-01 18:14:04,473 main.py:52] epoch 247, training loss: 9235.78, average training loss: 10458.67, base loss: 16693.61
[INFO 2017-07-01 18:14:08,705 main.py:52] epoch 248, training loss: 8455.96, average training loss: 10450.63, base loss: 16688.83
[INFO 2017-07-01 18:14:12,867 main.py:52] epoch 249, training loss: 8969.32, average training loss: 10444.70, base loss: 16691.06
[INFO 2017-07-01 18:14:17,048 main.py:52] epoch 250, training loss: 9492.68, average training loss: 10440.91, base loss: 16697.97
[INFO 2017-07-01 18:14:21,190 main.py:52] epoch 251, training loss: 10511.74, average training loss: 10441.19, base loss: 16705.51
[INFO 2017-07-01 18:14:25,326 main.py:52] epoch 252, training loss: 8459.54, average training loss: 10433.36, base loss: 16699.88
[INFO 2017-07-01 18:14:29,512 main.py:52] epoch 253, training loss: 9351.84, average training loss: 10429.10, base loss: 16703.84
[INFO 2017-07-01 18:14:33,693 main.py:52] epoch 254, training loss: 9120.23, average training loss: 10423.97, base loss: 16701.78
[INFO 2017-07-01 18:14:37,854 main.py:52] epoch 255, training loss: 8557.76, average training loss: 10416.68, base loss: 16701.75
[INFO 2017-07-01 18:14:42,115 main.py:52] epoch 256, training loss: 8393.71, average training loss: 10408.81, base loss: 16696.02
[INFO 2017-07-01 18:14:46,271 main.py:52] epoch 257, training loss: 8542.50, average training loss: 10401.57, base loss: 16695.65
[INFO 2017-07-01 18:14:50,415 main.py:52] epoch 258, training loss: 8732.95, average training loss: 10395.13, base loss: 16694.20
[INFO 2017-07-01 18:14:54,579 main.py:52] epoch 259, training loss: 8169.21, average training loss: 10386.57, base loss: 16687.39
[INFO 2017-07-01 18:14:58,830 main.py:52] epoch 260, training loss: 8495.62, average training loss: 10379.33, base loss: 16687.29
[INFO 2017-07-01 18:15:03,122 main.py:52] epoch 261, training loss: 10244.86, average training loss: 10378.81, base loss: 16693.41
[INFO 2017-07-01 18:15:07,387 main.py:52] epoch 262, training loss: 9159.99, average training loss: 10374.18, base loss: 16690.48
[INFO 2017-07-01 18:15:11,605 main.py:52] epoch 263, training loss: 9048.99, average training loss: 10369.16, base loss: 16691.95
[INFO 2017-07-01 18:15:15,858 main.py:52] epoch 264, training loss: 8586.77, average training loss: 10362.43, base loss: 16692.47
[INFO 2017-07-01 18:15:20,045 main.py:52] epoch 265, training loss: 8479.65, average training loss: 10355.35, base loss: 16686.69
[INFO 2017-07-01 18:15:24,300 main.py:52] epoch 266, training loss: 9405.70, average training loss: 10351.80, base loss: 16693.19
[INFO 2017-07-01 18:15:28,430 main.py:52] epoch 267, training loss: 8652.82, average training loss: 10345.46, base loss: 16689.27
[INFO 2017-07-01 18:15:32,632 main.py:52] epoch 268, training loss: 8672.36, average training loss: 10339.24, base loss: 16684.46
[INFO 2017-07-01 18:15:36,860 main.py:52] epoch 269, training loss: 8856.60, average training loss: 10333.75, base loss: 16684.64
[INFO 2017-07-01 18:15:41,138 main.py:52] epoch 270, training loss: 8280.69, average training loss: 10326.17, base loss: 16679.71
[INFO 2017-07-01 18:15:45,276 main.py:52] epoch 271, training loss: 9534.27, average training loss: 10323.26, base loss: 16681.12
[INFO 2017-07-01 18:15:49,438 main.py:52] epoch 272, training loss: 8753.64, average training loss: 10317.51, base loss: 16679.06
[INFO 2017-07-01 18:15:53,647 main.py:52] epoch 273, training loss: 8112.20, average training loss: 10309.46, base loss: 16669.42
[INFO 2017-07-01 18:15:57,931 main.py:52] epoch 274, training loss: 9849.92, average training loss: 10307.79, base loss: 16675.67
[INFO 2017-07-01 18:16:02,083 main.py:52] epoch 275, training loss: 8933.92, average training loss: 10302.81, base loss: 16679.35
[INFO 2017-07-01 18:16:06,263 main.py:52] epoch 276, training loss: 8421.12, average training loss: 10296.02, base loss: 16678.01
[INFO 2017-07-01 18:16:10,421 main.py:52] epoch 277, training loss: 8951.54, average training loss: 10291.18, base loss: 16675.70
[INFO 2017-07-01 18:16:14,619 main.py:52] epoch 278, training loss: 10166.13, average training loss: 10290.74, base loss: 16683.58
[INFO 2017-07-01 18:16:18,823 main.py:52] epoch 279, training loss: 8455.25, average training loss: 10284.18, base loss: 16677.81
[INFO 2017-07-01 18:16:22,980 main.py:52] epoch 280, training loss: 8954.76, average training loss: 10279.45, base loss: 16677.33
[INFO 2017-07-01 18:16:27,146 main.py:52] epoch 281, training loss: 8961.34, average training loss: 10274.77, base loss: 16679.55
[INFO 2017-07-01 18:16:31,395 main.py:52] epoch 282, training loss: 8777.43, average training loss: 10269.48, base loss: 16679.07
[INFO 2017-07-01 18:16:35,573 main.py:52] epoch 283, training loss: 9101.21, average training loss: 10265.37, base loss: 16682.47
[INFO 2017-07-01 18:16:39,808 main.py:52] epoch 284, training loss: 10421.62, average training loss: 10265.92, base loss: 16691.51
[INFO 2017-07-01 18:16:44,027 main.py:52] epoch 285, training loss: 8251.87, average training loss: 10258.88, base loss: 16691.80
[INFO 2017-07-01 18:16:48,226 main.py:52] epoch 286, training loss: 8166.47, average training loss: 10251.59, base loss: 16686.15
[INFO 2017-07-01 18:16:52,430 main.py:52] epoch 287, training loss: 8818.31, average training loss: 10246.61, base loss: 16683.46
[INFO 2017-07-01 18:16:56,617 main.py:52] epoch 288, training loss: 8680.13, average training loss: 10241.19, base loss: 16685.19
[INFO 2017-07-01 18:17:00,770 main.py:52] epoch 289, training loss: 7888.82, average training loss: 10233.08, base loss: 16679.17
[INFO 2017-07-01 18:17:04,973 main.py:52] epoch 290, training loss: 8030.58, average training loss: 10225.51, base loss: 16676.81
[INFO 2017-07-01 18:17:09,188 main.py:52] epoch 291, training loss: 7950.69, average training loss: 10217.72, base loss: 16670.75
[INFO 2017-07-01 18:17:13,315 main.py:52] epoch 292, training loss: 8731.73, average training loss: 10212.65, base loss: 16670.28
[INFO 2017-07-01 18:17:17,553 main.py:52] epoch 293, training loss: 9112.25, average training loss: 10208.90, base loss: 16669.73
[INFO 2017-07-01 18:17:21,745 main.py:52] epoch 294, training loss: 9115.60, average training loss: 10205.20, base loss: 16672.79
[INFO 2017-07-01 18:17:25,954 main.py:52] epoch 295, training loss: 8787.95, average training loss: 10200.41, base loss: 16672.29
[INFO 2017-07-01 18:17:30,114 main.py:52] epoch 296, training loss: 8331.62, average training loss: 10194.12, base loss: 16671.41
[INFO 2017-07-01 18:17:34,327 main.py:52] epoch 297, training loss: 8992.73, average training loss: 10190.09, base loss: 16673.54
[INFO 2017-07-01 18:17:38,598 main.py:52] epoch 298, training loss: 9206.13, average training loss: 10186.79, base loss: 16671.81
[INFO 2017-07-01 18:17:42,781 main.py:52] epoch 299, training loss: 8901.54, average training loss: 10182.51, base loss: 16673.74
[INFO 2017-07-01 18:17:42,781 main.py:54] epoch 299, testing
[INFO 2017-07-01 18:17:42,782 main.py:61] model save to ./model/final.pth
[INFO 2017-07-01 18:17:47,019 main.py:52] epoch 300, training loss: 7461.94, average training loss: 10173.47, base loss: 16664.41
[INFO 2017-07-01 18:17:51,244 main.py:52] epoch 301, training loss: 9102.68, average training loss: 10169.93, base loss: 16663.14
[INFO 2017-07-01 18:17:55,554 main.py:52] epoch 302, training loss: 8800.00, average training loss: 10165.41, base loss: 16665.95
[INFO 2017-07-01 18:17:59,750 main.py:52] epoch 303, training loss: 8565.88, average training loss: 10160.14, base loss: 16664.21
[INFO 2017-07-01 18:18:04,063 main.py:52] epoch 304, training loss: 8105.58, average training loss: 10153.41, base loss: 16659.46
[INFO 2017-07-01 18:18:08,244 main.py:52] epoch 305, training loss: 8354.14, average training loss: 10147.53, base loss: 16656.75
[INFO 2017-07-01 18:18:12,454 main.py:52] epoch 306, training loss: 7670.30, average training loss: 10139.46, base loss: 16649.46
[INFO 2017-07-01 18:18:16,621 main.py:52] epoch 307, training loss: 10890.10, average training loss: 10141.90, base loss: 16659.60
[INFO 2017-07-01 18:18:20,823 main.py:52] epoch 308, training loss: 9833.66, average training loss: 10140.90, base loss: 16666.10
[INFO 2017-07-01 18:18:24,986 main.py:52] epoch 309, training loss: 8931.44, average training loss: 10137.00, base loss: 16663.13
[INFO 2017-07-01 18:18:29,178 main.py:52] epoch 310, training loss: 8481.17, average training loss: 10131.67, base loss: 16659.68
[INFO 2017-07-01 18:18:33,367 main.py:52] epoch 311, training loss: 8169.36, average training loss: 10125.38, base loss: 16655.94
[INFO 2017-07-01 18:18:37,585 main.py:52] epoch 312, training loss: 9415.99, average training loss: 10123.12, base loss: 16659.82
[INFO 2017-07-01 18:18:41,808 main.py:52] epoch 313, training loss: 8173.81, average training loss: 10116.91, base loss: 16657.41
[INFO 2017-07-01 18:18:46,024 main.py:52] epoch 314, training loss: 9877.21, average training loss: 10116.15, base loss: 16662.82
[INFO 2017-07-01 18:18:50,238 main.py:52] epoch 315, training loss: 8700.68, average training loss: 10111.67, base loss: 16662.55
[INFO 2017-07-01 18:18:54,465 main.py:52] epoch 316, training loss: 9371.00, average training loss: 10109.33, base loss: 16665.10
[INFO 2017-07-01 18:18:58,638 main.py:52] epoch 317, training loss: 8703.22, average training loss: 10104.91, base loss: 16663.64
[INFO 2017-07-01 18:19:02,846 main.py:52] epoch 318, training loss: 8255.12, average training loss: 10099.11, base loss: 16659.47
[INFO 2017-07-01 18:19:06,990 main.py:52] epoch 319, training loss: 8116.30, average training loss: 10092.91, base loss: 16653.23
[INFO 2017-07-01 18:19:11,152 main.py:52] epoch 320, training loss: 7746.30, average training loss: 10085.60, base loss: 16648.07
[INFO 2017-07-01 18:19:15,312 main.py:52] epoch 321, training loss: 8493.07, average training loss: 10080.66, base loss: 16644.02
[INFO 2017-07-01 18:19:19,417 main.py:52] epoch 322, training loss: 8538.68, average training loss: 10075.88, base loss: 16645.83
[INFO 2017-07-01 18:19:23,516 main.py:52] epoch 323, training loss: 9238.58, average training loss: 10073.30, base loss: 16647.76
[INFO 2017-07-01 18:19:27,742 main.py:52] epoch 324, training loss: 8137.61, average training loss: 10067.34, base loss: 16645.61
[INFO 2017-07-01 18:19:31,966 main.py:52] epoch 325, training loss: 8813.57, average training loss: 10063.50, base loss: 16645.88
[INFO 2017-07-01 18:19:36,108 main.py:52] epoch 326, training loss: 8838.05, average training loss: 10059.75, base loss: 16641.02
[INFO 2017-07-01 18:19:40,302 main.py:52] epoch 327, training loss: 7492.35, average training loss: 10051.92, base loss: 16633.11
[INFO 2017-07-01 18:19:44,521 main.py:52] epoch 328, training loss: 8076.47, average training loss: 10045.92, base loss: 16629.23
[INFO 2017-07-01 18:19:48,682 main.py:52] epoch 329, training loss: 8972.50, average training loss: 10042.67, base loss: 16634.38
[INFO 2017-07-01 18:19:52,903 main.py:52] epoch 330, training loss: 8486.53, average training loss: 10037.97, base loss: 16634.37
[INFO 2017-07-01 18:19:57,110 main.py:52] epoch 331, training loss: 9757.84, average training loss: 10037.12, base loss: 16635.73
[INFO 2017-07-01 18:20:01,258 main.py:52] epoch 332, training loss: 8343.12, average training loss: 10032.03, base loss: 16633.44
[INFO 2017-07-01 18:20:05,433 main.py:52] epoch 333, training loss: 8283.71, average training loss: 10026.80, base loss: 16630.24
[INFO 2017-07-01 18:20:09,632 main.py:52] epoch 334, training loss: 8433.29, average training loss: 10022.04, base loss: 16629.37
[INFO 2017-07-01 18:20:13,853 main.py:52] epoch 335, training loss: 7850.15, average training loss: 10015.58, base loss: 16626.79
[INFO 2017-07-01 18:20:18,001 main.py:52] epoch 336, training loss: 8010.57, average training loss: 10009.63, base loss: 16624.28
[INFO 2017-07-01 18:20:22,142 main.py:52] epoch 337, training loss: 8922.78, average training loss: 10006.41, base loss: 16629.76
[INFO 2017-07-01 18:20:26,382 main.py:52] epoch 338, training loss: 9018.73, average training loss: 10003.50, base loss: 16630.05
[INFO 2017-07-01 18:20:30,538 main.py:52] epoch 339, training loss: 9972.37, average training loss: 10003.41, base loss: 16634.47
[INFO 2017-07-01 18:20:34,769 main.py:52] epoch 340, training loss: 9097.53, average training loss: 10000.75, base loss: 16639.96
[INFO 2017-07-01 18:20:38,990 main.py:52] epoch 341, training loss: 8618.01, average training loss: 9996.71, base loss: 16640.13
[INFO 2017-07-01 18:20:43,272 main.py:52] epoch 342, training loss: 8433.15, average training loss: 9992.15, base loss: 16641.17
[INFO 2017-07-01 18:20:47,497 main.py:52] epoch 343, training loss: 8407.22, average training loss: 9987.54, base loss: 16638.42
[INFO 2017-07-01 18:20:51,721 main.py:52] epoch 344, training loss: 8728.46, average training loss: 9983.89, base loss: 16641.86
[INFO 2017-07-01 18:20:55,944 main.py:52] epoch 345, training loss: 7997.83, average training loss: 9978.15, base loss: 16638.30
[INFO 2017-07-01 18:21:00,132 main.py:52] epoch 346, training loss: 8713.68, average training loss: 9974.51, base loss: 16640.46
[INFO 2017-07-01 18:21:04,284 main.py:52] epoch 347, training loss: 7603.64, average training loss: 9967.70, base loss: 16635.76
[INFO 2017-07-01 18:21:08,476 main.py:52] epoch 348, training loss: 8236.54, average training loss: 9962.74, base loss: 16634.10
[INFO 2017-07-01 18:21:12,684 main.py:52] epoch 349, training loss: 8503.28, average training loss: 9958.57, base loss: 16636.21
[INFO 2017-07-01 18:21:16,929 main.py:52] epoch 350, training loss: 7957.80, average training loss: 9952.87, base loss: 16631.32
[INFO 2017-07-01 18:21:21,101 main.py:52] epoch 351, training loss: 8057.50, average training loss: 9947.48, base loss: 16625.60
[INFO 2017-07-01 18:21:25,317 main.py:52] epoch 352, training loss: 8336.75, average training loss: 9942.92, base loss: 16620.56
[INFO 2017-07-01 18:21:29,467 main.py:52] epoch 353, training loss: 8866.49, average training loss: 9939.88, base loss: 16620.87
[INFO 2017-07-01 18:21:33,643 main.py:52] epoch 354, training loss: 7663.71, average training loss: 9933.47, base loss: 16616.42
[INFO 2017-07-01 18:21:37,894 main.py:52] epoch 355, training loss: 7566.74, average training loss: 9926.82, base loss: 16611.23
[INFO 2017-07-01 18:21:42,018 main.py:52] epoch 356, training loss: 9008.43, average training loss: 9924.25, base loss: 16611.01
[INFO 2017-07-01 18:21:46,210 main.py:52] epoch 357, training loss: 8753.62, average training loss: 9920.98, base loss: 16610.09
[INFO 2017-07-01 18:21:50,395 main.py:52] epoch 358, training loss: 9116.85, average training loss: 9918.74, base loss: 16613.59
[INFO 2017-07-01 18:21:54,600 main.py:52] epoch 359, training loss: 7987.15, average training loss: 9913.37, base loss: 16607.99
[INFO 2017-07-01 18:21:58,779 main.py:52] epoch 360, training loss: 8445.77, average training loss: 9909.31, base loss: 16608.92
[INFO 2017-07-01 18:22:02,910 main.py:52] epoch 361, training loss: 9032.86, average training loss: 9906.88, base loss: 16610.93
[INFO 2017-07-01 18:22:07,108 main.py:52] epoch 362, training loss: 8091.71, average training loss: 9901.88, base loss: 16604.82
[INFO 2017-07-01 18:22:11,272 main.py:52] epoch 363, training loss: 7636.76, average training loss: 9895.66, base loss: 16599.85
[INFO 2017-07-01 18:22:15,451 main.py:52] epoch 364, training loss: 10040.57, average training loss: 9896.06, base loss: 16604.59
[INFO 2017-07-01 18:22:19,671 main.py:52] epoch 365, training loss: 8689.25, average training loss: 9892.76, base loss: 16608.21
[INFO 2017-07-01 18:22:23,837 main.py:52] epoch 366, training loss: 8557.46, average training loss: 9889.12, base loss: 16608.27
[INFO 2017-07-01 18:22:27,977 main.py:52] epoch 367, training loss: 8083.64, average training loss: 9884.22, base loss: 16603.45
[INFO 2017-07-01 18:22:32,103 main.py:52] epoch 368, training loss: 9582.30, average training loss: 9883.40, base loss: 16605.17
[INFO 2017-07-01 18:22:36,274 main.py:52] epoch 369, training loss: 9232.78, average training loss: 9881.64, base loss: 16607.04
[INFO 2017-07-01 18:22:40,416 main.py:52] epoch 370, training loss: 11088.51, average training loss: 9884.89, base loss: 16614.93
[INFO 2017-07-01 18:22:44,650 main.py:52] epoch 371, training loss: 8444.55, average training loss: 9881.02, base loss: 16610.95
[INFO 2017-07-01 18:22:48,797 main.py:52] epoch 372, training loss: 8295.79, average training loss: 9876.77, base loss: 16608.48
[INFO 2017-07-01 18:22:52,967 main.py:52] epoch 373, training loss: 8338.51, average training loss: 9872.66, base loss: 16606.20
[INFO 2017-07-01 18:22:57,187 main.py:52] epoch 374, training loss: 7693.08, average training loss: 9866.85, base loss: 16600.38
[INFO 2017-07-01 18:23:01,344 main.py:52] epoch 375, training loss: 8176.58, average training loss: 9862.35, base loss: 16595.94
[INFO 2017-07-01 18:23:05,576 main.py:52] epoch 376, training loss: 8184.54, average training loss: 9857.90, base loss: 16590.52
[INFO 2017-07-01 18:23:09,775 main.py:52] epoch 377, training loss: 8563.76, average training loss: 9854.48, base loss: 16589.99
[INFO 2017-07-01 18:23:13,951 main.py:52] epoch 378, training loss: 7818.28, average training loss: 9849.10, base loss: 16583.11
[INFO 2017-07-01 18:23:18,091 main.py:52] epoch 379, training loss: 8307.36, average training loss: 9845.05, base loss: 16579.74
[INFO 2017-07-01 18:23:22,303 main.py:52] epoch 380, training loss: 8243.97, average training loss: 9840.84, base loss: 16577.52
[INFO 2017-07-01 18:23:26,543 main.py:52] epoch 381, training loss: 8955.88, average training loss: 9838.53, base loss: 16581.27
[INFO 2017-07-01 18:23:30,732 main.py:52] epoch 382, training loss: 7913.59, average training loss: 9833.50, base loss: 16577.48
[INFO 2017-07-01 18:23:34,932 main.py:52] epoch 383, training loss: 8875.95, average training loss: 9831.01, base loss: 16579.65
[INFO 2017-07-01 18:23:39,163 main.py:52] epoch 384, training loss: 7601.21, average training loss: 9825.22, base loss: 16573.85
[INFO 2017-07-01 18:23:43,303 main.py:52] epoch 385, training loss: 8591.29, average training loss: 9822.02, base loss: 16575.99
[INFO 2017-07-01 18:23:47,580 main.py:52] epoch 386, training loss: 8861.39, average training loss: 9819.54, base loss: 16577.63
[INFO 2017-07-01 18:23:51,835 main.py:52] epoch 387, training loss: 8726.41, average training loss: 9816.72, base loss: 16580.27
[INFO 2017-07-01 18:23:56,043 main.py:52] epoch 388, training loss: 7779.17, average training loss: 9811.48, base loss: 16574.39
[INFO 2017-07-01 18:24:00,201 main.py:52] epoch 389, training loss: 8450.70, average training loss: 9807.99, base loss: 16573.02
[INFO 2017-07-01 18:24:04,364 main.py:52] epoch 390, training loss: 7926.80, average training loss: 9803.18, base loss: 16569.82
[INFO 2017-07-01 18:24:08,502 main.py:52] epoch 391, training loss: 8705.27, average training loss: 9800.38, base loss: 16571.18
[INFO 2017-07-01 18:24:12,730 main.py:52] epoch 392, training loss: 8420.50, average training loss: 9796.87, base loss: 16571.75
[INFO 2017-07-01 18:24:16,910 main.py:52] epoch 393, training loss: 9249.02, average training loss: 9795.48, base loss: 16576.49
[INFO 2017-07-01 18:24:21,102 main.py:52] epoch 394, training loss: 8657.57, average training loss: 9792.60, base loss: 16573.79
[INFO 2017-07-01 18:24:25,237 main.py:52] epoch 395, training loss: 8576.00, average training loss: 9789.53, base loss: 16574.57
[INFO 2017-07-01 18:24:29,516 main.py:52] epoch 396, training loss: 8361.33, average training loss: 9785.93, base loss: 16575.65
[INFO 2017-07-01 18:24:33,716 main.py:52] epoch 397, training loss: 9190.49, average training loss: 9784.43, base loss: 16578.09
[INFO 2017-07-01 18:24:37,899 main.py:52] epoch 398, training loss: 8205.69, average training loss: 9780.48, base loss: 16573.18
[INFO 2017-07-01 18:24:42,088 main.py:52] epoch 399, training loss: 8425.30, average training loss: 9777.09, base loss: 16572.05
[INFO 2017-07-01 18:24:42,089 main.py:54] epoch 399, testing
[INFO 2017-07-01 18:24:42,089 main.py:61] model save to ./model/final.pth
[INFO 2017-07-01 18:24:46,359 main.py:52] epoch 400, training loss: 7865.43, average training loss: 9772.32, base loss: 16571.64
[INFO 2017-07-01 18:24:50,535 main.py:52] epoch 401, training loss: 9048.82, average training loss: 9770.52, base loss: 16575.12
[INFO 2017-07-01 18:24:54,715 main.py:52] epoch 402, training loss: 8613.99, average training loss: 9767.65, base loss: 16575.89
[INFO 2017-07-01 18:24:58,959 main.py:52] epoch 403, training loss: 9336.72, average training loss: 9766.58, base loss: 16578.26
[INFO 2017-07-01 18:25:03,154 main.py:52] epoch 404, training loss: 8752.89, average training loss: 9764.08, base loss: 16580.45
[INFO 2017-07-01 18:25:07,364 main.py:52] epoch 405, training loss: 9345.23, average training loss: 9763.05, base loss: 16584.21
[INFO 2017-07-01 18:25:11,569 main.py:52] epoch 406, training loss: 8996.20, average training loss: 9761.17, base loss: 16582.73
[INFO 2017-07-01 18:25:15,706 main.py:52] epoch 407, training loss: 9136.27, average training loss: 9759.63, base loss: 16585.73
[INFO 2017-07-01 18:25:19,891 main.py:52] epoch 408, training loss: 10350.44, average training loss: 9761.08, base loss: 16592.42
[INFO 2017-07-01 18:25:24,114 main.py:52] epoch 409, training loss: 8108.06, average training loss: 9757.05, base loss: 16590.12
[INFO 2017-07-01 18:25:28,329 main.py:52] epoch 410, training loss: 7757.88, average training loss: 9752.18, base loss: 16585.95
[INFO 2017-07-01 18:25:32,508 main.py:52] epoch 411, training loss: 8011.13, average training loss: 9747.96, base loss: 16582.71
[INFO 2017-07-01 18:25:36,777 main.py:52] epoch 412, training loss: 7783.36, average training loss: 9743.20, base loss: 16578.13
[INFO 2017-07-01 18:25:40,989 main.py:52] epoch 413, training loss: 9582.06, average training loss: 9742.81, base loss: 16580.81
[INFO 2017-07-01 18:25:45,227 main.py:52] epoch 414, training loss: 7674.73, average training loss: 9737.83, base loss: 16575.79
[INFO 2017-07-01 18:25:49,402 main.py:52] epoch 415, training loss: 9562.97, average training loss: 9737.41, base loss: 16582.21
[INFO 2017-07-01 18:25:53,566 main.py:52] epoch 416, training loss: 8714.07, average training loss: 9734.95, base loss: 16583.01
[INFO 2017-07-01 18:25:57,821 main.py:52] epoch 417, training loss: 8968.52, average training loss: 9733.12, base loss: 16585.84
[INFO 2017-07-01 18:26:02,076 main.py:52] epoch 418, training loss: 10062.86, average training loss: 9733.91, base loss: 16592.51
[INFO 2017-07-01 18:26:06,188 main.py:52] epoch 419, training loss: 8643.17, average training loss: 9731.31, base loss: 16593.76
[INFO 2017-07-01 18:26:10,414 main.py:52] epoch 420, training loss: 8242.92, average training loss: 9727.77, base loss: 16592.81
[INFO 2017-07-01 18:26:14,631 main.py:52] epoch 421, training loss: 8370.54, average training loss: 9724.56, base loss: 16592.27
[INFO 2017-07-01 18:26:18,955 main.py:52] epoch 422, training loss: 8571.69, average training loss: 9721.83, base loss: 16591.11
[INFO 2017-07-01 18:26:23,297 main.py:52] epoch 423, training loss: 7941.60, average training loss: 9717.63, base loss: 16588.91
[INFO 2017-07-01 18:26:27,463 main.py:52] epoch 424, training loss: 8955.53, average training loss: 9715.84, base loss: 16591.62
[INFO 2017-07-01 18:26:31,713 main.py:52] epoch 425, training loss: 8368.17, average training loss: 9712.68, base loss: 16591.54
[INFO 2017-07-01 18:26:35,888 main.py:52] epoch 426, training loss: 7750.44, average training loss: 9708.08, base loss: 16586.52
[INFO 2017-07-01 18:26:40,082 main.py:52] epoch 427, training loss: 8443.03, average training loss: 9705.13, base loss: 16585.40
[INFO 2017-07-01 18:26:44,301 main.py:52] epoch 428, training loss: 6673.58, average training loss: 9698.06, base loss: 16574.65
[INFO 2017-07-01 18:26:48,484 main.py:52] epoch 429, training loss: 7782.15, average training loss: 9693.60, base loss: 16569.73
[INFO 2017-07-01 18:26:52,696 main.py:52] epoch 430, training loss: 8116.06, average training loss: 9689.94, base loss: 16567.60
[INFO 2017-07-01 18:26:56,918 main.py:52] epoch 431, training loss: 7801.69, average training loss: 9685.57, base loss: 16564.86
[INFO 2017-07-01 18:27:01,149 main.py:52] epoch 432, training loss: 9344.82, average training loss: 9684.79, base loss: 16570.84
[INFO 2017-07-01 18:27:05,323 main.py:52] epoch 433, training loss: 8345.16, average training loss: 9681.70, base loss: 16571.69
[INFO 2017-07-01 18:27:09,512 main.py:52] epoch 434, training loss: 7492.30, average training loss: 9676.67, base loss: 16566.80
[INFO 2017-07-01 18:27:13,702 main.py:52] epoch 435, training loss: 8761.05, average training loss: 9674.57, base loss: 16568.59
[INFO 2017-07-01 18:27:17,904 main.py:52] epoch 436, training loss: 7616.95, average training loss: 9669.86, base loss: 16563.09
[INFO 2017-07-01 18:27:22,109 main.py:52] epoch 437, training loss: 7952.19, average training loss: 9665.94, base loss: 16561.70
[INFO 2017-07-01 18:27:26,246 main.py:52] epoch 438, training loss: 8168.60, average training loss: 9662.52, base loss: 16561.75
[INFO 2017-07-01 18:27:30,478 main.py:52] epoch 439, training loss: 7279.84, average training loss: 9657.11, base loss: 16556.83
[INFO 2017-07-01 18:27:34,700 main.py:52] epoch 440, training loss: 7758.92, average training loss: 9652.80, base loss: 16555.55
[INFO 2017-07-01 18:27:38,886 main.py:52] epoch 441, training loss: 8896.51, average training loss: 9651.09, base loss: 16557.03
[INFO 2017-07-01 18:27:43,032 main.py:52] epoch 442, training loss: 8324.16, average training loss: 9648.10, base loss: 16556.82
[INFO 2017-07-01 18:27:47,228 main.py:52] epoch 443, training loss: 8250.84, average training loss: 9644.95, base loss: 16558.17
[INFO 2017-07-01 18:27:51,451 main.py:52] epoch 444, training loss: 8250.70, average training loss: 9641.82, base loss: 16558.67
[INFO 2017-07-01 18:27:55,625 main.py:52] epoch 445, training loss: 8929.93, average training loss: 9640.22, base loss: 16562.54
[INFO 2017-07-01 18:27:59,889 main.py:52] epoch 446, training loss: 7644.74, average training loss: 9635.76, base loss: 16559.55
[INFO 2017-07-01 18:28:04,063 main.py:52] epoch 447, training loss: 8899.17, average training loss: 9634.11, base loss: 16563.10
[INFO 2017-07-01 18:28:08,256 main.py:52] epoch 448, training loss: 7868.59, average training loss: 9630.18, base loss: 16562.21
[INFO 2017-07-01 18:28:12,478 main.py:52] epoch 449, training loss: 7548.53, average training loss: 9625.56, base loss: 16559.50
[INFO 2017-07-01 18:28:16,686 main.py:52] epoch 450, training loss: 9005.80, average training loss: 9624.18, base loss: 16562.36
[INFO 2017-07-01 18:28:20,828 main.py:52] epoch 451, training loss: 8127.67, average training loss: 9620.87, base loss: 16562.20
[INFO 2017-07-01 18:28:25,055 main.py:52] epoch 452, training loss: 7733.73, average training loss: 9616.71, base loss: 16558.58
[INFO 2017-07-01 18:28:29,248 main.py:52] epoch 453, training loss: 9676.50, average training loss: 9616.84, base loss: 16559.56
[INFO 2017-07-01 18:28:33,511 main.py:52] epoch 454, training loss: 9701.22, average training loss: 9617.02, base loss: 16563.80
[INFO 2017-07-01 18:28:37,757 main.py:52] epoch 455, training loss: 8988.21, average training loss: 9615.64, base loss: 16565.27
[INFO 2017-07-01 18:28:41,917 main.py:52] epoch 456, training loss: 8673.43, average training loss: 9613.58, base loss: 16566.37
[INFO 2017-07-01 18:28:46,111 main.py:52] epoch 457, training loss: 8544.58, average training loss: 9611.25, base loss: 16566.55
[INFO 2017-07-01 18:28:50,282 main.py:52] epoch 458, training loss: 8146.80, average training loss: 9608.06, base loss: 16565.61
[INFO 2017-07-01 18:28:54,448 main.py:52] epoch 459, training loss: 8808.96, average training loss: 9606.32, base loss: 16570.13
[INFO 2017-07-01 18:28:58,621 main.py:52] epoch 460, training loss: 9968.66, average training loss: 9607.11, base loss: 16571.73
[INFO 2017-07-01 18:29:02,832 main.py:52] epoch 461, training loss: 8143.91, average training loss: 9603.94, base loss: 16571.18
[INFO 2017-07-01 18:29:06,988 main.py:52] epoch 462, training loss: 7939.02, average training loss: 9600.34, base loss: 16569.98
[INFO 2017-07-01 18:29:11,099 main.py:52] epoch 463, training loss: 7570.34, average training loss: 9595.97, base loss: 16565.80
[INFO 2017-07-01 18:29:15,340 main.py:52] epoch 464, training loss: 7268.53, average training loss: 9590.96, base loss: 16561.28
[INFO 2017-07-01 18:29:19,691 main.py:52] epoch 465, training loss: 8182.82, average training loss: 9587.94, base loss: 16561.03
[INFO 2017-07-01 18:29:23,917 main.py:52] epoch 466, training loss: 8168.70, average training loss: 9584.90, base loss: 16561.16
[INFO 2017-07-01 18:29:28,083 main.py:52] epoch 467, training loss: 7734.68, average training loss: 9580.95, base loss: 16558.30
[INFO 2017-07-01 18:29:32,264 main.py:52] epoch 468, training loss: 8236.02, average training loss: 9578.08, base loss: 16556.62
[INFO 2017-07-01 18:29:36,498 main.py:52] epoch 469, training loss: 8640.33, average training loss: 9576.09, base loss: 16557.97
[INFO 2017-07-01 18:29:40,689 main.py:52] epoch 470, training loss: 8665.86, average training loss: 9574.15, base loss: 16560.78
[INFO 2017-07-01 18:29:44,883 main.py:52] epoch 471, training loss: 8006.92, average training loss: 9570.83, base loss: 16559.72
[INFO 2017-07-01 18:29:49,099 main.py:52] epoch 472, training loss: 7651.58, average training loss: 9566.77, base loss: 16557.71
[INFO 2017-07-01 18:29:53,276 main.py:52] epoch 473, training loss: 8535.46, average training loss: 9564.60, base loss: 16558.10
[INFO 2017-07-01 18:29:57,427 main.py:52] epoch 474, training loss: 7926.41, average training loss: 9561.15, base loss: 16555.42
[INFO 2017-07-01 18:30:01,623 main.py:52] epoch 475, training loss: 7325.62, average training loss: 9556.45, base loss: 16549.50
[INFO 2017-07-01 18:30:05,887 main.py:52] epoch 476, training loss: 8889.58, average training loss: 9555.06, base loss: 16552.71
[INFO 2017-07-01 18:30:10,018 main.py:52] epoch 477, training loss: 8019.65, average training loss: 9551.84, base loss: 16552.69
[INFO 2017-07-01 18:30:14,206 main.py:52] epoch 478, training loss: 7541.06, average training loss: 9547.65, base loss: 16549.28
[INFO 2017-07-01 18:30:18,550 main.py:52] epoch 479, training loss: 8440.90, average training loss: 9545.34, base loss: 16549.62
[INFO 2017-07-01 18:30:22,715 main.py:52] epoch 480, training loss: 8905.18, average training loss: 9544.01, base loss: 16553.42
[INFO 2017-07-01 18:30:26,864 main.py:52] epoch 481, training loss: 9637.62, average training loss: 9544.20, base loss: 16556.54
[INFO 2017-07-01 18:30:31,038 main.py:52] epoch 482, training loss: 7625.43, average training loss: 9540.23, base loss: 16553.22
[INFO 2017-07-01 18:30:35,217 main.py:52] epoch 483, training loss: 8355.21, average training loss: 9537.78, base loss: 16552.45
[INFO 2017-07-01 18:30:39,377 main.py:52] epoch 484, training loss: 7717.80, average training loss: 9534.03, base loss: 16550.47
[INFO 2017-07-01 18:30:43,561 main.py:52] epoch 485, training loss: 8266.90, average training loss: 9531.42, base loss: 16549.02
[INFO 2017-07-01 18:30:47,788 main.py:52] epoch 486, training loss: 8435.96, average training loss: 9529.17, base loss: 16550.33
[INFO 2017-07-01 18:30:51,962 main.py:52] epoch 487, training loss: 8334.90, average training loss: 9526.73, base loss: 16549.62
[INFO 2017-07-01 18:30:56,153 main.py:52] epoch 488, training loss: 8266.71, average training loss: 9524.15, base loss: 16552.15
[INFO 2017-07-01 18:31:00,440 main.py:52] epoch 489, training loss: 8131.86, average training loss: 9521.31, base loss: 16552.70
[INFO 2017-07-01 18:31:04,776 main.py:52] epoch 490, training loss: 8395.41, average training loss: 9519.01, base loss: 16554.46
[INFO 2017-07-01 18:31:08,907 main.py:52] epoch 491, training loss: 7934.49, average training loss: 9515.79, base loss: 16551.36
[INFO 2017-07-01 18:31:13,062 main.py:52] epoch 492, training loss: 7930.84, average training loss: 9512.58, base loss: 16550.22
[INFO 2017-07-01 18:31:17,203 main.py:52] epoch 493, training loss: 8459.38, average training loss: 9510.45, base loss: 16552.23
[INFO 2017-07-01 18:31:21,339 main.py:52] epoch 494, training loss: 8088.33, average training loss: 9507.57, base loss: 16552.34
[INFO 2017-07-01 18:31:25,480 main.py:52] epoch 495, training loss: 8279.66, average training loss: 9505.10, base loss: 16552.26
[INFO 2017-07-01 18:31:29,642 main.py:52] epoch 496, training loss: 7594.94, average training loss: 9501.26, base loss: 16551.03
[INFO 2017-07-01 18:31:33,807 main.py:52] epoch 497, training loss: 8157.66, average training loss: 9498.56, base loss: 16551.04
[INFO 2017-07-01 18:31:37,951 main.py:52] epoch 498, training loss: 8861.76, average training loss: 9497.28, base loss: 16554.79
[INFO 2017-07-01 18:31:42,143 main.py:52] epoch 499, training loss: 8335.82, average training loss: 9494.96, base loss: 16554.14
[INFO 2017-07-01 18:31:42,143 main.py:54] epoch 499, testing
[INFO 2017-07-01 18:31:42,143 main.py:61] model save to ./model/final.pth
[INFO 2017-07-01 18:31:46,369 main.py:52] epoch 500, training loss: 8379.57, average training loss: 9492.73, base loss: 16556.95
[INFO 2017-07-01 18:31:50,543 main.py:52] epoch 501, training loss: 9278.10, average training loss: 9492.30, base loss: 16562.67
[INFO 2017-07-01 18:31:54,672 main.py:52] epoch 502, training loss: 8020.64, average training loss: 9489.38, base loss: 16559.30
[INFO 2017-07-01 18:31:58,813 main.py:52] epoch 503, training loss: 9491.55, average training loss: 9489.38, base loss: 16561.13
[INFO 2017-07-01 18:32:03,022 main.py:52] epoch 504, training loss: 7520.68, average training loss: 9485.48, base loss: 16559.73
[INFO 2017-07-01 18:32:07,192 main.py:52] epoch 505, training loss: 7269.11, average training loss: 9481.10, base loss: 16557.62
[INFO 2017-07-01 18:32:11,396 main.py:52] epoch 506, training loss: 8487.77, average training loss: 9479.14, base loss: 16558.18
[INFO 2017-07-01 18:32:15,546 main.py:52] epoch 507, training loss: 7972.61, average training loss: 9476.18, base loss: 16557.11
[INFO 2017-07-01 18:32:19,808 main.py:52] epoch 508, training loss: 8000.82, average training loss: 9473.28, base loss: 16553.12
[INFO 2017-07-01 18:32:23,968 main.py:52] epoch 509, training loss: 6934.66, average training loss: 9468.30, base loss: 16545.14
[INFO 2017-07-01 18:32:28,149 main.py:52] epoch 510, training loss: 7783.31, average training loss: 9465.01, base loss: 16543.96
[INFO 2017-07-01 18:32:32,329 main.py:52] epoch 511, training loss: 8079.86, average training loss: 9462.30, base loss: 16542.90
[INFO 2017-07-01 18:32:36,492 main.py:52] epoch 512, training loss: 8814.69, average training loss: 9461.04, base loss: 16539.65
[INFO 2017-07-01 18:32:40,638 main.py:52] epoch 513, training loss: 8172.17, average training loss: 9458.53, base loss: 16537.03
[INFO 2017-07-01 18:32:44,889 main.py:52] epoch 514, training loss: 7799.98, average training loss: 9455.31, base loss: 16533.78
[INFO 2017-07-01 18:32:49,101 main.py:52] epoch 515, training loss: 8755.56, average training loss: 9453.95, base loss: 16534.32
[INFO 2017-07-01 18:32:53,212 main.py:52] epoch 516, training loss: 7950.62, average training loss: 9451.05, base loss: 16532.93
[INFO 2017-07-01 18:32:57,329 main.py:52] epoch 517, training loss: 8368.30, average training loss: 9448.96, base loss: 16535.33
[INFO 2017-07-01 18:33:01,474 main.py:52] epoch 518, training loss: 7797.22, average training loss: 9445.77, base loss: 16531.69
[INFO 2017-07-01 18:33:05,599 main.py:52] epoch 519, training loss: 7478.19, average training loss: 9441.99, base loss: 16528.81
[INFO 2017-07-01 18:33:09,790 main.py:52] epoch 520, training loss: 8425.51, average training loss: 9440.04, base loss: 16525.80
[INFO 2017-07-01 18:33:13,996 main.py:52] epoch 521, training loss: 8363.56, average training loss: 9437.98, base loss: 16525.39
[INFO 2017-07-01 18:33:18,212 main.py:52] epoch 522, training loss: 8722.72, average training loss: 9436.61, base loss: 16528.45
[INFO 2017-07-01 18:33:22,429 main.py:52] epoch 523, training loss: 7996.67, average training loss: 9433.86, base loss: 16526.47
[INFO 2017-07-01 18:33:26,720 main.py:52] epoch 524, training loss: 9634.87, average training loss: 9434.24, base loss: 16528.66
[INFO 2017-07-01 18:33:30,864 main.py:52] epoch 525, training loss: 9487.09, average training loss: 9434.34, base loss: 16532.30
[INFO 2017-07-01 18:33:35,023 main.py:52] epoch 526, training loss: 7938.70, average training loss: 9431.51, base loss: 16529.21
[INFO 2017-07-01 18:33:39,178 main.py:52] epoch 527, training loss: 7508.49, average training loss: 9427.86, base loss: 16526.60
[INFO 2017-07-01 18:33:43,334 main.py:52] epoch 528, training loss: 8340.41, average training loss: 9425.81, base loss: 16524.11
[INFO 2017-07-01 18:33:47,595 main.py:52] epoch 529, training loss: 8262.68, average training loss: 9423.61, base loss: 16522.42
[INFO 2017-07-01 18:33:51,769 main.py:52] epoch 530, training loss: 8586.43, average training loss: 9422.04, base loss: 16523.08
[INFO 2017-07-01 18:33:55,924 main.py:52] epoch 531, training loss: 8647.00, average training loss: 9420.58, base loss: 16525.38
[INFO 2017-07-01 18:34:00,077 main.py:52] epoch 532, training loss: 8321.25, average training loss: 9418.52, base loss: 16525.68
[INFO 2017-07-01 18:34:04,358 main.py:52] epoch 533, training loss: 8090.57, average training loss: 9416.03, base loss: 16525.36
[INFO 2017-07-01 18:34:08,523 main.py:52] epoch 534, training loss: 8541.75, average training loss: 9414.40, base loss: 16530.35
[INFO 2017-07-01 18:34:12,690 main.py:52] epoch 535, training loss: 6997.45, average training loss: 9409.89, base loss: 16526.78
[INFO 2017-07-01 18:34:16,922 main.py:52] epoch 536, training loss: 8193.37, average training loss: 9407.62, base loss: 16529.53
[INFO 2017-07-01 18:34:21,098 main.py:52] epoch 537, training loss: 7862.62, average training loss: 9404.75, base loss: 16531.74
[INFO 2017-07-01 18:34:25,323 main.py:52] epoch 538, training loss: 8749.91, average training loss: 9403.54, base loss: 16534.67
[INFO 2017-07-01 18:34:29,410 main.py:52] epoch 539, training loss: 8888.00, average training loss: 9402.58, base loss: 16537.45
[INFO 2017-07-01 18:34:33,629 main.py:52] epoch 540, training loss: 8946.76, average training loss: 9401.74, base loss: 16539.00
[INFO 2017-07-01 18:34:37,838 main.py:52] epoch 541, training loss: 8185.39, average training loss: 9399.49, base loss: 16539.06
[INFO 2017-07-01 18:34:42,048 main.py:52] epoch 542, training loss: 7949.23, average training loss: 9396.82, base loss: 16537.85
[INFO 2017-07-01 18:34:46,190 main.py:52] epoch 543, training loss: 9679.52, average training loss: 9397.34, base loss: 16539.25
[INFO 2017-07-01 18:34:50,349 main.py:52] epoch 544, training loss: 7842.75, average training loss: 9394.49, base loss: 16536.51
[INFO 2017-07-01 18:34:54,538 main.py:52] epoch 545, training loss: 7731.96, average training loss: 9391.45, base loss: 16537.49
[INFO 2017-07-01 18:34:58,721 main.py:52] epoch 546, training loss: 8270.32, average training loss: 9389.40, base loss: 16538.14
[INFO 2017-07-01 18:35:02,904 main.py:52] epoch 547, training loss: 8950.83, average training loss: 9388.60, base loss: 16543.34
[INFO 2017-07-01 18:35:07,169 main.py:52] epoch 548, training loss: 10023.69, average training loss: 9389.75, base loss: 16549.75
[INFO 2017-07-01 18:35:11,365 main.py:52] epoch 549, training loss: 8135.32, average training loss: 9387.47, base loss: 16550.98
[INFO 2017-07-01 18:35:15,529 main.py:52] epoch 550, training loss: 8654.64, average training loss: 9386.14, base loss: 16551.81
[INFO 2017-07-01 18:35:19,737 main.py:52] epoch 551, training loss: 7994.31, average training loss: 9383.62, base loss: 16555.22
[INFO 2017-07-01 18:35:23,890 main.py:52] epoch 552, training loss: 7358.40, average training loss: 9379.96, base loss: 16551.23
[INFO 2017-07-01 18:35:28,033 main.py:52] epoch 553, training loss: 7552.66, average training loss: 9376.66, base loss: 16549.02
[INFO 2017-07-01 18:35:32,278 main.py:52] epoch 554, training loss: 8265.75, average training loss: 9374.66, base loss: 16548.29
[INFO 2017-07-01 18:35:36,435 main.py:52] epoch 555, training loss: 8071.17, average training loss: 9372.31, base loss: 16543.26
[INFO 2017-07-01 18:35:40,660 main.py:52] epoch 556, training loss: 7426.22, average training loss: 9368.82, base loss: 16540.59
[INFO 2017-07-01 18:35:44,869 main.py:52] epoch 557, training loss: 7551.15, average training loss: 9365.56, base loss: 16538.54
[INFO 2017-07-01 18:35:48,961 main.py:52] epoch 558, training loss: 9240.51, average training loss: 9365.34, base loss: 16541.41
[INFO 2017-07-01 18:35:53,187 main.py:52] epoch 559, training loss: 8028.16, average training loss: 9362.95, base loss: 16540.13
[INFO 2017-07-01 18:35:57,373 main.py:52] epoch 560, training loss: 8102.98, average training loss: 9360.70, base loss: 16540.82
[INFO 2017-07-01 18:36:01,568 main.py:52] epoch 561, training loss: 8190.51, average training loss: 9358.62, base loss: 16538.56
[INFO 2017-07-01 18:36:05,713 main.py:52] epoch 562, training loss: 7468.97, average training loss: 9355.27, base loss: 16536.57
[INFO 2017-07-01 18:36:09,915 main.py:52] epoch 563, training loss: 7993.08, average training loss: 9352.85, base loss: 16538.90
[INFO 2017-07-01 18:36:14,069 main.py:52] epoch 564, training loss: 7678.63, average training loss: 9349.89, base loss: 16535.70
[INFO 2017-07-01 18:36:18,240 main.py:52] epoch 565, training loss: 7547.86, average training loss: 9346.70, base loss: 16529.15
[INFO 2017-07-01 18:36:22,429 main.py:52] epoch 566, training loss: 8231.92, average training loss: 9344.74, base loss: 16529.03
[INFO 2017-07-01 18:36:26,638 main.py:52] epoch 567, training loss: 8416.21, average training loss: 9343.10, base loss: 16530.36
[INFO 2017-07-01 18:36:30,810 main.py:52] epoch 568, training loss: 10050.02, average training loss: 9344.35, base loss: 16536.23
[INFO 2017-07-01 18:36:35,037 main.py:52] epoch 569, training loss: 7747.43, average training loss: 9341.54, base loss: 16535.84
[INFO 2017-07-01 18:36:39,188 main.py:52] epoch 570, training loss: 8059.99, average training loss: 9339.30, base loss: 16534.54
[INFO 2017-07-01 18:36:43,385 main.py:52] epoch 571, training loss: 7943.34, average training loss: 9336.86, base loss: 16530.08
[INFO 2017-07-01 18:36:47,531 main.py:52] epoch 572, training loss: 9182.50, average training loss: 9336.59, base loss: 16531.09
[INFO 2017-07-01 18:36:51,731 main.py:52] epoch 573, training loss: 8443.19, average training loss: 9335.03, base loss: 16531.60
[INFO 2017-07-01 18:36:55,973 main.py:52] epoch 574, training loss: 9441.03, average training loss: 9335.22, base loss: 16533.14
[INFO 2017-07-01 18:37:00,198 main.py:52] epoch 575, training loss: 9217.63, average training loss: 9335.01, base loss: 16534.61
[INFO 2017-07-01 18:37:04,316 main.py:52] epoch 576, training loss: 7569.59, average training loss: 9331.95, base loss: 16532.39
[INFO 2017-07-01 18:37:08,517 main.py:52] epoch 577, training loss: 8236.18, average training loss: 9330.06, base loss: 16533.16
[INFO 2017-07-01 18:37:12,665 main.py:52] epoch 578, training loss: 8638.49, average training loss: 9328.86, base loss: 16536.05
[INFO 2017-07-01 18:37:16,888 main.py:52] epoch 579, training loss: 7428.61, average training loss: 9325.59, base loss: 16531.25
[INFO 2017-07-01 18:37:21,065 main.py:52] epoch 580, training loss: 9375.73, average training loss: 9325.67, base loss: 16538.71
[INFO 2017-07-01 18:37:25,293 main.py:52] epoch 581, training loss: 8053.87, average training loss: 9323.49, base loss: 16539.92
[INFO 2017-07-01 18:37:29,482 main.py:52] epoch 582, training loss: 7685.38, average training loss: 9320.68, base loss: 16535.87
[INFO 2017-07-01 18:37:33,680 main.py:52] epoch 583, training loss: 8366.04, average training loss: 9319.04, base loss: 16538.57
[INFO 2017-07-01 18:37:37,872 main.py:52] epoch 584, training loss: 8696.77, average training loss: 9317.98, base loss: 16538.69
[INFO 2017-07-01 18:37:42,123 main.py:52] epoch 585, training loss: 8092.34, average training loss: 9315.89, base loss: 16535.44
[INFO 2017-07-01 18:37:46,336 main.py:52] epoch 586, training loss: 8131.86, average training loss: 9313.87, base loss: 16535.93
[INFO 2017-07-01 18:37:50,587 main.py:52] epoch 587, training loss: 8037.40, average training loss: 9311.70, base loss: 16536.81
[INFO 2017-07-01 18:37:54,824 main.py:52] epoch 588, training loss: 7693.14, average training loss: 9308.95, base loss: 16536.76
[INFO 2017-07-01 18:37:59,069 main.py:52] epoch 589, training loss: 8552.15, average training loss: 9307.67, base loss: 16539.87
[INFO 2017-07-01 18:38:03,243 main.py:52] epoch 590, training loss: 9102.84, average training loss: 9307.32, base loss: 16542.71
[INFO 2017-07-01 18:38:07,390 main.py:52] epoch 591, training loss: 8584.46, average training loss: 9306.10, base loss: 16543.66
[INFO 2017-07-01 18:38:11,518 main.py:52] epoch 592, training loss: 9479.63, average training loss: 9306.39, base loss: 16548.05
[INFO 2017-07-01 18:38:15,649 main.py:52] epoch 593, training loss: 8342.99, average training loss: 9304.77, base loss: 16548.04
[INFO 2017-07-01 18:38:19,869 main.py:52] epoch 594, training loss: 8125.22, average training loss: 9302.79, base loss: 16548.84
[INFO 2017-07-01 18:38:24,067 main.py:52] epoch 595, training loss: 7627.44, average training loss: 9299.98, base loss: 16544.62
[INFO 2017-07-01 18:38:28,323 main.py:52] epoch 596, training loss: 8738.05, average training loss: 9299.04, base loss: 16548.04
[INFO 2017-07-01 18:38:32,545 main.py:52] epoch 597, training loss: 8855.42, average training loss: 9298.30, base loss: 16551.94
[INFO 2017-07-01 18:38:36,724 main.py:52] epoch 598, training loss: 6778.75, average training loss: 9294.09, base loss: 16544.82
[INFO 2017-07-01 18:38:40,949 main.py:52] epoch 599, training loss: 7793.86, average training loss: 9291.59, base loss: 16541.96
[INFO 2017-07-01 18:38:40,949 main.py:54] epoch 599, testing
[INFO 2017-07-01 18:38:40,949 main.py:61] model save to ./model/final.pth
[INFO 2017-07-01 18:38:45,298 main.py:52] epoch 600, training loss: 7553.86, average training loss: 9288.70, base loss: 16539.13
[INFO 2017-07-01 18:38:49,417 main.py:52] epoch 601, training loss: 7333.85, average training loss: 9285.45, base loss: 16534.62
[INFO 2017-07-01 18:38:53,629 main.py:52] epoch 602, training loss: 8796.78, average training loss: 9284.64, base loss: 16537.03
[INFO 2017-07-01 18:38:57,786 main.py:52] epoch 603, training loss: 7402.70, average training loss: 9281.52, base loss: 16534.60
[INFO 2017-07-01 18:39:01,933 main.py:52] epoch 604, training loss: 8858.26, average training loss: 9280.83, base loss: 16538.10
[INFO 2017-07-01 18:39:06,110 main.py:52] epoch 605, training loss: 8590.15, average training loss: 9279.69, base loss: 16541.67
[INFO 2017-07-01 18:39:10,350 main.py:52] epoch 606, training loss: 8179.89, average training loss: 9277.87, base loss: 16545.02
[INFO 2017-07-01 18:39:14,563 main.py:52] epoch 607, training loss: 9204.92, average training loss: 9277.75, base loss: 16551.72
[INFO 2017-07-01 18:39:18,780 main.py:52] epoch 608, training loss: 7860.73, average training loss: 9275.43, base loss: 16552.26
[INFO 2017-07-01 18:39:22,958 main.py:52] epoch 609, training loss: 7325.66, average training loss: 9272.23, base loss: 16549.86
[INFO 2017-07-01 18:39:27,167 main.py:52] epoch 610, training loss: 7769.53, average training loss: 9269.77, base loss: 16552.88
[INFO 2017-07-01 18:39:31,378 main.py:52] epoch 611, training loss: 8268.49, average training loss: 9268.13, base loss: 16557.98
[INFO 2017-07-01 18:39:35,631 main.py:52] epoch 612, training loss: 8339.08, average training loss: 9266.62, base loss: 16559.01
[INFO 2017-07-01 18:39:39,786 main.py:52] epoch 613, training loss: 7789.00, average training loss: 9264.21, base loss: 16558.97
[INFO 2017-07-01 18:39:43,942 main.py:52] epoch 614, training loss: 8415.05, average training loss: 9262.83, base loss: 16556.02
[INFO 2017-07-01 18:39:48,142 main.py:52] epoch 615, training loss: 7814.40, average training loss: 9260.48, base loss: 16553.49
[INFO 2017-07-01 18:39:52,295 main.py:52] epoch 616, training loss: 9327.71, average training loss: 9260.59, base loss: 16553.90
[INFO 2017-07-01 18:39:56,430 main.py:52] epoch 617, training loss: 8015.80, average training loss: 9258.58, base loss: 16552.97
[INFO 2017-07-01 18:40:00,668 main.py:52] epoch 618, training loss: 7642.17, average training loss: 9255.96, base loss: 16548.65
[INFO 2017-07-01 18:40:04,890 main.py:52] epoch 619, training loss: 7902.78, average training loss: 9253.78, base loss: 16545.47
[INFO 2017-07-01 18:40:09,141 main.py:52] epoch 620, training loss: 8106.50, average training loss: 9251.93, base loss: 16542.70
[INFO 2017-07-01 18:40:13,305 main.py:52] epoch 621, training loss: 8928.99, average training loss: 9251.41, base loss: 16541.39
[INFO 2017-07-01 18:40:17,438 main.py:52] epoch 622, training loss: 7086.39, average training loss: 9247.94, base loss: 16534.88
[INFO 2017-07-01 18:40:21,613 main.py:52] epoch 623, training loss: 7940.85, average training loss: 9245.84, base loss: 16533.31
[INFO 2017-07-01 18:40:25,801 main.py:52] epoch 624, training loss: 7876.91, average training loss: 9243.65, base loss: 16533.79
[INFO 2017-07-01 18:40:29,956 main.py:52] epoch 625, training loss: 8674.50, average training loss: 9242.75, base loss: 16535.78
[INFO 2017-07-01 18:40:34,141 main.py:52] epoch 626, training loss: 7707.33, average training loss: 9240.30, base loss: 16533.57
[INFO 2017-07-01 18:40:38,391 main.py:52] epoch 627, training loss: 7968.59, average training loss: 9238.27, base loss: 16531.96
[INFO 2017-07-01 18:40:42,497 main.py:52] epoch 628, training loss: 8889.11, average training loss: 9237.72, base loss: 16532.52
[INFO 2017-07-01 18:40:46,648 main.py:52] epoch 629, training loss: 8001.80, average training loss: 9235.75, base loss: 16533.21
[INFO 2017-07-01 18:40:50,817 main.py:52] epoch 630, training loss: 7816.08, average training loss: 9233.50, base loss: 16533.31
[INFO 2017-07-01 18:40:55,041 main.py:52] epoch 631, training loss: 7614.99, average training loss: 9230.94, base loss: 16532.74
