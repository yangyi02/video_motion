[INFO 2017-07-02 01:36:45,645 main.py:175] Namespace(batch_size=32, display=False, flow_dir='flow', flow_video_dir='flow-video', flow_video_fps=1, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=4, num_channel=3, num_inputs=2, save_dir='./model', test=False, test_dir='/home/yi/Downloads/mpii-test-64', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='/home/yi/Downloads/mpii-64', train_epoch=100000)
[INFO 2017-07-02 01:36:52,590 main.py:52] epoch 0, training loss: 42687.89, average training loss: 42687.89, base loss: 24067.14
[INFO 2017-07-02 01:36:56,700 main.py:52] epoch 1, training loss: 35279.36, average training loss: 38983.62, base loss: 24148.28
[INFO 2017-07-02 01:37:00,728 main.py:52] epoch 2, training loss: 32346.56, average training loss: 36771.27, base loss: 23608.96
[INFO 2017-07-02 01:37:04,795 main.py:52] epoch 3, training loss: 29868.39, average training loss: 35045.55, base loss: 23788.36
[INFO 2017-07-02 01:37:08,895 main.py:52] epoch 4, training loss: 26882.34, average training loss: 33412.91, base loss: 24193.94
[INFO 2017-07-02 01:37:12,901 main.py:52] epoch 5, training loss: 24477.19, average training loss: 31923.62, base loss: 24305.55
[INFO 2017-07-02 01:37:16,802 main.py:52] epoch 6, training loss: 21657.90, average training loss: 30457.09, base loss: 24124.58
[INFO 2017-07-02 01:37:21,253 main.py:52] epoch 7, training loss: 22321.58, average training loss: 29440.15, base loss: 24131.99
[INFO 2017-07-02 01:37:26,022 main.py:52] epoch 8, training loss: 22866.55, average training loss: 28709.75, base loss: 24532.08
[INFO 2017-07-02 01:37:30,597 main.py:52] epoch 9, training loss: 19622.48, average training loss: 27801.02, base loss: 24446.24
[INFO 2017-07-02 01:37:35,176 main.py:52] epoch 10, training loss: 18838.39, average training loss: 26986.24, base loss: 24411.17
[INFO 2017-07-02 01:37:39,924 main.py:52] epoch 11, training loss: 20095.74, average training loss: 26412.03, base loss: 24599.62
[INFO 2017-07-02 01:37:45,037 main.py:52] epoch 12, training loss: 19735.06, average training loss: 25898.42, base loss: 24744.76
[INFO 2017-07-02 01:37:49,712 main.py:52] epoch 13, training loss: 16833.04, average training loss: 25250.89, base loss: 24608.33
[INFO 2017-07-02 01:37:54,283 main.py:52] epoch 14, training loss: 17484.30, average training loss: 24733.12, base loss: 24632.11
[INFO 2017-07-02 01:37:58,976 main.py:52] epoch 15, training loss: 17575.98, average training loss: 24285.80, base loss: 24635.65
[INFO 2017-07-02 01:38:03,414 main.py:52] epoch 16, training loss: 16677.76, average training loss: 23838.27, base loss: 24558.63
[INFO 2017-07-02 01:38:08,018 main.py:52] epoch 17, training loss: 16857.77, average training loss: 23450.46, base loss: 24569.04
[INFO 2017-07-02 01:38:12,777 main.py:52] epoch 18, training loss: 15925.49, average training loss: 23054.41, base loss: 24545.83
[INFO 2017-07-02 01:38:17,471 main.py:52] epoch 19, training loss: 17240.22, average training loss: 22763.70, base loss: 24568.08
[INFO 2017-07-02 01:38:22,236 main.py:52] epoch 20, training loss: 17448.86, average training loss: 22510.61, base loss: 24632.91
[INFO 2017-07-02 01:38:27,436 main.py:52] epoch 21, training loss: 17731.42, average training loss: 22293.38, base loss: 24715.63
[INFO 2017-07-02 01:38:31,889 main.py:52] epoch 22, training loss: 15164.44, average training loss: 21983.42, base loss: 24692.31
[INFO 2017-07-02 01:38:36,771 main.py:52] epoch 23, training loss: 14929.93, average training loss: 21689.53, base loss: 24615.41
[INFO 2017-07-02 01:38:41,401 main.py:52] epoch 24, training loss: 16610.40, average training loss: 21486.36, base loss: 24667.44
[INFO 2017-07-02 01:38:45,909 main.py:52] epoch 25, training loss: 17987.82, average training loss: 21351.80, base loss: 24769.50
[INFO 2017-07-02 01:38:50,688 main.py:52] epoch 26, training loss: 16942.87, average training loss: 21188.51, base loss: 24843.52
[INFO 2017-07-02 01:38:55,293 main.py:52] epoch 27, training loss: 15430.67, average training loss: 20982.87, base loss: 24837.46
[INFO 2017-07-02 01:38:59,972 main.py:52] epoch 28, training loss: 15835.80, average training loss: 20805.39, base loss: 24858.42
[INFO 2017-07-02 01:39:04,612 main.py:52] epoch 29, training loss: 14916.40, average training loss: 20609.09, base loss: 24828.59
[INFO 2017-07-02 01:39:09,366 main.py:52] epoch 30, training loss: 15547.53, average training loss: 20445.81, base loss: 24880.41
[INFO 2017-07-02 01:39:14,290 main.py:52] epoch 31, training loss: 16617.27, average training loss: 20326.17, base loss: 24963.67
[INFO 2017-07-02 01:39:19,201 main.py:52] epoch 32, training loss: 14672.11, average training loss: 20154.83, base loss: 24906.79
[INFO 2017-07-02 01:39:23,777 main.py:52] epoch 33, training loss: 14339.59, average training loss: 19983.80, base loss: 24855.69
[INFO 2017-07-02 01:39:28,492 main.py:52] epoch 34, training loss: 15419.96, average training loss: 19853.40, base loss: 24884.81
[INFO 2017-07-02 01:39:33,278 main.py:52] epoch 35, training loss: 14620.86, average training loss: 19708.05, base loss: 24823.17
[INFO 2017-07-02 01:39:38,019 main.py:52] epoch 36, training loss: 16137.33, average training loss: 19611.55, base loss: 24844.02
[INFO 2017-07-02 01:39:43,035 main.py:52] epoch 37, training loss: 17740.27, average training loss: 19562.30, base loss: 24888.33
[INFO 2017-07-02 01:39:47,822 main.py:52] epoch 38, training loss: 16633.27, average training loss: 19487.20, base loss: 24910.66
[INFO 2017-07-02 01:39:52,609 main.py:52] epoch 39, training loss: 14460.14, average training loss: 19361.52, base loss: 24883.07
[INFO 2017-07-02 01:39:57,459 main.py:52] epoch 40, training loss: 13935.02, average training loss: 19229.17, base loss: 24820.96
[INFO 2017-07-02 01:40:02,124 main.py:52] epoch 41, training loss: 16185.79, average training loss: 19156.71, base loss: 24846.22
[INFO 2017-07-02 01:40:07,064 main.py:52] epoch 42, training loss: 15084.28, average training loss: 19062.00, base loss: 24841.52
[INFO 2017-07-02 01:40:11,695 main.py:52] epoch 43, training loss: 16384.27, average training loss: 19001.14, base loss: 24857.03
[INFO 2017-07-02 01:40:16,543 main.py:52] epoch 44, training loss: 13691.22, average training loss: 18883.14, base loss: 24802.46
[INFO 2017-07-02 01:40:21,122 main.py:52] epoch 45, training loss: 16025.83, average training loss: 18821.03, base loss: 24823.77
[INFO 2017-07-02 01:40:25,857 main.py:52] epoch 46, training loss: 15309.63, average training loss: 18746.32, base loss: 24829.09
[INFO 2017-07-02 01:40:30,453 main.py:52] epoch 47, training loss: 15947.81, average training loss: 18688.02, base loss: 24844.89
[INFO 2017-07-02 01:40:35,139 main.py:52] epoch 48, training loss: 16050.53, average training loss: 18634.19, base loss: 24869.85
[INFO 2017-07-02 01:40:39,785 main.py:52] epoch 49, training loss: 15023.89, average training loss: 18561.98, base loss: 24863.71
[INFO 2017-07-02 01:40:44,647 main.py:52] epoch 50, training loss: 15669.63, average training loss: 18505.27, base loss: 24869.06
[INFO 2017-07-02 01:40:49,660 main.py:52] epoch 51, training loss: 14509.14, average training loss: 18428.42, base loss: 24864.05
[INFO 2017-07-02 01:40:54,532 main.py:52] epoch 52, training loss: 14328.42, average training loss: 18351.06, base loss: 24847.78
[INFO 2017-07-02 01:40:59,183 main.py:52] epoch 53, training loss: 15663.99, average training loss: 18301.30, base loss: 24884.65
[INFO 2017-07-02 01:41:03,777 main.py:52] epoch 54, training loss: 13804.07, average training loss: 18219.54, base loss: 24861.81
[INFO 2017-07-02 01:41:08,543 main.py:52] epoch 55, training loss: 14119.68, average training loss: 18146.32, base loss: 24848.36
[INFO 2017-07-02 01:41:13,251 main.py:52] epoch 56, training loss: 14633.58, average training loss: 18084.70, base loss: 24852.54
[INFO 2017-07-02 01:41:18,044 main.py:52] epoch 57, training loss: 14869.76, average training loss: 18029.27, base loss: 24851.52
[INFO 2017-07-02 01:41:22,889 main.py:52] epoch 58, training loss: 14608.79, average training loss: 17971.29, base loss: 24841.34
[INFO 2017-07-02 01:41:27,439 main.py:52] epoch 59, training loss: 13954.84, average training loss: 17904.35, base loss: 24834.75
[INFO 2017-07-02 01:41:32,342 main.py:52] epoch 60, training loss: 13883.28, average training loss: 17838.43, base loss: 24810.43
[INFO 2017-07-02 01:41:37,023 main.py:52] epoch 61, training loss: 16312.22, average training loss: 17813.82, base loss: 24827.72
[INFO 2017-07-02 01:41:41,557 main.py:52] epoch 62, training loss: 15417.19, average training loss: 17775.77, base loss: 24840.44
[INFO 2017-07-02 01:41:46,359 main.py:52] epoch 63, training loss: 14029.12, average training loss: 17717.23, base loss: 24812.69
[INFO 2017-07-02 01:41:51,088 main.py:52] epoch 64, training loss: 13748.24, average training loss: 17656.17, base loss: 24798.74
[INFO 2017-07-02 01:41:55,846 main.py:52] epoch 65, training loss: 14011.77, average training loss: 17600.95, base loss: 24763.15
[INFO 2017-07-02 01:42:00,696 main.py:52] epoch 66, training loss: 14286.34, average training loss: 17551.48, base loss: 24779.82
[INFO 2017-07-02 01:42:05,435 main.py:52] epoch 67, training loss: 13677.90, average training loss: 17494.52, base loss: 24778.50
[INFO 2017-07-02 01:42:10,208 main.py:52] epoch 68, training loss: 12994.26, average training loss: 17429.30, base loss: 24752.31
[INFO 2017-07-02 01:42:14,883 main.py:52] epoch 69, training loss: 14842.76, average training loss: 17392.35, base loss: 24758.47
[INFO 2017-07-02 01:42:19,714 main.py:52] epoch 70, training loss: 14414.01, average training loss: 17350.40, base loss: 24759.93
[INFO 2017-07-02 01:42:24,403 main.py:52] epoch 71, training loss: 14805.06, average training loss: 17315.05, base loss: 24766.57
[INFO 2017-07-02 01:42:29,138 main.py:52] epoch 72, training loss: 14172.39, average training loss: 17271.99, base loss: 24747.34
[INFO 2017-07-02 01:42:33,741 main.py:52] epoch 73, training loss: 15825.93, average training loss: 17252.45, base loss: 24747.22
[INFO 2017-07-02 01:42:38,371 main.py:52] epoch 74, training loss: 13651.44, average training loss: 17204.44, base loss: 24731.97
[INFO 2017-07-02 01:42:43,046 main.py:52] epoch 75, training loss: 13401.92, average training loss: 17154.41, base loss: 24718.52
[INFO 2017-07-02 01:42:47,769 main.py:52] epoch 76, training loss: 14453.42, average training loss: 17119.33, base loss: 24712.30
[INFO 2017-07-02 01:42:52,314 main.py:52] epoch 77, training loss: 15763.96, average training loss: 17101.95, base loss: 24719.67
[INFO 2017-07-02 01:42:57,090 main.py:52] epoch 78, training loss: 13615.86, average training loss: 17057.83, base loss: 24704.79
[INFO 2017-07-02 01:43:01,846 main.py:52] epoch 79, training loss: 14312.56, average training loss: 17023.51, base loss: 24702.94
[INFO 2017-07-02 01:43:06,589 main.py:52] epoch 80, training loss: 13941.02, average training loss: 16985.45, base loss: 24706.24
[INFO 2017-07-02 01:43:11,320 main.py:52] epoch 81, training loss: 14355.05, average training loss: 16953.38, base loss: 24702.55
[INFO 2017-07-02 01:43:15,876 main.py:52] epoch 82, training loss: 13422.64, average training loss: 16910.84, base loss: 24683.39
[INFO 2017-07-02 01:43:20,609 main.py:52] epoch 83, training loss: 14762.02, average training loss: 16885.26, base loss: 24669.32
[INFO 2017-07-02 01:43:25,349 main.py:52] epoch 84, training loss: 14401.94, average training loss: 16856.04, base loss: 24655.56
[INFO 2017-07-02 01:43:30,139 main.py:52] epoch 85, training loss: 14840.27, average training loss: 16832.60, base loss: 24662.11
[INFO 2017-07-02 01:43:34,717 main.py:52] epoch 86, training loss: 14657.72, average training loss: 16807.60, base loss: 24672.12
[INFO 2017-07-02 01:43:39,670 main.py:52] epoch 87, training loss: 16826.69, average training loss: 16807.82, base loss: 24698.40
[INFO 2017-07-02 01:43:44,544 main.py:52] epoch 88, training loss: 14440.90, average training loss: 16781.22, base loss: 24704.77
[INFO 2017-07-02 01:43:49,193 main.py:52] epoch 89, training loss: 15032.37, average training loss: 16761.79, base loss: 24722.40
[INFO 2017-07-02 01:43:54,045 main.py:52] epoch 90, training loss: 15266.06, average training loss: 16745.36, base loss: 24742.41
[INFO 2017-07-02 01:43:58,923 main.py:52] epoch 91, training loss: 13049.61, average training loss: 16705.19, base loss: 24735.12
[INFO 2017-07-02 01:44:03,758 main.py:52] epoch 92, training loss: 15646.13, average training loss: 16693.80, base loss: 24744.58
[INFO 2017-07-02 01:44:08,408 main.py:52] epoch 93, training loss: 13482.61, average training loss: 16659.64, base loss: 24730.84
[INFO 2017-07-02 01:44:12,998 main.py:52] epoch 94, training loss: 15926.43, average training loss: 16651.92, base loss: 24752.63
[INFO 2017-07-02 01:44:17,744 main.py:52] epoch 95, training loss: 13283.82, average training loss: 16616.83, base loss: 24749.46
[INFO 2017-07-02 01:44:22,459 main.py:52] epoch 96, training loss: 13482.07, average training loss: 16584.52, base loss: 24760.14
[INFO 2017-07-02 01:44:27,270 main.py:52] epoch 97, training loss: 15545.12, average training loss: 16573.91, base loss: 24777.16
[INFO 2017-07-02 01:44:31,841 main.py:52] epoch 98, training loss: 13556.09, average training loss: 16543.43, base loss: 24772.28
[INFO 2017-07-02 01:44:36,873 main.py:52] epoch 99, training loss: 14720.95, average training loss: 16525.20, base loss: 24778.12
[INFO 2017-07-02 01:44:36,873 main.py:54] epoch 99, testing
[INFO 2017-07-02 01:44:36,873 main.py:61] model save to ./model/final.pth
[INFO 2017-07-02 01:44:41,601 main.py:52] epoch 100, training loss: 12592.91, average training loss: 16486.27, base loss: 24767.28
[INFO 2017-07-02 01:44:46,511 main.py:52] epoch 101, training loss: 13612.66, average training loss: 16458.10, base loss: 24764.35
[INFO 2017-07-02 01:44:51,285 main.py:52] epoch 102, training loss: 14877.87, average training loss: 16442.75, base loss: 24771.60
[INFO 2017-07-02 01:44:56,315 main.py:52] epoch 103, training loss: 14201.58, average training loss: 16421.20, base loss: 24772.59
[INFO 2017-07-02 01:45:00,942 main.py:52] epoch 104, training loss: 15451.75, average training loss: 16411.97, base loss: 24778.51
[INFO 2017-07-02 01:45:05,651 main.py:52] epoch 105, training loss: 14625.81, average training loss: 16395.12, base loss: 24788.69
[INFO 2017-07-02 01:45:10,298 main.py:52] epoch 106, training loss: 14152.96, average training loss: 16374.17, base loss: 24806.86
[INFO 2017-07-02 01:45:15,003 main.py:52] epoch 107, training loss: 12429.49, average training loss: 16337.64, base loss: 24785.96
[INFO 2017-07-02 01:45:19,766 main.py:52] epoch 108, training loss: 15306.02, average training loss: 16328.18, base loss: 24789.24
[INFO 2017-07-02 01:45:24,459 main.py:52] epoch 109, training loss: 14765.09, average training loss: 16313.97, base loss: 24809.50
[INFO 2017-07-02 01:45:29,009 main.py:52] epoch 110, training loss: 14682.15, average training loss: 16299.27, base loss: 24820.81
[INFO 2017-07-02 01:45:33,486 main.py:52] epoch 111, training loss: 14964.66, average training loss: 16287.35, base loss: 24830.26
[INFO 2017-07-02 01:45:38,359 main.py:52] epoch 112, training loss: 13897.97, average training loss: 16266.20, base loss: 24824.43
[INFO 2017-07-02 01:45:43,165 main.py:52] epoch 113, training loss: 14930.61, average training loss: 16254.49, base loss: 24830.42
[INFO 2017-07-02 01:45:47,827 main.py:52] epoch 114, training loss: 13020.37, average training loss: 16226.37, base loss: 24807.18
[INFO 2017-07-02 01:45:52,676 main.py:52] epoch 115, training loss: 15573.58, average training loss: 16220.74, base loss: 24833.08
[INFO 2017-07-02 01:45:57,468 main.py:52] epoch 116, training loss: 12497.57, average training loss: 16188.92, base loss: 24824.66
[INFO 2017-07-02 01:46:01,890 main.py:52] epoch 117, training loss: 13897.58, average training loss: 16169.50, base loss: 24823.56
[INFO 2017-07-02 01:46:06,600 main.py:52] epoch 118, training loss: 13945.48, average training loss: 16150.81, base loss: 24818.40
[INFO 2017-07-02 01:46:11,022 main.py:52] epoch 119, training loss: 12464.84, average training loss: 16120.09, base loss: 24801.88
[INFO 2017-07-02 01:46:15,733 main.py:52] epoch 120, training loss: 14369.85, average training loss: 16105.63, base loss: 24806.02
[INFO 2017-07-02 01:46:20,581 main.py:52] epoch 121, training loss: 14993.92, average training loss: 16096.52, base loss: 24809.47
[INFO 2017-07-02 01:46:25,076 main.py:52] epoch 122, training loss: 14998.33, average training loss: 16087.59, base loss: 24823.41
[INFO 2017-07-02 01:46:29,791 main.py:52] epoch 123, training loss: 12981.81, average training loss: 16062.54, base loss: 24811.94
[INFO 2017-07-02 01:46:34,443 main.py:52] epoch 124, training loss: 14119.90, average training loss: 16047.00, base loss: 24816.41
[INFO 2017-07-02 01:46:39,225 main.py:52] epoch 125, training loss: 13450.44, average training loss: 16026.39, base loss: 24814.92
[INFO 2017-07-02 01:46:43,825 main.py:52] epoch 126, training loss: 13306.78, average training loss: 16004.98, base loss: 24802.67
[INFO 2017-07-02 01:46:48,554 main.py:52] epoch 127, training loss: 14331.34, average training loss: 15991.90, base loss: 24798.50
[INFO 2017-07-02 01:46:53,353 main.py:52] epoch 128, training loss: 14088.02, average training loss: 15977.14, base loss: 24809.02
[INFO 2017-07-02 01:46:58,155 main.py:52] epoch 129, training loss: 13134.44, average training loss: 15955.28, base loss: 24804.55
[INFO 2017-07-02 01:47:03,040 main.py:52] epoch 130, training loss: 15108.82, average training loss: 15948.82, base loss: 24815.84
[INFO 2017-07-02 01:47:07,722 main.py:52] epoch 131, training loss: 12912.85, average training loss: 15925.82, base loss: 24807.62
[INFO 2017-07-02 01:47:12,362 main.py:52] epoch 132, training loss: 12954.58, average training loss: 15903.48, base loss: 24806.94
[INFO 2017-07-02 01:47:17,342 main.py:52] epoch 133, training loss: 13372.63, average training loss: 15884.59, base loss: 24806.66
[INFO 2017-07-02 01:47:22,162 main.py:52] epoch 134, training loss: 12503.11, average training loss: 15859.54, base loss: 24800.62
[INFO 2017-07-02 01:47:27,142 main.py:52] epoch 135, training loss: 12585.48, average training loss: 15835.47, base loss: 24791.92
[INFO 2017-07-02 01:47:31,860 main.py:52] epoch 136, training loss: 14661.59, average training loss: 15826.90, base loss: 24800.69
[INFO 2017-07-02 01:47:36,781 main.py:52] epoch 137, training loss: 15286.69, average training loss: 15822.98, base loss: 24815.57
[INFO 2017-07-02 01:47:41,613 main.py:52] epoch 138, training loss: 12501.33, average training loss: 15799.09, base loss: 24806.12
[INFO 2017-07-02 01:47:46,351 main.py:52] epoch 139, training loss: 13282.85, average training loss: 15781.11, base loss: 24799.37
[INFO 2017-07-02 01:47:50,970 main.py:52] epoch 140, training loss: 12911.80, average training loss: 15760.76, base loss: 24789.54
[INFO 2017-07-02 01:47:55,661 main.py:52] epoch 141, training loss: 13414.03, average training loss: 15744.24, base loss: 24783.64
[INFO 2017-07-02 01:48:00,214 main.py:52] epoch 142, training loss: 13667.93, average training loss: 15729.72, base loss: 24779.05
[INFO 2017-07-02 01:48:05,015 main.py:52] epoch 143, training loss: 12315.51, average training loss: 15706.01, base loss: 24764.68
[INFO 2017-07-02 01:48:09,988 main.py:52] epoch 144, training loss: 13528.05, average training loss: 15690.99, base loss: 24758.87
[INFO 2017-07-02 01:48:14,536 main.py:52] epoch 145, training loss: 15732.79, average training loss: 15691.27, base loss: 24766.71
[INFO 2017-07-02 01:48:19,529 main.py:52] epoch 146, training loss: 13372.46, average training loss: 15675.50, base loss: 24756.01
[INFO 2017-07-02 01:48:24,378 main.py:52] epoch 147, training loss: 13450.55, average training loss: 15660.47, base loss: 24761.52
[INFO 2017-07-02 01:48:28,991 main.py:52] epoch 148, training loss: 14605.70, average training loss: 15653.39, base loss: 24766.82
[INFO 2017-07-02 01:48:33,703 main.py:52] epoch 149, training loss: 12829.01, average training loss: 15634.56, base loss: 24766.30
[INFO 2017-07-02 01:48:38,368 main.py:52] epoch 150, training loss: 13754.32, average training loss: 15622.11, base loss: 24771.11
[INFO 2017-07-02 01:48:43,025 main.py:52] epoch 151, training loss: 13673.12, average training loss: 15609.28, base loss: 24772.48
[INFO 2017-07-02 01:48:48,056 main.py:52] epoch 152, training loss: 14345.05, average training loss: 15601.02, base loss: 24779.81
[INFO 2017-07-02 01:48:52,976 main.py:52] epoch 153, training loss: 13542.63, average training loss: 15587.66, base loss: 24785.72
[INFO 2017-07-02 01:48:57,847 main.py:52] epoch 154, training loss: 13768.69, average training loss: 15575.92, base loss: 24792.87
[INFO 2017-07-02 01:49:02,497 main.py:52] epoch 155, training loss: 14613.26, average training loss: 15569.75, base loss: 24794.05
[INFO 2017-07-02 01:49:07,020 main.py:52] epoch 156, training loss: 13152.20, average training loss: 15554.35, base loss: 24793.42
[INFO 2017-07-02 01:49:11,911 main.py:52] epoch 157, training loss: 13742.83, average training loss: 15542.89, base loss: 24807.64
[INFO 2017-07-02 01:49:16,595 main.py:52] epoch 158, training loss: 14494.82, average training loss: 15536.29, base loss: 24811.55
[INFO 2017-07-02 01:49:21,106 main.py:52] epoch 159, training loss: 13710.42, average training loss: 15524.88, base loss: 24802.52
[INFO 2017-07-02 01:49:25,845 main.py:52] epoch 160, training loss: 12333.14, average training loss: 15505.06, base loss: 24791.53
[INFO 2017-07-02 01:49:30,459 main.py:52] epoch 161, training loss: 13709.32, average training loss: 15493.97, base loss: 24789.19
[INFO 2017-07-02 01:49:35,254 main.py:52] epoch 162, training loss: 12525.26, average training loss: 15475.76, base loss: 24779.02
[INFO 2017-07-02 01:49:39,940 main.py:52] epoch 163, training loss: 16641.45, average training loss: 15482.87, base loss: 24789.64
[INFO 2017-07-02 01:49:44,786 main.py:52] epoch 164, training loss: 13889.08, average training loss: 15473.21, base loss: 24789.65
[INFO 2017-07-02 01:49:49,570 main.py:52] epoch 165, training loss: 12196.51, average training loss: 15453.47, base loss: 24773.45
[INFO 2017-07-02 01:49:54,267 main.py:52] epoch 166, training loss: 12891.99, average training loss: 15438.13, base loss: 24760.53
[INFO 2017-07-02 01:49:58,910 main.py:52] epoch 167, training loss: 13694.00, average training loss: 15427.75, base loss: 24760.88
[INFO 2017-07-02 01:50:03,433 main.py:52] epoch 168, training loss: 14433.74, average training loss: 15421.87, base loss: 24767.39
[INFO 2017-07-02 01:50:07,910 main.py:52] epoch 169, training loss: 12649.11, average training loss: 15405.56, base loss: 24760.42
[INFO 2017-07-02 01:50:12,715 main.py:52] epoch 170, training loss: 13285.55, average training loss: 15393.16, base loss: 24764.73
[INFO 2017-07-02 01:50:17,478 main.py:52] epoch 171, training loss: 12663.19, average training loss: 15377.29, base loss: 24759.35
[INFO 2017-07-02 01:50:22,545 main.py:52] epoch 172, training loss: 14742.49, average training loss: 15373.62, base loss: 24771.11
[INFO 2017-07-02 01:50:27,266 main.py:52] epoch 173, training loss: 15486.68, average training loss: 15374.27, base loss: 24779.47
[INFO 2017-07-02 01:50:32,150 main.py:52] epoch 174, training loss: 14563.25, average training loss: 15369.63, base loss: 24782.90
[INFO 2017-07-02 01:50:36,863 main.py:52] epoch 175, training loss: 13633.26, average training loss: 15359.77, base loss: 24784.73
[INFO 2017-07-02 01:50:41,568 main.py:52] epoch 176, training loss: 13859.60, average training loss: 15351.29, base loss: 24780.58
[INFO 2017-07-02 01:50:46,238 main.py:52] epoch 177, training loss: 13038.54, average training loss: 15338.30, base loss: 24784.53
[INFO 2017-07-02 01:50:51,043 main.py:52] epoch 178, training loss: 13679.64, average training loss: 15329.03, base loss: 24789.50
[INFO 2017-07-02 01:50:55,808 main.py:52] epoch 179, training loss: 12900.05, average training loss: 15315.54, base loss: 24784.85
[INFO 2017-07-02 01:51:00,657 main.py:52] epoch 180, training loss: 13326.42, average training loss: 15304.55, base loss: 24784.31
[INFO 2017-07-02 01:51:05,446 main.py:52] epoch 181, training loss: 13837.82, average training loss: 15296.49, base loss: 24785.13
[INFO 2017-07-02 01:51:10,099 main.py:52] epoch 182, training loss: 13871.00, average training loss: 15288.70, base loss: 24788.05
[INFO 2017-07-02 01:51:14,988 main.py:52] epoch 183, training loss: 14477.83, average training loss: 15284.29, base loss: 24804.25
[INFO 2017-07-02 01:51:19,525 main.py:52] epoch 184, training loss: 13562.57, average training loss: 15274.99, base loss: 24800.17
[INFO 2017-07-02 01:51:24,280 main.py:52] epoch 185, training loss: 13923.18, average training loss: 15267.72, base loss: 24799.48
[INFO 2017-07-02 01:51:28,715 main.py:52] epoch 186, training loss: 11725.52, average training loss: 15248.78, base loss: 24787.84
[INFO 2017-07-02 01:51:33,426 main.py:52] epoch 187, training loss: 12426.47, average training loss: 15233.76, base loss: 24788.00
[INFO 2017-07-02 01:51:38,095 main.py:52] epoch 188, training loss: 15360.54, average training loss: 15234.44, base loss: 24798.52
[INFO 2017-07-02 01:51:42,874 main.py:52] epoch 189, training loss: 12957.93, average training loss: 15222.45, base loss: 24791.59
[INFO 2017-07-02 01:51:47,529 main.py:52] epoch 190, training loss: 13180.98, average training loss: 15211.77, base loss: 24784.51
[INFO 2017-07-02 01:51:52,291 main.py:52] epoch 191, training loss: 14549.28, average training loss: 15208.31, base loss: 24792.10
[INFO 2017-07-02 01:51:56,911 main.py:52] epoch 192, training loss: 14642.63, average training loss: 15205.38, base loss: 24797.20
[INFO 2017-07-02 01:52:01,542 main.py:52] epoch 193, training loss: 11888.30, average training loss: 15188.29, base loss: 24788.88
[INFO 2017-07-02 01:52:05,981 main.py:52] epoch 194, training loss: 12593.84, average training loss: 15174.98, base loss: 24779.63
[INFO 2017-07-02 01:52:10,647 main.py:52] epoch 195, training loss: 13558.29, average training loss: 15166.73, base loss: 24776.42
[INFO 2017-07-02 01:52:15,237 main.py:52] epoch 196, training loss: 13161.72, average training loss: 15156.55, base loss: 24773.47
[INFO 2017-07-02 01:52:19,724 main.py:52] epoch 197, training loss: 13138.04, average training loss: 15146.36, base loss: 24773.03
[INFO 2017-07-02 01:52:24,378 main.py:52] epoch 198, training loss: 13625.36, average training loss: 15138.72, base loss: 24772.89
[INFO 2017-07-02 01:52:28,840 main.py:52] epoch 199, training loss: 12739.83, average training loss: 15126.72, base loss: 24773.06
[INFO 2017-07-02 01:52:28,840 main.py:54] epoch 199, testing
[INFO 2017-07-02 01:52:28,840 main.py:61] model save to ./model/final.pth
[INFO 2017-07-02 01:52:33,633 main.py:52] epoch 200, training loss: 13544.14, average training loss: 15118.85, base loss: 24774.59
[INFO 2017-07-02 01:52:38,101 main.py:52] epoch 201, training loss: 14134.98, average training loss: 15113.98, base loss: 24777.23
[INFO 2017-07-02 01:52:42,843 main.py:52] epoch 202, training loss: 12499.39, average training loss: 15101.10, base loss: 24767.63
[INFO 2017-07-02 01:52:47,536 main.py:52] epoch 203, training loss: 11752.50, average training loss: 15084.68, base loss: 24763.72
[INFO 2017-07-02 01:52:52,492 main.py:52] epoch 204, training loss: 13206.92, average training loss: 15075.52, base loss: 24764.02
[INFO 2017-07-02 01:52:57,344 main.py:52] epoch 205, training loss: 12733.82, average training loss: 15064.16, base loss: 24756.21
[INFO 2017-07-02 01:53:01,903 main.py:52] epoch 206, training loss: 13568.53, average training loss: 15056.93, base loss: 24750.35
[INFO 2017-07-02 01:53:06,654 main.py:52] epoch 207, training loss: 13691.29, average training loss: 15050.37, base loss: 24750.95
[INFO 2017-07-02 01:53:11,427 main.py:52] epoch 208, training loss: 14638.27, average training loss: 15048.39, base loss: 24762.15
[INFO 2017-07-02 01:53:16,023 main.py:52] epoch 209, training loss: 13864.83, average training loss: 15042.76, base loss: 24765.67
[INFO 2017-07-02 01:53:20,922 main.py:52] epoch 210, training loss: 13898.45, average training loss: 15037.33, base loss: 24768.38
[INFO 2017-07-02 01:53:25,787 main.py:52] epoch 211, training loss: 14211.79, average training loss: 15033.44, base loss: 24766.90
[INFO 2017-07-02 01:53:30,377 main.py:52] epoch 212, training loss: 12750.27, average training loss: 15022.72, base loss: 24762.31
[INFO 2017-07-02 01:53:35,172 main.py:52] epoch 213, training loss: 12073.33, average training loss: 15008.94, base loss: 24753.74
[INFO 2017-07-02 01:53:40,131 main.py:52] epoch 214, training loss: 12954.41, average training loss: 14999.38, base loss: 24760.08
[INFO 2017-07-02 01:53:44,779 main.py:52] epoch 215, training loss: 13377.23, average training loss: 14991.87, base loss: 24764.07
[INFO 2017-07-02 01:53:49,743 main.py:52] epoch 216, training loss: 13226.55, average training loss: 14983.74, base loss: 24766.40
[INFO 2017-07-02 01:53:54,640 main.py:52] epoch 217, training loss: 12785.68, average training loss: 14973.66, base loss: 24758.68
[INFO 2017-07-02 01:53:59,716 main.py:52] epoch 218, training loss: 15236.40, average training loss: 14974.85, base loss: 24766.18
[INFO 2017-07-02 01:54:04,577 main.py:52] epoch 219, training loss: 12786.80, average training loss: 14964.91, base loss: 24760.05
[INFO 2017-07-02 01:54:09,542 main.py:52] epoch 220, training loss: 13245.67, average training loss: 14957.13, base loss: 24764.00
[INFO 2017-07-02 01:54:14,497 main.py:52] epoch 221, training loss: 12057.33, average training loss: 14944.07, base loss: 24755.54
[INFO 2017-07-02 01:54:19,116 main.py:52] epoch 222, training loss: 13504.42, average training loss: 14937.61, base loss: 24756.15
[INFO 2017-07-02 01:54:24,026 main.py:52] epoch 223, training loss: 13043.63, average training loss: 14929.16, base loss: 24754.30
[INFO 2017-07-02 01:54:28,711 main.py:52] epoch 224, training loss: 12880.49, average training loss: 14920.05, base loss: 24752.69
[INFO 2017-07-02 01:54:33,193 main.py:52] epoch 225, training loss: 15374.95, average training loss: 14922.06, base loss: 24762.69
[INFO 2017-07-02 01:54:38,023 main.py:52] epoch 226, training loss: 14427.48, average training loss: 14919.89, base loss: 24767.87
[INFO 2017-07-02 01:54:42,787 main.py:52] epoch 227, training loss: 13228.67, average training loss: 14912.47, base loss: 24768.69
[INFO 2017-07-02 01:54:47,436 main.py:52] epoch 228, training loss: 13669.40, average training loss: 14907.04, base loss: 24764.42
[INFO 2017-07-02 01:54:52,447 main.py:52] epoch 229, training loss: 12825.71, average training loss: 14897.99, base loss: 24769.51
[INFO 2017-07-02 01:54:57,197 main.py:52] epoch 230, training loss: 14927.58, average training loss: 14898.12, base loss: 24777.94
[INFO 2017-07-02 01:55:01,768 main.py:52] epoch 231, training loss: 13420.93, average training loss: 14891.75, base loss: 24773.46
[INFO 2017-07-02 01:55:06,177 main.py:52] epoch 232, training loss: 12887.27, average training loss: 14883.15, base loss: 24774.02
[INFO 2017-07-02 01:55:10,838 main.py:52] epoch 233, training loss: 12780.07, average training loss: 14874.16, base loss: 24781.57
[INFO 2017-07-02 01:55:15,949 main.py:52] epoch 234, training loss: 12699.19, average training loss: 14864.91, base loss: 24780.95
[INFO 2017-07-02 01:55:20,770 main.py:52] epoch 235, training loss: 12528.63, average training loss: 14855.01, base loss: 24788.11
[INFO 2017-07-02 01:55:25,474 main.py:52] epoch 236, training loss: 13313.86, average training loss: 14848.50, base loss: 24789.29
[INFO 2017-07-02 01:55:30,584 main.py:52] epoch 237, training loss: 12595.78, average training loss: 14839.04, base loss: 24781.57
[INFO 2017-07-02 01:55:35,083 main.py:52] epoch 238, training loss: 14219.87, average training loss: 14836.45, base loss: 24787.18
[INFO 2017-07-02 01:55:39,908 main.py:52] epoch 239, training loss: 11167.32, average training loss: 14821.16, base loss: 24774.43
[INFO 2017-07-02 01:55:44,767 main.py:52] epoch 240, training loss: 13780.30, average training loss: 14816.84, base loss: 24777.72
[INFO 2017-07-02 01:55:49,287 main.py:52] epoch 241, training loss: 13016.11, average training loss: 14809.40, base loss: 24785.26
[INFO 2017-07-02 01:55:54,005 main.py:52] epoch 242, training loss: 13421.46, average training loss: 14803.69, base loss: 24791.40
[INFO 2017-07-02 01:55:58,666 main.py:52] epoch 243, training loss: 11525.75, average training loss: 14790.25, base loss: 24782.36
[INFO 2017-07-02 01:56:03,611 main.py:52] epoch 244, training loss: 12226.82, average training loss: 14779.79, base loss: 24783.91
[INFO 2017-07-02 01:56:08,647 main.py:52] epoch 245, training loss: 12816.92, average training loss: 14771.81, base loss: 24782.70
[INFO 2017-07-02 01:56:13,569 main.py:52] epoch 246, training loss: 13286.95, average training loss: 14765.80, base loss: 24786.46
[INFO 2017-07-02 01:56:18,318 main.py:52] epoch 247, training loss: 13469.38, average training loss: 14760.57, base loss: 24779.31
[INFO 2017-07-02 01:56:23,019 main.py:52] epoch 248, training loss: 13504.24, average training loss: 14755.53, base loss: 24781.81
[INFO 2017-07-02 01:56:27,803 main.py:52] epoch 249, training loss: 12854.91, average training loss: 14747.92, base loss: 24775.26
[INFO 2017-07-02 01:56:32,522 main.py:52] epoch 250, training loss: 12601.56, average training loss: 14739.37, base loss: 24767.18
[INFO 2017-07-02 01:56:37,358 main.py:52] epoch 251, training loss: 12759.12, average training loss: 14731.52, base loss: 24769.16
[INFO 2017-07-02 01:56:41,983 main.py:52] epoch 252, training loss: 14789.81, average training loss: 14731.75, base loss: 24777.40
[INFO 2017-07-02 01:56:46,701 main.py:52] epoch 253, training loss: 12558.59, average training loss: 14723.19, base loss: 24773.06
[INFO 2017-07-02 01:56:51,603 main.py:52] epoch 254, training loss: 12765.02, average training loss: 14715.51, base loss: 24769.92
[INFO 2017-07-02 01:56:56,453 main.py:52] epoch 255, training loss: 12620.93, average training loss: 14707.33, base loss: 24763.70
[INFO 2017-07-02 01:57:01,444 main.py:52] epoch 256, training loss: 13437.82, average training loss: 14702.39, base loss: 24764.43
[INFO 2017-07-02 01:57:06,209 main.py:52] epoch 257, training loss: 12559.90, average training loss: 14694.08, base loss: 24765.55
[INFO 2017-07-02 01:57:11,018 main.py:52] epoch 258, training loss: 14136.88, average training loss: 14691.93, base loss: 24774.35
[INFO 2017-07-02 01:57:15,761 main.py:52] epoch 259, training loss: 13548.36, average training loss: 14687.54, base loss: 24775.17
[INFO 2017-07-02 01:57:20,561 main.py:52] epoch 260, training loss: 12624.69, average training loss: 14679.63, base loss: 24773.75
[INFO 2017-07-02 01:57:25,191 main.py:52] epoch 261, training loss: 11556.54, average training loss: 14667.71, base loss: 24768.78
[INFO 2017-07-02 01:57:29,756 main.py:52] epoch 262, training loss: 12994.97, average training loss: 14661.35, base loss: 24766.01
[INFO 2017-07-02 01:57:34,730 main.py:52] epoch 263, training loss: 13252.25, average training loss: 14656.01, base loss: 24771.34
[INFO 2017-07-02 01:57:39,565 main.py:52] epoch 264, training loss: 13829.70, average training loss: 14652.90, base loss: 24770.50
[INFO 2017-07-02 01:57:44,483 main.py:52] epoch 265, training loss: 13796.17, average training loss: 14649.67, base loss: 24772.21
[INFO 2017-07-02 01:57:49,250 main.py:52] epoch 266, training loss: 12380.79, average training loss: 14641.18, base loss: 24767.48
[INFO 2017-07-02 01:57:53,843 main.py:52] epoch 267, training loss: 13733.97, average training loss: 14637.79, base loss: 24771.81
[INFO 2017-07-02 01:57:58,748 main.py:52] epoch 268, training loss: 13156.68, average training loss: 14632.29, base loss: 24774.61
[INFO 2017-07-02 01:58:03,382 main.py:52] epoch 269, training loss: 13258.05, average training loss: 14627.20, base loss: 24776.60
[INFO 2017-07-02 01:58:08,167 main.py:52] epoch 270, training loss: 15129.06, average training loss: 14629.05, base loss: 24784.53
[INFO 2017-07-02 01:58:12,904 main.py:52] epoch 271, training loss: 12210.18, average training loss: 14620.16, base loss: 24780.62
[INFO 2017-07-02 01:58:17,736 main.py:52] epoch 272, training loss: 10777.58, average training loss: 14606.08, base loss: 24769.63
[INFO 2017-07-02 01:58:22,493 main.py:52] epoch 273, training loss: 13590.86, average training loss: 14602.37, base loss: 24776.43
[INFO 2017-07-02 01:58:27,171 main.py:52] epoch 274, training loss: 14073.32, average training loss: 14600.45, base loss: 24779.91
[INFO 2017-07-02 01:58:31,972 main.py:52] epoch 275, training loss: 12231.96, average training loss: 14591.87, base loss: 24776.34
[INFO 2017-07-02 01:58:36,640 main.py:52] epoch 276, training loss: 13570.42, average training loss: 14588.18, base loss: 24775.55
[INFO 2017-07-02 01:58:41,488 main.py:52] epoch 277, training loss: 11514.87, average training loss: 14577.13, base loss: 24769.66
[INFO 2017-07-02 01:58:46,196 main.py:52] epoch 278, training loss: 13677.66, average training loss: 14573.90, base loss: 24767.68
[INFO 2017-07-02 01:58:51,021 main.py:52] epoch 279, training loss: 13926.22, average training loss: 14571.59, base loss: 24773.16
[INFO 2017-07-02 01:58:55,840 main.py:52] epoch 280, training loss: 13343.05, average training loss: 14567.22, base loss: 24773.20
[INFO 2017-07-02 01:59:00,566 main.py:52] epoch 281, training loss: 12703.20, average training loss: 14560.61, base loss: 24776.81
[INFO 2017-07-02 01:59:05,127 main.py:52] epoch 282, training loss: 12741.78, average training loss: 14554.18, base loss: 24776.90
[INFO 2017-07-02 01:59:09,993 main.py:52] epoch 283, training loss: 12267.89, average training loss: 14546.13, base loss: 24778.00
[INFO 2017-07-02 01:59:14,641 main.py:52] epoch 284, training loss: 13474.88, average training loss: 14542.37, base loss: 24778.62
[INFO 2017-07-02 01:59:19,196 main.py:52] epoch 285, training loss: 13014.64, average training loss: 14537.03, base loss: 24779.95
[INFO 2017-07-02 01:59:24,049 main.py:52] epoch 286, training loss: 12796.74, average training loss: 14530.97, base loss: 24780.01
[INFO 2017-07-02 01:59:28,682 main.py:52] epoch 287, training loss: 11669.34, average training loss: 14521.03, base loss: 24774.66
[INFO 2017-07-02 01:59:33,482 main.py:52] epoch 288, training loss: 12175.92, average training loss: 14512.92, base loss: 24766.80
[INFO 2017-07-02 01:59:38,281 main.py:52] epoch 289, training loss: 14258.80, average training loss: 14512.04, base loss: 24765.91
[INFO 2017-07-02 01:59:42,995 main.py:52] epoch 290, training loss: 13250.41, average training loss: 14507.70, base loss: 24761.55
[INFO 2017-07-02 01:59:47,620 main.py:52] epoch 291, training loss: 14460.70, average training loss: 14507.54, base loss: 24766.47
[INFO 2017-07-02 01:59:52,241 main.py:52] epoch 292, training loss: 12707.83, average training loss: 14501.40, base loss: 24759.52
[INFO 2017-07-02 01:59:57,089 main.py:52] epoch 293, training loss: 11883.52, average training loss: 14492.50, base loss: 24754.88
[INFO 2017-07-02 02:00:01,837 main.py:52] epoch 294, training loss: 13212.09, average training loss: 14488.16, base loss: 24756.05
[INFO 2017-07-02 02:00:06,369 main.py:52] epoch 295, training loss: 13472.37, average training loss: 14484.72, base loss: 24758.59
[INFO 2017-07-02 02:00:11,067 main.py:52] epoch 296, training loss: 14000.55, average training loss: 14483.09, base loss: 24757.36
[INFO 2017-07-02 02:00:15,630 main.py:52] epoch 297, training loss: 11644.60, average training loss: 14473.57, base loss: 24758.10
[INFO 2017-07-02 02:00:20,413 main.py:52] epoch 298, training loss: 14633.49, average training loss: 14474.10, base loss: 24763.35
[INFO 2017-07-02 02:00:25,154 main.py:52] epoch 299, training loss: 13570.15, average training loss: 14471.09, base loss: 24765.90
[INFO 2017-07-02 02:00:25,154 main.py:54] epoch 299, testing
[INFO 2017-07-02 02:00:25,155 main.py:61] model save to ./model/final.pth
[INFO 2017-07-02 02:00:29,868 main.py:52] epoch 300, training loss: 12731.57, average training loss: 14465.31, base loss: 24766.08
[INFO 2017-07-02 02:00:34,879 main.py:52] epoch 301, training loss: 12109.45, average training loss: 14457.51, base loss: 24762.53
[INFO 2017-07-02 02:00:39,676 main.py:52] epoch 302, training loss: 13389.22, average training loss: 14453.98, base loss: 24765.26
[INFO 2017-07-02 02:00:44,632 main.py:52] epoch 303, training loss: 14692.60, average training loss: 14454.77, base loss: 24779.02
[INFO 2017-07-02 02:00:49,432 main.py:52] epoch 304, training loss: 12503.02, average training loss: 14448.37, base loss: 24777.23
[INFO 2017-07-02 02:00:54,039 main.py:52] epoch 305, training loss: 12734.73, average training loss: 14442.77, base loss: 24779.65
[INFO 2017-07-02 02:00:58,894 main.py:52] epoch 306, training loss: 12739.68, average training loss: 14437.22, base loss: 24777.80
[INFO 2017-07-02 02:01:03,716 main.py:52] epoch 307, training loss: 11641.67, average training loss: 14428.15, base loss: 24774.76
[INFO 2017-07-02 02:01:08,315 main.py:52] epoch 308, training loss: 11496.68, average training loss: 14418.66, base loss: 24767.02
[INFO 2017-07-02 02:01:13,032 main.py:52] epoch 309, training loss: 12428.03, average training loss: 14412.24, base loss: 24764.19
[INFO 2017-07-02 02:01:17,839 main.py:52] epoch 310, training loss: 11154.20, average training loss: 14401.76, base loss: 24759.42
[INFO 2017-07-02 02:01:22,713 main.py:52] epoch 311, training loss: 14063.11, average training loss: 14400.68, base loss: 24764.41
[INFO 2017-07-02 02:01:27,422 main.py:52] epoch 312, training loss: 13598.94, average training loss: 14398.11, base loss: 24766.90
[INFO 2017-07-02 02:01:31,907 main.py:52] epoch 313, training loss: 13206.59, average training loss: 14394.32, base loss: 24767.71
[INFO 2017-07-02 02:01:36,627 main.py:52] epoch 314, training loss: 12927.55, average training loss: 14389.66, base loss: 24772.21
[INFO 2017-07-02 02:01:41,572 main.py:52] epoch 315, training loss: 11585.87, average training loss: 14380.79, base loss: 24768.81
[INFO 2017-07-02 02:01:46,577 main.py:52] epoch 316, training loss: 13733.27, average training loss: 14378.75, base loss: 24767.47
[INFO 2017-07-02 02:01:51,051 main.py:52] epoch 317, training loss: 12404.64, average training loss: 14372.54, base loss: 24765.24
