[INFO 2017-06-28 14:15:18,370 main.py:176] Namespace(batch_size=32, display=False, flow_dir='flow', flow_video_dir='flow-video', flow_video_fps=1, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=2, num_channel=3, num_inputs=1, save_dir='./model', test=False, test_dir='/home/yi/Downloads/mpii-test-64', test_epoch=10, test_interval=100, test_video=False, train=True, train_dir='/home/yi/Downloads/mpii-64', train_epoch=100000)
[INFO 2017-06-28 14:15:22,235 main.py:51] epoch 0, training loss: 28678.23, average training loss: 28678.23, base loss: 14460.34
[INFO 2017-06-28 14:15:22,996 main.py:51] epoch 1, training loss: 28571.50, average training loss: 28624.87, base loss: 17042.88
[INFO 2017-06-28 14:15:23,793 main.py:51] epoch 2, training loss: 23166.20, average training loss: 26805.31, base loss: 16739.68
[INFO 2017-06-28 14:15:24,401 main.py:51] epoch 3, training loss: 18292.51, average training loss: 24677.11, base loss: 15483.92
[INFO 2017-06-28 14:15:25,208 main.py:51] epoch 4, training loss: 18234.10, average training loss: 23388.51, base loss: 14867.22
[INFO 2017-06-28 14:15:26,035 main.py:51] epoch 5, training loss: 22265.17, average training loss: 23201.28, base loss: 15303.70
[INFO 2017-06-28 14:15:26,687 main.py:51] epoch 6, training loss: 22776.27, average training loss: 23140.57, base loss: 16043.20
[INFO 2017-06-28 14:15:27,422 main.py:51] epoch 7, training loss: 17800.68, average training loss: 22473.08, base loss: 15921.77
[INFO 2017-06-28 14:15:28,237 main.py:51] epoch 8, training loss: 23054.07, average training loss: 22537.64, base loss: 16535.39
[INFO 2017-06-28 14:15:28,915 main.py:51] epoch 9, training loss: 14679.49, average training loss: 21751.82, base loss: 16143.48
[INFO 2017-06-28 14:15:29,637 main.py:51] epoch 10, training loss: 15183.56, average training loss: 21154.71, base loss: 15935.84
[INFO 2017-06-28 14:15:30,424 main.py:51] epoch 11, training loss: 13684.02, average training loss: 20532.15, base loss: 15635.48
[INFO 2017-06-28 14:15:31,152 main.py:51] epoch 12, training loss: 13129.62, average training loss: 19962.72, base loss: 15363.37
[INFO 2017-06-28 14:15:31,835 main.py:51] epoch 13, training loss: 16159.66, average training loss: 19691.08, base loss: 15371.83
[INFO 2017-06-28 14:15:32,637 main.py:51] epoch 14, training loss: 15645.46, average training loss: 19421.37, base loss: 15348.77
[INFO 2017-06-28 14:15:33,353 main.py:51] epoch 15, training loss: 19800.21, average training loss: 19445.05, base loss: 15569.15
[INFO 2017-06-28 14:15:34,049 main.py:51] epoch 16, training loss: 16957.85, average training loss: 19298.74, base loss: 15634.09
[INFO 2017-06-28 14:15:34,857 main.py:51] epoch 17, training loss: 14519.36, average training loss: 19033.22, base loss: 15547.21
[INFO 2017-06-28 14:15:35,537 main.py:51] epoch 18, training loss: 12163.02, average training loss: 18671.63, base loss: 15328.64
[INFO 2017-06-28 14:15:36,220 main.py:51] epoch 19, training loss: 11738.38, average training loss: 18324.97, base loss: 15121.04
[INFO 2017-06-28 14:15:37,037 main.py:51] epoch 20, training loss: 15387.24, average training loss: 18185.08, base loss: 15122.20
[INFO 2017-06-28 14:15:37,731 main.py:51] epoch 21, training loss: 15838.06, average training loss: 18078.39, base loss: 15140.62
[INFO 2017-06-28 14:15:38,431 main.py:51] epoch 22, training loss: 12990.91, average training loss: 17857.20, base loss: 15035.82
[INFO 2017-06-28 14:15:39,238 main.py:51] epoch 23, training loss: 16326.11, average training loss: 17793.40, base loss: 15091.92
[INFO 2017-06-28 14:15:39,906 main.py:51] epoch 24, training loss: 17807.19, average training loss: 17793.95, base loss: 15201.18
[INFO 2017-06-28 14:15:40,608 main.py:51] epoch 25, training loss: 15896.55, average training loss: 17720.98, base loss: 15230.92
[INFO 2017-06-28 14:15:41,420 main.py:51] epoch 26, training loss: 12461.35, average training loss: 17526.18, base loss: 15133.20
[INFO 2017-06-28 14:15:42,060 main.py:51] epoch 27, training loss: 14698.22, average training loss: 17425.18, base loss: 15112.74
[INFO 2017-06-28 14:15:42,773 main.py:51] epoch 28, training loss: 12848.85, average training loss: 17267.37, base loss: 15033.78
[INFO 2017-06-28 14:15:43,549 main.py:51] epoch 29, training loss: 17093.70, average training loss: 17261.58, base loss: 15114.90
[INFO 2017-06-28 14:15:44,132 main.py:51] epoch 30, training loss: 18118.69, average training loss: 17289.23, base loss: 15218.16
[INFO 2017-06-28 14:15:44,850 main.py:51] epoch 31, training loss: 14325.12, average training loss: 17196.60, base loss: 15198.47
[INFO 2017-06-28 14:15:45,640 main.py:51] epoch 32, training loss: 15129.81, average training loss: 17133.97, base loss: 15205.01
[INFO 2017-06-28 14:15:46,287 main.py:51] epoch 33, training loss: 14052.91, average training loss: 17043.36, base loss: 15171.88
[INFO 2017-06-28 14:15:47,044 main.py:51] epoch 34, training loss: 15805.62, average training loss: 17007.99, base loss: 15198.40
[INFO 2017-06-28 14:15:47,843 main.py:51] epoch 35, training loss: 17054.41, average training loss: 17009.28, base loss: 15259.47
[INFO 2017-06-28 14:15:48,479 main.py:51] epoch 36, training loss: 14214.92, average training loss: 16933.76, base loss: 15230.33
[INFO 2017-06-28 14:15:49,225 main.py:51] epoch 37, training loss: 14429.36, average training loss: 16867.85, base loss: 15218.91
[INFO 2017-06-28 14:15:50,053 main.py:51] epoch 38, training loss: 14590.70, average training loss: 16809.46, base loss: 15211.11
[INFO 2017-06-28 14:15:50,725 main.py:51] epoch 39, training loss: 13012.44, average training loss: 16714.54, base loss: 15164.23
[INFO 2017-06-28 14:15:51,436 main.py:51] epoch 40, training loss: 16349.18, average training loss: 16705.63, base loss: 15202.97
[INFO 2017-06-28 14:15:52,243 main.py:51] epoch 41, training loss: 11742.56, average training loss: 16587.46, base loss: 15125.55
[INFO 2017-06-28 14:15:52,893 main.py:51] epoch 42, training loss: 15143.60, average training loss: 16553.88, base loss: 15132.18
[INFO 2017-06-28 14:15:53,636 main.py:51] epoch 43, training loss: 14535.94, average training loss: 16508.02, base loss: 15131.79
[INFO 2017-06-28 14:15:54,443 main.py:51] epoch 44, training loss: 15315.96, average training loss: 16481.53, base loss: 15140.41
[INFO 2017-06-28 14:15:55,123 main.py:51] epoch 45, training loss: 15088.18, average training loss: 16451.24, base loss: 15149.14
[INFO 2017-06-28 14:15:55,835 main.py:51] epoch 46, training loss: 14857.96, average training loss: 16417.34, base loss: 15151.91
[INFO 2017-06-28 14:15:56,641 main.py:51] epoch 47, training loss: 14590.82, average training loss: 16379.29, base loss: 15147.63
[INFO 2017-06-28 14:15:57,270 main.py:51] epoch 48, training loss: 14914.68, average training loss: 16349.40, base loss: 15146.58
[INFO 2017-06-28 14:15:57,973 main.py:51] epoch 49, training loss: 12621.93, average training loss: 16274.85, base loss: 15102.47
[INFO 2017-06-28 14:15:58,756 main.py:51] epoch 50, training loss: 11723.26, average training loss: 16185.60, base loss: 15041.18
[INFO 2017-06-28 14:15:59,388 main.py:51] epoch 51, training loss: 13991.66, average training loss: 16143.41, base loss: 15028.14
[INFO 2017-06-28 14:16:00,144 main.py:51] epoch 52, training loss: 13560.39, average training loss: 16094.67, base loss: 15006.17
[INFO 2017-06-28 14:16:00,954 main.py:51] epoch 53, training loss: 11678.42, average training loss: 16012.89, base loss: 14947.95
[INFO 2017-06-28 14:16:01,621 main.py:51] epoch 54, training loss: 16444.57, average training loss: 16020.74, base loss: 14982.32
[INFO 2017-06-28 14:16:02,351 main.py:51] epoch 55, training loss: 13273.94, average training loss: 15971.69, base loss: 14956.43
[INFO 2017-06-28 14:16:03,160 main.py:51] epoch 56, training loss: 13845.90, average training loss: 15934.39, base loss: 14941.05
[INFO 2017-06-28 14:16:03,881 main.py:51] epoch 57, training loss: 14266.26, average training loss: 15905.63, base loss: 14934.34
[INFO 2017-06-28 14:16:04,556 main.py:51] epoch 58, training loss: 11186.19, average training loss: 15825.64, base loss: 14873.44
[INFO 2017-06-28 14:16:05,368 main.py:51] epoch 59, training loss: 11562.92, average training loss: 15754.60, base loss: 14823.95
[INFO 2017-06-28 14:16:06,048 main.py:51] epoch 60, training loss: 14803.84, average training loss: 15739.01, base loss: 14828.62
[INFO 2017-06-28 14:16:06,757 main.py:51] epoch 61, training loss: 12784.60, average training loss: 15691.36, base loss: 14800.61
[INFO 2017-06-28 14:16:07,567 main.py:51] epoch 62, training loss: 12774.59, average training loss: 15645.06, base loss: 14771.08
[INFO 2017-06-28 14:16:08,187 main.py:51] epoch 63, training loss: 11698.79, average training loss: 15583.40, base loss: 14725.33
[INFO 2017-06-28 14:16:08,946 main.py:51] epoch 64, training loss: 13714.08, average training loss: 15554.64, base loss: 14714.08
[INFO 2017-06-28 14:16:09,760 main.py:51] epoch 65, training loss: 13692.49, average training loss: 15526.43, base loss: 14702.30
[INFO 2017-06-28 14:16:10,458 main.py:51] epoch 66, training loss: 13243.97, average training loss: 15492.36, base loss: 14684.50
[INFO 2017-06-28 14:16:11,159 main.py:51] epoch 67, training loss: 14419.13, average training loss: 15476.58, base loss: 14686.79
[INFO 2017-06-28 14:16:11,971 main.py:51] epoch 68, training loss: 13497.25, average training loss: 15447.89, base loss: 14672.92
[INFO 2017-06-28 14:16:12,594 main.py:51] epoch 69, training loss: 16372.86, average training loss: 15461.11, base loss: 14704.06
[INFO 2017-06-28 14:16:13,356 main.py:51] epoch 70, training loss: 15935.13, average training loss: 15467.78, base loss: 14725.93
[INFO 2017-06-28 14:16:14,170 main.py:51] epoch 71, training loss: 12432.60, average training loss: 15425.63, base loss: 14697.99
[INFO 2017-06-28 14:16:14,897 main.py:51] epoch 72, training loss: 13541.04, average training loss: 15399.81, base loss: 14686.58
[INFO 2017-06-28 14:16:15,577 main.py:51] epoch 73, training loss: 12658.30, average training loss: 15362.76, base loss: 14662.23
[INFO 2017-06-28 14:16:16,396 main.py:51] epoch 74, training loss: 12466.88, average training loss: 15324.15, base loss: 14635.15
[INFO 2017-06-28 14:16:17,098 main.py:51] epoch 75, training loss: 15419.16, average training loss: 15325.40, base loss: 14651.15
[INFO 2017-06-28 14:16:17,812 main.py:51] epoch 76, training loss: 13036.13, average training loss: 15295.67, base loss: 14633.49
[INFO 2017-06-28 14:16:18,585 main.py:51] epoch 77, training loss: 15485.29, average training loss: 15298.10, base loss: 14650.37
[INFO 2017-06-28 14:16:19,377 main.py:51] epoch 78, training loss: 13987.92, average training loss: 15281.52, base loss: 14645.35
[INFO 2017-06-28 14:16:20,037 main.py:51] epoch 79, training loss: 15836.74, average training loss: 15288.46, base loss: 14665.03
[INFO 2017-06-28 14:16:20,802 main.py:51] epoch 80, training loss: 13127.91, average training loss: 15261.78, base loss: 14650.12
[INFO 2017-06-28 14:16:21,587 main.py:51] epoch 81, training loss: 14791.88, average training loss: 15256.05, base loss: 14654.50
[INFO 2017-06-28 14:16:22,212 main.py:51] epoch 82, training loss: 11662.79, average training loss: 15212.76, base loss: 14621.20
[INFO 2017-06-28 14:16:22,962 main.py:51] epoch 83, training loss: 13005.36, average training loss: 15186.48, base loss: 14603.98
[INFO 2017-06-28 14:16:23,719 main.py:51] epoch 84, training loss: 13253.83, average training loss: 15163.75, base loss: 14591.40
[INFO 2017-06-28 14:16:24,328 main.py:51] epoch 85, training loss: 13907.75, average training loss: 15149.14, base loss: 14588.09
[INFO 2017-06-28 14:16:25,086 main.py:51] epoch 86, training loss: 12964.77, average training loss: 15124.03, base loss: 14572.57
[INFO 2017-06-28 14:16:25,830 main.py:51] epoch 87, training loss: 11911.89, average training loss: 15087.53, base loss: 14544.69
[INFO 2017-06-28 14:16:26,479 main.py:51] epoch 88, training loss: 16101.51, average training loss: 15098.93, base loss: 14567.94
[INFO 2017-06-28 14:16:27,298 main.py:51] epoch 89, training loss: 12648.72, average training loss: 15071.70, base loss: 14550.08
[INFO 2017-06-28 14:16:28,035 main.py:51] epoch 90, training loss: 15851.77, average training loss: 15080.27, base loss: 14567.83
[INFO 2017-06-28 14:16:28,725 main.py:51] epoch 91, training loss: 16299.08, average training loss: 15093.52, base loss: 14589.90
[INFO 2017-06-28 14:16:29,527 main.py:51] epoch 92, training loss: 15079.44, average training loss: 15093.37, base loss: 14599.50
[INFO 2017-06-28 14:16:30,263 main.py:51] epoch 93, training loss: 15944.30, average training loss: 15102.42, base loss: 14618.50
[INFO 2017-06-28 14:16:30,976 main.py:51] epoch 94, training loss: 13806.43, average training loss: 15088.78, base loss: 14613.26
[INFO 2017-06-28 14:16:31,757 main.py:51] epoch 95, training loss: 17557.08, average training loss: 15114.49, base loss: 14649.20
[INFO 2017-06-28 14:16:32,534 main.py:51] epoch 96, training loss: 13547.11, average training loss: 15098.33, base loss: 14640.96
[INFO 2017-06-28 14:16:33,167 main.py:51] epoch 97, training loss: 14954.57, average training loss: 15096.87, base loss: 14647.07
[INFO 2017-06-28 14:16:33,927 main.py:51] epoch 98, training loss: 13529.44, average training loss: 15081.03, base loss: 14639.36
[INFO 2017-06-28 14:16:34,714 main.py:51] epoch 99, training loss: 13819.25, average training loss: 15068.42, base loss: 14634.53
[INFO 2017-06-28 14:16:34,714 main.py:53] epoch 99, testing
[INFO 2017-06-28 14:16:37,186 main.py:105] average testing loss: 15679.30, base loss: 15981.56
[INFO 2017-06-28 14:16:37,187 main.py:106] improve_loss: 302.26, improve_percent: 0.02
[INFO 2017-06-28 14:16:37,187 main.py:72] model save to ./model/final.pth
[INFO 2017-06-28 14:16:37,200 main.py:76] current best improved percent: 0.02
[INFO 2017-06-28 14:16:37,926 main.py:51] epoch 100, training loss: 15965.76, average training loss: 15077.30, base loss: 14652.85
[INFO 2017-06-28 14:16:38,696 main.py:51] epoch 101, training loss: 13607.01, average training loss: 15062.89, base loss: 14647.04
[INFO 2017-06-28 14:16:39,330 main.py:51] epoch 102, training loss: 14608.82, average training loss: 15058.48, base loss: 14650.46
[INFO 2017-06-28 14:16:40,101 main.py:51] epoch 103, training loss: 14143.18, average training loss: 15049.68, base loss: 14648.24
[INFO 2017-06-28 14:16:40,850 main.py:51] epoch 104, training loss: 14833.99, average training loss: 15047.62, base loss: 14654.99
[INFO 2017-06-28 14:16:41,526 main.py:51] epoch 105, training loss: 15792.21, average training loss: 15054.65, base loss: 14670.14
[INFO 2017-06-28 14:16:42,322 main.py:51] epoch 106, training loss: 18801.60, average training loss: 15089.66, base loss: 14711.89
[INFO 2017-06-28 14:16:43,039 main.py:51] epoch 107, training loss: 14008.14, average training loss: 15079.65, base loss: 14708.57
[INFO 2017-06-28 14:16:43,749 main.py:51] epoch 108, training loss: 16922.28, average training loss: 15096.56, base loss: 14732.34
[INFO 2017-06-28 14:16:44,543 main.py:51] epoch 109, training loss: 15929.64, average training loss: 15104.13, base loss: 14747.15
[INFO 2017-06-28 14:16:45,298 main.py:51] epoch 110, training loss: 14244.58, average training loss: 15096.39, base loss: 14746.80
[INFO 2017-06-28 14:16:45,967 main.py:51] epoch 111, training loss: 16858.60, average training loss: 15112.12, base loss: 14769.85
[INFO 2017-06-28 14:16:46,769 main.py:51] epoch 112, training loss: 14238.16, average training loss: 15104.39, base loss: 14769.58
[INFO 2017-06-28 14:16:47,479 main.py:51] epoch 113, training loss: 14401.54, average training loss: 15098.22, base loss: 14770.78
[INFO 2017-06-28 14:16:48,161 main.py:51] epoch 114, training loss: 12124.90, average training loss: 15072.36, base loss: 14749.48
[INFO 2017-06-28 14:16:48,731 main.py:51] epoch 115, training loss: 13390.32, average training loss: 15057.86, base loss: 14742.12
[INFO 2017-06-28 14:16:49,367 main.py:51] epoch 116, training loss: 16387.96, average training loss: 15069.23, base loss: 14760.75
[INFO 2017-06-28 14:16:50,029 main.py:51] epoch 117, training loss: 15606.35, average training loss: 15073.78, base loss: 14771.39
[INFO 2017-06-28 14:16:50,585 main.py:51] epoch 118, training loss: 16188.18, average training loss: 15083.15, base loss: 14789.64
[INFO 2017-06-28 14:16:51,254 main.py:51] epoch 119, training loss: 14571.45, average training loss: 15078.89, base loss: 14792.07
[INFO 2017-06-28 14:16:51,828 main.py:51] epoch 120, training loss: 14861.45, average training loss: 15077.09, base loss: 14795.28
[INFO 2017-06-28 14:16:52,616 main.py:51] epoch 121, training loss: 16186.44, average training loss: 15086.18, base loss: 14812.50
[INFO 2017-06-28 14:16:53,228 main.py:51] epoch 122, training loss: 15061.76, average training loss: 15085.98, base loss: 14819.82
[INFO 2017-06-28 14:16:53,984 main.py:51] epoch 123, training loss: 15156.03, average training loss: 15086.55, base loss: 14825.91
[INFO 2017-06-28 14:16:54,790 main.py:51] epoch 124, training loss: 15318.29, average training loss: 15088.40, base loss: 14831.27
[INFO 2017-06-28 14:16:55,365 main.py:51] epoch 125, training loss: 15451.49, average training loss: 15091.28, base loss: 14838.55
[INFO 2017-06-28 14:16:56,117 main.py:51] epoch 126, training loss: 14015.21, average training loss: 15082.81, base loss: 14834.34
[INFO 2017-06-28 14:16:56,917 main.py:51] epoch 127, training loss: 15035.40, average training loss: 15082.44, base loss: 14839.92
[INFO 2017-06-28 14:16:57,516 main.py:51] epoch 128, training loss: 15196.21, average training loss: 15083.32, base loss: 14845.08
[INFO 2017-06-28 14:16:58,252 main.py:51] epoch 129, training loss: 16215.09, average training loss: 15092.03, base loss: 14859.87
[INFO 2017-06-28 14:16:59,037 main.py:51] epoch 130, training loss: 15132.66, average training loss: 15092.34, base loss: 14865.93
[INFO 2017-06-28 14:16:59,630 main.py:51] epoch 131, training loss: 14494.91, average training loss: 15087.81, base loss: 14865.30
[INFO 2017-06-28 14:17:00,380 main.py:51] epoch 132, training loss: 16202.01, average training loss: 15096.19, base loss: 14877.86
[INFO 2017-06-28 14:17:01,136 main.py:51] epoch 133, training loss: 15233.13, average training loss: 15097.21, base loss: 14883.94
[INFO 2017-06-28 14:17:01,745 main.py:51] epoch 134, training loss: 16445.99, average training loss: 15107.20, base loss: 14898.08
[INFO 2017-06-28 14:17:02,473 main.py:51] epoch 135, training loss: 16229.31, average training loss: 15115.45, base loss: 14909.34
[INFO 2017-06-28 14:17:03,288 main.py:51] epoch 136, training loss: 12359.27, average training loss: 15095.33, base loss: 14892.51
[INFO 2017-06-28 14:17:03,878 main.py:51] epoch 137, training loss: 13251.02, average training loss: 15081.97, base loss: 14882.40
[INFO 2017-06-28 14:17:04,646 main.py:51] epoch 138, training loss: 13594.27, average training loss: 15071.27, base loss: 14876.62
[INFO 2017-06-28 14:17:05,435 main.py:51] epoch 139, training loss: 14932.58, average training loss: 15070.28, base loss: 14880.45
[INFO 2017-06-28 14:17:06,066 main.py:51] epoch 140, training loss: 13417.41, average training loss: 15058.55, base loss: 14872.42
[INFO 2017-06-28 14:17:06,856 main.py:51] epoch 141, training loss: 14313.27, average training loss: 15053.31, base loss: 14871.36
[INFO 2017-06-28 14:17:07,599 main.py:51] epoch 142, training loss: 15968.85, average training loss: 15059.71, base loss: 14882.52
[INFO 2017-06-28 14:17:08,261 main.py:51] epoch 143, training loss: 17235.63, average training loss: 15074.82, base loss: 14901.88
[INFO 2017-06-28 14:17:09,052 main.py:51] epoch 144, training loss: 15594.04, average training loss: 15078.40, base loss: 14909.40
[INFO 2017-06-28 14:17:09,766 main.py:51] epoch 145, training loss: 16787.04, average training loss: 15090.10, base loss: 14925.01
[INFO 2017-06-28 14:17:10,466 main.py:51] epoch 146, training loss: 16836.34, average training loss: 15101.98, base loss: 14941.05
[INFO 2017-06-28 14:17:11,260 main.py:51] epoch 147, training loss: 12629.01, average training loss: 15085.27, base loss: 14926.54
[INFO 2017-06-28 14:17:11,900 main.py:51] epoch 148, training loss: 13396.68, average training loss: 15073.94, base loss: 14918.41
[INFO 2017-06-28 14:17:12,654 main.py:51] epoch 149, training loss: 12632.50, average training loss: 15057.66, base loss: 14904.37
[INFO 2017-06-28 14:17:13,426 main.py:51] epoch 150, training loss: 14389.36, average training loss: 15053.24, base loss: 14903.47
[INFO 2017-06-28 14:17:14,048 main.py:51] epoch 151, training loss: 13891.20, average training loss: 15045.59, base loss: 14899.31
[INFO 2017-06-28 14:17:14,823 main.py:51] epoch 152, training loss: 13975.01, average training loss: 15038.60, base loss: 14896.38
[INFO 2017-06-28 14:17:15,588 main.py:51] epoch 153, training loss: 11250.70, average training loss: 15014.00, base loss: 14874.18
[INFO 2017-06-28 14:17:16,176 main.py:51] epoch 154, training loss: 14304.56, average training loss: 15009.42, base loss: 14873.60
[INFO 2017-06-28 14:17:16,924 main.py:51] epoch 155, training loss: 13573.26, average training loss: 15000.22, base loss: 14867.49
[INFO 2017-06-28 14:17:17,663 main.py:51] epoch 156, training loss: 13470.28, average training loss: 14990.47, base loss: 14860.80
[INFO 2017-06-28 14:17:18,283 main.py:51] epoch 157, training loss: 15034.58, average training loss: 14990.75, base loss: 14865.31
[INFO 2017-06-28 14:17:19,042 main.py:51] epoch 158, training loss: 13545.66, average training loss: 14981.66, base loss: 14859.15
[INFO 2017-06-28 14:17:19,804 main.py:51] epoch 159, training loss: 12240.96, average training loss: 14964.53, base loss: 14845.35
[INFO 2017-06-28 14:17:20,418 main.py:51] epoch 160, training loss: 16771.25, average training loss: 14975.75, base loss: 14860.82
[INFO 2017-06-28 14:17:21,174 main.py:51] epoch 161, training loss: 13331.03, average training loss: 14965.60, base loss: 14854.06
[INFO 2017-06-28 14:17:21,939 main.py:51] epoch 162, training loss: 14952.71, average training loss: 14965.52, base loss: 14857.95
[INFO 2017-06-28 14:17:22,546 main.py:51] epoch 163, training loss: 14188.35, average training loss: 14960.78, base loss: 14856.56
[INFO 2017-06-28 14:17:23,355 main.py:51] epoch 164, training loss: 14133.38, average training loss: 14955.77, base loss: 14854.40
[INFO 2017-06-28 14:17:24,155 main.py:51] epoch 165, training loss: 14816.73, average training loss: 14954.93, base loss: 14857.72
[INFO 2017-06-28 14:17:24,809 main.py:51] epoch 166, training loss: 13722.46, average training loss: 14947.55, base loss: 14853.62
[INFO 2017-06-28 14:17:25,557 main.py:51] epoch 167, training loss: 12610.52, average training loss: 14933.64, base loss: 14841.89
[INFO 2017-06-28 14:17:26,379 main.py:51] epoch 168, training loss: 12865.69, average training loss: 14921.40, base loss: 14832.12
[INFO 2017-06-28 14:17:27,027 main.py:51] epoch 169, training loss: 12973.44, average training loss: 14909.95, base loss: 14822.23
[INFO 2017-06-28 14:17:27,774 main.py:51] epoch 170, training loss: 14014.57, average training loss: 14904.71, base loss: 14819.95
[INFO 2017-06-28 14:17:28,559 main.py:51] epoch 171, training loss: 15346.70, average training loss: 14907.28, base loss: 14825.72
[INFO 2017-06-28 14:17:29,214 main.py:51] epoch 172, training loss: 13084.89, average training loss: 14896.74, base loss: 14816.25
[INFO 2017-06-28 14:17:29,944 main.py:51] epoch 173, training loss: 17701.13, average training loss: 14912.86, base loss: 14834.95
[INFO 2017-06-28 14:17:30,762 main.py:51] epoch 174, training loss: 13034.72, average training loss: 14902.13, base loss: 14826.14
[INFO 2017-06-28 14:17:31,476 main.py:51] epoch 175, training loss: 13783.00, average training loss: 14895.77, base loss: 14822.45
[INFO 2017-06-28 14:17:32,160 main.py:51] epoch 176, training loss: 15669.21, average training loss: 14900.14, base loss: 14829.30
[INFO 2017-06-28 14:17:32,966 main.py:51] epoch 177, training loss: 12452.80, average training loss: 14886.39, base loss: 14817.29
[INFO 2017-06-28 14:17:33,732 main.py:51] epoch 178, training loss: 15568.22, average training loss: 14890.20, base loss: 14823.42
[INFO 2017-06-28 14:17:34,358 main.py:51] epoch 179, training loss: 12922.93, average training loss: 14879.27, base loss: 14814.83
[INFO 2017-06-28 14:17:35,162 main.py:51] epoch 180, training loss: 17809.75, average training loss: 14895.46, base loss: 14833.42
[INFO 2017-06-28 14:17:35,886 main.py:51] epoch 181, training loss: 14565.50, average training loss: 14893.65, base loss: 14834.51
[INFO 2017-06-28 14:17:36,562 main.py:51] epoch 182, training loss: 13382.20, average training loss: 14885.39, base loss: 14828.54
[INFO 2017-06-28 14:17:37,379 main.py:51] epoch 183, training loss: 13537.81, average training loss: 14878.07, base loss: 14823.00
[INFO 2017-06-28 14:17:38,037 main.py:51] epoch 184, training loss: 15568.70, average training loss: 14881.80, base loss: 14829.15
[INFO 2017-06-28 14:17:38,754 main.py:51] epoch 185, training loss: 13622.72, average training loss: 14875.03, base loss: 14824.58
[INFO 2017-06-28 14:17:39,523 main.py:51] epoch 186, training loss: 16125.72, average training loss: 14881.72, base loss: 14834.33
[INFO 2017-06-28 14:17:40,144 main.py:51] epoch 187, training loss: 14782.73, average training loss: 14881.19, base loss: 14836.42
[INFO 2017-06-28 14:17:40,859 main.py:51] epoch 188, training loss: 12912.44, average training loss: 14870.77, base loss: 14827.85
[INFO 2017-06-28 14:17:41,621 main.py:51] epoch 189, training loss: 13595.27, average training loss: 14864.06, base loss: 14824.03
[INFO 2017-06-28 14:17:42,262 main.py:51] epoch 190, training loss: 16078.23, average training loss: 14870.42, base loss: 14833.59
[INFO 2017-06-28 14:17:43,021 main.py:51] epoch 191, training loss: 15441.78, average training loss: 14873.39, base loss: 14839.55
[INFO 2017-06-28 14:17:43,809 main.py:51] epoch 192, training loss: 13141.56, average training loss: 14864.42, base loss: 14833.23
[INFO 2017-06-28 14:17:44,454 main.py:51] epoch 193, training loss: 18825.44, average training loss: 14884.84, base loss: 14857.26
[INFO 2017-06-28 14:17:45,200 main.py:51] epoch 194, training loss: 15306.88, average training loss: 14887.00, base loss: 14861.59
[INFO 2017-06-28 14:17:46,001 main.py:51] epoch 195, training loss: 12977.86, average training loss: 14877.26, base loss: 14852.99
[INFO 2017-06-28 14:17:46,619 main.py:51] epoch 196, training loss: 13968.59, average training loss: 14872.65, base loss: 14851.03
[INFO 2017-06-28 14:17:47,390 main.py:51] epoch 197, training loss: 14669.39, average training loss: 14871.62, base loss: 14852.33
[INFO 2017-06-28 14:17:48,167 main.py:51] epoch 198, training loss: 17827.12, average training loss: 14886.47, base loss: 14869.88
[INFO 2017-06-28 14:17:48,784 main.py:51] epoch 199, training loss: 12310.52, average training loss: 14873.60, base loss: 14858.69
[INFO 2017-06-28 14:17:48,784 main.py:53] epoch 199, testing
[INFO 2017-06-28 14:17:51,332 main.py:105] average testing loss: 15937.40, base loss: 16320.20
[INFO 2017-06-28 14:17:51,333 main.py:106] improve_loss: 382.80, improve_percent: 0.02
[INFO 2017-06-28 14:17:51,333 main.py:72] model save to ./model/final.pth
[INFO 2017-06-28 14:17:51,348 main.py:76] current best improved percent: 0.02
[INFO 2017-06-28 14:17:52,141 main.py:51] epoch 200, training loss: 12071.67, average training loss: 14859.66, base loss: 14846.37
[INFO 2017-06-28 14:17:52,701 main.py:51] epoch 201, training loss: 14371.97, average training loss: 14857.24, base loss: 14846.37
[INFO 2017-06-28 14:17:53,477 main.py:51] epoch 202, training loss: 10741.65, average training loss: 14836.97, base loss: 14827.22
[INFO 2017-06-28 14:17:54,286 main.py:51] epoch 203, training loss: 16720.28, average training loss: 14846.20, base loss: 14839.69
[INFO 2017-06-28 14:17:54,913 main.py:51] epoch 204, training loss: 14367.69, average training loss: 14843.86, base loss: 14840.08
[INFO 2017-06-28 14:17:55,632 main.py:51] epoch 205, training loss: 11975.18, average training loss: 14829.94, base loss: 14827.32
[INFO 2017-06-28 14:17:56,405 main.py:51] epoch 206, training loss: 12980.47, average training loss: 14821.00, base loss: 14819.88
[INFO 2017-06-28 14:17:57,001 main.py:51] epoch 207, training loss: 16111.50, average training loss: 14827.21, base loss: 14829.21
[INFO 2017-06-28 14:17:57,777 main.py:51] epoch 208, training loss: 13914.58, average training loss: 14822.84, base loss: 14826.34
[INFO 2017-06-28 14:17:58,559 main.py:51] epoch 209, training loss: 17026.62, average training loss: 14833.34, base loss: 14839.28
[INFO 2017-06-28 14:17:59,141 main.py:51] epoch 210, training loss: 14882.46, average training loss: 14833.57, base loss: 14842.51
[INFO 2017-06-28 14:17:59,860 main.py:51] epoch 211, training loss: 13391.71, average training loss: 14826.77, base loss: 14838.00
[INFO 2017-06-28 14:18:00,669 main.py:51] epoch 212, training loss: 14662.21, average training loss: 14826.00, base loss: 14838.86
[INFO 2017-06-28 14:18:01,284 main.py:51] epoch 213, training loss: 11125.25, average training loss: 14808.70, base loss: 14822.10
[INFO 2017-06-28 14:18:02,031 main.py:51] epoch 214, training loss: 16147.08, average training loss: 14814.93, base loss: 14830.82
[INFO 2017-06-28 14:18:02,845 main.py:51] epoch 215, training loss: 16719.34, average training loss: 14823.74, base loss: 14842.52
[INFO 2017-06-28 14:18:03,435 main.py:51] epoch 216, training loss: 15391.58, average training loss: 14826.36, base loss: 14846.62
[INFO 2017-06-28 14:18:04,231 main.py:51] epoch 217, training loss: 13460.12, average training loss: 14820.09, base loss: 14842.36
[INFO 2017-06-28 14:18:04,906 main.py:51] epoch 218, training loss: 13739.16, average training loss: 14815.16, base loss: 14840.08
[INFO 2017-06-28 14:18:05,611 main.py:51] epoch 219, training loss: 13519.80, average training loss: 14809.27, base loss: 14835.21
[INFO 2017-06-28 14:18:06,379 main.py:51] epoch 220, training loss: 17202.44, average training loss: 14820.10, base loss: 14847.88
[INFO 2017-06-28 14:18:06,960 main.py:51] epoch 221, training loss: 11537.94, average training loss: 14805.31, base loss: 14834.52
[INFO 2017-06-28 14:18:07,706 main.py:51] epoch 222, training loss: 13991.02, average training loss: 14801.66, base loss: 14832.51
[INFO 2017-06-28 14:18:08,489 main.py:51] epoch 223, training loss: 11420.05, average training loss: 14786.57, base loss: 14818.23
[INFO 2017-06-28 14:18:09,145 main.py:51] epoch 224, training loss: 12281.95, average training loss: 14775.43, base loss: 14807.96
[INFO 2017-06-28 14:18:09,922 main.py:51] epoch 225, training loss: 15948.46, average training loss: 14780.62, base loss: 14815.15
[INFO 2017-06-28 14:18:10,721 main.py:51] epoch 226, training loss: 13388.46, average training loss: 14774.49, base loss: 14810.37
[INFO 2017-06-28 14:18:11,366 main.py:51] epoch 227, training loss: 12807.39, average training loss: 14765.86, base loss: 14803.31
[INFO 2017-06-28 14:18:12,116 main.py:51] epoch 228, training loss: 13249.12, average training loss: 14759.24, base loss: 14798.30
[INFO 2017-06-28 14:18:12,913 main.py:51] epoch 229, training loss: 15697.15, average training loss: 14763.32, base loss: 14804.12
[INFO 2017-06-28 14:18:13,571 main.py:51] epoch 230, training loss: 12112.59, average training loss: 14751.84, base loss: 14793.69
[INFO 2017-06-28 14:18:14,315 main.py:51] epoch 231, training loss: 12899.97, average training loss: 14743.86, base loss: 14786.78
[INFO 2017-06-28 14:18:15,135 main.py:51] epoch 232, training loss: 17018.31, average training loss: 14753.62, base loss: 14798.08
[INFO 2017-06-28 14:18:15,799 main.py:51] epoch 233, training loss: 15703.31, average training loss: 14757.68, base loss: 14803.38
[INFO 2017-06-28 14:18:16,527 main.py:51] epoch 234, training loss: 17888.62, average training loss: 14771.00, base loss: 14818.96
[INFO 2017-06-28 14:18:17,323 main.py:51] epoch 235, training loss: 14345.62, average training loss: 14769.20, base loss: 14818.60
[INFO 2017-06-28 14:18:17,997 main.py:51] epoch 236, training loss: 14838.63, average training loss: 14769.50, base loss: 14820.58
[INFO 2017-06-28 14:18:18,701 main.py:51] epoch 237, training loss: 15386.09, average training loss: 14772.09, base loss: 14824.99
[INFO 2017-06-28 14:18:19,472 main.py:51] epoch 238, training loss: 12067.22, average training loss: 14760.77, base loss: 14814.85
[INFO 2017-06-28 14:18:20,090 main.py:51] epoch 239, training loss: 12569.79, average training loss: 14751.64, base loss: 14806.61
[INFO 2017-06-28 14:18:20,863 main.py:51] epoch 240, training loss: 14075.54, average training loss: 14748.83, base loss: 14806.11
[INFO 2017-06-28 14:18:21,675 main.py:51] epoch 241, training loss: 14912.36, average training loss: 14749.51, base loss: 14808.49
[INFO 2017-06-28 14:18:22,406 main.py:51] epoch 242, training loss: 13565.54, average training loss: 14744.64, base loss: 14804.44
[INFO 2017-06-28 14:18:23,071 main.py:51] epoch 243, training loss: 17377.14, average training loss: 14755.43, base loss: 14816.69
[INFO 2017-06-28 14:18:23,865 main.py:51] epoch 244, training loss: 12995.27, average training loss: 14748.24, base loss: 14810.20
[INFO 2017-06-28 14:18:24,614 main.py:51] epoch 245, training loss: 14673.31, average training loss: 14747.94, base loss: 14811.36
[INFO 2017-06-28 14:18:25,272 main.py:51] epoch 246, training loss: 14210.51, average training loss: 14745.76, base loss: 14810.61
[INFO 2017-06-28 14:18:26,067 main.py:51] epoch 247, training loss: 13252.29, average training loss: 14739.74, base loss: 14805.39
[INFO 2017-06-28 14:18:26,736 main.py:51] epoch 248, training loss: 15387.09, average training loss: 14742.34, base loss: 14809.97
[INFO 2017-06-28 14:18:27,463 main.py:51] epoch 249, training loss: 14261.98, average training loss: 14740.42, base loss: 14809.51
[INFO 2017-06-28 14:18:28,233 main.py:51] epoch 250, training loss: 15259.55, average training loss: 14742.49, base loss: 14813.59
[INFO 2017-06-28 14:18:28,876 main.py:51] epoch 251, training loss: 14042.77, average training loss: 14739.71, base loss: 14812.20
[INFO 2017-06-28 14:18:29,614 main.py:51] epoch 252, training loss: 15592.56, average training loss: 14743.08, base loss: 14817.14
[INFO 2017-06-28 14:18:30,385 main.py:51] epoch 253, training loss: 18614.55, average training loss: 14758.32, base loss: 14834.04
[INFO 2017-06-28 14:18:31,011 main.py:51] epoch 254, training loss: 11519.13, average training loss: 14745.62, base loss: 14822.05
[INFO 2017-06-28 14:18:31,762 main.py:51] epoch 255, training loss: 17669.09, average training loss: 14757.04, base loss: 14835.45
[INFO 2017-06-28 14:18:32,584 main.py:51] epoch 256, training loss: 14838.47, average training loss: 14757.36, base loss: 14837.54
[INFO 2017-06-28 14:18:33,216 main.py:51] epoch 257, training loss: 17747.54, average training loss: 14768.95, base loss: 14851.03
[INFO 2017-06-28 14:18:33,975 main.py:51] epoch 258, training loss: 14881.11, average training loss: 14769.38, base loss: 14852.34
[INFO 2017-06-28 14:18:34,755 main.py:51] epoch 259, training loss: 11989.59, average training loss: 14758.69, base loss: 14842.02
[INFO 2017-06-28 14:18:35,394 main.py:51] epoch 260, training loss: 12814.40, average training loss: 14751.24, base loss: 14835.56
[INFO 2017-06-28 14:18:36,147 main.py:51] epoch 261, training loss: 18403.58, average training loss: 14765.18, base loss: 14850.92
[INFO 2017-06-28 14:18:36,931 main.py:51] epoch 262, training loss: 15457.46, average training loss: 14767.81, base loss: 14855.51
[INFO 2017-06-28 14:18:37,568 main.py:51] epoch 263, training loss: 11227.26, average training loss: 14754.40, base loss: 14843.13
[INFO 2017-06-28 14:18:38,302 main.py:51] epoch 264, training loss: 14497.83, average training loss: 14753.43, base loss: 14843.28
[INFO 2017-06-28 14:18:39,126 main.py:51] epoch 265, training loss: 13654.42, average training loss: 14749.30, base loss: 14840.33
[INFO 2017-06-28 14:18:39,787 main.py:51] epoch 266, training loss: 14848.03, average training loss: 14749.67, base loss: 14842.24
[INFO 2017-06-28 14:18:40,514 main.py:51] epoch 267, training loss: 13624.15, average training loss: 14745.47, base loss: 14839.25
[INFO 2017-06-28 14:18:41,114 main.py:51] epoch 268, training loss: 13963.58, average training loss: 14742.56, base loss: 14837.42
[INFO 2017-06-28 14:18:41,728 main.py:51] epoch 269, training loss: 12740.30, average training loss: 14735.15, base loss: 14830.78
[INFO 2017-06-28 14:18:42,376 main.py:51] epoch 270, training loss: 14366.99, average training loss: 14733.79, base loss: 14830.74
[INFO 2017-06-28 14:18:42,950 main.py:51] epoch 271, training loss: 12981.64, average training loss: 14727.35, base loss: 14825.44
[INFO 2017-06-28 14:18:43,597 main.py:51] epoch 272, training loss: 15201.34, average training loss: 14729.08, base loss: 14828.86
[INFO 2017-06-28 14:18:44,194 main.py:51] epoch 273, training loss: 14024.11, average training loss: 14726.51, base loss: 14827.60
[INFO 2017-06-28 14:18:44,970 main.py:51] epoch 274, training loss: 16003.13, average training loss: 14731.15, base loss: 14833.75
[INFO 2017-06-28 14:18:45,582 main.py:51] epoch 275, training loss: 16738.45, average training loss: 14738.43, base loss: 14842.07
[INFO 2017-06-28 14:18:46,337 main.py:51] epoch 276, training loss: 13269.43, average training loss: 14733.12, base loss: 14837.79
[INFO 2017-06-28 14:18:47,123 main.py:51] epoch 277, training loss: 15732.05, average training loss: 14736.72, base loss: 14843.08
[INFO 2017-06-28 14:18:47,740 main.py:51] epoch 278, training loss: 13817.31, average training loss: 14733.42, base loss: 14841.17
[INFO 2017-06-28 14:18:48,452 main.py:51] epoch 279, training loss: 12625.07, average training loss: 14725.89, base loss: 14834.05
[INFO 2017-06-28 14:18:49,240 main.py:51] epoch 280, training loss: 16278.57, average training loss: 14731.42, base loss: 14840.86
[INFO 2017-06-28 14:18:49,852 main.py:51] epoch 281, training loss: 14884.43, average training loss: 14731.96, base loss: 14842.77
[INFO 2017-06-28 14:18:50,606 main.py:51] epoch 282, training loss: 17049.05, average training loss: 14740.15, base loss: 14852.83
[INFO 2017-06-28 14:18:51,412 main.py:51] epoch 283, training loss: 13924.45, average training loss: 14737.27, base loss: 14850.55
[INFO 2017-06-28 14:18:52,047 main.py:51] epoch 284, training loss: 13710.77, average training loss: 14733.67, base loss: 14848.15
[INFO 2017-06-28 14:18:52,788 main.py:51] epoch 285, training loss: 13352.51, average training loss: 14728.84, base loss: 14844.67
[INFO 2017-06-28 14:18:53,581 main.py:51] epoch 286, training loss: 13411.14, average training loss: 14724.25, base loss: 14841.21
[INFO 2017-06-28 14:18:54,191 main.py:51] epoch 287, training loss: 15144.06, average training loss: 14725.71, base loss: 14844.40
[INFO 2017-06-28 14:18:54,930 main.py:51] epoch 288, training loss: 13224.39, average training loss: 14720.51, base loss: 14840.11
[INFO 2017-06-28 14:18:55,721 main.py:51] epoch 289, training loss: 14411.49, average training loss: 14719.45, base loss: 14840.25
[INFO 2017-06-28 14:18:56,319 main.py:51] epoch 290, training loss: 12677.57, average training loss: 14712.43, base loss: 14834.04
[INFO 2017-06-28 14:18:57,053 main.py:51] epoch 291, training loss: 13681.55, average training loss: 14708.90, base loss: 14831.90
[INFO 2017-06-28 14:18:57,856 main.py:51] epoch 292, training loss: 13614.06, average training loss: 14705.17, base loss: 14829.00
[INFO 2017-06-28 14:18:58,457 main.py:51] epoch 293, training loss: 13978.68, average training loss: 14702.69, base loss: 14827.59
[INFO 2017-06-28 14:18:59,196 main.py:51] epoch 294, training loss: 13760.45, average training loss: 14699.50, base loss: 14825.71
[INFO 2017-06-28 14:19:00,003 main.py:51] epoch 295, training loss: 14873.75, average training loss: 14700.09, base loss: 14827.74
[INFO 2017-06-28 14:19:00,653 main.py:51] epoch 296, training loss: 13327.71, average training loss: 14695.47, base loss: 14824.17
[INFO 2017-06-28 14:19:01,425 main.py:51] epoch 297, training loss: 13813.37, average training loss: 14692.51, base loss: 14822.58
[INFO 2017-06-28 14:19:02,217 main.py:51] epoch 298, training loss: 15279.29, average training loss: 14694.47, base loss: 14825.59
[INFO 2017-06-28 14:19:02,892 main.py:51] epoch 299, training loss: 16058.90, average training loss: 14699.02, base loss: 14832.57
[INFO 2017-06-28 14:19:02,893 main.py:53] epoch 299, testing
[INFO 2017-06-28 14:19:05,437 main.py:105] average testing loss: 15091.06, base loss: 15485.17
[INFO 2017-06-28 14:19:05,437 main.py:106] improve_loss: 394.11, improve_percent: 0.03
[INFO 2017-06-28 14:19:05,438 main.py:72] model save to ./model/final.pth
[INFO 2017-06-28 14:19:05,453 main.py:76] current best improved percent: 0.03
[INFO 2017-06-28 14:19:06,247 main.py:51] epoch 300, training loss: 15635.77, average training loss: 14702.13, base loss: 14837.26
[INFO 2017-06-28 14:19:06,898 main.py:51] epoch 301, training loss: 14002.42, average training loss: 14699.81, base loss: 14835.83
