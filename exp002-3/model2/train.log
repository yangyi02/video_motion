[INFO 2017-06-26 13:21:30,821 main.py:170] Namespace(batch_size=32, display=False, image_dir='/home/yi/Downloads/mpii-64-one-2', image_size=64, init_model_path='', input_video_path='video', learning_rate=0.001, method='unsupervised', motion_range=3, num_channel=3, num_inputs=2, output_flow_path='flow', output_flow_video_path='flow_video', save_dir='./model', test=False, test_epoch=10, test_interval=100, test_video=False, train=True, train_epoch=10000)
[INFO 2017-06-26 13:21:33,088 main.py:50] epoch 0, training loss: 139307.22, average training loss: 139307.22, base loss: 10477.55
[INFO 2017-06-26 13:21:33,515 main.py:50] epoch 1, training loss: 111844.47, average training loss: 125575.84, base loss: 10791.49
[INFO 2017-06-26 13:21:33,935 main.py:50] epoch 2, training loss: 93252.37, average training loss: 114801.35, base loss: 10786.89
[INFO 2017-06-26 13:21:34,355 main.py:50] epoch 3, training loss: 81137.24, average training loss: 106385.32, base loss: 10584.46
[INFO 2017-06-26 13:21:34,779 main.py:50] epoch 4, training loss: 68457.12, average training loss: 98799.68, base loss: 10713.76
[INFO 2017-06-26 13:21:35,206 main.py:50] epoch 5, training loss: 59923.47, average training loss: 92320.31, base loss: 10756.13
[INFO 2017-06-26 13:21:35,628 main.py:50] epoch 6, training loss: 51000.48, average training loss: 86417.48, base loss: 10721.16
[INFO 2017-06-26 13:21:36,057 main.py:50] epoch 7, training loss: 43522.24, average training loss: 81055.58, base loss: 10709.05
[INFO 2017-06-26 13:21:36,481 main.py:50] epoch 8, training loss: 38019.27, average training loss: 76273.76, base loss: 10659.72
[INFO 2017-06-26 13:21:36,910 main.py:50] epoch 9, training loss: 33127.22, average training loss: 71959.11, base loss: 10631.42
[INFO 2017-06-26 13:21:37,333 main.py:50] epoch 10, training loss: 29378.17, average training loss: 68088.12, base loss: 10642.37
[INFO 2017-06-26 13:21:37,759 main.py:50] epoch 11, training loss: 26035.61, average training loss: 64583.74, base loss: 10609.35
[INFO 2017-06-26 13:21:38,178 main.py:50] epoch 12, training loss: 23367.60, average training loss: 61413.27, base loss: 10570.14
[INFO 2017-06-26 13:21:38,608 main.py:50] epoch 13, training loss: 21787.04, average training loss: 58582.82, base loss: 10569.94
[INFO 2017-06-26 13:21:39,033 main.py:50] epoch 14, training loss: 20018.68, average training loss: 56011.88, base loss: 10556.77
[INFO 2017-06-26 13:21:39,460 main.py:50] epoch 15, training loss: 18812.40, average training loss: 53686.91, base loss: 10568.88
[INFO 2017-06-26 13:21:39,884 main.py:50] epoch 16, training loss: 17447.58, average training loss: 51555.19, base loss: 10565.69
[INFO 2017-06-26 13:21:40,312 main.py:50] epoch 17, training loss: 16321.99, average training loss: 49597.79, base loss: 10560.99
[INFO 2017-06-26 13:21:40,737 main.py:50] epoch 18, training loss: 16028.65, average training loss: 47830.99, base loss: 10586.58
[INFO 2017-06-26 13:21:41,162 main.py:50] epoch 19, training loss: 15039.06, average training loss: 46191.39, base loss: 10590.05
[INFO 2017-06-26 13:21:41,591 main.py:50] epoch 20, training loss: 14219.39, average training loss: 44668.92, base loss: 10578.33
[INFO 2017-06-26 13:21:42,022 main.py:50] epoch 21, training loss: 13853.40, average training loss: 43268.21, base loss: 10581.61
[INFO 2017-06-26 13:21:42,462 main.py:50] epoch 22, training loss: 13223.83, average training loss: 41961.93, base loss: 10583.31
[INFO 2017-06-26 13:21:42,920 main.py:50] epoch 23, training loss: 12957.97, average training loss: 40753.44, base loss: 10591.81
[INFO 2017-06-26 13:21:43,403 main.py:50] epoch 24, training loss: 12109.51, average training loss: 39607.68, base loss: 10569.09
[INFO 2017-06-26 13:21:43,927 main.py:50] epoch 25, training loss: 11860.31, average training loss: 38540.47, base loss: 10552.67
[INFO 2017-06-26 13:21:44,476 main.py:50] epoch 26, training loss: 12082.52, average training loss: 37560.55, base loss: 10561.81
[INFO 2017-06-26 13:21:45,024 main.py:50] epoch 27, training loss: 11035.83, average training loss: 36613.24, base loss: 10540.99
[INFO 2017-06-26 13:21:45,575 main.py:50] epoch 28, training loss: 11674.80, average training loss: 35753.29, base loss: 10552.06
[INFO 2017-06-26 13:21:46,126 main.py:50] epoch 29, training loss: 11604.27, average training loss: 34948.32, base loss: 10565.11
[INFO 2017-06-26 13:21:46,676 main.py:50] epoch 30, training loss: 11493.17, average training loss: 34191.71, base loss: 10578.62
[INFO 2017-06-26 13:21:47,224 main.py:50] epoch 31, training loss: 10481.10, average training loss: 33450.75, base loss: 10560.21
[INFO 2017-06-26 13:21:47,775 main.py:50] epoch 32, training loss: 11308.12, average training loss: 32779.76, base loss: 10575.68
[INFO 2017-06-26 13:21:48,323 main.py:50] epoch 33, training loss: 10469.11, average training loss: 32123.57, base loss: 10566.26
[INFO 2017-06-26 13:21:48,871 main.py:50] epoch 34, training loss: 10981.09, average training loss: 31519.49, base loss: 10577.03
[INFO 2017-06-26 13:21:49,423 main.py:50] epoch 35, training loss: 10342.77, average training loss: 30931.25, base loss: 10570.13
[INFO 2017-06-26 13:21:49,971 main.py:50] epoch 36, training loss: 10111.08, average training loss: 30368.54, base loss: 10558.76
[INFO 2017-06-26 13:21:50,522 main.py:50] epoch 37, training loss: 10326.21, average training loss: 29841.11, base loss: 10556.91
[INFO 2017-06-26 13:21:51,071 main.py:50] epoch 38, training loss: 10726.96, average training loss: 29351.01, base loss: 10567.78
[INFO 2017-06-26 13:21:51,619 main.py:50] epoch 39, training loss: 9613.12, average training loss: 28857.56, base loss: 10548.20
[INFO 2017-06-26 13:21:52,169 main.py:50] epoch 40, training loss: 10147.27, average training loss: 28401.21, base loss: 10545.57
[INFO 2017-06-26 13:21:52,720 main.py:50] epoch 41, training loss: 10765.65, average training loss: 27981.32, base loss: 10561.22
[INFO 2017-06-26 13:21:53,270 main.py:50] epoch 42, training loss: 9994.95, average training loss: 27563.03, base loss: 10555.67
[INFO 2017-06-26 13:21:53,820 main.py:50] epoch 43, training loss: 10133.88, average training loss: 27166.91, base loss: 10555.09
[INFO 2017-06-26 13:21:54,370 main.py:50] epoch 44, training loss: 10336.64, average training loss: 26792.91, base loss: 10561.46
[INFO 2017-06-26 13:21:54,920 main.py:50] epoch 45, training loss: 10059.36, average training loss: 26429.13, base loss: 10561.19
[INFO 2017-06-26 13:21:55,470 main.py:50] epoch 46, training loss: 10391.33, average training loss: 26087.90, base loss: 10570.03
[INFO 2017-06-26 13:21:56,021 main.py:50] epoch 47, training loss: 10092.82, average training loss: 25754.67, base loss: 10571.83
[INFO 2017-06-26 13:21:56,569 main.py:50] epoch 48, training loss: 10030.37, average training loss: 25433.77, base loss: 10572.98
[INFO 2017-06-26 13:21:57,120 main.py:50] epoch 49, training loss: 10450.30, average training loss: 25134.10, base loss: 10583.84
[INFO 2017-06-26 13:21:57,670 main.py:50] epoch 50, training loss: 9939.96, average training loss: 24836.18, base loss: 10583.68
[INFO 2017-06-26 13:21:58,218 main.py:50] epoch 51, training loss: 9649.28, average training loss: 24544.12, base loss: 10577.45
[INFO 2017-06-26 13:21:58,767 main.py:50] epoch 52, training loss: 9996.33, average training loss: 24269.63, base loss: 10579.95
[INFO 2017-06-26 13:21:59,317 main.py:50] epoch 53, training loss: 10388.31, average training loss: 24012.57, base loss: 10591.52
[INFO 2017-06-26 13:21:59,866 main.py:50] epoch 54, training loss: 9450.19, average training loss: 23747.80, base loss: 10582.97
[INFO 2017-06-26 13:22:00,415 main.py:50] epoch 55, training loss: 9885.02, average training loss: 23500.25, base loss: 10584.51
[INFO 2017-06-26 13:22:00,966 main.py:50] epoch 56, training loss: 10165.19, average training loss: 23266.30, base loss: 10592.63
[INFO 2017-06-26 13:22:01,516 main.py:50] epoch 57, training loss: 10241.90, average training loss: 23041.74, base loss: 10602.34
[INFO 2017-06-26 13:22:02,067 main.py:50] epoch 58, training loss: 10076.28, average training loss: 22821.99, base loss: 10609.07
[INFO 2017-06-26 13:22:02,618 main.py:50] epoch 59, training loss: 9834.97, average training loss: 22605.54, base loss: 10610.85
[INFO 2017-06-26 13:22:03,167 main.py:50] epoch 60, training loss: 9514.56, average training loss: 22390.93, base loss: 10606.20
[INFO 2017-06-26 13:22:03,718 main.py:50] epoch 61, training loss: 9600.65, average training loss: 22184.64, base loss: 10604.29
[INFO 2017-06-26 13:22:04,268 main.py:50] epoch 62, training loss: 9617.45, average training loss: 21985.16, base loss: 10603.32
[INFO 2017-06-26 13:22:04,816 main.py:50] epoch 63, training loss: 9898.84, average training loss: 21796.31, base loss: 10607.89
[INFO 2017-06-26 13:22:05,365 main.py:50] epoch 64, training loss: 9678.70, average training loss: 21609.89, base loss: 10609.01
[INFO 2017-06-26 13:22:05,915 main.py:50] epoch 65, training loss: 9580.39, average training loss: 21427.62, base loss: 10608.38
[INFO 2017-06-26 13:22:06,464 main.py:50] epoch 66, training loss: 9394.76, average training loss: 21248.03, base loss: 10604.73
[INFO 2017-06-26 13:22:07,013 main.py:50] epoch 67, training loss: 9446.93, average training loss: 21074.48, base loss: 10602.48
[INFO 2017-06-26 13:22:07,562 main.py:50] epoch 68, training loss: 9628.57, average training loss: 20908.60, base loss: 10604.02
[INFO 2017-06-26 13:22:08,114 main.py:50] epoch 69, training loss: 9419.83, average training loss: 20744.47, base loss: 10602.16
[INFO 2017-06-26 13:22:08,663 main.py:50] epoch 70, training loss: 9582.44, average training loss: 20587.26, base loss: 10603.97
[INFO 2017-06-26 13:22:09,212 main.py:50] epoch 71, training loss: 9949.78, average training loss: 20439.52, base loss: 10611.91
[INFO 2017-06-26 13:22:09,761 main.py:50] epoch 72, training loss: 9695.03, average training loss: 20292.33, base loss: 10615.45
[INFO 2017-06-26 13:22:10,309 main.py:50] epoch 73, training loss: 9564.78, average training loss: 20147.37, base loss: 10617.30
[INFO 2017-06-26 13:22:10,857 main.py:50] epoch 74, training loss: 9434.89, average training loss: 20004.53, base loss: 10616.54
[INFO 2017-06-26 13:22:11,406 main.py:50] epoch 75, training loss: 9255.39, average training loss: 19863.10, base loss: 10613.05
[INFO 2017-06-26 13:22:11,956 main.py:50] epoch 76, training loss: 9482.21, average training loss: 19728.28, base loss: 10613.95
[INFO 2017-06-26 13:22:12,505 main.py:50] epoch 77, training loss: 9164.62, average training loss: 19592.85, base loss: 10610.67
[INFO 2017-06-26 13:22:13,056 main.py:50] epoch 78, training loss: 9118.87, average training loss: 19460.27, base loss: 10607.21
[INFO 2017-06-26 13:22:13,605 main.py:50] epoch 79, training loss: 9488.40, average training loss: 19335.62, base loss: 10609.48
[INFO 2017-06-26 13:22:14,154 main.py:50] epoch 80, training loss: 9136.92, average training loss: 19209.71, base loss: 10606.79
[INFO 2017-06-26 13:22:14,704 main.py:50] epoch 81, training loss: 9268.14, average training loss: 19088.47, base loss: 10605.51
[INFO 2017-06-26 13:22:15,254 main.py:50] epoch 82, training loss: 9527.14, average training loss: 18973.27, base loss: 10609.15
[INFO 2017-06-26 13:22:15,802 main.py:50] epoch 83, training loss: 9593.30, average training loss: 18861.61, base loss: 10614.12
[INFO 2017-06-26 13:22:16,352 main.py:50] epoch 84, training loss: 9742.17, average training loss: 18754.32, base loss: 10621.09
[INFO 2017-06-26 13:22:16,900 main.py:50] epoch 85, training loss: 9229.79, average training loss: 18643.57, base loss: 10620.45
[INFO 2017-06-26 13:22:17,451 main.py:50] epoch 86, training loss: 9188.78, average training loss: 18534.89, base loss: 10619.04
[INFO 2017-06-26 13:22:18,002 main.py:50] epoch 87, training loss: 9469.15, average training loss: 18431.87, base loss: 10622.50
[INFO 2017-06-26 13:22:18,553 main.py:50] epoch 88, training loss: 9126.27, average training loss: 18327.32, base loss: 10621.35
[INFO 2017-06-26 13:22:19,106 main.py:50] epoch 89, training loss: 9399.51, average training loss: 18228.12, base loss: 10624.25
[INFO 2017-06-26 13:22:19,655 main.py:50] epoch 90, training loss: 9288.43, average training loss: 18129.88, base loss: 10625.45
[INFO 2017-06-26 13:22:20,205 main.py:50] epoch 91, training loss: 8924.42, average training loss: 18029.82, base loss: 10621.74
[INFO 2017-06-26 13:22:20,754 main.py:50] epoch 92, training loss: 9658.58, average training loss: 17939.81, base loss: 10628.55
[INFO 2017-06-26 13:22:21,303 main.py:50] epoch 93, training loss: 8796.19, average training loss: 17842.54, base loss: 10623.58
[INFO 2017-06-26 13:22:21,852 main.py:50] epoch 94, training loss: 9060.01, average training loss: 17750.09, base loss: 10622.84
[INFO 2017-06-26 13:22:22,402 main.py:50] epoch 95, training loss: 9684.72, average training loss: 17666.07, base loss: 10631.01
[INFO 2017-06-26 13:22:22,953 main.py:50] epoch 96, training loss: 9024.98, average training loss: 17576.99, base loss: 10629.81
[INFO 2017-06-26 13:22:23,504 main.py:50] epoch 97, training loss: 9080.51, average training loss: 17490.29, base loss: 10629.37
[INFO 2017-06-26 13:22:24,053 main.py:50] epoch 98, training loss: 9419.12, average training loss: 17408.76, base loss: 10633.98
[INFO 2017-06-26 13:22:24,600 main.py:50] epoch 99, training loss: 9347.45, average training loss: 17328.15, base loss: 10637.82
[INFO 2017-06-26 13:22:24,601 main.py:52] epoch 99, testing
[INFO 2017-06-26 13:22:26,782 main.py:103] average testing loss: 9194.12, base loss: 10810.31
[INFO 2017-06-26 13:22:26,782 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:22:26,788 main.py:76] current best accuracy: 9194.12
[INFO 2017-06-26 13:22:27,336 main.py:50] epoch 100, training loss: 9157.77, average training loss: 17247.26, base loss: 10639.20
[INFO 2017-06-26 13:22:27,885 main.py:50] epoch 101, training loss: 8912.77, average training loss: 17165.55, base loss: 10637.73
[INFO 2017-06-26 13:22:28,436 main.py:50] epoch 102, training loss: 9028.56, average training loss: 17086.55, base loss: 10637.95
[INFO 2017-06-26 13:22:28,986 main.py:50] epoch 103, training loss: 8958.50, average training loss: 17008.39, base loss: 10636.92
[INFO 2017-06-26 13:22:29,535 main.py:50] epoch 104, training loss: 9132.58, average training loss: 16933.38, base loss: 10639.12
[INFO 2017-06-26 13:22:30,112 main.py:50] epoch 105, training loss: 8825.45, average training loss: 16856.89, base loss: 10636.86
[INFO 2017-06-26 13:22:30,662 main.py:50] epoch 106, training loss: 8655.96, average training loss: 16780.25, base loss: 10632.03
[INFO 2017-06-26 13:22:31,209 main.py:50] epoch 107, training loss: 9016.35, average training loss: 16708.36, base loss: 10632.30
[INFO 2017-06-26 13:22:31,757 main.py:50] epoch 108, training loss: 9349.75, average training loss: 16640.85, base loss: 10637.32
[INFO 2017-06-26 13:22:32,306 main.py:50] epoch 109, training loss: 8794.38, average training loss: 16569.52, base loss: 10635.75
[INFO 2017-06-26 13:22:32,854 main.py:50] epoch 110, training loss: 9081.70, average training loss: 16502.06, base loss: 10638.33
[INFO 2017-06-26 13:22:33,405 main.py:50] epoch 111, training loss: 9179.50, average training loss: 16436.68, base loss: 10641.50
[INFO 2017-06-26 13:22:33,953 main.py:50] epoch 112, training loss: 8435.14, average training loss: 16365.87, base loss: 10635.32
[INFO 2017-06-26 13:22:34,499 main.py:50] epoch 113, training loss: 8892.59, average training loss: 16300.32, base loss: 10635.31
[INFO 2017-06-26 13:22:35,047 main.py:50] epoch 114, training loss: 8912.99, average training loss: 16236.08, base loss: 10635.70
[INFO 2017-06-26 13:22:35,593 main.py:50] epoch 115, training loss: 9060.75, average training loss: 16174.22, base loss: 10638.43
[INFO 2017-06-26 13:22:36,143 main.py:50] epoch 116, training loss: 8809.87, average training loss: 16111.28, base loss: 10638.23
[INFO 2017-06-26 13:22:36,690 main.py:50] epoch 117, training loss: 8681.30, average training loss: 16048.31, base loss: 10635.83
[INFO 2017-06-26 13:22:37,238 main.py:50] epoch 118, training loss: 8947.97, average training loss: 15988.65, base loss: 10637.35
[INFO 2017-06-26 13:22:37,788 main.py:50] epoch 119, training loss: 9086.37, average training loss: 15931.13, base loss: 10640.07
[INFO 2017-06-26 13:22:38,338 main.py:50] epoch 120, training loss: 9028.85, average training loss: 15874.08, base loss: 10643.17
[INFO 2017-06-26 13:22:38,887 main.py:50] epoch 121, training loss: 8935.05, average training loss: 15817.21, base loss: 10644.90
[INFO 2017-06-26 13:22:39,435 main.py:50] epoch 122, training loss: 8668.23, average training loss: 15759.09, base loss: 10643.38
[INFO 2017-06-26 13:22:39,983 main.py:50] epoch 123, training loss: 8724.09, average training loss: 15702.35, base loss: 10643.06
[INFO 2017-06-26 13:22:40,531 main.py:50] epoch 124, training loss: 8770.53, average training loss: 15646.90, base loss: 10642.94
[INFO 2017-06-26 13:22:41,079 main.py:50] epoch 125, training loss: 8365.72, average training loss: 15589.11, base loss: 10638.45
[INFO 2017-06-26 13:22:41,629 main.py:50] epoch 126, training loss: 8522.17, average training loss: 15533.46, base loss: 10636.03
[INFO 2017-06-26 13:22:42,179 main.py:50] epoch 127, training loss: 8876.09, average training loss: 15481.45, base loss: 10638.02
[INFO 2017-06-26 13:22:42,729 main.py:50] epoch 128, training loss: 8857.95, average training loss: 15430.11, base loss: 10639.91
[INFO 2017-06-26 13:22:43,278 main.py:50] epoch 129, training loss: 8805.25, average training loss: 15379.15, base loss: 10641.84
[INFO 2017-06-26 13:22:43,828 main.py:50] epoch 130, training loss: 8576.70, average training loss: 15327.22, base loss: 10641.25
[INFO 2017-06-26 13:22:44,378 main.py:50] epoch 131, training loss: 9051.36, average training loss: 15279.68, base loss: 10646.26
[INFO 2017-06-26 13:22:44,929 main.py:50] epoch 132, training loss: 9016.77, average training loss: 15232.59, base loss: 10650.14
[INFO 2017-06-26 13:22:45,478 main.py:50] epoch 133, training loss: 8657.70, average training loss: 15183.52, base loss: 10649.78
[INFO 2017-06-26 13:22:46,029 main.py:50] epoch 134, training loss: 8470.73, average training loss: 15133.80, base loss: 10648.21
[INFO 2017-06-26 13:22:46,578 main.py:50] epoch 135, training loss: 8539.46, average training loss: 15085.31, base loss: 10646.89
[INFO 2017-06-26 13:22:47,129 main.py:50] epoch 136, training loss: 8385.82, average training loss: 15036.41, base loss: 10644.86
[INFO 2017-06-26 13:22:47,679 main.py:50] epoch 137, training loss: 8664.01, average training loss: 14990.23, base loss: 10645.32
[INFO 2017-06-26 13:22:48,229 main.py:50] epoch 138, training loss: 8503.69, average training loss: 14943.56, base loss: 10644.42
[INFO 2017-06-26 13:22:48,778 main.py:50] epoch 139, training loss: 8839.81, average training loss: 14899.97, base loss: 10647.75
[INFO 2017-06-26 13:22:49,327 main.py:50] epoch 140, training loss: 8463.42, average training loss: 14854.32, base loss: 10646.72
[INFO 2017-06-26 13:22:49,875 main.py:50] epoch 141, training loss: 8900.96, average training loss: 14812.39, base loss: 10650.91
[INFO 2017-06-26 13:22:50,423 main.py:50] epoch 142, training loss: 8620.52, average training loss: 14769.09, base loss: 10651.01
[INFO 2017-06-26 13:22:50,971 main.py:50] epoch 143, training loss: 8806.42, average training loss: 14727.69, base loss: 10653.87
[INFO 2017-06-26 13:22:51,520 main.py:50] epoch 144, training loss: 8476.24, average training loss: 14684.57, base loss: 10652.51
[INFO 2017-06-26 13:22:52,070 main.py:50] epoch 145, training loss: 8770.52, average training loss: 14644.06, base loss: 10655.94
[INFO 2017-06-26 13:22:52,620 main.py:50] epoch 146, training loss: 8635.28, average training loss: 14603.19, base loss: 10657.80
[INFO 2017-06-26 13:22:53,226 main.py:50] epoch 147, training loss: 8454.68, average training loss: 14561.64, base loss: 10656.78
[INFO 2017-06-26 13:22:53,819 main.py:50] epoch 148, training loss: 8759.49, average training loss: 14522.70, base loss: 10659.17
[INFO 2017-06-26 13:22:54,397 main.py:50] epoch 149, training loss: 8235.28, average training loss: 14480.79, base loss: 10656.59
[INFO 2017-06-26 13:22:54,980 main.py:50] epoch 150, training loss: 8138.41, average training loss: 14438.78, base loss: 10653.26
[INFO 2017-06-26 13:22:55,566 main.py:50] epoch 151, training loss: 8166.73, average training loss: 14397.52, base loss: 10649.54
[INFO 2017-06-26 13:22:56,119 main.py:50] epoch 152, training loss: 8212.87, average training loss: 14357.10, base loss: 10647.17
[INFO 2017-06-26 13:22:56,669 main.py:50] epoch 153, training loss: 8643.47, average training loss: 14320.00, base loss: 10648.77
[INFO 2017-06-26 13:22:57,218 main.py:50] epoch 154, training loss: 8539.17, average training loss: 14282.70, base loss: 10649.60
[INFO 2017-06-26 13:22:57,775 main.py:50] epoch 155, training loss: 8672.09, average training loss: 14246.74, base loss: 10652.94
[INFO 2017-06-26 13:22:58,332 main.py:50] epoch 156, training loss: 8196.53, average training loss: 14208.20, base loss: 10650.53
[INFO 2017-06-26 13:22:58,881 main.py:50] epoch 157, training loss: 8509.35, average training loss: 14172.13, base loss: 10651.97
[INFO 2017-06-26 13:22:59,458 main.py:50] epoch 158, training loss: 8582.67, average training loss: 14136.98, base loss: 10654.12
[INFO 2017-06-26 13:23:00,007 main.py:50] epoch 159, training loss: 7904.85, average training loss: 14098.03, base loss: 10649.55
[INFO 2017-06-26 13:23:00,595 main.py:50] epoch 160, training loss: 8329.39, average training loss: 14062.20, base loss: 10649.21
[INFO 2017-06-26 13:23:01,177 main.py:50] epoch 161, training loss: 8420.62, average training loss: 14027.37, base loss: 10650.61
[INFO 2017-06-26 13:23:01,761 main.py:50] epoch 162, training loss: 8349.62, average training loss: 13992.54, base loss: 10650.08
[INFO 2017-06-26 13:23:02,347 main.py:50] epoch 163, training loss: 8536.61, average training loss: 13959.27, base loss: 10651.66
[INFO 2017-06-26 13:23:02,911 main.py:50] epoch 164, training loss: 8446.11, average training loss: 13925.86, base loss: 10652.44
[INFO 2017-06-26 13:23:03,495 main.py:50] epoch 165, training loss: 8142.02, average training loss: 13891.02, base loss: 10650.51
[INFO 2017-06-26 13:23:04,046 main.py:50] epoch 166, training loss: 8157.76, average training loss: 13856.68, base loss: 10649.60
[INFO 2017-06-26 13:23:04,637 main.py:50] epoch 167, training loss: 8108.79, average training loss: 13822.47, base loss: 10647.72
[INFO 2017-06-26 13:23:05,233 main.py:50] epoch 168, training loss: 8182.80, average training loss: 13789.10, base loss: 10647.30
[INFO 2017-06-26 13:23:05,783 main.py:50] epoch 169, training loss: 8085.57, average training loss: 13755.55, base loss: 10646.05
[INFO 2017-06-26 13:23:06,375 main.py:50] epoch 170, training loss: 8047.97, average training loss: 13722.17, base loss: 10644.14
[INFO 2017-06-26 13:23:06,924 main.py:50] epoch 171, training loss: 8499.48, average training loss: 13691.81, base loss: 10647.05
[INFO 2017-06-26 13:23:07,476 main.py:50] epoch 172, training loss: 8127.48, average training loss: 13659.64, base loss: 10646.14
[INFO 2017-06-26 13:23:08,027 main.py:50] epoch 173, training loss: 7955.75, average training loss: 13626.86, base loss: 10644.59
[INFO 2017-06-26 13:23:08,575 main.py:50] epoch 174, training loss: 7629.28, average training loss: 13592.59, base loss: 10639.94
[INFO 2017-06-26 13:23:09,132 main.py:50] epoch 175, training loss: 8012.00, average training loss: 13560.88, base loss: 10638.25
[INFO 2017-06-26 13:23:09,679 main.py:50] epoch 176, training loss: 8038.28, average training loss: 13529.68, base loss: 10637.54
[INFO 2017-06-26 13:23:10,225 main.py:50] epoch 177, training loss: 8156.58, average training loss: 13499.50, base loss: 10637.31
[INFO 2017-06-26 13:23:10,771 main.py:50] epoch 178, training loss: 8106.30, average training loss: 13469.37, base loss: 10637.44
[INFO 2017-06-26 13:23:11,319 main.py:50] epoch 179, training loss: 8303.08, average training loss: 13440.67, base loss: 10639.02
[INFO 2017-06-26 13:23:11,867 main.py:50] epoch 180, training loss: 7943.40, average training loss: 13410.29, base loss: 10637.11
[INFO 2017-06-26 13:23:12,418 main.py:50] epoch 181, training loss: 8058.22, average training loss: 13380.89, base loss: 10637.04
[INFO 2017-06-26 13:23:12,965 main.py:50] epoch 182, training loss: 7992.36, average training loss: 13351.44, base loss: 10636.14
[INFO 2017-06-26 13:23:13,512 main.py:50] epoch 183, training loss: 8423.68, average training loss: 13324.66, base loss: 10639.04
[INFO 2017-06-26 13:23:14,059 main.py:50] epoch 184, training loss: 8031.29, average training loss: 13296.05, base loss: 10638.73
[INFO 2017-06-26 13:23:14,607 main.py:50] epoch 185, training loss: 8027.15, average training loss: 13267.72, base loss: 10639.37
[INFO 2017-06-26 13:23:15,154 main.py:50] epoch 186, training loss: 8424.48, average training loss: 13241.82, base loss: 10642.43
[INFO 2017-06-26 13:23:15,702 main.py:50] epoch 187, training loss: 8068.71, average training loss: 13214.30, base loss: 10641.99
[INFO 2017-06-26 13:23:16,252 main.py:50] epoch 188, training loss: 8003.00, average training loss: 13186.73, base loss: 10641.95
[INFO 2017-06-26 13:23:16,799 main.py:50] epoch 189, training loss: 8035.23, average training loss: 13159.62, base loss: 10641.70
[INFO 2017-06-26 13:23:17,345 main.py:50] epoch 190, training loss: 7757.23, average training loss: 13131.33, base loss: 10639.62
[INFO 2017-06-26 13:23:17,893 main.py:50] epoch 191, training loss: 7945.47, average training loss: 13104.32, base loss: 10639.15
[INFO 2017-06-26 13:23:18,442 main.py:50] epoch 192, training loss: 7877.30, average training loss: 13077.24, base loss: 10638.58
[INFO 2017-06-26 13:23:18,991 main.py:50] epoch 193, training loss: 7855.06, average training loss: 13050.32, base loss: 10638.10
[INFO 2017-06-26 13:23:19,537 main.py:50] epoch 194, training loss: 7754.22, average training loss: 13023.16, base loss: 10637.21
[INFO 2017-06-26 13:23:20,086 main.py:50] epoch 195, training loss: 8003.64, average training loss: 12997.55, base loss: 10638.53
[INFO 2017-06-26 13:23:20,637 main.py:50] epoch 196, training loss: 7862.65, average training loss: 12971.49, base loss: 10637.95
[INFO 2017-06-26 13:23:21,184 main.py:50] epoch 197, training loss: 7728.36, average training loss: 12945.01, base loss: 10636.77
[INFO 2017-06-26 13:23:21,730 main.py:50] epoch 198, training loss: 8053.35, average training loss: 12920.42, base loss: 10638.15
[INFO 2017-06-26 13:23:22,281 main.py:50] epoch 199, training loss: 7990.28, average training loss: 12895.77, base loss: 10638.85
[INFO 2017-06-26 13:23:22,281 main.py:52] epoch 199, testing
[INFO 2017-06-26 13:23:24,459 main.py:103] average testing loss: 7947.61, base loss: 10865.63
[INFO 2017-06-26 13:23:24,460 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:23:24,466 main.py:76] current best accuracy: 7947.61
[INFO 2017-06-26 13:23:25,015 main.py:50] epoch 200, training loss: 7777.07, average training loss: 12870.31, base loss: 10638.74
[INFO 2017-06-26 13:23:25,563 main.py:50] epoch 201, training loss: 7926.68, average training loss: 12845.83, base loss: 10639.66
[INFO 2017-06-26 13:23:26,113 main.py:50] epoch 202, training loss: 7770.27, average training loss: 12820.83, base loss: 10638.87
[INFO 2017-06-26 13:23:26,678 main.py:50] epoch 203, training loss: 7707.13, average training loss: 12795.76, base loss: 10638.65
[INFO 2017-06-26 13:23:27,228 main.py:50] epoch 204, training loss: 7706.23, average training loss: 12770.94, base loss: 10637.61
[INFO 2017-06-26 13:23:27,781 main.py:50] epoch 205, training loss: 7775.10, average training loss: 12746.69, base loss: 10638.34
[INFO 2017-06-26 13:23:28,332 main.py:50] epoch 206, training loss: 7582.90, average training loss: 12721.74, base loss: 10637.15
[INFO 2017-06-26 13:23:28,882 main.py:50] epoch 207, training loss: 7492.10, average training loss: 12696.60, base loss: 10634.92
[INFO 2017-06-26 13:23:29,455 main.py:50] epoch 208, training loss: 7865.13, average training loss: 12673.48, base loss: 10636.87
[INFO 2017-06-26 13:23:30,045 main.py:50] epoch 209, training loss: 7573.58, average training loss: 12649.20, base loss: 10634.68
[INFO 2017-06-26 13:23:30,629 main.py:50] epoch 210, training loss: 7728.42, average training loss: 12625.87, base loss: 10634.92
[INFO 2017-06-26 13:23:31,190 main.py:50] epoch 211, training loss: 7868.64, average training loss: 12603.43, base loss: 10635.43
[INFO 2017-06-26 13:23:31,798 main.py:50] epoch 212, training loss: 7674.47, average training loss: 12580.29, base loss: 10634.70
[INFO 2017-06-26 13:23:32,355 main.py:50] epoch 213, training loss: 7494.79, average training loss: 12556.53, base loss: 10633.17
[INFO 2017-06-26 13:23:32,904 main.py:50] epoch 214, training loss: 7749.74, average training loss: 12534.17, base loss: 10633.21
[INFO 2017-06-26 13:23:33,455 main.py:50] epoch 215, training loss: 7577.88, average training loss: 12511.23, base loss: 10633.07
[INFO 2017-06-26 13:23:34,004 main.py:50] epoch 216, training loss: 7583.12, average training loss: 12488.52, base loss: 10632.22
[INFO 2017-06-26 13:23:34,553 main.py:50] epoch 217, training loss: 7556.98, average training loss: 12465.89, base loss: 10632.06
[INFO 2017-06-26 13:23:35,105 main.py:50] epoch 218, training loss: 7324.19, average training loss: 12442.42, base loss: 10629.45
[INFO 2017-06-26 13:23:35,653 main.py:50] epoch 219, training loss: 7586.40, average training loss: 12420.34, base loss: 10629.10
[INFO 2017-06-26 13:23:36,201 main.py:50] epoch 220, training loss: 7543.86, average training loss: 12398.28, base loss: 10628.53
[INFO 2017-06-26 13:23:36,749 main.py:50] epoch 221, training loss: 7707.60, average training loss: 12377.15, base loss: 10629.69
[INFO 2017-06-26 13:23:37,296 main.py:50] epoch 222, training loss: 7184.65, average training loss: 12353.86, base loss: 10626.76
[INFO 2017-06-26 13:23:37,846 main.py:50] epoch 223, training loss: 7541.21, average training loss: 12332.38, base loss: 10626.40
[INFO 2017-06-26 13:23:38,397 main.py:50] epoch 224, training loss: 7175.11, average training loss: 12309.46, base loss: 10623.61
[INFO 2017-06-26 13:23:38,966 main.py:50] epoch 225, training loss: 7502.81, average training loss: 12288.19, base loss: 10623.26
[INFO 2017-06-26 13:23:39,515 main.py:50] epoch 226, training loss: 7585.19, average training loss: 12267.47, base loss: 10623.95
[INFO 2017-06-26 13:23:40,065 main.py:50] epoch 227, training loss: 7719.40, average training loss: 12247.52, base loss: 10625.26
[INFO 2017-06-26 13:23:40,612 main.py:50] epoch 228, training loss: 7507.49, average training loss: 12226.83, base loss: 10625.78
[INFO 2017-06-26 13:23:41,197 main.py:50] epoch 229, training loss: 7397.10, average training loss: 12205.83, base loss: 10624.78
[INFO 2017-06-26 13:23:41,758 main.py:50] epoch 230, training loss: 7406.98, average training loss: 12185.05, base loss: 10624.03
[INFO 2017-06-26 13:23:42,310 main.py:50] epoch 231, training loss: 7235.06, average training loss: 12163.72, base loss: 10622.24
[INFO 2017-06-26 13:23:42,857 main.py:50] epoch 232, training loss: 7453.06, average training loss: 12143.50, base loss: 10622.29
[INFO 2017-06-26 13:23:43,441 main.py:50] epoch 233, training loss: 7348.69, average training loss: 12123.01, base loss: 10620.90
[INFO 2017-06-26 13:23:44,003 main.py:50] epoch 234, training loss: 7471.17, average training loss: 12103.21, base loss: 10620.70
[INFO 2017-06-26 13:23:44,552 main.py:50] epoch 235, training loss: 7765.98, average training loss: 12084.83, base loss: 10622.88
[INFO 2017-06-26 13:23:45,115 main.py:50] epoch 236, training loss: 7265.84, average training loss: 12064.50, base loss: 10621.56
[INFO 2017-06-26 13:23:45,666 main.py:50] epoch 237, training loss: 7470.68, average training loss: 12045.20, base loss: 10621.30
[INFO 2017-06-26 13:23:46,252 main.py:50] epoch 238, training loss: 7264.90, average training loss: 12025.20, base loss: 10620.43
[INFO 2017-06-26 13:23:46,800 main.py:50] epoch 239, training loss: 7363.84, average training loss: 12005.78, base loss: 10620.43
[INFO 2017-06-26 13:23:47,360 main.py:50] epoch 240, training loss: 7615.29, average training loss: 11987.56, base loss: 10622.28
[INFO 2017-06-26 13:23:47,909 main.py:50] epoch 241, training loss: 7068.00, average training loss: 11967.23, base loss: 10620.19
[INFO 2017-06-26 13:23:48,496 main.py:50] epoch 242, training loss: 7469.46, average training loss: 11948.72, base loss: 10621.26
[INFO 2017-06-26 13:23:49,086 main.py:50] epoch 243, training loss: 7454.13, average training loss: 11930.30, base loss: 10621.89
[INFO 2017-06-26 13:23:49,642 main.py:50] epoch 244, training loss: 7312.41, average training loss: 11911.45, base loss: 10621.14
[INFO 2017-06-26 13:23:50,193 main.py:50] epoch 245, training loss: 7844.08, average training loss: 11894.92, base loss: 10624.03
[INFO 2017-06-26 13:23:50,785 main.py:50] epoch 246, training loss: 7633.35, average training loss: 11877.66, base loss: 10626.55
[INFO 2017-06-26 13:23:51,382 main.py:50] epoch 247, training loss: 7492.13, average training loss: 11859.98, base loss: 10626.76
[INFO 2017-06-26 13:23:51,963 main.py:50] epoch 248, training loss: 7294.99, average training loss: 11841.65, base loss: 10626.31
[INFO 2017-06-26 13:23:52,556 main.py:50] epoch 249, training loss: 7631.61, average training loss: 11824.81, base loss: 10628.06
[INFO 2017-06-26 13:23:53,145 main.py:50] epoch 250, training loss: 7061.15, average training loss: 11805.83, base loss: 10626.11
[INFO 2017-06-26 13:23:53,698 main.py:50] epoch 251, training loss: 7449.84, average training loss: 11788.54, base loss: 10627.37
[INFO 2017-06-26 13:23:54,291 main.py:50] epoch 252, training loss: 7494.86, average training loss: 11771.57, base loss: 10628.56
[INFO 2017-06-26 13:23:54,838 main.py:50] epoch 253, training loss: 7466.91, average training loss: 11754.62, base loss: 10629.25
[INFO 2017-06-26 13:23:55,386 main.py:50] epoch 254, training loss: 7056.64, average training loss: 11736.20, base loss: 10627.66
[INFO 2017-06-26 13:23:55,978 main.py:50] epoch 255, training loss: 7557.79, average training loss: 11719.88, base loss: 10628.80
[INFO 2017-06-26 13:23:56,528 main.py:50] epoch 256, training loss: 7327.18, average training loss: 11702.79, base loss: 10629.15
[INFO 2017-06-26 13:23:57,122 main.py:50] epoch 257, training loss: 7095.87, average training loss: 11684.93, base loss: 10627.60
[INFO 2017-06-26 13:23:57,684 main.py:50] epoch 258, training loss: 7203.13, average training loss: 11667.63, base loss: 10627.26
[INFO 2017-06-26 13:23:58,278 main.py:50] epoch 259, training loss: 7100.90, average training loss: 11650.06, base loss: 10626.30
[INFO 2017-06-26 13:23:58,873 main.py:50] epoch 260, training loss: 7371.00, average training loss: 11633.67, base loss: 10627.47
[INFO 2017-06-26 13:23:59,435 main.py:50] epoch 261, training loss: 7237.36, average training loss: 11616.89, base loss: 10628.04
[INFO 2017-06-26 13:24:00,043 main.py:50] epoch 262, training loss: 7433.14, average training loss: 11600.98, base loss: 10629.78
[INFO 2017-06-26 13:24:00,605 main.py:50] epoch 263, training loss: 7320.84, average training loss: 11584.77, base loss: 10629.97
[INFO 2017-06-26 13:24:01,200 main.py:50] epoch 264, training loss: 7249.96, average training loss: 11568.41, base loss: 10630.85
[INFO 2017-06-26 13:24:01,789 main.py:50] epoch 265, training loss: 7365.17, average training loss: 11552.61, base loss: 10632.03
[INFO 2017-06-26 13:24:02,344 main.py:50] epoch 266, training loss: 7103.72, average training loss: 11535.94, base loss: 10631.87
[INFO 2017-06-26 13:24:02,902 main.py:50] epoch 267, training loss: 7387.23, average training loss: 11520.46, base loss: 10633.56
[INFO 2017-06-26 13:24:03,489 main.py:50] epoch 268, training loss: 7009.98, average training loss: 11503.70, base loss: 10632.41
[INFO 2017-06-26 13:24:04,040 main.py:50] epoch 269, training loss: 7062.11, average training loss: 11487.25, base loss: 10631.92
[INFO 2017-06-26 13:24:04,596 main.py:50] epoch 270, training loss: 7311.07, average training loss: 11471.84, base loss: 10632.89
[INFO 2017-06-26 13:24:05,148 main.py:50] epoch 271, training loss: 7359.01, average training loss: 11456.72, base loss: 10634.73
[INFO 2017-06-26 13:24:05,700 main.py:50] epoch 272, training loss: 7254.96, average training loss: 11441.32, base loss: 10635.58
[INFO 2017-06-26 13:24:06,281 main.py:50] epoch 273, training loss: 7157.89, average training loss: 11425.69, base loss: 10635.79
[INFO 2017-06-26 13:24:06,868 main.py:50] epoch 274, training loss: 7110.21, average training loss: 11410.00, base loss: 10634.96
[INFO 2017-06-26 13:24:07,428 main.py:50] epoch 275, training loss: 7320.86, average training loss: 11395.18, base loss: 10636.27
[INFO 2017-06-26 13:24:08,021 main.py:50] epoch 276, training loss: 7087.81, average training loss: 11379.63, base loss: 10636.20
[INFO 2017-06-26 13:24:08,583 main.py:50] epoch 277, training loss: 6929.85, average training loss: 11363.63, base loss: 10634.55
[INFO 2017-06-26 13:24:09,170 main.py:50] epoch 278, training loss: 7472.28, average training loss: 11349.68, base loss: 10636.60
[INFO 2017-06-26 13:24:09,730 main.py:50] epoch 279, training loss: 7224.24, average training loss: 11334.95, base loss: 10637.80
[INFO 2017-06-26 13:24:10,325 main.py:50] epoch 280, training loss: 7005.91, average training loss: 11319.54, base loss: 10637.25
[INFO 2017-06-26 13:24:10,894 main.py:50] epoch 281, training loss: 7404.70, average training loss: 11305.66, base loss: 10639.16
[INFO 2017-06-26 13:24:11,452 main.py:50] epoch 282, training loss: 7106.70, average training loss: 11290.82, base loss: 10639.56
[INFO 2017-06-26 13:24:12,003 main.py:50] epoch 283, training loss: 7271.58, average training loss: 11276.67, base loss: 10641.86
[INFO 2017-06-26 13:24:12,589 main.py:50] epoch 284, training loss: 7128.00, average training loss: 11262.11, base loss: 10643.28
[INFO 2017-06-26 13:24:13,175 main.py:50] epoch 285, training loss: 7340.47, average training loss: 11248.40, base loss: 10645.00
[INFO 2017-06-26 13:24:13,754 main.py:50] epoch 286, training loss: 7448.50, average training loss: 11235.16, base loss: 10647.77
[INFO 2017-06-26 13:24:14,344 main.py:50] epoch 287, training loss: 7042.92, average training loss: 11220.60, base loss: 10647.18
[INFO 2017-06-26 13:24:14,916 main.py:50] epoch 288, training loss: 6969.66, average training loss: 11205.89, base loss: 10646.68
[INFO 2017-06-26 13:24:15,502 main.py:50] epoch 289, training loss: 6935.61, average training loss: 11191.17, base loss: 10645.96
[INFO 2017-06-26 13:24:16,051 main.py:50] epoch 290, training loss: 7148.20, average training loss: 11177.27, base loss: 10646.60
[INFO 2017-06-26 13:24:16,637 main.py:50] epoch 291, training loss: 7118.51, average training loss: 11163.37, base loss: 10646.23
[INFO 2017-06-26 13:24:17,238 main.py:50] epoch 292, training loss: 7034.69, average training loss: 11149.28, base loss: 10646.35
[INFO 2017-06-26 13:24:17,793 main.py:50] epoch 293, training loss: 6818.56, average training loss: 11134.55, base loss: 10644.18
[INFO 2017-06-26 13:24:18,345 main.py:50] epoch 294, training loss: 7157.58, average training loss: 11121.07, base loss: 10644.77
[INFO 2017-06-26 13:24:18,931 main.py:50] epoch 295, training loss: 7256.95, average training loss: 11108.02, base loss: 10646.47
[INFO 2017-06-26 13:24:19,495 main.py:50] epoch 296, training loss: 7012.77, average training loss: 11094.23, base loss: 10646.54
[INFO 2017-06-26 13:24:20,081 main.py:50] epoch 297, training loss: 6789.32, average training loss: 11079.78, base loss: 10645.27
[INFO 2017-06-26 13:24:20,642 main.py:50] epoch 298, training loss: 7026.22, average training loss: 11066.23, base loss: 10645.24
[INFO 2017-06-26 13:24:21,193 main.py:50] epoch 299, training loss: 6789.61, average training loss: 11051.97, base loss: 10643.67
[INFO 2017-06-26 13:24:21,193 main.py:52] epoch 299, testing
[INFO 2017-06-26 13:24:23,402 main.py:103] average testing loss: 6969.04, base loss: 10576.61
[INFO 2017-06-26 13:24:23,402 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:24:23,409 main.py:76] current best accuracy: 6969.04
[INFO 2017-06-26 13:24:23,960 main.py:50] epoch 300, training loss: 7020.91, average training loss: 11038.58, base loss: 10644.58
[INFO 2017-06-26 13:24:24,510 main.py:50] epoch 301, training loss: 6804.24, average training loss: 11024.56, base loss: 10643.39
[INFO 2017-06-26 13:24:25,062 main.py:50] epoch 302, training loss: 7029.00, average training loss: 11011.37, base loss: 10643.58
[INFO 2017-06-26 13:24:25,611 main.py:50] epoch 303, training loss: 6950.46, average training loss: 10998.01, base loss: 10643.50
[INFO 2017-06-26 13:24:26,163 main.py:50] epoch 304, training loss: 6743.80, average training loss: 10984.06, base loss: 10641.50
[INFO 2017-06-26 13:24:26,709 main.py:50] epoch 305, training loss: 6652.31, average training loss: 10969.91, base loss: 10639.95
[INFO 2017-06-26 13:24:27,272 main.py:50] epoch 306, training loss: 7255.97, average training loss: 10957.81, base loss: 10641.51
[INFO 2017-06-26 13:24:27,819 main.py:50] epoch 307, training loss: 7081.91, average training loss: 10945.23, base loss: 10641.96
[INFO 2017-06-26 13:24:28,367 main.py:50] epoch 308, training loss: 6890.10, average training loss: 10932.10, base loss: 10641.18
[INFO 2017-06-26 13:24:28,917 main.py:50] epoch 309, training loss: 7017.92, average training loss: 10919.48, base loss: 10641.47
[INFO 2017-06-26 13:24:29,467 main.py:50] epoch 310, training loss: 6869.47, average training loss: 10906.45, base loss: 10641.01
[INFO 2017-06-26 13:24:30,071 main.py:50] epoch 311, training loss: 7111.40, average training loss: 10894.29, base loss: 10642.24
[INFO 2017-06-26 13:24:30,660 main.py:50] epoch 312, training loss: 6912.07, average training loss: 10881.57, base loss: 10641.60
[INFO 2017-06-26 13:24:31,230 main.py:50] epoch 313, training loss: 6694.10, average training loss: 10868.23, base loss: 10640.61
[INFO 2017-06-26 13:24:31,808 main.py:50] epoch 314, training loss: 7029.73, average training loss: 10856.05, base loss: 10641.52
[INFO 2017-06-26 13:24:32,397 main.py:50] epoch 315, training loss: 6802.26, average training loss: 10843.22, base loss: 10641.42
[INFO 2017-06-26 13:24:32,945 main.py:50] epoch 316, training loss: 7075.83, average training loss: 10831.33, base loss: 10642.10
[INFO 2017-06-26 13:24:33,493 main.py:50] epoch 317, training loss: 7097.34, average training loss: 10819.59, base loss: 10643.98
[INFO 2017-06-26 13:24:34,039 main.py:50] epoch 318, training loss: 6908.67, average training loss: 10807.33, base loss: 10644.62
[INFO 2017-06-26 13:24:34,588 main.py:50] epoch 319, training loss: 7133.98, average training loss: 10795.85, base loss: 10646.41
[INFO 2017-06-26 13:24:35,138 main.py:50] epoch 320, training loss: 7083.73, average training loss: 10784.29, base loss: 10647.52
[INFO 2017-06-26 13:24:35,684 main.py:50] epoch 321, training loss: 6932.22, average training loss: 10772.32, base loss: 10648.21
[INFO 2017-06-26 13:24:36,229 main.py:50] epoch 322, training loss: 6766.38, average training loss: 10759.92, base loss: 10647.92
[INFO 2017-06-26 13:24:36,778 main.py:50] epoch 323, training loss: 6596.82, average training loss: 10747.07, base loss: 10646.68
[INFO 2017-06-26 13:24:37,324 main.py:50] epoch 324, training loss: 7097.53, average training loss: 10735.84, base loss: 10647.83
[INFO 2017-06-26 13:24:37,874 main.py:50] epoch 325, training loss: 6926.35, average training loss: 10724.16, base loss: 10648.13
[INFO 2017-06-26 13:24:38,422 main.py:50] epoch 326, training loss: 6661.15, average training loss: 10711.73, base loss: 10647.11
[INFO 2017-06-26 13:24:38,968 main.py:50] epoch 327, training loss: 7041.55, average training loss: 10700.54, base loss: 10647.81
[INFO 2017-06-26 13:24:39,516 main.py:50] epoch 328, training loss: 6777.54, average training loss: 10688.62, base loss: 10647.54
[INFO 2017-06-26 13:24:40,064 main.py:50] epoch 329, training loss: 6619.40, average training loss: 10676.29, base loss: 10645.95
[INFO 2017-06-26 13:24:40,647 main.py:50] epoch 330, training loss: 6808.22, average training loss: 10664.60, base loss: 10646.25
[INFO 2017-06-26 13:24:41,196 main.py:50] epoch 331, training loss: 6807.33, average training loss: 10652.98, base loss: 10645.76
[INFO 2017-06-26 13:24:41,782 main.py:50] epoch 332, training loss: 6999.99, average training loss: 10642.01, base loss: 10646.53
[INFO 2017-06-26 13:24:42,342 main.py:50] epoch 333, training loss: 6943.79, average training loss: 10630.94, base loss: 10647.46
[INFO 2017-06-26 13:24:42,891 main.py:50] epoch 334, training loss: 6660.94, average training loss: 10619.09, base loss: 10647.18
[INFO 2017-06-26 13:24:43,440 main.py:50] epoch 335, training loss: 6689.64, average training loss: 10607.40, base loss: 10647.09
[INFO 2017-06-26 13:24:44,020 main.py:50] epoch 336, training loss: 6730.49, average training loss: 10595.89, base loss: 10646.59
[INFO 2017-06-26 13:24:44,569 main.py:50] epoch 337, training loss: 6754.58, average training loss: 10584.53, base loss: 10646.02
[INFO 2017-06-26 13:24:45,121 main.py:50] epoch 338, training loss: 6727.10, average training loss: 10573.15, base loss: 10645.80
[INFO 2017-06-26 13:24:45,707 main.py:50] epoch 339, training loss: 7065.77, average training loss: 10562.83, base loss: 10647.65
[INFO 2017-06-26 13:24:46,255 main.py:50] epoch 340, training loss: 6777.61, average training loss: 10551.73, base loss: 10647.69
[INFO 2017-06-26 13:24:46,819 main.py:50] epoch 341, training loss: 6685.67, average training loss: 10540.43, base loss: 10647.07
[INFO 2017-06-26 13:24:47,401 main.py:50] epoch 342, training loss: 6759.93, average training loss: 10529.41, base loss: 10647.28
[INFO 2017-06-26 13:24:47,952 main.py:50] epoch 343, training loss: 6635.56, average training loss: 10518.09, base loss: 10646.26
[INFO 2017-06-26 13:24:48,541 main.py:50] epoch 344, training loss: 6893.50, average training loss: 10507.58, base loss: 10647.82
[INFO 2017-06-26 13:24:49,089 main.py:50] epoch 345, training loss: 6889.08, average training loss: 10497.12, base loss: 10648.89
[INFO 2017-06-26 13:24:49,637 main.py:50] epoch 346, training loss: 6678.60, average training loss: 10486.12, base loss: 10647.61
[INFO 2017-06-26 13:24:50,222 main.py:50] epoch 347, training loss: 6933.11, average training loss: 10475.91, base loss: 10648.25
[INFO 2017-06-26 13:24:50,785 main.py:50] epoch 348, training loss: 6606.25, average training loss: 10464.82, base loss: 10647.57
[INFO 2017-06-26 13:24:51,384 main.py:50] epoch 349, training loss: 6817.14, average training loss: 10454.40, base loss: 10648.84
[INFO 2017-06-26 13:24:51,946 main.py:50] epoch 350, training loss: 6556.82, average training loss: 10443.29, base loss: 10647.25
[INFO 2017-06-26 13:24:52,534 main.py:50] epoch 351, training loss: 6852.59, average training loss: 10433.09, base loss: 10648.42
[INFO 2017-06-26 13:24:53,103 main.py:50] epoch 352, training loss: 6605.10, average training loss: 10422.25, base loss: 10648.20
[INFO 2017-06-26 13:24:53,688 main.py:50] epoch 353, training loss: 6601.83, average training loss: 10411.46, base loss: 10647.69
[INFO 2017-06-26 13:24:54,250 main.py:50] epoch 354, training loss: 7057.33, average training loss: 10402.01, base loss: 10649.93
[INFO 2017-06-26 13:24:54,835 main.py:50] epoch 355, training loss: 6617.53, average training loss: 10391.38, base loss: 10649.46
[INFO 2017-06-26 13:24:55,399 main.py:50] epoch 356, training loss: 6590.64, average training loss: 10380.73, base loss: 10649.16
[INFO 2017-06-26 13:24:55,959 main.py:50] epoch 357, training loss: 6961.66, average training loss: 10371.18, base loss: 10651.26
[INFO 2017-06-26 13:24:56,543 main.py:50] epoch 358, training loss: 6571.45, average training loss: 10360.60, base loss: 10650.38
[INFO 2017-06-26 13:24:57,098 main.py:50] epoch 359, training loss: 6651.36, average training loss: 10350.29, base loss: 10649.93
[INFO 2017-06-26 13:24:57,646 main.py:50] epoch 360, training loss: 6800.98, average training loss: 10340.46, base loss: 10650.70
[INFO 2017-06-26 13:24:58,193 main.py:50] epoch 361, training loss: 6894.10, average training loss: 10330.94, base loss: 10652.41
[INFO 2017-06-26 13:24:58,776 main.py:50] epoch 362, training loss: 6709.84, average training loss: 10320.97, base loss: 10653.06
[INFO 2017-06-26 13:24:59,326 main.py:50] epoch 363, training loss: 6794.61, average training loss: 10311.28, base loss: 10654.25
[INFO 2017-06-26 13:24:59,877 main.py:50] epoch 364, training loss: 6510.54, average training loss: 10300.87, base loss: 10653.78
[INFO 2017-06-26 13:25:00,425 main.py:50] epoch 365, training loss: 6610.13, average training loss: 10290.78, base loss: 10654.05
[INFO 2017-06-26 13:25:01,009 main.py:50] epoch 366, training loss: 6744.31, average training loss: 10281.12, base loss: 10654.82
[INFO 2017-06-26 13:25:01,559 main.py:50] epoch 367, training loss: 6504.60, average training loss: 10270.86, base loss: 10654.57
[INFO 2017-06-26 13:25:02,146 main.py:50] epoch 368, training loss: 6532.50, average training loss: 10260.72, base loss: 10654.26
[INFO 2017-06-26 13:25:02,697 main.py:50] epoch 369, training loss: 6492.34, average training loss: 10250.54, base loss: 10654.35
[INFO 2017-06-26 13:25:03,244 main.py:50] epoch 370, training loss: 6519.35, average training loss: 10240.48, base loss: 10654.35
[INFO 2017-06-26 13:25:03,792 main.py:50] epoch 371, training loss: 6474.20, average training loss: 10230.36, base loss: 10653.07
[INFO 2017-06-26 13:25:04,375 main.py:50] epoch 372, training loss: 6610.73, average training loss: 10220.65, base loss: 10652.81
[INFO 2017-06-26 13:25:04,936 main.py:50] epoch 373, training loss: 6638.31, average training loss: 10211.08, base loss: 10653.76
[INFO 2017-06-26 13:25:05,519 main.py:50] epoch 374, training loss: 6647.66, average training loss: 10201.57, base loss: 10654.37
[INFO 2017-06-26 13:25:06,070 main.py:50] epoch 375, training loss: 6373.59, average training loss: 10191.39, base loss: 10653.63
[INFO 2017-06-26 13:25:06,654 main.py:50] epoch 376, training loss: 6518.93, average training loss: 10181.65, base loss: 10653.58
[INFO 2017-06-26 13:25:07,224 main.py:50] epoch 377, training loss: 6378.31, average training loss: 10171.59, base loss: 10651.80
[INFO 2017-06-26 13:25:07,808 main.py:50] epoch 378, training loss: 6474.24, average training loss: 10161.83, base loss: 10651.51
[INFO 2017-06-26 13:25:08,360 main.py:50] epoch 379, training loss: 6508.81, average training loss: 10152.22, base loss: 10651.37
[INFO 2017-06-26 13:25:08,943 main.py:50] epoch 380, training loss: 6485.77, average training loss: 10142.60, base loss: 10651.58
[INFO 2017-06-26 13:25:09,495 main.py:50] epoch 381, training loss: 6593.02, average training loss: 10133.31, base loss: 10652.80
[INFO 2017-06-26 13:25:10,045 main.py:50] epoch 382, training loss: 6679.21, average training loss: 10124.29, base loss: 10654.40
[INFO 2017-06-26 13:25:10,593 main.py:50] epoch 383, training loss: 6394.50, average training loss: 10114.57, base loss: 10653.57
[INFO 2017-06-26 13:25:11,140 main.py:50] epoch 384, training loss: 6579.92, average training loss: 10105.39, base loss: 10654.05
[INFO 2017-06-26 13:25:11,687 main.py:50] epoch 385, training loss: 6415.79, average training loss: 10095.83, base loss: 10654.11
[INFO 2017-06-26 13:25:12,234 main.py:50] epoch 386, training loss: 6352.84, average training loss: 10086.16, base loss: 10653.53
[INFO 2017-06-26 13:25:12,783 main.py:50] epoch 387, training loss: 6150.55, average training loss: 10076.02, base loss: 10652.05
[INFO 2017-06-26 13:25:13,333 main.py:50] epoch 388, training loss: 6773.72, average training loss: 10067.53, base loss: 10653.38
[INFO 2017-06-26 13:25:13,881 main.py:50] epoch 389, training loss: 6601.24, average training loss: 10058.64, base loss: 10654.25
[INFO 2017-06-26 13:25:14,463 main.py:50] epoch 390, training loss: 6394.67, average training loss: 10049.27, base loss: 10653.89
[INFO 2017-06-26 13:25:15,013 main.py:50] epoch 391, training loss: 6605.86, average training loss: 10040.49, base loss: 10654.24
[INFO 2017-06-26 13:25:15,582 main.py:50] epoch 392, training loss: 6562.02, average training loss: 10031.64, base loss: 10654.85
[INFO 2017-06-26 13:25:16,131 main.py:50] epoch 393, training loss: 6474.84, average training loss: 10022.61, base loss: 10654.66
[INFO 2017-06-26 13:25:16,682 main.py:50] epoch 394, training loss: 6469.83, average training loss: 10013.61, base loss: 10654.43
[INFO 2017-06-26 13:25:17,264 main.py:50] epoch 395, training loss: 6442.95, average training loss: 10004.60, base loss: 10654.05
[INFO 2017-06-26 13:25:17,818 main.py:50] epoch 396, training loss: 6619.18, average training loss: 9996.07, base loss: 10654.65
[INFO 2017-06-26 13:25:18,366 main.py:50] epoch 397, training loss: 6477.18, average training loss: 9987.23, base loss: 10654.26
[INFO 2017-06-26 13:25:18,916 main.py:50] epoch 398, training loss: 6498.83, average training loss: 9978.49, base loss: 10654.55
[INFO 2017-06-26 13:25:19,500 main.py:50] epoch 399, training loss: 6497.71, average training loss: 9969.78, base loss: 10654.81
[INFO 2017-06-26 13:25:19,500 main.py:52] epoch 399, testing
[INFO 2017-06-26 13:25:21,795 main.py:103] average testing loss: 6482.56, base loss: 10745.52
[INFO 2017-06-26 13:25:21,795 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:25:21,801 main.py:76] current best accuracy: 6482.56
[INFO 2017-06-26 13:25:22,350 main.py:50] epoch 400, training loss: 6402.78, average training loss: 9960.89, base loss: 10654.34
[INFO 2017-06-26 13:25:22,898 main.py:50] epoch 401, training loss: 6477.92, average training loss: 9952.22, base loss: 10654.77
[INFO 2017-06-26 13:25:23,447 main.py:50] epoch 402, training loss: 6620.96, average training loss: 9943.96, base loss: 10655.96
[INFO 2017-06-26 13:25:23,995 main.py:50] epoch 403, training loss: 6422.03, average training loss: 9935.24, base loss: 10655.48
[INFO 2017-06-26 13:25:24,545 main.py:50] epoch 404, training loss: 6409.62, average training loss: 9926.54, base loss: 10655.64
[INFO 2017-06-26 13:25:25,093 main.py:50] epoch 405, training loss: 6393.96, average training loss: 9917.83, base loss: 10655.52
[INFO 2017-06-26 13:25:25,641 main.py:50] epoch 406, training loss: 6494.71, average training loss: 9909.42, base loss: 10656.26
[INFO 2017-06-26 13:25:26,188 main.py:50] epoch 407, training loss: 6432.44, average training loss: 9900.90, base loss: 10655.93
[INFO 2017-06-26 13:25:26,736 main.py:50] epoch 408, training loss: 6276.96, average training loss: 9892.04, base loss: 10655.44
[INFO 2017-06-26 13:25:27,283 main.py:50] epoch 409, training loss: 6387.15, average training loss: 9883.49, base loss: 10655.14
[INFO 2017-06-26 13:25:27,831 main.py:50] epoch 410, training loss: 6664.30, average training loss: 9875.66, base loss: 10656.96
[INFO 2017-06-26 13:25:28,381 main.py:50] epoch 411, training loss: 6479.67, average training loss: 9867.42, base loss: 10657.09
[INFO 2017-06-26 13:25:28,933 main.py:50] epoch 412, training loss: 6441.36, average training loss: 9859.12, base loss: 10657.47
[INFO 2017-06-26 13:25:29,483 main.py:50] epoch 413, training loss: 6345.41, average training loss: 9850.63, base loss: 10657.27
[INFO 2017-06-26 13:25:30,032 main.py:50] epoch 414, training loss: 6169.83, average training loss: 9841.77, base loss: 10656.33
[INFO 2017-06-26 13:25:30,580 main.py:50] epoch 415, training loss: 6402.85, average training loss: 9833.50, base loss: 10656.48
[INFO 2017-06-26 13:25:31,130 main.py:50] epoch 416, training loss: 6283.32, average training loss: 9824.99, base loss: 10655.86
[INFO 2017-06-26 13:25:31,680 main.py:50] epoch 417, training loss: 6542.98, average training loss: 9817.13, base loss: 10657.37
[INFO 2017-06-26 13:25:32,230 main.py:50] epoch 418, training loss: 6165.00, average training loss: 9808.42, base loss: 10656.23
[INFO 2017-06-26 13:25:32,808 main.py:50] epoch 419, training loss: 6248.82, average training loss: 9799.94, base loss: 10655.74
[INFO 2017-06-26 13:25:33,398 main.py:50] epoch 420, training loss: 6431.40, average training loss: 9791.94, base loss: 10656.20
[INFO 2017-06-26 13:25:33,991 main.py:50] epoch 421, training loss: 6297.61, average training loss: 9783.66, base loss: 10655.96
[INFO 2017-06-26 13:25:34,553 main.py:50] epoch 422, training loss: 6465.15, average training loss: 9775.81, base loss: 10656.91
[INFO 2017-06-26 13:25:35,182 main.py:50] epoch 423, training loss: 6342.47, average training loss: 9767.72, base loss: 10657.51
[INFO 2017-06-26 13:25:35,732 main.py:50] epoch 424, training loss: 6330.31, average training loss: 9759.63, base loss: 10657.99
[INFO 2017-06-26 13:25:36,283 main.py:50] epoch 425, training loss: 6502.61, average training loss: 9751.98, base loss: 10659.47
[INFO 2017-06-26 13:25:36,832 main.py:50] epoch 426, training loss: 6327.48, average training loss: 9743.96, base loss: 10659.58
[INFO 2017-06-26 13:25:37,381 main.py:50] epoch 427, training loss: 6366.61, average training loss: 9736.07, base loss: 10659.79
[INFO 2017-06-26 13:25:37,966 main.py:50] epoch 428, training loss: 6262.64, average training loss: 9727.98, base loss: 10659.91
[INFO 2017-06-26 13:25:38,516 main.py:50] epoch 429, training loss: 6416.44, average training loss: 9720.28, base loss: 10660.67
[INFO 2017-06-26 13:25:39,073 main.py:50] epoch 430, training loss: 6228.82, average training loss: 9712.17, base loss: 10660.09
[INFO 2017-06-26 13:25:39,621 main.py:50] epoch 431, training loss: 6282.94, average training loss: 9704.24, base loss: 10660.32
[INFO 2017-06-26 13:25:40,207 main.py:50] epoch 432, training loss: 6393.58, average training loss: 9696.59, base loss: 10660.80
[INFO 2017-06-26 13:25:40,758 main.py:50] epoch 433, training loss: 6241.88, average training loss: 9688.63, base loss: 10660.77
[INFO 2017-06-26 13:25:41,307 main.py:50] epoch 434, training loss: 6217.28, average training loss: 9680.65, base loss: 10660.22
[INFO 2017-06-26 13:25:41,892 main.py:50] epoch 435, training loss: 6220.53, average training loss: 9672.71, base loss: 10660.02
[INFO 2017-06-26 13:25:42,450 main.py:50] epoch 436, training loss: 6349.29, average training loss: 9665.11, base loss: 10660.21
[INFO 2017-06-26 13:25:43,008 main.py:50] epoch 437, training loss: 6317.14, average training loss: 9657.47, base loss: 10660.72
[INFO 2017-06-26 13:25:43,593 main.py:50] epoch 438, training loss: 6421.59, average training loss: 9650.09, base loss: 10661.99
[INFO 2017-06-26 13:25:44,155 main.py:50] epoch 439, training loss: 6147.74, average training loss: 9642.13, base loss: 10661.36
[INFO 2017-06-26 13:25:44,703 main.py:50] epoch 440, training loss: 6325.08, average training loss: 9634.61, base loss: 10661.95
[INFO 2017-06-26 13:25:45,249 main.py:50] epoch 441, training loss: 6148.20, average training loss: 9626.72, base loss: 10661.39
[INFO 2017-06-26 13:25:45,806 main.py:50] epoch 442, training loss: 6133.65, average training loss: 9618.84, base loss: 10660.95
[INFO 2017-06-26 13:25:46,358 main.py:50] epoch 443, training loss: 6337.39, average training loss: 9611.45, base loss: 10662.09
[INFO 2017-06-26 13:25:46,907 main.py:50] epoch 444, training loss: 6013.61, average training loss: 9603.36, base loss: 10660.76
[INFO 2017-06-26 13:25:47,489 main.py:50] epoch 445, training loss: 6166.53, average training loss: 9595.66, base loss: 10660.70
[INFO 2017-06-26 13:25:48,049 main.py:50] epoch 446, training loss: 6212.30, average training loss: 9588.09, base loss: 10660.87
[INFO 2017-06-26 13:25:48,599 main.py:50] epoch 447, training loss: 6136.08, average training loss: 9580.38, base loss: 10659.99
[INFO 2017-06-26 13:25:49,146 main.py:50] epoch 448, training loss: 6119.88, average training loss: 9572.68, base loss: 10659.48
[INFO 2017-06-26 13:25:49,728 main.py:50] epoch 449, training loss: 6183.45, average training loss: 9565.14, base loss: 10659.00
[INFO 2017-06-26 13:25:50,277 main.py:50] epoch 450, training loss: 6288.85, average training loss: 9557.88, base loss: 10659.00
[INFO 2017-06-26 13:25:50,828 main.py:50] epoch 451, training loss: 6134.16, average training loss: 9550.31, base loss: 10658.38
[INFO 2017-06-26 13:25:51,375 main.py:50] epoch 452, training loss: 6218.80, average training loss: 9542.95, base loss: 10658.54
[INFO 2017-06-26 13:25:51,958 main.py:50] epoch 453, training loss: 6328.94, average training loss: 9535.87, base loss: 10658.75
[INFO 2017-06-26 13:25:52,518 main.py:50] epoch 454, training loss: 6245.48, average training loss: 9528.64, base loss: 10659.43
[INFO 2017-06-26 13:25:53,070 main.py:50] epoch 455, training loss: 6023.19, average training loss: 9520.95, base loss: 10658.56
[INFO 2017-06-26 13:25:53,653 main.py:50] epoch 456, training loss: 6189.02, average training loss: 9513.66, base loss: 10658.43
[INFO 2017-06-26 13:25:54,216 main.py:50] epoch 457, training loss: 6413.93, average training loss: 9506.89, base loss: 10659.66
[INFO 2017-06-26 13:25:54,812 main.py:50] epoch 458, training loss: 6306.02, average training loss: 9499.92, base loss: 10660.00
[INFO 2017-06-26 13:25:55,362 main.py:50] epoch 459, training loss: 6239.14, average training loss: 9492.83, base loss: 10660.51
[INFO 2017-06-26 13:25:55,914 main.py:50] epoch 460, training loss: 6113.40, average training loss: 9485.50, base loss: 10660.66
[INFO 2017-06-26 13:25:56,498 main.py:50] epoch 461, training loss: 6135.30, average training loss: 9478.25, base loss: 10660.46
[INFO 2017-06-26 13:25:57,047 main.py:50] epoch 462, training loss: 6094.70, average training loss: 9470.94, base loss: 10660.01
[INFO 2017-06-26 13:25:57,641 main.py:50] epoch 463, training loss: 6345.36, average training loss: 9464.21, base loss: 10660.48
[INFO 2017-06-26 13:25:58,225 main.py:50] epoch 464, training loss: 6273.41, average training loss: 9457.34, base loss: 10660.87
[INFO 2017-06-26 13:25:58,790 main.py:50] epoch 465, training loss: 6136.74, average training loss: 9450.22, base loss: 10660.38
[INFO 2017-06-26 13:25:59,388 main.py:50] epoch 466, training loss: 6079.12, average training loss: 9443.00, base loss: 10659.56
[INFO 2017-06-26 13:25:59,951 main.py:50] epoch 467, training loss: 6330.82, average training loss: 9436.35, base loss: 10660.26
[INFO 2017-06-26 13:26:00,536 main.py:50] epoch 468, training loss: 6043.83, average training loss: 9429.12, base loss: 10659.73
[INFO 2017-06-26 13:26:01,112 main.py:50] epoch 469, training loss: 6221.73, average training loss: 9422.29, base loss: 10659.77
[INFO 2017-06-26 13:26:01,696 main.py:50] epoch 470, training loss: 5996.89, average training loss: 9415.02, base loss: 10658.86
[INFO 2017-06-26 13:26:02,245 main.py:50] epoch 471, training loss: 6089.51, average training loss: 9407.97, base loss: 10658.95
[INFO 2017-06-26 13:26:02,801 main.py:50] epoch 472, training loss: 6098.43, average training loss: 9400.98, base loss: 10658.27
[INFO 2017-06-26 13:26:03,348 main.py:50] epoch 473, training loss: 6087.52, average training loss: 9393.99, base loss: 10657.86
[INFO 2017-06-26 13:26:03,934 main.py:50] epoch 474, training loss: 6234.69, average training loss: 9387.34, base loss: 10658.23
[INFO 2017-06-26 13:26:04,520 main.py:50] epoch 475, training loss: 6101.26, average training loss: 9380.43, base loss: 10658.26
[INFO 2017-06-26 13:26:05,070 main.py:50] epoch 476, training loss: 6157.56, average training loss: 9373.68, base loss: 10658.00
[INFO 2017-06-26 13:26:05,622 main.py:50] epoch 477, training loss: 6200.23, average training loss: 9367.04, base loss: 10658.16
[INFO 2017-06-26 13:26:06,206 main.py:50] epoch 478, training loss: 6004.61, average training loss: 9360.02, base loss: 10657.48
[INFO 2017-06-26 13:26:06,761 main.py:50] epoch 479, training loss: 6087.22, average training loss: 9353.20, base loss: 10657.21
[INFO 2017-06-26 13:26:07,310 main.py:50] epoch 480, training loss: 6252.79, average training loss: 9346.75, base loss: 10657.75
[INFO 2017-06-26 13:26:07,858 main.py:50] epoch 481, training loss: 6104.07, average training loss: 9340.02, base loss: 10657.30
[INFO 2017-06-26 13:26:08,444 main.py:50] epoch 482, training loss: 6107.36, average training loss: 9333.33, base loss: 10657.36
[INFO 2017-06-26 13:26:08,996 main.py:50] epoch 483, training loss: 6334.30, average training loss: 9327.14, base loss: 10658.08
[INFO 2017-06-26 13:26:09,582 main.py:50] epoch 484, training loss: 6176.13, average training loss: 9320.64, base loss: 10657.87
[INFO 2017-06-26 13:26:10,141 main.py:50] epoch 485, training loss: 6234.84, average training loss: 9314.29, base loss: 10658.24
[INFO 2017-06-26 13:26:10,725 main.py:50] epoch 486, training loss: 6135.15, average training loss: 9307.76, base loss: 10658.17
[INFO 2017-06-26 13:26:11,289 main.py:50] epoch 487, training loss: 6027.47, average training loss: 9301.04, base loss: 10657.40
[INFO 2017-06-26 13:26:11,839 main.py:50] epoch 488, training loss: 6106.00, average training loss: 9294.51, base loss: 10657.21
[INFO 2017-06-26 13:26:12,425 main.py:50] epoch 489, training loss: 6148.11, average training loss: 9288.08, base loss: 10657.63
[INFO 2017-06-26 13:26:13,012 main.py:50] epoch 490, training loss: 6013.54, average training loss: 9281.42, base loss: 10656.98
[INFO 2017-06-26 13:26:13,571 main.py:50] epoch 491, training loss: 6164.36, average training loss: 9275.08, base loss: 10657.50
[INFO 2017-06-26 13:26:14,126 main.py:50] epoch 492, training loss: 6072.30, average training loss: 9268.58, base loss: 10657.66
[INFO 2017-06-26 13:26:14,708 main.py:50] epoch 493, training loss: 5849.74, average training loss: 9261.66, base loss: 10656.23
[INFO 2017-06-26 13:26:15,257 main.py:50] epoch 494, training loss: 6123.91, average training loss: 9255.32, base loss: 10656.40
[INFO 2017-06-26 13:26:15,840 main.py:50] epoch 495, training loss: 5879.72, average training loss: 9248.52, base loss: 10655.62
[INFO 2017-06-26 13:26:16,392 main.py:50] epoch 496, training loss: 6176.23, average training loss: 9242.34, base loss: 10656.22
[INFO 2017-06-26 13:26:16,986 main.py:50] epoch 497, training loss: 6075.91, average training loss: 9235.98, base loss: 10656.37
[INFO 2017-06-26 13:26:17,536 main.py:50] epoch 498, training loss: 6118.03, average training loss: 9229.73, base loss: 10656.71
[INFO 2017-06-26 13:26:18,121 main.py:50] epoch 499, training loss: 5968.43, average training loss: 9223.21, base loss: 10656.42
[INFO 2017-06-26 13:26:18,121 main.py:52] epoch 499, testing
[INFO 2017-06-26 13:26:20,345 main.py:103] average testing loss: 6122.58, base loss: 10804.66
[INFO 2017-06-26 13:26:20,346 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:26:20,355 main.py:76] current best accuracy: 6122.58
[INFO 2017-06-26 13:26:20,907 main.py:50] epoch 500, training loss: 6143.99, average training loss: 9217.06, base loss: 10657.19
[INFO 2017-06-26 13:26:21,457 main.py:50] epoch 501, training loss: 5936.38, average training loss: 9210.53, base loss: 10656.11
[INFO 2017-06-26 13:26:22,005 main.py:50] epoch 502, training loss: 6077.57, average training loss: 9204.30, base loss: 10655.96
[INFO 2017-06-26 13:26:22,557 main.py:50] epoch 503, training loss: 6090.80, average training loss: 9198.12, base loss: 10656.30
[INFO 2017-06-26 13:26:23,106 main.py:50] epoch 504, training loss: 6141.67, average training loss: 9192.07, base loss: 10657.01
[INFO 2017-06-26 13:26:23,665 main.py:50] epoch 505, training loss: 6359.02, average training loss: 9186.47, base loss: 10658.27
[INFO 2017-06-26 13:26:24,212 main.py:50] epoch 506, training loss: 6170.70, average training loss: 9180.52, base loss: 10659.13
[INFO 2017-06-26 13:26:24,761 main.py:50] epoch 507, training loss: 6074.30, average training loss: 9174.41, base loss: 10659.56
[INFO 2017-06-26 13:26:25,308 main.py:50] epoch 508, training loss: 5822.49, average training loss: 9167.82, base loss: 10658.34
[INFO 2017-06-26 13:26:25,871 main.py:50] epoch 509, training loss: 6025.11, average training loss: 9161.66, base loss: 10657.97
[INFO 2017-06-26 13:26:26,444 main.py:50] epoch 510, training loss: 6056.83, average training loss: 9155.58, base loss: 10657.87
[INFO 2017-06-26 13:26:26,994 main.py:50] epoch 511, training loss: 5995.57, average training loss: 9149.41, base loss: 10657.27
[INFO 2017-06-26 13:26:27,553 main.py:50] epoch 512, training loss: 5819.75, average training loss: 9142.92, base loss: 10656.58
[INFO 2017-06-26 13:26:28,143 main.py:50] epoch 513, training loss: 6040.65, average training loss: 9136.88, base loss: 10656.40
[INFO 2017-06-26 13:26:28,735 main.py:50] epoch 514, training loss: 5889.70, average training loss: 9130.58, base loss: 10655.67
[INFO 2017-06-26 13:26:29,312 main.py:50] epoch 515, training loss: 6177.04, average training loss: 9124.85, base loss: 10656.70
[INFO 2017-06-26 13:26:29,900 main.py:50] epoch 516, training loss: 5997.06, average training loss: 9118.80, base loss: 10656.52
[INFO 2017-06-26 13:26:30,486 main.py:50] epoch 517, training loss: 6097.14, average training loss: 9112.97, base loss: 10657.00
[INFO 2017-06-26 13:26:31,035 main.py:50] epoch 518, training loss: 5996.76, average training loss: 9106.97, base loss: 10657.21
[INFO 2017-06-26 13:26:31,585 main.py:50] epoch 519, training loss: 5985.65, average training loss: 9100.96, base loss: 10657.16
[INFO 2017-06-26 13:26:32,166 main.py:50] epoch 520, training loss: 6008.46, average training loss: 9095.03, base loss: 10657.30
[INFO 2017-06-26 13:26:32,731 main.py:50] epoch 521, training loss: 6015.94, average training loss: 9089.13, base loss: 10657.59
[INFO 2017-06-26 13:26:33,317 main.py:50] epoch 522, training loss: 6161.78, average training loss: 9083.53, base loss: 10658.63
[INFO 2017-06-26 13:26:33,869 main.py:50] epoch 523, training loss: 6050.44, average training loss: 9077.74, base loss: 10659.39
[INFO 2017-06-26 13:26:34,456 main.py:50] epoch 524, training loss: 5926.39, average training loss: 9071.74, base loss: 10659.08
[INFO 2017-06-26 13:26:35,041 main.py:50] epoch 525, training loss: 6071.30, average training loss: 9066.04, base loss: 10659.03
[INFO 2017-06-26 13:26:35,614 main.py:50] epoch 526, training loss: 5922.33, average training loss: 9060.07, base loss: 10658.71
[INFO 2017-06-26 13:26:36,200 main.py:50] epoch 527, training loss: 6016.15, average training loss: 9054.31, base loss: 10658.80
[INFO 2017-06-26 13:26:36,750 main.py:50] epoch 528, training loss: 6202.81, average training loss: 9048.92, base loss: 10659.88
[INFO 2017-06-26 13:26:37,316 main.py:50] epoch 529, training loss: 6010.00, average training loss: 9043.18, base loss: 10659.76
[INFO 2017-06-26 13:26:37,868 main.py:50] epoch 530, training loss: 5755.24, average training loss: 9036.99, base loss: 10658.97
[INFO 2017-06-26 13:26:38,417 main.py:50] epoch 531, training loss: 6508.42, average training loss: 9032.24, base loss: 10660.69
[INFO 2017-06-26 13:26:38,966 main.py:50] epoch 532, training loss: 5931.31, average training loss: 9026.42, base loss: 10660.39
[INFO 2017-06-26 13:26:39,516 main.py:50] epoch 533, training loss: 6015.94, average training loss: 9020.78, base loss: 10660.38
[INFO 2017-06-26 13:26:40,066 main.py:50] epoch 534, training loss: 6111.25, average training loss: 9015.34, base loss: 10660.77
[INFO 2017-06-26 13:26:40,617 main.py:50] epoch 535, training loss: 5878.71, average training loss: 9009.49, base loss: 10659.68
[INFO 2017-06-26 13:26:41,167 main.py:50] epoch 536, training loss: 5964.55, average training loss: 9003.82, base loss: 10659.91
[INFO 2017-06-26 13:26:41,716 main.py:50] epoch 537, training loss: 6056.79, average training loss: 8998.34, base loss: 10660.16
[INFO 2017-06-26 13:26:42,268 main.py:50] epoch 538, training loss: 6011.00, average training loss: 8992.80, base loss: 10660.33
[INFO 2017-06-26 13:26:42,816 main.py:50] epoch 539, training loss: 5857.06, average training loss: 8987.00, base loss: 10659.50
[INFO 2017-06-26 13:26:43,364 main.py:50] epoch 540, training loss: 6006.13, average training loss: 8981.49, base loss: 10659.45
[INFO 2017-06-26 13:26:43,913 main.py:50] epoch 541, training loss: 5901.70, average training loss: 8975.80, base loss: 10659.17
[INFO 2017-06-26 13:26:44,462 main.py:50] epoch 542, training loss: 5964.99, average training loss: 8970.26, base loss: 10658.95
[INFO 2017-06-26 13:26:45,011 main.py:50] epoch 543, training loss: 6163.97, average training loss: 8965.10, base loss: 10659.90
[INFO 2017-06-26 13:26:45,561 main.py:50] epoch 544, training loss: 5795.03, average training loss: 8959.28, base loss: 10659.44
[INFO 2017-06-26 13:26:46,111 main.py:50] epoch 545, training loss: 5951.37, average training loss: 8953.77, base loss: 10659.28
[INFO 2017-06-26 13:26:46,660 main.py:50] epoch 546, training loss: 6054.35, average training loss: 8948.47, base loss: 10659.91
[INFO 2017-06-26 13:26:47,208 main.py:50] epoch 547, training loss: 6001.02, average training loss: 8943.10, base loss: 10660.12
[INFO 2017-06-26 13:26:47,757 main.py:50] epoch 548, training loss: 5811.40, average training loss: 8937.39, base loss: 10659.08
[INFO 2017-06-26 13:26:48,307 main.py:50] epoch 549, training loss: 5932.24, average training loss: 8931.93, base loss: 10659.15
[INFO 2017-06-26 13:26:48,856 main.py:50] epoch 550, training loss: 5787.79, average training loss: 8926.22, base loss: 10658.13
[INFO 2017-06-26 13:26:49,407 main.py:50] epoch 551, training loss: 5958.83, average training loss: 8920.84, base loss: 10658.42
[INFO 2017-06-26 13:26:49,957 main.py:50] epoch 552, training loss: 5906.74, average training loss: 8915.39, base loss: 10658.39
[INFO 2017-06-26 13:26:50,507 main.py:50] epoch 553, training loss: 5918.13, average training loss: 8909.98, base loss: 10658.10
[INFO 2017-06-26 13:26:51,073 main.py:50] epoch 554, training loss: 5845.18, average training loss: 8904.46, base loss: 10657.88
[INFO 2017-06-26 13:26:51,622 main.py:50] epoch 555, training loss: 5945.47, average training loss: 8899.14, base loss: 10657.81
[INFO 2017-06-26 13:26:52,205 main.py:50] epoch 556, training loss: 5777.22, average training loss: 8893.54, base loss: 10657.32
[INFO 2017-06-26 13:26:52,796 main.py:50] epoch 557, training loss: 5850.68, average training loss: 8888.08, base loss: 10656.50
[INFO 2017-06-26 13:26:53,386 main.py:50] epoch 558, training loss: 5976.72, average training loss: 8882.87, base loss: 10656.73
[INFO 2017-06-26 13:26:53,951 main.py:50] epoch 559, training loss: 5872.15, average training loss: 8877.50, base loss: 10656.54
[INFO 2017-06-26 13:26:54,551 main.py:50] epoch 560, training loss: 5861.49, average training loss: 8872.12, base loss: 10656.05
[INFO 2017-06-26 13:26:55,102 main.py:50] epoch 561, training loss: 5842.09, average training loss: 8866.73, base loss: 10655.74
[INFO 2017-06-26 13:26:55,651 main.py:50] epoch 562, training loss: 5981.04, average training loss: 8861.60, base loss: 10655.94
[INFO 2017-06-26 13:26:56,203 main.py:50] epoch 563, training loss: 5862.80, average training loss: 8856.29, base loss: 10655.29
[INFO 2017-06-26 13:26:56,756 main.py:50] epoch 564, training loss: 5787.09, average training loss: 8850.86, base loss: 10654.92
[INFO 2017-06-26 13:26:57,304 main.py:50] epoch 565, training loss: 5622.81, average training loss: 8845.15, base loss: 10653.37
[INFO 2017-06-26 13:26:57,852 main.py:50] epoch 566, training loss: 6082.65, average training loss: 8840.28, base loss: 10654.21
[INFO 2017-06-26 13:26:58,399 main.py:50] epoch 567, training loss: 5790.42, average training loss: 8834.91, base loss: 10653.66
[INFO 2017-06-26 13:26:58,946 main.py:50] epoch 568, training loss: 5889.96, average training loss: 8829.73, base loss: 10654.06
[INFO 2017-06-26 13:26:59,495 main.py:50] epoch 569, training loss: 5928.11, average training loss: 8824.64, base loss: 10654.28
[INFO 2017-06-26 13:27:00,043 main.py:50] epoch 570, training loss: 5847.04, average training loss: 8819.43, base loss: 10654.40
[INFO 2017-06-26 13:27:00,592 main.py:50] epoch 571, training loss: 5789.56, average training loss: 8814.13, base loss: 10653.78
[INFO 2017-06-26 13:27:01,140 main.py:50] epoch 572, training loss: 5955.36, average training loss: 8809.14, base loss: 10654.07
[INFO 2017-06-26 13:27:01,689 main.py:50] epoch 573, training loss: 5815.04, average training loss: 8803.93, base loss: 10653.52
[INFO 2017-06-26 13:27:02,237 main.py:50] epoch 574, training loss: 5874.19, average training loss: 8798.83, base loss: 10653.61
[INFO 2017-06-26 13:27:02,785 main.py:50] epoch 575, training loss: 5896.51, average training loss: 8793.79, base loss: 10654.21
[INFO 2017-06-26 13:27:03,333 main.py:50] epoch 576, training loss: 5869.00, average training loss: 8788.72, base loss: 10654.55
[INFO 2017-06-26 13:27:03,882 main.py:50] epoch 577, training loss: 5904.66, average training loss: 8783.73, base loss: 10654.65
[INFO 2017-06-26 13:27:04,433 main.py:50] epoch 578, training loss: 5984.74, average training loss: 8778.90, base loss: 10654.90
[INFO 2017-06-26 13:27:04,982 main.py:50] epoch 579, training loss: 5687.92, average training loss: 8773.57, base loss: 10653.93
[INFO 2017-06-26 13:27:05,533 main.py:50] epoch 580, training loss: 5879.12, average training loss: 8768.59, base loss: 10653.62
[INFO 2017-06-26 13:27:06,098 main.py:50] epoch 581, training loss: 5816.57, average training loss: 8763.52, base loss: 10653.13
[INFO 2017-06-26 13:27:06,648 main.py:50] epoch 582, training loss: 6134.52, average training loss: 8759.01, base loss: 10654.49
[INFO 2017-06-26 13:27:07,203 main.py:50] epoch 583, training loss: 5988.61, average training loss: 8754.26, base loss: 10654.57
[INFO 2017-06-26 13:27:07,751 main.py:50] epoch 584, training loss: 5919.50, average training loss: 8749.42, base loss: 10655.33
[INFO 2017-06-26 13:27:08,300 main.py:50] epoch 585, training loss: 5833.25, average training loss: 8744.44, base loss: 10654.76
[INFO 2017-06-26 13:27:08,848 main.py:50] epoch 586, training loss: 5897.71, average training loss: 8739.59, base loss: 10654.76
[INFO 2017-06-26 13:27:09,399 main.py:50] epoch 587, training loss: 5872.98, average training loss: 8734.72, base loss: 10654.80
[INFO 2017-06-26 13:27:09,947 main.py:50] epoch 588, training loss: 5834.97, average training loss: 8729.79, base loss: 10654.74
[INFO 2017-06-26 13:27:10,496 main.py:50] epoch 589, training loss: 5902.64, average training loss: 8725.00, base loss: 10655.18
[INFO 2017-06-26 13:27:11,047 main.py:50] epoch 590, training loss: 5881.34, average training loss: 8720.19, base loss: 10655.42
[INFO 2017-06-26 13:27:11,594 main.py:50] epoch 591, training loss: 5754.62, average training loss: 8715.18, base loss: 10655.00
[INFO 2017-06-26 13:27:12,145 main.py:50] epoch 592, training loss: 5892.53, average training loss: 8710.42, base loss: 10655.02
[INFO 2017-06-26 13:27:12,695 main.py:50] epoch 593, training loss: 5691.97, average training loss: 8705.34, base loss: 10654.52
[INFO 2017-06-26 13:27:13,278 main.py:50] epoch 594, training loss: 5721.61, average training loss: 8700.32, base loss: 10654.34
[INFO 2017-06-26 13:27:13,829 main.py:50] epoch 595, training loss: 5826.80, average training loss: 8695.50, base loss: 10654.16
[INFO 2017-06-26 13:27:14,381 main.py:50] epoch 596, training loss: 5855.31, average training loss: 8690.75, base loss: 10654.47
[INFO 2017-06-26 13:27:14,930 main.py:50] epoch 597, training loss: 5926.34, average training loss: 8686.12, base loss: 10654.87
[INFO 2017-06-26 13:27:15,478 main.py:50] epoch 598, training loss: 5655.81, average training loss: 8681.06, base loss: 10654.42
[INFO 2017-06-26 13:27:16,027 main.py:50] epoch 599, training loss: 5748.70, average training loss: 8676.18, base loss: 10654.06
[INFO 2017-06-26 13:27:16,027 main.py:52] epoch 599, testing
[INFO 2017-06-26 13:27:18,216 main.py:103] average testing loss: 5825.93, base loss: 10680.71
[INFO 2017-06-26 13:27:18,216 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:27:18,222 main.py:76] current best accuracy: 5825.93
[INFO 2017-06-26 13:27:18,803 main.py:50] epoch 600, training loss: 5819.33, average training loss: 8671.42, base loss: 10654.46
[INFO 2017-06-26 13:27:19,363 main.py:50] epoch 601, training loss: 5874.95, average training loss: 8666.78, base loss: 10654.54
[INFO 2017-06-26 13:27:19,950 main.py:50] epoch 602, training loss: 5760.53, average training loss: 8661.96, base loss: 10653.93
[INFO 2017-06-26 13:27:20,499 main.py:50] epoch 603, training loss: 5971.91, average training loss: 8657.50, base loss: 10654.28
[INFO 2017-06-26 13:27:21,087 main.py:50] epoch 604, training loss: 5687.87, average training loss: 8652.60, base loss: 10653.83
[INFO 2017-06-26 13:27:21,655 main.py:50] epoch 605, training loss: 5795.28, average training loss: 8647.88, base loss: 10653.39
[INFO 2017-06-26 13:27:22,222 main.py:50] epoch 606, training loss: 5698.42, average training loss: 8643.02, base loss: 10652.70
[INFO 2017-06-26 13:27:22,774 main.py:50] epoch 607, training loss: 5812.15, average training loss: 8638.37, base loss: 10652.40
[INFO 2017-06-26 13:27:23,367 main.py:50] epoch 608, training loss: 5737.67, average training loss: 8633.60, base loss: 10651.80
[INFO 2017-06-26 13:27:23,930 main.py:50] epoch 609, training loss: 5759.65, average training loss: 8628.89, base loss: 10651.45
[INFO 2017-06-26 13:27:24,520 main.py:50] epoch 610, training loss: 6002.54, average training loss: 8624.59, base loss: 10652.11
[INFO 2017-06-26 13:27:25,083 main.py:50] epoch 611, training loss: 5681.16, average training loss: 8619.78, base loss: 10651.92
[INFO 2017-06-26 13:27:25,634 main.py:50] epoch 612, training loss: 5739.12, average training loss: 8615.08, base loss: 10651.56
[INFO 2017-06-26 13:27:26,183 main.py:50] epoch 613, training loss: 5803.40, average training loss: 8610.51, base loss: 10651.57
[INFO 2017-06-26 13:27:26,731 main.py:50] epoch 614, training loss: 5677.68, average training loss: 8605.74, base loss: 10651.07
[INFO 2017-06-26 13:27:27,278 main.py:50] epoch 615, training loss: 5497.50, average training loss: 8600.69, base loss: 10649.83
[INFO 2017-06-26 13:27:27,826 main.py:50] epoch 616, training loss: 5882.73, average training loss: 8596.29, base loss: 10649.94
[INFO 2017-06-26 13:27:28,373 main.py:50] epoch 617, training loss: 5831.66, average training loss: 8591.81, base loss: 10650.00
[INFO 2017-06-26 13:27:28,920 main.py:50] epoch 618, training loss: 5647.32, average training loss: 8587.05, base loss: 10649.18
[INFO 2017-06-26 13:27:29,468 main.py:50] epoch 619, training loss: 5701.34, average training loss: 8582.40, base loss: 10649.35
[INFO 2017-06-26 13:27:30,016 main.py:50] epoch 620, training loss: 5935.51, average training loss: 8578.14, base loss: 10650.00
[INFO 2017-06-26 13:27:30,561 main.py:50] epoch 621, training loss: 5774.64, average training loss: 8573.63, base loss: 10649.66
[INFO 2017-06-26 13:27:31,109 main.py:50] epoch 622, training loss: 6031.72, average training loss: 8569.55, base loss: 10651.07
[INFO 2017-06-26 13:27:31,658 main.py:50] epoch 623, training loss: 5754.40, average training loss: 8565.04, base loss: 10651.04
[INFO 2017-06-26 13:27:32,206 main.py:50] epoch 624, training loss: 5759.63, average training loss: 8560.55, base loss: 10651.07
[INFO 2017-06-26 13:27:32,753 main.py:50] epoch 625, training loss: 5691.30, average training loss: 8555.97, base loss: 10650.91
[INFO 2017-06-26 13:27:33,302 main.py:50] epoch 626, training loss: 5835.90, average training loss: 8551.63, base loss: 10651.26
[INFO 2017-06-26 13:27:33,887 main.py:50] epoch 627, training loss: 5791.47, average training loss: 8547.23, base loss: 10651.61
[INFO 2017-06-26 13:27:34,450 main.py:50] epoch 628, training loss: 5678.22, average training loss: 8542.67, base loss: 10650.72
[INFO 2017-06-26 13:27:35,002 main.py:50] epoch 629, training loss: 5753.40, average training loss: 8538.25, base loss: 10650.49
[INFO 2017-06-26 13:27:35,569 main.py:50] epoch 630, training loss: 5602.37, average training loss: 8533.59, base loss: 10650.15
[INFO 2017-06-26 13:27:36,120 main.py:50] epoch 631, training loss: 5664.76, average training loss: 8529.05, base loss: 10649.38
[INFO 2017-06-26 13:27:36,701 main.py:50] epoch 632, training loss: 5758.14, average training loss: 8524.68, base loss: 10649.33
[INFO 2017-06-26 13:27:37,249 main.py:50] epoch 633, training loss: 5805.38, average training loss: 8520.39, base loss: 10649.65
[INFO 2017-06-26 13:27:37,796 main.py:50] epoch 634, training loss: 5798.09, average training loss: 8516.10, base loss: 10649.75
[INFO 2017-06-26 13:27:38,378 main.py:50] epoch 635, training loss: 5763.69, average training loss: 8511.77, base loss: 10649.90
[INFO 2017-06-26 13:27:38,955 main.py:50] epoch 636, training loss: 5799.49, average training loss: 8507.51, base loss: 10650.16
[INFO 2017-06-26 13:27:39,509 main.py:50] epoch 637, training loss: 5668.44, average training loss: 8503.06, base loss: 10649.54
[INFO 2017-06-26 13:27:40,096 main.py:50] epoch 638, training loss: 5902.83, average training loss: 8498.99, base loss: 10649.97
[INFO 2017-06-26 13:27:40,665 main.py:50] epoch 639, training loss: 5579.92, average training loss: 8494.43, base loss: 10649.25
[INFO 2017-06-26 13:27:41,250 main.py:50] epoch 640, training loss: 5911.69, average training loss: 8490.40, base loss: 10649.84
[INFO 2017-06-26 13:27:41,802 main.py:50] epoch 641, training loss: 5704.06, average training loss: 8486.06, base loss: 10650.13
[INFO 2017-06-26 13:27:42,349 main.py:50] epoch 642, training loss: 5614.21, average training loss: 8481.60, base loss: 10649.52
[INFO 2017-06-26 13:27:42,899 main.py:50] epoch 643, training loss: 5639.60, average training loss: 8477.19, base loss: 10649.34
[INFO 2017-06-26 13:27:43,450 main.py:50] epoch 644, training loss: 5736.60, average training loss: 8472.94, base loss: 10649.41
[INFO 2017-06-26 13:27:43,998 main.py:50] epoch 645, training loss: 5713.55, average training loss: 8468.66, base loss: 10649.17
[INFO 2017-06-26 13:27:44,547 main.py:50] epoch 646, training loss: 5616.60, average training loss: 8464.26, base loss: 10648.45
[INFO 2017-06-26 13:27:45,098 main.py:50] epoch 647, training loss: 5935.47, average training loss: 8460.35, base loss: 10648.80
[INFO 2017-06-26 13:27:45,650 main.py:50] epoch 648, training loss: 5751.12, average training loss: 8456.18, base loss: 10648.71
[INFO 2017-06-26 13:27:46,197 main.py:50] epoch 649, training loss: 5857.45, average training loss: 8452.18, base loss: 10649.39
[INFO 2017-06-26 13:27:46,745 main.py:50] epoch 650, training loss: 5808.73, average training loss: 8448.12, base loss: 10649.80
[INFO 2017-06-26 13:27:47,292 main.py:50] epoch 651, training loss: 5726.17, average training loss: 8443.95, base loss: 10649.64
[INFO 2017-06-26 13:27:47,840 main.py:50] epoch 652, training loss: 5768.34, average training loss: 8439.85, base loss: 10649.70
[INFO 2017-06-26 13:27:48,389 main.py:50] epoch 653, training loss: 5760.42, average training loss: 8435.75, base loss: 10649.75
[INFO 2017-06-26 13:27:48,937 main.py:50] epoch 654, training loss: 5783.32, average training loss: 8431.70, base loss: 10649.94
[INFO 2017-06-26 13:27:49,486 main.py:50] epoch 655, training loss: 5794.53, average training loss: 8427.68, base loss: 10650.09
[INFO 2017-06-26 13:27:50,035 main.py:50] epoch 656, training loss: 5759.01, average training loss: 8423.62, base loss: 10650.42
[INFO 2017-06-26 13:27:50,584 main.py:50] epoch 657, training loss: 5638.12, average training loss: 8419.39, base loss: 10650.39
[INFO 2017-06-26 13:27:51,132 main.py:50] epoch 658, training loss: 5823.53, average training loss: 8415.45, base loss: 10650.88
[INFO 2017-06-26 13:27:51,683 main.py:50] epoch 659, training loss: 5751.96, average training loss: 8411.41, base loss: 10650.78
[INFO 2017-06-26 13:27:52,234 main.py:50] epoch 660, training loss: 5623.81, average training loss: 8407.20, base loss: 10650.63
[INFO 2017-06-26 13:27:52,787 main.py:50] epoch 661, training loss: 5698.20, average training loss: 8403.10, base loss: 10650.64
[INFO 2017-06-26 13:27:53,372 main.py:50] epoch 662, training loss: 5622.24, average training loss: 8398.91, base loss: 10650.51
[INFO 2017-06-26 13:27:53,922 main.py:50] epoch 663, training loss: 5774.46, average training loss: 8394.96, base loss: 10650.68
[INFO 2017-06-26 13:27:54,483 main.py:50] epoch 664, training loss: 5780.00, average training loss: 8391.02, base loss: 10650.89
[INFO 2017-06-26 13:27:55,071 main.py:50] epoch 665, training loss: 5652.09, average training loss: 8386.91, base loss: 10650.80
[INFO 2017-06-26 13:27:55,656 main.py:50] epoch 666, training loss: 5716.52, average training loss: 8382.91, base loss: 10650.68
[INFO 2017-06-26 13:27:56,225 main.py:50] epoch 667, training loss: 5781.27, average training loss: 8379.01, base loss: 10651.11
[INFO 2017-06-26 13:27:56,847 main.py:50] epoch 668, training loss: 5486.38, average training loss: 8374.69, base loss: 10650.12
[INFO 2017-06-26 13:27:57,396 main.py:50] epoch 669, training loss: 5629.64, average training loss: 8370.59, base loss: 10649.98
[INFO 2017-06-26 13:27:57,945 main.py:50] epoch 670, training loss: 5823.67, average training loss: 8366.80, base loss: 10650.60
[INFO 2017-06-26 13:27:58,493 main.py:50] epoch 671, training loss: 5928.89, average training loss: 8363.17, base loss: 10651.39
[INFO 2017-06-26 13:27:59,040 main.py:50] epoch 672, training loss: 5643.01, average training loss: 8359.13, base loss: 10650.86
[INFO 2017-06-26 13:27:59,621 main.py:50] epoch 673, training loss: 5818.69, average training loss: 8355.36, base loss: 10651.27
[INFO 2017-06-26 13:28:00,173 main.py:50] epoch 674, training loss: 5665.47, average training loss: 8351.37, base loss: 10651.36
[INFO 2017-06-26 13:28:00,769 main.py:50] epoch 675, training loss: 5817.18, average training loss: 8347.62, base loss: 10651.93
[INFO 2017-06-26 13:28:01,317 main.py:50] epoch 676, training loss: 5658.96, average training loss: 8343.65, base loss: 10651.83
[INFO 2017-06-26 13:28:01,865 main.py:50] epoch 677, training loss: 5544.17, average training loss: 8339.52, base loss: 10651.47
[INFO 2017-06-26 13:28:02,412 main.py:50] epoch 678, training loss: 5842.70, average training loss: 8335.85, base loss: 10651.72
[INFO 2017-06-26 13:28:02,962 main.py:50] epoch 679, training loss: 5609.27, average training loss: 8331.84, base loss: 10651.79
[INFO 2017-06-26 13:28:03,544 main.py:50] epoch 680, training loss: 5761.23, average training loss: 8328.06, base loss: 10652.11
[INFO 2017-06-26 13:28:04,097 main.py:50] epoch 681, training loss: 5546.96, average training loss: 8323.98, base loss: 10651.75
[INFO 2017-06-26 13:28:04,646 main.py:50] epoch 682, training loss: 5644.24, average training loss: 8320.06, base loss: 10651.54
[INFO 2017-06-26 13:28:05,228 main.py:50] epoch 683, training loss: 5505.44, average training loss: 8315.95, base loss: 10650.86
[INFO 2017-06-26 13:28:05,786 main.py:50] epoch 684, training loss: 5873.54, average training loss: 8312.38, base loss: 10651.44
[INFO 2017-06-26 13:28:06,381 main.py:50] epoch 685, training loss: 5713.56, average training loss: 8308.59, base loss: 10651.72
[INFO 2017-06-26 13:28:06,931 main.py:50] epoch 686, training loss: 5592.65, average training loss: 8304.64, base loss: 10651.22
[INFO 2017-06-26 13:28:07,483 main.py:50] epoch 687, training loss: 5507.19, average training loss: 8300.57, base loss: 10650.60
[INFO 2017-06-26 13:28:08,030 main.py:50] epoch 688, training loss: 5695.01, average training loss: 8296.79, base loss: 10650.41
[INFO 2017-06-26 13:28:08,580 main.py:50] epoch 689, training loss: 5567.91, average training loss: 8292.84, base loss: 10650.16
[INFO 2017-06-26 13:28:09,130 main.py:50] epoch 690, training loss: 5806.92, average training loss: 8289.24, base loss: 10650.54
[INFO 2017-06-26 13:28:09,678 main.py:50] epoch 691, training loss: 5646.20, average training loss: 8285.42, base loss: 10650.45
[INFO 2017-06-26 13:28:10,229 main.py:50] epoch 692, training loss: 5657.34, average training loss: 8281.63, base loss: 10650.59
[INFO 2017-06-26 13:28:10,778 main.py:50] epoch 693, training loss: 5694.62, average training loss: 8277.90, base loss: 10650.76
[INFO 2017-06-26 13:28:11,328 main.py:50] epoch 694, training loss: 5551.22, average training loss: 8273.98, base loss: 10650.53
[INFO 2017-06-26 13:28:11,877 main.py:50] epoch 695, training loss: 5406.77, average training loss: 8269.86, base loss: 10649.52
[INFO 2017-06-26 13:28:12,458 main.py:50] epoch 696, training loss: 5550.13, average training loss: 8265.95, base loss: 10649.02
[INFO 2017-06-26 13:28:13,005 main.py:50] epoch 697, training loss: 5449.02, average training loss: 8261.92, base loss: 10648.27
[INFO 2017-06-26 13:28:13,569 main.py:50] epoch 698, training loss: 5619.85, average training loss: 8258.14, base loss: 10648.22
[INFO 2017-06-26 13:28:14,118 main.py:50] epoch 699, training loss: 5677.73, average training loss: 8254.45, base loss: 10648.25
[INFO 2017-06-26 13:28:14,118 main.py:52] epoch 699, testing
[INFO 2017-06-26 13:28:16,286 main.py:103] average testing loss: 5574.45, base loss: 10543.34
[INFO 2017-06-26 13:28:16,286 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:28:16,292 main.py:76] current best accuracy: 5574.45
[INFO 2017-06-26 13:28:16,839 main.py:50] epoch 700, training loss: 5692.07, average training loss: 8250.80, base loss: 10648.67
[INFO 2017-06-26 13:28:17,387 main.py:50] epoch 701, training loss: 5539.06, average training loss: 8246.93, base loss: 10648.44
[INFO 2017-06-26 13:28:17,934 main.py:50] epoch 702, training loss: 5650.48, average training loss: 8243.24, base loss: 10648.48
[INFO 2017-06-26 13:28:18,482 main.py:50] epoch 703, training loss: 5619.52, average training loss: 8239.51, base loss: 10648.43
[INFO 2017-06-26 13:28:19,028 main.py:50] epoch 704, training loss: 5674.51, average training loss: 8235.88, base loss: 10648.54
