[INFO 2017-06-26 13:34:44,768 main.py:170] Namespace(batch_size=32, display=False, image_dir='/home/yi/Downloads/mpii-64-one-2', image_size=64, init_model_path='', input_video_path='video', learning_rate=0.001, method='unsupervised', motion_range=5, num_channel=3, num_inputs=2, output_flow_path='flow', output_flow_video_path='flow_video', save_dir='./model', test=False, test_epoch=10, test_interval=100, test_video=False, train=True, train_epoch=10000)
[INFO 2017-06-26 13:34:48,180 main.py:50] epoch 0, training loss: 150810.83, average training loss: 150810.83, base loss: 10700.86
[INFO 2017-06-26 13:34:49,832 main.py:50] epoch 1, training loss: 125374.62, average training loss: 138092.73, base loss: 10837.39
[INFO 2017-06-26 13:34:51,504 main.py:50] epoch 2, training loss: 108057.75, average training loss: 128081.07, base loss: 10813.28
[INFO 2017-06-26 13:34:53,165 main.py:50] epoch 3, training loss: 94451.09, average training loss: 119673.57, base loss: 10821.61
[INFO 2017-06-26 13:34:54,818 main.py:50] epoch 4, training loss: 82697.20, average training loss: 112278.30, base loss: 10794.11
[INFO 2017-06-26 13:34:56,470 main.py:50] epoch 5, training loss: 71545.64, average training loss: 105489.52, base loss: 10838.35
[INFO 2017-06-26 13:34:58,121 main.py:50] epoch 6, training loss: 62664.41, average training loss: 99371.65, base loss: 10709.85
[INFO 2017-06-26 13:34:59,775 main.py:50] epoch 7, training loss: 54087.70, average training loss: 93711.16, base loss: 10639.32
[INFO 2017-06-26 13:35:01,425 main.py:50] epoch 8, training loss: 47864.52, average training loss: 88617.09, base loss: 10640.48
[INFO 2017-06-26 13:35:03,082 main.py:50] epoch 9, training loss: 41529.53, average training loss: 83908.33, base loss: 10660.31
[INFO 2017-06-26 13:35:04,749 main.py:50] epoch 10, training loss: 36788.77, average training loss: 79624.73, base loss: 10656.07
[INFO 2017-06-26 13:35:06,399 main.py:50] epoch 11, training loss: 32942.77, average training loss: 75734.57, base loss: 10655.02
[INFO 2017-06-26 13:35:08,057 main.py:50] epoch 12, training loss: 30069.29, average training loss: 72221.86, base loss: 10658.26
[INFO 2017-06-26 13:35:09,719 main.py:50] epoch 13, training loss: 27080.73, average training loss: 68997.49, base loss: 10643.94
[INFO 2017-06-26 13:35:11,370 main.py:50] epoch 14, training loss: 24318.05, average training loss: 66018.86, base loss: 10607.29
[INFO 2017-06-26 13:35:13,031 main.py:50] epoch 15, training loss: 22506.59, average training loss: 63299.34, base loss: 10591.03
[INFO 2017-06-26 13:35:14,684 main.py:50] epoch 16, training loss: 21010.11, average training loss: 60811.74, base loss: 10596.23
[INFO 2017-06-26 13:35:16,339 main.py:50] epoch 17, training loss: 19681.33, average training loss: 58526.72, base loss: 10624.73
[INFO 2017-06-26 13:35:17,992 main.py:50] epoch 18, training loss: 18552.99, average training loss: 56422.84, base loss: 10643.40
[INFO 2017-06-26 13:35:19,640 main.py:50] epoch 19, training loss: 17321.33, average training loss: 54467.76, base loss: 10640.57
[INFO 2017-06-26 13:35:21,310 main.py:50] epoch 20, training loss: 16416.31, average training loss: 52655.79, base loss: 10631.61
[INFO 2017-06-26 13:35:22,962 main.py:50] epoch 21, training loss: 15926.18, average training loss: 50986.26, base loss: 10633.33
[INFO 2017-06-26 13:35:24,614 main.py:50] epoch 22, training loss: 15337.15, average training loss: 49436.30, base loss: 10640.79
[INFO 2017-06-26 13:35:26,267 main.py:50] epoch 23, training loss: 14884.53, average training loss: 47996.64, base loss: 10649.78
[INFO 2017-06-26 13:35:27,921 main.py:50] epoch 24, training loss: 14572.21, average training loss: 46659.67, base loss: 10666.77
[INFO 2017-06-26 13:35:29,579 main.py:50] epoch 25, training loss: 13583.61, average training loss: 45387.51, base loss: 10663.04
[INFO 2017-06-26 13:35:31,229 main.py:50] epoch 26, training loss: 13351.54, average training loss: 44200.99, base loss: 10662.61
[INFO 2017-06-26 13:35:32,899 main.py:50] epoch 27, training loss: 12973.75, average training loss: 43085.73, base loss: 10663.99
[INFO 2017-06-26 13:35:34,571 main.py:50] epoch 28, training loss: 12676.34, average training loss: 42037.13, base loss: 10666.13
[INFO 2017-06-26 13:35:36,221 main.py:50] epoch 29, training loss: 12337.40, average training loss: 41047.14, base loss: 10668.15
[INFO 2017-06-26 13:35:37,875 main.py:50] epoch 30, training loss: 12284.26, average training loss: 40119.31, base loss: 10677.88
[INFO 2017-06-26 13:35:39,542 main.py:50] epoch 31, training loss: 11646.11, average training loss: 39229.52, base loss: 10676.31
[INFO 2017-06-26 13:35:41,190 main.py:50] epoch 32, training loss: 11395.04, average training loss: 38386.05, base loss: 10671.85
[INFO 2017-06-26 13:35:42,843 main.py:50] epoch 33, training loss: 11284.34, average training loss: 37588.94, base loss: 10669.56
[INFO 2017-06-26 13:35:44,494 main.py:50] epoch 34, training loss: 11235.72, average training loss: 36835.99, base loss: 10670.05
[INFO 2017-06-26 13:35:46,143 main.py:50] epoch 35, training loss: 10842.03, average training loss: 36113.94, base loss: 10664.64
[INFO 2017-06-26 13:35:47,805 main.py:50] epoch 36, training loss: 10817.83, average training loss: 35430.26, base loss: 10662.23
[INFO 2017-06-26 13:35:49,456 main.py:50] epoch 37, training loss: 10779.67, average training loss: 34781.56, base loss: 10662.87
[INFO 2017-06-26 13:35:51,118 main.py:50] epoch 38, training loss: 11164.82, average training loss: 34176.00, base loss: 10676.43
[INFO 2017-06-26 13:35:52,772 main.py:50] epoch 39, training loss: 10292.17, average training loss: 33578.91, base loss: 10667.03
[INFO 2017-06-26 13:35:54,423 main.py:50] epoch 40, training loss: 10841.33, average training loss: 33024.33, base loss: 10674.00
[INFO 2017-06-26 13:35:56,083 main.py:50] epoch 41, training loss: 10685.48, average training loss: 32492.45, base loss: 10678.79
[INFO 2017-06-26 13:35:57,735 main.py:50] epoch 42, training loss: 9761.18, average training loss: 31963.82, base loss: 10660.70
[INFO 2017-06-26 13:35:59,384 main.py:50] epoch 43, training loss: 11094.10, average training loss: 31489.51, base loss: 10678.87
[INFO 2017-06-26 13:36:01,032 main.py:50] epoch 44, training loss: 9797.76, average training loss: 31007.47, base loss: 10665.04
[INFO 2017-06-26 13:36:02,684 main.py:50] epoch 45, training loss: 10282.00, average training loss: 30556.92, base loss: 10665.69
[INFO 2017-06-26 13:36:04,335 main.py:50] epoch 46, training loss: 10292.30, average training loss: 30125.75, base loss: 10667.27
[INFO 2017-06-26 13:36:05,987 main.py:50] epoch 47, training loss: 10478.68, average training loss: 29716.44, base loss: 10673.90
[INFO 2017-06-26 13:36:07,641 main.py:50] epoch 48, training loss: 10509.68, average training loss: 29324.46, base loss: 10681.87
[INFO 2017-06-26 13:36:09,294 main.py:50] epoch 49, training loss: 10452.93, average training loss: 28947.03, base loss: 10689.10
[INFO 2017-06-26 13:36:10,946 main.py:50] epoch 50, training loss: 10034.09, average training loss: 28576.19, base loss: 10687.07
[INFO 2017-06-26 13:36:12,601 main.py:50] epoch 51, training loss: 9688.58, average training loss: 28212.97, base loss: 10677.95
[INFO 2017-06-26 13:36:14,254 main.py:50] epoch 52, training loss: 10507.78, average training loss: 27878.91, base loss: 10688.96
[INFO 2017-06-26 13:36:15,905 main.py:50] epoch 53, training loss: 9984.33, average training loss: 27547.53, base loss: 10688.57
[INFO 2017-06-26 13:36:17,565 main.py:50] epoch 54, training loss: 9951.65, average training loss: 27227.60, base loss: 10686.71
[INFO 2017-06-26 13:36:19,215 main.py:50] epoch 55, training loss: 9486.63, average training loss: 26910.80, base loss: 10676.33
[INFO 2017-06-26 13:36:20,864 main.py:50] epoch 56, training loss: 9858.00, average training loss: 26611.63, base loss: 10674.87
[INFO 2017-06-26 13:36:22,519 main.py:50] epoch 57, training loss: 10269.98, average training loss: 26329.87, base loss: 10682.10
[INFO 2017-06-26 13:36:24,185 main.py:50] epoch 58, training loss: 10562.59, average training loss: 26062.63, base loss: 10695.83
[INFO 2017-06-26 13:36:25,835 main.py:50] epoch 59, training loss: 10215.55, average training loss: 25798.51, base loss: 10702.64
[INFO 2017-06-26 13:36:27,487 main.py:50] epoch 60, training loss: 10207.71, average training loss: 25542.93, base loss: 10709.21
[INFO 2017-06-26 13:36:29,142 main.py:50] epoch 61, training loss: 9630.17, average training loss: 25286.27, base loss: 10705.23
[INFO 2017-06-26 13:36:30,793 main.py:50] epoch 62, training loss: 8998.64, average training loss: 25027.74, base loss: 10689.84
[INFO 2017-06-26 13:36:32,445 main.py:50] epoch 63, training loss: 10003.84, average training loss: 24792.99, base loss: 10693.75
[INFO 2017-06-26 13:36:34,101 main.py:50] epoch 64, training loss: 9734.71, average training loss: 24561.32, base loss: 10693.31
[INFO 2017-06-26 13:36:35,751 main.py:50] epoch 65, training loss: 9138.09, average training loss: 24327.64, base loss: 10682.53
[INFO 2017-06-26 13:36:37,414 main.py:50] epoch 66, training loss: 9186.87, average training loss: 24101.66, base loss: 10673.09
[INFO 2017-06-26 13:36:39,063 main.py:50] epoch 67, training loss: 9000.89, average training loss: 23879.59, base loss: 10660.73
[INFO 2017-06-26 13:36:40,713 main.py:50] epoch 68, training loss: 9273.89, average training loss: 23667.91, base loss: 10653.68
[INFO 2017-06-26 13:36:42,369 main.py:50] epoch 69, training loss: 9741.46, average training loss: 23468.96, base loss: 10655.74
[INFO 2017-06-26 13:36:44,021 main.py:50] epoch 70, training loss: 9618.22, average training loss: 23273.88, base loss: 10656.18
[INFO 2017-06-26 13:36:45,671 main.py:50] epoch 71, training loss: 9761.31, average training loss: 23086.20, base loss: 10658.78
[INFO 2017-06-26 13:36:47,325 main.py:50] epoch 72, training loss: 9536.55, average training loss: 22900.59, base loss: 10658.08
[INFO 2017-06-26 13:36:48,988 main.py:50] epoch 73, training loss: 9835.71, average training loss: 22724.04, base loss: 10663.14
[INFO 2017-06-26 13:36:50,637 main.py:50] epoch 74, training loss: 9522.06, average training loss: 22548.01, base loss: 10663.08
[INFO 2017-06-26 13:36:52,290 main.py:50] epoch 75, training loss: 9832.87, average training loss: 22380.71, base loss: 10668.84
[INFO 2017-06-26 13:36:53,941 main.py:50] epoch 76, training loss: 9301.77, average training loss: 22210.85, base loss: 10665.87
[INFO 2017-06-26 13:36:55,589 main.py:50] epoch 77, training loss: 9652.24, average training loss: 22049.84, base loss: 10669.62
[INFO 2017-06-26 13:36:57,241 main.py:50] epoch 78, training loss: 9199.75, average training loss: 21887.19, base loss: 10665.75
[INFO 2017-06-26 13:36:58,890 main.py:50] epoch 79, training loss: 9377.24, average training loss: 21730.81, base loss: 10665.39
[INFO 2017-06-26 13:37:00,541 main.py:50] epoch 80, training loss: 9129.07, average training loss: 21575.23, base loss: 10661.26
[INFO 2017-06-26 13:37:02,217 main.py:50] epoch 81, training loss: 9807.75, average training loss: 21431.73, base loss: 10667.35
[INFO 2017-06-26 13:37:03,880 main.py:50] epoch 82, training loss: 9427.19, average training loss: 21287.09, base loss: 10668.41
[INFO 2017-06-26 13:37:05,543 main.py:50] epoch 83, training loss: 9488.17, average training loss: 21146.63, base loss: 10670.54
[INFO 2017-06-26 13:37:07,196 main.py:50] epoch 84, training loss: 9528.03, average training loss: 21009.94, base loss: 10673.01
[INFO 2017-06-26 13:37:08,846 main.py:50] epoch 85, training loss: 9578.23, average training loss: 20877.02, base loss: 10675.75
[INFO 2017-06-26 13:37:10,511 main.py:50] epoch 86, training loss: 9270.76, average training loss: 20743.61, base loss: 10675.66
[INFO 2017-06-26 13:37:12,180 main.py:50] epoch 87, training loss: 9256.97, average training loss: 20613.08, base loss: 10675.41
[INFO 2017-06-26 13:37:13,834 main.py:50] epoch 88, training loss: 9185.32, average training loss: 20484.68, base loss: 10673.39
[INFO 2017-06-26 13:37:15,484 main.py:50] epoch 89, training loss: 9015.91, average training loss: 20357.25, base loss: 10670.18
[INFO 2017-06-26 13:37:17,156 main.py:50] epoch 90, training loss: 9192.41, average training loss: 20234.56, base loss: 10670.57
[INFO 2017-06-26 13:37:18,810 main.py:50] epoch 91, training loss: 8832.30, average training loss: 20110.62, base loss: 10665.97
[INFO 2017-06-26 13:37:20,460 main.py:50] epoch 92, training loss: 8980.35, average training loss: 19990.94, base loss: 10661.89
[INFO 2017-06-26 13:37:22,113 main.py:50] epoch 93, training loss: 9252.07, average training loss: 19876.70, base loss: 10662.50
[INFO 2017-06-26 13:37:23,772 main.py:50] epoch 94, training loss: 8913.08, average training loss: 19761.29, base loss: 10659.53
[INFO 2017-06-26 13:37:25,422 main.py:50] epoch 95, training loss: 9421.38, average training loss: 19653.58, base loss: 10663.70
[INFO 2017-06-26 13:37:27,081 main.py:50] epoch 96, training loss: 9031.63, average training loss: 19544.08, base loss: 10663.18
[INFO 2017-06-26 13:37:28,733 main.py:50] epoch 97, training loss: 8765.39, average training loss: 19434.09, base loss: 10657.84
[INFO 2017-06-26 13:37:30,386 main.py:50] epoch 98, training loss: 8705.89, average training loss: 19325.72, base loss: 10653.32
[INFO 2017-06-26 13:37:32,039 main.py:50] epoch 99, training loss: 9274.16, average training loss: 19225.21, base loss: 10656.34
[INFO 2017-06-26 13:37:32,039 main.py:52] epoch 99, testing
[INFO 2017-06-26 13:37:39,372 main.py:103] average testing loss: 9022.80, base loss: 10662.27
[INFO 2017-06-26 13:37:39,373 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:37:39,379 main.py:76] current best accuracy: 9022.80
[INFO 2017-06-26 13:37:41,044 main.py:50] epoch 100, training loss: 8931.22, average training loss: 19123.29, base loss: 10654.83
[INFO 2017-06-26 13:37:42,699 main.py:50] epoch 101, training loss: 8894.26, average training loss: 19023.00, base loss: 10652.17
[INFO 2017-06-26 13:37:44,371 main.py:50] epoch 102, training loss: 8931.37, average training loss: 18925.03, base loss: 10651.34
[INFO 2017-06-26 13:37:46,025 main.py:50] epoch 103, training loss: 8880.09, average training loss: 18828.44, base loss: 10648.40
[INFO 2017-06-26 13:37:47,686 main.py:50] epoch 104, training loss: 8582.88, average training loss: 18730.86, base loss: 10643.82
[INFO 2017-06-26 13:37:49,342 main.py:50] epoch 105, training loss: 8908.60, average training loss: 18638.20, base loss: 10643.31
[INFO 2017-06-26 13:37:51,006 main.py:50] epoch 106, training loss: 8872.43, average training loss: 18546.93, base loss: 10643.64
[INFO 2017-06-26 13:37:52,656 main.py:50] epoch 107, training loss: 8462.41, average training loss: 18453.56, base loss: 10637.13
[INFO 2017-06-26 13:37:54,311 main.py:50] epoch 108, training loss: 8827.73, average training loss: 18365.25, base loss: 10634.78
[INFO 2017-06-26 13:37:55,980 main.py:50] epoch 109, training loss: 8911.33, average training loss: 18279.30, base loss: 10634.61
[INFO 2017-06-26 13:37:57,645 main.py:50] epoch 110, training loss: 8654.88, average training loss: 18192.60, base loss: 10632.59
[INFO 2017-06-26 13:37:59,301 main.py:50] epoch 111, training loss: 8486.65, average training loss: 18105.94, base loss: 10627.27
[INFO 2017-06-26 13:38:00,954 main.py:50] epoch 112, training loss: 8965.18, average training loss: 18025.04, base loss: 10628.16
[INFO 2017-06-26 13:38:02,614 main.py:50] epoch 113, training loss: 8859.78, average training loss: 17944.65, base loss: 10628.50
[INFO 2017-06-26 13:38:04,271 main.py:50] epoch 114, training loss: 8875.34, average training loss: 17865.78, base loss: 10630.09
[INFO 2017-06-26 13:38:05,923 main.py:50] epoch 115, training loss: 8655.89, average training loss: 17786.39, base loss: 10628.62
[INFO 2017-06-26 13:38:07,575 main.py:50] epoch 116, training loss: 8712.38, average training loss: 17708.83, base loss: 10627.52
[INFO 2017-06-26 13:38:09,231 main.py:50] epoch 117, training loss: 8806.94, average training loss: 17633.39, base loss: 10628.55
[INFO 2017-06-26 13:38:10,883 main.py:50] epoch 118, training loss: 8939.87, average training loss: 17560.34, base loss: 10630.75
[INFO 2017-06-26 13:38:12,536 main.py:50] epoch 119, training loss: 8492.43, average training loss: 17484.77, base loss: 10628.20
[INFO 2017-06-26 13:38:14,190 main.py:50] epoch 120, training loss: 9195.25, average training loss: 17416.26, base loss: 10633.50
[INFO 2017-06-26 13:38:15,841 main.py:50] epoch 121, training loss: 8854.10, average training loss: 17346.08, base loss: 10635.39
[INFO 2017-06-26 13:38:17,494 main.py:50] epoch 122, training loss: 8612.52, average training loss: 17275.08, base loss: 10634.91
[INFO 2017-06-26 13:38:19,153 main.py:50] epoch 123, training loss: 8579.79, average training loss: 17204.95, base loss: 10633.50
[INFO 2017-06-26 13:38:20,810 main.py:50] epoch 124, training loss: 8560.14, average training loss: 17135.80, base loss: 10632.82
[INFO 2017-06-26 13:38:22,465 main.py:50] epoch 125, training loss: 8386.62, average training loss: 17066.36, base loss: 10630.25
[INFO 2017-06-26 13:38:24,141 main.py:50] epoch 126, training loss: 8516.48, average training loss: 16999.04, base loss: 10628.83
[INFO 2017-06-26 13:38:25,796 main.py:50] epoch 127, training loss: 8437.54, average training loss: 16932.15, base loss: 10626.98
[INFO 2017-06-26 13:38:27,457 main.py:50] epoch 128, training loss: 8720.50, average training loss: 16868.49, base loss: 10628.75
[INFO 2017-06-26 13:38:29,128 main.py:50] epoch 129, training loss: 8736.95, average training loss: 16805.94, base loss: 10630.18
[INFO 2017-06-26 13:38:30,781 main.py:50] epoch 130, training loss: 8533.40, average training loss: 16742.79, base loss: 10629.33
[INFO 2017-06-26 13:38:32,433 main.py:50] epoch 131, training loss: 8552.99, average training loss: 16680.75, base loss: 10629.93
[INFO 2017-06-26 13:38:34,088 main.py:50] epoch 132, training loss: 8838.41, average training loss: 16621.78, base loss: 10633.56
[INFO 2017-06-26 13:38:35,755 main.py:50] epoch 133, training loss: 8834.73, average training loss: 16563.67, base loss: 10636.41
[INFO 2017-06-26 13:38:37,409 main.py:50] epoch 134, training loss: 8748.63, average training loss: 16505.78, base loss: 10639.05
[INFO 2017-06-26 13:38:39,067 main.py:50] epoch 135, training loss: 8611.71, average training loss: 16447.74, base loss: 10639.91
[INFO 2017-06-26 13:38:40,721 main.py:50] epoch 136, training loss: 8674.40, average training loss: 16391.00, base loss: 10642.11
[INFO 2017-06-26 13:38:42,380 main.py:50] epoch 137, training loss: 8340.57, average training loss: 16332.66, base loss: 10640.13
[INFO 2017-06-26 13:38:44,049 main.py:50] epoch 138, training loss: 8627.43, average training loss: 16277.23, base loss: 10641.07
[INFO 2017-06-26 13:38:45,707 main.py:50] epoch 139, training loss: 8668.40, average training loss: 16222.88, base loss: 10643.39
[INFO 2017-06-26 13:38:47,375 main.py:50] epoch 140, training loss: 8793.18, average training loss: 16170.19, base loss: 10647.23
[INFO 2017-06-26 13:38:49,035 main.py:50] epoch 141, training loss: 8419.62, average training loss: 16115.61, base loss: 10646.34
[INFO 2017-06-26 13:38:50,693 main.py:50] epoch 142, training loss: 8348.53, average training loss: 16061.29, base loss: 10646.17
[INFO 2017-06-26 13:38:52,343 main.py:50] epoch 143, training loss: 8835.42, average training loss: 16011.11, base loss: 10650.63
[INFO 2017-06-26 13:38:53,998 main.py:50] epoch 144, training loss: 8203.39, average training loss: 15957.26, base loss: 10648.00
[INFO 2017-06-26 13:38:55,651 main.py:50] epoch 145, training loss: 8251.05, average training loss: 15904.48, base loss: 10646.39
[INFO 2017-06-26 13:38:57,326 main.py:50] epoch 146, training loss: 8598.84, average training loss: 15854.78, base loss: 10648.26
[INFO 2017-06-26 13:38:58,981 main.py:50] epoch 147, training loss: 8586.84, average training loss: 15805.68, base loss: 10650.57
[INFO 2017-06-26 13:39:00,635 main.py:50] epoch 148, training loss: 8075.91, average training loss: 15753.80, base loss: 10645.80
[INFO 2017-06-26 13:39:02,290 main.py:50] epoch 149, training loss: 8349.16, average training loss: 15704.43, base loss: 10645.45
[INFO 2017-06-26 13:39:03,947 main.py:50] epoch 150, training loss: 8417.55, average training loss: 15656.18, base loss: 10646.70
[INFO 2017-06-26 13:39:05,604 main.py:50] epoch 151, training loss: 8387.77, average training loss: 15608.36, base loss: 10647.77
[INFO 2017-06-26 13:39:07,269 main.py:50] epoch 152, training loss: 8319.36, average training loss: 15560.72, base loss: 10646.99
[INFO 2017-06-26 13:39:08,939 main.py:50] epoch 153, training loss: 8212.05, average training loss: 15513.00, base loss: 10646.49
[INFO 2017-06-26 13:39:10,596 main.py:50] epoch 154, training loss: 8454.47, average training loss: 15467.46, base loss: 10648.08
[INFO 2017-06-26 13:39:12,263 main.py:50] epoch 155, training loss: 8723.94, average training loss: 15424.23, base loss: 10652.43
[INFO 2017-06-26 13:39:13,933 main.py:50] epoch 156, training loss: 8057.70, average training loss: 15377.31, base loss: 10649.16
[INFO 2017-06-26 13:39:15,585 main.py:50] epoch 157, training loss: 8270.65, average training loss: 15332.33, base loss: 10649.67
[INFO 2017-06-26 13:39:17,239 main.py:50] epoch 158, training loss: 8440.87, average training loss: 15288.99, base loss: 10651.07
[INFO 2017-06-26 13:39:18,894 main.py:50] epoch 159, training loss: 8223.40, average training loss: 15244.83, base loss: 10650.66
[INFO 2017-06-26 13:39:20,551 main.py:50] epoch 160, training loss: 8174.73, average training loss: 15200.92, base loss: 10651.01
[INFO 2017-06-26 13:39:22,207 main.py:50] epoch 161, training loss: 8579.83, average training loss: 15160.05, base loss: 10653.83
[INFO 2017-06-26 13:39:23,864 main.py:50] epoch 162, training loss: 8142.23, average training loss: 15116.99, base loss: 10653.49
[INFO 2017-06-26 13:39:25,520 main.py:50] epoch 163, training loss: 8057.94, average training loss: 15073.95, base loss: 10652.44
[INFO 2017-06-26 13:39:27,177 main.py:50] epoch 164, training loss: 8268.77, average training loss: 15032.71, base loss: 10653.95
[INFO 2017-06-26 13:39:28,836 main.py:50] epoch 165, training loss: 8026.83, average training loss: 14990.50, base loss: 10652.28
[INFO 2017-06-26 13:39:30,494 main.py:50] epoch 166, training loss: 8171.93, average training loss: 14949.67, base loss: 10653.19
[INFO 2017-06-26 13:39:32,151 main.py:50] epoch 167, training loss: 8019.20, average training loss: 14908.42, base loss: 10652.48
[INFO 2017-06-26 13:39:33,811 main.py:50] epoch 168, training loss: 7835.98, average training loss: 14866.57, base loss: 10649.28
[INFO 2017-06-26 13:39:35,476 main.py:50] epoch 169, training loss: 7797.82, average training loss: 14824.99, base loss: 10645.82
[INFO 2017-06-26 13:39:37,127 main.py:50] epoch 170, training loss: 8438.97, average training loss: 14787.64, base loss: 10649.14
[INFO 2017-06-26 13:39:38,787 main.py:50] epoch 171, training loss: 8144.75, average training loss: 14749.02, base loss: 10649.88
[INFO 2017-06-26 13:39:40,447 main.py:50] epoch 172, training loss: 8021.95, average training loss: 14710.14, base loss: 10649.86
[INFO 2017-06-26 13:39:42,104 main.py:50] epoch 173, training loss: 7900.26, average training loss: 14671.00, base loss: 10648.66
[INFO 2017-06-26 13:39:43,759 main.py:50] epoch 174, training loss: 8020.79, average training loss: 14633.00, base loss: 10649.08
[INFO 2017-06-26 13:39:45,418 main.py:50] epoch 175, training loss: 8496.25, average training loss: 14598.13, base loss: 10653.89
[INFO 2017-06-26 13:39:47,070 main.py:50] epoch 176, training loss: 8185.41, average training loss: 14561.90, base loss: 10655.83
[INFO 2017-06-26 13:39:48,729 main.py:50] epoch 177, training loss: 8011.47, average training loss: 14525.10, base loss: 10656.03
[INFO 2017-06-26 13:39:50,388 main.py:50] epoch 178, training loss: 8205.69, average training loss: 14489.80, base loss: 10657.08
[INFO 2017-06-26 13:39:52,046 main.py:50] epoch 179, training loss: 7909.45, average training loss: 14453.24, base loss: 10656.32
[INFO 2017-06-26 13:39:53,706 main.py:50] epoch 180, training loss: 8036.22, average training loss: 14417.79, base loss: 10656.94
[INFO 2017-06-26 13:39:55,365 main.py:50] epoch 181, training loss: 8021.29, average training loss: 14382.64, base loss: 10658.14
[INFO 2017-06-26 13:39:57,022 main.py:50] epoch 182, training loss: 7812.62, average training loss: 14346.74, base loss: 10657.52
[INFO 2017-06-26 13:39:58,682 main.py:50] epoch 183, training loss: 8098.15, average training loss: 14312.78, base loss: 10659.36
[INFO 2017-06-26 13:40:00,343 main.py:50] epoch 184, training loss: 8270.67, average training loss: 14280.12, base loss: 10662.95
[INFO 2017-06-26 13:40:02,003 main.py:50] epoch 185, training loss: 7967.47, average training loss: 14246.18, base loss: 10663.54
[INFO 2017-06-26 13:40:03,661 main.py:50] epoch 186, training loss: 7749.81, average training loss: 14211.44, base loss: 10662.05
[INFO 2017-06-26 13:40:05,318 main.py:50] epoch 187, training loss: 7762.11, average training loss: 14177.14, base loss: 10660.55
[INFO 2017-06-26 13:40:06,974 main.py:50] epoch 188, training loss: 7928.48, average training loss: 14144.07, base loss: 10661.61
[INFO 2017-06-26 13:40:08,640 main.py:50] epoch 189, training loss: 7968.76, average training loss: 14111.57, base loss: 10662.18
[INFO 2017-06-26 13:40:10,294 main.py:50] epoch 190, training loss: 7843.87, average training loss: 14078.76, base loss: 10662.59
[INFO 2017-06-26 13:40:11,956 main.py:50] epoch 191, training loss: 7812.13, average training loss: 14046.12, base loss: 10661.61
[INFO 2017-06-26 13:40:13,622 main.py:50] epoch 192, training loss: 7862.62, average training loss: 14014.08, base loss: 10661.65
[INFO 2017-06-26 13:40:15,275 main.py:50] epoch 193, training loss: 7952.86, average training loss: 13982.84, base loss: 10663.15
[INFO 2017-06-26 13:40:16,945 main.py:50] epoch 194, training loss: 7881.15, average training loss: 13951.55, base loss: 10664.87
[INFO 2017-06-26 13:40:18,602 main.py:50] epoch 195, training loss: 7799.27, average training loss: 13920.16, base loss: 10664.64
[INFO 2017-06-26 13:40:20,255 main.py:50] epoch 196, training loss: 8081.87, average training loss: 13890.52, base loss: 10666.70
[INFO 2017-06-26 13:40:21,907 main.py:50] epoch 197, training loss: 7298.82, average training loss: 13857.23, base loss: 10662.98
[INFO 2017-06-26 13:40:23,561 main.py:50] epoch 198, training loss: 7702.05, average training loss: 13826.30, base loss: 10662.14
[INFO 2017-06-26 13:40:25,212 main.py:50] epoch 199, training loss: 7779.79, average training loss: 13796.07, base loss: 10662.77
[INFO 2017-06-26 13:40:25,212 main.py:52] epoch 199, testing
[INFO 2017-06-26 13:40:32,534 main.py:103] average testing loss: 7802.61, base loss: 10844.60
[INFO 2017-06-26 13:40:32,534 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:40:32,541 main.py:76] current best accuracy: 7802.61
[INFO 2017-06-26 13:40:34,192 main.py:50] epoch 200, training loss: 7739.73, average training loss: 13765.93, base loss: 10663.02
[INFO 2017-06-26 13:40:35,846 main.py:50] epoch 201, training loss: 7902.39, average training loss: 13736.91, base loss: 10664.79
[INFO 2017-06-26 13:40:37,500 main.py:50] epoch 202, training loss: 7548.10, average training loss: 13706.42, base loss: 10663.13
[INFO 2017-06-26 13:40:39,148 main.py:50] epoch 203, training loss: 7996.31, average training loss: 13678.43, base loss: 10664.76
[INFO 2017-06-26 13:40:40,802 main.py:50] epoch 204, training loss: 7786.40, average training loss: 13649.69, base loss: 10666.15
[INFO 2017-06-26 13:40:42,455 main.py:50] epoch 205, training loss: 7509.63, average training loss: 13619.88, base loss: 10663.82
[INFO 2017-06-26 13:40:44,107 main.py:50] epoch 206, training loss: 7727.95, average training loss: 13591.42, base loss: 10664.82
[INFO 2017-06-26 13:40:45,763 main.py:50] epoch 207, training loss: 7455.98, average training loss: 13561.92, base loss: 10662.73
[INFO 2017-06-26 13:40:47,419 main.py:50] epoch 208, training loss: 7640.36, average training loss: 13533.59, base loss: 10662.97
[INFO 2017-06-26 13:40:49,067 main.py:50] epoch 209, training loss: 7589.22, average training loss: 13505.28, base loss: 10661.38
[INFO 2017-06-26 13:40:50,729 main.py:50] epoch 210, training loss: 7639.84, average training loss: 13477.48, base loss: 10660.75
[INFO 2017-06-26 13:40:52,398 main.py:50] epoch 211, training loss: 7784.83, average training loss: 13450.63, base loss: 10661.70
[INFO 2017-06-26 13:40:54,052 main.py:50] epoch 212, training loss: 7455.45, average training loss: 13422.49, base loss: 10660.68
[INFO 2017-06-26 13:40:55,707 main.py:50] epoch 213, training loss: 7778.81, average training loss: 13396.11, base loss: 10662.33
[INFO 2017-06-26 13:40:57,357 main.py:50] epoch 214, training loss: 7391.10, average training loss: 13368.18, base loss: 10659.97
[INFO 2017-06-26 13:40:59,011 main.py:50] epoch 215, training loss: 7272.58, average training loss: 13339.96, base loss: 10657.26
[INFO 2017-06-26 13:41:00,666 main.py:50] epoch 216, training loss: 7670.71, average training loss: 13313.84, base loss: 10657.54
[INFO 2017-06-26 13:41:02,331 main.py:50] epoch 217, training loss: 7807.55, average training loss: 13288.58, base loss: 10660.49
[INFO 2017-06-26 13:41:03,981 main.py:50] epoch 218, training loss: 7731.50, average training loss: 13263.20, base loss: 10661.49
[INFO 2017-06-26 13:41:05,633 main.py:50] epoch 219, training loss: 7716.86, average training loss: 13237.99, base loss: 10662.40
[INFO 2017-06-26 13:41:07,284 main.py:50] epoch 220, training loss: 7545.65, average training loss: 13212.24, base loss: 10661.66
[INFO 2017-06-26 13:41:08,945 main.py:50] epoch 221, training loss: 7745.76, average training loss: 13187.61, base loss: 10662.71
[INFO 2017-06-26 13:41:10,603 main.py:50] epoch 222, training loss: 7617.38, average training loss: 13162.63, base loss: 10663.01
[INFO 2017-06-26 13:41:12,252 main.py:50] epoch 223, training loss: 7731.64, average training loss: 13138.39, base loss: 10665.23
[INFO 2017-06-26 13:41:13,909 main.py:50] epoch 224, training loss: 7413.20, average training loss: 13112.94, base loss: 10664.23
[INFO 2017-06-26 13:41:15,579 main.py:50] epoch 225, training loss: 7200.60, average training loss: 13086.78, base loss: 10661.72
[INFO 2017-06-26 13:41:17,233 main.py:50] epoch 226, training loss: 7600.98, average training loss: 13062.62, base loss: 10661.77
[INFO 2017-06-26 13:41:18,886 main.py:50] epoch 227, training loss: 7586.09, average training loss: 13038.60, base loss: 10662.11
[INFO 2017-06-26 13:41:20,549 main.py:50] epoch 228, training loss: 7618.44, average training loss: 13014.93, base loss: 10663.51
[INFO 2017-06-26 13:41:22,202 main.py:50] epoch 229, training loss: 7786.25, average training loss: 12992.19, base loss: 10666.02
[INFO 2017-06-26 13:41:23,865 main.py:50] epoch 230, training loss: 7523.02, average training loss: 12968.52, base loss: 10667.07
[INFO 2017-06-26 13:41:25,519 main.py:50] epoch 231, training loss: 7469.56, average training loss: 12944.81, base loss: 10666.59
[INFO 2017-06-26 13:41:27,170 main.py:50] epoch 232, training loss: 7264.55, average training loss: 12920.44, base loss: 10664.83
[INFO 2017-06-26 13:41:28,830 main.py:50] epoch 233, training loss: 7423.77, average training loss: 12896.95, base loss: 10664.71
[INFO 2017-06-26 13:41:30,482 main.py:50] epoch 234, training loss: 7341.50, average training loss: 12873.31, base loss: 10663.75
[INFO 2017-06-26 13:41:32,136 main.py:50] epoch 235, training loss: 7299.30, average training loss: 12849.69, base loss: 10663.30
[INFO 2017-06-26 13:41:33,796 main.py:50] epoch 236, training loss: 7463.55, average training loss: 12826.96, base loss: 10664.14
[INFO 2017-06-26 13:41:35,450 main.py:50] epoch 237, training loss: 7384.39, average training loss: 12804.09, base loss: 10664.57
[INFO 2017-06-26 13:41:37,114 main.py:50] epoch 238, training loss: 7468.46, average training loss: 12781.77, base loss: 10665.82
[INFO 2017-06-26 13:41:38,764 main.py:50] epoch 239, training loss: 7549.25, average training loss: 12759.97, base loss: 10666.82
[INFO 2017-06-26 13:41:40,420 main.py:50] epoch 240, training loss: 7677.40, average training loss: 12738.88, base loss: 10668.92
[INFO 2017-06-26 13:41:42,072 main.py:50] epoch 241, training loss: 7521.56, average training loss: 12717.32, base loss: 10670.71
[INFO 2017-06-26 13:41:43,725 main.py:50] epoch 242, training loss: 7461.18, average training loss: 12695.69, base loss: 10670.67
[INFO 2017-06-26 13:41:45,380 main.py:50] epoch 243, training loss: 7485.64, average training loss: 12674.33, base loss: 10672.34
[INFO 2017-06-26 13:41:47,030 main.py:50] epoch 244, training loss: 7297.61, average training loss: 12652.39, base loss: 10672.56
[INFO 2017-06-26 13:41:48,682 main.py:50] epoch 245, training loss: 7362.87, average training loss: 12630.89, base loss: 10673.32
[INFO 2017-06-26 13:41:50,336 main.py:50] epoch 246, training loss: 7198.91, average training loss: 12608.89, base loss: 10672.78
[INFO 2017-06-26 13:41:51,987 main.py:50] epoch 247, training loss: 7358.77, average training loss: 12587.72, base loss: 10673.36
[INFO 2017-06-26 13:41:53,645 main.py:50] epoch 248, training loss: 7188.65, average training loss: 12566.04, base loss: 10673.03
[INFO 2017-06-26 13:41:55,305 main.py:50] epoch 249, training loss: 7500.23, average training loss: 12545.78, base loss: 10674.96
[INFO 2017-06-26 13:41:56,974 main.py:50] epoch 250, training loss: 7166.70, average training loss: 12524.35, base loss: 10674.03
[INFO 2017-06-26 13:41:58,622 main.py:50] epoch 251, training loss: 7092.82, average training loss: 12502.79, base loss: 10672.17
[INFO 2017-06-26 13:42:00,290 main.py:50] epoch 252, training loss: 7028.64, average training loss: 12481.16, base loss: 10670.12
[INFO 2017-06-26 13:42:01,944 main.py:50] epoch 253, training loss: 7482.75, average training loss: 12461.48, base loss: 10671.01
[INFO 2017-06-26 13:42:03,594 main.py:50] epoch 254, training loss: 7009.64, average training loss: 12440.10, base loss: 10669.11
[INFO 2017-06-26 13:42:05,245 main.py:50] epoch 255, training loss: 7330.46, average training loss: 12420.14, base loss: 10669.61
[INFO 2017-06-26 13:42:06,894 main.py:50] epoch 256, training loss: 7378.64, average training loss: 12400.52, base loss: 10670.66
[INFO 2017-06-26 13:42:08,557 main.py:50] epoch 257, training loss: 7276.38, average training loss: 12380.66, base loss: 10671.67
[INFO 2017-06-26 13:42:10,208 main.py:50] epoch 258, training loss: 7300.81, average training loss: 12361.05, base loss: 10671.41
[INFO 2017-06-26 13:42:11,857 main.py:50] epoch 259, training loss: 7932.46, average training loss: 12344.02, base loss: 10675.48
[INFO 2017-06-26 13:42:13,505 main.py:50] epoch 260, training loss: 7290.66, average training loss: 12324.65, base loss: 10676.56
[INFO 2017-06-26 13:42:15,157 main.py:50] epoch 261, training loss: 7479.50, average training loss: 12306.16, base loss: 10677.10
[INFO 2017-06-26 13:42:16,807 main.py:50] epoch 262, training loss: 7383.88, average training loss: 12287.44, base loss: 10678.48
[INFO 2017-06-26 13:42:18,456 main.py:50] epoch 263, training loss: 7017.89, average training loss: 12267.48, base loss: 10676.66
[INFO 2017-06-26 13:42:20,109 main.py:50] epoch 264, training loss: 7482.66, average training loss: 12249.43, base loss: 10678.36
[INFO 2017-06-26 13:42:21,769 main.py:50] epoch 265, training loss: 7203.66, average training loss: 12230.46, base loss: 10678.42
[INFO 2017-06-26 13:42:23,423 main.py:50] epoch 266, training loss: 7139.24, average training loss: 12211.39, base loss: 10678.53
[INFO 2017-06-26 13:42:25,076 main.py:50] epoch 267, training loss: 7034.67, average training loss: 12192.07, base loss: 10677.51
[INFO 2017-06-26 13:42:26,724 main.py:50] epoch 268, training loss: 7047.86, average training loss: 12172.95, base loss: 10676.62
[INFO 2017-06-26 13:42:28,385 main.py:50] epoch 269, training loss: 7377.82, average training loss: 12155.19, base loss: 10678.21
[INFO 2017-06-26 13:42:30,040 main.py:50] epoch 270, training loss: 7262.23, average training loss: 12137.14, base loss: 10679.07
[INFO 2017-06-26 13:42:31,696 main.py:50] epoch 271, training loss: 7271.12, average training loss: 12119.25, base loss: 10679.86
[INFO 2017-06-26 13:42:33,351 main.py:50] epoch 272, training loss: 7295.76, average training loss: 12101.58, base loss: 10680.82
[INFO 2017-06-26 13:42:35,011 main.py:50] epoch 273, training loss: 7273.91, average training loss: 12083.96, base loss: 10682.13
[INFO 2017-06-26 13:42:36,665 main.py:50] epoch 274, training loss: 6796.54, average training loss: 12064.73, base loss: 10679.40
[INFO 2017-06-26 13:42:38,319 main.py:50] epoch 275, training loss: 7297.09, average training loss: 12047.46, base loss: 10680.44
[INFO 2017-06-26 13:42:39,971 main.py:50] epoch 276, training loss: 6900.65, average training loss: 12028.88, base loss: 10679.02
[INFO 2017-06-26 13:42:41,620 main.py:50] epoch 277, training loss: 7134.59, average training loss: 12011.27, base loss: 10679.27
[INFO 2017-06-26 13:42:43,276 main.py:50] epoch 278, training loss: 6863.17, average training loss: 11992.82, base loss: 10676.94
[INFO 2017-06-26 13:42:44,939 main.py:50] epoch 279, training loss: 7283.10, average training loss: 11976.00, base loss: 10678.05
[INFO 2017-06-26 13:42:46,593 main.py:50] epoch 280, training loss: 7209.02, average training loss: 11959.04, base loss: 10679.52
[INFO 2017-06-26 13:42:48,245 main.py:50] epoch 281, training loss: 7270.06, average training loss: 11942.41, base loss: 10680.13
[INFO 2017-06-26 13:42:49,910 main.py:50] epoch 282, training loss: 6939.86, average training loss: 11924.73, base loss: 10679.53
[INFO 2017-06-26 13:42:51,562 main.py:50] epoch 283, training loss: 7026.60, average training loss: 11907.48, base loss: 10678.29
[INFO 2017-06-26 13:42:53,219 main.py:50] epoch 284, training loss: 7429.70, average training loss: 11891.77, base loss: 10680.90
[INFO 2017-06-26 13:42:54,883 main.py:50] epoch 285, training loss: 7255.53, average training loss: 11875.56, base loss: 10679.73
[INFO 2017-06-26 13:42:56,550 main.py:50] epoch 286, training loss: 6970.04, average training loss: 11858.47, base loss: 10678.61
[INFO 2017-06-26 13:42:58,203 main.py:50] epoch 287, training loss: 7100.11, average training loss: 11841.95, base loss: 10677.38
[INFO 2017-06-26 13:42:59,862 main.py:50] epoch 288, training loss: 7159.99, average training loss: 11825.75, base loss: 10676.93
[INFO 2017-06-26 13:43:01,516 main.py:50] epoch 289, training loss: 7226.45, average training loss: 11809.89, base loss: 10678.13
[INFO 2017-06-26 13:43:03,175 main.py:50] epoch 290, training loss: 7110.08, average training loss: 11793.74, base loss: 10678.66
[INFO 2017-06-26 13:43:04,830 main.py:50] epoch 291, training loss: 7098.79, average training loss: 11777.66, base loss: 10678.55
[INFO 2017-06-26 13:43:06,493 main.py:50] epoch 292, training loss: 7428.66, average training loss: 11762.82, base loss: 10679.97
[INFO 2017-06-26 13:43:08,147 main.py:50] epoch 293, training loss: 7308.71, average training loss: 11747.67, base loss: 10681.52
[INFO 2017-06-26 13:43:09,806 main.py:50] epoch 294, training loss: 7089.10, average training loss: 11731.87, base loss: 10681.32
[INFO 2017-06-26 13:43:11,464 main.py:50] epoch 295, training loss: 7162.38, average training loss: 11716.44, base loss: 10680.98
[INFO 2017-06-26 13:43:13,122 main.py:50] epoch 296, training loss: 7139.30, average training loss: 11701.02, base loss: 10681.33
[INFO 2017-06-26 13:43:14,781 main.py:50] epoch 297, training loss: 7185.99, average training loss: 11685.87, base loss: 10681.32
[INFO 2017-06-26 13:43:16,438 main.py:50] epoch 298, training loss: 7324.92, average training loss: 11671.29, base loss: 10683.13
[INFO 2017-06-26 13:43:18,090 main.py:50] epoch 299, training loss: 7007.38, average training loss: 11655.74, base loss: 10682.56
[INFO 2017-06-26 13:43:18,090 main.py:52] epoch 299, testing
[INFO 2017-06-26 13:43:25,403 main.py:103] average testing loss: 7050.30, base loss: 10671.99
[INFO 2017-06-26 13:43:25,404 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:43:25,411 main.py:76] current best accuracy: 7050.30
[INFO 2017-06-26 13:43:27,067 main.py:50] epoch 300, training loss: 7109.72, average training loss: 11640.64, base loss: 10683.36
[INFO 2017-06-26 13:43:28,721 main.py:50] epoch 301, training loss: 7232.00, average training loss: 11626.04, base loss: 10684.78
[INFO 2017-06-26 13:43:30,375 main.py:50] epoch 302, training loss: 6792.10, average training loss: 11610.09, base loss: 10682.77
[INFO 2017-06-26 13:43:32,031 main.py:50] epoch 303, training loss: 6908.99, average training loss: 11594.62, base loss: 10681.63
[INFO 2017-06-26 13:43:33,680 main.py:50] epoch 304, training loss: 6802.61, average training loss: 11578.91, base loss: 10680.66
[INFO 2017-06-26 13:43:35,331 main.py:50] epoch 305, training loss: 6964.44, average training loss: 11563.83, base loss: 10680.51
[INFO 2017-06-26 13:43:36,984 main.py:50] epoch 306, training loss: 7122.52, average training loss: 11549.36, base loss: 10682.37
[INFO 2017-06-26 13:43:38,636 main.py:50] epoch 307, training loss: 6742.27, average training loss: 11533.76, base loss: 10681.41
[INFO 2017-06-26 13:43:40,287 main.py:50] epoch 308, training loss: 6734.32, average training loss: 11518.23, base loss: 10680.10
[INFO 2017-06-26 13:43:41,953 main.py:50] epoch 309, training loss: 6836.65, average training loss: 11503.12, base loss: 10678.74
[INFO 2017-06-26 13:43:43,610 main.py:50] epoch 310, training loss: 7024.06, average training loss: 11488.72, base loss: 10679.01
[INFO 2017-06-26 13:43:45,269 main.py:50] epoch 311, training loss: 6703.27, average training loss: 11473.38, base loss: 10677.25
[INFO 2017-06-26 13:43:46,926 main.py:50] epoch 312, training loss: 7054.26, average training loss: 11459.26, base loss: 10678.08
[INFO 2017-06-26 13:43:48,577 main.py:50] epoch 313, training loss: 7016.80, average training loss: 11445.12, base loss: 10678.15
[INFO 2017-06-26 13:43:50,231 main.py:50] epoch 314, training loss: 6780.42, average training loss: 11430.31, base loss: 10677.33
[INFO 2017-06-26 13:43:51,890 main.py:50] epoch 315, training loss: 6706.18, average training loss: 11415.36, base loss: 10676.53
[INFO 2017-06-26 13:43:53,541 main.py:50] epoch 316, training loss: 6941.04, average training loss: 11401.24, base loss: 10676.98
[INFO 2017-06-26 13:43:55,193 main.py:50] epoch 317, training loss: 6812.32, average training loss: 11386.81, base loss: 10676.83
[INFO 2017-06-26 13:43:56,847 main.py:50] epoch 318, training loss: 6801.80, average training loss: 11372.44, base loss: 10676.62
[INFO 2017-06-26 13:43:58,495 main.py:50] epoch 319, training loss: 6808.23, average training loss: 11358.18, base loss: 10676.42
[INFO 2017-06-26 13:44:00,145 main.py:50] epoch 320, training loss: 7081.57, average training loss: 11344.85, base loss: 10678.09
[INFO 2017-06-26 13:44:01,798 main.py:50] epoch 321, training loss: 6775.91, average training loss: 11330.66, base loss: 10677.45
[INFO 2017-06-26 13:44:03,447 main.py:50] epoch 322, training loss: 6754.12, average training loss: 11316.50, base loss: 10676.91
[INFO 2017-06-26 13:44:05,096 main.py:50] epoch 323, training loss: 6678.85, average training loss: 11302.18, base loss: 10676.01
[INFO 2017-06-26 13:44:06,752 main.py:50] epoch 324, training loss: 6895.97, average training loss: 11288.62, base loss: 10676.49
[INFO 2017-06-26 13:44:08,401 main.py:50] epoch 325, training loss: 7062.90, average training loss: 11275.66, base loss: 10678.05
[INFO 2017-06-26 13:44:10,051 main.py:50] epoch 326, training loss: 6612.73, average training loss: 11261.40, base loss: 10677.11
[INFO 2017-06-26 13:44:11,706 main.py:50] epoch 327, training loss: 6745.54, average training loss: 11247.63, base loss: 10676.68
[INFO 2017-06-26 13:44:13,356 main.py:50] epoch 328, training loss: 6799.03, average training loss: 11234.11, base loss: 10675.60
[INFO 2017-06-26 13:44:15,009 main.py:50] epoch 329, training loss: 6837.08, average training loss: 11220.79, base loss: 10675.29
[INFO 2017-06-26 13:44:16,662 main.py:50] epoch 330, training loss: 6958.21, average training loss: 11207.91, base loss: 10676.04
[INFO 2017-06-26 13:44:18,321 main.py:50] epoch 331, training loss: 6963.89, average training loss: 11195.13, base loss: 10676.57
[INFO 2017-06-26 13:44:19,982 main.py:50] epoch 332, training loss: 6764.61, average training loss: 11181.82, base loss: 10676.75
[INFO 2017-06-26 13:44:21,631 main.py:50] epoch 333, training loss: 6810.28, average training loss: 11168.73, base loss: 10676.00
[INFO 2017-06-26 13:44:23,280 main.py:50] epoch 334, training loss: 7123.46, average training loss: 11156.66, base loss: 10677.94
[INFO 2017-06-26 13:44:24,930 main.py:50] epoch 335, training loss: 6686.00, average training loss: 11143.35, base loss: 10677.41
[INFO 2017-06-26 13:44:26,584 main.py:50] epoch 336, training loss: 6841.88, average training loss: 11130.59, base loss: 10678.45
[INFO 2017-06-26 13:44:28,237 main.py:50] epoch 337, training loss: 6742.81, average training loss: 11117.61, base loss: 10677.56
[INFO 2017-06-26 13:44:29,887 main.py:50] epoch 338, training loss: 7249.86, average training loss: 11106.20, base loss: 10679.85
[INFO 2017-06-26 13:44:31,550 main.py:50] epoch 339, training loss: 6860.51, average training loss: 11093.71, base loss: 10680.94
[INFO 2017-06-26 13:44:33,199 main.py:50] epoch 340, training loss: 6761.94, average training loss: 11081.01, base loss: 10680.77
[INFO 2017-06-26 13:44:34,852 main.py:50] epoch 341, training loss: 6839.17, average training loss: 11068.61, base loss: 10681.02
[INFO 2017-06-26 13:44:36,516 main.py:50] epoch 342, training loss: 6576.22, average training loss: 11055.51, base loss: 10679.51
[INFO 2017-06-26 13:44:38,166 main.py:50] epoch 343, training loss: 7044.71, average training loss: 11043.85, base loss: 10680.63
[INFO 2017-06-26 13:44:39,814 main.py:50] epoch 344, training loss: 6776.29, average training loss: 11031.48, base loss: 10680.24
[INFO 2017-06-26 13:44:41,464 main.py:50] epoch 345, training loss: 6805.00, average training loss: 11019.26, base loss: 10681.05
[INFO 2017-06-26 13:44:43,112 main.py:50] epoch 346, training loss: 7016.45, average training loss: 11007.73, base loss: 10682.44
[INFO 2017-06-26 13:44:44,768 main.py:50] epoch 347, training loss: 6808.95, average training loss: 10995.66, base loss: 10682.91
[INFO 2017-06-26 13:44:46,423 main.py:50] epoch 348, training loss: 6585.71, average training loss: 10983.03, base loss: 10682.25
[INFO 2017-06-26 13:44:48,073 main.py:50] epoch 349, training loss: 6694.82, average training loss: 10970.77, base loss: 10682.20
[INFO 2017-06-26 13:44:49,724 main.py:50] epoch 350, training loss: 6818.27, average training loss: 10958.94, base loss: 10682.86
[INFO 2017-06-26 13:44:51,379 main.py:50] epoch 351, training loss: 6757.40, average training loss: 10947.01, base loss: 10682.70
[INFO 2017-06-26 13:44:53,036 main.py:50] epoch 352, training loss: 6780.87, average training loss: 10935.21, base loss: 10683.19
[INFO 2017-06-26 13:44:54,684 main.py:50] epoch 353, training loss: 6604.49, average training loss: 10922.97, base loss: 10682.58
[INFO 2017-06-26 13:44:56,338 main.py:50] epoch 354, training loss: 6559.31, average training loss: 10910.68, base loss: 10681.96
[INFO 2017-06-26 13:44:57,994 main.py:50] epoch 355, training loss: 6547.40, average training loss: 10898.42, base loss: 10681.36
[INFO 2017-06-26 13:44:59,655 main.py:50] epoch 356, training loss: 6559.22, average training loss: 10886.27, base loss: 10680.52
[INFO 2017-06-26 13:45:01,307 main.py:50] epoch 357, training loss: 6586.71, average training loss: 10874.26, base loss: 10679.79
[INFO 2017-06-26 13:45:02,956 main.py:50] epoch 358, training loss: 6770.51, average training loss: 10862.83, base loss: 10680.18
[INFO 2017-06-26 13:45:04,607 main.py:50] epoch 359, training loss: 6766.93, average training loss: 10851.45, base loss: 10680.29
[INFO 2017-06-26 13:45:06,260 main.py:50] epoch 360, training loss: 6691.05, average training loss: 10839.93, base loss: 10681.21
[INFO 2017-06-26 13:45:07,909 main.py:50] epoch 361, training loss: 6701.70, average training loss: 10828.49, base loss: 10681.46
[INFO 2017-06-26 13:45:09,573 main.py:50] epoch 362, training loss: 6525.46, average training loss: 10816.64, base loss: 10681.13
[INFO 2017-06-26 13:45:11,231 main.py:50] epoch 363, training loss: 6711.96, average training loss: 10805.36, base loss: 10682.04
[INFO 2017-06-26 13:45:12,885 main.py:50] epoch 364, training loss: 6592.01, average training loss: 10793.82, base loss: 10681.15
[INFO 2017-06-26 13:45:14,535 main.py:50] epoch 365, training loss: 6874.28, average training loss: 10783.11, base loss: 10682.23
[INFO 2017-06-26 13:45:16,207 main.py:50] epoch 366, training loss: 6538.33, average training loss: 10771.54, base loss: 10681.32
[INFO 2017-06-26 13:45:17,875 main.py:50] epoch 367, training loss: 6566.00, average training loss: 10760.12, base loss: 10680.77
[INFO 2017-06-26 13:45:19,536 main.py:50] epoch 368, training loss: 6653.26, average training loss: 10748.99, base loss: 10681.28
[INFO 2017-06-26 13:45:21,205 main.py:50] epoch 369, training loss: 6646.81, average training loss: 10737.90, base loss: 10682.00
[INFO 2017-06-26 13:45:22,857 main.py:50] epoch 370, training loss: 6589.99, average training loss: 10726.72, base loss: 10681.71
[INFO 2017-06-26 13:45:24,505 main.py:50] epoch 371, training loss: 6684.89, average training loss: 10715.85, base loss: 10682.46
[INFO 2017-06-26 13:45:26,157 main.py:50] epoch 372, training loss: 6756.60, average training loss: 10705.24, base loss: 10683.53
[INFO 2017-06-26 13:45:27,810 main.py:50] epoch 373, training loss: 6576.05, average training loss: 10694.20, base loss: 10683.63
[INFO 2017-06-26 13:45:29,475 main.py:50] epoch 374, training loss: 6808.17, average training loss: 10683.84, base loss: 10685.18
[INFO 2017-06-26 13:45:31,127 main.py:50] epoch 375, training loss: 6639.69, average training loss: 10673.08, base loss: 10685.76
[INFO 2017-06-26 13:45:32,781 main.py:50] epoch 376, training loss: 6432.54, average training loss: 10661.83, base loss: 10684.66
[INFO 2017-06-26 13:45:34,446 main.py:50] epoch 377, training loss: 6395.91, average training loss: 10650.55, base loss: 10683.63
[INFO 2017-06-26 13:45:36,100 main.py:50] epoch 378, training loss: 6496.26, average training loss: 10639.59, base loss: 10683.00
[INFO 2017-06-26 13:45:37,752 main.py:50] epoch 379, training loss: 6621.22, average training loss: 10629.01, base loss: 10683.80
[INFO 2017-06-26 13:45:39,403 main.py:50] epoch 380, training loss: 6548.19, average training loss: 10618.30, base loss: 10682.59
[INFO 2017-06-26 13:45:41,055 main.py:50] epoch 381, training loss: 6550.55, average training loss: 10607.65, base loss: 10682.13
[INFO 2017-06-26 13:45:42,708 main.py:50] epoch 382, training loss: 6692.22, average training loss: 10597.43, base loss: 10682.71
[INFO 2017-06-26 13:45:44,360 main.py:50] epoch 383, training loss: 6674.46, average training loss: 10587.21, base loss: 10682.09
[INFO 2017-06-26 13:45:46,014 main.py:50] epoch 384, training loss: 6454.94, average training loss: 10576.48, base loss: 10680.83
[INFO 2017-06-26 13:45:47,665 main.py:50] epoch 385, training loss: 6320.56, average training loss: 10565.45, base loss: 10678.57
[INFO 2017-06-26 13:45:49,322 main.py:50] epoch 386, training loss: 6662.15, average training loss: 10555.37, base loss: 10678.58
[INFO 2017-06-26 13:45:50,973 main.py:50] epoch 387, training loss: 6657.27, average training loss: 10545.32, base loss: 10678.64
[INFO 2017-06-26 13:45:52,623 main.py:50] epoch 388, training loss: 6614.57, average training loss: 10535.22, base loss: 10679.40
[INFO 2017-06-26 13:45:54,273 main.py:50] epoch 389, training loss: 6693.81, average training loss: 10525.37, base loss: 10680.10
[INFO 2017-06-26 13:45:55,929 main.py:50] epoch 390, training loss: 6641.69, average training loss: 10515.43, base loss: 10680.63
[INFO 2017-06-26 13:45:57,580 main.py:50] epoch 391, training loss: 6483.52, average training loss: 10505.15, base loss: 10680.36
[INFO 2017-06-26 13:45:59,233 main.py:50] epoch 392, training loss: 6459.14, average training loss: 10494.85, base loss: 10679.90
[INFO 2017-06-26 13:46:00,905 main.py:50] epoch 393, training loss: 6650.24, average training loss: 10485.10, base loss: 10679.96
[INFO 2017-06-26 13:46:02,558 main.py:50] epoch 394, training loss: 6635.08, average training loss: 10475.35, base loss: 10680.29
[INFO 2017-06-26 13:46:04,211 main.py:50] epoch 395, training loss: 6653.53, average training loss: 10465.70, base loss: 10681.12
[INFO 2017-06-26 13:46:05,873 main.py:50] epoch 396, training loss: 6503.43, average training loss: 10455.72, base loss: 10681.02
[INFO 2017-06-26 13:46:07,535 main.py:50] epoch 397, training loss: 6550.69, average training loss: 10445.91, base loss: 10681.54
[INFO 2017-06-26 13:46:09,203 main.py:50] epoch 398, training loss: 6534.81, average training loss: 10436.10, base loss: 10681.39
[INFO 2017-06-26 13:46:10,857 main.py:50] epoch 399, training loss: 6627.21, average training loss: 10426.58, base loss: 10682.39
[INFO 2017-06-26 13:46:10,857 main.py:52] epoch 399, testing
[INFO 2017-06-26 13:46:18,162 main.py:103] average testing loss: 6447.14, base loss: 10442.36
[INFO 2017-06-26 13:46:18,162 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:46:18,169 main.py:76] current best accuracy: 6447.14
[INFO 2017-06-26 13:46:19,821 main.py:50] epoch 400, training loss: 6488.33, average training loss: 10416.76, base loss: 10681.68
[INFO 2017-06-26 13:46:21,470 main.py:50] epoch 401, training loss: 6524.89, average training loss: 10407.08, base loss: 10681.99
[INFO 2017-06-26 13:46:23,126 main.py:50] epoch 402, training loss: 6423.74, average training loss: 10397.19, base loss: 10681.23
[INFO 2017-06-26 13:46:24,782 main.py:50] epoch 403, training loss: 6565.57, average training loss: 10387.71, base loss: 10681.65
[INFO 2017-06-26 13:46:26,433 main.py:50] epoch 404, training loss: 6326.13, average training loss: 10377.68, base loss: 10680.60
[INFO 2017-06-26 13:46:28,089 main.py:50] epoch 405, training loss: 6913.29, average training loss: 10369.15, base loss: 10683.03
[INFO 2017-06-26 13:46:29,745 main.py:50] epoch 406, training loss: 6663.75, average training loss: 10360.04, base loss: 10684.23
[INFO 2017-06-26 13:46:31,411 main.py:50] epoch 407, training loss: 6516.40, average training loss: 10350.62, base loss: 10684.11
[INFO 2017-06-26 13:46:33,064 main.py:50] epoch 408, training loss: 6364.66, average training loss: 10340.88, base loss: 10683.91
[INFO 2017-06-26 13:46:34,713 main.py:50] epoch 409, training loss: 6459.32, average training loss: 10331.41, base loss: 10684.05
[INFO 2017-06-26 13:46:36,360 main.py:50] epoch 410, training loss: 6477.31, average training loss: 10322.03, base loss: 10684.34
[INFO 2017-06-26 13:46:38,021 main.py:50] epoch 411, training loss: 6454.99, average training loss: 10312.65, base loss: 10684.64
[INFO 2017-06-26 13:46:39,680 main.py:50] epoch 412, training loss: 6306.75, average training loss: 10302.95, base loss: 10684.28
[INFO 2017-06-26 13:46:41,335 main.py:50] epoch 413, training loss: 6371.13, average training loss: 10293.45, base loss: 10683.79
[INFO 2017-06-26 13:46:42,988 main.py:50] epoch 414, training loss: 6436.88, average training loss: 10284.16, base loss: 10683.43
[INFO 2017-06-26 13:46:44,644 main.py:50] epoch 415, training loss: 6373.22, average training loss: 10274.76, base loss: 10683.10
[INFO 2017-06-26 13:46:46,304 main.py:50] epoch 416, training loss: 6421.80, average training loss: 10265.52, base loss: 10682.74
[INFO 2017-06-26 13:46:47,961 main.py:50] epoch 417, training loss: 6254.47, average training loss: 10255.92, base loss: 10681.72
[INFO 2017-06-26 13:46:49,618 main.py:50] epoch 418, training loss: 6212.14, average training loss: 10246.27, base loss: 10680.71
[INFO 2017-06-26 13:46:51,266 main.py:50] epoch 419, training loss: 6617.33, average training loss: 10237.63, base loss: 10681.74
[INFO 2017-06-26 13:46:52,928 main.py:50] epoch 420, training loss: 6494.05, average training loss: 10228.74, base loss: 10681.96
[INFO 2017-06-26 13:46:54,590 main.py:50] epoch 421, training loss: 6382.90, average training loss: 10219.62, base loss: 10682.15
[INFO 2017-06-26 13:46:56,241 main.py:50] epoch 422, training loss: 6161.46, average training loss: 10210.03, base loss: 10680.41
[INFO 2017-06-26 13:46:57,905 main.py:50] epoch 423, training loss: 6298.21, average training loss: 10200.80, base loss: 10679.86
[INFO 2017-06-26 13:46:59,571 main.py:50] epoch 424, training loss: 6378.22, average training loss: 10191.81, base loss: 10679.81
[INFO 2017-06-26 13:47:01,224 main.py:50] epoch 425, training loss: 6266.03, average training loss: 10182.59, base loss: 10679.29
[INFO 2017-06-26 13:47:02,883 main.py:50] epoch 426, training loss: 6731.13, average training loss: 10174.51, base loss: 10680.87
[INFO 2017-06-26 13:47:04,535 main.py:50] epoch 427, training loss: 6406.96, average training loss: 10165.71, base loss: 10681.00
[INFO 2017-06-26 13:47:06,186 main.py:50] epoch 428, training loss: 6395.65, average training loss: 10156.92, base loss: 10680.60
[INFO 2017-06-26 13:47:07,842 main.py:50] epoch 429, training loss: 6456.43, average training loss: 10148.32, base loss: 10680.80
[INFO 2017-06-26 13:47:09,497 main.py:50] epoch 430, training loss: 6291.16, average training loss: 10139.37, base loss: 10680.09
[INFO 2017-06-26 13:47:11,147 main.py:50] epoch 431, training loss: 6438.90, average training loss: 10130.80, base loss: 10680.60
[INFO 2017-06-26 13:47:12,801 main.py:50] epoch 432, training loss: 6214.26, average training loss: 10121.75, base loss: 10679.72
[INFO 2017-06-26 13:47:14,456 main.py:50] epoch 433, training loss: 6621.73, average training loss: 10113.69, base loss: 10681.24
[INFO 2017-06-26 13:47:16,106 main.py:50] epoch 434, training loss: 6438.47, average training loss: 10105.24, base loss: 10680.87
[INFO 2017-06-26 13:47:17,762 main.py:50] epoch 435, training loss: 6550.40, average training loss: 10097.09, base loss: 10681.61
[INFO 2017-06-26 13:47:19,417 main.py:50] epoch 436, training loss: 6328.44, average training loss: 10088.46, base loss: 10681.53
[INFO 2017-06-26 13:47:21,080 main.py:50] epoch 437, training loss: 6364.46, average training loss: 10079.96, base loss: 10681.33
[INFO 2017-06-26 13:47:22,739 main.py:50] epoch 438, training loss: 6350.38, average training loss: 10071.47, base loss: 10681.25
[INFO 2017-06-26 13:47:24,402 main.py:50] epoch 439, training loss: 6092.55, average training loss: 10062.42, base loss: 10679.97
[INFO 2017-06-26 13:47:26,054 main.py:50] epoch 440, training loss: 6580.48, average training loss: 10054.53, base loss: 10680.86
[INFO 2017-06-26 13:47:27,721 main.py:50] epoch 441, training loss: 6251.51, average training loss: 10045.92, base loss: 10680.41
[INFO 2017-06-26 13:47:29,378 main.py:50] epoch 442, training loss: 6146.68, average training loss: 10037.12, base loss: 10679.69
[INFO 2017-06-26 13:47:31,033 main.py:50] epoch 443, training loss: 6533.11, average training loss: 10029.23, base loss: 10680.72
[INFO 2017-06-26 13:47:32,701 main.py:50] epoch 444, training loss: 6278.93, average training loss: 10020.80, base loss: 10680.68
[INFO 2017-06-26 13:47:34,358 main.py:50] epoch 445, training loss: 6364.78, average training loss: 10012.60, base loss: 10680.84
[INFO 2017-06-26 13:47:36,014 main.py:50] epoch 446, training loss: 6236.14, average training loss: 10004.16, base loss: 10680.27
[INFO 2017-06-26 13:47:37,669 main.py:50] epoch 447, training loss: 6288.95, average training loss: 9995.86, base loss: 10680.04
[INFO 2017-06-26 13:47:39,328 main.py:50] epoch 448, training loss: 6162.37, average training loss: 9987.33, base loss: 10679.62
[INFO 2017-06-26 13:47:40,983 main.py:50] epoch 449, training loss: 6221.03, average training loss: 9978.96, base loss: 10679.35
[INFO 2017-06-26 13:47:42,652 main.py:50] epoch 450, training loss: 6351.61, average training loss: 9970.91, base loss: 10680.06
[INFO 2017-06-26 13:47:44,302 main.py:50] epoch 451, training loss: 6172.06, average training loss: 9962.51, base loss: 10679.10
[INFO 2017-06-26 13:47:45,967 main.py:50] epoch 452, training loss: 6136.83, average training loss: 9954.06, base loss: 10678.62
[INFO 2017-06-26 13:47:47,620 main.py:50] epoch 453, training loss: 6241.84, average training loss: 9945.89, base loss: 10678.27
[INFO 2017-06-26 13:47:49,271 main.py:50] epoch 454, training loss: 6375.88, average training loss: 9938.04, base loss: 10678.80
[INFO 2017-06-26 13:47:50,943 main.py:50] epoch 455, training loss: 6260.13, average training loss: 9929.98, base loss: 10679.58
[INFO 2017-06-26 13:47:52,610 main.py:50] epoch 456, training loss: 6380.27, average training loss: 9922.21, base loss: 10680.03
[INFO 2017-06-26 13:47:54,272 main.py:50] epoch 457, training loss: 6198.63, average training loss: 9914.08, base loss: 10679.96
[INFO 2017-06-26 13:47:55,927 main.py:50] epoch 458, training loss: 6191.39, average training loss: 9905.97, base loss: 10679.42
[INFO 2017-06-26 13:47:57,582 main.py:50] epoch 459, training loss: 6211.29, average training loss: 9897.94, base loss: 10679.09
[INFO 2017-06-26 13:47:59,243 main.py:50] epoch 460, training loss: 6309.93, average training loss: 9890.15, base loss: 10679.63
[INFO 2017-06-26 13:48:00,898 main.py:50] epoch 461, training loss: 6467.21, average training loss: 9882.74, base loss: 10680.76
[INFO 2017-06-26 13:48:02,552 main.py:50] epoch 462, training loss: 6226.45, average training loss: 9874.85, base loss: 10679.66
[INFO 2017-06-26 13:48:04,220 main.py:50] epoch 463, training loss: 6384.73, average training loss: 9867.32, base loss: 10679.79
[INFO 2017-06-26 13:48:05,877 main.py:50] epoch 464, training loss: 6244.68, average training loss: 9859.53, base loss: 10679.83
[INFO 2017-06-26 13:48:07,540 main.py:50] epoch 465, training loss: 6404.60, average training loss: 9852.12, base loss: 10679.71
[INFO 2017-06-26 13:48:09,193 main.py:50] epoch 466, training loss: 6387.09, average training loss: 9844.70, base loss: 10680.33
[INFO 2017-06-26 13:48:10,847 main.py:50] epoch 467, training loss: 6462.27, average training loss: 9837.47, base loss: 10681.16
[INFO 2017-06-26 13:48:12,506 main.py:50] epoch 468, training loss: 6300.85, average training loss: 9829.93, base loss: 10680.79
[INFO 2017-06-26 13:48:14,157 main.py:50] epoch 469, training loss: 6262.22, average training loss: 9822.34, base loss: 10680.54
[INFO 2017-06-26 13:48:15,813 main.py:50] epoch 470, training loss: 6286.45, average training loss: 9814.83, base loss: 10680.21
[INFO 2017-06-26 13:48:17,466 main.py:50] epoch 471, training loss: 6763.84, average training loss: 9808.37, base loss: 10682.17
[INFO 2017-06-26 13:48:19,117 main.py:50] epoch 472, training loss: 6164.91, average training loss: 9800.67, base loss: 10681.44
[INFO 2017-06-26 13:48:20,773 main.py:50] epoch 473, training loss: 6197.13, average training loss: 9793.06, base loss: 10680.37
[INFO 2017-06-26 13:48:22,430 main.py:50] epoch 474, training loss: 6211.89, average training loss: 9785.53, base loss: 10680.02
[INFO 2017-06-26 13:48:24,102 main.py:50] epoch 475, training loss: 6418.07, average training loss: 9778.45, base loss: 10680.02
[INFO 2017-06-26 13:48:25,764 main.py:50] epoch 476, training loss: 6398.35, average training loss: 9771.36, base loss: 10680.52
[INFO 2017-06-26 13:48:27,422 main.py:50] epoch 477, training loss: 6200.44, average training loss: 9763.89, base loss: 10680.22
[INFO 2017-06-26 13:48:29,078 main.py:50] epoch 478, training loss: 6286.84, average training loss: 9756.64, base loss: 10680.41
[INFO 2017-06-26 13:48:30,740 main.py:50] epoch 479, training loss: 6318.43, average training loss: 9749.47, base loss: 10680.91
[INFO 2017-06-26 13:48:32,400 main.py:50] epoch 480, training loss: 6365.19, average training loss: 9742.44, base loss: 10681.49
[INFO 2017-06-26 13:48:34,053 main.py:50] epoch 481, training loss: 6142.01, average training loss: 9734.97, base loss: 10680.57
[INFO 2017-06-26 13:48:35,708 main.py:50] epoch 482, training loss: 6479.99, average training loss: 9728.23, base loss: 10681.68
[INFO 2017-06-26 13:48:37,368 main.py:50] epoch 483, training loss: 6352.64, average training loss: 9721.25, base loss: 10682.46
[INFO 2017-06-26 13:48:39,029 main.py:50] epoch 484, training loss: 6437.23, average training loss: 9714.48, base loss: 10683.29
[INFO 2017-06-26 13:48:40,683 main.py:50] epoch 485, training loss: 6161.83, average training loss: 9707.17, base loss: 10682.50
[INFO 2017-06-26 13:48:42,348 main.py:50] epoch 486, training loss: 6383.99, average training loss: 9700.35, base loss: 10682.87
[INFO 2017-06-26 13:48:44,021 main.py:50] epoch 487, training loss: 6437.86, average training loss: 9693.66, base loss: 10683.34
[INFO 2017-06-26 13:48:45,678 main.py:50] epoch 488, training loss: 6227.45, average training loss: 9686.57, base loss: 10683.02
[INFO 2017-06-26 13:48:47,353 main.py:50] epoch 489, training loss: 6219.08, average training loss: 9679.50, base loss: 10683.10
[INFO 2017-06-26 13:48:49,015 main.py:50] epoch 490, training loss: 6246.51, average training loss: 9672.51, base loss: 10683.51
[INFO 2017-06-26 13:48:50,687 main.py:50] epoch 491, training loss: 6125.12, average training loss: 9665.30, base loss: 10683.12
[INFO 2017-06-26 13:48:52,348 main.py:50] epoch 492, training loss: 6086.83, average training loss: 9658.04, base loss: 10682.81
[INFO 2017-06-26 13:48:54,004 main.py:50] epoch 493, training loss: 6241.67, average training loss: 9651.12, base loss: 10683.25
[INFO 2017-06-26 13:48:55,657 main.py:50] epoch 494, training loss: 6309.08, average training loss: 9644.37, base loss: 10684.30
[INFO 2017-06-26 13:48:57,319 main.py:50] epoch 495, training loss: 6171.98, average training loss: 9637.37, base loss: 10684.74
[INFO 2017-06-26 13:48:58,974 main.py:50] epoch 496, training loss: 6198.39, average training loss: 9630.45, base loss: 10685.14
[INFO 2017-06-26 13:49:00,630 main.py:50] epoch 497, training loss: 6119.18, average training loss: 9623.40, base loss: 10684.91
[INFO 2017-06-26 13:49:02,379 main.py:50] epoch 498, training loss: 6316.18, average training loss: 9616.77, base loss: 10685.53
[INFO 2017-06-26 13:49:04,140 main.py:50] epoch 499, training loss: 6015.26, average training loss: 9609.57, base loss: 10685.16
[INFO 2017-06-26 13:49:04,141 main.py:52] epoch 499, testing
[INFO 2017-06-26 13:49:11,506 main.py:103] average testing loss: 6100.90, base loss: 10643.78
[INFO 2017-06-26 13:49:11,506 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:49:11,513 main.py:76] current best accuracy: 6100.90
[INFO 2017-06-26 13:49:13,321 main.py:50] epoch 500, training loss: 6143.61, average training loss: 9602.65, base loss: 10685.24
[INFO 2017-06-26 13:49:15,037 main.py:50] epoch 501, training loss: 6098.88, average training loss: 9595.67, base loss: 10684.92
[INFO 2017-06-26 13:49:16,686 main.py:50] epoch 502, training loss: 6294.09, average training loss: 9589.11, base loss: 10685.70
[INFO 2017-06-26 13:49:18,424 main.py:50] epoch 503, training loss: 6064.25, average training loss: 9582.11, base loss: 10685.26
[INFO 2017-06-26 13:49:20,105 main.py:50] epoch 504, training loss: 6077.20, average training loss: 9575.17, base loss: 10685.25
[INFO 2017-06-26 13:49:21,879 main.py:50] epoch 505, training loss: 6066.30, average training loss: 9568.24, base loss: 10685.15
[INFO 2017-06-26 13:49:23,619 main.py:50] epoch 506, training loss: 6066.79, average training loss: 9561.33, base loss: 10685.09
[INFO 2017-06-26 13:49:25,365 main.py:50] epoch 507, training loss: 6138.31, average training loss: 9554.59, base loss: 10685.70
[INFO 2017-06-26 13:49:27,070 main.py:50] epoch 508, training loss: 5975.39, average training loss: 9547.56, base loss: 10685.36
[INFO 2017-06-26 13:49:28,814 main.py:50] epoch 509, training loss: 5892.90, average training loss: 9540.40, base loss: 10685.02
[INFO 2017-06-26 13:49:30,580 main.py:50] epoch 510, training loss: 6117.10, average training loss: 9533.70, base loss: 10685.12
[INFO 2017-06-26 13:49:32,358 main.py:50] epoch 511, training loss: 6334.83, average training loss: 9527.45, base loss: 10686.03
[INFO 2017-06-26 13:49:34,020 main.py:50] epoch 512, training loss: 6089.34, average training loss: 9520.75, base loss: 10686.49
[INFO 2017-06-26 13:49:35,670 main.py:50] epoch 513, training loss: 6099.92, average training loss: 9514.09, base loss: 10686.59
[INFO 2017-06-26 13:49:37,321 main.py:50] epoch 514, training loss: 6125.80, average training loss: 9507.51, base loss: 10686.57
[INFO 2017-06-26 13:49:38,983 main.py:50] epoch 515, training loss: 6037.53, average training loss: 9500.79, base loss: 10686.16
[INFO 2017-06-26 13:49:40,654 main.py:50] epoch 516, training loss: 6150.94, average training loss: 9494.31, base loss: 10686.69
[INFO 2017-06-26 13:49:42,419 main.py:50] epoch 517, training loss: 6107.94, average training loss: 9487.77, base loss: 10686.56
[INFO 2017-06-26 13:49:44,200 main.py:50] epoch 518, training loss: 6074.94, average training loss: 9481.19, base loss: 10686.08
[INFO 2017-06-26 13:49:45,859 main.py:50] epoch 519, training loss: 6144.27, average training loss: 9474.78, base loss: 10686.37
[INFO 2017-06-26 13:49:47,509 main.py:50] epoch 520, training loss: 6087.97, average training loss: 9468.28, base loss: 10686.24
[INFO 2017-06-26 13:49:49,155 main.py:50] epoch 521, training loss: 6057.07, average training loss: 9461.74, base loss: 10685.83
[INFO 2017-06-26 13:49:50,808 main.py:50] epoch 522, training loss: 6157.70, average training loss: 9455.42, base loss: 10686.29
[INFO 2017-06-26 13:49:52,457 main.py:50] epoch 523, training loss: 5925.90, average training loss: 9448.69, base loss: 10685.88
[INFO 2017-06-26 13:49:54,109 main.py:50] epoch 524, training loss: 6058.58, average training loss: 9442.23, base loss: 10686.08
[INFO 2017-06-26 13:49:55,760 main.py:50] epoch 525, training loss: 5944.96, average training loss: 9435.58, base loss: 10685.25
[INFO 2017-06-26 13:49:57,406 main.py:50] epoch 526, training loss: 6105.64, average training loss: 9429.26, base loss: 10685.52
[INFO 2017-06-26 13:49:59,063 main.py:50] epoch 527, training loss: 5988.85, average training loss: 9422.75, base loss: 10685.49
[INFO 2017-06-26 13:50:00,715 main.py:50] epoch 528, training loss: 6073.38, average training loss: 9416.42, base loss: 10684.76
[INFO 2017-06-26 13:50:02,378 main.py:50] epoch 529, training loss: 6012.35, average training loss: 9409.99, base loss: 10684.71
[INFO 2017-06-26 13:50:04,041 main.py:50] epoch 530, training loss: 6160.93, average training loss: 9403.88, base loss: 10685.44
[INFO 2017-06-26 13:50:05,714 main.py:50] epoch 531, training loss: 6112.03, average training loss: 9397.69, base loss: 10686.13
[INFO 2017-06-26 13:50:07,362 main.py:50] epoch 532, training loss: 6068.55, average training loss: 9391.44, base loss: 10686.10
[INFO 2017-06-26 13:50:09,009 main.py:50] epoch 533, training loss: 5980.44, average training loss: 9385.05, base loss: 10686.09
[INFO 2017-06-26 13:50:10,661 main.py:50] epoch 534, training loss: 6195.76, average training loss: 9379.09, base loss: 10686.60
[INFO 2017-06-26 13:50:12,309 main.py:50] epoch 535, training loss: 5955.96, average training loss: 9372.71, base loss: 10686.05
[INFO 2017-06-26 13:50:13,958 main.py:50] epoch 536, training loss: 6002.95, average training loss: 9366.43, base loss: 10686.08
[INFO 2017-06-26 13:50:15,623 main.py:50] epoch 537, training loss: 6040.07, average training loss: 9360.25, base loss: 10686.42
[INFO 2017-06-26 13:50:17,313 main.py:50] epoch 538, training loss: 6269.66, average training loss: 9354.51, base loss: 10687.54
[INFO 2017-06-26 13:50:19,071 main.py:50] epoch 539, training loss: 5968.17, average training loss: 9348.24, base loss: 10686.77
[INFO 2017-06-26 13:50:20,866 main.py:50] epoch 540, training loss: 6165.49, average training loss: 9342.36, base loss: 10687.35
[INFO 2017-06-26 13:50:22,638 main.py:50] epoch 541, training loss: 5800.30, average training loss: 9335.82, base loss: 10686.48
[INFO 2017-06-26 13:50:24,399 main.py:50] epoch 542, training loss: 5903.84, average training loss: 9329.50, base loss: 10686.39
[INFO 2017-06-26 13:50:26,176 main.py:50] epoch 543, training loss: 6025.01, average training loss: 9323.43, base loss: 10686.78
[INFO 2017-06-26 13:50:27,833 main.py:50] epoch 544, training loss: 5906.37, average training loss: 9317.16, base loss: 10686.11
[INFO 2017-06-26 13:50:29,598 main.py:50] epoch 545, training loss: 6051.43, average training loss: 9311.18, base loss: 10685.95
[INFO 2017-06-26 13:50:31,364 main.py:50] epoch 546, training loss: 6079.24, average training loss: 9305.27, base loss: 10686.31
[INFO 2017-06-26 13:50:33,016 main.py:50] epoch 547, training loss: 5995.16, average training loss: 9299.23, base loss: 10686.21
[INFO 2017-06-26 13:50:34,664 main.py:50] epoch 548, training loss: 5852.31, average training loss: 9292.95, base loss: 10685.57
