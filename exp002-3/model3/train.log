[INFO 2017-06-26 13:28:36,393 main.py:170] Namespace(batch_size=32, display=False, image_dir='/home/yi/Downloads/mpii-64-one-2', image_size=64, init_model_path='', input_video_path='video', learning_rate=0.001, method='unsupervised', motion_range=4, num_channel=3, num_inputs=2, output_flow_path='flow', output_flow_video_path='flow_video', save_dir='./model', test=False, test_epoch=10, test_interval=100, test_video=False, train=True, train_epoch=10000)
[INFO 2017-06-26 13:28:38,946 main.py:50] epoch 0, training loss: 148429.80, average training loss: 148429.80, base loss: 10749.65
[INFO 2017-06-26 13:28:39,663 main.py:50] epoch 1, training loss: 121953.34, average training loss: 135191.57, base loss: 10502.90
[INFO 2017-06-26 13:28:40,381 main.py:50] epoch 2, training loss: 106860.12, average training loss: 125747.75, base loss: 10491.99
[INFO 2017-06-26 13:28:41,090 main.py:50] epoch 3, training loss: 92392.05, average training loss: 117408.82, base loss: 10620.29
[INFO 2017-06-26 13:28:41,849 main.py:50] epoch 4, training loss: 81326.02, average training loss: 110192.26, base loss: 10638.34
[INFO 2017-06-26 13:28:42,689 main.py:50] epoch 5, training loss: 70696.77, average training loss: 103609.68, base loss: 10623.57
[INFO 2017-06-26 13:28:43,626 main.py:50] epoch 6, training loss: 61818.15, average training loss: 97639.46, base loss: 10689.04
[INFO 2017-06-26 13:28:44,568 main.py:50] epoch 7, training loss: 53505.23, average training loss: 92122.68, base loss: 10736.65
[INFO 2017-06-26 13:28:45,509 main.py:50] epoch 8, training loss: 47403.94, average training loss: 87153.93, base loss: 10746.48
[INFO 2017-06-26 13:28:46,455 main.py:50] epoch 9, training loss: 41381.02, average training loss: 82576.64, base loss: 10743.79
[INFO 2017-06-26 13:28:47,398 main.py:50] epoch 10, training loss: 36448.39, average training loss: 78383.16, base loss: 10695.61
[INFO 2017-06-26 13:28:48,341 main.py:50] epoch 11, training loss: 32985.53, average training loss: 74600.03, base loss: 10700.82
[INFO 2017-06-26 13:28:49,282 main.py:50] epoch 12, training loss: 29587.64, average training loss: 71137.54, base loss: 10700.72
[INFO 2017-06-26 13:28:50,225 main.py:50] epoch 13, training loss: 26585.19, average training loss: 67955.23, base loss: 10686.45
[INFO 2017-06-26 13:28:51,167 main.py:50] epoch 14, training loss: 23988.39, average training loss: 65024.10, base loss: 10677.32
[INFO 2017-06-26 13:28:52,108 main.py:50] epoch 15, training loss: 22193.93, average training loss: 62347.22, base loss: 10692.33
[INFO 2017-06-26 13:28:53,051 main.py:50] epoch 16, training loss: 20061.16, average training loss: 59859.80, base loss: 10675.35
[INFO 2017-06-26 13:28:53,993 main.py:50] epoch 17, training loss: 19194.73, average training loss: 57600.63, base loss: 10694.40
[INFO 2017-06-26 13:28:54,934 main.py:50] epoch 18, training loss: 17605.96, average training loss: 55495.65, base loss: 10698.60
[INFO 2017-06-26 13:28:55,876 main.py:50] epoch 19, training loss: 16403.75, average training loss: 53541.05, base loss: 10692.07
[INFO 2017-06-26 13:28:56,817 main.py:50] epoch 20, training loss: 16265.22, average training loss: 51766.01, base loss: 10720.19
[INFO 2017-06-26 13:28:57,760 main.py:50] epoch 21, training loss: 15200.94, average training loss: 50103.97, base loss: 10687.84
[INFO 2017-06-26 13:28:58,704 main.py:50] epoch 22, training loss: 14553.62, average training loss: 48558.30, base loss: 10682.60
[INFO 2017-06-26 13:28:59,647 main.py:50] epoch 23, training loss: 14224.89, average training loss: 47127.74, base loss: 10697.69
[INFO 2017-06-26 13:29:00,590 main.py:50] epoch 24, training loss: 13356.22, average training loss: 45776.88, base loss: 10692.45
[INFO 2017-06-26 13:29:01,534 main.py:50] epoch 25, training loss: 13005.07, average training loss: 44516.43, base loss: 10687.44
[INFO 2017-06-26 13:29:02,475 main.py:50] epoch 26, training loss: 12357.77, average training loss: 43325.36, base loss: 10674.72
[INFO 2017-06-26 13:29:03,417 main.py:50] epoch 27, training loss: 12590.95, average training loss: 42227.71, base loss: 10692.41
[INFO 2017-06-26 13:29:04,359 main.py:50] epoch 28, training loss: 12118.50, average training loss: 41189.46, base loss: 10699.30
[INFO 2017-06-26 13:29:05,305 main.py:50] epoch 29, training loss: 11188.84, average training loss: 40189.44, base loss: 10680.25
[INFO 2017-06-26 13:29:06,248 main.py:50] epoch 30, training loss: 11215.71, average training loss: 39254.80, base loss: 10673.38
[INFO 2017-06-26 13:29:07,189 main.py:50] epoch 31, training loss: 11312.84, average training loss: 38381.62, base loss: 10683.97
[INFO 2017-06-26 13:29:08,132 main.py:50] epoch 32, training loss: 10688.33, average training loss: 37542.42, base loss: 10677.13
[INFO 2017-06-26 13:29:09,074 main.py:50] epoch 33, training loss: 10728.89, average training loss: 36753.79, base loss: 10676.37
[INFO 2017-06-26 13:29:10,016 main.py:50] epoch 34, training loss: 10934.78, average training loss: 36016.11, base loss: 10687.65
[INFO 2017-06-26 13:29:10,959 main.py:50] epoch 35, training loss: 10159.23, average training loss: 35297.86, base loss: 10676.36
[INFO 2017-06-26 13:29:11,902 main.py:50] epoch 36, training loss: 10123.23, average training loss: 34617.46, base loss: 10667.87
[INFO 2017-06-26 13:29:12,843 main.py:50] epoch 37, training loss: 10579.90, average training loss: 33984.90, base loss: 10676.23
[INFO 2017-06-26 13:29:13,786 main.py:50] epoch 38, training loss: 10043.27, average training loss: 33371.01, base loss: 10670.22
[INFO 2017-06-26 13:29:14,730 main.py:50] epoch 39, training loss: 10277.49, average training loss: 32793.67, base loss: 10673.43
[INFO 2017-06-26 13:29:15,672 main.py:50] epoch 40, training loss: 10403.61, average training loss: 32247.57, base loss: 10681.85
[INFO 2017-06-26 13:29:16,614 main.py:50] epoch 41, training loss: 10372.78, average training loss: 31726.74, base loss: 10689.10
[INFO 2017-06-26 13:29:17,558 main.py:50] epoch 42, training loss: 9923.82, average training loss: 31219.70, base loss: 10686.01
[INFO 2017-06-26 13:29:18,503 main.py:50] epoch 43, training loss: 9944.91, average training loss: 30736.18, base loss: 10683.45
[INFO 2017-06-26 13:29:19,449 main.py:50] epoch 44, training loss: 10187.33, average training loss: 30279.54, base loss: 10689.19
[INFO 2017-06-26 13:29:20,393 main.py:50] epoch 45, training loss: 9993.68, average training loss: 29838.54, base loss: 10689.50
[INFO 2017-06-26 13:29:21,335 main.py:50] epoch 46, training loss: 9683.32, average training loss: 29409.71, base loss: 10684.02
[INFO 2017-06-26 13:29:22,278 main.py:50] epoch 47, training loss: 10130.85, average training loss: 29008.06, base loss: 10689.40
[INFO 2017-06-26 13:29:23,221 main.py:50] epoch 48, training loss: 9851.58, average training loss: 28617.12, base loss: 10689.33
[INFO 2017-06-26 13:29:24,164 main.py:50] epoch 49, training loss: 9889.71, average training loss: 28242.57, base loss: 10690.71
[INFO 2017-06-26 13:29:25,107 main.py:50] epoch 50, training loss: 9612.38, average training loss: 27877.27, base loss: 10686.02
[INFO 2017-06-26 13:29:26,049 main.py:50] epoch 51, training loss: 9726.07, average training loss: 27528.21, base loss: 10684.59
[INFO 2017-06-26 13:29:26,991 main.py:50] epoch 52, training loss: 9815.36, average training loss: 27194.00, base loss: 10685.88
[INFO 2017-06-26 13:29:27,931 main.py:50] epoch 53, training loss: 9878.05, average training loss: 26873.34, base loss: 10688.90
[INFO 2017-06-26 13:29:28,873 main.py:50] epoch 54, training loss: 9315.97, average training loss: 26554.11, base loss: 10679.72
[INFO 2017-06-26 13:29:29,817 main.py:50] epoch 55, training loss: 9625.40, average training loss: 26251.82, base loss: 10677.04
[INFO 2017-06-26 13:29:30,763 main.py:50] epoch 56, training loss: 9469.18, average training loss: 25957.38, base loss: 10672.67
[INFO 2017-06-26 13:29:31,705 main.py:50] epoch 57, training loss: 10154.11, average training loss: 25684.91, base loss: 10683.06
[INFO 2017-06-26 13:29:32,648 main.py:50] epoch 58, training loss: 9214.71, average training loss: 25405.76, base loss: 10674.08
[INFO 2017-06-26 13:29:33,592 main.py:50] epoch 59, training loss: 9799.81, average training loss: 25145.66, base loss: 10677.30
[INFO 2017-06-26 13:29:34,534 main.py:50] epoch 60, training loss: 9539.07, average training loss: 24889.81, base loss: 10675.75
[INFO 2017-06-26 13:29:35,477 main.py:50] epoch 61, training loss: 10404.72, average training loss: 24656.18, base loss: 10692.47
[INFO 2017-06-26 13:29:36,420 main.py:50] epoch 62, training loss: 9416.37, average training loss: 24414.28, base loss: 10688.67
[INFO 2017-06-26 13:29:37,363 main.py:50] epoch 63, training loss: 9391.98, average training loss: 24179.56, base loss: 10684.16
[INFO 2017-06-26 13:29:38,305 main.py:50] epoch 64, training loss: 9454.30, average training loss: 23953.01, base loss: 10682.77
[INFO 2017-06-26 13:29:39,250 main.py:50] epoch 65, training loss: 9207.28, average training loss: 23729.59, base loss: 10676.60
[INFO 2017-06-26 13:29:40,192 main.py:50] epoch 66, training loss: 9396.17, average training loss: 23515.66, base loss: 10674.31
[INFO 2017-06-26 13:29:41,140 main.py:50] epoch 67, training loss: 9415.26, average training loss: 23308.30, base loss: 10673.12
[INFO 2017-06-26 13:29:42,081 main.py:50] epoch 68, training loss: 9625.11, average training loss: 23110.00, base loss: 10676.29
[INFO 2017-06-26 13:29:43,023 main.py:50] epoch 69, training loss: 9671.25, average training loss: 22918.01, base loss: 10679.61
[INFO 2017-06-26 13:29:43,964 main.py:50] epoch 70, training loss: 9218.45, average training loss: 22725.06, base loss: 10675.20
[INFO 2017-06-26 13:29:44,905 main.py:50] epoch 71, training loss: 9474.29, average training loss: 22541.02, base loss: 10676.46
[INFO 2017-06-26 13:29:45,846 main.py:50] epoch 72, training loss: 9041.52, average training loss: 22356.10, base loss: 10670.20
[INFO 2017-06-26 13:29:46,787 main.py:50] epoch 73, training loss: 9360.47, average training loss: 22180.48, base loss: 10669.73
[INFO 2017-06-26 13:29:47,730 main.py:50] epoch 74, training loss: 10036.30, average training loss: 22018.56, base loss: 10681.10
[INFO 2017-06-26 13:29:48,675 main.py:50] epoch 75, training loss: 9623.29, average training loss: 21855.46, base loss: 10685.45
[INFO 2017-06-26 13:29:49,617 main.py:50] epoch 76, training loss: 9115.23, average training loss: 21690.01, base loss: 10680.46
[INFO 2017-06-26 13:29:50,561 main.py:50] epoch 77, training loss: 9599.00, average training loss: 21534.99, base loss: 10684.25
[INFO 2017-06-26 13:29:51,503 main.py:50] epoch 78, training loss: 9749.16, average training loss: 21385.81, base loss: 10691.37
[INFO 2017-06-26 13:29:52,446 main.py:50] epoch 79, training loss: 9569.57, average training loss: 21238.10, base loss: 10696.09
[INFO 2017-06-26 13:29:53,387 main.py:50] epoch 80, training loss: 9535.96, average training loss: 21093.63, base loss: 10699.79
[INFO 2017-06-26 13:29:54,328 main.py:50] epoch 81, training loss: 9397.29, average training loss: 20950.99, base loss: 10701.02
[INFO 2017-06-26 13:29:55,269 main.py:50] epoch 82, training loss: 9299.45, average training loss: 20810.61, base loss: 10700.31
[INFO 2017-06-26 13:29:56,212 main.py:50] epoch 83, training loss: 8843.71, average training loss: 20668.15, base loss: 10693.70
[INFO 2017-06-26 13:29:57,154 main.py:50] epoch 84, training loss: 9435.91, average training loss: 20536.01, base loss: 10696.50
[INFO 2017-06-26 13:29:58,096 main.py:50] epoch 85, training loss: 9131.64, average training loss: 20403.40, base loss: 10695.07
[INFO 2017-06-26 13:29:59,037 main.py:50] epoch 86, training loss: 9302.50, average training loss: 20275.80, base loss: 10696.19
[INFO 2017-06-26 13:29:59,979 main.py:50] epoch 87, training loss: 9487.83, average training loss: 20153.21, base loss: 10700.56
[INFO 2017-06-26 13:30:00,921 main.py:50] epoch 88, training loss: 8823.06, average training loss: 20025.91, base loss: 10694.31
[INFO 2017-06-26 13:30:01,863 main.py:50] epoch 89, training loss: 8918.91, average training loss: 19902.49, base loss: 10690.53
[INFO 2017-06-26 13:30:02,805 main.py:50] epoch 90, training loss: 9160.06, average training loss: 19784.45, base loss: 10690.69
[INFO 2017-06-26 13:30:03,747 main.py:50] epoch 91, training loss: 8929.87, average training loss: 19666.46, base loss: 10687.33
[INFO 2017-06-26 13:30:04,688 main.py:50] epoch 92, training loss: 9250.63, average training loss: 19554.46, base loss: 10688.84
[INFO 2017-06-26 13:30:05,632 main.py:50] epoch 93, training loss: 9132.64, average training loss: 19443.59, base loss: 10688.95
[INFO 2017-06-26 13:30:06,574 main.py:50] epoch 94, training loss: 9164.12, average training loss: 19335.39, base loss: 10690.67
[INFO 2017-06-26 13:30:07,516 main.py:50] epoch 95, training loss: 9299.14, average training loss: 19230.84, base loss: 10694.01
[INFO 2017-06-26 13:30:08,459 main.py:50] epoch 96, training loss: 9236.34, average training loss: 19127.81, base loss: 10695.79
[INFO 2017-06-26 13:30:09,403 main.py:50] epoch 97, training loss: 9262.91, average training loss: 19027.15, base loss: 10698.31
[INFO 2017-06-26 13:30:10,350 main.py:50] epoch 98, training loss: 9037.57, average training loss: 18926.24, base loss: 10698.32
[INFO 2017-06-26 13:30:11,292 main.py:50] epoch 99, training loss: 9210.69, average training loss: 18829.09, base loss: 10700.68
[INFO 2017-06-26 13:30:11,293 main.py:52] epoch 99, testing
[INFO 2017-06-26 13:30:15,255 main.py:103] average testing loss: 9032.51, base loss: 10682.69
[INFO 2017-06-26 13:30:15,256 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:30:15,262 main.py:76] current best accuracy: 9032.51
[INFO 2017-06-26 13:30:16,204 main.py:50] epoch 100, training loss: 8978.95, average training loss: 18731.56, base loss: 10700.19
[INFO 2017-06-26 13:30:17,151 main.py:50] epoch 101, training loss: 8880.09, average training loss: 18634.98, base loss: 10698.64
[INFO 2017-06-26 13:30:18,093 main.py:50] epoch 102, training loss: 8803.63, average training loss: 18539.53, base loss: 10695.24
[INFO 2017-06-26 13:30:19,034 main.py:50] epoch 103, training loss: 9024.10, average training loss: 18448.03, base loss: 10695.94
[INFO 2017-06-26 13:30:19,978 main.py:50] epoch 104, training loss: 9259.86, average training loss: 18360.53, base loss: 10699.23
[INFO 2017-06-26 13:30:20,922 main.py:50] epoch 105, training loss: 9284.95, average training loss: 18274.91, base loss: 10703.54
[INFO 2017-06-26 13:30:21,866 main.py:50] epoch 106, training loss: 8983.26, average training loss: 18188.07, base loss: 10702.50
[INFO 2017-06-26 13:30:22,809 main.py:50] epoch 107, training loss: 8630.60, average training loss: 18099.57, base loss: 10698.49
[INFO 2017-06-26 13:30:23,753 main.py:50] epoch 108, training loss: 9368.38, average training loss: 18019.47, base loss: 10703.11
[INFO 2017-06-26 13:30:24,696 main.py:50] epoch 109, training loss: 9523.06, average training loss: 17942.23, base loss: 10710.35
[INFO 2017-06-26 13:30:25,638 main.py:50] epoch 110, training loss: 8984.71, average training loss: 17861.53, base loss: 10709.37
[INFO 2017-06-26 13:30:26,580 main.py:50] epoch 111, training loss: 9064.33, average training loss: 17782.99, base loss: 10710.91
[INFO 2017-06-26 13:30:27,523 main.py:50] epoch 112, training loss: 9355.27, average training loss: 17708.40, base loss: 10716.62
[INFO 2017-06-26 13:30:28,466 main.py:50] epoch 113, training loss: 9226.60, average training loss: 17634.00, base loss: 10719.62
[INFO 2017-06-26 13:30:29,412 main.py:50] epoch 114, training loss: 8755.05, average training loss: 17556.79, base loss: 10718.15
[INFO 2017-06-26 13:30:30,356 main.py:50] epoch 115, training loss: 8779.57, average training loss: 17481.13, base loss: 10716.95
[INFO 2017-06-26 13:30:31,304 main.py:50] epoch 116, training loss: 8725.51, average training loss: 17406.29, base loss: 10714.59
[INFO 2017-06-26 13:30:32,248 main.py:50] epoch 117, training loss: 8497.72, average training loss: 17330.80, base loss: 10710.88
[INFO 2017-06-26 13:30:33,197 main.py:50] epoch 118, training loss: 8801.04, average training loss: 17259.12, base loss: 10709.83
[INFO 2017-06-26 13:30:34,141 main.py:50] epoch 119, training loss: 8974.58, average training loss: 17190.08, base loss: 10711.64
[INFO 2017-06-26 13:30:35,084 main.py:50] epoch 120, training loss: 8960.45, average training loss: 17122.07, base loss: 10713.76
[INFO 2017-06-26 13:30:36,028 main.py:50] epoch 121, training loss: 8903.93, average training loss: 17054.71, base loss: 10714.39
[INFO 2017-06-26 13:30:36,971 main.py:50] epoch 122, training loss: 8666.60, average training loss: 16986.51, base loss: 10713.15
[INFO 2017-06-26 13:30:37,914 main.py:50] epoch 123, training loss: 8488.39, average training loss: 16917.98, base loss: 10709.29
[INFO 2017-06-26 13:30:38,858 main.py:50] epoch 124, training loss: 8859.25, average training loss: 16853.51, base loss: 10710.01
[INFO 2017-06-26 13:30:39,804 main.py:50] epoch 125, training loss: 8855.03, average training loss: 16790.03, base loss: 10710.98
[INFO 2017-06-26 13:30:40,747 main.py:50] epoch 126, training loss: 8737.06, average training loss: 16726.62, base loss: 10710.47
[INFO 2017-06-26 13:30:41,691 main.py:50] epoch 127, training loss: 8917.65, average training loss: 16665.61, base loss: 10711.50
[INFO 2017-06-26 13:30:42,634 main.py:50] epoch 128, training loss: 8458.24, average training loss: 16601.99, base loss: 10708.69
[INFO 2017-06-26 13:30:43,578 main.py:50] epoch 129, training loss: 8440.06, average training loss: 16539.20, base loss: 10705.61
[INFO 2017-06-26 13:30:44,520 main.py:50] epoch 130, training loss: 8471.61, average training loss: 16477.62, base loss: 10703.06
[INFO 2017-06-26 13:30:45,462 main.py:50] epoch 131, training loss: 9103.20, average training loss: 16421.75, base loss: 10708.28
[INFO 2017-06-26 13:30:46,404 main.py:50] epoch 132, training loss: 8606.76, average training loss: 16362.99, base loss: 10706.97
[INFO 2017-06-26 13:30:47,347 main.py:50] epoch 133, training loss: 8880.74, average training loss: 16307.15, base loss: 10709.33
[INFO 2017-06-26 13:30:48,291 main.py:50] epoch 134, training loss: 8383.27, average training loss: 16248.46, base loss: 10706.32
[INFO 2017-06-26 13:30:49,234 main.py:50] epoch 135, training loss: 8957.99, average training loss: 16194.85, base loss: 10708.72
[INFO 2017-06-26 13:30:50,178 main.py:50] epoch 136, training loss: 8748.50, average training loss: 16140.50, base loss: 10709.94
[INFO 2017-06-26 13:30:51,121 main.py:50] epoch 137, training loss: 8782.83, average training loss: 16087.18, base loss: 10711.91
[INFO 2017-06-26 13:30:52,067 main.py:50] epoch 138, training loss: 8551.02, average training loss: 16032.97, base loss: 10711.27
[INFO 2017-06-26 13:30:53,009 main.py:50] epoch 139, training loss: 8825.24, average training loss: 15981.48, base loss: 10714.22
[INFO 2017-06-26 13:30:53,950 main.py:50] epoch 140, training loss: 8608.30, average training loss: 15929.19, base loss: 10713.92
[INFO 2017-06-26 13:30:54,892 main.py:50] epoch 141, training loss: 8804.15, average training loss: 15879.01, base loss: 10716.36
[INFO 2017-06-26 13:30:55,836 main.py:50] epoch 142, training loss: 8721.37, average training loss: 15828.96, base loss: 10718.58
[INFO 2017-06-26 13:30:56,780 main.py:50] epoch 143, training loss: 8312.82, average training loss: 15776.77, base loss: 10715.76
[INFO 2017-06-26 13:30:57,724 main.py:50] epoch 144, training loss: 8505.90, average training loss: 15726.62, base loss: 10716.34
[INFO 2017-06-26 13:30:58,667 main.py:50] epoch 145, training loss: 8407.91, average training loss: 15676.49, base loss: 10715.76
[INFO 2017-06-26 13:30:59,610 main.py:50] epoch 146, training loss: 8567.22, average training loss: 15628.13, base loss: 10716.83
[INFO 2017-06-26 13:31:00,556 main.py:50] epoch 147, training loss: 8096.55, average training loss: 15577.24, base loss: 10713.05
[INFO 2017-06-26 13:31:01,500 main.py:50] epoch 148, training loss: 8585.24, average training loss: 15530.32, base loss: 10714.85
[INFO 2017-06-26 13:31:02,442 main.py:50] epoch 149, training loss: 8361.79, average training loss: 15482.53, base loss: 10714.44
[INFO 2017-06-26 13:31:03,389 main.py:50] epoch 150, training loss: 8313.70, average training loss: 15435.05, base loss: 10713.69
[INFO 2017-06-26 13:31:04,331 main.py:50] epoch 151, training loss: 8282.59, average training loss: 15387.99, base loss: 10712.74
[INFO 2017-06-26 13:31:05,274 main.py:50] epoch 152, training loss: 8245.09, average training loss: 15341.31, base loss: 10711.73
[INFO 2017-06-26 13:31:06,216 main.py:50] epoch 153, training loss: 8241.56, average training loss: 15295.21, base loss: 10710.17
[INFO 2017-06-26 13:31:07,158 main.py:50] epoch 154, training loss: 8436.99, average training loss: 15250.96, base loss: 10711.10
[INFO 2017-06-26 13:31:08,101 main.py:50] epoch 155, training loss: 8198.56, average training loss: 15205.75, base loss: 10708.78
[INFO 2017-06-26 13:31:09,043 main.py:50] epoch 156, training loss: 8222.22, average training loss: 15161.27, base loss: 10708.01
[INFO 2017-06-26 13:31:09,987 main.py:50] epoch 157, training loss: 8427.36, average training loss: 15118.65, base loss: 10708.92
[INFO 2017-06-26 13:31:10,932 main.py:50] epoch 158, training loss: 8351.37, average training loss: 15076.09, base loss: 10709.08
[INFO 2017-06-26 13:31:11,874 main.py:50] epoch 159, training loss: 8599.80, average training loss: 15035.61, base loss: 10712.49
[INFO 2017-06-26 13:31:12,817 main.py:50] epoch 160, training loss: 8554.05, average training loss: 14995.35, base loss: 10715.24
[INFO 2017-06-26 13:31:13,759 main.py:50] epoch 161, training loss: 8206.10, average training loss: 14953.45, base loss: 10714.12
[INFO 2017-06-26 13:31:14,700 main.py:50] epoch 162, training loss: 8149.69, average training loss: 14911.70, base loss: 10713.31
[INFO 2017-06-26 13:31:15,641 main.py:50] epoch 163, training loss: 8181.95, average training loss: 14870.67, base loss: 10712.98
[INFO 2017-06-26 13:31:16,585 main.py:50] epoch 164, training loss: 8079.62, average training loss: 14829.51, base loss: 10712.59
[INFO 2017-06-26 13:31:17,529 main.py:50] epoch 165, training loss: 7870.40, average training loss: 14787.59, base loss: 10708.67
[INFO 2017-06-26 13:31:18,471 main.py:50] epoch 166, training loss: 8144.62, average training loss: 14747.81, base loss: 10707.86
[INFO 2017-06-26 13:31:19,418 main.py:50] epoch 167, training loss: 8532.09, average training loss: 14710.81, base loss: 10710.73
[INFO 2017-06-26 13:31:20,366 main.py:50] epoch 168, training loss: 8129.94, average training loss: 14671.87, base loss: 10709.34
[INFO 2017-06-26 13:31:21,309 main.py:50] epoch 169, training loss: 8238.92, average training loss: 14634.03, base loss: 10710.37
[INFO 2017-06-26 13:31:22,252 main.py:50] epoch 170, training loss: 8213.70, average training loss: 14596.49, base loss: 10711.93
[INFO 2017-06-26 13:31:23,195 main.py:50] epoch 171, training loss: 8308.92, average training loss: 14559.93, base loss: 10713.52
[INFO 2017-06-26 13:31:24,137 main.py:50] epoch 172, training loss: 8037.85, average training loss: 14522.23, base loss: 10713.19
[INFO 2017-06-26 13:31:25,080 main.py:50] epoch 173, training loss: 7875.76, average training loss: 14484.03, base loss: 10711.37
[INFO 2017-06-26 13:31:26,022 main.py:50] epoch 174, training loss: 7700.50, average training loss: 14445.27, base loss: 10708.74
[INFO 2017-06-26 13:31:26,964 main.py:50] epoch 175, training loss: 8562.36, average training loss: 14411.84, base loss: 10713.32
[INFO 2017-06-26 13:31:27,906 main.py:50] epoch 176, training loss: 8006.70, average training loss: 14375.66, base loss: 10713.46
[INFO 2017-06-26 13:31:28,852 main.py:50] epoch 177, training loss: 8376.45, average training loss: 14341.95, base loss: 10716.53
[INFO 2017-06-26 13:31:29,794 main.py:50] epoch 178, training loss: 8238.74, average training loss: 14307.86, base loss: 10718.26
[INFO 2017-06-26 13:31:30,736 main.py:50] epoch 179, training loss: 7923.47, average training loss: 14272.39, base loss: 10717.37
[INFO 2017-06-26 13:31:31,679 main.py:50] epoch 180, training loss: 8034.26, average training loss: 14237.92, base loss: 10717.45
[INFO 2017-06-26 13:31:32,621 main.py:50] epoch 181, training loss: 7900.04, average training loss: 14203.10, base loss: 10715.84
[INFO 2017-06-26 13:31:33,567 main.py:50] epoch 182, training loss: 8007.38, average training loss: 14169.24, base loss: 10716.09
[INFO 2017-06-26 13:31:34,509 main.py:50] epoch 183, training loss: 7680.69, average training loss: 14133.98, base loss: 10713.66
[INFO 2017-06-26 13:31:35,452 main.py:50] epoch 184, training loss: 8013.14, average training loss: 14100.89, base loss: 10714.13
[INFO 2017-06-26 13:31:36,394 main.py:50] epoch 185, training loss: 8122.88, average training loss: 14068.75, base loss: 10715.61
[INFO 2017-06-26 13:31:37,337 main.py:50] epoch 186, training loss: 8035.99, average training loss: 14036.49, base loss: 10715.61
[INFO 2017-06-26 13:31:38,284 main.py:50] epoch 187, training loss: 8136.60, average training loss: 14005.11, base loss: 10716.77
[INFO 2017-06-26 13:31:39,228 main.py:50] epoch 188, training loss: 7892.88, average training loss: 13972.77, base loss: 10716.79
[INFO 2017-06-26 13:31:40,171 main.py:50] epoch 189, training loss: 7821.84, average training loss: 13940.40, base loss: 10715.48
[INFO 2017-06-26 13:31:41,114 main.py:50] epoch 190, training loss: 7919.44, average training loss: 13908.87, base loss: 10715.84
[INFO 2017-06-26 13:31:42,059 main.py:50] epoch 191, training loss: 7837.95, average training loss: 13877.26, base loss: 10715.35
[INFO 2017-06-26 13:31:43,002 main.py:50] epoch 192, training loss: 7624.28, average training loss: 13844.86, base loss: 10713.12
[INFO 2017-06-26 13:31:43,947 main.py:50] epoch 193, training loss: 7820.48, average training loss: 13813.80, base loss: 10713.22
[INFO 2017-06-26 13:31:44,890 main.py:50] epoch 194, training loss: 7792.06, average training loss: 13782.92, base loss: 10712.53
[INFO 2017-06-26 13:31:45,834 main.py:50] epoch 195, training loss: 8176.78, average training loss: 13754.32, base loss: 10715.29
[INFO 2017-06-26 13:31:46,776 main.py:50] epoch 196, training loss: 7903.53, average training loss: 13724.62, base loss: 10714.22
[INFO 2017-06-26 13:31:47,722 main.py:50] epoch 197, training loss: 7637.30, average training loss: 13693.88, base loss: 10712.69
[INFO 2017-06-26 13:31:48,668 main.py:50] epoch 198, training loss: 7771.74, average training loss: 13664.12, base loss: 10712.10
[INFO 2017-06-26 13:31:49,609 main.py:50] epoch 199, training loss: 7913.47, average training loss: 13635.36, base loss: 10712.62
[INFO 2017-06-26 13:31:49,609 main.py:52] epoch 199, testing
[INFO 2017-06-26 13:31:53,566 main.py:103] average testing loss: 7846.16, base loss: 10755.89
[INFO 2017-06-26 13:31:53,567 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:31:53,573 main.py:76] current best accuracy: 7846.16
[INFO 2017-06-26 13:31:54,516 main.py:50] epoch 200, training loss: 7913.15, average training loss: 13606.89, base loss: 10713.05
[INFO 2017-06-26 13:31:55,459 main.py:50] epoch 201, training loss: 7952.98, average training loss: 13578.90, base loss: 10714.22
[INFO 2017-06-26 13:31:56,403 main.py:50] epoch 202, training loss: 7707.56, average training loss: 13549.98, base loss: 10713.80
[INFO 2017-06-26 13:31:57,348 main.py:50] epoch 203, training loss: 7979.14, average training loss: 13522.67, base loss: 10715.58
[INFO 2017-06-26 13:31:58,292 main.py:50] epoch 204, training loss: 7721.26, average training loss: 13494.37, base loss: 10714.98
[INFO 2017-06-26 13:31:59,250 main.py:50] epoch 205, training loss: 7595.85, average training loss: 13465.74, base loss: 10713.99
[INFO 2017-06-26 13:32:00,194 main.py:50] epoch 206, training loss: 7800.86, average training loss: 13438.37, base loss: 10714.65
[INFO 2017-06-26 13:32:01,140 main.py:50] epoch 207, training loss: 7597.93, average training loss: 13410.29, base loss: 10713.63
[INFO 2017-06-26 13:32:02,082 main.py:50] epoch 208, training loss: 7990.12, average training loss: 13384.36, base loss: 10715.97
[INFO 2017-06-26 13:32:03,026 main.py:50] epoch 209, training loss: 7687.64, average training loss: 13357.23, base loss: 10715.68
[INFO 2017-06-26 13:32:03,969 main.py:50] epoch 210, training loss: 7658.85, average training loss: 13330.23, base loss: 10715.17
[INFO 2017-06-26 13:32:04,913 main.py:50] epoch 211, training loss: 7860.47, average training loss: 13304.43, base loss: 10716.27
[INFO 2017-06-26 13:32:05,857 main.py:50] epoch 212, training loss: 7719.69, average training loss: 13278.21, base loss: 10716.31
[INFO 2017-06-26 13:32:06,799 main.py:50] epoch 213, training loss: 7467.55, average training loss: 13251.05, base loss: 10714.50
[INFO 2017-06-26 13:32:07,742 main.py:50] epoch 214, training loss: 7374.88, average training loss: 13223.72, base loss: 10712.34
[INFO 2017-06-26 13:32:08,690 main.py:50] epoch 215, training loss: 7776.27, average training loss: 13198.50, base loss: 10712.35
[INFO 2017-06-26 13:32:09,634 main.py:50] epoch 216, training loss: 7551.74, average training loss: 13172.48, base loss: 10711.97
[INFO 2017-06-26 13:32:10,580 main.py:50] epoch 217, training loss: 7583.06, average training loss: 13146.84, base loss: 10711.98
[INFO 2017-06-26 13:32:11,523 main.py:50] epoch 218, training loss: 8187.18, average training loss: 13124.20, base loss: 10716.40
[INFO 2017-06-26 13:32:12,466 main.py:50] epoch 219, training loss: 7923.76, average training loss: 13100.56, base loss: 10718.07
[INFO 2017-06-26 13:32:13,409 main.py:50] epoch 220, training loss: 7904.71, average training loss: 13077.05, base loss: 10720.98
[INFO 2017-06-26 13:32:14,355 main.py:50] epoch 221, training loss: 7870.75, average training loss: 13053.59, base loss: 10723.21
[INFO 2017-06-26 13:32:15,300 main.py:50] epoch 222, training loss: 7414.46, average training loss: 13028.31, base loss: 10720.67
[INFO 2017-06-26 13:32:16,248 main.py:50] epoch 223, training loss: 8212.94, average training loss: 13006.81, base loss: 10724.08
[INFO 2017-06-26 13:32:17,193 main.py:50] epoch 224, training loss: 7602.70, average training loss: 12982.79, base loss: 10723.58
[INFO 2017-06-26 13:32:18,190 main.py:50] epoch 225, training loss: 7634.90, average training loss: 12959.13, base loss: 10723.26
[INFO 2017-06-26 13:32:19,204 main.py:50] epoch 226, training loss: 7443.76, average training loss: 12934.83, base loss: 10722.10
[INFO 2017-06-26 13:32:20,228 main.py:50] epoch 227, training loss: 7794.43, average training loss: 12912.29, base loss: 10723.39
[INFO 2017-06-26 13:32:21,173 main.py:50] epoch 228, training loss: 7698.14, average training loss: 12889.52, base loss: 10724.70
[INFO 2017-06-26 13:32:22,119 main.py:50] epoch 229, training loss: 7607.67, average training loss: 12866.55, base loss: 10723.89
[INFO 2017-06-26 13:32:23,062 main.py:50] epoch 230, training loss: 7462.43, average training loss: 12843.16, base loss: 10722.82
[INFO 2017-06-26 13:32:24,044 main.py:50] epoch 231, training loss: 7502.98, average training loss: 12820.14, base loss: 10721.99
[INFO 2017-06-26 13:32:24,987 main.py:50] epoch 232, training loss: 7643.75, average training loss: 12797.92, base loss: 10722.46
[INFO 2017-06-26 13:32:25,933 main.py:50] epoch 233, training loss: 7831.06, average training loss: 12776.70, base loss: 10724.07
[INFO 2017-06-26 13:32:26,876 main.py:50] epoch 234, training loss: 7556.33, average training loss: 12754.48, base loss: 10723.08
[INFO 2017-06-26 13:32:27,876 main.py:50] epoch 235, training loss: 7657.37, average training loss: 12732.89, base loss: 10723.42
[INFO 2017-06-26 13:32:28,835 main.py:50] epoch 236, training loss: 7744.72, average training loss: 12711.84, base loss: 10724.44
[INFO 2017-06-26 13:32:29,777 main.py:50] epoch 237, training loss: 8075.06, average training loss: 12692.36, base loss: 10727.64
[INFO 2017-06-26 13:32:30,803 main.py:50] epoch 238, training loss: 7869.16, average training loss: 12672.18, base loss: 10728.69
[INFO 2017-06-26 13:32:31,766 main.py:50] epoch 239, training loss: 7737.44, average training loss: 12651.61, base loss: 10730.20
[INFO 2017-06-26 13:32:32,709 main.py:50] epoch 240, training loss: 7452.64, average training loss: 12630.04, base loss: 10729.87
[INFO 2017-06-26 13:32:33,666 main.py:50] epoch 241, training loss: 7230.64, average training loss: 12607.73, base loss: 10727.55
[INFO 2017-06-26 13:32:34,645 main.py:50] epoch 242, training loss: 7567.34, average training loss: 12586.99, base loss: 10726.95
[INFO 2017-06-26 13:32:35,598 main.py:50] epoch 243, training loss: 7797.77, average training loss: 12567.36, base loss: 10728.59
[INFO 2017-06-26 13:32:36,580 main.py:50] epoch 244, training loss: 7519.84, average training loss: 12546.76, base loss: 10728.42
[INFO 2017-06-26 13:32:37,522 main.py:50] epoch 245, training loss: 7771.74, average training loss: 12527.35, base loss: 10730.79
[INFO 2017-06-26 13:32:38,543 main.py:50] epoch 246, training loss: 7367.27, average training loss: 12506.46, base loss: 10730.00
[INFO 2017-06-26 13:32:39,499 main.py:50] epoch 247, training loss: 7166.28, average training loss: 12484.92, base loss: 10727.49
[INFO 2017-06-26 13:32:40,514 main.py:50] epoch 248, training loss: 7505.44, average training loss: 12464.92, base loss: 10727.02
[INFO 2017-06-26 13:32:41,460 main.py:50] epoch 249, training loss: 7286.23, average training loss: 12444.21, base loss: 10725.61
[INFO 2017-06-26 13:32:42,403 main.py:50] epoch 250, training loss: 7252.86, average training loss: 12423.53, base loss: 10725.01
[INFO 2017-06-26 13:32:43,351 main.py:50] epoch 251, training loss: 7226.98, average training loss: 12402.91, base loss: 10722.82
[INFO 2017-06-26 13:32:44,294 main.py:50] epoch 252, training loss: 7157.87, average training loss: 12382.17, base loss: 10720.74
[INFO 2017-06-26 13:32:45,236 main.py:50] epoch 253, training loss: 7359.96, average training loss: 12362.40, base loss: 10719.76
[INFO 2017-06-26 13:32:46,179 main.py:50] epoch 254, training loss: 7533.82, average training loss: 12343.47, base loss: 10720.35
[INFO 2017-06-26 13:32:47,172 main.py:50] epoch 255, training loss: 7374.95, average training loss: 12324.06, base loss: 10720.57
[INFO 2017-06-26 13:32:48,142 main.py:50] epoch 256, training loss: 7428.89, average training loss: 12305.01, base loss: 10720.23
[INFO 2017-06-26 13:32:49,090 main.py:50] epoch 257, training loss: 7455.32, average training loss: 12286.21, base loss: 10720.08
[INFO 2017-06-26 13:32:50,033 main.py:50] epoch 258, training loss: 7333.34, average training loss: 12267.09, base loss: 10719.83
[INFO 2017-06-26 13:32:50,975 main.py:50] epoch 259, training loss: 7222.22, average training loss: 12247.69, base loss: 10717.94
[INFO 2017-06-26 13:32:51,917 main.py:50] epoch 260, training loss: 7239.33, average training loss: 12228.50, base loss: 10716.39
[INFO 2017-06-26 13:32:52,859 main.py:50] epoch 261, training loss: 7372.18, average training loss: 12209.96, base loss: 10716.26
[INFO 2017-06-26 13:32:53,802 main.py:50] epoch 262, training loss: 7013.67, average training loss: 12190.20, base loss: 10713.82
[INFO 2017-06-26 13:32:54,785 main.py:50] epoch 263, training loss: 7153.83, average training loss: 12171.13, base loss: 10712.70
[INFO 2017-06-26 13:32:55,782 main.py:50] epoch 264, training loss: 7154.47, average training loss: 12152.20, base loss: 10711.45
[INFO 2017-06-26 13:32:56,762 main.py:50] epoch 265, training loss: 7263.35, average training loss: 12133.82, base loss: 10711.35
[INFO 2017-06-26 13:32:57,736 main.py:50] epoch 266, training loss: 7123.38, average training loss: 12115.05, base loss: 10710.60
[INFO 2017-06-26 13:32:58,682 main.py:50] epoch 267, training loss: 7165.19, average training loss: 12096.58, base loss: 10709.80
[INFO 2017-06-26 13:32:59,628 main.py:50] epoch 268, training loss: 7349.43, average training loss: 12078.94, base loss: 10710.42
[INFO 2017-06-26 13:33:00,570 main.py:50] epoch 269, training loss: 7322.08, average training loss: 12061.32, base loss: 10710.63
[INFO 2017-06-26 13:33:01,512 main.py:50] epoch 270, training loss: 6979.63, average training loss: 12042.57, base loss: 10709.20
[INFO 2017-06-26 13:33:02,453 main.py:50] epoch 271, training loss: 7272.41, average training loss: 12025.03, base loss: 10709.56
[INFO 2017-06-26 13:33:03,483 main.py:50] epoch 272, training loss: 7323.61, average training loss: 12007.81, base loss: 10710.34
[INFO 2017-06-26 13:33:04,429 main.py:50] epoch 273, training loss: 7357.03, average training loss: 11990.83, base loss: 10710.97
[INFO 2017-06-26 13:33:05,450 main.py:50] epoch 274, training loss: 7267.02, average training loss: 11973.66, base loss: 10710.80
[INFO 2017-06-26 13:33:06,394 main.py:50] epoch 275, training loss: 7415.82, average training loss: 11957.14, base loss: 10712.09
[INFO 2017-06-26 13:33:07,336 main.py:50] epoch 276, training loss: 7193.90, average training loss: 11939.95, base loss: 10711.14
[INFO 2017-06-26 13:33:08,360 main.py:50] epoch 277, training loss: 7101.81, average training loss: 11922.54, base loss: 10710.44
[INFO 2017-06-26 13:33:09,303 main.py:50] epoch 278, training loss: 7168.86, average training loss: 11905.50, base loss: 10709.97
[INFO 2017-06-26 13:33:10,244 main.py:50] epoch 279, training loss: 7126.44, average training loss: 11888.44, base loss: 10708.90
[INFO 2017-06-26 13:33:11,185 main.py:50] epoch 280, training loss: 7286.96, average training loss: 11872.06, base loss: 10709.05
[INFO 2017-06-26 13:33:12,197 main.py:50] epoch 281, training loss: 7115.34, average training loss: 11855.19, base loss: 10708.79
[INFO 2017-06-26 13:33:13,208 main.py:50] epoch 282, training loss: 7375.81, average training loss: 11839.36, base loss: 10710.32
[INFO 2017-06-26 13:33:14,151 main.py:50] epoch 283, training loss: 7131.83, average training loss: 11822.79, base loss: 10710.04
[INFO 2017-06-26 13:33:15,096 main.py:50] epoch 284, training loss: 7225.11, average training loss: 11806.66, base loss: 10710.40
[INFO 2017-06-26 13:33:16,080 main.py:50] epoch 285, training loss: 7010.45, average training loss: 11789.89, base loss: 10709.15
[INFO 2017-06-26 13:33:17,067 main.py:50] epoch 286, training loss: 7288.54, average training loss: 11774.20, base loss: 10710.50
[INFO 2017-06-26 13:33:18,016 main.py:50] epoch 287, training loss: 7073.57, average training loss: 11757.88, base loss: 10709.86
[INFO 2017-06-26 13:33:18,959 main.py:50] epoch 288, training loss: 7172.90, average training loss: 11742.02, base loss: 10709.45
[INFO 2017-06-26 13:33:19,902 main.py:50] epoch 289, training loss: 7050.74, average training loss: 11725.84, base loss: 10708.52
[INFO 2017-06-26 13:33:20,846 main.py:50] epoch 290, training loss: 7250.21, average training loss: 11710.46, base loss: 10709.32
[INFO 2017-06-26 13:33:21,789 main.py:50] epoch 291, training loss: 7088.31, average training loss: 11694.63, base loss: 10708.67
[INFO 2017-06-26 13:33:22,732 main.py:50] epoch 292, training loss: 7093.59, average training loss: 11678.93, base loss: 10708.36
[INFO 2017-06-26 13:33:23,713 main.py:50] epoch 293, training loss: 7415.16, average training loss: 11664.42, base loss: 10709.74
[INFO 2017-06-26 13:33:24,656 main.py:50] epoch 294, training loss: 7195.50, average training loss: 11649.28, base loss: 10710.45
[INFO 2017-06-26 13:33:25,659 main.py:50] epoch 295, training loss: 7246.52, average training loss: 11634.40, base loss: 10710.12
[INFO 2017-06-26 13:33:26,615 main.py:50] epoch 296, training loss: 6909.24, average training loss: 11618.49, base loss: 10708.59
[INFO 2017-06-26 13:33:27,557 main.py:50] epoch 297, training loss: 7085.07, average training loss: 11603.28, base loss: 10707.49
[INFO 2017-06-26 13:33:28,520 main.py:50] epoch 298, training loss: 7165.88, average training loss: 11588.44, base loss: 10706.92
[INFO 2017-06-26 13:33:29,464 main.py:50] epoch 299, training loss: 7236.06, average training loss: 11573.93, base loss: 10707.45
[INFO 2017-06-26 13:33:29,464 main.py:52] epoch 299, testing
[INFO 2017-06-26 13:33:33,434 main.py:103] average testing loss: 7137.10, base loss: 10677.97
[INFO 2017-06-26 13:33:33,435 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 13:33:33,441 main.py:76] current best accuracy: 7137.10
[INFO 2017-06-26 13:33:34,384 main.py:50] epoch 300, training loss: 7165.05, average training loss: 11559.28, base loss: 10706.65
[INFO 2017-06-26 13:33:35,329 main.py:50] epoch 301, training loss: 7206.04, average training loss: 11544.87, base loss: 10706.99
[INFO 2017-06-26 13:33:36,272 main.py:50] epoch 302, training loss: 7232.82, average training loss: 11530.64, base loss: 10707.86
[INFO 2017-06-26 13:33:37,215 main.py:50] epoch 303, training loss: 6946.94, average training loss: 11515.56, base loss: 10706.67
[INFO 2017-06-26 13:33:38,159 main.py:50] epoch 304, training loss: 7177.55, average training loss: 11501.34, base loss: 10707.16
[INFO 2017-06-26 13:33:39,102 main.py:50] epoch 305, training loss: 6833.43, average training loss: 11486.08, base loss: 10706.03
[INFO 2017-06-26 13:33:40,046 main.py:50] epoch 306, training loss: 6915.79, average training loss: 11471.19, base loss: 10704.81
[INFO 2017-06-26 13:33:40,991 main.py:50] epoch 307, training loss: 7014.87, average training loss: 11456.73, base loss: 10704.47
[INFO 2017-06-26 13:33:41,942 main.py:50] epoch 308, training loss: 7165.95, average training loss: 11442.84, base loss: 10704.89
[INFO 2017-06-26 13:33:42,924 main.py:50] epoch 309, training loss: 6942.14, average training loss: 11428.32, base loss: 10704.23
[INFO 2017-06-26 13:33:43,867 main.py:50] epoch 310, training loss: 6740.25, average training loss: 11413.25, base loss: 10702.88
[INFO 2017-06-26 13:33:44,811 main.py:50] epoch 311, training loss: 7003.29, average training loss: 11399.11, base loss: 10702.98
[INFO 2017-06-26 13:33:45,755 main.py:50] epoch 312, training loss: 7061.97, average training loss: 11385.26, base loss: 10703.37
[INFO 2017-06-26 13:33:46,758 main.py:50] epoch 313, training loss: 7241.20, average training loss: 11372.06, base loss: 10704.59
[INFO 2017-06-26 13:33:47,761 main.py:50] epoch 314, training loss: 7045.51, average training loss: 11358.32, base loss: 10704.95
[INFO 2017-06-26 13:33:48,783 main.py:50] epoch 315, training loss: 7233.60, average training loss: 11345.27, base loss: 10705.80
[INFO 2017-06-26 13:33:49,730 main.py:50] epoch 316, training loss: 7249.41, average training loss: 11332.35, base loss: 10707.47
[INFO 2017-06-26 13:33:50,673 main.py:50] epoch 317, training loss: 6758.50, average training loss: 11317.97, base loss: 10706.43
[INFO 2017-06-26 13:33:51,618 main.py:50] epoch 318, training loss: 6674.62, average training loss: 11303.41, base loss: 10704.91
[INFO 2017-06-26 13:33:52,561 main.py:50] epoch 319, training loss: 7128.49, average training loss: 11290.36, base loss: 10705.80
[INFO 2017-06-26 13:33:53,503 main.py:50] epoch 320, training loss: 6971.77, average training loss: 11276.91, base loss: 10705.79
[INFO 2017-06-26 13:33:54,484 main.py:50] epoch 321, training loss: 6842.80, average training loss: 11263.14, base loss: 10705.25
[INFO 2017-06-26 13:33:55,428 main.py:50] epoch 322, training loss: 6806.28, average training loss: 11249.34, base loss: 10704.81
[INFO 2017-06-26 13:33:56,372 main.py:50] epoch 323, training loss: 7075.73, average training loss: 11236.46, base loss: 10705.74
[INFO 2017-06-26 13:33:57,316 main.py:50] epoch 324, training loss: 7026.51, average training loss: 11223.51, base loss: 10706.88
[INFO 2017-06-26 13:33:58,261 main.py:50] epoch 325, training loss: 6778.77, average training loss: 11209.87, base loss: 10705.59
[INFO 2017-06-26 13:33:59,206 main.py:50] epoch 326, training loss: 6897.95, average training loss: 11196.69, base loss: 10705.77
[INFO 2017-06-26 13:34:00,148 main.py:50] epoch 327, training loss: 6937.67, average training loss: 11183.70, base loss: 10706.40
[INFO 2017-06-26 13:34:01,090 main.py:50] epoch 328, training loss: 6860.44, average training loss: 11170.56, base loss: 10706.48
[INFO 2017-06-26 13:34:02,033 main.py:50] epoch 329, training loss: 6987.14, average training loss: 11157.88, base loss: 10706.90
[INFO 2017-06-26 13:34:03,018 main.py:50] epoch 330, training loss: 6648.29, average training loss: 11144.26, base loss: 10705.46
[INFO 2017-06-26 13:34:03,962 main.py:50] epoch 331, training loss: 6795.90, average training loss: 11131.16, base loss: 10704.64
[INFO 2017-06-26 13:34:04,905 main.py:50] epoch 332, training loss: 6973.46, average training loss: 11118.68, base loss: 10705.58
[INFO 2017-06-26 13:34:05,848 main.py:50] epoch 333, training loss: 6850.64, average training loss: 11105.90, base loss: 10705.09
[INFO 2017-06-26 13:34:06,857 main.py:50] epoch 334, training loss: 7170.70, average training loss: 11094.15, base loss: 10706.91
[INFO 2017-06-26 13:34:07,810 main.py:50] epoch 335, training loss: 6921.85, average training loss: 11081.73, base loss: 10707.14
[INFO 2017-06-26 13:34:08,801 main.py:50] epoch 336, training loss: 6689.47, average training loss: 11068.70, base loss: 10706.46
[INFO 2017-06-26 13:34:09,776 main.py:50] epoch 337, training loss: 6904.66, average training loss: 11056.38, base loss: 10706.91
[INFO 2017-06-26 13:34:10,728 main.py:50] epoch 338, training loss: 6695.32, average training loss: 11043.52, base loss: 10705.85
[INFO 2017-06-26 13:34:11,672 main.py:50] epoch 339, training loss: 6832.59, average training loss: 11031.13, base loss: 10705.69
[INFO 2017-06-26 13:34:12,616 main.py:50] epoch 340, training loss: 6857.10, average training loss: 11018.89, base loss: 10705.58
[INFO 2017-06-26 13:34:13,560 main.py:50] epoch 341, training loss: 6737.26, average training loss: 11006.37, base loss: 10704.78
[INFO 2017-06-26 13:34:14,503 main.py:50] epoch 342, training loss: 6811.99, average training loss: 10994.14, base loss: 10704.64
[INFO 2017-06-26 13:34:15,489 main.py:50] epoch 343, training loss: 6683.69, average training loss: 10981.61, base loss: 10703.67
[INFO 2017-06-26 13:34:16,439 main.py:50] epoch 344, training loss: 6425.45, average training loss: 10968.41, base loss: 10701.28
[INFO 2017-06-26 13:34:17,399 main.py:50] epoch 345, training loss: 6693.20, average training loss: 10956.05, base loss: 10700.69
[INFO 2017-06-26 13:34:18,366 main.py:50] epoch 346, training loss: 6739.94, average training loss: 10943.90, base loss: 10700.93
[INFO 2017-06-26 13:34:19,346 main.py:50] epoch 347, training loss: 6948.13, average training loss: 10932.42, base loss: 10701.76
[INFO 2017-06-26 13:34:20,341 main.py:50] epoch 348, training loss: 6678.58, average training loss: 10920.23, base loss: 10700.57
[INFO 2017-06-26 13:34:21,338 main.py:50] epoch 349, training loss: 6913.41, average training loss: 10908.78, base loss: 10701.19
[INFO 2017-06-26 13:34:22,322 main.py:50] epoch 350, training loss: 6648.52, average training loss: 10896.64, base loss: 10700.83
[INFO 2017-06-26 13:34:23,280 main.py:50] epoch 351, training loss: 6954.28, average training loss: 10885.44, base loss: 10701.92
[INFO 2017-06-26 13:34:24,223 main.py:50] epoch 352, training loss: 6572.16, average training loss: 10873.22, base loss: 10700.70
[INFO 2017-06-26 13:34:25,166 main.py:50] epoch 353, training loss: 6811.47, average training loss: 10861.75, base loss: 10701.25
[INFO 2017-06-26 13:34:26,148 main.py:50] epoch 354, training loss: 7046.59, average training loss: 10851.00, base loss: 10702.66
[INFO 2017-06-26 13:34:27,145 main.py:50] epoch 355, training loss: 6594.86, average training loss: 10839.05, base loss: 10701.53
[INFO 2017-06-26 13:34:28,090 main.py:50] epoch 356, training loss: 6610.72, average training loss: 10827.20, base loss: 10700.43
[INFO 2017-06-26 13:34:29,076 main.py:50] epoch 357, training loss: 7009.02, average training loss: 10816.54, base loss: 10701.22
