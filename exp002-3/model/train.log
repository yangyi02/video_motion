[INFO 2017-06-26 15:11:17,955 main.py:170] Namespace(batch_size=32, display=False, image_dir='/home/yi/Downloads/mpii-64-one-2', image_size=64, init_model_path='', input_video_path='video', learning_rate=0.001, method='unsupervised', motion_range=6, num_channel=3, num_inputs=1, output_flow_path='flow', output_flow_video_path='flow_video', save_dir='./model', test=False, test_epoch=10, test_interval=100, test_video=False, train=True, train_epoch=10000)
[INFO 2017-06-26 15:11:21,907 main.py:50] epoch 0, training loss: 154693.98, average training loss: 154693.98, base loss: 10809.32
[INFO 2017-06-26 15:11:24,017 main.py:50] epoch 1, training loss: 129241.60, average training loss: 141967.79, base loss: 10564.08
[INFO 2017-06-26 15:11:26,120 main.py:50] epoch 2, training loss: 111671.73, average training loss: 131869.11, base loss: 10557.55
[INFO 2017-06-26 15:11:28,713 main.py:50] epoch 3, training loss: 97673.30, average training loss: 123320.15, base loss: 10545.39
[INFO 2017-06-26 15:11:31,580 main.py:50] epoch 4, training loss: 85244.70, average training loss: 115705.06, base loss: 10576.73
[INFO 2017-06-26 15:11:34,431 main.py:50] epoch 5, training loss: 74603.37, average training loss: 108854.78, base loss: 10521.22
[INFO 2017-06-26 15:11:37,295 main.py:50] epoch 6, training loss: 64705.55, average training loss: 102547.75, base loss: 10527.78
[INFO 2017-06-26 15:11:40,156 main.py:50] epoch 7, training loss: 56602.82, average training loss: 96804.63, base loss: 10554.59
[INFO 2017-06-26 15:11:43,003 main.py:50] epoch 8, training loss: 49699.57, average training loss: 91570.74, base loss: 10585.65
[INFO 2017-06-26 15:11:45,859 main.py:50] epoch 9, training loss: 43871.62, average training loss: 86800.83, base loss: 10651.36
[INFO 2017-06-26 15:11:48,740 main.py:50] epoch 10, training loss: 38528.08, average training loss: 82412.39, base loss: 10652.77
[INFO 2017-06-26 15:11:51,591 main.py:50] epoch 11, training loss: 34475.64, average training loss: 78417.66, base loss: 10610.29
[INFO 2017-06-26 15:11:54,484 main.py:50] epoch 12, training loss: 31635.61, average training loss: 74819.04, base loss: 10654.73
[INFO 2017-06-26 15:11:57,335 main.py:50] epoch 13, training loss: 28964.98, average training loss: 71543.75, base loss: 10657.62
[INFO 2017-06-26 15:12:00,188 main.py:50] epoch 14, training loss: 26370.22, average training loss: 68532.19, base loss: 10670.54
[INFO 2017-06-26 15:12:03,095 main.py:50] epoch 15, training loss: 23682.80, average training loss: 65729.10, base loss: 10632.56
[INFO 2017-06-26 15:12:05,970 main.py:50] epoch 16, training loss: 22242.23, average training loss: 63171.05, base loss: 10651.06
[INFO 2017-06-26 15:12:08,830 main.py:50] epoch 17, training loss: 21280.27, average training loss: 60843.78, base loss: 10669.92
[INFO 2017-06-26 15:12:11,701 main.py:50] epoch 18, training loss: 20135.09, average training loss: 58701.22, base loss: 10706.42
[INFO 2017-06-26 15:12:14,558 main.py:50] epoch 19, training loss: 18373.01, average training loss: 56684.81, base loss: 10695.95
[INFO 2017-06-26 15:12:17,419 main.py:50] epoch 20, training loss: 17750.20, average training loss: 54830.78, base loss: 10693.61
[INFO 2017-06-26 15:12:20,298 main.py:50] epoch 21, training loss: 17315.32, average training loss: 53125.53, base loss: 10703.06
[INFO 2017-06-26 15:12:23,177 main.py:50] epoch 22, training loss: 16137.67, average training loss: 51517.36, base loss: 10681.79
[INFO 2017-06-26 15:12:26,043 main.py:50] epoch 23, training loss: 15972.65, average training loss: 50036.33, base loss: 10685.14
[INFO 2017-06-26 15:12:28,940 main.py:50] epoch 24, training loss: 15222.32, average training loss: 48643.77, base loss: 10682.75
[INFO 2017-06-26 15:12:31,806 main.py:50] epoch 25, training loss: 14666.77, average training loss: 47336.97, base loss: 10678.00
[INFO 2017-06-26 15:12:34,673 main.py:50] epoch 26, training loss: 14331.10, average training loss: 46114.53, base loss: 10675.68
[INFO 2017-06-26 15:12:37,537 main.py:50] epoch 27, training loss: 14138.60, average training loss: 44972.53, base loss: 10682.73
[INFO 2017-06-26 15:12:40,430 main.py:50] epoch 28, training loss: 13069.79, average training loss: 43872.43, base loss: 10667.47
[INFO 2017-06-26 15:12:43,322 main.py:50] epoch 29, training loss: 13251.74, average training loss: 42851.74, base loss: 10668.64
[INFO 2017-06-26 15:12:46,196 main.py:50] epoch 30, training loss: 13050.59, average training loss: 41890.42, base loss: 10671.89
[INFO 2017-06-26 15:12:49,094 main.py:50] epoch 31, training loss: 12501.89, average training loss: 40972.03, base loss: 10666.66
[INFO 2017-06-26 15:12:51,963 main.py:50] epoch 32, training loss: 13132.48, average training loss: 40128.40, base loss: 10688.19
[INFO 2017-06-26 15:12:54,836 main.py:50] epoch 33, training loss: 12418.18, average training loss: 39313.40, base loss: 10690.56
[INFO 2017-06-26 15:12:57,699 main.py:50] epoch 34, training loss: 12061.08, average training loss: 38534.76, base loss: 10690.55
[INFO 2017-06-26 15:13:00,588 main.py:50] epoch 35, training loss: 11617.53, average training loss: 37787.06, base loss: 10682.90
[INFO 2017-06-26 15:13:03,455 main.py:50] epoch 36, training loss: 11167.13, average training loss: 37067.60, base loss: 10666.78
[INFO 2017-06-26 15:13:06,319 main.py:50] epoch 37, training loss: 11259.80, average training loss: 36388.45, base loss: 10658.11
[INFO 2017-06-26 15:13:09,192 main.py:50] epoch 38, training loss: 11023.31, average training loss: 35738.06, base loss: 10647.02
[INFO 2017-06-26 15:13:12,073 main.py:50] epoch 39, training loss: 10681.23, average training loss: 35111.64, base loss: 10630.29
[INFO 2017-06-26 15:13:14,940 main.py:50] epoch 40, training loss: 10900.04, average training loss: 34521.11, base loss: 10622.63
[INFO 2017-06-26 15:13:17,805 main.py:50] epoch 41, training loss: 10753.47, average training loss: 33955.22, base loss: 10613.79
[INFO 2017-06-26 15:13:20,686 main.py:50] epoch 42, training loss: 10919.21, average training loss: 33419.49, base loss: 10611.68
[INFO 2017-06-26 15:13:23,588 main.py:50] epoch 43, training loss: 10756.67, average training loss: 32904.43, base loss: 10607.30
[INFO 2017-06-26 15:13:26,449 main.py:50] epoch 44, training loss: 10665.58, average training loss: 32410.23, base loss: 10601.88
[INFO 2017-06-26 15:13:29,314 main.py:50] epoch 45, training loss: 10505.70, average training loss: 31934.05, base loss: 10594.09
[INFO 2017-06-26 15:13:32,168 main.py:50] epoch 46, training loss: 11534.70, average training loss: 31500.02, base loss: 10610.35
[INFO 2017-06-26 15:13:35,043 main.py:50] epoch 47, training loss: 10591.54, average training loss: 31064.43, base loss: 10606.80
[INFO 2017-06-26 15:13:37,913 main.py:50] epoch 48, training loss: 10981.34, average training loss: 30654.57, base loss: 10612.44
[INFO 2017-06-26 15:13:40,776 main.py:50] epoch 49, training loss: 10604.79, average training loss: 30253.57, base loss: 10610.55
[INFO 2017-06-26 15:13:43,642 main.py:50] epoch 50, training loss: 11203.52, average training loss: 29880.04, base loss: 10621.62
[INFO 2017-06-26 15:13:46,504 main.py:50] epoch 51, training loss: 10776.36, average training loss: 29512.66, base loss: 10624.06
[INFO 2017-06-26 15:13:49,403 main.py:50] epoch 52, training loss: 10368.61, average training loss: 29151.45, base loss: 10619.09
[INFO 2017-06-26 15:13:52,262 main.py:50] epoch 53, training loss: 10544.23, average training loss: 28806.88, base loss: 10618.04
[INFO 2017-06-26 15:13:55,121 main.py:50] epoch 54, training loss: 10889.25, average training loss: 28481.10, base loss: 10623.66
[INFO 2017-06-26 15:13:57,990 main.py:50] epoch 55, training loss: 10891.74, average training loss: 28167.01, base loss: 10630.08
[INFO 2017-06-26 15:14:00,878 main.py:50] epoch 56, training loss: 10973.20, average training loss: 27865.36, base loss: 10637.70
[INFO 2017-06-26 15:14:03,738 main.py:50] epoch 57, training loss: 11009.20, average training loss: 27574.74, base loss: 10645.79
[INFO 2017-06-26 15:14:06,596 main.py:50] epoch 58, training loss: 10377.67, average training loss: 27283.26, base loss: 10642.50
[INFO 2017-06-26 15:14:09,501 main.py:50] epoch 59, training loss: 10683.68, average training loss: 27006.60, base loss: 10645.31
[INFO 2017-06-26 15:14:12,367 main.py:50] epoch 60, training loss: 10562.83, average training loss: 26737.03, base loss: 10646.07
[INFO 2017-06-26 15:14:15,243 main.py:50] epoch 61, training loss: 10937.34, average training loss: 26482.20, base loss: 10653.04
[INFO 2017-06-26 15:14:18,117 main.py:50] epoch 62, training loss: 10463.83, average training loss: 26227.94, base loss: 10651.83
[INFO 2017-06-26 15:14:21,015 main.py:50] epoch 63, training loss: 10511.63, average training loss: 25982.37, base loss: 10652.08
[INFO 2017-06-26 15:14:23,892 main.py:50] epoch 64, training loss: 10155.98, average training loss: 25738.89, base loss: 10646.50
[INFO 2017-06-26 15:14:26,772 main.py:50] epoch 65, training loss: 10163.26, average training loss: 25502.89, base loss: 10641.70
[INFO 2017-06-26 15:14:29,652 main.py:50] epoch 66, training loss: 10714.65, average training loss: 25282.17, base loss: 10645.81
[INFO 2017-06-26 15:14:32,536 main.py:50] epoch 67, training loss: 10395.92, average training loss: 25063.26, base loss: 10644.69
[INFO 2017-06-26 15:14:35,400 main.py:50] epoch 68, training loss: 11258.24, average training loss: 24863.18, base loss: 10656.97
[INFO 2017-06-26 15:14:38,274 main.py:50] epoch 69, training loss: 10335.23, average training loss: 24655.64, base loss: 10655.31
[INFO 2017-06-26 15:14:41,161 main.py:50] epoch 70, training loss: 10167.41, average training loss: 24451.58, base loss: 10651.50
[INFO 2017-06-26 15:14:44,030 main.py:50] epoch 71, training loss: 10244.17, average training loss: 24254.26, base loss: 10648.97
[INFO 2017-06-26 15:14:46,930 main.py:50] epoch 72, training loss: 11160.33, average training loss: 24074.89, base loss: 10659.39
[INFO 2017-06-26 15:14:49,793 main.py:50] epoch 73, training loss: 10443.39, average training loss: 23890.68, base loss: 10659.44
[INFO 2017-06-26 15:14:52,689 main.py:50] epoch 74, training loss: 10556.45, average training loss: 23712.89, base loss: 10661.54
[INFO 2017-06-26 15:14:55,613 main.py:50] epoch 75, training loss: 11155.83, average training loss: 23547.67, base loss: 10671.87
[INFO 2017-06-26 15:14:58,503 main.py:50] epoch 76, training loss: 10427.38, average training loss: 23377.27, base loss: 10672.15
[INFO 2017-06-26 15:15:01,415 main.py:50] epoch 77, training loss: 10013.31, average training loss: 23205.94, base loss: 10666.92
[INFO 2017-06-26 15:15:04,325 main.py:50] epoch 78, training loss: 10638.79, average training loss: 23046.86, base loss: 10670.62
[INFO 2017-06-26 15:15:07,213 main.py:50] epoch 79, training loss: 10432.68, average training loss: 22889.18, base loss: 10671.19
[INFO 2017-06-26 15:15:10,079 main.py:50] epoch 80, training loss: 10427.65, average training loss: 22735.34, base loss: 10672.01
[INFO 2017-06-26 15:15:12,973 main.py:50] epoch 81, training loss: 10225.13, average training loss: 22582.77, base loss: 10669.84
[INFO 2017-06-26 15:15:15,837 main.py:50] epoch 82, training loss: 10976.17, average training loss: 22442.94, base loss: 10677.90
[INFO 2017-06-26 15:15:18,745 main.py:50] epoch 83, training loss: 10777.51, average training loss: 22304.06, base loss: 10683.08
[INFO 2017-06-26 15:15:21,610 main.py:50] epoch 84, training loss: 10289.99, average training loss: 22162.72, base loss: 10682.46
[INFO 2017-06-26 15:15:24,488 main.py:50] epoch 85, training loss: 10281.09, average training loss: 22024.56, base loss: 10681.94
[INFO 2017-06-26 15:15:27,354 main.py:50] epoch 86, training loss: 10415.73, average training loss: 21891.13, base loss: 10682.67
[INFO 2017-06-26 15:15:30,217 main.py:50] epoch 87, training loss: 10329.28, average training loss: 21759.74, base loss: 10682.72
[INFO 2017-06-26 15:15:33,111 main.py:50] epoch 88, training loss: 10665.50, average training loss: 21635.09, base loss: 10686.71
[INFO 2017-06-26 15:15:35,968 main.py:50] epoch 89, training loss: 9971.52, average training loss: 21505.49, base loss: 10682.04
[INFO 2017-06-26 15:15:38,845 main.py:50] epoch 90, training loss: 10300.42, average training loss: 21382.36, base loss: 10681.92
[INFO 2017-06-26 15:15:41,721 main.py:50] epoch 91, training loss: 10998.82, average training loss: 21269.49, base loss: 10689.52
[INFO 2017-06-26 15:15:44,633 main.py:50] epoch 92, training loss: 10114.38, average training loss: 21149.55, base loss: 10686.95
[INFO 2017-06-26 15:15:47,514 main.py:50] epoch 93, training loss: 11155.15, average training loss: 21043.22, base loss: 10696.31
[INFO 2017-06-26 15:15:50,407 main.py:50] epoch 94, training loss: 10295.30, average training loss: 20930.09, base loss: 10696.05
[INFO 2017-06-26 15:15:53,318 main.py:50] epoch 95, training loss: 10382.91, average training loss: 20820.22, base loss: 10697.00
[INFO 2017-06-26 15:15:56,229 main.py:50] epoch 96, training loss: 9983.49, average training loss: 20708.50, base loss: 10693.09
[INFO 2017-06-26 15:15:59,128 main.py:50] epoch 97, training loss: 10357.47, average training loss: 20602.88, base loss: 10693.39
[INFO 2017-06-26 15:16:02,021 main.py:50] epoch 98, training loss: 10323.77, average training loss: 20499.05, base loss: 10693.90
[INFO 2017-06-26 15:16:04,930 main.py:50] epoch 99, training loss: 10134.66, average training loss: 20395.41, base loss: 10691.87
[INFO 2017-06-26 15:16:04,930 main.py:52] epoch 99, testing
[INFO 2017-06-26 15:16:18,105 main.py:103] average testing loss: 10209.20, base loss: 10613.06
[INFO 2017-06-26 15:16:18,106 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 15:16:18,112 main.py:76] current best accuracy: 10209.20
[INFO 2017-06-26 15:16:20,988 main.py:50] epoch 100, training loss: 10031.40, average training loss: 20292.79, base loss: 10689.22
[INFO 2017-06-26 15:16:23,870 main.py:50] epoch 101, training loss: 10041.26, average training loss: 20192.29, base loss: 10686.77
[INFO 2017-06-26 15:16:26,742 main.py:50] epoch 102, training loss: 9770.18, average training loss: 20091.10, base loss: 10681.74
[INFO 2017-06-26 15:16:29,616 main.py:50] epoch 103, training loss: 10328.88, average training loss: 19997.23, base loss: 10682.70
[INFO 2017-06-26 15:16:32,481 main.py:50] epoch 104, training loss: 10207.54, average training loss: 19904.00, base loss: 10681.92
[INFO 2017-06-26 15:16:35,387 main.py:50] epoch 105, training loss: 10079.40, average training loss: 19811.31, base loss: 10679.89
[INFO 2017-06-26 15:16:38,269 main.py:50] epoch 106, training loss: 9597.03, average training loss: 19715.85, base loss: 10673.20
[INFO 2017-06-26 15:16:41,143 main.py:50] epoch 107, training loss: 9911.52, average training loss: 19625.07, base loss: 10670.19
[INFO 2017-06-26 15:16:44,056 main.py:50] epoch 108, training loss: 10015.16, average training loss: 19536.91, base loss: 10667.88
[INFO 2017-06-26 15:16:46,935 main.py:50] epoch 109, training loss: 9765.26, average training loss: 19448.08, base loss: 10663.11
[INFO 2017-06-26 15:16:49,803 main.py:50] epoch 110, training loss: 9935.89, average training loss: 19362.38, base loss: 10660.90
[INFO 2017-06-26 15:16:52,695 main.py:50] epoch 111, training loss: 10397.95, average training loss: 19282.34, base loss: 10662.87
[INFO 2017-06-26 15:16:55,602 main.py:50] epoch 112, training loss: 10317.46, average training loss: 19203.01, base loss: 10663.91
[INFO 2017-06-26 15:16:58,473 main.py:50] epoch 113, training loss: 9633.88, average training loss: 19119.07, base loss: 10658.39
[INFO 2017-06-26 15:17:01,345 main.py:50] epoch 114, training loss: 10040.93, average training loss: 19040.13, base loss: 10656.87
[INFO 2017-06-26 15:17:04,206 main.py:50] epoch 115, training loss: 10158.69, average training loss: 18963.56, base loss: 10657.21
[INFO 2017-06-26 15:17:07,066 main.py:50] epoch 116, training loss: 10411.84, average training loss: 18890.47, base loss: 10659.09
[INFO 2017-06-26 15:17:09,936 main.py:50] epoch 117, training loss: 9998.37, average training loss: 18815.11, base loss: 10657.38
[INFO 2017-06-26 15:17:12,852 main.py:50] epoch 118, training loss: 10291.95, average training loss: 18743.49, base loss: 10659.00
[INFO 2017-06-26 15:17:15,715 main.py:50] epoch 119, training loss: 10556.29, average training loss: 18675.26, base loss: 10662.44
[INFO 2017-06-26 15:17:18,623 main.py:50] epoch 120, training loss: 10083.74, average training loss: 18604.26, base loss: 10662.08
[INFO 2017-06-26 15:17:21,519 main.py:50] epoch 121, training loss: 10484.68, average training loss: 18537.70, base loss: 10665.17
[INFO 2017-06-26 15:17:24,385 main.py:50] epoch 122, training loss: 9747.18, average training loss: 18466.24, base loss: 10661.74
[INFO 2017-06-26 15:17:27,250 main.py:50] epoch 123, training loss: 10386.75, average training loss: 18401.08, base loss: 10663.89
[INFO 2017-06-26 15:17:30,111 main.py:50] epoch 124, training loss: 9806.19, average training loss: 18332.32, base loss: 10661.22
[INFO 2017-06-26 15:17:32,974 main.py:50] epoch 125, training loss: 9803.75, average training loss: 18264.63, base loss: 10658.85
[INFO 2017-06-26 15:17:35,856 main.py:50] epoch 126, training loss: 10248.26, average training loss: 18201.51, base loss: 10660.12
[INFO 2017-06-26 15:17:38,720 main.py:50] epoch 127, training loss: 9889.83, average training loss: 18136.58, base loss: 10658.15
[INFO 2017-06-26 15:17:41,604 main.py:50] epoch 128, training loss: 10568.59, average training loss: 18077.91, base loss: 10662.20
[INFO 2017-06-26 15:17:44,487 main.py:50] epoch 129, training loss: 10020.83, average training loss: 18015.93, base loss: 10661.53
[INFO 2017-06-26 15:17:47,400 main.py:50] epoch 130, training loss: 10283.97, average training loss: 17956.91, base loss: 10663.39
[INFO 2017-06-26 15:17:50,284 main.py:50] epoch 131, training loss: 10049.30, average training loss: 17897.00, base loss: 10663.18
[INFO 2017-06-26 15:17:53,167 main.py:50] epoch 132, training loss: 10351.90, average training loss: 17840.27, base loss: 10665.32
[INFO 2017-06-26 15:17:56,063 main.py:50] epoch 133, training loss: 9942.37, average training loss: 17781.33, base loss: 10664.28
[INFO 2017-06-26 15:17:58,974 main.py:50] epoch 134, training loss: 9866.92, average training loss: 17722.71, base loss: 10663.26
[INFO 2017-06-26 15:18:01,849 main.py:50] epoch 135, training loss: 9655.75, average training loss: 17663.39, base loss: 10660.05
[INFO 2017-06-26 15:18:04,725 main.py:50] epoch 136, training loss: 9605.79, average training loss: 17604.58, base loss: 10656.42
[INFO 2017-06-26 15:18:07,593 main.py:50] epoch 137, training loss: 10525.29, average training loss: 17553.28, base loss: 10660.47
[INFO 2017-06-26 15:18:10,460 main.py:50] epoch 138, training loss: 9807.90, average training loss: 17497.56, base loss: 10659.21
[INFO 2017-06-26 15:18:13,331 main.py:50] epoch 139, training loss: 9777.53, average training loss: 17442.41, base loss: 10657.79
[INFO 2017-06-26 15:18:16,233 main.py:50] epoch 140, training loss: 9855.69, average training loss: 17388.61, base loss: 10656.52
[INFO 2017-06-26 15:18:19,104 main.py:50] epoch 141, training loss: 10459.66, average training loss: 17339.81, base loss: 10660.21
[INFO 2017-06-26 15:18:21,962 main.py:50] epoch 142, training loss: 9402.94, average training loss: 17284.31, base loss: 10655.83
[INFO 2017-06-26 15:18:24,839 main.py:50] epoch 143, training loss: 9928.77, average training loss: 17233.23, base loss: 10655.57
[INFO 2017-06-26 15:18:27,699 main.py:50] epoch 144, training loss: 10517.46, average training loss: 17186.91, base loss: 10659.89
[INFO 2017-06-26 15:18:30,570 main.py:50] epoch 145, training loss: 10297.29, average training loss: 17139.72, base loss: 10662.37
[INFO 2017-06-26 15:18:33,442 main.py:50] epoch 146, training loss: 10466.03, average training loss: 17094.33, base loss: 10666.18
[INFO 2017-06-26 15:18:36,304 main.py:50] epoch 147, training loss: 10085.10, average training loss: 17046.97, base loss: 10667.08
[INFO 2017-06-26 15:18:39,166 main.py:50] epoch 148, training loss: 10227.23, average training loss: 17001.20, base loss: 10669.40
[INFO 2017-06-26 15:18:42,030 main.py:50] epoch 149, training loss: 9799.35, average training loss: 16953.18, base loss: 10668.45
[INFO 2017-06-26 15:18:44,895 main.py:50] epoch 150, training loss: 9586.97, average training loss: 16904.40, base loss: 10666.44
[INFO 2017-06-26 15:18:47,777 main.py:50] epoch 151, training loss: 9588.88, average training loss: 16856.27, base loss: 10664.48
[INFO 2017-06-26 15:18:50,664 main.py:50] epoch 152, training loss: 9959.21, average training loss: 16811.19, base loss: 10665.51
[INFO 2017-06-26 15:18:53,564 main.py:50] epoch 153, training loss: 9977.68, average training loss: 16766.82, base loss: 10666.54
[INFO 2017-06-26 15:18:56,424 main.py:50] epoch 154, training loss: 9491.94, average training loss: 16719.89, base loss: 10664.14
[INFO 2017-06-26 15:18:59,299 main.py:50] epoch 155, training loss: 9829.47, average training loss: 16675.72, base loss: 10664.64
[INFO 2017-06-26 15:19:02,180 main.py:50] epoch 156, training loss: 9350.00, average training loss: 16629.06, base loss: 10661.28
[INFO 2017-06-26 15:19:05,048 main.py:50] epoch 157, training loss: 9870.46, average training loss: 16586.28, base loss: 10662.25
[INFO 2017-06-26 15:19:07,915 main.py:50] epoch 158, training loss: 10190.48, average training loss: 16546.05, base loss: 10665.35
[INFO 2017-06-26 15:19:10,812 main.py:50] epoch 159, training loss: 9384.12, average training loss: 16501.29, base loss: 10663.06
[INFO 2017-06-26 15:19:13,707 main.py:50] epoch 160, training loss: 9682.36, average training loss: 16458.94, base loss: 10662.98
[INFO 2017-06-26 15:19:16,575 main.py:50] epoch 161, training loss: 9670.47, average training loss: 16417.03, base loss: 10662.82
[INFO 2017-06-26 15:19:19,480 main.py:50] epoch 162, training loss: 10252.11, average training loss: 16379.21, base loss: 10666.55
[INFO 2017-06-26 15:19:22,346 main.py:50] epoch 163, training loss: 9729.62, average training loss: 16338.67, base loss: 10666.67
[INFO 2017-06-26 15:19:25,209 main.py:50] epoch 164, training loss: 9671.62, average training loss: 16298.26, base loss: 10667.15
[INFO 2017-06-26 15:19:28,075 main.py:50] epoch 165, training loss: 9577.61, average training loss: 16257.77, base loss: 10666.41
[INFO 2017-06-26 15:19:30,936 main.py:50] epoch 166, training loss: 9870.92, average training loss: 16219.53, base loss: 10668.93
[INFO 2017-06-26 15:19:33,803 main.py:50] epoch 167, training loss: 9293.71, average training loss: 16178.30, base loss: 10666.78
[INFO 2017-06-26 15:19:36,668 main.py:50] epoch 168, training loss: 9811.54, average training loss: 16140.63, base loss: 10668.71
[INFO 2017-06-26 15:19:39,532 main.py:50] epoch 169, training loss: 9576.71, average training loss: 16102.02, base loss: 10668.12
[INFO 2017-06-26 15:19:42,432 main.py:50] epoch 170, training loss: 9599.52, average training loss: 16063.99, base loss: 10667.76
[INFO 2017-06-26 15:19:45,311 main.py:50] epoch 171, training loss: 9295.40, average training loss: 16024.64, base loss: 10666.89
[INFO 2017-06-26 15:19:48,203 main.py:50] epoch 172, training loss: 9728.34, average training loss: 15988.25, base loss: 10669.20
[INFO 2017-06-26 15:19:51,076 main.py:50] epoch 173, training loss: 9590.07, average training loss: 15951.48, base loss: 10671.12
[INFO 2017-06-26 15:19:53,941 main.py:50] epoch 174, training loss: 8860.63, average training loss: 15910.96, base loss: 10667.93
[INFO 2017-06-26 15:19:56,803 main.py:50] epoch 175, training loss: 9421.09, average training loss: 15874.08, base loss: 10668.81
[INFO 2017-06-26 15:19:59,667 main.py:50] epoch 176, training loss: 9526.68, average training loss: 15838.22, base loss: 10670.97
[INFO 2017-06-26 15:20:02,545 main.py:50] epoch 177, training loss: 9609.19, average training loss: 15803.23, base loss: 10673.02
[INFO 2017-06-26 15:20:05,409 main.py:50] epoch 178, training loss: 9245.63, average training loss: 15766.59, base loss: 10674.00
[INFO 2017-06-26 15:20:08,271 main.py:50] epoch 179, training loss: 9242.62, average training loss: 15730.35, base loss: 10674.53
[INFO 2017-06-26 15:20:11,136 main.py:50] epoch 180, training loss: 9237.08, average training loss: 15694.47, base loss: 10675.07
[INFO 2017-06-26 15:20:14,016 main.py:50] epoch 181, training loss: 9429.43, average training loss: 15660.05, base loss: 10676.93
[INFO 2017-06-26 15:20:16,915 main.py:50] epoch 182, training loss: 9180.71, average training loss: 15624.64, base loss: 10677.82
[INFO 2017-06-26 15:20:19,785 main.py:50] epoch 183, training loss: 9146.85, average training loss: 15589.44, base loss: 10677.83
[INFO 2017-06-26 15:20:22,673 main.py:50] epoch 184, training loss: 9094.33, average training loss: 15554.33, base loss: 10678.69
[INFO 2017-06-26 15:20:25,542 main.py:50] epoch 185, training loss: 9029.51, average training loss: 15519.25, base loss: 10679.17
[INFO 2017-06-26 15:20:28,418 main.py:50] epoch 186, training loss: 9431.64, average training loss: 15486.70, base loss: 10680.91
[INFO 2017-06-26 15:20:31,320 main.py:50] epoch 187, training loss: 9039.95, average training loss: 15452.40, base loss: 10679.31
[INFO 2017-06-26 15:20:34,222 main.py:50] epoch 188, training loss: 9082.70, average training loss: 15418.70, base loss: 10677.00
[INFO 2017-06-26 15:20:37,101 main.py:50] epoch 189, training loss: 9808.40, average training loss: 15389.17, base loss: 10677.04
[INFO 2017-06-26 15:20:39,983 main.py:50] epoch 190, training loss: 9633.90, average training loss: 15359.04, base loss: 10678.72
[INFO 2017-06-26 15:20:42,854 main.py:50] epoch 191, training loss: 9280.34, average training loss: 15327.38, base loss: 10678.14
[INFO 2017-06-26 15:20:45,722 main.py:50] epoch 192, training loss: 9440.29, average training loss: 15296.88, base loss: 10680.07
[INFO 2017-06-26 15:20:48,603 main.py:50] epoch 193, training loss: 9365.77, average training loss: 15266.31, base loss: 10681.37
[INFO 2017-06-26 15:20:51,462 main.py:50] epoch 194, training loss: 9677.41, average training loss: 15237.65, base loss: 10684.34
[INFO 2017-06-26 15:20:54,337 main.py:50] epoch 195, training loss: 9179.38, average training loss: 15206.74, base loss: 10683.20
[INFO 2017-06-26 15:20:57,220 main.py:50] epoch 196, training loss: 8984.66, average training loss: 15175.15, base loss: 10681.80
[INFO 2017-06-26 15:21:00,078 main.py:50] epoch 197, training loss: 8618.28, average training loss: 15142.04, base loss: 10679.17
[INFO 2017-06-26 15:21:02,962 main.py:50] epoch 198, training loss: 8778.09, average training loss: 15110.06, base loss: 10677.03
[INFO 2017-06-26 15:21:05,841 main.py:50] epoch 199, training loss: 9217.83, average training loss: 15080.60, base loss: 10678.25
[INFO 2017-06-26 15:21:05,841 main.py:52] epoch 199, testing
[INFO 2017-06-26 15:21:19,064 main.py:103] average testing loss: 8971.05, base loss: 10663.64
[INFO 2017-06-26 15:21:19,064 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 15:21:19,071 main.py:76] current best accuracy: 8971.05
[INFO 2017-06-26 15:21:21,971 main.py:50] epoch 200, training loss: 8729.34, average training loss: 15049.00, base loss: 10676.22
[INFO 2017-06-26 15:21:24,869 main.py:50] epoch 201, training loss: 8555.53, average training loss: 15016.85, base loss: 10674.85
[INFO 2017-06-26 15:21:27,745 main.py:50] epoch 202, training loss: 9387.24, average training loss: 14989.12, base loss: 10677.88
[INFO 2017-06-26 15:21:30,618 main.py:50] epoch 203, training loss: 8782.01, average training loss: 14958.69, base loss: 10677.13
[INFO 2017-06-26 15:21:33,503 main.py:50] epoch 204, training loss: 8810.30, average training loss: 14928.70, base loss: 10677.29
[INFO 2017-06-26 15:21:36,374 main.py:50] epoch 205, training loss: 8643.32, average training loss: 14898.19, base loss: 10676.35
[INFO 2017-06-26 15:21:39,249 main.py:50] epoch 206, training loss: 8552.54, average training loss: 14867.53, base loss: 10674.81
[INFO 2017-06-26 15:21:42,129 main.py:50] epoch 207, training loss: 8936.78, average training loss: 14839.02, base loss: 10674.90
[INFO 2017-06-26 15:21:45,016 main.py:50] epoch 208, training loss: 9033.00, average training loss: 14811.24, base loss: 10676.23
[INFO 2017-06-26 15:21:47,883 main.py:50] epoch 209, training loss: 8444.95, average training loss: 14780.92, base loss: 10674.63
[INFO 2017-06-26 15:21:50,787 main.py:50] epoch 210, training loss: 8819.95, average training loss: 14752.67, base loss: 10675.04
[INFO 2017-06-26 15:21:53,652 main.py:50] epoch 211, training loss: 8508.64, average training loss: 14723.22, base loss: 10672.99
[INFO 2017-06-26 15:21:56,510 main.py:50] epoch 212, training loss: 9082.71, average training loss: 14696.74, base loss: 10675.11
[INFO 2017-06-26 15:21:59,372 main.py:50] epoch 213, training loss: 8748.46, average training loss: 14668.94, base loss: 10676.07
[INFO 2017-06-26 15:22:02,252 main.py:50] epoch 214, training loss: 8718.13, average training loss: 14641.27, base loss: 10676.38
[INFO 2017-06-26 15:22:05,149 main.py:50] epoch 215, training loss: 8602.16, average training loss: 14613.31, base loss: 10676.97
[INFO 2017-06-26 15:22:08,048 main.py:50] epoch 216, training loss: 8438.24, average training loss: 14584.85, base loss: 10676.23
[INFO 2017-06-26 15:22:10,956 main.py:50] epoch 217, training loss: 8577.40, average training loss: 14557.29, base loss: 10676.70
[INFO 2017-06-26 15:22:13,815 main.py:50] epoch 218, training loss: 8322.31, average training loss: 14528.82, base loss: 10675.66
[INFO 2017-06-26 15:22:16,689 main.py:50] epoch 219, training loss: 8707.54, average training loss: 14502.36, base loss: 10676.77
[INFO 2017-06-26 15:22:19,556 main.py:50] epoch 220, training loss: 8120.98, average training loss: 14473.49, base loss: 10675.25
[INFO 2017-06-26 15:22:22,445 main.py:50] epoch 221, training loss: 8221.98, average training loss: 14445.33, base loss: 10672.55
[INFO 2017-06-26 15:22:25,306 main.py:50] epoch 222, training loss: 8154.73, average training loss: 14417.12, base loss: 10670.61
[INFO 2017-06-26 15:22:28,172 main.py:50] epoch 223, training loss: 8628.67, average training loss: 14391.28, base loss: 10671.62
[INFO 2017-06-26 15:22:31,046 main.py:50] epoch 224, training loss: 8258.17, average training loss: 14364.02, base loss: 10670.97
[INFO 2017-06-26 15:22:33,956 main.py:50] epoch 225, training loss: 8369.27, average training loss: 14337.49, base loss: 10671.23
[INFO 2017-06-26 15:22:36,836 main.py:50] epoch 226, training loss: 8432.64, average training loss: 14311.48, base loss: 10671.31
[INFO 2017-06-26 15:22:39,728 main.py:50] epoch 227, training loss: 8273.76, average training loss: 14285.00, base loss: 10671.05
[INFO 2017-06-26 15:22:42,598 main.py:50] epoch 228, training loss: 8485.55, average training loss: 14259.67, base loss: 10671.82
[INFO 2017-06-26 15:22:45,479 main.py:50] epoch 229, training loss: 8320.51, average training loss: 14233.85, base loss: 10671.31
[INFO 2017-06-26 15:22:48,334 main.py:50] epoch 230, training loss: 8180.88, average training loss: 14207.65, base loss: 10670.43
[INFO 2017-06-26 15:22:51,212 main.py:50] epoch 231, training loss: 8318.14, average training loss: 14182.26, base loss: 10670.63
[INFO 2017-06-26 15:22:54,078 main.py:50] epoch 232, training loss: 8267.96, average training loss: 14156.88, base loss: 10670.70
[INFO 2017-06-26 15:22:56,965 main.py:50] epoch 233, training loss: 8051.41, average training loss: 14130.79, base loss: 10669.76
[INFO 2017-06-26 15:22:59,866 main.py:50] epoch 234, training loss: 8275.71, average training loss: 14105.87, base loss: 10669.84
[INFO 2017-06-26 15:23:02,757 main.py:50] epoch 235, training loss: 8246.87, average training loss: 14081.05, base loss: 10669.26
[INFO 2017-06-26 15:23:05,624 main.py:50] epoch 236, training loss: 8211.12, average training loss: 14056.28, base loss: 10669.06
[INFO 2017-06-26 15:23:08,489 main.py:50] epoch 237, training loss: 8471.85, average training loss: 14032.81, base loss: 10670.47
[INFO 2017-06-26 15:23:11,361 main.py:50] epoch 238, training loss: 8515.14, average training loss: 14009.73, base loss: 10671.95
[INFO 2017-06-26 15:23:14,214 main.py:50] epoch 239, training loss: 8423.99, average training loss: 13986.45, base loss: 10673.69
[INFO 2017-06-26 15:23:17,106 main.py:50] epoch 240, training loss: 8050.87, average training loss: 13961.83, base loss: 10672.62
[INFO 2017-06-26 15:23:20,006 main.py:50] epoch 241, training loss: 7806.85, average training loss: 13936.39, base loss: 10669.97
[INFO 2017-06-26 15:23:22,861 main.py:50] epoch 242, training loss: 8236.54, average training loss: 13912.94, base loss: 10670.13
[INFO 2017-06-26 15:23:25,733 main.py:50] epoch 243, training loss: 8426.01, average training loss: 13890.45, base loss: 10672.17
[INFO 2017-06-26 15:23:28,601 main.py:50] epoch 244, training loss: 8469.55, average training loss: 13868.32, base loss: 10672.19
[INFO 2017-06-26 15:23:31,467 main.py:50] epoch 245, training loss: 8142.26, average training loss: 13845.05, base loss: 10672.28
[INFO 2017-06-26 15:23:34,336 main.py:50] epoch 246, training loss: 8043.59, average training loss: 13821.56, base loss: 10672.07
[INFO 2017-06-26 15:23:37,205 main.py:50] epoch 247, training loss: 8409.00, average training loss: 13799.73, base loss: 10672.74
[INFO 2017-06-26 15:23:40,063 main.py:50] epoch 248, training loss: 7875.47, average training loss: 13775.94, base loss: 10671.22
[INFO 2017-06-26 15:23:42,930 main.py:50] epoch 249, training loss: 8045.30, average training loss: 13753.02, base loss: 10671.06
[INFO 2017-06-26 15:23:45,808 main.py:50] epoch 250, training loss: 7969.48, average training loss: 13729.98, base loss: 10670.70
[INFO 2017-06-26 15:23:48,669 main.py:50] epoch 251, training loss: 8184.98, average training loss: 13707.97, base loss: 10670.38
[INFO 2017-06-26 15:23:51,533 main.py:50] epoch 252, training loss: 7971.47, average training loss: 13685.30, base loss: 10669.94
[INFO 2017-06-26 15:23:54,425 main.py:50] epoch 253, training loss: 8350.78, average training loss: 13664.30, base loss: 10671.98
[INFO 2017-06-26 15:23:57,291 main.py:50] epoch 254, training loss: 8035.87, average training loss: 13642.22, base loss: 10671.86
[INFO 2017-06-26 15:24:00,157 main.py:50] epoch 255, training loss: 8194.32, average training loss: 13620.94, base loss: 10672.56
[INFO 2017-06-26 15:24:03,036 main.py:50] epoch 256, training loss: 8260.75, average training loss: 13600.09, base loss: 10674.26
[INFO 2017-06-26 15:24:05,898 main.py:50] epoch 257, training loss: 8289.36, average training loss: 13579.50, base loss: 10675.74
[INFO 2017-06-26 15:24:08,765 main.py:50] epoch 258, training loss: 7944.20, average training loss: 13557.74, base loss: 10674.91
[INFO 2017-06-26 15:24:11,633 main.py:50] epoch 259, training loss: 8217.53, average training loss: 13537.20, base loss: 10676.32
[INFO 2017-06-26 15:24:14,492 main.py:50] epoch 260, training loss: 7728.48, average training loss: 13514.95, base loss: 10674.50
[INFO 2017-06-26 15:24:17,363 main.py:50] epoch 261, training loss: 8011.79, average training loss: 13493.94, base loss: 10674.65
[INFO 2017-06-26 15:24:20,238 main.py:50] epoch 262, training loss: 7938.44, average training loss: 13472.82, base loss: 10674.71
[INFO 2017-06-26 15:24:23,109 main.py:50] epoch 263, training loss: 8035.02, average training loss: 13452.22, base loss: 10675.81
[INFO 2017-06-26 15:24:25,986 main.py:50] epoch 264, training loss: 7991.25, average training loss: 13431.62, base loss: 10676.78
[INFO 2017-06-26 15:24:28,901 main.py:50] epoch 265, training loss: 7936.90, average training loss: 13410.96, base loss: 10677.43
[INFO 2017-06-26 15:24:31,772 main.py:50] epoch 266, training loss: 8084.76, average training loss: 13391.01, base loss: 10677.64
[INFO 2017-06-26 15:24:34,653 main.py:50] epoch 267, training loss: 7706.23, average training loss: 13369.80, base loss: 10677.33
[INFO 2017-06-26 15:24:37,518 main.py:50] epoch 268, training loss: 7915.04, average training loss: 13349.52, base loss: 10676.43
[INFO 2017-06-26 15:24:40,382 main.py:50] epoch 269, training loss: 7966.39, average training loss: 13329.58, base loss: 10676.59
[INFO 2017-06-26 15:24:43,287 main.py:50] epoch 270, training loss: 7896.64, average training loss: 13309.54, base loss: 10676.94
[INFO 2017-06-26 15:24:46,178 main.py:50] epoch 271, training loss: 7636.02, average training loss: 13288.68, base loss: 10674.84
[INFO 2017-06-26 15:24:49,054 main.py:50] epoch 272, training loss: 8259.50, average training loss: 13270.26, base loss: 10677.06
[INFO 2017-06-26 15:24:51,924 main.py:50] epoch 273, training loss: 8055.30, average training loss: 13251.22, base loss: 10678.27
[INFO 2017-06-26 15:24:54,793 main.py:50] epoch 274, training loss: 8022.42, average training loss: 13232.21, base loss: 10679.97
[INFO 2017-06-26 15:24:57,662 main.py:50] epoch 275, training loss: 7950.99, average training loss: 13213.07, base loss: 10680.56
[INFO 2017-06-26 15:25:00,557 main.py:50] epoch 276, training loss: 7981.48, average training loss: 13194.19, base loss: 10681.11
[INFO 2017-06-26 15:25:03,475 main.py:50] epoch 277, training loss: 7923.62, average training loss: 13175.23, base loss: 10681.02
[INFO 2017-06-26 15:25:06,342 main.py:50] epoch 278, training loss: 7904.60, average training loss: 13156.34, base loss: 10680.85
[INFO 2017-06-26 15:25:09,257 main.py:50] epoch 279, training loss: 8077.65, average training loss: 13138.20, base loss: 10681.77
[INFO 2017-06-26 15:25:12,155 main.py:50] epoch 280, training loss: 7915.02, average training loss: 13119.61, base loss: 10682.38
[INFO 2017-06-26 15:25:15,031 main.py:50] epoch 281, training loss: 7922.13, average training loss: 13101.18, base loss: 10683.13
[INFO 2017-06-26 15:25:17,935 main.py:50] epoch 282, training loss: 7868.26, average training loss: 13082.69, base loss: 10683.38
[INFO 2017-06-26 15:25:20,806 main.py:50] epoch 283, training loss: 7883.64, average training loss: 13064.38, base loss: 10682.94
[INFO 2017-06-26 15:25:23,685 main.py:50] epoch 284, training loss: 8115.83, average training loss: 13047.02, base loss: 10684.14
[INFO 2017-06-26 15:25:26,582 main.py:50] epoch 285, training loss: 7736.55, average training loss: 13028.45, base loss: 10683.61
[INFO 2017-06-26 15:25:29,448 main.py:50] epoch 286, training loss: 7503.21, average training loss: 13009.20, base loss: 10681.87
[INFO 2017-06-26 15:25:32,337 main.py:50] epoch 287, training loss: 7695.55, average training loss: 12990.75, base loss: 10681.19
[INFO 2017-06-26 15:25:35,213 main.py:50] epoch 288, training loss: 8030.56, average training loss: 12973.59, base loss: 10682.01
[INFO 2017-06-26 15:25:38,091 main.py:50] epoch 289, training loss: 7480.59, average training loss: 12954.65, base loss: 10681.06
[INFO 2017-06-26 15:25:40,975 main.py:50] epoch 290, training loss: 7626.57, average training loss: 12936.34, base loss: 10680.25
[INFO 2017-06-26 15:25:43,851 main.py:50] epoch 291, training loss: 8070.61, average training loss: 12919.67, base loss: 10681.89
[INFO 2017-06-26 15:25:46,772 main.py:50] epoch 292, training loss: 7750.36, average training loss: 12902.03, base loss: 10682.29
[INFO 2017-06-26 15:25:49,646 main.py:50] epoch 293, training loss: 7423.84, average training loss: 12883.40, base loss: 10679.89
[INFO 2017-06-26 15:25:52,518 main.py:50] epoch 294, training loss: 7713.13, average training loss: 12865.87, base loss: 10679.92
[INFO 2017-06-26 15:25:55,386 main.py:50] epoch 295, training loss: 7812.17, average training loss: 12848.80, base loss: 10679.77
[INFO 2017-06-26 15:25:58,257 main.py:50] epoch 296, training loss: 7906.93, average training loss: 12832.16, base loss: 10680.38
[INFO 2017-06-26 15:26:01,152 main.py:50] epoch 297, training loss: 8032.52, average training loss: 12816.05, base loss: 10681.91
[INFO 2017-06-26 15:26:04,059 main.py:50] epoch 298, training loss: 7322.18, average training loss: 12797.68, base loss: 10679.37
[INFO 2017-06-26 15:26:06,947 main.py:50] epoch 299, training loss: 7569.29, average training loss: 12780.25, base loss: 10678.50
[INFO 2017-06-26 15:26:06,948 main.py:52] epoch 299, testing
[INFO 2017-06-26 15:26:20,202 main.py:103] average testing loss: 7672.11, base loss: 10617.93
[INFO 2017-06-26 15:26:20,202 main.py:72] model save to ./model/final.pth
[INFO 2017-06-26 15:26:20,209 main.py:76] current best accuracy: 7672.11
[INFO 2017-06-26 15:26:23,121 main.py:50] epoch 300, training loss: 7458.14, average training loss: 12762.57, base loss: 10676.63
[INFO 2017-06-26 15:26:26,006 main.py:50] epoch 301, training loss: 7706.09, average training loss: 12745.82, base loss: 10676.90
[INFO 2017-06-26 15:26:28,907 main.py:50] epoch 302, training loss: 7941.54, average training loss: 12729.97, base loss: 10678.34
[INFO 2017-06-26 15:26:31,820 main.py:50] epoch 303, training loss: 7700.48, average training loss: 12713.42, base loss: 10678.46
[INFO 2017-06-26 15:26:34,687 main.py:50] epoch 304, training loss: 7690.46, average training loss: 12696.96, base loss: 10677.95
[INFO 2017-06-26 15:26:37,593 main.py:50] epoch 305, training loss: 7510.97, average training loss: 12680.01, base loss: 10677.14
[INFO 2017-06-26 15:26:40,529 main.py:50] epoch 306, training loss: 7582.52, average training loss: 12663.40, base loss: 10676.82
[INFO 2017-06-26 15:26:43,549 main.py:50] epoch 307, training loss: 7443.56, average training loss: 12646.46, base loss: 10676.10
[INFO 2017-06-26 15:26:46,405 main.py:50] epoch 308, training loss: 7579.51, average training loss: 12630.06, base loss: 10675.94
[INFO 2017-06-26 15:26:49,321 main.py:50] epoch 309, training loss: 7998.44, average training loss: 12615.12, base loss: 10677.72
[INFO 2017-06-26 15:26:52,236 main.py:50] epoch 310, training loss: 7640.40, average training loss: 12599.12, base loss: 10677.71
[INFO 2017-06-26 15:26:55,109 main.py:50] epoch 311, training loss: 7517.35, average training loss: 12582.83, base loss: 10677.67
[INFO 2017-06-26 15:26:57,991 main.py:50] epoch 312, training loss: 7337.25, average training loss: 12566.07, base loss: 10675.84
[INFO 2017-06-26 15:27:00,861 main.py:50] epoch 313, training loss: 7540.96, average training loss: 12550.07, base loss: 10675.63
[INFO 2017-06-26 15:27:03,819 main.py:50] epoch 314, training loss: 7630.72, average training loss: 12534.45, base loss: 10675.48
[INFO 2017-06-26 15:27:06,823 main.py:50] epoch 315, training loss: 8369.47, average training loss: 12521.27, base loss: 10679.45
[INFO 2017-06-26 15:27:09,703 main.py:50] epoch 316, training loss: 7836.43, average training loss: 12506.50, base loss: 10680.74
[INFO 2017-06-26 15:27:12,770 main.py:50] epoch 317, training loss: 7583.44, average training loss: 12491.01, base loss: 10680.26
[INFO 2017-06-26 15:27:15,625 main.py:50] epoch 318, training loss: 7786.78, average training loss: 12476.27, base loss: 10680.54
[INFO 2017-06-26 15:27:18,490 main.py:50] epoch 319, training loss: 7360.64, average training loss: 12460.28, base loss: 10679.02
[INFO 2017-06-26 15:27:21,507 main.py:50] epoch 320, training loss: 7426.16, average training loss: 12444.60, base loss: 10678.53
[INFO 2017-06-26 15:27:24,368 main.py:50] epoch 321, training loss: 7209.00, average training loss: 12428.34, base loss: 10676.60
[INFO 2017-06-26 15:27:27,452 main.py:50] epoch 322, training loss: 7703.02, average training loss: 12413.71, base loss: 10677.42
[INFO 2017-06-26 15:27:30,714 main.py:50] epoch 323, training loss: 7399.19, average training loss: 12398.23, base loss: 10676.88
[INFO 2017-06-26 15:27:33,788 main.py:50] epoch 324, training loss: 7849.76, average training loss: 12384.24, base loss: 10677.80
[INFO 2017-06-26 15:27:36,881 main.py:50] epoch 325, training loss: 7280.90, average training loss: 12368.58, base loss: 10676.33
[INFO 2017-06-26 15:27:39,779 main.py:50] epoch 326, training loss: 7353.01, average training loss: 12353.24, base loss: 10675.68
[INFO 2017-06-26 15:27:42,810 main.py:50] epoch 327, training loss: 7491.76, average training loss: 12338.42, base loss: 10675.43
[INFO 2017-06-26 15:27:45,704 main.py:50] epoch 328, training loss: 7479.15, average training loss: 12323.65, base loss: 10675.38
[INFO 2017-06-26 15:27:48,583 main.py:50] epoch 329, training loss: 7615.78, average training loss: 12309.39, base loss: 10676.29
[INFO 2017-06-26 15:27:51,442 main.py:50] epoch 330, training loss: 7398.51, average training loss: 12294.55, base loss: 10675.69
[INFO 2017-06-26 15:27:54,306 main.py:50] epoch 331, training loss: 7751.77, average training loss: 12280.87, base loss: 10676.65
[INFO 2017-06-26 15:27:57,194 main.py:50] epoch 332, training loss: 7475.78, average training loss: 12266.44, base loss: 10677.18
[INFO 2017-06-26 15:28:00,053 main.py:50] epoch 333, training loss: 7548.55, average training loss: 12252.31, base loss: 10677.68
[INFO 2017-06-26 15:28:02,916 main.py:50] epoch 334, training loss: 7712.92, average training loss: 12238.76, base loss: 10678.72
[INFO 2017-06-26 15:28:05,779 main.py:50] epoch 335, training loss: 7547.64, average training loss: 12224.80, base loss: 10679.21
[INFO 2017-06-26 15:28:08,642 main.py:50] epoch 336, training loss: 7357.67, average training loss: 12210.36, base loss: 10678.34
[INFO 2017-06-26 15:28:11,538 main.py:50] epoch 337, training loss: 7660.58, average training loss: 12196.90, base loss: 10679.58
[INFO 2017-06-26 15:28:14,394 main.py:50] epoch 338, training loss: 7700.73, average training loss: 12183.63, base loss: 10680.48
[INFO 2017-06-26 15:28:17,260 main.py:50] epoch 339, training loss: 7332.48, average training loss: 12169.37, base loss: 10678.36
[INFO 2017-06-26 15:28:20,119 main.py:50] epoch 340, training loss: 7778.67, average training loss: 12156.49, base loss: 10679.56
[INFO 2017-06-26 15:28:22,979 main.py:50] epoch 341, training loss: 7919.94, average training loss: 12144.10, base loss: 10681.82
[INFO 2017-06-26 15:28:25,838 main.py:50] epoch 342, training loss: 7380.79, average training loss: 12130.21, base loss: 10681.23
[INFO 2017-06-26 15:28:28,702 main.py:50] epoch 343, training loss: 7507.52, average training loss: 12116.78, base loss: 10680.80
[INFO 2017-06-26 15:28:31,569 main.py:50] epoch 344, training loss: 7354.90, average training loss: 12102.97, base loss: 10679.71
[INFO 2017-06-26 15:28:34,432 main.py:50] epoch 345, training loss: 7277.49, average training loss: 12089.03, base loss: 10679.12
[INFO 2017-06-26 15:28:37,299 main.py:50] epoch 346, training loss: 7680.39, average training loss: 12076.32, base loss: 10679.94
[INFO 2017-06-26 15:28:40,155 main.py:50] epoch 347, training loss: 7049.07, average training loss: 12061.88, base loss: 10677.95
[INFO 2017-06-26 15:28:43,034 main.py:50] epoch 348, training loss: 7435.43, average training loss: 12048.62, base loss: 10678.20
[INFO 2017-06-26 15:28:45,938 main.py:50] epoch 349, training loss: 7435.75, average training loss: 12035.44, base loss: 10677.69
[INFO 2017-06-26 15:28:48,803 main.py:50] epoch 350, training loss: 7533.41, average training loss: 12022.61, base loss: 10678.48
[INFO 2017-06-26 15:28:51,666 main.py:50] epoch 351, training loss: 7172.56, average training loss: 12008.84, base loss: 10677.27
[INFO 2017-06-26 15:28:54,534 main.py:50] epoch 352, training loss: 7072.12, average training loss: 11994.85, base loss: 10676.03
[INFO 2017-06-26 15:28:57,411 main.py:50] epoch 353, training loss: 7225.65, average training loss: 11981.38, base loss: 10675.53
[INFO 2017-06-26 15:29:00,283 main.py:50] epoch 354, training loss: 7375.08, average training loss: 11968.40, base loss: 10675.66
[INFO 2017-06-26 15:29:03,164 main.py:50] epoch 355, training loss: 7364.21, average training loss: 11955.47, base loss: 10675.90
