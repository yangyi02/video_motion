[INFO 2017-06-26 19:01:03,082 main.py:123] Namespace(batch_size=32, display=False, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=2, num_channel=1, num_inputs=4, save_dir='./model', test=False, test_dir='/home/yi/Downloads/robot-64', test_epoch=10, test_interval=100, train=True, train_dir='/home/yi/Downloads/robot-64', train_epoch=10000)
[INFO 2017-06-26 19:01:08,160 main.py:47] epoch 0, training loss: 34641.72, average training loss: 34641.72, base loss: 2948.86
[INFO 2017-06-26 19:01:08,448 main.py:47] epoch 1, training loss: 26787.92, average training loss: 30714.82, base loss: 2858.50
[INFO 2017-06-26 19:01:08,717 main.py:47] epoch 2, training loss: 22838.58, average training loss: 28089.41, base loss: 2896.76
[INFO 2017-06-26 19:01:08,978 main.py:47] epoch 3, training loss: 19662.28, average training loss: 25982.62, base loss: 2819.00
[INFO 2017-06-26 19:01:09,237 main.py:47] epoch 4, training loss: 17984.34, average training loss: 24382.97, base loss: 2873.10
[INFO 2017-06-26 19:01:09,494 main.py:47] epoch 5, training loss: 16061.87, average training loss: 22996.12, base loss: 2813.47
[INFO 2017-06-26 19:01:09,751 main.py:47] epoch 6, training loss: 14416.42, average training loss: 21770.45, base loss: 2849.19
[INFO 2017-06-26 19:01:10,006 main.py:47] epoch 7, training loss: 12092.18, average training loss: 20560.66, base loss: 2802.07
[INFO 2017-06-26 19:01:10,262 main.py:47] epoch 8, training loss: 10386.16, average training loss: 19430.16, base loss: 2796.81
[INFO 2017-06-26 19:01:10,521 main.py:47] epoch 9, training loss: 9075.14, average training loss: 18394.66, base loss: 2773.31
[INFO 2017-06-26 19:01:10,779 main.py:47] epoch 10, training loss: 8221.46, average training loss: 17469.82, base loss: 2733.14
[INFO 2017-06-26 19:01:11,040 main.py:47] epoch 11, training loss: 6952.50, average training loss: 16593.38, base loss: 2687.67
[INFO 2017-06-26 19:01:11,301 main.py:47] epoch 12, training loss: 6678.54, average training loss: 15830.70, base loss: 2686.81
[INFO 2017-06-26 19:01:11,566 main.py:47] epoch 13, training loss: 6013.18, average training loss: 15129.45, base loss: 2701.09
[INFO 2017-06-26 19:01:11,836 main.py:47] epoch 14, training loss: 5425.90, average training loss: 14482.55, base loss: 2712.17
[INFO 2017-06-26 19:01:12,111 main.py:47] epoch 15, training loss: 4546.25, average training loss: 13861.53, base loss: 2690.22
[INFO 2017-06-26 19:01:12,394 main.py:47] epoch 16, training loss: 4565.61, average training loss: 13314.71, base loss: 2692.91
[INFO 2017-06-26 19:01:12,691 main.py:47] epoch 17, training loss: 4098.02, average training loss: 12802.67, base loss: 2691.98
[INFO 2017-06-26 19:01:12,996 main.py:47] epoch 18, training loss: 4179.89, average training loss: 12348.84, base loss: 2711.29
[INFO 2017-06-26 19:01:13,310 main.py:47] epoch 19, training loss: 3504.78, average training loss: 11906.64, base loss: 2698.49
[INFO 2017-06-26 19:01:13,628 main.py:47] epoch 20, training loss: 3166.82, average training loss: 11490.46, base loss: 2679.82
[INFO 2017-06-26 19:01:13,945 main.py:47] epoch 21, training loss: 3851.32, average training loss: 11143.22, base loss: 2704.02
[INFO 2017-06-26 19:01:14,262 main.py:47] epoch 22, training loss: 3046.20, average training loss: 10791.18, base loss: 2693.73
[INFO 2017-06-26 19:01:14,577 main.py:47] epoch 23, training loss: 2968.60, average training loss: 10465.24, base loss: 2687.95
[INFO 2017-06-26 19:01:14,892 main.py:47] epoch 24, training loss: 2954.77, average training loss: 10164.82, base loss: 2684.97
[INFO 2017-06-26 19:01:15,206 main.py:47] epoch 25, training loss: 2928.64, average training loss: 9886.50, base loss: 2685.13
[INFO 2017-06-26 19:01:15,522 main.py:47] epoch 26, training loss: 2486.55, average training loss: 9612.43, base loss: 2669.69
[INFO 2017-06-26 19:01:15,840 main.py:47] epoch 27, training loss: 3010.42, average training loss: 9376.65, base loss: 2676.96
[INFO 2017-06-26 19:01:16,157 main.py:47] epoch 28, training loss: 2667.74, average training loss: 9145.30, base loss: 2671.44
[INFO 2017-06-26 19:01:16,472 main.py:47] epoch 29, training loss: 3168.91, average training loss: 8946.09, base loss: 2685.98
[INFO 2017-06-26 19:01:16,788 main.py:47] epoch 30, training loss: 3261.07, average training loss: 8762.70, base loss: 2703.03
[INFO 2017-06-26 19:01:17,105 main.py:47] epoch 31, training loss: 3050.37, average training loss: 8584.19, base loss: 2712.14
[INFO 2017-06-26 19:01:17,415 main.py:47] epoch 32, training loss: 2682.47, average training loss: 8405.35, base loss: 2710.11
[INFO 2017-06-26 19:01:17,732 main.py:47] epoch 33, training loss: 2406.41, average training loss: 8228.91, base loss: 2700.62
[INFO 2017-06-26 19:01:18,045 main.py:47] epoch 34, training loss: 3000.36, average training loss: 8079.53, base loss: 2709.26
[INFO 2017-06-26 19:01:18,355 main.py:47] epoch 35, training loss: 2241.78, average training loss: 7917.37, base loss: 2694.80
[INFO 2017-06-26 19:01:18,671 main.py:47] epoch 36, training loss: 2692.41, average training loss: 7776.15, base loss: 2693.75
[INFO 2017-06-26 19:01:18,987 main.py:47] epoch 37, training loss: 2275.63, average training loss: 7631.40, base loss: 2682.07
[INFO 2017-06-26 19:01:19,302 main.py:47] epoch 38, training loss: 2574.48, average training loss: 7501.74, base loss: 2679.29
[INFO 2017-06-26 19:01:19,618 main.py:47] epoch 39, training loss: 2826.46, average training loss: 7384.85, base loss: 2683.00
[INFO 2017-06-26 19:01:19,931 main.py:47] epoch 40, training loss: 2873.82, average training loss: 7274.83, base loss: 2687.77
[INFO 2017-06-26 19:01:20,246 main.py:47] epoch 41, training loss: 2146.75, average training loss: 7152.73, base loss: 2674.86
[INFO 2017-06-26 19:01:20,563 main.py:47] epoch 42, training loss: 2439.79, average training loss: 7043.13, base loss: 2669.63
[INFO 2017-06-26 19:01:20,877 main.py:47] epoch 43, training loss: 2243.31, average training loss: 6934.04, base loss: 2659.80
[INFO 2017-06-26 19:01:21,193 main.py:47] epoch 44, training loss: 2753.56, average training loss: 6841.14, base loss: 2662.28
[INFO 2017-06-26 19:01:21,508 main.py:47] epoch 45, training loss: 2598.43, average training loss: 6748.91, base loss: 2661.15
[INFO 2017-06-26 19:01:21,821 main.py:47] epoch 46, training loss: 3041.18, average training loss: 6670.02, base loss: 2670.54
[INFO 2017-06-26 19:01:22,134 main.py:47] epoch 47, training loss: 2420.23, average training loss: 6581.48, base loss: 2666.22
[INFO 2017-06-26 19:01:22,447 main.py:47] epoch 48, training loss: 2937.02, average training loss: 6507.11, base loss: 2672.97
[INFO 2017-06-26 19:01:22,764 main.py:47] epoch 49, training loss: 2946.54, average training loss: 6435.90, base loss: 2679.55
[INFO 2017-06-26 19:01:23,075 main.py:47] epoch 50, training loss: 2964.80, average training loss: 6367.84, base loss: 2686.00
[INFO 2017-06-26 19:01:23,394 main.py:47] epoch 51, training loss: 2812.10, average training loss: 6299.46, base loss: 2689.71
[INFO 2017-06-26 19:01:23,709 main.py:47] epoch 52, training loss: 2548.38, average training loss: 6228.68, base loss: 2688.09
[INFO 2017-06-26 19:01:24,024 main.py:47] epoch 53, training loss: 2401.10, average training loss: 6157.80, base loss: 2683.73
[INFO 2017-06-26 19:01:24,342 main.py:47] epoch 54, training loss: 2759.93, average training loss: 6096.02, base loss: 2686.50
[INFO 2017-06-26 19:01:24,659 main.py:47] epoch 55, training loss: 2574.18, average training loss: 6033.13, base loss: 2685.39
[INFO 2017-06-26 19:01:24,981 main.py:47] epoch 56, training loss: 2444.24, average training loss: 5970.17, base loss: 2681.99
[INFO 2017-06-26 19:01:25,296 main.py:47] epoch 57, training loss: 2694.61, average training loss: 5913.69, base loss: 2682.94
[INFO 2017-06-26 19:01:25,614 main.py:47] epoch 58, training loss: 2677.28, average training loss: 5858.84, base loss: 2683.99
[INFO 2017-06-26 19:01:25,930 main.py:47] epoch 59, training loss: 2572.70, average training loss: 5804.07, base loss: 2683.32
[INFO 2017-06-26 19:01:26,247 main.py:47] epoch 60, training loss: 2567.37, average training loss: 5751.01, base loss: 2682.49
[INFO 2017-06-26 19:01:26,561 main.py:47] epoch 61, training loss: 2615.37, average training loss: 5700.43, base loss: 2682.27
[INFO 2017-06-26 19:01:26,872 main.py:47] epoch 62, training loss: 2055.02, average training loss: 5642.57, base loss: 2673.01
[INFO 2017-06-26 19:01:27,184 main.py:47] epoch 63, training loss: 2441.07, average training loss: 5592.55, base loss: 2669.82
[INFO 2017-06-26 19:01:27,497 main.py:47] epoch 64, training loss: 2402.19, average training loss: 5543.46, base loss: 2667.15
[INFO 2017-06-26 19:01:27,814 main.py:47] epoch 65, training loss: 2306.33, average training loss: 5494.42, base loss: 2662.69
[INFO 2017-06-26 19:01:28,129 main.py:47] epoch 66, training loss: 2806.16, average training loss: 5454.29, base loss: 2666.49
[INFO 2017-06-26 19:01:28,446 main.py:47] epoch 67, training loss: 2732.94, average training loss: 5414.27, base loss: 2668.21
[INFO 2017-06-26 19:01:28,762 main.py:47] epoch 68, training loss: 3003.49, average training loss: 5379.33, base loss: 2674.94
[INFO 2017-06-26 19:01:29,080 main.py:47] epoch 69, training loss: 2630.89, average training loss: 5340.07, base loss: 2675.63
[INFO 2017-06-26 19:01:29,396 main.py:47] epoch 70, training loss: 2481.99, average training loss: 5299.82, base loss: 2674.26
[INFO 2017-06-26 19:01:29,712 main.py:47] epoch 71, training loss: 2535.74, average training loss: 5261.43, base loss: 2673.51
[INFO 2017-06-26 19:01:30,028 main.py:47] epoch 72, training loss: 2026.78, average training loss: 5217.12, base loss: 2664.98
[INFO 2017-06-26 19:01:30,343 main.py:47] epoch 73, training loss: 2766.31, average training loss: 5184.00, base loss: 2667.68
[INFO 2017-06-26 19:01:30,656 main.py:47] epoch 74, training loss: 2419.41, average training loss: 5147.14, base loss: 2665.50
[INFO 2017-06-26 19:01:30,970 main.py:47] epoch 75, training loss: 2394.54, average training loss: 5110.92, base loss: 2662.31
[INFO 2017-06-26 19:01:31,288 main.py:47] epoch 76, training loss: 2735.65, average training loss: 5080.07, base loss: 2664.72
[INFO 2017-06-26 19:01:31,605 main.py:47] epoch 77, training loss: 2890.83, average training loss: 5052.00, base loss: 2668.88
[INFO 2017-06-26 19:01:31,923 main.py:47] epoch 78, training loss: 2476.55, average training loss: 5019.40, base loss: 2667.09
[INFO 2017-06-26 19:01:32,240 main.py:47] epoch 79, training loss: 2871.95, average training loss: 4992.56, base loss: 2670.85
[INFO 2017-06-26 19:01:32,552 main.py:47] epoch 80, training loss: 2378.51, average training loss: 4960.29, base loss: 2668.34
[INFO 2017-06-26 19:01:32,866 main.py:47] epoch 81, training loss: 2833.08, average training loss: 4934.34, base loss: 2672.07
[INFO 2017-06-26 19:01:33,178 main.py:47] epoch 82, training loss: 2633.48, average training loss: 4906.62, base loss: 2673.28
[INFO 2017-06-26 19:01:33,491 main.py:47] epoch 83, training loss: 2879.08, average training loss: 4882.49, base loss: 2677.78
[INFO 2017-06-26 19:01:33,807 main.py:47] epoch 84, training loss: 2877.73, average training loss: 4858.90, base loss: 2681.90
[INFO 2017-06-26 19:01:34,124 main.py:47] epoch 85, training loss: 2790.88, average training loss: 4834.85, base loss: 2684.72
[INFO 2017-06-26 19:01:34,441 main.py:47] epoch 86, training loss: 2728.84, average training loss: 4810.65, base loss: 2686.79
[INFO 2017-06-26 19:01:34,754 main.py:47] epoch 87, training loss: 2507.00, average training loss: 4784.47, base loss: 2685.77
[INFO 2017-06-26 19:01:35,069 main.py:47] epoch 88, training loss: 2069.22, average training loss: 4753.96, base loss: 2679.28
[INFO 2017-06-26 19:01:35,386 main.py:47] epoch 89, training loss: 2801.79, average training loss: 4732.27, base loss: 2681.92
[INFO 2017-06-26 19:01:35,704 main.py:47] epoch 90, training loss: 2660.60, average training loss: 4709.50, base loss: 2682.98
[INFO 2017-06-26 19:01:36,017 main.py:47] epoch 91, training loss: 2673.57, average training loss: 4687.37, base loss: 2684.50
[INFO 2017-06-26 19:01:36,334 main.py:47] epoch 92, training loss: 2496.96, average training loss: 4663.82, base loss: 2683.74
[INFO 2017-06-26 19:01:36,650 main.py:47] epoch 93, training loss: 2509.99, average training loss: 4640.91, base loss: 2683.17
[INFO 2017-06-26 19:01:36,967 main.py:47] epoch 94, training loss: 2419.59, average training loss: 4617.53, base loss: 2681.50
[INFO 2017-06-26 19:01:37,282 main.py:47] epoch 95, training loss: 3111.42, average training loss: 4601.84, base loss: 2688.02
[INFO 2017-06-26 19:01:37,598 main.py:47] epoch 96, training loss: 2625.03, average training loss: 4581.46, base loss: 2689.02
[INFO 2017-06-26 19:01:37,912 main.py:47] epoch 97, training loss: 2331.11, average training loss: 4558.50, base loss: 2686.66
[INFO 2017-06-26 19:01:38,225 main.py:47] epoch 98, training loss: 2728.59, average training loss: 4540.01, base loss: 2688.72
[INFO 2017-06-26 19:01:38,543 main.py:47] epoch 99, training loss: 2426.05, average training loss: 4518.87, base loss: 2687.79
[INFO 2017-06-26 19:01:38,543 main.py:49] epoch 99, testing
[INFO 2017-06-26 19:01:42,615 main.py:100] average testing loss: 2360.22, base loss: 2484.53
[INFO 2017-06-26 19:01:42,636 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 19:01:42,648 main.py:73] current best accuracy: 2360.22
[INFO 2017-06-26 19:01:42,965 main.py:47] epoch 100, training loss: 2544.86, average training loss: 4499.33, base loss: 2687.49
[INFO 2017-06-26 19:01:43,275 main.py:47] epoch 101, training loss: 2453.13, average training loss: 4479.27, base loss: 2686.52
[INFO 2017-06-26 19:01:43,591 main.py:47] epoch 102, training loss: 2244.76, average training loss: 4457.57, base loss: 2683.18
[INFO 2017-06-26 19:01:43,909 main.py:47] epoch 103, training loss: 2414.91, average training loss: 4437.93, base loss: 2681.36
[INFO 2017-06-26 19:01:44,225 main.py:47] epoch 104, training loss: 2809.64, average training loss: 4422.42, base loss: 2684.12
[INFO 2017-06-26 19:01:44,540 main.py:47] epoch 105, training loss: 2544.01, average training loss: 4404.70, base loss: 2684.11
[INFO 2017-06-26 19:01:44,857 main.py:47] epoch 106, training loss: 2545.42, average training loss: 4387.33, base loss: 2684.50
[INFO 2017-06-26 19:01:45,173 main.py:47] epoch 107, training loss: 2277.01, average training loss: 4367.79, base loss: 2682.18
[INFO 2017-06-26 19:01:45,490 main.py:47] epoch 108, training loss: 2688.63, average training loss: 4352.38, base loss: 2684.14
[INFO 2017-06-26 19:01:45,806 main.py:47] epoch 109, training loss: 2216.22, average training loss: 4332.96, base loss: 2680.70
[INFO 2017-06-26 19:01:46,118 main.py:47] epoch 110, training loss: 2465.65, average training loss: 4316.14, base loss: 2679.48
[INFO 2017-06-26 19:01:46,435 main.py:47] epoch 111, training loss: 2503.46, average training loss: 4299.95, base loss: 2679.26
[INFO 2017-06-26 19:01:46,752 main.py:47] epoch 112, training loss: 2820.78, average training loss: 4286.86, base loss: 2682.26
[INFO 2017-06-26 19:01:47,069 main.py:47] epoch 113, training loss: 2344.80, average training loss: 4269.83, base loss: 2680.98
[INFO 2017-06-26 19:01:47,387 main.py:47] epoch 114, training loss: 2603.34, average training loss: 4255.34, base loss: 2681.81
[INFO 2017-06-26 19:01:47,706 main.py:47] epoch 115, training loss: 2483.81, average training loss: 4240.07, base loss: 2681.57
[INFO 2017-06-26 19:01:48,025 main.py:47] epoch 116, training loss: 2696.88, average training loss: 4226.88, base loss: 2683.36
[INFO 2017-06-26 19:01:48,341 main.py:47] epoch 117, training loss: 2530.86, average training loss: 4212.50, base loss: 2683.24
[INFO 2017-06-26 19:01:48,658 main.py:47] epoch 118, training loss: 1965.73, average training loss: 4193.62, base loss: 2678.53
[INFO 2017-06-26 19:01:48,975 main.py:47] epoch 119, training loss: 2391.79, average training loss: 4178.61, base loss: 2677.21
[INFO 2017-06-26 19:01:49,290 main.py:47] epoch 120, training loss: 2261.27, average training loss: 4162.76, base loss: 2675.31
[INFO 2017-06-26 19:01:49,607 main.py:47] epoch 121, training loss: 2274.69, average training loss: 4147.29, base loss: 2673.41
[INFO 2017-06-26 19:01:49,925 main.py:47] epoch 122, training loss: 2689.48, average training loss: 4135.43, base loss: 2674.88
[INFO 2017-06-26 19:01:50,243 main.py:47] epoch 123, training loss: 2403.23, average training loss: 4121.46, base loss: 2673.58
[INFO 2017-06-26 19:01:50,560 main.py:47] epoch 124, training loss: 2027.89, average training loss: 4104.72, base loss: 2669.16
[INFO 2017-06-26 19:01:50,876 main.py:47] epoch 125, training loss: 2138.33, average training loss: 4089.11, base loss: 2666.36
[INFO 2017-06-26 19:01:51,194 main.py:47] epoch 126, training loss: 2737.65, average training loss: 4078.47, base loss: 2668.18
[INFO 2017-06-26 19:01:51,511 main.py:47] epoch 127, training loss: 2600.11, average training loss: 4066.92, base loss: 2669.21
[INFO 2017-06-26 19:01:51,825 main.py:47] epoch 128, training loss: 2412.35, average training loss: 4054.09, base loss: 2668.23
[INFO 2017-06-26 19:01:52,143 main.py:47] epoch 129, training loss: 2829.51, average training loss: 4044.67, base loss: 2671.17
[INFO 2017-06-26 19:01:52,458 main.py:47] epoch 130, training loss: 2196.31, average training loss: 4030.56, base loss: 2668.50
[INFO 2017-06-26 19:01:52,771 main.py:47] epoch 131, training loss: 2472.12, average training loss: 4018.76, base loss: 2668.56
[INFO 2017-06-26 19:01:53,088 main.py:47] epoch 132, training loss: 2500.16, average training loss: 4007.34, base loss: 2668.66
[INFO 2017-06-26 19:01:53,403 main.py:47] epoch 133, training loss: 2869.73, average training loss: 3998.85, base loss: 2671.96
[INFO 2017-06-26 19:01:53,719 main.py:47] epoch 134, training loss: 2128.66, average training loss: 3985.00, base loss: 2668.51
[INFO 2017-06-26 19:01:54,036 main.py:47] epoch 135, training loss: 2471.83, average training loss: 3973.87, base loss: 2668.32
[INFO 2017-06-26 19:01:54,350 main.py:47] epoch 136, training loss: 2580.48, average training loss: 3963.70, base loss: 2669.62
[INFO 2017-06-26 19:01:54,667 main.py:47] epoch 137, training loss: 2499.61, average training loss: 3953.09, base loss: 2670.09
[INFO 2017-06-26 19:01:54,981 main.py:47] epoch 138, training loss: 2419.60, average training loss: 3942.06, base loss: 2669.82
[INFO 2017-06-26 19:01:55,298 main.py:47] epoch 139, training loss: 2431.79, average training loss: 3931.27, base loss: 2669.37
[INFO 2017-06-26 19:01:55,612 main.py:47] epoch 140, training loss: 2420.27, average training loss: 3920.55, base loss: 2668.82
[INFO 2017-06-26 19:01:55,926 main.py:47] epoch 141, training loss: 2165.83, average training loss: 3908.20, base loss: 2666.30
[INFO 2017-06-26 19:01:56,241 main.py:47] epoch 142, training loss: 2157.71, average training loss: 3895.95, base loss: 2663.91
[INFO 2017-06-26 19:01:56,557 main.py:47] epoch 143, training loss: 2547.90, average training loss: 3886.59, base loss: 2664.37
[INFO 2017-06-26 19:01:56,875 main.py:47] epoch 144, training loss: 2367.26, average training loss: 3876.11, base loss: 2663.39
[INFO 2017-06-26 19:01:57,192 main.py:47] epoch 145, training loss: 2828.04, average training loss: 3868.94, base loss: 2666.51
[INFO 2017-06-26 19:01:57,510 main.py:47] epoch 146, training loss: 2305.69, average training loss: 3858.30, base loss: 2665.38
[INFO 2017-06-26 19:01:57,824 main.py:47] epoch 147, training loss: 2428.82, average training loss: 3848.64, base loss: 2665.52
[INFO 2017-06-26 19:01:58,148 main.py:47] epoch 148, training loss: 2304.59, average training loss: 3838.28, base loss: 2664.47
[INFO 2017-06-26 19:01:58,461 main.py:47] epoch 149, training loss: 2696.06, average training loss: 3830.67, base loss: 2666.59
[INFO 2017-06-26 19:01:58,776 main.py:47] epoch 150, training loss: 2459.83, average training loss: 3821.59, base loss: 2666.78
[INFO 2017-06-26 19:01:59,089 main.py:47] epoch 151, training loss: 2638.89, average training loss: 3813.81, base loss: 2667.96
[INFO 2017-06-26 19:01:59,408 main.py:47] epoch 152, training loss: 2686.22, average training loss: 3806.44, base loss: 2670.33
[INFO 2017-06-26 19:01:59,727 main.py:47] epoch 153, training loss: 2512.85, average training loss: 3798.04, base loss: 2671.15
[INFO 2017-06-26 19:02:00,044 main.py:47] epoch 154, training loss: 2827.82, average training loss: 3791.78, base loss: 2674.22
[INFO 2017-06-26 19:02:00,358 main.py:47] epoch 155, training loss: 2502.95, average training loss: 3783.52, base loss: 2674.63
[INFO 2017-06-26 19:02:00,676 main.py:47] epoch 156, training loss: 2247.15, average training loss: 3773.73, base loss: 2673.14
[INFO 2017-06-26 19:02:00,990 main.py:47] epoch 157, training loss: 2351.86, average training loss: 3764.73, base loss: 2672.63
[INFO 2017-06-26 19:02:01,309 main.py:47] epoch 158, training loss: 2186.29, average training loss: 3754.80, base loss: 2670.49
[INFO 2017-06-26 19:02:01,634 main.py:47] epoch 159, training loss: 2315.03, average training loss: 3745.80, base loss: 2669.84
[INFO 2017-06-26 19:02:01,951 main.py:47] epoch 160, training loss: 2232.89, average training loss: 3736.41, base loss: 2668.39
[INFO 2017-06-26 19:02:02,268 main.py:47] epoch 161, training loss: 2130.59, average training loss: 3726.50, base loss: 2666.30
[INFO 2017-06-26 19:02:02,583 main.py:47] epoch 162, training loss: 2573.78, average training loss: 3719.42, base loss: 2667.63
[INFO 2017-06-26 19:02:02,900 main.py:47] epoch 163, training loss: 2690.96, average training loss: 3713.15, base loss: 2669.60
[INFO 2017-06-26 19:02:03,214 main.py:47] epoch 164, training loss: 2474.83, average training loss: 3705.65, base loss: 2669.94
[INFO 2017-06-26 19:02:03,534 main.py:47] epoch 165, training loss: 2547.83, average training loss: 3698.67, base loss: 2671.59
[INFO 2017-06-26 19:02:03,853 main.py:47] epoch 166, training loss: 2475.29, average training loss: 3691.35, base loss: 2671.46
[INFO 2017-06-26 19:02:04,172 main.py:47] epoch 167, training loss: 2388.55, average training loss: 3683.59, base loss: 2671.35
[INFO 2017-06-26 19:02:04,482 main.py:47] epoch 168, training loss: 2332.60, average training loss: 3675.60, base loss: 2670.66
[INFO 2017-06-26 19:02:04,797 main.py:47] epoch 169, training loss: 2364.81, average training loss: 3667.89, base loss: 2670.07
[INFO 2017-06-26 19:02:05,107 main.py:47] epoch 170, training loss: 2220.89, average training loss: 3659.43, base loss: 2668.18
[INFO 2017-06-26 19:02:05,422 main.py:47] epoch 171, training loss: 2594.20, average training loss: 3653.23, base loss: 2669.66
[INFO 2017-06-26 19:02:05,738 main.py:47] epoch 172, training loss: 2376.73, average training loss: 3645.85, base loss: 2669.39
[INFO 2017-06-26 19:02:06,052 main.py:47] epoch 173, training loss: 2237.47, average training loss: 3637.76, base loss: 2668.20
[INFO 2017-06-26 19:02:06,368 main.py:47] epoch 174, training loss: 2451.94, average training loss: 3630.98, base loss: 2668.46
[INFO 2017-06-26 19:02:06,686 main.py:47] epoch 175, training loss: 2902.29, average training loss: 3626.84, base loss: 2671.63
[INFO 2017-06-26 19:02:07,001 main.py:47] epoch 176, training loss: 2832.88, average training loss: 3622.36, base loss: 2674.32
[INFO 2017-06-26 19:02:07,319 main.py:47] epoch 177, training loss: 2324.05, average training loss: 3615.06, base loss: 2673.49
[INFO 2017-06-26 19:02:07,635 main.py:47] epoch 178, training loss: 2483.24, average training loss: 3608.74, base loss: 2673.71
[INFO 2017-06-26 19:02:07,954 main.py:47] epoch 179, training loss: 2220.38, average training loss: 3601.03, base loss: 2672.50
[INFO 2017-06-26 19:02:08,271 main.py:47] epoch 180, training loss: 2166.92, average training loss: 3593.10, base loss: 2670.88
[INFO 2017-06-26 19:02:08,585 main.py:47] epoch 181, training loss: 2795.99, average training loss: 3588.72, base loss: 2673.26
[INFO 2017-06-26 19:02:08,895 main.py:47] epoch 182, training loss: 1794.10, average training loss: 3578.92, base loss: 2668.99
[INFO 2017-06-26 19:02:09,213 main.py:47] epoch 183, training loss: 2417.42, average training loss: 3572.61, base loss: 2669.09
[INFO 2017-06-26 19:02:09,528 main.py:47] epoch 184, training loss: 2479.54, average training loss: 3566.70, base loss: 2669.26
[INFO 2017-06-26 19:02:09,841 main.py:47] epoch 185, training loss: 2285.26, average training loss: 3559.81, base loss: 2668.48
[INFO 2017-06-26 19:02:10,155 main.py:47] epoch 186, training loss: 2426.67, average training loss: 3553.75, base loss: 2668.59
[INFO 2017-06-26 19:02:10,471 main.py:47] epoch 187, training loss: 2228.68, average training loss: 3546.70, base loss: 2667.55
[INFO 2017-06-26 19:02:10,787 main.py:47] epoch 188, training loss: 2426.08, average training loss: 3540.77, base loss: 2667.77
[INFO 2017-06-26 19:02:11,102 main.py:47] epoch 189, training loss: 2349.62, average training loss: 3534.50, base loss: 2667.37
[INFO 2017-06-26 19:02:11,419 main.py:47] epoch 190, training loss: 2486.49, average training loss: 3529.01, base loss: 2667.52
[INFO 2017-06-26 19:02:11,737 main.py:47] epoch 191, training loss: 2443.61, average training loss: 3523.36, base loss: 2668.02
[INFO 2017-06-26 19:02:12,054 main.py:47] epoch 192, training loss: 2205.00, average training loss: 3516.53, base loss: 2666.44
[INFO 2017-06-26 19:02:12,372 main.py:47] epoch 193, training loss: 2134.92, average training loss: 3509.41, base loss: 2665.38
[INFO 2017-06-26 19:02:12,690 main.py:47] epoch 194, training loss: 2233.98, average training loss: 3502.87, base loss: 2664.21
[INFO 2017-06-26 19:02:13,004 main.py:47] epoch 195, training loss: 2663.24, average training loss: 3498.58, base loss: 2665.56
[INFO 2017-06-26 19:02:13,320 main.py:47] epoch 196, training loss: 2587.47, average training loss: 3493.96, base loss: 2666.47
[INFO 2017-06-26 19:02:13,636 main.py:47] epoch 197, training loss: 2170.79, average training loss: 3487.28, base loss: 2665.17
[INFO 2017-06-26 19:02:13,953 main.py:47] epoch 198, training loss: 2758.21, average training loss: 3483.61, base loss: 2667.08
[INFO 2017-06-26 19:02:14,270 main.py:47] epoch 199, training loss: 2288.72, average training loss: 3477.64, base loss: 2666.18
[INFO 2017-06-26 19:02:14,270 main.py:49] epoch 199, testing
[INFO 2017-06-26 19:02:18,340 main.py:100] average testing loss: 2213.15, base loss: 2462.96
[INFO 2017-06-26 19:02:18,363 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 19:02:18,377 main.py:73] current best accuracy: 2213.15
[INFO 2017-06-26 19:02:18,692 main.py:47] epoch 200, training loss: 2411.27, average training loss: 3472.33, base loss: 2666.11
[INFO 2017-06-26 19:02:19,010 main.py:47] epoch 201, training loss: 1996.92, average training loss: 3465.03, base loss: 2663.82
[INFO 2017-06-26 19:02:19,331 main.py:47] epoch 202, training loss: 1998.46, average training loss: 3457.80, base loss: 2661.62
[INFO 2017-06-26 19:02:19,648 main.py:47] epoch 203, training loss: 2285.23, average training loss: 3452.06, base loss: 2661.24
[INFO 2017-06-26 19:02:19,964 main.py:47] epoch 204, training loss: 2274.41, average training loss: 3446.31, base loss: 2660.60
[INFO 2017-06-26 19:02:20,281 main.py:47] epoch 205, training loss: 2528.11, average training loss: 3441.85, base loss: 2661.49
[INFO 2017-06-26 19:02:20,596 main.py:47] epoch 206, training loss: 2563.70, average training loss: 3437.61, base loss: 2662.41
[INFO 2017-06-26 19:02:20,913 main.py:47] epoch 207, training loss: 2185.22, average training loss: 3431.59, base loss: 2661.15
[INFO 2017-06-26 19:02:21,229 main.py:47] epoch 208, training loss: 2241.48, average training loss: 3425.90, base loss: 2660.34
[INFO 2017-06-26 19:02:21,546 main.py:47] epoch 209, training loss: 2371.31, average training loss: 3420.88, base loss: 2660.67
[INFO 2017-06-26 19:02:21,864 main.py:47] epoch 210, training loss: 2286.82, average training loss: 3415.50, base loss: 2659.90
[INFO 2017-06-26 19:02:22,176 main.py:47] epoch 211, training loss: 2778.52, average training loss: 3412.50, base loss: 2662.73
[INFO 2017-06-26 19:02:22,491 main.py:47] epoch 212, training loss: 2177.48, average training loss: 3406.70, base loss: 2661.79
[INFO 2017-06-26 19:02:22,804 main.py:47] epoch 213, training loss: 2267.11, average training loss: 3401.37, base loss: 2661.07
[INFO 2017-06-26 19:02:23,117 main.py:47] epoch 214, training loss: 1829.06, average training loss: 3394.06, base loss: 2658.26
[INFO 2017-06-26 19:02:23,432 main.py:47] epoch 215, training loss: 2325.89, average training loss: 3389.11, base loss: 2657.59
[INFO 2017-06-26 19:02:23,746 main.py:47] epoch 216, training loss: 2310.74, average training loss: 3384.14, base loss: 2657.30
[INFO 2017-06-26 19:02:24,060 main.py:47] epoch 217, training loss: 2267.78, average training loss: 3379.02, base loss: 2656.73
[INFO 2017-06-26 19:02:24,378 main.py:47] epoch 218, training loss: 2099.92, average training loss: 3373.18, base loss: 2654.98
[INFO 2017-06-26 19:02:24,696 main.py:47] epoch 219, training loss: 2205.53, average training loss: 3367.88, base loss: 2653.96
[INFO 2017-06-26 19:02:25,013 main.py:47] epoch 220, training loss: 2582.16, average training loss: 3364.32, base loss: 2655.31
[INFO 2017-06-26 19:02:25,332 main.py:47] epoch 221, training loss: 2245.02, average training loss: 3359.28, base loss: 2654.80
[INFO 2017-06-26 19:02:25,652 main.py:47] epoch 222, training loss: 2087.81, average training loss: 3353.58, base loss: 2653.68
[INFO 2017-06-26 19:02:25,973 main.py:47] epoch 223, training loss: 2396.19, average training loss: 3349.30, base loss: 2653.65
[INFO 2017-06-26 19:02:26,293 main.py:47] epoch 224, training loss: 2175.41, average training loss: 3344.09, base loss: 2652.56
[INFO 2017-06-26 19:02:26,611 main.py:47] epoch 225, training loss: 2386.77, average training loss: 3339.85, base loss: 2653.26
[INFO 2017-06-26 19:02:26,932 main.py:47] epoch 226, training loss: 2077.18, average training loss: 3334.29, base loss: 2652.22
[INFO 2017-06-26 19:02:27,251 main.py:47] epoch 227, training loss: 2236.12, average training loss: 3329.47, base loss: 2651.71
[INFO 2017-06-26 19:02:27,571 main.py:47] epoch 228, training loss: 2170.60, average training loss: 3324.41, base loss: 2651.38
[INFO 2017-06-26 19:02:27,889 main.py:47] epoch 229, training loss: 2486.07, average training loss: 3320.77, base loss: 2652.45
[INFO 2017-06-26 19:02:28,205 main.py:47] epoch 230, training loss: 2921.21, average training loss: 3319.04, base loss: 2655.25
[INFO 2017-06-26 19:02:28,521 main.py:47] epoch 231, training loss: 2308.77, average training loss: 3314.68, base loss: 2654.74
[INFO 2017-06-26 19:02:28,839 main.py:47] epoch 232, training loss: 2050.74, average training loss: 3309.26, base loss: 2652.67
[INFO 2017-06-26 19:02:29,154 main.py:47] epoch 233, training loss: 2151.62, average training loss: 3304.31, base loss: 2651.84
[INFO 2017-06-26 19:02:29,472 main.py:47] epoch 234, training loss: 2299.37, average training loss: 3300.03, base loss: 2651.37
[INFO 2017-06-26 19:02:29,787 main.py:47] epoch 235, training loss: 2299.68, average training loss: 3295.79, base loss: 2651.23
[INFO 2017-06-26 19:02:30,105 main.py:47] epoch 236, training loss: 2205.02, average training loss: 3291.19, base loss: 2650.49
[INFO 2017-06-26 19:02:30,424 main.py:47] epoch 237, training loss: 2098.06, average training loss: 3286.18, base loss: 2648.97
[INFO 2017-06-26 19:02:30,741 main.py:47] epoch 238, training loss: 2450.11, average training loss: 3282.68, base loss: 2649.65
[INFO 2017-06-26 19:02:31,059 main.py:47] epoch 239, training loss: 2394.69, average training loss: 3278.98, base loss: 2649.91
[INFO 2017-06-26 19:02:31,378 main.py:47] epoch 240, training loss: 2252.60, average training loss: 3274.72, base loss: 2649.64
[INFO 2017-06-26 19:02:31,693 main.py:47] epoch 241, training loss: 2204.20, average training loss: 3270.30, base loss: 2649.28
[INFO 2017-06-26 19:02:32,011 main.py:47] epoch 242, training loss: 2327.80, average training loss: 3266.42, base loss: 2649.17
[INFO 2017-06-26 19:02:32,329 main.py:47] epoch 243, training loss: 2126.30, average training loss: 3261.75, base loss: 2648.14
[INFO 2017-06-26 19:02:32,647 main.py:47] epoch 244, training loss: 2409.23, average training loss: 3258.27, base loss: 2648.36
[INFO 2017-06-26 19:02:32,966 main.py:47] epoch 245, training loss: 2081.47, average training loss: 3253.48, base loss: 2646.65
[INFO 2017-06-26 19:02:33,279 main.py:47] epoch 246, training loss: 2209.21, average training loss: 3249.26, base loss: 2646.10
[INFO 2017-06-26 19:02:33,594 main.py:47] epoch 247, training loss: 2202.66, average training loss: 3245.04, base loss: 2645.52
[INFO 2017-06-26 19:02:33,924 main.py:47] epoch 248, training loss: 2335.56, average training loss: 3241.38, base loss: 2645.61
[INFO 2017-06-26 19:02:34,240 main.py:47] epoch 249, training loss: 2323.12, average training loss: 3237.71, base loss: 2645.55
[INFO 2017-06-26 19:02:34,557 main.py:47] epoch 250, training loss: 2187.05, average training loss: 3233.52, base loss: 2644.70
[INFO 2017-06-26 19:02:34,872 main.py:47] epoch 251, training loss: 2116.30, average training loss: 3229.09, base loss: 2643.64
[INFO 2017-06-26 19:02:35,194 main.py:47] epoch 252, training loss: 2413.85, average training loss: 3225.87, base loss: 2644.11
[INFO 2017-06-26 19:02:35,508 main.py:47] epoch 253, training loss: 2182.50, average training loss: 3221.76, base loss: 2643.56
[INFO 2017-06-26 19:02:35,827 main.py:47] epoch 254, training loss: 2384.61, average training loss: 3218.48, base loss: 2644.40
[INFO 2017-06-26 19:02:36,147 main.py:47] epoch 255, training loss: 2387.05, average training loss: 3215.23, base loss: 2644.76
[INFO 2017-06-26 19:02:36,462 main.py:47] epoch 256, training loss: 2053.85, average training loss: 3210.71, base loss: 2643.72
[INFO 2017-06-26 19:02:36,776 main.py:47] epoch 257, training loss: 2274.07, average training loss: 3207.08, base loss: 2643.98
[INFO 2017-06-26 19:02:37,091 main.py:47] epoch 258, training loss: 2028.62, average training loss: 3202.53, base loss: 2642.62
[INFO 2017-06-26 19:02:37,405 main.py:47] epoch 259, training loss: 1881.05, average training loss: 3197.45, base loss: 2640.41
[INFO 2017-06-26 19:02:37,721 main.py:47] epoch 260, training loss: 1961.99, average training loss: 3192.71, base loss: 2638.65
[INFO 2017-06-26 19:02:38,040 main.py:47] epoch 261, training loss: 2533.76, average training loss: 3190.20, base loss: 2639.59
[INFO 2017-06-26 19:02:38,358 main.py:47] epoch 262, training loss: 2463.56, average training loss: 3187.44, base loss: 2639.90
[INFO 2017-06-26 19:02:38,674 main.py:47] epoch 263, training loss: 2101.67, average training loss: 3183.32, base loss: 2639.11
[INFO 2017-06-26 19:02:38,991 main.py:47] epoch 264, training loss: 2067.03, average training loss: 3179.11, base loss: 2637.93
[INFO 2017-06-26 19:02:39,305 main.py:47] epoch 265, training loss: 1966.18, average training loss: 3174.55, base loss: 2636.63
[INFO 2017-06-26 19:02:39,621 main.py:47] epoch 266, training loss: 2315.86, average training loss: 3171.33, base loss: 2636.82
[INFO 2017-06-26 19:02:39,936 main.py:47] epoch 267, training loss: 2137.90, average training loss: 3167.48, base loss: 2636.16
[INFO 2017-06-26 19:02:40,252 main.py:47] epoch 268, training loss: 2255.84, average training loss: 3164.09, base loss: 2635.87
[INFO 2017-06-26 19:02:40,566 main.py:47] epoch 269, training loss: 2348.98, average training loss: 3161.07, base loss: 2636.29
[INFO 2017-06-26 19:02:40,881 main.py:47] epoch 270, training loss: 1872.84, average training loss: 3156.32, base loss: 2634.14
[INFO 2017-06-26 19:02:41,199 main.py:47] epoch 271, training loss: 2241.37, average training loss: 3152.95, base loss: 2633.55
[INFO 2017-06-26 19:02:41,518 main.py:47] epoch 272, training loss: 2070.39, average training loss: 3148.99, base loss: 2632.81
[INFO 2017-06-26 19:02:41,833 main.py:47] epoch 273, training loss: 2448.56, average training loss: 3146.43, base loss: 2633.43
[INFO 2017-06-26 19:02:42,151 main.py:47] epoch 274, training loss: 2731.14, average training loss: 3144.92, base loss: 2635.51
[INFO 2017-06-26 19:02:42,467 main.py:47] epoch 275, training loss: 2317.92, average training loss: 3141.93, base loss: 2635.43
[INFO 2017-06-26 19:02:42,784 main.py:47] epoch 276, training loss: 2106.24, average training loss: 3138.19, base loss: 2634.51
[INFO 2017-06-26 19:02:43,102 main.py:47] epoch 277, training loss: 2393.57, average training loss: 3135.51, base loss: 2635.14
[INFO 2017-06-26 19:02:43,417 main.py:47] epoch 278, training loss: 2593.04, average training loss: 3133.56, base loss: 2636.41
[INFO 2017-06-26 19:02:43,734 main.py:47] epoch 279, training loss: 2462.08, average training loss: 3131.17, base loss: 2637.56
[INFO 2017-06-26 19:02:44,048 main.py:47] epoch 280, training loss: 2249.31, average training loss: 3128.03, base loss: 2637.52
[INFO 2017-06-26 19:02:44,361 main.py:47] epoch 281, training loss: 2619.16, average training loss: 3126.22, base loss: 2639.06
[INFO 2017-06-26 19:02:44,679 main.py:47] epoch 282, training loss: 2404.51, average training loss: 3123.67, base loss: 2639.07
[INFO 2017-06-26 19:02:44,993 main.py:47] epoch 283, training loss: 2061.09, average training loss: 3119.93, base loss: 2637.73
[INFO 2017-06-26 19:02:45,311 main.py:47] epoch 284, training loss: 2348.41, average training loss: 3117.22, base loss: 2638.31
[INFO 2017-06-26 19:02:45,629 main.py:47] epoch 285, training loss: 2316.89, average training loss: 3114.43, base loss: 2638.50
[INFO 2017-06-26 19:02:45,947 main.py:47] epoch 286, training loss: 2116.36, average training loss: 3110.95, base loss: 2637.93
[INFO 2017-06-26 19:02:46,271 main.py:47] epoch 287, training loss: 2627.33, average training loss: 3109.27, base loss: 2639.31
[INFO 2017-06-26 19:02:46,588 main.py:47] epoch 288, training loss: 1992.59, average training loss: 3105.40, base loss: 2638.26
[INFO 2017-06-26 19:02:46,907 main.py:47] epoch 289, training loss: 2312.09, average training loss: 3102.67, base loss: 2638.16
[INFO 2017-06-26 19:02:47,224 main.py:47] epoch 290, training loss: 2139.01, average training loss: 3099.36, base loss: 2637.82
[INFO 2017-06-26 19:02:47,540 main.py:47] epoch 291, training loss: 2639.98, average training loss: 3097.78, base loss: 2639.19
[INFO 2017-06-26 19:02:47,857 main.py:47] epoch 292, training loss: 2133.28, average training loss: 3094.49, base loss: 2637.66
[INFO 2017-06-26 19:02:48,173 main.py:47] epoch 293, training loss: 2402.60, average training loss: 3092.14, base loss: 2638.36
[INFO 2017-06-26 19:02:48,490 main.py:47] epoch 294, training loss: 2398.84, average training loss: 3089.79, base loss: 2638.62
[INFO 2017-06-26 19:02:48,804 main.py:47] epoch 295, training loss: 2689.53, average training loss: 3088.44, base loss: 2640.08
[INFO 2017-06-26 19:02:49,119 main.py:47] epoch 296, training loss: 2139.74, average training loss: 3085.24, base loss: 2639.28
[INFO 2017-06-26 19:02:49,435 main.py:47] epoch 297, training loss: 2263.16, average training loss: 3082.48, base loss: 2639.25
[INFO 2017-06-26 19:02:49,749 main.py:47] epoch 298, training loss: 2441.08, average training loss: 3080.34, base loss: 2640.09
[INFO 2017-06-26 19:02:50,061 main.py:47] epoch 299, training loss: 2072.76, average training loss: 3076.98, base loss: 2639.29
[INFO 2017-06-26 19:02:50,061 main.py:49] epoch 299, testing
[INFO 2017-06-26 19:02:54,235 main.py:100] average testing loss: 2368.77, base loss: 2738.42
[INFO 2017-06-26 19:02:54,257 main.py:73] current best accuracy: 2213.15
[INFO 2017-06-26 19:02:54,573 main.py:47] epoch 300, training loss: 2520.72, average training loss: 3075.13, base loss: 2640.45
[INFO 2017-06-26 19:02:54,887 main.py:47] epoch 301, training loss: 2212.59, average training loss: 3072.28, base loss: 2640.58
[INFO 2017-06-26 19:02:55,202 main.py:47] epoch 302, training loss: 2102.81, average training loss: 3069.08, base loss: 2639.89
[INFO 2017-06-26 19:02:55,517 main.py:47] epoch 303, training loss: 2227.97, average training loss: 3066.31, base loss: 2639.71
[INFO 2017-06-26 19:02:55,834 main.py:47] epoch 304, training loss: 2310.55, average training loss: 3063.83, base loss: 2640.20
[INFO 2017-06-26 19:02:56,150 main.py:47] epoch 305, training loss: 2265.01, average training loss: 3061.22, base loss: 2640.06
[INFO 2017-06-26 19:02:56,466 main.py:47] epoch 306, training loss: 1913.29, average training loss: 3057.48, base loss: 2638.61
[INFO 2017-06-26 19:02:56,782 main.py:47] epoch 307, training loss: 2016.78, average training loss: 3054.10, base loss: 2637.53
[INFO 2017-06-26 19:02:57,099 main.py:47] epoch 308, training loss: 2370.56, average training loss: 3051.89, base loss: 2637.91
[INFO 2017-06-26 19:02:57,416 main.py:47] epoch 309, training loss: 2510.19, average training loss: 3050.14, base loss: 2638.70
[INFO 2017-06-26 19:02:57,732 main.py:47] epoch 310, training loss: 2288.49, average training loss: 3047.69, base loss: 2638.92
[INFO 2017-06-26 19:02:58,050 main.py:47] epoch 311, training loss: 2182.09, average training loss: 3044.92, base loss: 2638.56
[INFO 2017-06-26 19:02:58,364 main.py:47] epoch 312, training loss: 2242.75, average training loss: 3042.36, base loss: 2638.61
[INFO 2017-06-26 19:02:58,679 main.py:47] epoch 313, training loss: 2278.37, average training loss: 3039.92, base loss: 2639.02
[INFO 2017-06-26 19:02:58,994 main.py:47] epoch 314, training loss: 2111.95, average training loss: 3036.98, base loss: 2637.76
[INFO 2017-06-26 19:02:59,306 main.py:47] epoch 315, training loss: 2182.30, average training loss: 3034.27, base loss: 2637.48
[INFO 2017-06-26 19:02:59,623 main.py:47] epoch 316, training loss: 2125.72, average training loss: 3031.41, base loss: 2637.25
[INFO 2017-06-26 19:02:59,938 main.py:47] epoch 317, training loss: 2121.01, average training loss: 3028.54, base loss: 2636.68
[INFO 2017-06-26 19:03:00,255 main.py:47] epoch 318, training loss: 2097.34, average training loss: 3025.63, base loss: 2636.11
[INFO 2017-06-26 19:03:00,572 main.py:47] epoch 319, training loss: 2123.75, average training loss: 3022.81, base loss: 2635.46
[INFO 2017-06-26 19:03:00,888 main.py:47] epoch 320, training loss: 2152.11, average training loss: 3020.09, base loss: 2635.54
[INFO 2017-06-26 19:03:01,201 main.py:47] epoch 321, training loss: 1757.98, average training loss: 3016.17, base loss: 2633.61
[INFO 2017-06-26 19:03:01,516 main.py:47] epoch 322, training loss: 2646.28, average training loss: 3015.03, base loss: 2634.96
[INFO 2017-06-26 19:03:01,829 main.py:47] epoch 323, training loss: 2530.15, average training loss: 3013.53, base loss: 2636.18
[INFO 2017-06-26 19:03:02,142 main.py:47] epoch 324, training loss: 1984.43, average training loss: 3010.37, base loss: 2635.47
[INFO 2017-06-26 19:03:02,462 main.py:47] epoch 325, training loss: 2442.23, average training loss: 3008.62, base loss: 2636.76
[INFO 2017-06-26 19:03:02,781 main.py:47] epoch 326, training loss: 2221.81, average training loss: 3006.22, base loss: 2636.94
[INFO 2017-06-26 19:03:03,097 main.py:47] epoch 327, training loss: 2241.23, average training loss: 3003.89, base loss: 2637.08
[INFO 2017-06-26 19:03:03,410 main.py:47] epoch 328, training loss: 2218.56, average training loss: 3001.50, base loss: 2637.18
[INFO 2017-06-26 19:03:03,728 main.py:47] epoch 329, training loss: 2026.22, average training loss: 2998.54, base loss: 2636.22
[INFO 2017-06-26 19:03:04,045 main.py:47] epoch 330, training loss: 1971.70, average training loss: 2995.44, base loss: 2635.21
[INFO 2017-06-26 19:03:04,363 main.py:47] epoch 331, training loss: 2473.28, average training loss: 2993.87, base loss: 2636.24
[INFO 2017-06-26 19:03:04,679 main.py:47] epoch 332, training loss: 2580.93, average training loss: 2992.63, base loss: 2637.48
[INFO 2017-06-26 19:03:04,997 main.py:47] epoch 333, training loss: 2213.53, average training loss: 2990.30, base loss: 2637.27
[INFO 2017-06-26 19:03:05,310 main.py:47] epoch 334, training loss: 2003.66, average training loss: 2987.35, base loss: 2636.58
[INFO 2017-06-26 19:03:05,628 main.py:47] epoch 335, training loss: 2262.31, average training loss: 2985.19, base loss: 2636.75
[INFO 2017-06-26 19:03:05,945 main.py:47] epoch 336, training loss: 2661.73, average training loss: 2984.23, base loss: 2638.37
[INFO 2017-06-26 19:03:06,260 main.py:47] epoch 337, training loss: 2317.64, average training loss: 2982.26, base loss: 2638.83
[INFO 2017-06-26 19:03:06,575 main.py:47] epoch 338, training loss: 2262.76, average training loss: 2980.14, base loss: 2638.93
[INFO 2017-06-26 19:03:06,888 main.py:47] epoch 339, training loss: 2492.15, average training loss: 2978.70, base loss: 2639.57
[INFO 2017-06-26 19:03:07,201 main.py:47] epoch 340, training loss: 1960.59, average training loss: 2975.72, base loss: 2638.75
[INFO 2017-06-26 19:03:07,515 main.py:47] epoch 341, training loss: 2140.34, average training loss: 2973.27, base loss: 2637.70
[INFO 2017-06-26 19:03:07,833 main.py:47] epoch 342, training loss: 2162.22, average training loss: 2970.91, base loss: 2637.16
[INFO 2017-06-26 19:03:08,148 main.py:47] epoch 343, training loss: 1785.09, average training loss: 2967.46, base loss: 2635.56
[INFO 2017-06-26 19:03:08,467 main.py:47] epoch 344, training loss: 2551.26, average training loss: 2966.26, base loss: 2636.41
[INFO 2017-06-26 19:03:08,785 main.py:47] epoch 345, training loss: 2005.91, average training loss: 2963.48, base loss: 2635.19
[INFO 2017-06-26 19:03:09,099 main.py:47] epoch 346, training loss: 2663.54, average training loss: 2962.62, base loss: 2636.60
[INFO 2017-06-26 19:03:09,416 main.py:47] epoch 347, training loss: 2266.30, average training loss: 2960.62, base loss: 2636.89
[INFO 2017-06-26 19:03:09,733 main.py:47] epoch 348, training loss: 1980.72, average training loss: 2957.81, base loss: 2635.69
[INFO 2017-06-26 19:03:10,050 main.py:47] epoch 349, training loss: 2258.70, average training loss: 2955.81, base loss: 2635.97
[INFO 2017-06-26 19:03:10,365 main.py:47] epoch 350, training loss: 2028.11, average training loss: 2953.17, base loss: 2635.23
[INFO 2017-06-26 19:03:10,683 main.py:47] epoch 351, training loss: 2270.67, average training loss: 2951.23, base loss: 2635.43
[INFO 2017-06-26 19:03:11,000 main.py:47] epoch 352, training loss: 2203.23, average training loss: 2949.11, base loss: 2635.38
[INFO 2017-06-26 19:03:11,318 main.py:47] epoch 353, training loss: 2504.31, average training loss: 2947.85, base loss: 2636.79
[INFO 2017-06-26 19:03:11,632 main.py:47] epoch 354, training loss: 2172.40, average training loss: 2945.67, base loss: 2636.88
[INFO 2017-06-26 19:03:11,948 main.py:47] epoch 355, training loss: 2249.10, average training loss: 2943.71, base loss: 2637.39
[INFO 2017-06-26 19:03:12,261 main.py:47] epoch 356, training loss: 2193.52, average training loss: 2941.61, base loss: 2637.26
[INFO 2017-06-26 19:03:12,577 main.py:47] epoch 357, training loss: 2342.28, average training loss: 2939.94, base loss: 2637.71
[INFO 2017-06-26 19:03:12,894 main.py:47] epoch 358, training loss: 2379.94, average training loss: 2938.38, base loss: 2638.43
[INFO 2017-06-26 19:03:13,211 main.py:47] epoch 359, training loss: 2860.88, average training loss: 2938.16, base loss: 2640.68
[INFO 2017-06-26 19:03:13,526 main.py:47] epoch 360, training loss: 2126.41, average training loss: 2935.91, base loss: 2640.35
[INFO 2017-06-26 19:03:13,839 main.py:47] epoch 361, training loss: 2352.48, average training loss: 2934.30, base loss: 2641.45
[INFO 2017-06-26 19:03:14,156 main.py:47] epoch 362, training loss: 2359.62, average training loss: 2932.72, base loss: 2642.18
[INFO 2017-06-26 19:03:14,470 main.py:47] epoch 363, training loss: 2092.94, average training loss: 2930.41, base loss: 2642.13
[INFO 2017-06-26 19:03:14,788 main.py:47] epoch 364, training loss: 2214.86, average training loss: 2928.45, base loss: 2641.81
[INFO 2017-06-26 19:03:15,102 main.py:47] epoch 365, training loss: 1849.78, average training loss: 2925.50, base loss: 2640.40
[INFO 2017-06-26 19:03:15,415 main.py:47] epoch 366, training loss: 2345.23, average training loss: 2923.92, base loss: 2640.47
[INFO 2017-06-26 19:03:15,733 main.py:47] epoch 367, training loss: 2040.42, average training loss: 2921.52, base loss: 2639.90
[INFO 2017-06-26 19:03:16,054 main.py:47] epoch 368, training loss: 2115.26, average training loss: 2919.34, base loss: 2639.05
[INFO 2017-06-26 19:03:16,368 main.py:47] epoch 369, training loss: 1965.07, average training loss: 2916.76, base loss: 2638.20
[INFO 2017-06-26 19:03:16,686 main.py:47] epoch 370, training loss: 2615.34, average training loss: 2915.94, base loss: 2638.90
[INFO 2017-06-26 19:03:17,000 main.py:47] epoch 371, training loss: 2145.94, average training loss: 2913.87, base loss: 2638.68
[INFO 2017-06-26 19:03:17,313 main.py:47] epoch 372, training loss: 2236.71, average training loss: 2912.06, base loss: 2638.47
[INFO 2017-06-26 19:03:17,626 main.py:47] epoch 373, training loss: 2167.88, average training loss: 2910.07, base loss: 2638.38
[INFO 2017-06-26 19:03:17,941 main.py:47] epoch 374, training loss: 1900.52, average training loss: 2907.38, base loss: 2637.10
[INFO 2017-06-26 19:03:18,255 main.py:47] epoch 375, training loss: 2494.87, average training loss: 2906.28, base loss: 2638.02
[INFO 2017-06-26 19:03:18,574 main.py:47] epoch 376, training loss: 2469.68, average training loss: 2905.12, base loss: 2638.81
[INFO 2017-06-26 19:03:18,893 main.py:47] epoch 377, training loss: 2196.14, average training loss: 2903.25, base loss: 2638.71
[INFO 2017-06-26 19:03:19,212 main.py:47] epoch 378, training loss: 2432.00, average training loss: 2902.00, base loss: 2639.58
[INFO 2017-06-26 19:03:19,528 main.py:47] epoch 379, training loss: 2447.54, average training loss: 2900.81, base loss: 2640.12
[INFO 2017-06-26 19:03:19,843 main.py:47] epoch 380, training loss: 2164.86, average training loss: 2898.88, base loss: 2639.47
[INFO 2017-06-26 19:03:20,161 main.py:47] epoch 381, training loss: 2332.41, average training loss: 2897.39, base loss: 2639.71
[INFO 2017-06-26 19:03:20,477 main.py:47] epoch 382, training loss: 2709.57, average training loss: 2896.90, base loss: 2641.30
[INFO 2017-06-26 19:03:20,792 main.py:47] epoch 383, training loss: 1988.39, average training loss: 2894.54, base loss: 2640.69
[INFO 2017-06-26 19:03:21,103 main.py:47] epoch 384, training loss: 2088.67, average training loss: 2892.44, base loss: 2640.38
[INFO 2017-06-26 19:03:21,418 main.py:47] epoch 385, training loss: 2341.73, average training loss: 2891.02, base loss: 2640.97
[INFO 2017-06-26 19:03:21,737 main.py:47] epoch 386, training loss: 2238.42, average training loss: 2889.33, base loss: 2641.11
[INFO 2017-06-26 19:03:22,051 main.py:47] epoch 387, training loss: 2375.79, average training loss: 2888.01, base loss: 2641.61
[INFO 2017-06-26 19:03:22,365 main.py:47] epoch 388, training loss: 2106.83, average training loss: 2886.00, base loss: 2640.93
[INFO 2017-06-26 19:03:22,682 main.py:47] epoch 389, training loss: 2038.01, average training loss: 2883.82, base loss: 2640.66
[INFO 2017-06-26 19:03:23,001 main.py:47] epoch 390, training loss: 2134.17, average training loss: 2881.91, base loss: 2640.52
[INFO 2017-06-26 19:03:23,315 main.py:47] epoch 391, training loss: 1986.99, average training loss: 2879.62, base loss: 2639.45
[INFO 2017-06-26 19:03:23,633 main.py:47] epoch 392, training loss: 2269.91, average training loss: 2878.07, base loss: 2639.70
[INFO 2017-06-26 19:03:23,949 main.py:47] epoch 393, training loss: 1980.54, average training loss: 2875.79, base loss: 2639.09
[INFO 2017-06-26 19:03:24,267 main.py:47] epoch 394, training loss: 1938.84, average training loss: 2873.42, base loss: 2638.03
[INFO 2017-06-26 19:03:24,585 main.py:47] epoch 395, training loss: 2322.74, average training loss: 2872.03, base loss: 2638.50
[INFO 2017-06-26 19:03:24,903 main.py:47] epoch 396, training loss: 2179.12, average training loss: 2870.29, base loss: 2638.38
[INFO 2017-06-26 19:03:25,217 main.py:47] epoch 397, training loss: 1868.09, average training loss: 2867.77, base loss: 2637.14
[INFO 2017-06-26 19:03:25,534 main.py:47] epoch 398, training loss: 2052.69, average training loss: 2865.73, base loss: 2636.58
[INFO 2017-06-26 19:03:25,848 main.py:47] epoch 399, training loss: 2583.83, average training loss: 2865.02, base loss: 2637.79
[INFO 2017-06-26 19:03:25,848 main.py:49] epoch 399, testing
[INFO 2017-06-26 19:03:29,925 main.py:100] average testing loss: 2264.32, base loss: 2676.02
[INFO 2017-06-26 19:03:29,949 main.py:73] current best accuracy: 2213.15
[INFO 2017-06-26 19:03:30,264 main.py:47] epoch 400, training loss: 1929.23, average training loss: 2862.69, base loss: 2636.78
[INFO 2017-06-26 19:03:30,575 main.py:47] epoch 401, training loss: 2177.10, average training loss: 2860.98, base loss: 2636.66
[INFO 2017-06-26 19:03:30,892 main.py:47] epoch 402, training loss: 2264.40, average training loss: 2859.50, base loss: 2636.94
[INFO 2017-06-26 19:03:31,210 main.py:47] epoch 403, training loss: 2436.09, average training loss: 2858.45, base loss: 2637.66
[INFO 2017-06-26 19:03:31,526 main.py:47] epoch 404, training loss: 2524.98, average training loss: 2857.63, base loss: 2638.75
[INFO 2017-06-26 19:03:31,842 main.py:47] epoch 405, training loss: 2291.89, average training loss: 2856.24, base loss: 2639.10
[INFO 2017-06-26 19:03:32,159 main.py:47] epoch 406, training loss: 2030.68, average training loss: 2854.21, base loss: 2638.42
[INFO 2017-06-26 19:03:32,471 main.py:47] epoch 407, training loss: 2663.15, average training loss: 2853.74, base loss: 2639.98
[INFO 2017-06-26 19:03:32,789 main.py:47] epoch 408, training loss: 1982.78, average training loss: 2851.61, base loss: 2639.10
[INFO 2017-06-26 19:03:33,105 main.py:47] epoch 409, training loss: 2276.02, average training loss: 2850.21, base loss: 2639.57
[INFO 2017-06-26 19:03:33,418 main.py:47] epoch 410, training loss: 2497.58, average training loss: 2849.35, base loss: 2640.47
[INFO 2017-06-26 19:03:33,732 main.py:47] epoch 411, training loss: 2551.65, average training loss: 2848.63, base loss: 2641.81
[INFO 2017-06-26 19:03:34,049 main.py:47] epoch 412, training loss: 2492.40, average training loss: 2847.76, base loss: 2642.69
[INFO 2017-06-26 19:03:34,365 main.py:47] epoch 413, training loss: 2446.55, average training loss: 2846.79, base loss: 2643.42
[INFO 2017-06-26 19:03:34,681 main.py:47] epoch 414, training loss: 2192.62, average training loss: 2845.22, base loss: 2643.26
[INFO 2017-06-26 19:03:34,995 main.py:47] epoch 415, training loss: 2385.30, average training loss: 2844.11, base loss: 2643.72
[INFO 2017-06-26 19:03:35,307 main.py:47] epoch 416, training loss: 2357.45, average training loss: 2842.95, base loss: 2644.27
[INFO 2017-06-26 19:03:35,622 main.py:47] epoch 417, training loss: 2560.07, average training loss: 2842.27, base loss: 2645.53
[INFO 2017-06-26 19:03:35,936 main.py:47] epoch 418, training loss: 1931.89, average training loss: 2840.10, base loss: 2644.85
[INFO 2017-06-26 19:03:36,249 main.py:47] epoch 419, training loss: 2290.75, average training loss: 2838.79, base loss: 2645.32
[INFO 2017-06-26 19:03:36,562 main.py:47] epoch 420, training loss: 2100.25, average training loss: 2837.03, base loss: 2644.99
[INFO 2017-06-26 19:03:36,878 main.py:47] epoch 421, training loss: 2293.80, average training loss: 2835.75, base loss: 2645.30
[INFO 2017-06-26 19:03:37,194 main.py:47] epoch 422, training loss: 2020.00, average training loss: 2833.82, base loss: 2644.90
[INFO 2017-06-26 19:03:37,511 main.py:47] epoch 423, training loss: 1966.21, average training loss: 2831.77, base loss: 2644.44
[INFO 2017-06-26 19:03:37,828 main.py:47] epoch 424, training loss: 2047.78, average training loss: 2829.93, base loss: 2644.01
[INFO 2017-06-26 19:03:38,144 main.py:47] epoch 425, training loss: 2331.17, average training loss: 2828.76, base loss: 2644.22
[INFO 2017-06-26 19:03:38,454 main.py:47] epoch 426, training loss: 2213.65, average training loss: 2827.32, base loss: 2644.08
[INFO 2017-06-26 19:03:38,768 main.py:47] epoch 427, training loss: 1888.96, average training loss: 2825.12, base loss: 2643.40
[INFO 2017-06-26 19:03:39,085 main.py:47] epoch 428, training loss: 2466.37, average training loss: 2824.29, base loss: 2644.28
[INFO 2017-06-26 19:03:39,403 main.py:47] epoch 429, training loss: 2024.04, average training loss: 2822.43, base loss: 2643.95
[INFO 2017-06-26 19:03:39,720 main.py:47] epoch 430, training loss: 2625.42, average training loss: 2821.97, base loss: 2645.05
[INFO 2017-06-26 19:03:40,032 main.py:47] epoch 431, training loss: 2202.88, average training loss: 2820.54, base loss: 2645.05
[INFO 2017-06-26 19:03:40,347 main.py:47] epoch 432, training loss: 2983.43, average training loss: 2820.91, base loss: 2647.37
[INFO 2017-06-26 19:03:40,666 main.py:47] epoch 433, training loss: 2059.76, average training loss: 2819.16, base loss: 2647.10
[INFO 2017-06-26 19:03:40,980 main.py:47] epoch 434, training loss: 2262.14, average training loss: 2817.88, base loss: 2647.13
[INFO 2017-06-26 19:03:41,296 main.py:47] epoch 435, training loss: 2115.88, average training loss: 2816.27, base loss: 2646.73
[INFO 2017-06-26 19:03:41,613 main.py:47] epoch 436, training loss: 2166.41, average training loss: 2814.78, base loss: 2646.52
[INFO 2017-06-26 19:03:41,929 main.py:47] epoch 437, training loss: 2292.96, average training loss: 2813.59, base loss: 2646.79
[INFO 2017-06-26 19:03:42,247 main.py:47] epoch 438, training loss: 2152.43, average training loss: 2812.08, base loss: 2646.37
[INFO 2017-06-26 19:03:42,563 main.py:47] epoch 439, training loss: 2352.68, average training loss: 2811.04, base loss: 2646.72
[INFO 2017-06-26 19:03:42,887 main.py:47] epoch 440, training loss: 1960.74, average training loss: 2809.11, base loss: 2646.05
[INFO 2017-06-26 19:03:43,201 main.py:47] epoch 441, training loss: 2212.74, average training loss: 2807.76, base loss: 2646.29
[INFO 2017-06-26 19:03:43,514 main.py:47] epoch 442, training loss: 2073.31, average training loss: 2806.10, base loss: 2645.96
[INFO 2017-06-26 19:03:43,824 main.py:47] epoch 443, training loss: 2446.95, average training loss: 2805.29, base loss: 2646.70
[INFO 2017-06-26 19:03:44,137 main.py:47] epoch 444, training loss: 1982.89, average training loss: 2803.45, base loss: 2646.43
[INFO 2017-06-26 19:03:44,454 main.py:47] epoch 445, training loss: 2002.24, average training loss: 2801.65, base loss: 2645.71
[INFO 2017-06-26 19:03:44,772 main.py:47] epoch 446, training loss: 2577.47, average training loss: 2801.15, base loss: 2646.56
[INFO 2017-06-26 19:03:45,093 main.py:47] epoch 447, training loss: 2583.84, average training loss: 2800.66, base loss: 2647.67
[INFO 2017-06-26 19:03:45,412 main.py:47] epoch 448, training loss: 2722.93, average training loss: 2800.49, base loss: 2649.06
[INFO 2017-06-26 19:03:45,731 main.py:47] epoch 449, training loss: 2362.16, average training loss: 2799.52, base loss: 2649.68
[INFO 2017-06-26 19:03:46,049 main.py:47] epoch 450, training loss: 2449.23, average training loss: 2798.74, base loss: 2650.70
[INFO 2017-06-26 19:03:46,370 main.py:47] epoch 451, training loss: 2077.04, average training loss: 2797.14, base loss: 2650.06
[INFO 2017-06-26 19:03:46,690 main.py:47] epoch 452, training loss: 1877.38, average training loss: 2795.11, base loss: 2648.95
[INFO 2017-06-26 19:03:47,006 main.py:47] epoch 453, training loss: 2245.63, average training loss: 2793.90, base loss: 2649.02
[INFO 2017-06-26 19:03:47,323 main.py:47] epoch 454, training loss: 2310.69, average training loss: 2792.84, base loss: 2649.47
[INFO 2017-06-26 19:03:47,643 main.py:47] epoch 455, training loss: 2492.60, average training loss: 2792.18, base loss: 2650.03
[INFO 2017-06-26 19:03:47,964 main.py:47] epoch 456, training loss: 2005.28, average training loss: 2790.46, base loss: 2649.35
[INFO 2017-06-26 19:03:48,282 main.py:47] epoch 457, training loss: 1870.05, average training loss: 2788.45, base loss: 2648.48
[INFO 2017-06-26 19:03:48,602 main.py:47] epoch 458, training loss: 2447.07, average training loss: 2787.71, base loss: 2648.98
[INFO 2017-06-26 19:03:48,922 main.py:47] epoch 459, training loss: 2364.85, average training loss: 2786.79, base loss: 2649.57
[INFO 2017-06-26 19:03:49,243 main.py:47] epoch 460, training loss: 2262.38, average training loss: 2785.65, base loss: 2649.77
[INFO 2017-06-26 19:03:49,559 main.py:47] epoch 461, training loss: 2112.17, average training loss: 2784.19, base loss: 2649.59
[INFO 2017-06-26 19:03:49,877 main.py:47] epoch 462, training loss: 2122.98, average training loss: 2782.76, base loss: 2649.35
[INFO 2017-06-26 19:03:50,196 main.py:47] epoch 463, training loss: 2300.62, average training loss: 2781.72, base loss: 2649.64
[INFO 2017-06-26 19:03:50,510 main.py:47] epoch 464, training loss: 2074.83, average training loss: 2780.20, base loss: 2649.43
[INFO 2017-06-26 19:03:50,827 main.py:47] epoch 465, training loss: 2186.48, average training loss: 2778.93, base loss: 2649.22
[INFO 2017-06-26 19:03:51,141 main.py:47] epoch 466, training loss: 2367.64, average training loss: 2778.05, base loss: 2649.49
[INFO 2017-06-26 19:03:51,458 main.py:47] epoch 467, training loss: 2428.66, average training loss: 2777.30, base loss: 2650.15
[INFO 2017-06-26 19:03:51,771 main.py:47] epoch 468, training loss: 2384.89, average training loss: 2776.47, base loss: 2650.66
[INFO 2017-06-26 19:03:52,084 main.py:47] epoch 469, training loss: 2247.56, average training loss: 2775.34, base loss: 2650.76
[INFO 2017-06-26 19:03:52,400 main.py:47] epoch 470, training loss: 2602.44, average training loss: 2774.97, base loss: 2651.72
[INFO 2017-06-26 19:03:52,715 main.py:47] epoch 471, training loss: 2380.44, average training loss: 2774.14, base loss: 2652.35
[INFO 2017-06-26 19:03:53,031 main.py:47] epoch 472, training loss: 2190.11, average training loss: 2772.90, base loss: 2652.26
[INFO 2017-06-26 19:03:53,346 main.py:47] epoch 473, training loss: 1957.36, average training loss: 2771.18, base loss: 2651.64
[INFO 2017-06-26 19:03:53,662 main.py:47] epoch 474, training loss: 2194.08, average training loss: 2769.97, base loss: 2651.61
[INFO 2017-06-26 19:03:53,977 main.py:47] epoch 475, training loss: 2306.95, average training loss: 2769.00, base loss: 2651.58
[INFO 2017-06-26 19:03:54,291 main.py:47] epoch 476, training loss: 2419.28, average training loss: 2768.26, base loss: 2652.09
[INFO 2017-06-26 19:03:54,608 main.py:47] epoch 477, training loss: 2463.41, average training loss: 2767.62, base loss: 2652.78
[INFO 2017-06-26 19:03:54,925 main.py:47] epoch 478, training loss: 2153.94, average training loss: 2766.34, base loss: 2652.63
[INFO 2017-06-26 19:03:55,239 main.py:47] epoch 479, training loss: 2588.31, average training loss: 2765.97, base loss: 2653.67
[INFO 2017-06-26 19:03:55,553 main.py:47] epoch 480, training loss: 2029.90, average training loss: 2764.44, base loss: 2653.18
[INFO 2017-06-26 19:03:55,870 main.py:47] epoch 481, training loss: 2270.50, average training loss: 2763.42, base loss: 2653.33
[INFO 2017-06-26 19:03:56,187 main.py:47] epoch 482, training loss: 2772.05, average training loss: 2763.44, base loss: 2654.77
[INFO 2017-06-26 19:03:56,500 main.py:47] epoch 483, training loss: 2170.85, average training loss: 2762.21, base loss: 2654.90
[INFO 2017-06-26 19:03:56,818 main.py:47] epoch 484, training loss: 2584.90, average training loss: 2761.85, base loss: 2655.65
[INFO 2017-06-26 19:03:57,135 main.py:47] epoch 485, training loss: 2504.22, average training loss: 2761.32, base loss: 2656.43
[INFO 2017-06-26 19:03:57,451 main.py:47] epoch 486, training loss: 2606.00, average training loss: 2761.00, base loss: 2657.52
[INFO 2017-06-26 19:03:57,777 main.py:47] epoch 487, training loss: 2306.90, average training loss: 2760.07, base loss: 2657.69
[INFO 2017-06-26 19:03:58,090 main.py:47] epoch 488, training loss: 1982.89, average training loss: 2758.48, base loss: 2657.24
[INFO 2017-06-26 19:03:58,407 main.py:47] epoch 489, training loss: 2219.02, average training loss: 2757.38, base loss: 2657.54
[INFO 2017-06-26 19:03:58,723 main.py:47] epoch 490, training loss: 2135.77, average training loss: 2756.11, base loss: 2657.10
[INFO 2017-06-26 19:03:59,037 main.py:47] epoch 491, training loss: 2111.94, average training loss: 2754.80, base loss: 2656.89
[INFO 2017-06-26 19:03:59,351 main.py:47] epoch 492, training loss: 2153.23, average training loss: 2753.58, base loss: 2656.88
[INFO 2017-06-26 19:03:59,666 main.py:47] epoch 493, training loss: 2093.07, average training loss: 2752.24, base loss: 2656.73
[INFO 2017-06-26 19:03:59,980 main.py:47] epoch 494, training loss: 1958.32, average training loss: 2750.64, base loss: 2656.10
[INFO 2017-06-26 19:04:00,294 main.py:47] epoch 495, training loss: 2121.31, average training loss: 2749.37, base loss: 2655.89
[INFO 2017-06-26 19:04:00,608 main.py:47] epoch 496, training loss: 1822.99, average training loss: 2747.51, base loss: 2654.78
[INFO 2017-06-26 19:04:00,924 main.py:47] epoch 497, training loss: 2193.16, average training loss: 2746.39, base loss: 2655.14
[INFO 2017-06-26 19:04:01,238 main.py:47] epoch 498, training loss: 2211.67, average training loss: 2745.32, base loss: 2654.78
[INFO 2017-06-26 19:04:01,551 main.py:47] epoch 499, training loss: 2591.48, average training loss: 2745.01, base loss: 2655.65
[INFO 2017-06-26 19:04:01,551 main.py:49] epoch 499, testing
[INFO 2017-06-26 19:04:05,620 main.py:100] average testing loss: 2164.89, base loss: 2656.01
[INFO 2017-06-26 19:04:05,643 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 19:04:05,657 main.py:73] current best accuracy: 2164.89
[INFO 2017-06-26 19:04:05,972 main.py:47] epoch 500, training loss: 2508.10, average training loss: 2744.54, base loss: 2656.56
[INFO 2017-06-26 19:04:06,288 main.py:47] epoch 501, training loss: 1955.27, average training loss: 2742.97, base loss: 2656.27
[INFO 2017-06-26 19:04:06,606 main.py:47] epoch 502, training loss: 2064.98, average training loss: 2741.62, base loss: 2656.25
[INFO 2017-06-26 19:04:06,922 main.py:47] epoch 503, training loss: 2162.35, average training loss: 2740.47, base loss: 2655.94
[INFO 2017-06-26 19:04:07,238 main.py:47] epoch 504, training loss: 2249.63, average training loss: 2739.50, base loss: 2656.21
[INFO 2017-06-26 19:04:07,554 main.py:47] epoch 505, training loss: 2177.89, average training loss: 2738.39, base loss: 2656.39
[INFO 2017-06-26 19:04:07,868 main.py:47] epoch 506, training loss: 2082.99, average training loss: 2737.10, base loss: 2655.90
[INFO 2017-06-26 19:04:08,182 main.py:47] epoch 507, training loss: 2147.87, average training loss: 2735.94, base loss: 2655.79
[INFO 2017-06-26 19:04:08,500 main.py:47] epoch 508, training loss: 2073.45, average training loss: 2734.64, base loss: 2655.50
[INFO 2017-06-26 19:04:08,814 main.py:47] epoch 509, training loss: 2047.25, average training loss: 2733.29, base loss: 2655.11
[INFO 2017-06-26 19:04:09,128 main.py:47] epoch 510, training loss: 2010.68, average training loss: 2731.87, base loss: 2654.72
[INFO 2017-06-26 19:04:09,446 main.py:47] epoch 511, training loss: 1870.52, average training loss: 2730.19, base loss: 2654.03
[INFO 2017-06-26 19:04:09,755 main.py:47] epoch 512, training loss: 2128.87, average training loss: 2729.02, base loss: 2653.84
[INFO 2017-06-26 19:04:10,070 main.py:47] epoch 513, training loss: 1997.31, average training loss: 2727.60, base loss: 2653.47
[INFO 2017-06-26 19:04:10,384 main.py:47] epoch 514, training loss: 1913.64, average training loss: 2726.01, base loss: 2652.97
[INFO 2017-06-26 19:04:10,700 main.py:47] epoch 515, training loss: 1914.06, average training loss: 2724.44, base loss: 2652.23
[INFO 2017-06-26 19:04:11,014 main.py:47] epoch 516, training loss: 1916.43, average training loss: 2722.88, base loss: 2651.76
[INFO 2017-06-26 19:04:11,330 main.py:47] epoch 517, training loss: 1907.90, average training loss: 2721.31, base loss: 2650.92
[INFO 2017-06-26 19:04:11,647 main.py:47] epoch 518, training loss: 1969.19, average training loss: 2719.86, base loss: 2650.67
[INFO 2017-06-26 19:04:11,965 main.py:47] epoch 519, training loss: 2311.00, average training loss: 2719.07, base loss: 2651.20
[INFO 2017-06-26 19:04:12,283 main.py:47] epoch 520, training loss: 2009.23, average training loss: 2717.71, base loss: 2650.54
[INFO 2017-06-26 19:04:12,601 main.py:47] epoch 521, training loss: 1741.14, average training loss: 2715.84, base loss: 2649.40
[INFO 2017-06-26 19:04:12,915 main.py:47] epoch 522, training loss: 2347.48, average training loss: 2715.13, base loss: 2649.72
[INFO 2017-06-26 19:04:13,235 main.py:47] epoch 523, training loss: 2296.21, average training loss: 2714.33, base loss: 2650.06
[INFO 2017-06-26 19:04:13,554 main.py:47] epoch 524, training loss: 2202.76, average training loss: 2713.36, base loss: 2650.24
[INFO 2017-06-26 19:04:13,870 main.py:47] epoch 525, training loss: 2071.76, average training loss: 2712.14, base loss: 2650.01
[INFO 2017-06-26 19:04:14,189 main.py:47] epoch 526, training loss: 1989.35, average training loss: 2710.77, base loss: 2649.50
[INFO 2017-06-26 19:04:14,508 main.py:47] epoch 527, training loss: 2457.41, average training loss: 2710.29, base loss: 2650.10
[INFO 2017-06-26 19:04:14,829 main.py:47] epoch 528, training loss: 2183.13, average training loss: 2709.29, base loss: 2650.12
[INFO 2017-06-26 19:04:15,149 main.py:47] epoch 529, training loss: 2328.13, average training loss: 2708.57, base loss: 2650.40
[INFO 2017-06-26 19:04:15,464 main.py:47] epoch 530, training loss: 2214.98, average training loss: 2707.64, base loss: 2650.46
[INFO 2017-06-26 19:04:15,781 main.py:47] epoch 531, training loss: 2135.92, average training loss: 2706.57, base loss: 2650.35
[INFO 2017-06-26 19:04:16,095 main.py:47] epoch 532, training loss: 2137.34, average training loss: 2705.50, base loss: 2650.18
[INFO 2017-06-26 19:04:16,410 main.py:47] epoch 533, training loss: 2136.70, average training loss: 2704.43, base loss: 2650.36
[INFO 2017-06-26 19:04:16,728 main.py:47] epoch 534, training loss: 1896.58, average training loss: 2702.92, base loss: 2649.80
[INFO 2017-06-26 19:04:17,043 main.py:47] epoch 535, training loss: 2535.10, average training loss: 2702.61, base loss: 2650.51
[INFO 2017-06-26 19:04:17,358 main.py:47] epoch 536, training loss: 2409.99, average training loss: 2702.07, base loss: 2650.89
[INFO 2017-06-26 19:04:17,675 main.py:47] epoch 537, training loss: 2185.17, average training loss: 2701.11, base loss: 2650.95
[INFO 2017-06-26 19:04:17,991 main.py:47] epoch 538, training loss: 2000.29, average training loss: 2699.81, base loss: 2650.53
[INFO 2017-06-26 19:04:18,304 main.py:47] epoch 539, training loss: 2088.31, average training loss: 2698.67, base loss: 2650.33
[INFO 2017-06-26 19:04:18,619 main.py:47] epoch 540, training loss: 2206.50, average training loss: 2697.76, base loss: 2650.27
[INFO 2017-06-26 19:04:18,937 main.py:47] epoch 541, training loss: 1864.69, average training loss: 2696.23, base loss: 2649.31
[INFO 2017-06-26 19:04:19,252 main.py:47] epoch 542, training loss: 2350.76, average training loss: 2695.59, base loss: 2649.57
[INFO 2017-06-26 19:04:19,569 main.py:47] epoch 543, training loss: 2106.36, average training loss: 2694.51, base loss: 2649.39
[INFO 2017-06-26 19:04:19,887 main.py:47] epoch 544, training loss: 2374.91, average training loss: 2693.92, base loss: 2649.84
[INFO 2017-06-26 19:04:20,202 main.py:47] epoch 545, training loss: 2785.50, average training loss: 2694.09, base loss: 2651.48
[INFO 2017-06-26 19:04:20,519 main.py:47] epoch 546, training loss: 2445.52, average training loss: 2693.63, base loss: 2652.29
[INFO 2017-06-26 19:04:20,834 main.py:47] epoch 547, training loss: 2657.72, average training loss: 2693.57, base loss: 2653.56
[INFO 2017-06-26 19:04:21,150 main.py:47] epoch 548, training loss: 2673.48, average training loss: 2693.53, base loss: 2654.94
[INFO 2017-06-26 19:04:21,468 main.py:47] epoch 549, training loss: 2244.51, average training loss: 2692.71, base loss: 2655.09
[INFO 2017-06-26 19:04:21,781 main.py:47] epoch 550, training loss: 2240.83, average training loss: 2691.89, base loss: 2655.25
[INFO 2017-06-26 19:04:22,098 main.py:47] epoch 551, training loss: 1917.59, average training loss: 2690.49, base loss: 2654.28
[INFO 2017-06-26 19:04:22,414 main.py:47] epoch 552, training loss: 1897.28, average training loss: 2689.06, base loss: 2653.68
[INFO 2017-06-26 19:04:22,733 main.py:47] epoch 553, training loss: 2452.71, average training loss: 2688.63, base loss: 2654.31
[INFO 2017-06-26 19:04:23,050 main.py:47] epoch 554, training loss: 2492.02, average training loss: 2688.28, base loss: 2655.26
[INFO 2017-06-26 19:04:23,366 main.py:47] epoch 555, training loss: 2179.90, average training loss: 2687.36, base loss: 2655.34
[INFO 2017-06-26 19:04:23,686 main.py:47] epoch 556, training loss: 2462.18, average training loss: 2686.96, base loss: 2656.09
[INFO 2017-06-26 19:04:24,003 main.py:47] epoch 557, training loss: 1904.81, average training loss: 2685.56, base loss: 2655.34
[INFO 2017-06-26 19:04:24,319 main.py:47] epoch 558, training loss: 2437.86, average training loss: 2685.11, base loss: 2655.78
[INFO 2017-06-26 19:04:24,636 main.py:47] epoch 559, training loss: 2083.81, average training loss: 2684.04, base loss: 2655.65
[INFO 2017-06-26 19:04:24,950 main.py:47] epoch 560, training loss: 2399.41, average training loss: 2683.53, base loss: 2656.24
[INFO 2017-06-26 19:04:25,267 main.py:47] epoch 561, training loss: 2463.65, average training loss: 2683.14, base loss: 2656.80
[INFO 2017-06-26 19:04:25,583 main.py:47] epoch 562, training loss: 2500.42, average training loss: 2682.82, base loss: 2657.75
[INFO 2017-06-26 19:04:25,897 main.py:47] epoch 563, training loss: 1881.12, average training loss: 2681.40, base loss: 2657.12
[INFO 2017-06-26 19:04:26,214 main.py:47] epoch 564, training loss: 2063.95, average training loss: 2680.30, base loss: 2657.22
[INFO 2017-06-26 19:04:26,528 main.py:47] epoch 565, training loss: 1958.50, average training loss: 2679.03, base loss: 2656.85
[INFO 2017-06-26 19:04:26,842 main.py:47] epoch 566, training loss: 2109.80, average training loss: 2678.02, base loss: 2656.51
[INFO 2017-06-26 19:04:27,159 main.py:47] epoch 567, training loss: 1968.91, average training loss: 2676.77, base loss: 2656.08
[INFO 2017-06-26 19:04:27,473 main.py:47] epoch 568, training loss: 2414.12, average training loss: 2676.31, base loss: 2656.49
[INFO 2017-06-26 19:04:27,789 main.py:47] epoch 569, training loss: 2191.74, average training loss: 2675.46, base loss: 2656.37
[INFO 2017-06-26 19:04:28,104 main.py:47] epoch 570, training loss: 2508.82, average training loss: 2675.17, base loss: 2657.06
[INFO 2017-06-26 19:04:28,420 main.py:47] epoch 571, training loss: 2312.57, average training loss: 2674.54, base loss: 2657.20
[INFO 2017-06-26 19:04:28,736 main.py:47] epoch 572, training loss: 1893.03, average training loss: 2673.17, base loss: 2656.63
[INFO 2017-06-26 19:04:29,050 main.py:47] epoch 573, training loss: 2300.65, average training loss: 2672.52, base loss: 2656.83
[INFO 2017-06-26 19:04:29,367 main.py:47] epoch 574, training loss: 2248.34, average training loss: 2671.79, base loss: 2656.96
[INFO 2017-06-26 19:04:29,685 main.py:47] epoch 575, training loss: 1895.42, average training loss: 2670.44, base loss: 2656.19
[INFO 2017-06-26 19:04:29,999 main.py:47] epoch 576, training loss: 2463.44, average training loss: 2670.08, base loss: 2656.68
[INFO 2017-06-26 19:04:30,318 main.py:47] epoch 577, training loss: 2051.69, average training loss: 2669.01, base loss: 2656.41
[INFO 2017-06-26 19:04:30,635 main.py:47] epoch 578, training loss: 2113.55, average training loss: 2668.05, base loss: 2656.18
[INFO 2017-06-26 19:04:30,948 main.py:47] epoch 579, training loss: 2015.38, average training loss: 2666.93, base loss: 2655.70
[INFO 2017-06-26 19:04:31,266 main.py:47] epoch 580, training loss: 1929.18, average training loss: 2665.66, base loss: 2655.41
[INFO 2017-06-26 19:04:31,580 main.py:47] epoch 581, training loss: 2078.89, average training loss: 2664.65, base loss: 2654.92
[INFO 2017-06-26 19:04:31,894 main.py:47] epoch 582, training loss: 2529.37, average training loss: 2664.42, base loss: 2655.88
[INFO 2017-06-26 19:04:32,209 main.py:47] epoch 583, training loss: 2017.69, average training loss: 2663.31, base loss: 2655.34
[INFO 2017-06-26 19:04:32,526 main.py:47] epoch 584, training loss: 2645.58, average training loss: 2663.28, base loss: 2656.40
[INFO 2017-06-26 19:04:32,843 main.py:47] epoch 585, training loss: 2057.25, average training loss: 2662.24, base loss: 2656.28
[INFO 2017-06-26 19:04:33,156 main.py:47] epoch 586, training loss: 1936.56, average training loss: 2661.01, base loss: 2655.68
[INFO 2017-06-26 19:04:33,471 main.py:47] epoch 587, training loss: 1915.94, average training loss: 2659.74, base loss: 2655.17
[INFO 2017-06-26 19:04:33,785 main.py:47] epoch 588, training loss: 2007.82, average training loss: 2658.63, base loss: 2654.83
[INFO 2017-06-26 19:04:34,099 main.py:47] epoch 589, training loss: 2348.95, average training loss: 2658.11, base loss: 2655.33
[INFO 2017-06-26 19:04:34,414 main.py:47] epoch 590, training loss: 1840.04, average training loss: 2656.72, base loss: 2654.46
[INFO 2017-06-26 19:04:34,737 main.py:47] epoch 591, training loss: 2247.24, average training loss: 2656.03, base loss: 2654.67
[INFO 2017-06-26 19:04:35,054 main.py:47] epoch 592, training loss: 2305.00, average training loss: 2655.44, base loss: 2654.85
[INFO 2017-06-26 19:04:35,370 main.py:47] epoch 593, training loss: 1744.51, average training loss: 2653.91, base loss: 2653.90
[INFO 2017-06-26 19:04:35,691 main.py:47] epoch 594, training loss: 2149.45, average training loss: 2653.06, base loss: 2653.75
[INFO 2017-06-26 19:04:36,006 main.py:47] epoch 595, training loss: 2348.86, average training loss: 2652.55, base loss: 2654.36
[INFO 2017-06-26 19:04:36,321 main.py:47] epoch 596, training loss: 2343.48, average training loss: 2652.03, base loss: 2654.77
[INFO 2017-06-26 19:04:36,636 main.py:47] epoch 597, training loss: 1954.22, average training loss: 2650.86, base loss: 2654.45
[INFO 2017-06-26 19:04:36,953 main.py:47] epoch 598, training loss: 2268.91, average training loss: 2650.23, base loss: 2654.48
[INFO 2017-06-26 19:04:37,266 main.py:47] epoch 599, training loss: 2019.32, average training loss: 2649.17, base loss: 2654.06
[INFO 2017-06-26 19:04:37,266 main.py:49] epoch 599, testing
[INFO 2017-06-26 19:04:41,352 main.py:100] average testing loss: 2188.31, base loss: 2673.29
[INFO 2017-06-26 19:04:41,377 main.py:73] current best accuracy: 2164.89
[INFO 2017-06-26 19:04:41,698 main.py:47] epoch 600, training loss: 2054.10, average training loss: 2648.18, base loss: 2653.96
[INFO 2017-06-26 19:04:42,013 main.py:47] epoch 601, training loss: 2253.62, average training loss: 2647.53, base loss: 2654.22
[INFO 2017-06-26 19:04:42,327 main.py:47] epoch 602, training loss: 2015.17, average training loss: 2646.48, base loss: 2653.96
[INFO 2017-06-26 19:04:42,645 main.py:47] epoch 603, training loss: 2190.35, average training loss: 2645.73, base loss: 2653.95
[INFO 2017-06-26 19:04:42,958 main.py:47] epoch 604, training loss: 2039.78, average training loss: 2644.72, base loss: 2653.66
[INFO 2017-06-26 19:04:43,271 main.py:47] epoch 605, training loss: 1918.39, average training loss: 2643.53, base loss: 2653.15
[INFO 2017-06-26 19:04:43,587 main.py:47] epoch 606, training loss: 2199.09, average training loss: 2642.79, base loss: 2653.08
[INFO 2017-06-26 19:04:43,904 main.py:47] epoch 607, training loss: 1967.86, average training loss: 2641.68, base loss: 2652.66
[INFO 2017-06-26 19:04:44,221 main.py:47] epoch 608, training loss: 2492.62, average training loss: 2641.44, base loss: 2653.29
[INFO 2017-06-26 19:04:44,536 main.py:47] epoch 609, training loss: 2154.83, average training loss: 2640.64, base loss: 2652.91
[INFO 2017-06-26 19:04:44,854 main.py:47] epoch 610, training loss: 2107.21, average training loss: 2639.77, base loss: 2652.84
[INFO 2017-06-26 19:04:45,173 main.py:47] epoch 611, training loss: 2126.45, average training loss: 2638.93, base loss: 2652.63
[INFO 2017-06-26 19:04:45,489 main.py:47] epoch 612, training loss: 1937.12, average training loss: 2637.78, base loss: 2652.29
[INFO 2017-06-26 19:04:45,807 main.py:47] epoch 613, training loss: 2176.15, average training loss: 2637.03, base loss: 2652.50
[INFO 2017-06-26 19:04:46,130 main.py:47] epoch 614, training loss: 2006.13, average training loss: 2636.01, base loss: 2651.95
[INFO 2017-06-26 19:04:46,443 main.py:47] epoch 615, training loss: 1887.79, average training loss: 2634.79, base loss: 2651.18
[INFO 2017-06-26 19:04:46,753 main.py:47] epoch 616, training loss: 1974.46, average training loss: 2633.72, base loss: 2650.80
[INFO 2017-06-26 19:04:47,067 main.py:47] epoch 617, training loss: 2178.17, average training loss: 2632.98, base loss: 2650.86
[INFO 2017-06-26 19:04:47,383 main.py:47] epoch 618, training loss: 1781.60, average training loss: 2631.61, base loss: 2649.96
[INFO 2017-06-26 19:04:47,704 main.py:47] epoch 619, training loss: 2147.56, average training loss: 2630.83, base loss: 2649.88
[INFO 2017-06-26 19:04:48,020 main.py:47] epoch 620, training loss: 1999.44, average training loss: 2629.81, base loss: 2649.40
[INFO 2017-06-26 19:04:48,334 main.py:47] epoch 621, training loss: 2208.44, average training loss: 2629.13, base loss: 2649.56
[INFO 2017-06-26 19:04:48,652 main.py:47] epoch 622, training loss: 2108.10, average training loss: 2628.30, base loss: 2649.61
[INFO 2017-06-26 19:04:48,968 main.py:47] epoch 623, training loss: 2042.86, average training loss: 2627.36, base loss: 2649.25
[INFO 2017-06-26 19:04:49,282 main.py:47] epoch 624, training loss: 2331.55, average training loss: 2626.89, base loss: 2649.25
[INFO 2017-06-26 19:04:49,598 main.py:47] epoch 625, training loss: 2172.22, average training loss: 2626.16, base loss: 2649.28
[INFO 2017-06-26 19:04:49,912 main.py:47] epoch 626, training loss: 2156.37, average training loss: 2625.41, base loss: 2649.13
[INFO 2017-06-26 19:04:50,226 main.py:47] epoch 627, training loss: 2260.76, average training loss: 2624.83, base loss: 2649.33
[INFO 2017-06-26 19:04:50,540 main.py:47] epoch 628, training loss: 2003.26, average training loss: 2623.84, base loss: 2648.96
[INFO 2017-06-26 19:04:50,856 main.py:47] epoch 629, training loss: 1920.51, average training loss: 2622.73, base loss: 2648.32
[INFO 2017-06-26 19:04:51,173 main.py:47] epoch 630, training loss: 2149.52, average training loss: 2621.98, base loss: 2648.32
[INFO 2017-06-26 19:04:51,483 main.py:47] epoch 631, training loss: 2152.09, average training loss: 2621.23, base loss: 2648.50
[INFO 2017-06-26 19:04:51,800 main.py:47] epoch 632, training loss: 2436.43, average training loss: 2620.94, base loss: 2649.14
[INFO 2017-06-26 19:04:52,114 main.py:47] epoch 633, training loss: 2107.95, average training loss: 2620.13, base loss: 2648.85
[INFO 2017-06-26 19:04:52,431 main.py:47] epoch 634, training loss: 2121.44, average training loss: 2619.35, base loss: 2648.67
[INFO 2017-06-26 19:04:52,745 main.py:47] epoch 635, training loss: 2091.37, average training loss: 2618.52, base loss: 2648.61
[INFO 2017-06-26 19:04:53,062 main.py:47] epoch 636, training loss: 2009.52, average training loss: 2617.56, base loss: 2647.96
[INFO 2017-06-26 19:04:53,378 main.py:47] epoch 637, training loss: 1848.74, average training loss: 2616.35, base loss: 2647.29
[INFO 2017-06-26 19:04:53,699 main.py:47] epoch 638, training loss: 2042.60, average training loss: 2615.46, base loss: 2647.11
[INFO 2017-06-26 19:04:54,010 main.py:47] epoch 639, training loss: 2244.66, average training loss: 2614.88, base loss: 2647.33
[INFO 2017-06-26 19:04:54,325 main.py:47] epoch 640, training loss: 2018.59, average training loss: 2613.95, base loss: 2647.08
[INFO 2017-06-26 19:04:54,643 main.py:47] epoch 641, training loss: 1901.37, average training loss: 2612.84, base loss: 2646.60
[INFO 2017-06-26 19:04:54,960 main.py:47] epoch 642, training loss: 2061.95, average training loss: 2611.98, base loss: 2646.48
[INFO 2017-06-26 19:04:55,275 main.py:47] epoch 643, training loss: 1799.22, average training loss: 2610.72, base loss: 2645.81
[INFO 2017-06-26 19:04:55,593 main.py:47] epoch 644, training loss: 1851.04, average training loss: 2609.54, base loss: 2645.25
[INFO 2017-06-26 19:04:55,904 main.py:47] epoch 645, training loss: 2023.46, average training loss: 2608.63, base loss: 2645.00
[INFO 2017-06-26 19:04:56,218 main.py:47] epoch 646, training loss: 2332.62, average training loss: 2608.21, base loss: 2645.30
[INFO 2017-06-26 19:04:56,536 main.py:47] epoch 647, training loss: 2294.02, average training loss: 2607.72, base loss: 2645.60
[INFO 2017-06-26 19:04:56,853 main.py:47] epoch 648, training loss: 2169.02, average training loss: 2607.05, base loss: 2645.76
[INFO 2017-06-26 19:04:57,167 main.py:47] epoch 649, training loss: 2356.67, average training loss: 2606.66, base loss: 2646.19
[INFO 2017-06-26 19:04:57,483 main.py:47] epoch 650, training loss: 2129.20, average training loss: 2605.93, base loss: 2646.41
[INFO 2017-06-26 19:04:57,793 main.py:47] epoch 651, training loss: 1981.71, average training loss: 2604.97, base loss: 2645.80
[INFO 2017-06-26 19:04:58,108 main.py:47] epoch 652, training loss: 2414.09, average training loss: 2604.68, base loss: 2646.09
[INFO 2017-06-26 19:04:58,425 main.py:47] epoch 653, training loss: 2302.93, average training loss: 2604.22, base loss: 2646.44
[INFO 2017-06-26 19:04:58,740 main.py:47] epoch 654, training loss: 2155.33, average training loss: 2603.53, base loss: 2646.67
[INFO 2017-06-26 19:04:59,058 main.py:47] epoch 655, training loss: 2391.56, average training loss: 2603.21, base loss: 2647.26
[INFO 2017-06-26 19:04:59,374 main.py:47] epoch 656, training loss: 2134.09, average training loss: 2602.49, base loss: 2647.27
[INFO 2017-06-26 19:04:59,692 main.py:47] epoch 657, training loss: 2379.98, average training loss: 2602.16, base loss: 2647.54
[INFO 2017-06-26 19:05:00,006 main.py:47] epoch 658, training loss: 2360.84, average training loss: 2601.79, base loss: 2647.95
[INFO 2017-06-26 19:05:00,320 main.py:47] epoch 659, training loss: 2230.58, average training loss: 2601.23, base loss: 2647.87
[INFO 2017-06-26 19:05:00,637 main.py:47] epoch 660, training loss: 2148.41, average training loss: 2600.54, base loss: 2647.78
[INFO 2017-06-26 19:05:00,955 main.py:47] epoch 661, training loss: 2349.25, average training loss: 2600.16, base loss: 2648.11
[INFO 2017-06-26 19:05:01,275 main.py:47] epoch 662, training loss: 2259.60, average training loss: 2599.65, base loss: 2648.45
[INFO 2017-06-26 19:05:01,592 main.py:47] epoch 663, training loss: 2298.23, average training loss: 2599.19, base loss: 2648.83
[INFO 2017-06-26 19:05:01,906 main.py:47] epoch 664, training loss: 1889.56, average training loss: 2598.13, base loss: 2648.36
[INFO 2017-06-26 19:05:02,223 main.py:47] epoch 665, training loss: 1949.99, average training loss: 2597.15, base loss: 2647.86
[INFO 2017-06-26 19:05:02,540 main.py:47] epoch 666, training loss: 2184.20, average training loss: 2596.53, base loss: 2648.03
[INFO 2017-06-26 19:05:02,854 main.py:47] epoch 667, training loss: 2021.93, average training loss: 2595.67, base loss: 2647.89
[INFO 2017-06-26 19:05:03,169 main.py:47] epoch 668, training loss: 2526.04, average training loss: 2595.57, base loss: 2648.77
[INFO 2017-06-26 19:05:03,486 main.py:47] epoch 669, training loss: 1988.59, average training loss: 2594.66, base loss: 2648.42
[INFO 2017-06-26 19:05:03,802 main.py:47] epoch 670, training loss: 2055.12, average training loss: 2593.86, base loss: 2648.27
[INFO 2017-06-26 19:05:04,119 main.py:47] epoch 671, training loss: 2123.39, average training loss: 2593.16, base loss: 2648.13
[INFO 2017-06-26 19:05:04,437 main.py:47] epoch 672, training loss: 2437.56, average training loss: 2592.93, base loss: 2648.77
[INFO 2017-06-26 19:05:04,750 main.py:47] epoch 673, training loss: 2163.15, average training loss: 2592.29, base loss: 2648.62
[INFO 2017-06-26 19:05:05,064 main.py:47] epoch 674, training loss: 1866.07, average training loss: 2591.22, base loss: 2648.11
[INFO 2017-06-26 19:05:05,384 main.py:47] epoch 675, training loss: 2025.79, average training loss: 2590.38, base loss: 2647.94
[INFO 2017-06-26 19:05:05,702 main.py:47] epoch 676, training loss: 2062.61, average training loss: 2589.60, base loss: 2647.78
[INFO 2017-06-26 19:05:06,018 main.py:47] epoch 677, training loss: 2102.67, average training loss: 2588.88, base loss: 2647.84
[INFO 2017-06-26 19:05:06,336 main.py:47] epoch 678, training loss: 2007.12, average training loss: 2588.02, base loss: 2647.53
[INFO 2017-06-26 19:05:06,650 main.py:47] epoch 679, training loss: 1917.12, average training loss: 2587.04, base loss: 2647.15
[INFO 2017-06-26 19:05:06,966 main.py:47] epoch 680, training loss: 1814.43, average training loss: 2585.90, base loss: 2646.41
[INFO 2017-06-26 19:05:07,283 main.py:47] epoch 681, training loss: 1938.97, average training loss: 2584.95, base loss: 2646.00
[INFO 2017-06-26 19:05:07,600 main.py:47] epoch 682, training loss: 1872.32, average training loss: 2583.91, base loss: 2645.54
[INFO 2017-06-26 19:05:07,915 main.py:47] epoch 683, training loss: 1834.38, average training loss: 2582.82, base loss: 2644.96
[INFO 2017-06-26 19:05:08,232 main.py:47] epoch 684, training loss: 2298.28, average training loss: 2582.40, base loss: 2645.39
[INFO 2017-06-26 19:05:08,549 main.py:47] epoch 685, training loss: 1873.95, average training loss: 2581.37, base loss: 2644.94
[INFO 2017-06-26 19:05:08,866 main.py:47] epoch 686, training loss: 2263.03, average training loss: 2580.90, base loss: 2645.26
[INFO 2017-06-26 19:05:09,183 main.py:47] epoch 687, training loss: 2132.82, average training loss: 2580.25, base loss: 2645.18
[INFO 2017-06-26 19:05:09,502 main.py:47] epoch 688, training loss: 1970.14, average training loss: 2579.37, base loss: 2644.90
[INFO 2017-06-26 19:05:09,820 main.py:47] epoch 689, training loss: 2080.83, average training loss: 2578.64, base loss: 2644.57
[INFO 2017-06-26 19:05:10,136 main.py:47] epoch 690, training loss: 2147.78, average training loss: 2578.02, base loss: 2644.53
[INFO 2017-06-26 19:05:10,454 main.py:47] epoch 691, training loss: 2120.72, average training loss: 2577.36, base loss: 2644.68
[INFO 2017-06-26 19:05:10,766 main.py:47] epoch 692, training loss: 2341.59, average training loss: 2577.02, base loss: 2645.10
[INFO 2017-06-26 19:05:11,079 main.py:47] epoch 693, training loss: 2219.62, average training loss: 2576.51, base loss: 2645.03
[INFO 2017-06-26 19:05:11,393 main.py:47] epoch 694, training loss: 2253.62, average training loss: 2576.04, base loss: 2645.44
[INFO 2017-06-26 19:05:11,710 main.py:47] epoch 695, training loss: 2214.65, average training loss: 2575.52, base loss: 2645.60
[INFO 2017-06-26 19:05:12,023 main.py:47] epoch 696, training loss: 2053.21, average training loss: 2574.77, base loss: 2645.54
[INFO 2017-06-26 19:05:12,336 main.py:47] epoch 697, training loss: 2049.88, average training loss: 2574.02, base loss: 2645.32
[INFO 2017-06-26 19:05:12,653 main.py:47] epoch 698, training loss: 2057.63, average training loss: 2573.28, base loss: 2645.25
[INFO 2017-06-26 19:05:12,994 main.py:47] epoch 699, training loss: 2198.98, average training loss: 2572.75, base loss: 2645.47
[INFO 2017-06-26 19:05:12,994 main.py:49] epoch 699, testing
[INFO 2017-06-26 19:05:17,004 main.py:100] average testing loss: 2125.94, base loss: 2662.57
[INFO 2017-06-26 19:05:17,028 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 19:05:17,041 main.py:73] current best accuracy: 2125.94
[INFO 2017-06-26 19:05:17,356 main.py:47] epoch 700, training loss: 2477.19, average training loss: 2572.61, base loss: 2646.15
[INFO 2017-06-26 19:05:17,672 main.py:47] epoch 701, training loss: 2199.98, average training loss: 2572.08, base loss: 2646.47
[INFO 2017-06-26 19:05:17,983 main.py:47] epoch 702, training loss: 2350.48, average training loss: 2571.76, base loss: 2646.69
[INFO 2017-06-26 19:05:18,300 main.py:47] epoch 703, training loss: 2218.14, average training loss: 2571.26, base loss: 2647.00
[INFO 2017-06-26 19:05:18,618 main.py:47] epoch 704, training loss: 2210.12, average training loss: 2570.75, base loss: 2647.09
[INFO 2017-06-26 19:05:18,931 main.py:47] epoch 705, training loss: 2227.31, average training loss: 2570.26, base loss: 2647.42
[INFO 2017-06-26 19:05:19,248 main.py:47] epoch 706, training loss: 2130.06, average training loss: 2569.64, base loss: 2647.51
[INFO 2017-06-26 19:05:19,563 main.py:47] epoch 707, training loss: 2170.57, average training loss: 2569.08, base loss: 2647.35
[INFO 2017-06-26 19:05:19,880 main.py:47] epoch 708, training loss: 1887.87, average training loss: 2568.12, base loss: 2646.73
[INFO 2017-06-26 19:05:20,195 main.py:47] epoch 709, training loss: 2218.08, average training loss: 2567.62, base loss: 2646.93
[INFO 2017-06-26 19:05:20,514 main.py:47] epoch 710, training loss: 2017.83, average training loss: 2566.85, base loss: 2646.82
[INFO 2017-06-26 19:05:20,826 main.py:47] epoch 711, training loss: 1910.58, average training loss: 2565.93, base loss: 2646.45
[INFO 2017-06-26 19:05:21,142 main.py:47] epoch 712, training loss: 1918.09, average training loss: 2565.02, base loss: 2645.97
[INFO 2017-06-26 19:05:21,458 main.py:47] epoch 713, training loss: 1804.95, average training loss: 2563.96, base loss: 2645.36
[INFO 2017-06-26 19:05:21,776 main.py:47] epoch 714, training loss: 1932.97, average training loss: 2563.07, base loss: 2645.04
[INFO 2017-06-26 19:05:22,092 main.py:47] epoch 715, training loss: 2013.67, average training loss: 2562.31, base loss: 2645.04
[INFO 2017-06-26 19:05:22,406 main.py:47] epoch 716, training loss: 1911.34, average training loss: 2561.40, base loss: 2644.67
[INFO 2017-06-26 19:05:22,722 main.py:47] epoch 717, training loss: 1747.21, average training loss: 2560.26, base loss: 2644.03
[INFO 2017-06-26 19:05:23,036 main.py:47] epoch 718, training loss: 2104.33, average training loss: 2559.63, base loss: 2644.01
[INFO 2017-06-26 19:05:23,353 main.py:47] epoch 719, training loss: 2392.16, average training loss: 2559.40, base loss: 2644.56
[INFO 2017-06-26 19:05:23,667 main.py:47] epoch 720, training loss: 1873.17, average training loss: 2558.45, base loss: 2644.19
[INFO 2017-06-26 19:05:23,982 main.py:47] epoch 721, training loss: 1829.67, average training loss: 2557.44, base loss: 2643.63
[INFO 2017-06-26 19:05:24,297 main.py:47] epoch 722, training loss: 2099.67, average training loss: 2556.80, base loss: 2643.56
[INFO 2017-06-26 19:05:24,616 main.py:47] epoch 723, training loss: 2115.66, average training loss: 2556.19, base loss: 2643.64
[INFO 2017-06-26 19:05:24,933 main.py:47] epoch 724, training loss: 2010.20, average training loss: 2555.44, base loss: 2643.52
[INFO 2017-06-26 19:05:25,250 main.py:47] epoch 725, training loss: 1952.44, average training loss: 2554.61, base loss: 2643.07
[INFO 2017-06-26 19:05:25,566 main.py:47] epoch 726, training loss: 1930.31, average training loss: 2553.75, base loss: 2642.64
[INFO 2017-06-26 19:05:25,879 main.py:47] epoch 727, training loss: 2018.35, average training loss: 2553.02, base loss: 2642.36
[INFO 2017-06-26 19:05:26,195 main.py:47] epoch 728, training loss: 1946.40, average training loss: 2552.18, base loss: 2642.12
[INFO 2017-06-26 19:05:26,510 main.py:47] epoch 729, training loss: 2433.99, average training loss: 2552.02, base loss: 2642.80
[INFO 2017-06-26 19:05:26,827 main.py:47] epoch 730, training loss: 2249.31, average training loss: 2551.61, base loss: 2643.02
[INFO 2017-06-26 19:05:27,143 main.py:47] epoch 731, training loss: 2094.28, average training loss: 2550.98, base loss: 2642.89
[INFO 2017-06-26 19:05:27,461 main.py:47] epoch 732, training loss: 2164.66, average training loss: 2550.46, base loss: 2642.90
[INFO 2017-06-26 19:05:27,771 main.py:47] epoch 733, training loss: 2159.86, average training loss: 2549.92, base loss: 2642.81
[INFO 2017-06-26 19:05:28,086 main.py:47] epoch 734, training loss: 2251.63, average training loss: 2549.52, base loss: 2643.15
[INFO 2017-06-26 19:05:28,401 main.py:47] epoch 735, training loss: 2123.96, average training loss: 2548.94, base loss: 2643.01
[INFO 2017-06-26 19:05:28,719 main.py:47] epoch 736, training loss: 2280.23, average training loss: 2548.57, base loss: 2643.40
[INFO 2017-06-26 19:05:29,033 main.py:47] epoch 737, training loss: 2212.93, average training loss: 2548.12, base loss: 2643.57
[INFO 2017-06-26 19:05:29,349 main.py:47] epoch 738, training loss: 2027.61, average training loss: 2547.42, base loss: 2643.28
[INFO 2017-06-26 19:05:29,665 main.py:47] epoch 739, training loss: 2191.23, average training loss: 2546.93, base loss: 2643.45
[INFO 2017-06-26 19:05:29,980 main.py:47] epoch 740, training loss: 2160.20, average training loss: 2546.41, base loss: 2643.60
[INFO 2017-06-26 19:05:30,301 main.py:47] epoch 741, training loss: 2010.73, average training loss: 2545.69, base loss: 2643.41
[INFO 2017-06-26 19:05:30,619 main.py:47] epoch 742, training loss: 2203.83, average training loss: 2545.23, base loss: 2643.64
[INFO 2017-06-26 19:05:30,941 main.py:47] epoch 743, training loss: 2278.17, average training loss: 2544.87, base loss: 2644.06
[INFO 2017-06-26 19:05:31,255 main.py:47] epoch 744, training loss: 1981.11, average training loss: 2544.11, base loss: 2643.97
[INFO 2017-06-26 19:05:31,570 main.py:47] epoch 745, training loss: 2218.45, average training loss: 2543.68, base loss: 2644.35
[INFO 2017-06-26 19:05:31,886 main.py:47] epoch 746, training loss: 2298.87, average training loss: 2543.35, base loss: 2644.97
[INFO 2017-06-26 19:05:32,203 main.py:47] epoch 747, training loss: 2341.29, average training loss: 2543.08, base loss: 2645.36
[INFO 2017-06-26 19:05:32,522 main.py:47] epoch 748, training loss: 2183.77, average training loss: 2542.60, base loss: 2645.50
[INFO 2017-06-26 19:05:32,838 main.py:47] epoch 749, training loss: 2128.13, average training loss: 2542.05, base loss: 2645.25
[INFO 2017-06-26 19:05:33,151 main.py:47] epoch 750, training loss: 1993.04, average training loss: 2541.32, base loss: 2645.02
[INFO 2017-06-26 19:05:33,464 main.py:47] epoch 751, training loss: 1703.19, average training loss: 2540.20, base loss: 2644.29
[INFO 2017-06-26 19:05:33,782 main.py:47] epoch 752, training loss: 1998.96, average training loss: 2539.48, base loss: 2643.93
[INFO 2017-06-26 19:05:34,099 main.py:47] epoch 753, training loss: 2177.50, average training loss: 2539.00, base loss: 2644.02
[INFO 2017-06-26 19:05:34,416 main.py:47] epoch 754, training loss: 2578.25, average training loss: 2539.06, base loss: 2644.80
[INFO 2017-06-26 19:05:34,735 main.py:47] epoch 755, training loss: 2256.38, average training loss: 2538.68, base loss: 2645.06
[INFO 2017-06-26 19:05:35,050 main.py:47] epoch 756, training loss: 2026.20, average training loss: 2538.00, base loss: 2644.82
[INFO 2017-06-26 19:05:35,365 main.py:47] epoch 757, training loss: 1896.49, average training loss: 2537.16, base loss: 2644.28
[INFO 2017-06-26 19:05:35,683 main.py:47] epoch 758, training loss: 2117.84, average training loss: 2536.61, base loss: 2644.25
[INFO 2017-06-26 19:05:35,996 main.py:47] epoch 759, training loss: 1725.97, average training loss: 2535.54, base loss: 2643.49
[INFO 2017-06-26 19:05:36,313 main.py:47] epoch 760, training loss: 2022.49, average training loss: 2534.86, base loss: 2643.22
[INFO 2017-06-26 19:05:36,630 main.py:47] epoch 761, training loss: 2402.67, average training loss: 2534.69, base loss: 2643.84
[INFO 2017-06-26 19:05:36,946 main.py:47] epoch 762, training loss: 2474.37, average training loss: 2534.61, base loss: 2644.39
[INFO 2017-06-26 19:05:37,261 main.py:47] epoch 763, training loss: 1922.42, average training loss: 2533.81, base loss: 2644.00
[INFO 2017-06-26 19:05:37,580 main.py:47] epoch 764, training loss: 1861.65, average training loss: 2532.93, base loss: 2643.61
[INFO 2017-06-26 19:05:37,896 main.py:47] epoch 765, training loss: 2267.61, average training loss: 2532.59, base loss: 2643.87
[INFO 2017-06-26 19:05:38,211 main.py:47] epoch 766, training loss: 1931.98, average training loss: 2531.80, base loss: 2643.61
[INFO 2017-06-26 19:05:38,524 main.py:47] epoch 767, training loss: 2334.22, average training loss: 2531.55, base loss: 2643.96
[INFO 2017-06-26 19:05:38,841 main.py:47] epoch 768, training loss: 1934.57, average training loss: 2530.77, base loss: 2643.57
[INFO 2017-06-26 19:05:39,157 main.py:47] epoch 769, training loss: 1920.18, average training loss: 2529.98, base loss: 2643.28
[INFO 2017-06-26 19:05:39,470 main.py:47] epoch 770, training loss: 2037.54, average training loss: 2529.34, base loss: 2642.94
[INFO 2017-06-26 19:05:39,784 main.py:47] epoch 771, training loss: 1968.86, average training loss: 2528.61, base loss: 2642.64
[INFO 2017-06-26 19:05:40,098 main.py:47] epoch 772, training loss: 2210.52, average training loss: 2528.20, base loss: 2642.82
[INFO 2017-06-26 19:05:40,415 main.py:47] epoch 773, training loss: 2320.09, average training loss: 2527.93, base loss: 2643.08
[INFO 2017-06-26 19:05:40,733 main.py:47] epoch 774, training loss: 2110.66, average training loss: 2527.39, base loss: 2643.07
[INFO 2017-06-26 19:05:41,046 main.py:47] epoch 775, training loss: 1954.43, average training loss: 2526.65, base loss: 2642.73
[INFO 2017-06-26 19:05:41,361 main.py:47] epoch 776, training loss: 1930.87, average training loss: 2525.89, base loss: 2642.52
[INFO 2017-06-26 19:05:41,679 main.py:47] epoch 777, training loss: 2109.89, average training loss: 2525.35, base loss: 2642.54
[INFO 2017-06-26 19:05:41,992 main.py:47] epoch 778, training loss: 2247.21, average training loss: 2525.00, base loss: 2642.81
[INFO 2017-06-26 19:05:42,306 main.py:47] epoch 779, training loss: 1981.52, average training loss: 2524.30, base loss: 2642.66
[INFO 2017-06-26 19:05:42,620 main.py:47] epoch 780, training loss: 2152.92, average training loss: 2523.82, base loss: 2642.82
[INFO 2017-06-26 19:05:42,937 main.py:47] epoch 781, training loss: 2505.55, average training loss: 2523.80, base loss: 2643.34
[INFO 2017-06-26 19:05:43,255 main.py:47] epoch 782, training loss: 2392.85, average training loss: 2523.63, base loss: 2643.73
[INFO 2017-06-26 19:05:43,568 main.py:47] epoch 783, training loss: 2061.42, average training loss: 2523.04, base loss: 2643.74
[INFO 2017-06-26 19:05:43,882 main.py:47] epoch 784, training loss: 2015.72, average training loss: 2522.40, base loss: 2643.56
[INFO 2017-06-26 19:05:44,199 main.py:47] epoch 785, training loss: 2114.52, average training loss: 2521.88, base loss: 2643.53
[INFO 2017-06-26 19:05:44,516 main.py:47] epoch 786, training loss: 1882.46, average training loss: 2521.07, base loss: 2643.20
[INFO 2017-06-26 19:05:44,826 main.py:47] epoch 787, training loss: 1974.17, average training loss: 2520.37, base loss: 2642.81
[INFO 2017-06-26 19:05:45,145 main.py:47] epoch 788, training loss: 2450.42, average training loss: 2520.28, base loss: 2643.33
[INFO 2017-06-26 19:05:45,463 main.py:47] epoch 789, training loss: 2105.23, average training loss: 2519.76, base loss: 2643.50
[INFO 2017-06-26 19:05:45,780 main.py:47] epoch 790, training loss: 2432.89, average training loss: 2519.65, base loss: 2644.20
[INFO 2017-06-26 19:05:46,096 main.py:47] epoch 791, training loss: 2784.51, average training loss: 2519.98, base loss: 2645.18
[INFO 2017-06-26 19:05:46,411 main.py:47] epoch 792, training loss: 2025.58, average training loss: 2519.36, base loss: 2645.02
[INFO 2017-06-26 19:05:46,728 main.py:47] epoch 793, training loss: 2242.37, average training loss: 2519.01, base loss: 2645.35
[INFO 2017-06-26 19:05:47,042 main.py:47] epoch 794, training loss: 2018.42, average training loss: 2518.38, base loss: 2645.19
[INFO 2017-06-26 19:05:47,356 main.py:47] epoch 795, training loss: 2083.34, average training loss: 2517.83, base loss: 2645.02
[INFO 2017-06-26 19:05:47,672 main.py:47] epoch 796, training loss: 2210.80, average training loss: 2517.45, base loss: 2645.16
[INFO 2017-06-26 19:05:47,989 main.py:47] epoch 797, training loss: 2164.67, average training loss: 2517.01, base loss: 2645.25
[INFO 2017-06-26 19:05:48,302 main.py:47] epoch 798, training loss: 2361.00, average training loss: 2516.81, base loss: 2645.64
[INFO 2017-06-26 19:05:48,617 main.py:47] epoch 799, training loss: 2363.56, average training loss: 2516.62, base loss: 2645.67
[INFO 2017-06-26 19:05:48,617 main.py:49] epoch 799, testing
[INFO 2017-06-26 19:05:52,746 main.py:100] average testing loss: 2106.39, base loss: 2659.49
[INFO 2017-06-26 19:05:52,769 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 19:05:52,782 main.py:73] current best accuracy: 2106.39
[INFO 2017-06-26 19:05:53,100 main.py:47] epoch 800, training loss: 1935.49, average training loss: 2515.89, base loss: 2645.32
[INFO 2017-06-26 19:05:53,417 main.py:47] epoch 801, training loss: 2127.29, average training loss: 2515.41, base loss: 2645.13
[INFO 2017-06-26 19:05:53,730 main.py:47] epoch 802, training loss: 1819.41, average training loss: 2514.54, base loss: 2644.70
[INFO 2017-06-26 19:05:54,044 main.py:47] epoch 803, training loss: 2218.83, average training loss: 2514.18, base loss: 2644.74
[INFO 2017-06-26 19:05:54,361 main.py:47] epoch 804, training loss: 2088.78, average training loss: 2513.65, base loss: 2644.79
[INFO 2017-06-26 19:05:54,678 main.py:47] epoch 805, training loss: 1892.80, average training loss: 2512.88, base loss: 2644.45
[INFO 2017-06-26 19:05:54,994 main.py:47] epoch 806, training loss: 2016.87, average training loss: 2512.26, base loss: 2644.24
[INFO 2017-06-26 19:05:55,310 main.py:47] epoch 807, training loss: 2313.94, average training loss: 2512.02, base loss: 2644.68
[INFO 2017-06-26 19:05:55,630 main.py:47] epoch 808, training loss: 2136.46, average training loss: 2511.55, base loss: 2644.73
[INFO 2017-06-26 19:05:55,949 main.py:47] epoch 809, training loss: 1986.07, average training loss: 2510.90, base loss: 2644.45
[INFO 2017-06-26 19:05:56,264 main.py:47] epoch 810, training loss: 1927.63, average training loss: 2510.18, base loss: 2644.27
[INFO 2017-06-26 19:05:56,582 main.py:47] epoch 811, training loss: 2152.76, average training loss: 2509.74, base loss: 2644.13
[INFO 2017-06-26 19:05:56,895 main.py:47] epoch 812, training loss: 1901.98, average training loss: 2509.00, base loss: 2643.73
[INFO 2017-06-26 19:05:57,212 main.py:47] epoch 813, training loss: 2248.09, average training loss: 2508.68, base loss: 2643.93
[INFO 2017-06-26 19:05:57,530 main.py:47] epoch 814, training loss: 1958.38, average training loss: 2508.00, base loss: 2643.49
[INFO 2017-06-26 19:05:57,847 main.py:47] epoch 815, training loss: 2001.03, average training loss: 2507.38, base loss: 2643.12
[INFO 2017-06-26 19:05:58,163 main.py:47] epoch 816, training loss: 2070.04, average training loss: 2506.84, base loss: 2643.01
[INFO 2017-06-26 19:05:58,478 main.py:47] epoch 817, training loss: 2481.89, average training loss: 2506.81, base loss: 2643.48
[INFO 2017-06-26 19:05:58,792 main.py:47] epoch 818, training loss: 2255.13, average training loss: 2506.51, base loss: 2643.73
[INFO 2017-06-26 19:05:59,103 main.py:47] epoch 819, training loss: 2029.73, average training loss: 2505.92, base loss: 2643.56
[INFO 2017-06-26 19:05:59,416 main.py:47] epoch 820, training loss: 2029.42, average training loss: 2505.34, base loss: 2643.33
[INFO 2017-06-26 19:05:59,729 main.py:47] epoch 821, training loss: 1931.31, average training loss: 2504.65, base loss: 2642.92
[INFO 2017-06-26 19:06:00,047 main.py:47] epoch 822, training loss: 2416.97, average training loss: 2504.54, base loss: 2643.23
[INFO 2017-06-26 19:06:00,364 main.py:47] epoch 823, training loss: 2463.70, average training loss: 2504.49, base loss: 2643.88
[INFO 2017-06-26 19:06:00,681 main.py:47] epoch 824, training loss: 2013.53, average training loss: 2503.89, base loss: 2643.66
[INFO 2017-06-26 19:06:00,997 main.py:47] epoch 825, training loss: 1926.71, average training loss: 2503.20, base loss: 2643.35
[INFO 2017-06-26 19:06:01,310 main.py:47] epoch 826, training loss: 1846.29, average training loss: 2502.40, base loss: 2642.65
[INFO 2017-06-26 19:06:01,623 main.py:47] epoch 827, training loss: 2141.06, average training loss: 2501.97, base loss: 2642.74
[INFO 2017-06-26 19:06:01,940 main.py:47] epoch 828, training loss: 1974.87, average training loss: 2501.33, base loss: 2642.51
[INFO 2017-06-26 19:06:02,253 main.py:47] epoch 829, training loss: 2143.25, average training loss: 2500.90, base loss: 2642.58
[INFO 2017-06-26 19:06:02,566 main.py:47] epoch 830, training loss: 2656.58, average training loss: 2501.09, base loss: 2643.46
[INFO 2017-06-26 19:06:02,882 main.py:47] epoch 831, training loss: 2041.51, average training loss: 2500.53, base loss: 2643.50
[INFO 2017-06-26 19:06:03,197 main.py:47] epoch 832, training loss: 2145.16, average training loss: 2500.11, base loss: 2643.74
[INFO 2017-06-26 19:06:03,514 main.py:47] epoch 833, training loss: 1915.63, average training loss: 2499.41, base loss: 2643.36
[INFO 2017-06-26 19:06:03,828 main.py:47] epoch 834, training loss: 2106.67, average training loss: 2498.94, base loss: 2643.27
[INFO 2017-06-26 19:06:04,145 main.py:47] epoch 835, training loss: 2052.95, average training loss: 2498.40, base loss: 2643.26
[INFO 2017-06-26 19:06:04,461 main.py:47] epoch 836, training loss: 2101.93, average training loss: 2497.93, base loss: 2643.21
[INFO 2017-06-26 19:06:04,774 main.py:47] epoch 837, training loss: 2660.53, average training loss: 2498.12, base loss: 2644.19
[INFO 2017-06-26 19:06:05,091 main.py:47] epoch 838, training loss: 2628.37, average training loss: 2498.28, base loss: 2645.03
[INFO 2017-06-26 19:06:05,404 main.py:47] epoch 839, training loss: 2191.81, average training loss: 2497.91, base loss: 2645.13
[INFO 2017-06-26 19:06:05,720 main.py:47] epoch 840, training loss: 2079.39, average training loss: 2497.41, base loss: 2645.21
[INFO 2017-06-26 19:06:06,036 main.py:47] epoch 841, training loss: 2026.72, average training loss: 2496.86, base loss: 2644.99
[INFO 2017-06-26 19:06:06,352 main.py:47] epoch 842, training loss: 2083.33, average training loss: 2496.37, base loss: 2645.18
[INFO 2017-06-26 19:06:06,669 main.py:47] epoch 843, training loss: 1851.31, average training loss: 2495.60, base loss: 2644.82
[INFO 2017-06-26 19:06:06,986 main.py:47] epoch 844, training loss: 2216.36, average training loss: 2495.27, base loss: 2644.71
[INFO 2017-06-26 19:06:07,303 main.py:47] epoch 845, training loss: 2155.65, average training loss: 2494.87, base loss: 2644.93
[INFO 2017-06-26 19:06:07,628 main.py:47] epoch 846, training loss: 1962.71, average training loss: 2494.24, base loss: 2644.78
[INFO 2017-06-26 19:06:07,945 main.py:47] epoch 847, training loss: 2257.31, average training loss: 2493.96, base loss: 2645.10
[INFO 2017-06-26 19:06:08,260 main.py:47] epoch 848, training loss: 1851.36, average training loss: 2493.20, base loss: 2644.60
[INFO 2017-06-26 19:06:08,577 main.py:47] epoch 849, training loss: 2165.13, average training loss: 2492.82, base loss: 2644.60
[INFO 2017-06-26 19:06:08,886 main.py:47] epoch 850, training loss: 1977.43, average training loss: 2492.21, base loss: 2644.46
[INFO 2017-06-26 19:06:09,200 main.py:47] epoch 851, training loss: 2162.92, average training loss: 2491.83, base loss: 2644.60
[INFO 2017-06-26 19:06:09,518 main.py:47] epoch 852, training loss: 2307.06, average training loss: 2491.61, base loss: 2644.97
[INFO 2017-06-26 19:06:09,833 main.py:47] epoch 853, training loss: 1927.89, average training loss: 2490.95, base loss: 2644.65
[INFO 2017-06-26 19:06:10,150 main.py:47] epoch 854, training loss: 2132.51, average training loss: 2490.53, base loss: 2644.60
[INFO 2017-06-26 19:06:10,467 main.py:47] epoch 855, training loss: 2139.10, average training loss: 2490.12, base loss: 2644.54
[INFO 2017-06-26 19:06:10,781 main.py:47] epoch 856, training loss: 2000.22, average training loss: 2489.55, base loss: 2644.29
[INFO 2017-06-26 19:06:11,093 main.py:47] epoch 857, training loss: 2266.87, average training loss: 2489.29, base loss: 2644.61
[INFO 2017-06-26 19:06:11,407 main.py:47] epoch 858, training loss: 2259.37, average training loss: 2489.02, base loss: 2644.68
[INFO 2017-06-26 19:06:11,727 main.py:47] epoch 859, training loss: 2075.75, average training loss: 2488.54, base loss: 2644.64
[INFO 2017-06-26 19:06:12,044 main.py:47] epoch 860, training loss: 2103.16, average training loss: 2488.09, base loss: 2644.77
[INFO 2017-06-26 19:06:12,362 main.py:47] epoch 861, training loss: 2001.76, average training loss: 2487.53, base loss: 2644.65
[INFO 2017-06-26 19:06:12,681 main.py:47] epoch 862, training loss: 2087.09, average training loss: 2487.06, base loss: 2644.73
[INFO 2017-06-26 19:06:12,997 main.py:47] epoch 863, training loss: 1842.82, average training loss: 2486.32, base loss: 2644.27
[INFO 2017-06-26 19:06:13,311 main.py:47] epoch 864, training loss: 1919.15, average training loss: 2485.66, base loss: 2644.03
[INFO 2017-06-26 19:06:13,629 main.py:47] epoch 865, training loss: 2101.71, average training loss: 2485.22, base loss: 2644.09
[INFO 2017-06-26 19:06:13,944 main.py:47] epoch 866, training loss: 2521.71, average training loss: 2485.26, base loss: 2644.64
[INFO 2017-06-26 19:06:14,257 main.py:47] epoch 867, training loss: 1906.06, average training loss: 2484.59, base loss: 2644.38
[INFO 2017-06-26 19:06:14,571 main.py:47] epoch 868, training loss: 1718.40, average training loss: 2483.71, base loss: 2643.53
[INFO 2017-06-26 19:06:14,887 main.py:47] epoch 869, training loss: 1947.89, average training loss: 2483.10, base loss: 2643.41
[INFO 2017-06-26 19:06:15,200 main.py:47] epoch 870, training loss: 2469.93, average training loss: 2483.08, base loss: 2644.13
[INFO 2017-06-26 19:06:15,516 main.py:47] epoch 871, training loss: 2386.11, average training loss: 2482.97, base loss: 2644.55
[INFO 2017-06-26 19:06:15,834 main.py:47] epoch 872, training loss: 2263.69, average training loss: 2482.72, base loss: 2644.80
[INFO 2017-06-26 19:06:16,151 main.py:47] epoch 873, training loss: 2017.89, average training loss: 2482.19, base loss: 2644.75
[INFO 2017-06-26 19:06:16,470 main.py:47] epoch 874, training loss: 1944.29, average training loss: 2481.57, base loss: 2644.36
[INFO 2017-06-26 19:06:16,787 main.py:47] epoch 875, training loss: 1957.67, average training loss: 2480.98, base loss: 2644.13
[INFO 2017-06-26 19:06:17,101 main.py:47] epoch 876, training loss: 2089.53, average training loss: 2480.53, base loss: 2644.04
[INFO 2017-06-26 19:06:17,415 main.py:47] epoch 877, training loss: 1967.55, average training loss: 2479.94, base loss: 2643.70
[INFO 2017-06-26 19:06:17,734 main.py:47] epoch 878, training loss: 2302.78, average training loss: 2479.74, base loss: 2644.13
[INFO 2017-06-26 19:06:18,055 main.py:47] epoch 879, training loss: 2234.51, average training loss: 2479.46, base loss: 2644.41
[INFO 2017-06-26 19:06:18,372 main.py:47] epoch 880, training loss: 2363.10, average training loss: 2479.33, base loss: 2644.82
[INFO 2017-06-26 19:06:18,686 main.py:47] epoch 881, training loss: 2037.16, average training loss: 2478.83, base loss: 2644.77
[INFO 2017-06-26 19:06:19,004 main.py:47] epoch 882, training loss: 1832.14, average training loss: 2478.10, base loss: 2644.39
[INFO 2017-06-26 19:06:19,319 main.py:47] epoch 883, training loss: 2113.41, average training loss: 2477.69, base loss: 2644.41
[INFO 2017-06-26 19:06:19,638 main.py:47] epoch 884, training loss: 1713.27, average training loss: 2476.82, base loss: 2643.79
[INFO 2017-06-26 19:06:19,955 main.py:47] epoch 885, training loss: 1837.93, average training loss: 2476.10, base loss: 2643.41
[INFO 2017-06-26 19:06:20,272 main.py:47] epoch 886, training loss: 2228.06, average training loss: 2475.82, base loss: 2643.41
[INFO 2017-06-26 19:06:20,583 main.py:47] epoch 887, training loss: 2062.95, average training loss: 2475.36, base loss: 2643.24
[INFO 2017-06-26 19:06:20,901 main.py:47] epoch 888, training loss: 1784.60, average training loss: 2474.58, base loss: 2642.85
[INFO 2017-06-26 19:06:21,218 main.py:47] epoch 889, training loss: 2156.82, average training loss: 2474.22, base loss: 2642.75
[INFO 2017-06-26 19:06:21,533 main.py:47] epoch 890, training loss: 1954.94, average training loss: 2473.64, base loss: 2642.50
[INFO 2017-06-26 19:06:21,848 main.py:47] epoch 891, training loss: 2163.50, average training loss: 2473.29, base loss: 2642.66
[INFO 2017-06-26 19:06:22,165 main.py:47] epoch 892, training loss: 1625.98, average training loss: 2472.34, base loss: 2641.88
[INFO 2017-06-26 19:06:22,484 main.py:47] epoch 893, training loss: 1807.86, average training loss: 2471.60, base loss: 2641.51
[INFO 2017-06-26 19:06:22,801 main.py:47] epoch 894, training loss: 2189.91, average training loss: 2471.29, base loss: 2641.75
[INFO 2017-06-26 19:06:23,116 main.py:47] epoch 895, training loss: 2241.01, average training loss: 2471.03, base loss: 2641.92
[INFO 2017-06-26 19:06:23,434 main.py:47] epoch 896, training loss: 2161.73, average training loss: 2470.68, base loss: 2642.11
[INFO 2017-06-26 19:06:23,751 main.py:47] epoch 897, training loss: 2129.97, average training loss: 2470.30, base loss: 2642.25
[INFO 2017-06-26 19:06:24,068 main.py:47] epoch 898, training loss: 2181.24, average training loss: 2469.98, base loss: 2642.30
[INFO 2017-06-26 19:06:24,382 main.py:47] epoch 899, training loss: 2307.11, average training loss: 2469.80, base loss: 2642.73
[INFO 2017-06-26 19:06:24,382 main.py:49] epoch 899, testing
[INFO 2017-06-26 19:06:28,503 main.py:100] average testing loss: 2163.63, base loss: 2729.49
[INFO 2017-06-26 19:06:28,527 main.py:73] current best accuracy: 2106.39
[INFO 2017-06-26 19:06:28,845 main.py:47] epoch 900, training loss: 2038.46, average training loss: 2469.32, base loss: 2642.74
[INFO 2017-06-26 19:06:29,160 main.py:47] epoch 901, training loss: 2685.69, average training loss: 2469.56, base loss: 2643.40
[INFO 2017-06-26 19:06:29,470 main.py:47] epoch 902, training loss: 2010.86, average training loss: 2469.05, base loss: 2643.19
[INFO 2017-06-26 19:06:29,790 main.py:47] epoch 903, training loss: 2030.63, average training loss: 2468.57, base loss: 2643.25
[INFO 2017-06-26 19:06:30,103 main.py:47] epoch 904, training loss: 2457.24, average training loss: 2468.56, base loss: 2643.84
[INFO 2017-06-26 19:06:30,420 main.py:47] epoch 905, training loss: 2402.26, average training loss: 2468.48, base loss: 2644.27
[INFO 2017-06-26 19:06:30,738 main.py:47] epoch 906, training loss: 2156.69, average training loss: 2468.14, base loss: 2644.49
[INFO 2017-06-26 19:06:31,056 main.py:47] epoch 907, training loss: 2269.37, average training loss: 2467.92, base loss: 2644.75
[INFO 2017-06-26 19:06:31,374 main.py:47] epoch 908, training loss: 2174.29, average training loss: 2467.60, base loss: 2644.84
[INFO 2017-06-26 19:06:31,691 main.py:47] epoch 909, training loss: 1978.13, average training loss: 2467.06, base loss: 2644.68
[INFO 2017-06-26 19:06:32,004 main.py:47] epoch 910, training loss: 2282.06, average training loss: 2466.86, base loss: 2644.88
[INFO 2017-06-26 19:06:32,320 main.py:47] epoch 911, training loss: 2200.76, average training loss: 2466.57, base loss: 2645.07
[INFO 2017-06-26 19:06:32,635 main.py:47] epoch 912, training loss: 1956.35, average training loss: 2466.01, base loss: 2644.94
[INFO 2017-06-26 19:06:32,948 main.py:47] epoch 913, training loss: 2023.71, average training loss: 2465.52, base loss: 2644.82
[INFO 2017-06-26 19:06:33,261 main.py:47] epoch 914, training loss: 2223.29, average training loss: 2465.26, base loss: 2645.09
[INFO 2017-06-26 19:06:33,577 main.py:47] epoch 915, training loss: 2305.34, average training loss: 2465.08, base loss: 2645.51
[INFO 2017-06-26 19:06:33,889 main.py:47] epoch 916, training loss: 2003.99, average training loss: 2464.58, base loss: 2645.40
[INFO 2017-06-26 19:06:34,204 main.py:47] epoch 917, training loss: 2017.76, average training loss: 2464.09, base loss: 2645.32
[INFO 2017-06-26 19:06:34,518 main.py:47] epoch 918, training loss: 1952.97, average training loss: 2463.54, base loss: 2645.03
[INFO 2017-06-26 19:06:34,834 main.py:47] epoch 919, training loss: 2049.72, average training loss: 2463.09, base loss: 2644.97
[INFO 2017-06-26 19:06:35,149 main.py:47] epoch 920, training loss: 2110.16, average training loss: 2462.70, base loss: 2645.06
[INFO 2017-06-26 19:06:35,464 main.py:47] epoch 921, training loss: 2292.60, average training loss: 2462.52, base loss: 2645.26
[INFO 2017-06-26 19:06:35,781 main.py:47] epoch 922, training loss: 2258.67, average training loss: 2462.30, base loss: 2645.64
[INFO 2017-06-26 19:06:36,098 main.py:47] epoch 923, training loss: 2433.12, average training loss: 2462.27, base loss: 2646.01
[INFO 2017-06-26 19:06:36,411 main.py:47] epoch 924, training loss: 2405.68, average training loss: 2462.21, base loss: 2646.38
[INFO 2017-06-26 19:06:36,731 main.py:47] epoch 925, training loss: 2014.64, average training loss: 2461.72, base loss: 2646.28
[INFO 2017-06-26 19:06:37,048 main.py:47] epoch 926, training loss: 2123.52, average training loss: 2461.36, base loss: 2646.11
[INFO 2017-06-26 19:06:37,366 main.py:47] epoch 927, training loss: 2180.49, average training loss: 2461.06, base loss: 2646.12
[INFO 2017-06-26 19:06:37,684 main.py:47] epoch 928, training loss: 2308.45, average training loss: 2460.89, base loss: 2646.52
[INFO 2017-06-26 19:06:38,001 main.py:47] epoch 929, training loss: 2175.41, average training loss: 2460.58, base loss: 2646.76
[INFO 2017-06-26 19:06:38,316 main.py:47] epoch 930, training loss: 2016.20, average training loss: 2460.11, base loss: 2646.54
[INFO 2017-06-26 19:06:38,633 main.py:47] epoch 931, training loss: 2010.14, average training loss: 2459.62, base loss: 2646.34
[INFO 2017-06-26 19:06:38,949 main.py:47] epoch 932, training loss: 1785.49, average training loss: 2458.90, base loss: 2645.88
[INFO 2017-06-26 19:06:39,265 main.py:47] epoch 933, training loss: 2061.44, average training loss: 2458.48, base loss: 2645.74
[INFO 2017-06-26 19:06:39,580 main.py:47] epoch 934, training loss: 2377.79, average training loss: 2458.39, base loss: 2646.04
[INFO 2017-06-26 19:06:39,890 main.py:47] epoch 935, training loss: 2083.07, average training loss: 2457.99, base loss: 2646.08
[INFO 2017-06-26 19:06:40,204 main.py:47] epoch 936, training loss: 2142.17, average training loss: 2457.65, base loss: 2646.06
[INFO 2017-06-26 19:06:40,521 main.py:47] epoch 937, training loss: 2008.19, average training loss: 2457.17, base loss: 2645.72
[INFO 2017-06-26 19:06:40,836 main.py:47] epoch 938, training loss: 1856.82, average training loss: 2456.53, base loss: 2645.46
[INFO 2017-06-26 19:06:41,150 main.py:47] epoch 939, training loss: 2336.49, average training loss: 2456.41, base loss: 2645.74
[INFO 2017-06-26 19:06:41,466 main.py:47] epoch 940, training loss: 1944.31, average training loss: 2455.86, base loss: 2645.52
[INFO 2017-06-26 19:06:41,785 main.py:47] epoch 941, training loss: 2253.15, average training loss: 2455.65, base loss: 2645.59
[INFO 2017-06-26 19:06:42,102 main.py:47] epoch 942, training loss: 2377.81, average training loss: 2455.56, base loss: 2645.98
[INFO 2017-06-26 19:06:42,412 main.py:47] epoch 943, training loss: 2033.95, average training loss: 2455.12, base loss: 2645.77
[INFO 2017-06-26 19:06:42,728 main.py:47] epoch 944, training loss: 2060.50, average training loss: 2454.70, base loss: 2645.80
[INFO 2017-06-26 19:06:43,043 main.py:47] epoch 945, training loss: 2061.66, average training loss: 2454.28, base loss: 2645.90
[INFO 2017-06-26 19:06:43,357 main.py:47] epoch 946, training loss: 1888.98, average training loss: 2453.69, base loss: 2645.57
[INFO 2017-06-26 19:06:43,674 main.py:47] epoch 947, training loss: 2056.56, average training loss: 2453.27, base loss: 2645.62
[INFO 2017-06-26 19:06:43,990 main.py:47] epoch 948, training loss: 1790.22, average training loss: 2452.57, base loss: 2645.06
[INFO 2017-06-26 19:06:44,305 main.py:47] epoch 949, training loss: 2025.25, average training loss: 2452.12, base loss: 2644.82
[INFO 2017-06-26 19:06:44,620 main.py:47] epoch 950, training loss: 2363.91, average training loss: 2452.03, base loss: 2645.32
[INFO 2017-06-26 19:06:44,936 main.py:47] epoch 951, training loss: 1935.07, average training loss: 2451.48, base loss: 2645.12
[INFO 2017-06-26 19:06:45,249 main.py:47] epoch 952, training loss: 2360.06, average training loss: 2451.39, base loss: 2645.56
[INFO 2017-06-26 19:06:45,563 main.py:47] epoch 953, training loss: 2201.87, average training loss: 2451.13, base loss: 2645.67
[INFO 2017-06-26 19:06:45,877 main.py:47] epoch 954, training loss: 2176.08, average training loss: 2450.84, base loss: 2645.69
[INFO 2017-06-26 19:06:46,191 main.py:47] epoch 955, training loss: 2161.16, average training loss: 2450.54, base loss: 2645.94
[INFO 2017-06-26 19:06:46,508 main.py:47] epoch 956, training loss: 2002.38, average training loss: 2450.07, base loss: 2645.58
[INFO 2017-06-26 19:06:46,823 main.py:47] epoch 957, training loss: 2016.49, average training loss: 2449.61, base loss: 2645.26
[INFO 2017-06-26 19:06:47,137 main.py:47] epoch 958, training loss: 1997.09, average training loss: 2449.14, base loss: 2645.04
[INFO 2017-06-26 19:06:47,452 main.py:47] epoch 959, training loss: 2081.79, average training loss: 2448.76, base loss: 2645.04
[INFO 2017-06-26 19:06:47,768 main.py:47] epoch 960, training loss: 2269.34, average training loss: 2448.57, base loss: 2645.33
[INFO 2017-06-26 19:06:48,080 main.py:47] epoch 961, training loss: 2224.91, average training loss: 2448.34, base loss: 2645.48
[INFO 2017-06-26 19:06:48,394 main.py:47] epoch 962, training loss: 1955.29, average training loss: 2447.83, base loss: 2645.26
[INFO 2017-06-26 19:06:48,712 main.py:47] epoch 963, training loss: 2116.90, average training loss: 2447.49, base loss: 2645.35
[INFO 2017-06-26 19:06:49,029 main.py:47] epoch 964, training loss: 2036.77, average training loss: 2447.06, base loss: 2645.51
[INFO 2017-06-26 19:06:49,345 main.py:47] epoch 965, training loss: 2008.57, average training loss: 2446.61, base loss: 2645.48
[INFO 2017-06-26 19:06:49,659 main.py:47] epoch 966, training loss: 2037.18, average training loss: 2446.18, base loss: 2645.40
[INFO 2017-06-26 19:06:49,976 main.py:47] epoch 967, training loss: 2590.73, average training loss: 2446.33, base loss: 2646.12
[INFO 2017-06-26 19:06:50,293 main.py:47] epoch 968, training loss: 1767.44, average training loss: 2445.63, base loss: 2645.73
[INFO 2017-06-26 19:06:50,610 main.py:47] epoch 969, training loss: 1954.60, average training loss: 2445.13, base loss: 2645.58
[INFO 2017-06-26 19:06:50,928 main.py:47] epoch 970, training loss: 2250.18, average training loss: 2444.92, base loss: 2645.74
[INFO 2017-06-26 19:06:51,245 main.py:47] epoch 971, training loss: 2170.61, average training loss: 2444.64, base loss: 2645.67
[INFO 2017-06-26 19:06:51,563 main.py:47] epoch 972, training loss: 2041.92, average training loss: 2444.23, base loss: 2645.55
[INFO 2017-06-26 19:06:51,878 main.py:47] epoch 973, training loss: 1949.98, average training loss: 2443.72, base loss: 2645.33
[INFO 2017-06-26 19:06:52,194 main.py:47] epoch 974, training loss: 2330.75, average training loss: 2443.61, base loss: 2645.87
[INFO 2017-06-26 19:06:52,510 main.py:47] epoch 975, training loss: 1949.24, average training loss: 2443.10, base loss: 2645.69
[INFO 2017-06-26 19:06:52,829 main.py:47] epoch 976, training loss: 2023.98, average training loss: 2442.67, base loss: 2645.75
[INFO 2017-06-26 19:06:53,145 main.py:47] epoch 977, training loss: 2154.79, average training loss: 2442.38, base loss: 2645.71
[INFO 2017-06-26 19:06:53,462 main.py:47] epoch 978, training loss: 2096.63, average training loss: 2442.02, base loss: 2645.81
[INFO 2017-06-26 19:06:53,780 main.py:47] epoch 979, training loss: 1901.46, average training loss: 2441.47, base loss: 2645.43
[INFO 2017-06-26 19:06:54,097 main.py:47] epoch 980, training loss: 1985.94, average training loss: 2441.01, base loss: 2645.16
[INFO 2017-06-26 19:06:54,414 main.py:47] epoch 981, training loss: 2209.54, average training loss: 2440.77, base loss: 2645.31
[INFO 2017-06-26 19:06:54,730 main.py:47] epoch 982, training loss: 1965.28, average training loss: 2440.29, base loss: 2645.12
[INFO 2017-06-26 19:06:55,044 main.py:47] epoch 983, training loss: 2053.10, average training loss: 2439.89, base loss: 2645.06
[INFO 2017-06-26 19:06:55,361 main.py:47] epoch 984, training loss: 2257.97, average training loss: 2439.71, base loss: 2645.21
[INFO 2017-06-26 19:06:55,679 main.py:47] epoch 985, training loss: 2089.40, average training loss: 2439.35, base loss: 2645.23
[INFO 2017-06-26 19:06:55,997 main.py:47] epoch 986, training loss: 2206.01, average training loss: 2439.12, base loss: 2645.47
[INFO 2017-06-26 19:06:56,314 main.py:47] epoch 987, training loss: 2230.70, average training loss: 2438.91, base loss: 2645.60
[INFO 2017-06-26 19:06:56,632 main.py:47] epoch 988, training loss: 2064.55, average training loss: 2438.53, base loss: 2645.59
[INFO 2017-06-26 19:06:56,949 main.py:47] epoch 989, training loss: 2087.37, average training loss: 2438.17, base loss: 2645.61
[INFO 2017-06-26 19:06:57,263 main.py:47] epoch 990, training loss: 2001.00, average training loss: 2437.73, base loss: 2645.54
[INFO 2017-06-26 19:06:57,577 main.py:47] epoch 991, training loss: 1961.25, average training loss: 2437.25, base loss: 2645.44
[INFO 2017-06-26 19:06:57,895 main.py:47] epoch 992, training loss: 1985.54, average training loss: 2436.80, base loss: 2645.27
[INFO 2017-06-26 19:06:58,212 main.py:47] epoch 993, training loss: 2201.05, average training loss: 2436.56, base loss: 2645.42
[INFO 2017-06-26 19:06:58,528 main.py:47] epoch 994, training loss: 2135.07, average training loss: 2436.26, base loss: 2645.51
[INFO 2017-06-26 19:06:58,844 main.py:47] epoch 995, training loss: 2052.66, average training loss: 2435.87, base loss: 2645.40
[INFO 2017-06-26 19:06:59,157 main.py:47] epoch 996, training loss: 2054.85, average training loss: 2435.49, base loss: 2645.26
[INFO 2017-06-26 19:06:59,475 main.py:47] epoch 997, training loss: 2087.40, average training loss: 2435.14, base loss: 2645.32
[INFO 2017-06-26 19:06:59,787 main.py:47] epoch 998, training loss: 2003.07, average training loss: 2434.71, base loss: 2645.18
[INFO 2017-06-26 19:07:00,106 main.py:47] epoch 999, training loss: 2061.06, average training loss: 2434.33, base loss: 2645.04
[INFO 2017-06-26 19:07:00,106 main.py:49] epoch 999, testing
[INFO 2017-06-26 19:07:04,098 main.py:100] average testing loss: 2057.65, base loss: 2557.99
[INFO 2017-06-26 19:07:04,122 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 19:07:04,136 main.py:73] current best accuracy: 2057.65
[INFO 2017-06-26 19:07:04,450 main.py:47] epoch 1000, training loss: 1905.91, average training loss: 2401.60, base loss: 2644.55
[INFO 2017-06-26 19:07:04,767 main.py:47] epoch 1001, training loss: 2292.58, average training loss: 2377.10, base loss: 2644.78
[INFO 2017-06-26 19:07:05,083 main.py:47] epoch 1002, training loss: 1921.39, average training loss: 2356.19, base loss: 2644.36
[INFO 2017-06-26 19:07:05,400 main.py:47] epoch 1003, training loss: 1797.75, average training loss: 2338.32, base loss: 2644.05
[INFO 2017-06-26 19:07:05,715 main.py:47] epoch 1004, training loss: 2189.53, average training loss: 2322.53, base loss: 2643.66
[INFO 2017-06-26 19:07:06,031 main.py:47] epoch 1005, training loss: 1959.81, average training loss: 2308.42, base loss: 2643.67
[INFO 2017-06-26 19:07:06,348 main.py:47] epoch 1006, training loss: 1969.08, average training loss: 2295.98, base loss: 2643.17
[INFO 2017-06-26 19:07:06,666 main.py:47] epoch 1007, training loss: 1758.25, average training loss: 2285.64, base loss: 2642.75
[INFO 2017-06-26 19:07:06,981 main.py:47] epoch 1008, training loss: 2026.81, average training loss: 2277.28, base loss: 2642.64
[INFO 2017-06-26 19:07:07,299 main.py:47] epoch 1009, training loss: 2004.80, average training loss: 2270.21, base loss: 2642.60
[INFO 2017-06-26 19:07:07,614 main.py:47] epoch 1010, training loss: 1660.42, average training loss: 2263.65, base loss: 2642.15
[INFO 2017-06-26 19:07:07,931 main.py:47] epoch 1011, training loss: 1681.10, average training loss: 2258.38, base loss: 2642.03
[INFO 2017-06-26 19:07:08,251 main.py:47] epoch 1012, training loss: 1713.68, average training loss: 2253.42, base loss: 2641.40
[INFO 2017-06-26 19:07:08,565 main.py:47] epoch 1013, training loss: 2181.77, average training loss: 2249.58, base loss: 2641.09
[INFO 2017-06-26 19:07:08,881 main.py:47] epoch 1014, training loss: 1830.41, average training loss: 2245.99, base loss: 2640.53
[INFO 2017-06-26 19:07:09,196 main.py:47] epoch 1015, training loss: 2277.55, average training loss: 2243.72, base loss: 2640.97
[INFO 2017-06-26 19:07:09,510 main.py:47] epoch 1016, training loss: 2074.61, average training loss: 2241.23, base loss: 2640.86
[INFO 2017-06-26 19:07:09,820 main.py:47] epoch 1017, training loss: 2038.90, average training loss: 2239.17, base loss: 2640.80
[INFO 2017-06-26 19:07:10,132 main.py:47] epoch 1018, training loss: 1906.40, average training loss: 2236.90, base loss: 2640.14
[INFO 2017-06-26 19:07:10,445 main.py:47] epoch 1019, training loss: 2440.39, average training loss: 2235.83, base loss: 2640.70
[INFO 2017-06-26 19:07:10,759 main.py:47] epoch 1020, training loss: 1789.22, average training loss: 2234.45, base loss: 2640.57
[INFO 2017-06-26 19:07:11,074 main.py:47] epoch 1021, training loss: 1966.09, average training loss: 2232.57, base loss: 2639.75
[INFO 2017-06-26 19:07:11,390 main.py:47] epoch 1022, training loss: 2706.94, average training loss: 2232.23, base loss: 2640.74
[INFO 2017-06-26 19:07:11,710 main.py:47] epoch 1023, training loss: 1937.56, average training loss: 2231.20, base loss: 2640.75
[INFO 2017-06-26 19:07:12,027 main.py:47] epoch 1024, training loss: 2283.53, average training loss: 2230.53, base loss: 2640.97
[INFO 2017-06-26 19:07:12,344 main.py:47] epoch 1025, training loss: 1968.03, average training loss: 2229.57, base loss: 2640.75
[INFO 2017-06-26 19:07:12,661 main.py:47] epoch 1026, training loss: 2010.99, average training loss: 2229.09, base loss: 2640.99
[INFO 2017-06-26 19:07:12,974 main.py:47] epoch 1027, training loss: 2269.84, average training loss: 2228.35, base loss: 2641.10
[INFO 2017-06-26 19:07:13,288 main.py:47] epoch 1028, training loss: 2213.66, average training loss: 2227.90, base loss: 2641.38
[INFO 2017-06-26 19:07:13,606 main.py:47] epoch 1029, training loss: 2188.10, average training loss: 2226.92, base loss: 2641.00
[INFO 2017-06-26 19:07:13,924 main.py:47] epoch 1030, training loss: 2043.48, average training loss: 2225.70, base loss: 2640.37
[INFO 2017-06-26 19:07:14,237 main.py:47] epoch 1031, training loss: 2091.96, average training loss: 2224.74, base loss: 2639.93
[INFO 2017-06-26 19:07:14,550 main.py:47] epoch 1032, training loss: 2440.64, average training loss: 2224.50, base loss: 2640.34
[INFO 2017-06-26 19:07:14,866 main.py:47] epoch 1033, training loss: 2104.13, average training loss: 2224.20, base loss: 2640.62
[INFO 2017-06-26 19:07:15,180 main.py:47] epoch 1034, training loss: 2329.29, average training loss: 2223.53, base loss: 2640.58
[INFO 2017-06-26 19:07:15,497 main.py:47] epoch 1035, training loss: 2185.47, average training loss: 2223.47, base loss: 2641.17
[INFO 2017-06-26 19:07:15,815 main.py:47] epoch 1036, training loss: 2606.95, average training loss: 2223.38, base loss: 2641.84
[INFO 2017-06-26 19:07:16,129 main.py:47] epoch 1037, training loss: 1999.88, average training loss: 2223.11, base loss: 2642.24
[INFO 2017-06-26 19:07:16,445 main.py:47] epoch 1038, training loss: 2195.12, average training loss: 2222.73, base loss: 2642.59
[INFO 2017-06-26 19:07:16,762 main.py:47] epoch 1039, training loss: 2226.69, average training loss: 2222.13, base loss: 2642.67
[INFO 2017-06-26 19:07:17,079 main.py:47] epoch 1040, training loss: 2025.25, average training loss: 2221.28, base loss: 2642.21
[INFO 2017-06-26 19:07:17,396 main.py:47] epoch 1041, training loss: 2723.92, average training loss: 2221.86, base loss: 2643.50
[INFO 2017-06-26 19:07:17,713 main.py:47] epoch 1042, training loss: 2401.06, average training loss: 2221.82, base loss: 2644.03
[INFO 2017-06-26 19:07:18,029 main.py:47] epoch 1043, training loss: 2464.06, average training loss: 2222.04, base loss: 2644.91
[INFO 2017-06-26 19:07:18,343 main.py:47] epoch 1044, training loss: 2105.49, average training loss: 2221.39, base loss: 2644.81
[INFO 2017-06-26 19:07:18,661 main.py:47] epoch 1045, training loss: 1943.02, average training loss: 2220.74, base loss: 2644.69
[INFO 2017-06-26 19:07:18,977 main.py:47] epoch 1046, training loss: 1973.42, average training loss: 2219.67, base loss: 2644.09
[INFO 2017-06-26 19:07:19,294 main.py:47] epoch 1047, training loss: 2254.94, average training loss: 2219.50, base loss: 2644.40
[INFO 2017-06-26 19:07:19,612 main.py:47] epoch 1048, training loss: 1899.78, average training loss: 2218.47, base loss: 2643.71
[INFO 2017-06-26 19:07:19,926 main.py:47] epoch 1049, training loss: 2122.84, average training loss: 2217.64, base loss: 2643.39
[INFO 2017-06-26 19:07:20,238 main.py:47] epoch 1050, training loss: 1983.74, average training loss: 2216.66, base loss: 2642.69
[INFO 2017-06-26 19:07:20,552 main.py:47] epoch 1051, training loss: 2414.27, average training loss: 2216.26, base loss: 2642.73
[INFO 2017-06-26 19:07:20,867 main.py:47] epoch 1052, training loss: 2129.47, average training loss: 2215.84, base loss: 2642.97
[INFO 2017-06-26 19:07:21,185 main.py:47] epoch 1053, training loss: 1940.64, average training loss: 2215.38, base loss: 2642.94
[INFO 2017-06-26 19:07:21,498 main.py:47] epoch 1054, training loss: 1919.29, average training loss: 2214.54, base loss: 2642.61
[INFO 2017-06-26 19:07:21,812 main.py:47] epoch 1055, training loss: 1872.28, average training loss: 2213.84, base loss: 2642.31
[INFO 2017-06-26 19:07:22,127 main.py:47] epoch 1056, training loss: 2035.87, average training loss: 2213.43, base loss: 2642.45
[INFO 2017-06-26 19:07:22,445 main.py:47] epoch 1057, training loss: 2121.22, average training loss: 2212.86, base loss: 2642.41
[INFO 2017-06-26 19:07:22,762 main.py:47] epoch 1058, training loss: 1864.65, average training loss: 2212.05, base loss: 2641.91
[INFO 2017-06-26 19:07:23,078 main.py:47] epoch 1059, training loss: 2124.52, average training loss: 2211.60, base loss: 2641.97
[INFO 2017-06-26 19:07:23,395 main.py:47] epoch 1060, training loss: 2251.50, average training loss: 2211.28, base loss: 2642.27
[INFO 2017-06-26 19:07:23,713 main.py:47] epoch 1061, training loss: 2281.41, average training loss: 2210.95, base loss: 2642.64
[INFO 2017-06-26 19:07:24,029 main.py:47] epoch 1062, training loss: 1985.24, average training loss: 2210.88, base loss: 2642.97
[INFO 2017-06-26 19:07:24,346 main.py:47] epoch 1063, training loss: 2274.18, average training loss: 2210.71, base loss: 2643.43
[INFO 2017-06-26 19:07:24,663 main.py:47] epoch 1064, training loss: 2211.52, average training loss: 2210.52, base loss: 2643.62
[INFO 2017-06-26 19:07:24,979 main.py:47] epoch 1065, training loss: 2162.62, average training loss: 2210.38, base loss: 2644.00
[INFO 2017-06-26 19:07:25,295 main.py:47] epoch 1066, training loss: 2119.82, average training loss: 2209.69, base loss: 2643.74
[INFO 2017-06-26 19:07:25,611 main.py:47] epoch 1067, training loss: 2146.85, average training loss: 2209.10, base loss: 2643.71
[INFO 2017-06-26 19:07:25,929 main.py:47] epoch 1068, training loss: 2321.88, average training loss: 2208.42, base loss: 2643.51
[INFO 2017-06-26 19:07:26,245 main.py:47] epoch 1069, training loss: 2663.58, average training loss: 2208.46, base loss: 2644.10
[INFO 2017-06-26 19:07:26,561 main.py:47] epoch 1070, training loss: 2226.63, average training loss: 2208.20, base loss: 2644.52
[INFO 2017-06-26 19:07:26,877 main.py:47] epoch 1071, training loss: 2078.24, average training loss: 2207.74, base loss: 2644.29
[INFO 2017-06-26 19:07:27,190 main.py:47] epoch 1072, training loss: 1848.86, average training loss: 2207.57, base loss: 2644.65
[INFO 2017-06-26 19:07:27,504 main.py:47] epoch 1073, training loss: 1772.12, average training loss: 2206.57, base loss: 2643.98
[INFO 2017-06-26 19:07:27,820 main.py:47] epoch 1074, training loss: 1812.96, average training loss: 2205.96, base loss: 2643.69
[INFO 2017-06-26 19:07:28,135 main.py:47] epoch 1075, training loss: 1724.85, average training loss: 2205.29, base loss: 2643.34
[INFO 2017-06-26 19:07:28,448 main.py:47] epoch 1076, training loss: 2536.06, average training loss: 2205.10, base loss: 2643.63
[INFO 2017-06-26 19:07:28,766 main.py:47] epoch 1077, training loss: 2095.07, average training loss: 2204.30, base loss: 2643.11
[INFO 2017-06-26 19:07:29,083 main.py:47] epoch 1078, training loss: 2391.41, average training loss: 2204.21, base loss: 2643.55
[INFO 2017-06-26 19:07:29,400 main.py:47] epoch 1079, training loss: 2225.56, average training loss: 2203.57, base loss: 2643.37
[INFO 2017-06-26 19:07:29,717 main.py:47] epoch 1080, training loss: 2499.62, average training loss: 2203.69, base loss: 2644.07
[INFO 2017-06-26 19:07:30,034 main.py:47] epoch 1081, training loss: 2009.05, average training loss: 2202.87, base loss: 2643.67
[INFO 2017-06-26 19:07:30,349 main.py:47] epoch 1082, training loss: 1798.28, average training loss: 2202.03, base loss: 2643.02
[INFO 2017-06-26 19:07:30,667 main.py:47] epoch 1083, training loss: 2250.10, average training loss: 2201.40, base loss: 2642.93
[INFO 2017-06-26 19:07:30,982 main.py:47] epoch 1084, training loss: 2266.27, average training loss: 2200.79, base loss: 2642.85
[INFO 2017-06-26 19:07:31,296 main.py:47] epoch 1085, training loss: 2232.23, average training loss: 2200.23, base loss: 2642.71
[INFO 2017-06-26 19:07:31,613 main.py:47] epoch 1086, training loss: 1969.57, average training loss: 2199.47, base loss: 2642.33
[INFO 2017-06-26 19:07:31,929 main.py:47] epoch 1087, training loss: 1807.60, average training loss: 2198.77, base loss: 2641.83
[INFO 2017-06-26 19:07:32,245 main.py:47] epoch 1088, training loss: 1832.48, average training loss: 2198.54, base loss: 2641.97
[INFO 2017-06-26 19:07:32,561 main.py:47] epoch 1089, training loss: 2053.61, average training loss: 2197.79, base loss: 2641.55
[INFO 2017-06-26 19:07:32,878 main.py:47] epoch 1090, training loss: 1778.76, average training loss: 2196.91, base loss: 2640.98
[INFO 2017-06-26 19:07:33,192 main.py:47] epoch 1091, training loss: 2469.69, average training loss: 2196.70, base loss: 2641.26
[INFO 2017-06-26 19:07:33,508 main.py:47] epoch 1092, training loss: 2261.51, average training loss: 2196.47, base loss: 2641.32
[INFO 2017-06-26 19:07:33,824 main.py:47] epoch 1093, training loss: 1759.68, average training loss: 2195.72, base loss: 2640.90
[INFO 2017-06-26 19:07:34,141 main.py:47] epoch 1094, training loss: 1958.76, average training loss: 2195.25, base loss: 2640.83
[INFO 2017-06-26 19:07:34,456 main.py:47] epoch 1095, training loss: 2299.58, average training loss: 2194.44, base loss: 2640.47
[INFO 2017-06-26 19:07:34,766 main.py:47] epoch 1096, training loss: 2422.54, average training loss: 2194.24, base loss: 2640.73
[INFO 2017-06-26 19:07:35,081 main.py:47] epoch 1097, training loss: 2284.86, average training loss: 2194.19, base loss: 2641.19
[INFO 2017-06-26 19:07:35,398 main.py:47] epoch 1098, training loss: 1871.01, average training loss: 2193.34, base loss: 2640.62
[INFO 2017-06-26 19:07:35,712 main.py:47] epoch 1099, training loss: 1923.52, average training loss: 2192.83, base loss: 2640.27
[INFO 2017-06-26 19:07:35,712 main.py:49] epoch 1099, testing
[INFO 2017-06-26 19:07:39,822 main.py:100] average testing loss: 2074.68, base loss: 2681.73
[INFO 2017-06-26 19:07:39,844 main.py:73] current best accuracy: 2057.65
[INFO 2017-06-26 19:07:40,162 main.py:47] epoch 1100, training loss: 2068.88, average training loss: 2192.36, base loss: 2640.29
[INFO 2017-06-26 19:07:40,478 main.py:47] epoch 1101, training loss: 2214.66, average training loss: 2192.12, base loss: 2640.53
[INFO 2017-06-26 19:07:40,793 main.py:47] epoch 1102, training loss: 2090.18, average training loss: 2191.97, base loss: 2640.88
[INFO 2017-06-26 19:07:41,113 main.py:47] epoch 1103, training loss: 2228.82, average training loss: 2191.78, base loss: 2641.29
[INFO 2017-06-26 19:07:41,431 main.py:47] epoch 1104, training loss: 1938.02, average training loss: 2190.91, base loss: 2640.69
[INFO 2017-06-26 19:07:41,747 main.py:47] epoch 1105, training loss: 1793.32, average training loss: 2190.16, base loss: 2640.23
[INFO 2017-06-26 19:07:42,063 main.py:47] epoch 1106, training loss: 2058.74, average training loss: 2189.67, base loss: 2640.23
[INFO 2017-06-26 19:07:42,376 main.py:47] epoch 1107, training loss: 2007.41, average training loss: 2189.40, base loss: 2640.38
[INFO 2017-06-26 19:07:42,694 main.py:47] epoch 1108, training loss: 2062.31, average training loss: 2188.77, base loss: 2640.18
[INFO 2017-06-26 19:07:43,010 main.py:47] epoch 1109, training loss: 2148.51, average training loss: 2188.71, base loss: 2640.45
[INFO 2017-06-26 19:07:43,328 main.py:47] epoch 1110, training loss: 2282.31, average training loss: 2188.52, base loss: 2640.63
[INFO 2017-06-26 19:07:43,645 main.py:47] epoch 1111, training loss: 1788.46, average training loss: 2187.81, base loss: 2640.12
[INFO 2017-06-26 19:07:43,961 main.py:47] epoch 1112, training loss: 2407.95, average training loss: 2187.40, base loss: 2640.16
[INFO 2017-06-26 19:07:44,276 main.py:47] epoch 1113, training loss: 2371.70, average training loss: 2187.42, base loss: 2640.69
[INFO 2017-06-26 19:07:44,593 main.py:47] epoch 1114, training loss: 2057.26, average training loss: 2186.88, base loss: 2640.64
[INFO 2017-06-26 19:07:44,909 main.py:47] epoch 1115, training loss: 2086.50, average training loss: 2186.48, base loss: 2640.69
[INFO 2017-06-26 19:07:45,226 main.py:47] epoch 1116, training loss: 1813.54, average training loss: 2185.60, base loss: 2640.06
[INFO 2017-06-26 19:07:45,538 main.py:47] epoch 1117, training loss: 1998.89, average training loss: 2185.06, base loss: 2640.07
[INFO 2017-06-26 19:07:45,852 main.py:47] epoch 1118, training loss: 2121.14, average training loss: 2185.22, base loss: 2640.61
[INFO 2017-06-26 19:07:46,167 main.py:47] epoch 1119, training loss: 2215.49, average training loss: 2185.04, base loss: 2640.84
[INFO 2017-06-26 19:07:46,479 main.py:47] epoch 1120, training loss: 2093.38, average training loss: 2184.87, base loss: 2640.91
[INFO 2017-06-26 19:07:46,793 main.py:47] epoch 1121, training loss: 1810.02, average training loss: 2184.41, base loss: 2640.74
[INFO 2017-06-26 19:07:47,111 main.py:47] epoch 1122, training loss: 1841.40, average training loss: 2183.56, base loss: 2640.11
[INFO 2017-06-26 19:07:47,449 main.py:47] epoch 1123, training loss: 2358.12, average training loss: 2183.52, base loss: 2640.57
[INFO 2017-06-26 19:07:47,769 main.py:47] epoch 1124, training loss: 1986.28, average training loss: 2183.48, base loss: 2640.99
[INFO 2017-06-26 19:07:48,089 main.py:47] epoch 1125, training loss: 2047.47, average training loss: 2183.38, base loss: 2641.38
[INFO 2017-06-26 19:07:48,407 main.py:47] epoch 1126, training loss: 2221.55, average training loss: 2182.87, base loss: 2641.20
[INFO 2017-06-26 19:07:48,725 main.py:47] epoch 1127, training loss: 1680.61, average training loss: 2181.95, base loss: 2640.45
[INFO 2017-06-26 19:07:49,039 main.py:47] epoch 1128, training loss: 1917.70, average training loss: 2181.45, base loss: 2640.29
[INFO 2017-06-26 19:07:49,352 main.py:47] epoch 1129, training loss: 2087.28, average training loss: 2180.71, base loss: 2639.73
[INFO 2017-06-26 19:07:49,668 main.py:47] epoch 1130, training loss: 2117.26, average training loss: 2180.63, base loss: 2640.02
[INFO 2017-06-26 19:07:49,986 main.py:47] epoch 1131, training loss: 2238.92, average training loss: 2180.40, base loss: 2640.27
[INFO 2017-06-26 19:07:50,302 main.py:47] epoch 1132, training loss: 2026.27, average training loss: 2179.93, base loss: 2640.08
[INFO 2017-06-26 19:07:50,617 main.py:47] epoch 1133, training loss: 2239.79, average training loss: 2179.30, base loss: 2639.85
[INFO 2017-06-26 19:07:50,930 main.py:47] epoch 1134, training loss: 1931.46, average training loss: 2179.10, base loss: 2640.17
[INFO 2017-06-26 19:07:51,248 main.py:47] epoch 1135, training loss: 1908.79, average training loss: 2178.54, base loss: 2639.86
[INFO 2017-06-26 19:07:51,564 main.py:47] epoch 1136, training loss: 2168.94, average training loss: 2178.12, base loss: 2639.82
[INFO 2017-06-26 19:07:51,878 main.py:47] epoch 1137, training loss: 2478.18, average training loss: 2178.10, base loss: 2640.36
[INFO 2017-06-26 19:07:52,192 main.py:47] epoch 1138, training loss: 2284.80, average training loss: 2177.97, base loss: 2640.64
[INFO 2017-06-26 19:07:52,509 main.py:47] epoch 1139, training loss: 1959.98, average training loss: 2177.50, base loss: 2640.57
[INFO 2017-06-26 19:07:52,826 main.py:47] epoch 1140, training loss: 1980.84, average training loss: 2177.06, base loss: 2640.33
[INFO 2017-06-26 19:07:53,148 main.py:47] epoch 1141, training loss: 2007.87, average training loss: 2176.90, base loss: 2640.37
[INFO 2017-06-26 19:07:53,467 main.py:47] epoch 1142, training loss: 2075.75, average training loss: 2176.82, base loss: 2640.63
[INFO 2017-06-26 19:07:53,783 main.py:47] epoch 1143, training loss: 2015.85, average training loss: 2176.28, base loss: 2640.33
[INFO 2017-06-26 19:07:54,141 main.py:47] epoch 1144, training loss: 2193.95, average training loss: 2176.11, base loss: 2640.62
[INFO 2017-06-26 19:07:54,461 main.py:47] epoch 1145, training loss: 1794.53, average training loss: 2175.08, base loss: 2639.70
[INFO 2017-06-26 19:07:54,779 main.py:47] epoch 1146, training loss: 2076.99, average training loss: 2174.85, base loss: 2639.88
[INFO 2017-06-26 19:07:55,104 main.py:47] epoch 1147, training loss: 2577.93, average training loss: 2175.00, base loss: 2640.37
[INFO 2017-06-26 19:07:55,420 main.py:47] epoch 1148, training loss: 2032.76, average training loss: 2174.73, base loss: 2640.45
[INFO 2017-06-26 19:07:55,737 main.py:47] epoch 1149, training loss: 2407.92, average training loss: 2174.44, base loss: 2640.59
[INFO 2017-06-26 19:07:56,054 main.py:47] epoch 1150, training loss: 1929.65, average training loss: 2173.91, base loss: 2640.46
[INFO 2017-06-26 19:07:56,371 main.py:47] epoch 1151, training loss: 1909.45, average training loss: 2173.18, base loss: 2640.10
[INFO 2017-06-26 19:07:56,693 main.py:47] epoch 1152, training loss: 1956.10, average training loss: 2172.45, base loss: 2639.66
[INFO 2017-06-26 19:07:57,012 main.py:47] epoch 1153, training loss: 1932.86, average training loss: 2171.87, base loss: 2639.38
[INFO 2017-06-26 19:07:57,331 main.py:47] epoch 1154, training loss: 2050.73, average training loss: 2171.09, base loss: 2638.97
[INFO 2017-06-26 19:07:57,656 main.py:47] epoch 1155, training loss: 2175.39, average training loss: 2170.76, base loss: 2638.92
[INFO 2017-06-26 19:07:57,983 main.py:47] epoch 1156, training loss: 2209.99, average training loss: 2170.73, base loss: 2639.40
[INFO 2017-06-26 19:07:58,303 main.py:47] epoch 1157, training loss: 2105.62, average training loss: 2170.48, base loss: 2639.52
[INFO 2017-06-26 19:07:58,622 main.py:47] epoch 1158, training loss: 1991.35, average training loss: 2170.29, base loss: 2639.83
[INFO 2017-06-26 19:07:58,942 main.py:47] epoch 1159, training loss: 1990.23, average training loss: 2169.96, base loss: 2639.71
[INFO 2017-06-26 19:07:59,263 main.py:47] epoch 1160, training loss: 1942.03, average training loss: 2169.67, base loss: 2639.80
[INFO 2017-06-26 19:07:59,582 main.py:47] epoch 1161, training loss: 2062.58, average training loss: 2169.60, base loss: 2640.04
[INFO 2017-06-26 19:07:59,903 main.py:47] epoch 1162, training loss: 1943.77, average training loss: 2168.97, base loss: 2639.67
[INFO 2017-06-26 19:08:00,216 main.py:47] epoch 1163, training loss: 2185.14, average training loss: 2168.47, base loss: 2639.47
[INFO 2017-06-26 19:08:00,534 main.py:47] epoch 1164, training loss: 1698.80, average training loss: 2167.69, base loss: 2638.90
[INFO 2017-06-26 19:08:00,853 main.py:47] epoch 1165, training loss: 2170.32, average training loss: 2167.31, base loss: 2638.88
[INFO 2017-06-26 19:08:01,168 main.py:47] epoch 1166, training loss: 1991.16, average training loss: 2166.83, base loss: 2638.79
[INFO 2017-06-26 19:08:01,485 main.py:47] epoch 1167, training loss: 2111.87, average training loss: 2166.55, base loss: 2638.85
[INFO 2017-06-26 19:08:01,807 main.py:47] epoch 1168, training loss: 2378.17, average training loss: 2166.60, base loss: 2639.26
[INFO 2017-06-26 19:08:02,122 main.py:47] epoch 1169, training loss: 2006.19, average training loss: 2166.24, base loss: 2639.40
[INFO 2017-06-26 19:08:02,444 main.py:47] epoch 1170, training loss: 2052.29, average training loss: 2166.07, base loss: 2639.77
[INFO 2017-06-26 19:08:02,763 main.py:47] epoch 1171, training loss: 2115.72, average training loss: 2165.59, base loss: 2639.73
[INFO 2017-06-26 19:08:03,080 main.py:47] epoch 1172, training loss: 1913.38, average training loss: 2165.13, base loss: 2639.42
[INFO 2017-06-26 19:08:03,397 main.py:47] epoch 1173, training loss: 2159.89, average training loss: 2165.05, base loss: 2639.92
[INFO 2017-06-26 19:08:03,712 main.py:47] epoch 1174, training loss: 1827.91, average training loss: 2164.43, base loss: 2639.43
[INFO 2017-06-26 19:08:04,028 main.py:47] epoch 1175, training loss: 2072.35, average training loss: 2163.60, base loss: 2638.79
[INFO 2017-06-26 19:08:04,347 main.py:47] epoch 1176, training loss: 2074.99, average training loss: 2162.84, base loss: 2638.35
[INFO 2017-06-26 19:08:04,669 main.py:47] epoch 1177, training loss: 2076.17, average training loss: 2162.59, base loss: 2638.51
[INFO 2017-06-26 19:08:04,988 main.py:47] epoch 1178, training loss: 2003.15, average training loss: 2162.11, base loss: 2638.38
[INFO 2017-06-26 19:08:05,304 main.py:47] epoch 1179, training loss: 1735.68, average training loss: 2161.63, base loss: 2638.13
[INFO 2017-06-26 19:08:05,619 main.py:47] epoch 1180, training loss: 1968.14, average training loss: 2161.43, base loss: 2638.27
[INFO 2017-06-26 19:08:05,938 main.py:47] epoch 1181, training loss: 2383.26, average training loss: 2161.01, base loss: 2638.18
[INFO 2017-06-26 19:08:06,255 main.py:47] epoch 1182, training loss: 2495.46, average training loss: 2161.72, base loss: 2639.29
[INFO 2017-06-26 19:08:06,571 main.py:47] epoch 1183, training loss: 2016.37, average training loss: 2161.31, base loss: 2639.13
[INFO 2017-06-26 19:08:06,890 main.py:47] epoch 1184, training loss: 1820.33, average training loss: 2160.66, base loss: 2638.89
[INFO 2017-06-26 19:08:07,219 main.py:47] epoch 1185, training loss: 1917.87, average training loss: 2160.29, base loss: 2638.79
[INFO 2017-06-26 19:08:07,539 main.py:47] epoch 1186, training loss: 2292.51, average training loss: 2160.15, base loss: 2638.98
[INFO 2017-06-26 19:08:07,858 main.py:47] epoch 1187, training loss: 2044.68, average training loss: 2159.97, base loss: 2639.17
[INFO 2017-06-26 19:08:08,178 main.py:47] epoch 1188, training loss: 1953.18, average training loss: 2159.50, base loss: 2639.02
[INFO 2017-06-26 19:08:08,499 main.py:47] epoch 1189, training loss: 1878.36, average training loss: 2159.03, base loss: 2638.76
[INFO 2017-06-26 19:08:08,821 main.py:47] epoch 1190, training loss: 2106.00, average training loss: 2158.65, base loss: 2638.73
[INFO 2017-06-26 19:08:09,139 main.py:47] epoch 1191, training loss: 2187.08, average training loss: 2158.39, base loss: 2638.81
[INFO 2017-06-26 19:08:09,457 main.py:47] epoch 1192, training loss: 2197.22, average training loss: 2158.38, base loss: 2639.13
[INFO 2017-06-26 19:08:09,776 main.py:47] epoch 1193, training loss: 2205.54, average training loss: 2158.45, base loss: 2639.65
[INFO 2017-06-26 19:08:10,098 main.py:47] epoch 1194, training loss: 2147.52, average training loss: 2158.37, base loss: 2639.86
[INFO 2017-06-26 19:08:10,417 main.py:47] epoch 1195, training loss: 1741.17, average training loss: 2157.44, base loss: 2639.18
[INFO 2017-06-26 19:08:10,736 main.py:47] epoch 1196, training loss: 2110.25, average training loss: 2156.97, base loss: 2639.04
[INFO 2017-06-26 19:08:11,056 main.py:47] epoch 1197, training loss: 2167.48, average training loss: 2156.96, base loss: 2639.24
[INFO 2017-06-26 19:08:11,375 main.py:47] epoch 1198, training loss: 1750.33, average training loss: 2155.95, base loss: 2638.44
[INFO 2017-06-26 19:08:11,694 main.py:47] epoch 1199, training loss: 2117.47, average training loss: 2155.78, base loss: 2638.73
[INFO 2017-06-26 19:08:11,694 main.py:49] epoch 1199, testing
[INFO 2017-06-26 19:08:15,939 main.py:100] average testing loss: 2026.47, base loss: 2580.42
[INFO 2017-06-26 19:08:15,965 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 19:08:15,984 main.py:73] current best accuracy: 2026.47
[INFO 2017-06-26 19:08:16,346 main.py:47] epoch 1200, training loss: 2146.28, average training loss: 2155.52, base loss: 2638.85
[INFO 2017-06-26 19:08:16,667 main.py:47] epoch 1201, training loss: 2157.58, average training loss: 2155.68, base loss: 2639.38
[INFO 2017-06-26 19:08:16,984 main.py:47] epoch 1202, training loss: 2225.18, average training loss: 2155.91, base loss: 2640.16
[INFO 2017-06-26 19:08:17,301 main.py:47] epoch 1203, training loss: 2305.22, average training loss: 2155.93, base loss: 2640.55
[INFO 2017-06-26 19:08:17,666 main.py:47] epoch 1204, training loss: 2049.03, average training loss: 2155.70, base loss: 2640.67
[INFO 2017-06-26 19:08:17,990 main.py:47] epoch 1205, training loss: 2141.71, average training loss: 2155.31, base loss: 2640.56
[INFO 2017-06-26 19:08:18,309 main.py:47] epoch 1206, training loss: 2044.36, average training loss: 2154.79, base loss: 2640.46
[INFO 2017-06-26 19:08:18,629 main.py:47] epoch 1207, training loss: 2071.20, average training loss: 2154.68, base loss: 2640.60
[INFO 2017-06-26 19:08:18,948 main.py:47] epoch 1208, training loss: 1833.84, average training loss: 2154.27, base loss: 2640.34
[INFO 2017-06-26 19:08:19,269 main.py:47] epoch 1209, training loss: 2324.57, average training loss: 2154.23, base loss: 2640.52
[INFO 2017-06-26 19:08:19,617 main.py:47] epoch 1210, training loss: 2233.22, average training loss: 2154.17, base loss: 2640.92
[INFO 2017-06-26 19:08:19,971 main.py:47] epoch 1211, training loss: 2053.13, average training loss: 2153.45, base loss: 2640.29
[INFO 2017-06-26 19:08:20,291 main.py:47] epoch 1212, training loss: 1965.71, average training loss: 2153.24, base loss: 2640.43
[INFO 2017-06-26 19:08:20,634 main.py:47] epoch 1213, training loss: 2092.05, average training loss: 2153.06, base loss: 2640.46
[INFO 2017-06-26 19:08:20,976 main.py:47] epoch 1214, training loss: 2037.98, average training loss: 2153.27, base loss: 2641.11
[INFO 2017-06-26 19:08:21,296 main.py:47] epoch 1215, training loss: 1970.11, average training loss: 2152.91, base loss: 2641.27
[INFO 2017-06-26 19:08:21,615 main.py:47] epoch 1216, training loss: 1966.20, average training loss: 2152.57, base loss: 2641.14
[INFO 2017-06-26 19:08:21,931 main.py:47] epoch 1217, training loss: 1829.61, average training loss: 2152.13, base loss: 2640.86
[INFO 2017-06-26 19:08:22,247 main.py:47] epoch 1218, training loss: 2281.05, average training loss: 2152.31, base loss: 2641.47
[INFO 2017-06-26 19:08:22,565 main.py:47] epoch 1219, training loss: 2072.33, average training loss: 2152.18, base loss: 2641.65
[INFO 2017-06-26 19:08:22,882 main.py:47] epoch 1220, training loss: 1839.90, average training loss: 2151.44, base loss: 2641.22
[INFO 2017-06-26 19:08:23,200 main.py:47] epoch 1221, training loss: 1808.26, average training loss: 2151.00, base loss: 2640.87
[INFO 2017-06-26 19:08:23,519 main.py:47] epoch 1222, training loss: 1870.50, average training loss: 2150.78, base loss: 2641.01
[INFO 2017-06-26 19:08:23,838 main.py:47] epoch 1223, training loss: 2035.90, average training loss: 2150.42, base loss: 2641.10
[INFO 2017-06-26 19:08:24,153 main.py:47] epoch 1224, training loss: 1788.02, average training loss: 2150.03, base loss: 2640.86
[INFO 2017-06-26 19:08:24,474 main.py:47] epoch 1225, training loss: 1990.32, average training loss: 2149.64, base loss: 2640.57
[INFO 2017-06-26 19:08:24,791 main.py:47] epoch 1226, training loss: 2005.44, average training loss: 2149.57, base loss: 2640.65
[INFO 2017-06-26 19:08:25,108 main.py:47] epoch 1227, training loss: 1944.31, average training loss: 2149.27, base loss: 2640.57
[INFO 2017-06-26 19:08:25,427 main.py:47] epoch 1228, training loss: 2116.47, average training loss: 2149.22, base loss: 2640.77
[INFO 2017-06-26 19:08:25,745 main.py:47] epoch 1229, training loss: 2158.44, average training loss: 2148.89, base loss: 2640.80
[INFO 2017-06-26 19:08:26,062 main.py:47] epoch 1230, training loss: 1823.81, average training loss: 2147.80, base loss: 2639.78
[INFO 2017-06-26 19:08:26,380 main.py:47] epoch 1231, training loss: 1953.48, average training loss: 2147.44, base loss: 2639.77
[INFO 2017-06-26 19:08:26,701 main.py:47] epoch 1232, training loss: 1971.25, average training loss: 2147.36, base loss: 2640.19
[INFO 2017-06-26 19:08:27,023 main.py:47] epoch 1233, training loss: 1902.60, average training loss: 2147.11, base loss: 2640.11
[INFO 2017-06-26 19:08:27,338 main.py:47] epoch 1234, training loss: 2011.85, average training loss: 2146.82, base loss: 2640.17
[INFO 2017-06-26 19:08:27,656 main.py:47] epoch 1235, training loss: 1865.42, average training loss: 2146.39, base loss: 2639.91
[INFO 2017-06-26 19:08:27,975 main.py:47] epoch 1236, training loss: 2077.34, average training loss: 2146.26, base loss: 2640.08
[INFO 2017-06-26 19:08:28,291 main.py:47] epoch 1237, training loss: 1817.80, average training loss: 2145.98, base loss: 2640.08
[INFO 2017-06-26 19:08:28,609 main.py:47] epoch 1238, training loss: 2165.18, average training loss: 2145.70, base loss: 2640.22
[INFO 2017-06-26 19:08:28,925 main.py:47] epoch 1239, training loss: 2141.63, average training loss: 2145.44, base loss: 2640.22
[INFO 2017-06-26 19:08:29,240 main.py:47] epoch 1240, training loss: 2062.68, average training loss: 2145.25, base loss: 2640.24
[INFO 2017-06-26 19:08:29,557 main.py:47] epoch 1241, training loss: 2310.45, average training loss: 2145.36, base loss: 2640.77
[INFO 2017-06-26 19:08:29,874 main.py:47] epoch 1242, training loss: 1728.45, average training loss: 2144.76, base loss: 2640.26
[INFO 2017-06-26 19:08:30,191 main.py:47] epoch 1243, training loss: 2163.67, average training loss: 2144.80, base loss: 2640.81
[INFO 2017-06-26 19:08:30,506 main.py:47] epoch 1244, training loss: 2240.97, average training loss: 2144.63, base loss: 2641.08
[INFO 2017-06-26 19:08:30,818 main.py:47] epoch 1245, training loss: 1974.83, average training loss: 2144.52, base loss: 2641.12
[INFO 2017-06-26 19:08:31,133 main.py:47] epoch 1246, training loss: 1675.64, average training loss: 2143.99, base loss: 2640.59
[INFO 2017-06-26 19:08:31,448 main.py:47] epoch 1247, training loss: 1922.64, average training loss: 2143.71, base loss: 2640.54
[INFO 2017-06-26 19:08:31,762 main.py:47] epoch 1248, training loss: 2298.59, average training loss: 2143.67, base loss: 2640.81
[INFO 2017-06-26 19:08:32,078 main.py:47] epoch 1249, training loss: 2058.46, average training loss: 2143.41, base loss: 2641.00
[INFO 2017-06-26 19:08:32,395 main.py:47] epoch 1250, training loss: 2329.56, average training loss: 2143.55, base loss: 2641.61
[INFO 2017-06-26 19:08:32,708 main.py:47] epoch 1251, training loss: 2182.18, average training loss: 2143.62, base loss: 2641.95
[INFO 2017-06-26 19:08:33,024 main.py:47] epoch 1252, training loss: 2047.83, average training loss: 2143.25, base loss: 2641.75
[INFO 2017-06-26 19:08:33,338 main.py:47] epoch 1253, training loss: 2076.59, average training loss: 2143.14, base loss: 2641.99
[INFO 2017-06-26 19:08:33,651 main.py:47] epoch 1254, training loss: 2328.20, average training loss: 2143.09, base loss: 2642.05
[INFO 2017-06-26 19:08:33,968 main.py:47] epoch 1255, training loss: 2193.52, average training loss: 2142.89, base loss: 2642.22
[INFO 2017-06-26 19:08:34,282 main.py:47] epoch 1256, training loss: 1770.28, average training loss: 2142.61, base loss: 2642.03
[INFO 2017-06-26 19:08:34,596 main.py:47] epoch 1257, training loss: 1872.96, average training loss: 2142.21, base loss: 2641.64
[INFO 2017-06-26 19:08:34,913 main.py:47] epoch 1258, training loss: 2297.62, average training loss: 2142.48, base loss: 2642.23
[INFO 2017-06-26 19:08:35,225 main.py:47] epoch 1259, training loss: 2226.80, average training loss: 2142.83, base loss: 2643.03
[INFO 2017-06-26 19:08:35,539 main.py:47] epoch 1260, training loss: 2090.36, average training loss: 2142.95, base loss: 2643.56
[INFO 2017-06-26 19:08:35,854 main.py:47] epoch 1261, training loss: 1862.74, average training loss: 2142.28, base loss: 2643.11
[INFO 2017-06-26 19:08:36,168 main.py:47] epoch 1262, training loss: 2180.11, average training loss: 2142.00, base loss: 2643.13
[INFO 2017-06-26 19:08:36,486 main.py:47] epoch 1263, training loss: 2091.41, average training loss: 2141.99, base loss: 2643.63
[INFO 2017-06-26 19:08:36,804 main.py:47] epoch 1264, training loss: 2043.30, average training loss: 2141.96, base loss: 2644.05
[INFO 2017-06-26 19:08:37,120 main.py:47] epoch 1265, training loss: 2069.07, average training loss: 2142.07, base loss: 2644.47
[INFO 2017-06-26 19:08:37,436 main.py:47] epoch 1266, training loss: 1988.46, average training loss: 2141.74, base loss: 2644.21
[INFO 2017-06-26 19:08:37,746 main.py:47] epoch 1267, training loss: 2223.76, average training loss: 2141.83, base loss: 2644.65
[INFO 2017-06-26 19:08:38,063 main.py:47] epoch 1268, training loss: 1936.71, average training loss: 2141.51, base loss: 2644.43
[INFO 2017-06-26 19:08:38,381 main.py:47] epoch 1269, training loss: 2051.71, average training loss: 2141.21, base loss: 2644.46
[INFO 2017-06-26 19:08:38,697 main.py:47] epoch 1270, training loss: 1813.80, average training loss: 2141.15, base loss: 2644.57
[INFO 2017-06-26 19:08:39,013 main.py:47] epoch 1271, training loss: 2166.34, average training loss: 2141.08, base loss: 2645.01
[INFO 2017-06-26 19:08:39,327 main.py:47] epoch 1272, training loss: 2064.61, average training loss: 2141.07, base loss: 2645.01
[INFO 2017-06-26 19:08:39,646 main.py:47] epoch 1273, training loss: 2392.69, average training loss: 2141.01, base loss: 2645.29
[INFO 2017-06-26 19:08:39,956 main.py:47] epoch 1274, training loss: 1883.34, average training loss: 2140.17, base loss: 2644.37
[INFO 2017-06-26 19:08:40,270 main.py:47] epoch 1275, training loss: 1925.53, average training loss: 2139.77, base loss: 2644.15
[INFO 2017-06-26 19:08:40,588 main.py:47] epoch 1276, training loss: 1966.67, average training loss: 2139.63, base loss: 2644.29
[INFO 2017-06-26 19:08:40,904 main.py:47] epoch 1277, training loss: 2166.41, average training loss: 2139.41, base loss: 2644.22
[INFO 2017-06-26 19:08:41,221 main.py:47] epoch 1278, training loss: 1844.03, average training loss: 2138.66, base loss: 2643.41
[INFO 2017-06-26 19:08:41,538 main.py:47] epoch 1279, training loss: 2042.65, average training loss: 2138.24, base loss: 2643.10
[INFO 2017-06-26 19:08:41,855 main.py:47] epoch 1280, training loss: 1900.62, average training loss: 2137.89, base loss: 2642.80
[INFO 2017-06-26 19:08:42,168 main.py:47] epoch 1281, training loss: 1897.62, average training loss: 2137.17, base loss: 2642.14
[INFO 2017-06-26 19:08:42,483 main.py:47] epoch 1282, training loss: 1718.90, average training loss: 2136.48, base loss: 2641.62
[INFO 2017-06-26 19:08:42,794 main.py:47] epoch 1283, training loss: 1869.63, average training loss: 2136.29, base loss: 2641.83
[INFO 2017-06-26 19:08:43,109 main.py:47] epoch 1284, training loss: 2028.62, average training loss: 2135.97, base loss: 2641.67
[INFO 2017-06-26 19:08:43,426 main.py:47] epoch 1285, training loss: 2068.89, average training loss: 2135.72, base loss: 2641.63
[INFO 2017-06-26 19:08:43,743 main.py:47] epoch 1286, training loss: 2301.17, average training loss: 2135.91, base loss: 2642.14
[INFO 2017-06-26 19:08:44,060 main.py:47] epoch 1287, training loss: 1883.48, average training loss: 2135.16, base loss: 2641.41
[INFO 2017-06-26 19:08:44,375 main.py:47] epoch 1288, training loss: 2172.42, average training loss: 2135.34, base loss: 2641.92
[INFO 2017-06-26 19:08:44,692 main.py:47] epoch 1289, training loss: 1998.54, average training loss: 2135.03, base loss: 2641.92
[INFO 2017-06-26 19:08:45,005 main.py:47] epoch 1290, training loss: 1995.15, average training loss: 2134.89, base loss: 2641.95
[INFO 2017-06-26 19:08:45,317 main.py:47] epoch 1291, training loss: 2050.43, average training loss: 2134.30, base loss: 2641.57
[INFO 2017-06-26 19:08:45,637 main.py:47] epoch 1292, training loss: 2127.99, average training loss: 2134.29, base loss: 2642.32
[INFO 2017-06-26 19:08:45,952 main.py:47] epoch 1293, training loss: 2211.47, average training loss: 2134.10, base loss: 2642.42
[INFO 2017-06-26 19:08:46,265 main.py:47] epoch 1294, training loss: 1908.49, average training loss: 2133.61, base loss: 2642.13
[INFO 2017-06-26 19:08:46,578 main.py:47] epoch 1295, training loss: 1959.44, average training loss: 2132.88, base loss: 2641.55
[INFO 2017-06-26 19:08:46,892 main.py:47] epoch 1296, training loss: 2022.16, average training loss: 2132.76, base loss: 2641.82
[INFO 2017-06-26 19:08:47,205 main.py:47] epoch 1297, training loss: 2061.77, average training loss: 2132.56, base loss: 2641.76
[INFO 2017-06-26 19:08:47,516 main.py:47] epoch 1298, training loss: 2588.45, average training loss: 2132.71, base loss: 2642.28
[INFO 2017-06-26 19:08:47,827 main.py:47] epoch 1299, training loss: 1969.22, average training loss: 2132.61, base loss: 2642.37
[INFO 2017-06-26 19:08:47,827 main.py:49] epoch 1299, testing
[INFO 2017-06-26 19:08:51,811 main.py:100] average testing loss: 2062.88, base loss: 2627.38
[INFO 2017-06-26 19:08:51,836 main.py:73] current best accuracy: 2026.47
[INFO 2017-06-26 19:08:52,146 main.py:47] epoch 1300, training loss: 1768.85, average training loss: 2131.85, base loss: 2641.58
[INFO 2017-06-26 19:08:52,463 main.py:47] epoch 1301, training loss: 1886.75, average training loss: 2131.53, base loss: 2641.38
[INFO 2017-06-26 19:08:52,777 main.py:47] epoch 1302, training loss: 1967.48, average training loss: 2131.39, base loss: 2641.55
[INFO 2017-06-26 19:08:53,088 main.py:47] epoch 1303, training loss: 1966.28, average training loss: 2131.13, base loss: 2641.35
[INFO 2017-06-26 19:08:53,406 main.py:47] epoch 1304, training loss: 1773.35, average training loss: 2130.59, base loss: 2640.82
[INFO 2017-06-26 19:08:53,721 main.py:47] epoch 1305, training loss: 2059.59, average training loss: 2130.39, base loss: 2641.00
[INFO 2017-06-26 19:08:54,037 main.py:47] epoch 1306, training loss: 2078.37, average training loss: 2130.55, base loss: 2641.50
[INFO 2017-06-26 19:08:54,354 main.py:47] epoch 1307, training loss: 2475.47, average training loss: 2131.01, base loss: 2642.30
[INFO 2017-06-26 19:08:54,670 main.py:47] epoch 1308, training loss: 1942.59, average training loss: 2130.58, base loss: 2641.94
[INFO 2017-06-26 19:08:54,985 main.py:47] epoch 1309, training loss: 1965.82, average training loss: 2130.04, base loss: 2641.60
[INFO 2017-06-26 19:08:55,302 main.py:47] epoch 1310, training loss: 1951.07, average training loss: 2129.70, base loss: 2641.42
[INFO 2017-06-26 19:08:55,618 main.py:47] epoch 1311, training loss: 2073.94, average training loss: 2129.59, base loss: 2641.57
[INFO 2017-06-26 19:08:55,934 main.py:47] epoch 1312, training loss: 2023.77, average training loss: 2129.38, base loss: 2641.61
[INFO 2017-06-26 19:08:56,250 main.py:47] epoch 1313, training loss: 1981.46, average training loss: 2129.08, base loss: 2641.56
[INFO 2017-06-26 19:08:56,566 main.py:47] epoch 1314, training loss: 2077.65, average training loss: 2129.04, base loss: 2642.06
[INFO 2017-06-26 19:08:56,881 main.py:47] epoch 1315, training loss: 1859.77, average training loss: 2128.72, base loss: 2641.90
[INFO 2017-06-26 19:08:57,197 main.py:47] epoch 1316, training loss: 1964.67, average training loss: 2128.56, base loss: 2641.82
[INFO 2017-06-26 19:08:57,510 main.py:47] epoch 1317, training loss: 1910.44, average training loss: 2128.35, base loss: 2641.73
[INFO 2017-06-26 19:08:57,827 main.py:47] epoch 1318, training loss: 2154.97, average training loss: 2128.41, base loss: 2642.01
[INFO 2017-06-26 19:08:58,139 main.py:47] epoch 1319, training loss: 1978.62, average training loss: 2128.26, base loss: 2642.07
[INFO 2017-06-26 19:08:58,457 main.py:47] epoch 1320, training loss: 1694.86, average training loss: 2127.80, base loss: 2641.53
[INFO 2017-06-26 19:08:58,775 main.py:47] epoch 1321, training loss: 2013.15, average training loss: 2128.06, base loss: 2642.05
[INFO 2017-06-26 19:08:59,092 main.py:47] epoch 1322, training loss: 1987.62, average training loss: 2127.40, base loss: 2641.41
[INFO 2017-06-26 19:08:59,408 main.py:47] epoch 1323, training loss: 1970.28, average training loss: 2126.84, base loss: 2640.98
[INFO 2017-06-26 19:08:59,725 main.py:47] epoch 1324, training loss: 2218.62, average training loss: 2127.08, base loss: 2641.38
[INFO 2017-06-26 19:09:00,039 main.py:47] epoch 1325, training loss: 1777.77, average training loss: 2126.41, base loss: 2640.49
[INFO 2017-06-26 19:09:00,353 main.py:47] epoch 1326, training loss: 1991.55, average training loss: 2126.18, base loss: 2640.05
[INFO 2017-06-26 19:09:00,664 main.py:47] epoch 1327, training loss: 1712.06, average training loss: 2125.65, base loss: 2639.62
[INFO 2017-06-26 19:09:00,980 main.py:47] epoch 1328, training loss: 2145.91, average training loss: 2125.58, base loss: 2639.70
[INFO 2017-06-26 19:09:01,294 main.py:47] epoch 1329, training loss: 1801.69, average training loss: 2125.35, base loss: 2639.66
[INFO 2017-06-26 19:09:01,612 main.py:47] epoch 1330, training loss: 1891.00, average training loss: 2125.27, base loss: 2639.76
[INFO 2017-06-26 19:09:01,926 main.py:47] epoch 1331, training loss: 2106.32, average training loss: 2124.91, base loss: 2639.55
[INFO 2017-06-26 19:09:02,243 main.py:47] epoch 1332, training loss: 1951.89, average training loss: 2124.28, base loss: 2639.04
[INFO 2017-06-26 19:09:02,556 main.py:47] epoch 1333, training loss: 2282.85, average training loss: 2124.35, base loss: 2639.30
[INFO 2017-06-26 19:09:02,872 main.py:47] epoch 1334, training loss: 2020.95, average training loss: 2124.36, base loss: 2639.54
[INFO 2017-06-26 19:09:03,187 main.py:47] epoch 1335, training loss: 2372.14, average training loss: 2124.47, base loss: 2639.98
[INFO 2017-06-26 19:09:03,501 main.py:47] epoch 1336, training loss: 1789.45, average training loss: 2123.60, base loss: 2639.26
[INFO 2017-06-26 19:09:03,817 main.py:47] epoch 1337, training loss: 2347.47, average training loss: 2123.63, base loss: 2639.57
[INFO 2017-06-26 19:09:04,134 main.py:47] epoch 1338, training loss: 2123.89, average training loss: 2123.49, base loss: 2639.49
[INFO 2017-06-26 19:09:04,447 main.py:47] epoch 1339, training loss: 2009.89, average training loss: 2123.01, base loss: 2639.16
[INFO 2017-06-26 19:09:04,765 main.py:47] epoch 1340, training loss: 1906.61, average training loss: 2122.96, base loss: 2639.21
[INFO 2017-06-26 19:09:05,081 main.py:47] epoch 1341, training loss: 1949.28, average training loss: 2122.77, base loss: 2639.52
[INFO 2017-06-26 19:09:05,390 main.py:47] epoch 1342, training loss: 1616.57, average training loss: 2122.22, base loss: 2639.22
[INFO 2017-06-26 19:09:05,704 main.py:47] epoch 1343, training loss: 2051.65, average training loss: 2122.49, base loss: 2639.70
[INFO 2017-06-26 19:09:06,019 main.py:47] epoch 1344, training loss: 1853.29, average training loss: 2121.79, base loss: 2639.08
[INFO 2017-06-26 19:09:06,334 main.py:47] epoch 1345, training loss: 2412.77, average training loss: 2122.20, base loss: 2639.92
[INFO 2017-06-26 19:09:06,648 main.py:47] epoch 1346, training loss: 2077.57, average training loss: 2121.61, base loss: 2639.38
[INFO 2017-06-26 19:09:06,965 main.py:47] epoch 1347, training loss: 2068.19, average training loss: 2121.41, base loss: 2639.29
[INFO 2017-06-26 19:09:07,287 main.py:47] epoch 1348, training loss: 1938.83, average training loss: 2121.37, base loss: 2639.61
[INFO 2017-06-26 19:09:07,604 main.py:47] epoch 1349, training loss: 2000.50, average training loss: 2121.11, base loss: 2639.38
[INFO 2017-06-26 19:09:07,914 main.py:47] epoch 1350, training loss: 1893.75, average training loss: 2120.98, base loss: 2639.47
[INFO 2017-06-26 19:09:08,229 main.py:47] epoch 1351, training loss: 1902.87, average training loss: 2120.61, base loss: 2639.30
[INFO 2017-06-26 19:09:08,546 main.py:47] epoch 1352, training loss: 1934.86, average training loss: 2120.34, base loss: 2639.11
[INFO 2017-06-26 19:09:08,865 main.py:47] epoch 1353, training loss: 1888.09, average training loss: 2119.72, base loss: 2638.34
[INFO 2017-06-26 19:09:09,184 main.py:47] epoch 1354, training loss: 2000.36, average training loss: 2119.55, base loss: 2638.38
[INFO 2017-06-26 19:09:09,500 main.py:47] epoch 1355, training loss: 2218.45, average training loss: 2119.52, base loss: 2638.58
[INFO 2017-06-26 19:09:09,817 main.py:47] epoch 1356, training loss: 1920.22, average training loss: 2119.25, base loss: 2638.25
[INFO 2017-06-26 19:09:10,133 main.py:47] epoch 1357, training loss: 2177.39, average training loss: 2119.08, base loss: 2638.39
[INFO 2017-06-26 19:09:10,452 main.py:47] epoch 1358, training loss: 2034.94, average training loss: 2118.74, base loss: 2638.01
[INFO 2017-06-26 19:09:10,770 main.py:47] epoch 1359, training loss: 2028.56, average training loss: 2117.91, base loss: 2636.90
[INFO 2017-06-26 19:09:11,088 main.py:47] epoch 1360, training loss: 2039.39, average training loss: 2117.82, base loss: 2637.00
[INFO 2017-06-26 19:09:11,405 main.py:47] epoch 1361, training loss: 2140.05, average training loss: 2117.61, base loss: 2636.58
[INFO 2017-06-26 19:09:11,723 main.py:47] epoch 1362, training loss: 2210.85, average training loss: 2117.46, base loss: 2636.42
[INFO 2017-06-26 19:09:12,037 main.py:47] epoch 1363, training loss: 2178.42, average training loss: 2117.54, base loss: 2636.67
[INFO 2017-06-26 19:09:12,355 main.py:47] epoch 1364, training loss: 2055.65, average training loss: 2117.38, base loss: 2636.73
[INFO 2017-06-26 19:09:12,673 main.py:47] epoch 1365, training loss: 1978.26, average training loss: 2117.51, base loss: 2637.10
[INFO 2017-06-26 19:09:12,989 main.py:47] epoch 1366, training loss: 2248.91, average training loss: 2117.42, base loss: 2637.38
[INFO 2017-06-26 19:09:13,308 main.py:47] epoch 1367, training loss: 1952.21, average training loss: 2117.33, base loss: 2637.47
[INFO 2017-06-26 19:09:13,621 main.py:47] epoch 1368, training loss: 2275.48, average training loss: 2117.49, base loss: 2637.90
[INFO 2017-06-26 19:09:13,939 main.py:47] epoch 1369, training loss: 2019.38, average training loss: 2117.54, base loss: 2638.14
[INFO 2017-06-26 19:09:14,256 main.py:47] epoch 1370, training loss: 1878.23, average training loss: 2116.81, base loss: 2637.41
[INFO 2017-06-26 19:09:14,574 main.py:47] epoch 1371, training loss: 2051.17, average training loss: 2116.71, base loss: 2637.59
[INFO 2017-06-26 19:09:14,887 main.py:47] epoch 1372, training loss: 2081.30, average training loss: 2116.56, base loss: 2637.75
[INFO 2017-06-26 19:09:15,205 main.py:47] epoch 1373, training loss: 2171.61, average training loss: 2116.56, base loss: 2637.78
[INFO 2017-06-26 19:09:15,523 main.py:47] epoch 1374, training loss: 2163.73, average training loss: 2116.82, base loss: 2638.35
[INFO 2017-06-26 19:09:15,838 main.py:47] epoch 1375, training loss: 1677.30, average training loss: 2116.01, base loss: 2637.45
[INFO 2017-06-26 19:09:16,153 main.py:47] epoch 1376, training loss: 1988.83, average training loss: 2115.52, base loss: 2637.06
[INFO 2017-06-26 19:09:16,471 main.py:47] epoch 1377, training loss: 2099.61, average training loss: 2115.43, base loss: 2637.09
[INFO 2017-06-26 19:09:16,789 main.py:47] epoch 1378, training loss: 1950.82, average training loss: 2114.95, base loss: 2636.73
[INFO 2017-06-26 19:09:17,104 main.py:47] epoch 1379, training loss: 1723.17, average training loss: 2114.22, base loss: 2636.17
[INFO 2017-06-26 19:09:17,420 main.py:47] epoch 1380, training loss: 2174.38, average training loss: 2114.23, base loss: 2636.41
[INFO 2017-06-26 19:09:17,738 main.py:47] epoch 1381, training loss: 1919.41, average training loss: 2113.82, base loss: 2636.19
[INFO 2017-06-26 19:09:18,056 main.py:47] epoch 1382, training loss: 2075.64, average training loss: 2113.18, base loss: 2635.57
[INFO 2017-06-26 19:09:18,377 main.py:47] epoch 1383, training loss: 1881.95, average training loss: 2113.08, base loss: 2635.56
[INFO 2017-06-26 19:09:18,695 main.py:47] epoch 1384, training loss: 2181.59, average training loss: 2113.17, base loss: 2635.84
[INFO 2017-06-26 19:09:19,010 main.py:47] epoch 1385, training loss: 1951.63, average training loss: 2112.78, base loss: 2635.36
[INFO 2017-06-26 19:09:19,324 main.py:47] epoch 1386, training loss: 1945.48, average training loss: 2112.49, base loss: 2635.15
[INFO 2017-06-26 19:09:19,639 main.py:47] epoch 1387, training loss: 2120.89, average training loss: 2112.23, base loss: 2635.06
[INFO 2017-06-26 19:09:19,954 main.py:47] epoch 1388, training loss: 2063.18, average training loss: 2112.19, base loss: 2635.17
[INFO 2017-06-26 19:09:20,265 main.py:47] epoch 1389, training loss: 2663.32, average training loss: 2112.81, base loss: 2636.26
[INFO 2017-06-26 19:09:20,580 main.py:47] epoch 1390, training loss: 1794.07, average training loss: 2112.47, base loss: 2635.92
[INFO 2017-06-26 19:09:20,899 main.py:47] epoch 1391, training loss: 2016.51, average training loss: 2112.50, base loss: 2636.53
[INFO 2017-06-26 19:09:21,214 main.py:47] epoch 1392, training loss: 2355.14, average training loss: 2112.59, base loss: 2636.95
[INFO 2017-06-26 19:09:21,529 main.py:47] epoch 1393, training loss: 2062.47, average training loss: 2112.67, base loss: 2637.34
[INFO 2017-06-26 19:09:21,843 main.py:47] epoch 1394, training loss: 1925.15, average training loss: 2112.66, base loss: 2637.70
[INFO 2017-06-26 19:09:22,161 main.py:47] epoch 1395, training loss: 1887.84, average training loss: 2112.22, base loss: 2637.43
[INFO 2017-06-26 19:09:22,477 main.py:47] epoch 1396, training loss: 2251.50, average training loss: 2112.30, base loss: 2637.91
[INFO 2017-06-26 19:09:22,793 main.py:47] epoch 1397, training loss: 2111.45, average training loss: 2112.54, base loss: 2638.36
[INFO 2017-06-26 19:09:23,111 main.py:47] epoch 1398, training loss: 1657.62, average training loss: 2112.14, base loss: 2638.03
[INFO 2017-06-26 19:09:23,427 main.py:47] epoch 1399, training loss: 1932.40, average training loss: 2111.49, base loss: 2637.46
[INFO 2017-06-26 19:09:23,427 main.py:49] epoch 1399, testing
[INFO 2017-06-26 19:09:27,539 main.py:100] average testing loss: 1987.33, base loss: 2548.83
[INFO 2017-06-26 19:09:27,562 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 19:09:27,576 main.py:73] current best accuracy: 1987.33
[INFO 2017-06-26 19:09:27,891 main.py:47] epoch 1400, training loss: 1969.85, average training loss: 2111.53, base loss: 2637.70
[INFO 2017-06-26 19:09:28,207 main.py:47] epoch 1401, training loss: 2091.13, average training loss: 2111.45, base loss: 2637.64
[INFO 2017-06-26 19:09:28,521 main.py:47] epoch 1402, training loss: 2281.95, average training loss: 2111.46, base loss: 2637.73
[INFO 2017-06-26 19:09:28,837 main.py:47] epoch 1403, training loss: 1964.50, average training loss: 2110.99, base loss: 2637.23
[INFO 2017-06-26 19:09:29,153 main.py:47] epoch 1404, training loss: 1814.39, average training loss: 2110.28, base loss: 2636.44
[INFO 2017-06-26 19:09:29,469 main.py:47] epoch 1405, training loss: 2038.79, average training loss: 2110.03, base loss: 2636.21
[INFO 2017-06-26 19:09:29,782 main.py:47] epoch 1406, training loss: 2057.28, average training loss: 2110.06, base loss: 2636.57
[INFO 2017-06-26 19:09:30,099 main.py:47] epoch 1407, training loss: 2023.05, average training loss: 2109.42, base loss: 2635.83
[INFO 2017-06-26 19:09:30,411 main.py:47] epoch 1408, training loss: 1985.03, average training loss: 2109.42, base loss: 2636.14
[INFO 2017-06-26 19:09:30,726 main.py:47] epoch 1409, training loss: 1934.78, average training loss: 2109.08, base loss: 2635.63
[INFO 2017-06-26 19:09:31,040 main.py:47] epoch 1410, training loss: 1976.75, average training loss: 2108.56, base loss: 2635.16
[INFO 2017-06-26 19:09:31,355 main.py:47] epoch 1411, training loss: 2180.03, average training loss: 2108.18, base loss: 2634.90
[INFO 2017-06-26 19:09:31,670 main.py:47] epoch 1412, training loss: 1985.29, average training loss: 2107.68, base loss: 2634.52
[INFO 2017-06-26 19:09:31,986 main.py:47] epoch 1413, training loss: 2157.52, average training loss: 2107.39, base loss: 2634.37
[INFO 2017-06-26 19:09:32,317 main.py:47] epoch 1414, training loss: 2272.01, average training loss: 2107.47, base loss: 2634.63
[INFO 2017-06-26 19:09:32,638 main.py:47] epoch 1415, training loss: 2205.12, average training loss: 2107.29, base loss: 2634.69
[INFO 2017-06-26 19:09:32,954 main.py:47] epoch 1416, training loss: 2103.20, average training loss: 2107.03, base loss: 2634.35
[INFO 2017-06-26 19:09:33,270 main.py:47] epoch 1417, training loss: 2144.12, average training loss: 2106.62, base loss: 2633.81
[INFO 2017-06-26 19:09:33,585 main.py:47] epoch 1418, training loss: 2165.88, average training loss: 2106.85, base loss: 2634.18
[INFO 2017-06-26 19:09:33,899 main.py:47] epoch 1419, training loss: 1991.95, average training loss: 2106.55, base loss: 2633.94
[INFO 2017-06-26 19:09:34,214 main.py:47] epoch 1420, training loss: 2230.23, average training loss: 2106.68, base loss: 2634.50
[INFO 2017-06-26 19:09:34,525 main.py:47] epoch 1421, training loss: 2179.78, average training loss: 2106.57, base loss: 2634.62
[INFO 2017-06-26 19:09:34,844 main.py:47] epoch 1422, training loss: 1770.50, average training loss: 2106.32, base loss: 2634.65
[INFO 2017-06-26 19:09:35,161 main.py:47] epoch 1423, training loss: 1865.27, average training loss: 2106.22, base loss: 2634.62
[INFO 2017-06-26 19:09:35,478 main.py:47] epoch 1424, training loss: 2125.26, average training loss: 2106.30, base loss: 2634.96
[INFO 2017-06-26 19:09:35,792 main.py:47] epoch 1425, training loss: 2053.09, average training loss: 2106.02, base loss: 2634.94
[INFO 2017-06-26 19:09:36,107 main.py:47] epoch 1426, training loss: 2027.26, average training loss: 2105.83, base loss: 2635.12
[INFO 2017-06-26 19:09:36,419 main.py:47] epoch 1427, training loss: 2526.36, average training loss: 2106.47, base loss: 2636.04
[INFO 2017-06-26 19:09:36,734 main.py:47] epoch 1428, training loss: 2294.90, average training loss: 2106.30, base loss: 2636.19
[INFO 2017-06-26 19:09:37,047 main.py:47] epoch 1429, training loss: 2178.73, average training loss: 2106.45, base loss: 2636.47
[INFO 2017-06-26 19:09:37,361 main.py:47] epoch 1430, training loss: 2187.17, average training loss: 2106.01, base loss: 2636.32
[INFO 2017-06-26 19:09:37,676 main.py:47] epoch 1431, training loss: 1924.74, average training loss: 2105.73, base loss: 2636.04
[INFO 2017-06-26 19:09:37,990 main.py:47] epoch 1432, training loss: 2147.74, average training loss: 2104.90, base loss: 2635.24
[INFO 2017-06-26 19:09:38,306 main.py:47] epoch 1433, training loss: 1814.71, average training loss: 2104.65, base loss: 2635.13
[INFO 2017-06-26 19:09:38,623 main.py:47] epoch 1434, training loss: 1780.37, average training loss: 2104.17, base loss: 2634.76
[INFO 2017-06-26 19:09:38,940 main.py:47] epoch 1435, training loss: 2345.25, average training loss: 2104.40, base loss: 2635.24
[INFO 2017-06-26 19:09:39,256 main.py:47] epoch 1436, training loss: 2147.20, average training loss: 2104.38, base loss: 2635.37
[INFO 2017-06-26 19:09:39,571 main.py:47] epoch 1437, training loss: 2451.09, average training loss: 2104.54, base loss: 2635.79
[INFO 2017-06-26 19:09:39,885 main.py:47] epoch 1438, training loss: 2526.29, average training loss: 2104.91, base loss: 2636.49
[INFO 2017-06-26 19:09:40,198 main.py:47] epoch 1439, training loss: 1797.72, average training loss: 2104.36, base loss: 2635.87
[INFO 2017-06-26 19:09:40,516 main.py:47] epoch 1440, training loss: 2109.10, average training loss: 2104.51, base loss: 2636.15
[INFO 2017-06-26 19:09:40,830 main.py:47] epoch 1441, training loss: 2212.65, average training loss: 2104.51, base loss: 2636.11
[INFO 2017-06-26 19:09:41,148 main.py:47] epoch 1442, training loss: 2257.71, average training loss: 2104.69, base loss: 2636.65
[INFO 2017-06-26 19:09:41,459 main.py:47] epoch 1443, training loss: 2053.71, average training loss: 2104.30, base loss: 2636.35
[INFO 2017-06-26 19:09:41,770 main.py:47] epoch 1444, training loss: 1819.82, average training loss: 2104.14, base loss: 2636.15
[INFO 2017-06-26 19:09:42,083 main.py:47] epoch 1445, training loss: 2271.30, average training loss: 2104.41, base loss: 2636.77
[INFO 2017-06-26 19:09:42,397 main.py:47] epoch 1446, training loss: 2024.21, average training loss: 2103.85, base loss: 2636.55
[INFO 2017-06-26 19:09:42,714 main.py:47] epoch 1447, training loss: 2309.85, average training loss: 2103.58, base loss: 2636.51
[INFO 2017-06-26 19:09:43,031 main.py:47] epoch 1448, training loss: 2097.85, average training loss: 2102.95, base loss: 2636.03
[INFO 2017-06-26 19:09:43,347 main.py:47] epoch 1449, training loss: 1890.78, average training loss: 2102.48, base loss: 2635.60
[INFO 2017-06-26 19:09:43,660 main.py:47] epoch 1450, training loss: 1988.61, average training loss: 2102.02, base loss: 2634.89
[INFO 2017-06-26 19:09:43,977 main.py:47] epoch 1451, training loss: 2150.65, average training loss: 2102.09, base loss: 2635.32
[INFO 2017-06-26 19:09:44,291 main.py:47] epoch 1452, training loss: 1758.89, average training loss: 2101.98, base loss: 2635.36
[INFO 2017-06-26 19:09:44,607 main.py:47] epoch 1453, training loss: 2031.13, average training loss: 2101.76, base loss: 2635.40
[INFO 2017-06-26 19:09:44,924 main.py:47] epoch 1454, training loss: 2279.43, average training loss: 2101.73, base loss: 2635.43
[INFO 2017-06-26 19:09:45,241 main.py:47] epoch 1455, training loss: 1974.93, average training loss: 2101.21, base loss: 2635.18
[INFO 2017-06-26 19:09:45,558 main.py:47] epoch 1456, training loss: 2232.56, average training loss: 2101.44, base loss: 2635.67
[INFO 2017-06-26 19:09:45,874 main.py:47] epoch 1457, training loss: 1806.72, average training loss: 2101.38, base loss: 2635.71
[INFO 2017-06-26 19:09:46,189 main.py:47] epoch 1458, training loss: 1958.87, average training loss: 2100.89, base loss: 2635.52
[INFO 2017-06-26 19:09:46,507 main.py:47] epoch 1459, training loss: 2241.11, average training loss: 2100.76, base loss: 2635.52
[INFO 2017-06-26 19:09:46,822 main.py:47] epoch 1460, training loss: 2203.47, average training loss: 2100.71, base loss: 2635.58
[INFO 2017-06-26 19:09:47,138 main.py:47] epoch 1461, training loss: 1760.55, average training loss: 2100.35, base loss: 2635.28
[INFO 2017-06-26 19:09:47,455 main.py:47] epoch 1462, training loss: 1858.03, average training loss: 2100.09, base loss: 2635.31
[INFO 2017-06-26 19:09:47,769 main.py:47] epoch 1463, training loss: 1998.91, average training loss: 2099.79, base loss: 2635.03
[INFO 2017-06-26 19:09:48,086 main.py:47] epoch 1464, training loss: 2149.55, average training loss: 2099.86, base loss: 2635.21
[INFO 2017-06-26 19:09:48,400 main.py:47] epoch 1465, training loss: 2082.23, average training loss: 2099.76, base loss: 2635.23
[INFO 2017-06-26 19:09:48,716 main.py:47] epoch 1466, training loss: 2141.82, average training loss: 2099.53, base loss: 2635.30
[INFO 2017-06-26 19:09:49,034 main.py:47] epoch 1467, training loss: 1878.69, average training loss: 2098.98, base loss: 2634.70
[INFO 2017-06-26 19:09:49,349 main.py:47] epoch 1468, training loss: 2103.08, average training loss: 2098.70, base loss: 2634.60
[INFO 2017-06-26 19:09:49,663 main.py:47] epoch 1469, training loss: 1912.48, average training loss: 2098.37, base loss: 2634.26
[INFO 2017-06-26 19:09:49,981 main.py:47] epoch 1470, training loss: 2066.38, average training loss: 2097.83, base loss: 2633.88
[INFO 2017-06-26 19:09:50,298 main.py:47] epoch 1471, training loss: 1903.04, average training loss: 2097.35, base loss: 2633.46
[INFO 2017-06-26 19:09:50,616 main.py:47] epoch 1472, training loss: 2214.15, average training loss: 2097.38, base loss: 2633.74
[INFO 2017-06-26 19:09:50,933 main.py:47] epoch 1473, training loss: 2248.70, average training loss: 2097.67, base loss: 2634.31
[INFO 2017-06-26 19:09:51,254 main.py:47] epoch 1474, training loss: 2105.98, average training loss: 2097.58, base loss: 2634.49
[INFO 2017-06-26 19:09:51,593 main.py:47] epoch 1475, training loss: 1895.73, average training loss: 2097.17, base loss: 2634.31
[INFO 2017-06-26 19:09:51,922 main.py:47] epoch 1476, training loss: 2185.13, average training loss: 2096.93, base loss: 2634.29
[INFO 2017-06-26 19:09:52,237 main.py:47] epoch 1477, training loss: 1894.71, average training loss: 2096.36, base loss: 2633.81
[INFO 2017-06-26 19:09:52,573 main.py:47] epoch 1478, training loss: 2109.90, average training loss: 2096.32, base loss: 2633.80
[INFO 2017-06-26 19:09:52,887 main.py:47] epoch 1479, training loss: 2028.50, average training loss: 2095.76, base loss: 2633.27
[INFO 2017-06-26 19:09:53,205 main.py:47] epoch 1480, training loss: 2094.67, average training loss: 2095.83, base loss: 2633.59
[INFO 2017-06-26 19:09:53,519 main.py:47] epoch 1481, training loss: 2201.89, average training loss: 2095.76, base loss: 2633.61
[INFO 2017-06-26 19:09:53,834 main.py:47] epoch 1482, training loss: 2113.09, average training loss: 2095.10, base loss: 2633.19
[INFO 2017-06-26 19:09:54,149 main.py:47] epoch 1483, training loss: 2038.49, average training loss: 2094.97, base loss: 2633.11
[INFO 2017-06-26 19:09:54,470 main.py:47] epoch 1484, training loss: 1781.28, average training loss: 2094.16, base loss: 2632.30
[INFO 2017-06-26 19:09:54,781 main.py:47] epoch 1485, training loss: 2319.36, average training loss: 2093.98, base loss: 2632.00
[INFO 2017-06-26 19:09:55,095 main.py:47] epoch 1486, training loss: 1883.99, average training loss: 2093.26, base loss: 2631.18
[INFO 2017-06-26 19:09:55,409 main.py:47] epoch 1487, training loss: 2444.51, average training loss: 2093.39, base loss: 2631.55
[INFO 2017-06-26 19:09:55,730 main.py:47] epoch 1488, training loss: 2051.70, average training loss: 2093.46, base loss: 2631.80
[INFO 2017-06-26 19:09:56,046 main.py:47] epoch 1489, training loss: 1887.80, average training loss: 2093.13, base loss: 2631.42
[INFO 2017-06-26 19:09:56,363 main.py:47] epoch 1490, training loss: 1785.16, average training loss: 2092.78, base loss: 2631.53
[INFO 2017-06-26 19:09:56,679 main.py:47] epoch 1491, training loss: 2020.68, average training loss: 2092.69, base loss: 2631.55
[INFO 2017-06-26 19:09:56,993 main.py:47] epoch 1492, training loss: 2317.44, average training loss: 2092.85, base loss: 2631.87
[INFO 2017-06-26 19:09:57,310 main.py:47] epoch 1493, training loss: 1854.32, average training loss: 2092.61, base loss: 2631.76
[INFO 2017-06-26 19:09:57,629 main.py:47] epoch 1494, training loss: 2032.69, average training loss: 2092.69, base loss: 2631.89
[INFO 2017-06-26 19:09:57,947 main.py:47] epoch 1495, training loss: 2083.00, average training loss: 2092.65, base loss: 2632.05
[INFO 2017-06-26 19:09:58,265 main.py:47] epoch 1496, training loss: 1934.82, average training loss: 2092.76, base loss: 2632.50
[INFO 2017-06-26 19:09:58,581 main.py:47] epoch 1497, training loss: 2590.40, average training loss: 2093.16, base loss: 2632.94
[INFO 2017-06-26 19:09:58,898 main.py:47] epoch 1498, training loss: 2047.17, average training loss: 2092.99, base loss: 2633.09
[INFO 2017-06-26 19:09:59,214 main.py:47] epoch 1499, training loss: 1905.53, average training loss: 2092.31, base loss: 2632.36
[INFO 2017-06-26 19:09:59,215 main.py:49] epoch 1499, testing
[INFO 2017-06-26 19:10:03,291 main.py:100] average testing loss: 2128.62, base loss: 2726.05
[INFO 2017-06-26 19:10:03,317 main.py:73] current best accuracy: 1987.33
[INFO 2017-06-26 19:10:03,640 main.py:47] epoch 1500, training loss: 1841.34, average training loss: 2091.64, base loss: 2631.69
[INFO 2017-06-26 19:10:03,959 main.py:47] epoch 1501, training loss: 2017.76, average training loss: 2091.70, base loss: 2631.79
[INFO 2017-06-26 19:10:04,280 main.py:47] epoch 1502, training loss: 1977.99, average training loss: 2091.62, base loss: 2631.80
[INFO 2017-06-26 19:10:04,602 main.py:47] epoch 1503, training loss: 2257.72, average training loss: 2091.71, base loss: 2632.19
[INFO 2017-06-26 19:10:04,918 main.py:47] epoch 1504, training loss: 1860.27, average training loss: 2091.32, base loss: 2631.75
[INFO 2017-06-26 19:10:05,235 main.py:47] epoch 1505, training loss: 2183.71, average training loss: 2091.33, base loss: 2631.82
[INFO 2017-06-26 19:10:05,552 main.py:47] epoch 1506, training loss: 2365.10, average training loss: 2091.61, base loss: 2632.48
[INFO 2017-06-26 19:10:05,868 main.py:47] epoch 1507, training loss: 2061.99, average training loss: 2091.53, base loss: 2632.60
[INFO 2017-06-26 19:10:06,186 main.py:47] epoch 1508, training loss: 1941.93, average training loss: 2091.39, base loss: 2632.58
[INFO 2017-06-26 19:10:06,502 main.py:47] epoch 1509, training loss: 2091.69, average training loss: 2091.44, base loss: 2632.62
[INFO 2017-06-26 19:10:06,819 main.py:47] epoch 1510, training loss: 2078.50, average training loss: 2091.51, base loss: 2632.84
[INFO 2017-06-26 19:10:07,136 main.py:47] epoch 1511, training loss: 2116.94, average training loss: 2091.75, base loss: 2633.31
[INFO 2017-06-26 19:10:07,476 main.py:47] epoch 1512, training loss: 2073.94, average training loss: 2091.70, base loss: 2633.47
[INFO 2017-06-26 19:10:07,842 main.py:47] epoch 1513, training loss: 1771.87, average training loss: 2091.47, base loss: 2633.23
[INFO 2017-06-26 19:10:08,200 main.py:47] epoch 1514, training loss: 2029.73, average training loss: 2091.59, base loss: 2633.49
[INFO 2017-06-26 19:10:08,568 main.py:47] epoch 1515, training loss: 2295.83, average training loss: 2091.97, base loss: 2634.35
[INFO 2017-06-26 19:10:08,940 main.py:47] epoch 1516, training loss: 1921.48, average training loss: 2091.98, base loss: 2634.40
[INFO 2017-06-26 19:10:09,297 main.py:47] epoch 1517, training loss: 2033.50, average training loss: 2092.10, base loss: 2634.70
[INFO 2017-06-26 19:10:09,635 main.py:47] epoch 1518, training loss: 1872.39, average training loss: 2092.00, base loss: 2634.68
[INFO 2017-06-26 19:10:09,975 main.py:47] epoch 1519, training loss: 1981.84, average training loss: 2091.67, base loss: 2634.20
[INFO 2017-06-26 19:10:10,351 main.py:47] epoch 1520, training loss: 1907.63, average training loss: 2091.57, base loss: 2634.36
[INFO 2017-06-26 19:10:10,737 main.py:47] epoch 1521, training loss: 2158.30, average training loss: 2091.99, base loss: 2635.05
[INFO 2017-06-26 19:10:11,078 main.py:47] epoch 1522, training loss: 2051.38, average training loss: 2091.69, base loss: 2634.90
[INFO 2017-06-26 19:10:11,405 main.py:47] epoch 1523, training loss: 1933.98, average training loss: 2091.33, base loss: 2634.57
[INFO 2017-06-26 19:10:11,718 main.py:47] epoch 1524, training loss: 1957.08, average training loss: 2091.09, base loss: 2634.40
[INFO 2017-06-26 19:10:12,032 main.py:47] epoch 1525, training loss: 2141.43, average training loss: 2091.16, base loss: 2634.75
[INFO 2017-06-26 19:10:12,355 main.py:47] epoch 1526, training loss: 1823.52, average training loss: 2090.99, base loss: 2634.86
[INFO 2017-06-26 19:10:12,667 main.py:47] epoch 1527, training loss: 2005.74, average training loss: 2090.54, base loss: 2634.47
[INFO 2017-06-26 19:10:12,999 main.py:47] epoch 1528, training loss: 1955.73, average training loss: 2090.31, base loss: 2634.43
[INFO 2017-06-26 19:10:13,318 main.py:47] epoch 1529, training loss: 1846.78, average training loss: 2089.83, base loss: 2634.01
[INFO 2017-06-26 19:10:13,637 main.py:47] epoch 1530, training loss: 2163.57, average training loss: 2089.78, base loss: 2634.13
[INFO 2017-06-26 19:10:13,950 main.py:47] epoch 1531, training loss: 2045.76, average training loss: 2089.69, base loss: 2634.25
[INFO 2017-06-26 19:10:14,263 main.py:47] epoch 1532, training loss: 2055.67, average training loss: 2089.61, base loss: 2634.38
[INFO 2017-06-26 19:10:14,578 main.py:47] epoch 1533, training loss: 1968.02, average training loss: 2089.44, base loss: 2634.16
[INFO 2017-06-26 19:10:14,894 main.py:47] epoch 1534, training loss: 2130.42, average training loss: 2089.67, base loss: 2634.54
[INFO 2017-06-26 19:10:15,208 main.py:47] epoch 1535, training loss: 2121.57, average training loss: 2089.26, base loss: 2634.34
[INFO 2017-06-26 19:10:15,522 main.py:47] epoch 1536, training loss: 1967.73, average training loss: 2088.82, base loss: 2633.99
[INFO 2017-06-26 19:10:15,837 main.py:47] epoch 1537, training loss: 1871.98, average training loss: 2088.50, base loss: 2633.73
[INFO 2017-06-26 19:10:16,151 main.py:47] epoch 1538, training loss: 1993.43, average training loss: 2088.50, base loss: 2633.75
[INFO 2017-06-26 19:10:16,465 main.py:47] epoch 1539, training loss: 2195.85, average training loss: 2088.60, base loss: 2634.15
[INFO 2017-06-26 19:10:16,776 main.py:47] epoch 1540, training loss: 1877.82, average training loss: 2088.27, base loss: 2633.99
[INFO 2017-06-26 19:10:17,087 main.py:47] epoch 1541, training loss: 2384.05, average training loss: 2088.79, base loss: 2635.01
[INFO 2017-06-26 19:10:17,404 main.py:47] epoch 1542, training loss: 1929.18, average training loss: 2088.37, base loss: 2634.87
[INFO 2017-06-26 19:10:17,719 main.py:47] epoch 1543, training loss: 1886.53, average training loss: 2088.15, base loss: 2634.78
[INFO 2017-06-26 19:10:18,034 main.py:47] epoch 1544, training loss: 2183.31, average training loss: 2087.96, base loss: 2634.77
[INFO 2017-06-26 19:10:18,347 main.py:47] epoch 1545, training loss: 1816.85, average training loss: 2086.99, base loss: 2633.74
[INFO 2017-06-26 19:10:18,661 main.py:47] epoch 1546, training loss: 2397.04, average training loss: 2086.94, base loss: 2633.67
[INFO 2017-06-26 19:10:18,974 main.py:47] epoch 1547, training loss: 2094.51, average training loss: 2086.38, base loss: 2633.30
[INFO 2017-06-26 19:10:19,290 main.py:47] epoch 1548, training loss: 2000.91, average training loss: 2085.71, base loss: 2632.42
[INFO 2017-06-26 19:10:19,603 main.py:47] epoch 1549, training loss: 1930.69, average training loss: 2085.39, base loss: 2632.20
[INFO 2017-06-26 19:10:19,921 main.py:47] epoch 1550, training loss: 1935.68, average training loss: 2085.09, base loss: 2631.96
[INFO 2017-06-26 19:10:20,236 main.py:47] epoch 1551, training loss: 2104.52, average training loss: 2085.28, base loss: 2632.50
[INFO 2017-06-26 19:10:20,552 main.py:47] epoch 1552, training loss: 1696.51, average training loss: 2085.08, base loss: 2632.35
[INFO 2017-06-26 19:10:20,869 main.py:47] epoch 1553, training loss: 2111.51, average training loss: 2084.73, base loss: 2632.02
[INFO 2017-06-26 19:10:21,182 main.py:47] epoch 1554, training loss: 1975.04, average training loss: 2084.22, base loss: 2631.32
[INFO 2017-06-26 19:10:21,496 main.py:47] epoch 1555, training loss: 1936.38, average training loss: 2083.97, base loss: 2630.94
[INFO 2017-06-26 19:10:21,810 main.py:47] epoch 1556, training loss: 2208.97, average training loss: 2083.72, base loss: 2630.69
[INFO 2017-06-26 19:10:22,128 main.py:47] epoch 1557, training loss: 2036.40, average training loss: 2083.85, base loss: 2631.05
[INFO 2017-06-26 19:10:22,447 main.py:47] epoch 1558, training loss: 1970.08, average training loss: 2083.38, base loss: 2630.74
[INFO 2017-06-26 19:10:22,763 main.py:47] epoch 1559, training loss: 2169.38, average training loss: 2083.47, base loss: 2630.87
[INFO 2017-06-26 19:10:23,077 main.py:47] epoch 1560, training loss: 1819.77, average training loss: 2082.89, base loss: 2630.21
[INFO 2017-06-26 19:10:23,391 main.py:47] epoch 1561, training loss: 2174.90, average training loss: 2082.60, base loss: 2630.11
[INFO 2017-06-26 19:10:23,706 main.py:47] epoch 1562, training loss: 2219.33, average training loss: 2082.32, base loss: 2629.82
[INFO 2017-06-26 19:10:24,022 main.py:47] epoch 1563, training loss: 2327.72, average training loss: 2082.77, base loss: 2630.33
[INFO 2017-06-26 19:10:24,337 main.py:47] epoch 1564, training loss: 2205.67, average training loss: 2082.91, base loss: 2630.39
[INFO 2017-06-26 19:10:24,650 main.py:47] epoch 1565, training loss: 1914.05, average training loss: 2082.86, base loss: 2630.38
[INFO 2017-06-26 19:10:24,965 main.py:47] epoch 1566, training loss: 2148.31, average training loss: 2082.90, base loss: 2630.64
[INFO 2017-06-26 19:10:25,277 main.py:47] epoch 1567, training loss: 2353.85, average training loss: 2083.29, base loss: 2631.18
[INFO 2017-06-26 19:10:25,593 main.py:47] epoch 1568, training loss: 2156.67, average training loss: 2083.03, base loss: 2630.98
[INFO 2017-06-26 19:10:25,907 main.py:47] epoch 1569, training loss: 2108.15, average training loss: 2082.95, base loss: 2631.10
[INFO 2017-06-26 19:10:26,226 main.py:47] epoch 1570, training loss: 2051.90, average training loss: 2082.49, base loss: 2630.68
[INFO 2017-06-26 19:10:26,541 main.py:47] epoch 1571, training loss: 2147.75, average training loss: 2082.32, base loss: 2630.68
[INFO 2017-06-26 19:10:26,855 main.py:47] epoch 1572, training loss: 1807.87, average training loss: 2082.24, base loss: 2630.71
[INFO 2017-06-26 19:10:27,170 main.py:47] epoch 1573, training loss: 1785.85, average training loss: 2081.73, base loss: 2630.23
[INFO 2017-06-26 19:10:27,487 main.py:47] epoch 1574, training loss: 2100.51, average training loss: 2081.58, base loss: 2630.21
[INFO 2017-06-26 19:10:27,804 main.py:47] epoch 1575, training loss: 2289.46, average training loss: 2081.97, base loss: 2631.05
[INFO 2017-06-26 19:10:28,121 main.py:47] epoch 1576, training loss: 1841.12, average training loss: 2081.35, base loss: 2630.52
[INFO 2017-06-26 19:10:28,437 main.py:47] epoch 1577, training loss: 2082.07, average training loss: 2081.38, base loss: 2630.63
[INFO 2017-06-26 19:10:28,752 main.py:47] epoch 1578, training loss: 2087.30, average training loss: 2081.35, base loss: 2630.62
[INFO 2017-06-26 19:10:29,067 main.py:47] epoch 1579, training loss: 1967.02, average training loss: 2081.30, base loss: 2630.51
[INFO 2017-06-26 19:10:29,381 main.py:47] epoch 1580, training loss: 2153.43, average training loss: 2081.53, base loss: 2630.92
[INFO 2017-06-26 19:10:29,696 main.py:47] epoch 1581, training loss: 1986.43, average training loss: 2081.44, base loss: 2631.03
[INFO 2017-06-26 19:10:30,016 main.py:47] epoch 1582, training loss: 1885.35, average training loss: 2080.79, base loss: 2630.14
[INFO 2017-06-26 19:10:30,331 main.py:47] epoch 1583, training loss: 1936.52, average training loss: 2080.71, base loss: 2630.32
[INFO 2017-06-26 19:10:30,648 main.py:47] epoch 1584, training loss: 1993.16, average training loss: 2080.06, base loss: 2629.63
[INFO 2017-06-26 19:10:30,964 main.py:47] epoch 1585, training loss: 2060.03, average training loss: 2080.06, base loss: 2629.68
[INFO 2017-06-26 19:10:31,280 main.py:47] epoch 1586, training loss: 1767.43, average training loss: 2079.89, base loss: 2629.63
[INFO 2017-06-26 19:10:31,597 main.py:47] epoch 1587, training loss: 1746.82, average training loss: 2079.72, base loss: 2629.61
[INFO 2017-06-26 19:10:31,913 main.py:47] epoch 1588, training loss: 1794.81, average training loss: 2079.51, base loss: 2629.44
[INFO 2017-06-26 19:10:32,228 main.py:47] epoch 1589, training loss: 1897.12, average training loss: 2079.06, base loss: 2628.86
[INFO 2017-06-26 19:10:32,588 main.py:47] epoch 1590, training loss: 1717.04, average training loss: 2078.94, base loss: 2628.94
[INFO 2017-06-26 19:10:33,001 main.py:47] epoch 1591, training loss: 2039.27, average training loss: 2078.73, base loss: 2628.80
[INFO 2017-06-26 19:10:33,326 main.py:47] epoch 1592, training loss: 2162.01, average training loss: 2078.58, base loss: 2628.94
[INFO 2017-06-26 19:10:33,691 main.py:47] epoch 1593, training loss: 1998.92, average training loss: 2078.84, base loss: 2629.42
[INFO 2017-06-26 19:10:34,068 main.py:47] epoch 1594, training loss: 1907.55, average training loss: 2078.60, base loss: 2629.36
[INFO 2017-06-26 19:10:34,383 main.py:47] epoch 1595, training loss: 2443.55, average training loss: 2078.69, base loss: 2629.50
[INFO 2017-06-26 19:10:34,756 main.py:47] epoch 1596, training loss: 1715.01, average training loss: 2078.06, base loss: 2628.83
[INFO 2017-06-26 19:10:35,145 main.py:47] epoch 1597, training loss: 2195.78, average training loss: 2078.30, base loss: 2629.41
[INFO 2017-06-26 19:10:35,467 main.py:47] epoch 1598, training loss: 2097.87, average training loss: 2078.13, base loss: 2629.38
[INFO 2017-06-26 19:10:35,805 main.py:47] epoch 1599, training loss: 2045.46, average training loss: 2078.16, base loss: 2629.58
[INFO 2017-06-26 19:10:35,805 main.py:49] epoch 1599, testing
[INFO 2017-06-26 19:10:40,399 main.py:100] average testing loss: 2041.96, base loss: 2698.56
[INFO 2017-06-26 19:10:40,421 main.py:73] current best accuracy: 1987.33
[INFO 2017-06-26 19:10:40,739 main.py:47] epoch 1600, training loss: 2000.34, average training loss: 2078.11, base loss: 2629.44
[INFO 2017-06-26 19:10:41,055 main.py:47] epoch 1601, training loss: 1850.97, average training loss: 2077.70, base loss: 2629.18
[INFO 2017-06-26 19:10:41,370 main.py:47] epoch 1602, training loss: 2147.06, average training loss: 2077.84, base loss: 2629.44
[INFO 2017-06-26 19:10:41,688 main.py:47] epoch 1603, training loss: 1959.24, average training loss: 2077.60, base loss: 2629.62
[INFO 2017-06-26 19:10:42,007 main.py:47] epoch 1604, training loss: 1899.93, average training loss: 2077.46, base loss: 2629.55
[INFO 2017-06-26 19:10:42,322 main.py:47] epoch 1605, training loss: 2094.07, average training loss: 2077.64, base loss: 2629.90
[INFO 2017-06-26 19:10:42,638 main.py:47] epoch 1606, training loss: 2121.89, average training loss: 2077.56, base loss: 2630.19
[INFO 2017-06-26 19:10:42,952 main.py:47] epoch 1607, training loss: 2005.73, average training loss: 2077.60, base loss: 2630.50
[INFO 2017-06-26 19:10:43,267 main.py:47] epoch 1608, training loss: 2217.56, average training loss: 2077.33, base loss: 2630.33
[INFO 2017-06-26 19:10:43,582 main.py:47] epoch 1609, training loss: 2049.99, average training loss: 2077.22, base loss: 2630.53
[INFO 2017-06-26 19:10:43,897 main.py:47] epoch 1610, training loss: 2114.24, average training loss: 2077.23, base loss: 2630.50
[INFO 2017-06-26 19:10:44,212 main.py:47] epoch 1611, training loss: 2066.60, average training loss: 2077.17, base loss: 2630.76
[INFO 2017-06-26 19:10:44,525 main.py:47] epoch 1612, training loss: 1867.22, average training loss: 2077.10, base loss: 2630.57
[INFO 2017-06-26 19:10:44,840 main.py:47] epoch 1613, training loss: 2247.85, average training loss: 2077.17, base loss: 2630.63
[INFO 2017-06-26 19:10:45,157 main.py:47] epoch 1614, training loss: 1918.12, average training loss: 2077.08, base loss: 2630.82
[INFO 2017-06-26 19:10:45,472 main.py:47] epoch 1615, training loss: 1998.37, average training loss: 2077.19, base loss: 2631.40
[INFO 2017-06-26 19:10:45,789 main.py:47] epoch 1616, training loss: 2157.32, average training loss: 2077.38, base loss: 2631.69
[INFO 2017-06-26 19:10:46,107 main.py:47] epoch 1617, training loss: 2126.07, average training loss: 2077.32, base loss: 2631.75
[INFO 2017-06-26 19:10:46,422 main.py:47] epoch 1618, training loss: 1887.94, average training loss: 2077.43, base loss: 2632.17
[INFO 2017-06-26 19:10:46,736 main.py:47] epoch 1619, training loss: 1942.98, average training loss: 2077.23, base loss: 2632.02
[INFO 2017-06-26 19:10:47,053 main.py:47] epoch 1620, training loss: 2008.52, average training loss: 2077.23, base loss: 2632.10
[INFO 2017-06-26 19:10:47,366 main.py:47] epoch 1621, training loss: 1833.25, average training loss: 2076.86, base loss: 2631.67
[INFO 2017-06-26 19:10:47,680 main.py:47] epoch 1622, training loss: 2151.36, average training loss: 2076.90, base loss: 2631.59
[INFO 2017-06-26 19:10:47,990 main.py:47] epoch 1623, training loss: 2127.24, average training loss: 2076.99, base loss: 2631.91
[INFO 2017-06-26 19:10:48,304 main.py:47] epoch 1624, training loss: 1902.02, average training loss: 2076.56, base loss: 2631.83
[INFO 2017-06-26 19:10:48,621 main.py:47] epoch 1625, training loss: 2088.33, average training loss: 2076.47, base loss: 2632.00
[INFO 2017-06-26 19:10:48,937 main.py:47] epoch 1626, training loss: 2055.84, average training loss: 2076.37, base loss: 2632.06
[INFO 2017-06-26 19:10:49,256 main.py:47] epoch 1627, training loss: 1935.80, average training loss: 2076.05, base loss: 2631.93
[INFO 2017-06-26 19:10:49,569 main.py:47] epoch 1628, training loss: 1769.15, average training loss: 2075.81, base loss: 2631.65
[INFO 2017-06-26 19:10:49,883 main.py:47] epoch 1629, training loss: 2051.35, average training loss: 2075.94, base loss: 2632.03
[INFO 2017-06-26 19:10:50,197 main.py:47] epoch 1630, training loss: 2201.55, average training loss: 2076.00, base loss: 2632.27
[INFO 2017-06-26 19:10:50,512 main.py:47] epoch 1631, training loss: 2013.52, average training loss: 2075.86, base loss: 2632.17
[INFO 2017-06-26 19:10:50,826 main.py:47] epoch 1632, training loss: 1982.94, average training loss: 2075.40, base loss: 2631.67
[INFO 2017-06-26 19:10:51,144 main.py:47] epoch 1633, training loss: 1926.17, average training loss: 2075.22, base loss: 2631.74
[INFO 2017-06-26 19:10:51,462 main.py:47] epoch 1634, training loss: 2132.40, average training loss: 2075.23, base loss: 2631.84
[INFO 2017-06-26 19:10:51,778 main.py:47] epoch 1635, training loss: 1579.47, average training loss: 2074.72, base loss: 2631.23
[INFO 2017-06-26 19:10:52,096 main.py:47] epoch 1636, training loss: 1760.94, average training loss: 2074.47, base loss: 2631.21
[INFO 2017-06-26 19:10:52,412 main.py:47] epoch 1637, training loss: 2032.33, average training loss: 2074.66, base loss: 2631.73
[INFO 2017-06-26 19:10:52,727 main.py:47] epoch 1638, training loss: 2108.38, average training loss: 2074.72, base loss: 2631.79
[INFO 2017-06-26 19:10:53,044 main.py:47] epoch 1639, training loss: 1957.59, average training loss: 2074.44, base loss: 2631.48
[INFO 2017-06-26 19:10:53,420 main.py:47] epoch 1640, training loss: 2168.19, average training loss: 2074.58, base loss: 2631.81
[INFO 2017-06-26 19:10:53,771 main.py:47] epoch 1641, training loss: 1976.55, average training loss: 2074.66, base loss: 2632.13
[INFO 2017-06-26 19:10:54,087 main.py:47] epoch 1642, training loss: 1925.36, average training loss: 2074.52, base loss: 2632.06
[INFO 2017-06-26 19:10:54,407 main.py:47] epoch 1643, training loss: 1724.10, average training loss: 2074.45, base loss: 2632.11
[INFO 2017-06-26 19:10:54,801 main.py:47] epoch 1644, training loss: 2066.56, average training loss: 2074.66, base loss: 2632.69
[INFO 2017-06-26 19:10:55,144 main.py:47] epoch 1645, training loss: 2113.88, average training loss: 2074.75, base loss: 2632.98
[INFO 2017-06-26 19:10:55,463 main.py:47] epoch 1646, training loss: 2015.16, average training loss: 2074.44, base loss: 2632.85
[INFO 2017-06-26 19:10:55,851 main.py:47] epoch 1647, training loss: 1881.10, average training loss: 2074.02, base loss: 2632.52
[INFO 2017-06-26 19:10:56,200 main.py:47] epoch 1648, training loss: 2140.51, average training loss: 2074.00, base loss: 2632.34
[INFO 2017-06-26 19:10:56,520 main.py:47] epoch 1649, training loss: 1969.74, average training loss: 2073.61, base loss: 2631.96
[INFO 2017-06-26 19:10:56,900 main.py:47] epoch 1650, training loss: 2165.59, average training loss: 2073.64, base loss: 2631.91
[INFO 2017-06-26 19:10:57,264 main.py:47] epoch 1651, training loss: 1992.97, average training loss: 2073.66, base loss: 2632.45
[INFO 2017-06-26 19:10:57,601 main.py:47] epoch 1652, training loss: 1964.55, average training loss: 2073.21, base loss: 2632.02
[INFO 2017-06-26 19:10:57,946 main.py:47] epoch 1653, training loss: 1748.50, average training loss: 2072.65, base loss: 2631.30
[INFO 2017-06-26 19:10:58,261 main.py:47] epoch 1654, training loss: 1892.11, average training loss: 2072.39, base loss: 2631.01
[INFO 2017-06-26 19:10:58,584 main.py:47] epoch 1655, training loss: 1758.50, average training loss: 2071.76, base loss: 2630.35
[INFO 2017-06-26 19:10:58,924 main.py:47] epoch 1656, training loss: 2254.65, average training loss: 2071.88, base loss: 2630.57
[INFO 2017-06-26 19:10:59,242 main.py:47] epoch 1657, training loss: 1958.69, average training loss: 2071.46, base loss: 2630.23
[INFO 2017-06-26 19:10:59,671 main.py:47] epoch 1658, training loss: 2257.47, average training loss: 2071.35, base loss: 2630.35
[INFO 2017-06-26 19:11:00,036 main.py:47] epoch 1659, training loss: 2194.47, average training loss: 2071.32, base loss: 2630.67
[INFO 2017-06-26 19:11:00,353 main.py:47] epoch 1660, training loss: 2161.43, average training loss: 2071.33, base loss: 2630.84
[INFO 2017-06-26 19:11:00,751 main.py:47] epoch 1661, training loss: 1834.01, average training loss: 2070.81, base loss: 2630.40
[INFO 2017-06-26 19:11:01,116 main.py:47] epoch 1662, training loss: 1932.11, average training loss: 2070.49, base loss: 2630.14
[INFO 2017-06-26 19:11:01,445 main.py:47] epoch 1663, training loss: 2060.65, average training loss: 2070.25, base loss: 2630.05
[INFO 2017-06-26 19:11:01,787 main.py:47] epoch 1664, training loss: 2233.56, average training loss: 2070.59, base loss: 2630.59
[INFO 2017-06-26 19:11:02,104 main.py:47] epoch 1665, training loss: 2266.74, average training loss: 2070.91, base loss: 2631.09
[INFO 2017-06-26 19:11:02,417 main.py:47] epoch 1666, training loss: 1883.96, average training loss: 2070.61, base loss: 2630.77
[INFO 2017-06-26 19:11:02,825 main.py:47] epoch 1667, training loss: 2134.16, average training loss: 2070.72, base loss: 2630.92
[INFO 2017-06-26 19:11:03,148 main.py:47] epoch 1668, training loss: 1827.45, average training loss: 2070.02, base loss: 2629.98
[INFO 2017-06-26 19:11:03,524 main.py:47] epoch 1669, training loss: 2250.74, average training loss: 2070.28, base loss: 2630.53
[INFO 2017-06-26 19:11:03,928 main.py:47] epoch 1670, training loss: 2003.10, average training loss: 2070.23, base loss: 2630.63
[INFO 2017-06-26 19:11:04,247 main.py:47] epoch 1671, training loss: 2235.47, average training loss: 2070.34, base loss: 2631.05
[INFO 2017-06-26 19:11:04,669 main.py:47] epoch 1672, training loss: 2216.27, average training loss: 2070.12, base loss: 2630.91
[INFO 2017-06-26 19:11:05,000 main.py:47] epoch 1673, training loss: 1828.21, average training loss: 2069.79, base loss: 2630.69
[INFO 2017-06-26 19:11:05,331 main.py:47] epoch 1674, training loss: 1989.85, average training loss: 2069.91, base loss: 2631.02
[INFO 2017-06-26 19:11:05,713 main.py:47] epoch 1675, training loss: 1937.11, average training loss: 2069.82, base loss: 2630.96
[INFO 2017-06-26 19:11:06,068 main.py:47] epoch 1676, training loss: 2168.98, average training loss: 2069.93, base loss: 2631.29
[INFO 2017-06-26 19:11:06,397 main.py:47] epoch 1677, training loss: 2201.65, average training loss: 2070.03, base loss: 2631.31
[INFO 2017-06-26 19:11:06,720 main.py:47] epoch 1678, training loss: 2228.89, average training loss: 2070.25, base loss: 2631.73
[INFO 2017-06-26 19:11:07,039 main.py:47] epoch 1679, training loss: 1975.59, average training loss: 2070.31, base loss: 2631.93
[INFO 2017-06-26 19:11:07,415 main.py:47] epoch 1680, training loss: 1926.30, average training loss: 2070.42, base loss: 2632.34
[INFO 2017-06-26 19:11:07,753 main.py:47] epoch 1681, training loss: 1873.47, average training loss: 2070.36, base loss: 2632.28
[INFO 2017-06-26 19:11:08,085 main.py:47] epoch 1682, training loss: 2246.36, average training loss: 2070.73, base loss: 2632.79
[INFO 2017-06-26 19:11:08,436 main.py:47] epoch 1683, training loss: 1875.31, average training loss: 2070.77, base loss: 2632.92
[INFO 2017-06-26 19:11:08,760 main.py:47] epoch 1684, training loss: 2252.22, average training loss: 2070.72, base loss: 2633.01
[INFO 2017-06-26 19:11:09,095 main.py:47] epoch 1685, training loss: 1883.83, average training loss: 2070.73, base loss: 2633.03
[INFO 2017-06-26 19:11:09,427 main.py:47] epoch 1686, training loss: 1815.37, average training loss: 2070.29, base loss: 2632.48
[INFO 2017-06-26 19:11:09,753 main.py:47] epoch 1687, training loss: 2186.50, average training loss: 2070.34, base loss: 2632.71
[INFO 2017-06-26 19:11:10,110 main.py:47] epoch 1688, training loss: 1962.28, average training loss: 2070.33, base loss: 2632.89
[INFO 2017-06-26 19:11:10,468 main.py:47] epoch 1689, training loss: 2432.74, average training loss: 2070.68, base loss: 2633.56
[INFO 2017-06-26 19:11:10,784 main.py:47] epoch 1690, training loss: 1986.64, average training loss: 2070.52, base loss: 2633.63
[INFO 2017-06-26 19:11:11,174 main.py:47] epoch 1691, training loss: 1874.22, average training loss: 2070.28, base loss: 2633.07
[INFO 2017-06-26 19:11:11,525 main.py:47] epoch 1692, training loss: 2515.37, average training loss: 2070.45, base loss: 2633.47
[INFO 2017-06-26 19:11:11,883 main.py:47] epoch 1693, training loss: 1898.11, average training loss: 2070.13, base loss: 2633.10
[INFO 2017-06-26 19:11:12,230 main.py:47] epoch 1694, training loss: 2031.07, average training loss: 2069.91, base loss: 2632.72
[INFO 2017-06-26 19:11:12,548 main.py:47] epoch 1695, training loss: 2199.11, average training loss: 2069.89, base loss: 2633.05
[INFO 2017-06-26 19:11:12,929 main.py:47] epoch 1696, training loss: 2136.99, average training loss: 2069.97, base loss: 2633.21
[INFO 2017-06-26 19:11:13,287 main.py:47] epoch 1697, training loss: 2036.05, average training loss: 2069.96, base loss: 2633.54
[INFO 2017-06-26 19:11:13,608 main.py:47] epoch 1698, training loss: 2043.09, average training loss: 2069.95, base loss: 2633.63
[INFO 2017-06-26 19:11:13,946 main.py:47] epoch 1699, training loss: 1869.32, average training loss: 2069.62, base loss: 2633.39
[INFO 2017-06-26 19:11:13,946 main.py:49] epoch 1699, testing
[INFO 2017-06-26 19:11:18,479 main.py:100] average testing loss: 2023.57, base loss: 2604.05
[INFO 2017-06-26 19:11:18,502 main.py:73] current best accuracy: 1987.33
[INFO 2017-06-26 19:11:18,815 main.py:47] epoch 1700, training loss: 1874.47, average training loss: 2069.01, base loss: 2632.61
[INFO 2017-06-26 19:11:19,132 main.py:47] epoch 1701, training loss: 1762.02, average training loss: 2068.58, base loss: 2632.05
[INFO 2017-06-26 19:11:19,447 main.py:47] epoch 1702, training loss: 1798.44, average training loss: 2068.02, base loss: 2631.65
[INFO 2017-06-26 19:11:19,761 main.py:47] epoch 1703, training loss: 1871.84, average training loss: 2067.68, base loss: 2631.06
[INFO 2017-06-26 19:11:20,078 main.py:47] epoch 1704, training loss: 1845.45, average training loss: 2067.31, base loss: 2630.66
[INFO 2017-06-26 19:11:20,395 main.py:47] epoch 1705, training loss: 2386.52, average training loss: 2067.47, base loss: 2630.81
[INFO 2017-06-26 19:11:20,707 main.py:47] epoch 1706, training loss: 1991.63, average training loss: 2067.33, base loss: 2630.72
[INFO 2017-06-26 19:11:21,024 main.py:47] epoch 1707, training loss: 2180.75, average training loss: 2067.34, base loss: 2630.97
[INFO 2017-06-26 19:11:21,338 main.py:47] epoch 1708, training loss: 2305.80, average training loss: 2067.76, base loss: 2631.76
[INFO 2017-06-26 19:11:21,697 main.py:47] epoch 1709, training loss: 1966.97, average training loss: 2067.51, base loss: 2631.44
[INFO 2017-06-26 19:11:22,045 main.py:47] epoch 1710, training loss: 2048.41, average training loss: 2067.54, base loss: 2631.62
[INFO 2017-06-26 19:11:22,365 main.py:47] epoch 1711, training loss: 2141.14, average training loss: 2067.77, base loss: 2632.25
[INFO 2017-06-26 19:11:22,786 main.py:47] epoch 1712, training loss: 2137.54, average training loss: 2067.99, base loss: 2632.75
[INFO 2017-06-26 19:11:23,140 main.py:47] epoch 1713, training loss: 1949.83, average training loss: 2068.14, base loss: 2632.92
[INFO 2017-06-26 19:11:23,464 main.py:47] epoch 1714, training loss: 2142.56, average training loss: 2068.35, base loss: 2633.29
[INFO 2017-06-26 19:11:23,853 main.py:47] epoch 1715, training loss: 2084.15, average training loss: 2068.42, base loss: 2633.20
[INFO 2017-06-26 19:11:24,195 main.py:47] epoch 1716, training loss: 1772.19, average training loss: 2068.28, base loss: 2633.13
[INFO 2017-06-26 19:11:24,594 main.py:47] epoch 1717, training loss: 2167.06, average training loss: 2068.70, base loss: 2633.77
[INFO 2017-06-26 19:11:24,965 main.py:47] epoch 1718, training loss: 1961.22, average training loss: 2068.55, base loss: 2633.73
[INFO 2017-06-26 19:11:25,289 main.py:47] epoch 1719, training loss: 1973.84, average training loss: 2068.14, base loss: 2633.32
[INFO 2017-06-26 19:11:25,637 main.py:47] epoch 1720, training loss: 1856.71, average training loss: 2068.12, base loss: 2633.35
[INFO 2017-06-26 19:11:25,965 main.py:47] epoch 1721, training loss: 2017.95, average training loss: 2068.31, base loss: 2633.74
[INFO 2017-06-26 19:11:26,291 main.py:47] epoch 1722, training loss: 1978.78, average training loss: 2068.19, base loss: 2633.54
[INFO 2017-06-26 19:11:26,632 main.py:47] epoch 1723, training loss: 1778.32, average training loss: 2067.85, base loss: 2633.07
[INFO 2017-06-26 19:11:26,950 main.py:47] epoch 1724, training loss: 1964.67, average training loss: 2067.80, base loss: 2633.03
[INFO 2017-06-26 19:11:27,343 main.py:47] epoch 1725, training loss: 1883.21, average training loss: 2067.73, base loss: 2633.19
[INFO 2017-06-26 19:11:27,681 main.py:47] epoch 1726, training loss: 2136.66, average training loss: 2067.94, base loss: 2633.58
[INFO 2017-06-26 19:11:28,002 main.py:47] epoch 1727, training loss: 2061.22, average training loss: 2067.98, base loss: 2633.72
[INFO 2017-06-26 19:11:28,394 main.py:47] epoch 1728, training loss: 2196.41, average training loss: 2068.23, base loss: 2634.09
[INFO 2017-06-26 19:11:28,757 main.py:47] epoch 1729, training loss: 1845.35, average training loss: 2067.65, base loss: 2633.44
[INFO 2017-06-26 19:11:29,075 main.py:47] epoch 1730, training loss: 2049.40, average training loss: 2067.45, base loss: 2633.28
[INFO 2017-06-26 19:11:29,398 main.py:47] epoch 1731, training loss: 1962.91, average training loss: 2067.31, base loss: 2633.18
[INFO 2017-06-26 19:11:29,783 main.py:47] epoch 1732, training loss: 1960.63, average training loss: 2067.11, base loss: 2633.06
[INFO 2017-06-26 19:11:30,137 main.py:47] epoch 1733, training loss: 1767.95, average training loss: 2066.72, base loss: 2632.67
[INFO 2017-06-26 19:11:30,457 main.py:47] epoch 1734, training loss: 2015.44, average training loss: 2066.48, base loss: 2632.26
[INFO 2017-06-26 19:11:30,867 main.py:47] epoch 1735, training loss: 1713.54, average training loss: 2066.07, base loss: 2631.89
[INFO 2017-06-26 19:11:31,197 main.py:47] epoch 1736, training loss: 2017.37, average training loss: 2065.81, base loss: 2631.54
[INFO 2017-06-26 19:11:31,588 main.py:47] epoch 1737, training loss: 1890.28, average training loss: 2065.49, base loss: 2631.15
[INFO 2017-06-26 19:11:31,992 main.py:47] epoch 1738, training loss: 1885.04, average training loss: 2065.34, base loss: 2631.16
[INFO 2017-06-26 19:11:32,330 main.py:47] epoch 1739, training loss: 2133.86, average training loss: 2065.29, base loss: 2631.27
[INFO 2017-06-26 19:11:32,652 main.py:47] epoch 1740, training loss: 2094.90, average training loss: 2065.22, base loss: 2631.39
[INFO 2017-06-26 19:11:32,971 main.py:47] epoch 1741, training loss: 1921.44, average training loss: 2065.13, base loss: 2631.51
[INFO 2017-06-26 19:11:33,304 main.py:47] epoch 1742, training loss: 2044.57, average training loss: 2064.97, base loss: 2631.31
[INFO 2017-06-26 19:11:33,622 main.py:47] epoch 1743, training loss: 1902.37, average training loss: 2064.60, base loss: 2630.79
[INFO 2017-06-26 19:11:33,935 main.py:47] epoch 1744, training loss: 2061.87, average training loss: 2064.68, base loss: 2631.03
[INFO 2017-06-26 19:11:34,252 main.py:47] epoch 1745, training loss: 1965.81, average training loss: 2064.42, base loss: 2630.59
[INFO 2017-06-26 19:11:34,570 main.py:47] epoch 1746, training loss: 1735.78, average training loss: 2063.86, base loss: 2629.72
[INFO 2017-06-26 19:11:34,883 main.py:47] epoch 1747, training loss: 1891.06, average training loss: 2063.41, base loss: 2629.16
[INFO 2017-06-26 19:11:35,200 main.py:47] epoch 1748, training loss: 1803.00, average training loss: 2063.03, base loss: 2628.72
[INFO 2017-06-26 19:11:35,522 main.py:47] epoch 1749, training loss: 2076.01, average training loss: 2062.98, base loss: 2628.93
[INFO 2017-06-26 19:11:35,835 main.py:47] epoch 1750, training loss: 2380.63, average training loss: 2063.37, base loss: 2629.55
[INFO 2017-06-26 19:11:36,220 main.py:47] epoch 1751, training loss: 2159.34, average training loss: 2063.82, base loss: 2630.35
[INFO 2017-06-26 19:11:36,565 main.py:47] epoch 1752, training loss: 2039.72, average training loss: 2063.86, base loss: 2630.65
[INFO 2017-06-26 19:11:36,901 main.py:47] epoch 1753, training loss: 2027.06, average training loss: 2063.71, base loss: 2630.54
[INFO 2017-06-26 19:11:37,218 main.py:47] epoch 1754, training loss: 1981.02, average training loss: 2063.11, base loss: 2629.82
[INFO 2017-06-26 19:11:37,534 main.py:47] epoch 1755, training loss: 1907.79, average training loss: 2062.77, base loss: 2629.38
[INFO 2017-06-26 19:11:37,851 main.py:47] epoch 1756, training loss: 1868.37, average training loss: 2062.61, base loss: 2629.38
[INFO 2017-06-26 19:11:38,167 main.py:47] epoch 1757, training loss: 2117.29, average training loss: 2062.83, base loss: 2630.05
[INFO 2017-06-26 19:11:38,484 main.py:47] epoch 1758, training loss: 1943.46, average training loss: 2062.65, base loss: 2630.07
[INFO 2017-06-26 19:11:38,801 main.py:47] epoch 1759, training loss: 1928.93, average training loss: 2062.86, base loss: 2630.65
[INFO 2017-06-26 19:11:39,118 main.py:47] epoch 1760, training loss: 1754.46, average training loss: 2062.59, base loss: 2630.45
[INFO 2017-06-26 19:11:39,435 main.py:47] epoch 1761, training loss: 2037.52, average training loss: 2062.22, base loss: 2630.11
[INFO 2017-06-26 19:11:39,753 main.py:47] epoch 1762, training loss: 2113.43, average training loss: 2061.86, base loss: 2629.91
[INFO 2017-06-26 19:11:40,069 main.py:47] epoch 1763, training loss: 1835.70, average training loss: 2061.78, base loss: 2629.94
[INFO 2017-06-26 19:11:40,390 main.py:47] epoch 1764, training loss: 2006.53, average training loss: 2061.92, base loss: 2630.34
[INFO 2017-06-26 19:11:40,707 main.py:47] epoch 1765, training loss: 1944.37, average training loss: 2061.60, base loss: 2629.97
