[INFO 2017-06-15 15:14:25,739 main.py:112] Namespace(batch_size=32, display=False, image_size=11, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=5, save_dir='./model', test=False, test_epoch=100, test_interval=100, train=True, train_epoch=10000)
[INFO 2017-06-15 15:14:29,081 main.py:103] epoch 0, training loss: 29718.16, average training loss: 29718.16
[INFO 2017-06-15 15:14:30,294 main.py:103] epoch 1, training loss: 25106.96, average training loss: 27412.56
[INFO 2017-06-15 15:14:31,488 main.py:103] epoch 2, training loss: 23002.39, average training loss: 25942.50
[INFO 2017-06-15 15:14:32,650 main.py:103] epoch 3, training loss: 20056.62, average training loss: 24471.03
[INFO 2017-06-15 15:14:33,826 main.py:103] epoch 4, training loss: 18786.32, average training loss: 23334.09
[INFO 2017-06-15 15:14:34,989 main.py:103] epoch 5, training loss: 16947.80, average training loss: 22269.71
[INFO 2017-06-15 15:14:36,149 main.py:103] epoch 6, training loss: 15262.18, average training loss: 21268.63
[INFO 2017-06-15 15:14:37,319 main.py:103] epoch 7, training loss: 15136.96, average training loss: 20502.17
[INFO 2017-06-15 15:14:38,493 main.py:103] epoch 8, training loss: 14239.05, average training loss: 19806.27
[INFO 2017-06-15 15:14:39,659 main.py:103] epoch 9, training loss: 13795.29, average training loss: 19205.17
[INFO 2017-06-15 15:14:40,841 main.py:103] epoch 10, training loss: 12179.21, average training loss: 18566.45
[INFO 2017-06-15 15:14:42,008 main.py:103] epoch 11, training loss: 12594.71, average training loss: 18068.81
[INFO 2017-06-15 15:14:43,176 main.py:103] epoch 12, training loss: 12230.34, average training loss: 17619.69
[INFO 2017-06-15 15:14:44,354 main.py:103] epoch 13, training loss: 11697.70, average training loss: 17196.69
[INFO 2017-06-15 15:14:45,520 main.py:103] epoch 14, training loss: 11461.04, average training loss: 16814.32
[INFO 2017-06-15 15:14:46,694 main.py:103] epoch 15, training loss: 10104.75, average training loss: 16394.97
[INFO 2017-06-15 15:14:47,864 main.py:103] epoch 16, training loss: 9622.18, average training loss: 15996.57
[INFO 2017-06-15 15:14:49,031 main.py:103] epoch 17, training loss: 9455.06, average training loss: 15633.15
[INFO 2017-06-15 15:14:50,274 main.py:103] epoch 18, training loss: 10019.70, average training loss: 15337.71
[INFO 2017-06-15 15:14:51,741 main.py:103] epoch 19, training loss: 9702.61, average training loss: 15055.95
[INFO 2017-06-15 15:14:53,237 main.py:103] epoch 20, training loss: 10561.66, average training loss: 14841.94
[INFO 2017-06-15 15:14:54,732 main.py:103] epoch 21, training loss: 10119.04, average training loss: 14627.26
[INFO 2017-06-15 15:14:56,228 main.py:103] epoch 22, training loss: 8894.72, average training loss: 14378.02
[INFO 2017-06-15 15:14:57,724 main.py:103] epoch 23, training loss: 9520.01, average training loss: 14175.60
[INFO 2017-06-15 15:14:59,221 main.py:103] epoch 24, training loss: 9077.53, average training loss: 13971.68
[INFO 2017-06-15 15:15:00,717 main.py:103] epoch 25, training loss: 8988.94, average training loss: 13780.04
[INFO 2017-06-15 15:15:02,213 main.py:103] epoch 26, training loss: 8460.76, average training loss: 13583.03
[INFO 2017-06-15 15:15:03,709 main.py:103] epoch 27, training loss: 8955.14, average training loss: 13417.74
[INFO 2017-06-15 15:15:05,205 main.py:103] epoch 28, training loss: 8467.33, average training loss: 13247.04
[INFO 2017-06-15 15:15:06,702 main.py:103] epoch 29, training loss: 7882.00, average training loss: 13068.21
[INFO 2017-06-15 15:15:08,199 main.py:103] epoch 30, training loss: 8433.38, average training loss: 12918.70
[INFO 2017-06-15 15:15:09,696 main.py:103] epoch 31, training loss: 8940.27, average training loss: 12794.37
[INFO 2017-06-15 15:15:11,194 main.py:103] epoch 32, training loss: 8404.63, average training loss: 12661.35
[INFO 2017-06-15 15:15:12,689 main.py:103] epoch 33, training loss: 8090.24, average training loss: 12526.90
[INFO 2017-06-15 15:15:14,184 main.py:103] epoch 34, training loss: 7958.25, average training loss: 12396.37
[INFO 2017-06-15 15:15:15,683 main.py:103] epoch 35, training loss: 7893.33, average training loss: 12271.29
[INFO 2017-06-15 15:15:17,179 main.py:103] epoch 36, training loss: 9227.97, average training loss: 12189.03
[INFO 2017-06-15 15:15:18,676 main.py:103] epoch 37, training loss: 8227.73, average training loss: 12084.79
[INFO 2017-06-15 15:15:20,173 main.py:103] epoch 38, training loss: 7861.77, average training loss: 11976.51
[INFO 2017-06-15 15:15:21,669 main.py:103] epoch 39, training loss: 7867.50, average training loss: 11873.78
[INFO 2017-06-15 15:15:23,170 main.py:103] epoch 40, training loss: 7812.32, average training loss: 11774.72
[INFO 2017-06-15 15:15:24,666 main.py:103] epoch 41, training loss: 7834.39, average training loss: 11680.90
[INFO 2017-06-15 15:15:26,163 main.py:103] epoch 42, training loss: 8445.91, average training loss: 11605.67
[INFO 2017-06-15 15:15:27,662 main.py:103] epoch 43, training loss: 8049.33, average training loss: 11524.85
[INFO 2017-06-15 15:15:29,161 main.py:103] epoch 44, training loss: 9207.85, average training loss: 11473.36
[INFO 2017-06-15 15:15:30,658 main.py:103] epoch 45, training loss: 7846.52, average training loss: 11394.51
[INFO 2017-06-15 15:15:32,166 main.py:103] epoch 46, training loss: 8227.58, average training loss: 11327.13
[INFO 2017-06-15 15:15:33,663 main.py:103] epoch 47, training loss: 7485.83, average training loss: 11247.10
[INFO 2017-06-15 15:15:35,160 main.py:103] epoch 48, training loss: 8000.08, average training loss: 11180.84
[INFO 2017-06-15 15:15:36,655 main.py:103] epoch 49, training loss: 8117.98, average training loss: 11119.58
[INFO 2017-06-15 15:15:38,157 main.py:103] epoch 50, training loss: 9179.68, average training loss: 11081.54
[INFO 2017-06-15 15:15:39,655 main.py:103] epoch 51, training loss: 9366.84, average training loss: 11048.57
[INFO 2017-06-15 15:15:41,152 main.py:103] epoch 52, training loss: 7698.17, average training loss: 10985.35
[INFO 2017-06-15 15:15:42,649 main.py:103] epoch 53, training loss: 7885.86, average training loss: 10927.96
[INFO 2017-06-15 15:15:44,146 main.py:103] epoch 54, training loss: 8243.60, average training loss: 10879.15
[INFO 2017-06-15 15:15:45,642 main.py:103] epoch 55, training loss: 8296.16, average training loss: 10833.02
[INFO 2017-06-15 15:15:47,139 main.py:103] epoch 56, training loss: 7862.04, average training loss: 10780.90
[INFO 2017-06-15 15:15:48,637 main.py:103] epoch 57, training loss: 8103.69, average training loss: 10734.74
[INFO 2017-06-15 15:15:50,138 main.py:103] epoch 58, training loss: 7800.66, average training loss: 10685.01
[INFO 2017-06-15 15:15:51,667 main.py:103] epoch 59, training loss: 8329.17, average training loss: 10645.75
[INFO 2017-06-15 15:15:53,185 main.py:103] epoch 60, training loss: 7408.44, average training loss: 10592.68
[INFO 2017-06-15 15:15:54,682 main.py:103] epoch 61, training loss: 8178.27, average training loss: 10553.74
[INFO 2017-06-15 15:15:56,180 main.py:103] epoch 62, training loss: 8329.00, average training loss: 10518.42
[INFO 2017-06-15 15:15:57,677 main.py:103] epoch 63, training loss: 8553.44, average training loss: 10487.72
[INFO 2017-06-15 15:15:59,177 main.py:103] epoch 64, training loss: 7803.42, average training loss: 10446.42
[INFO 2017-06-15 15:16:00,678 main.py:103] epoch 65, training loss: 8224.20, average training loss: 10412.75
[INFO 2017-06-15 15:16:02,176 main.py:103] epoch 66, training loss: 7894.74, average training loss: 10375.17
[INFO 2017-06-15 15:16:03,673 main.py:103] epoch 67, training loss: 7958.76, average training loss: 10339.63
[INFO 2017-06-15 15:16:05,172 main.py:103] epoch 68, training loss: 7863.79, average training loss: 10303.75
[INFO 2017-06-15 15:16:06,671 main.py:103] epoch 69, training loss: 8010.99, average training loss: 10271.00
[INFO 2017-06-15 15:16:08,178 main.py:103] epoch 70, training loss: 7434.53, average training loss: 10231.05
[INFO 2017-06-15 15:16:09,678 main.py:103] epoch 71, training loss: 7775.98, average training loss: 10196.95
[INFO 2017-06-15 15:16:11,177 main.py:103] epoch 72, training loss: 7855.21, average training loss: 10164.87
[INFO 2017-06-15 15:16:12,676 main.py:103] epoch 73, training loss: 8111.63, average training loss: 10137.13
[INFO 2017-06-15 15:16:14,174 main.py:103] epoch 74, training loss: 6816.47, average training loss: 10092.85
[INFO 2017-06-15 15:16:15,676 main.py:103] epoch 75, training loss: 7871.50, average training loss: 10063.62
[INFO 2017-06-15 15:16:17,175 main.py:103] epoch 76, training loss: 8212.39, average training loss: 10039.58
[INFO 2017-06-15 15:16:18,682 main.py:103] epoch 77, training loss: 8198.15, average training loss: 10015.97
[INFO 2017-06-15 15:16:20,199 main.py:103] epoch 78, training loss: 8054.98, average training loss: 9991.15
[INFO 2017-06-15 15:16:21,698 main.py:103] epoch 79, training loss: 7704.46, average training loss: 9962.57
[INFO 2017-06-15 15:16:23,207 main.py:103] epoch 80, training loss: 6812.39, average training loss: 9923.67
[INFO 2017-06-15 15:16:24,704 main.py:103] epoch 81, training loss: 8125.21, average training loss: 9901.74
[INFO 2017-06-15 15:16:26,202 main.py:103] epoch 82, training loss: 8541.99, average training loss: 9885.36
[INFO 2017-06-15 15:16:27,699 main.py:103] epoch 83, training loss: 7613.89, average training loss: 9858.32
[INFO 2017-06-15 15:16:29,195 main.py:103] epoch 84, training loss: 7802.74, average training loss: 9834.13
[INFO 2017-06-15 15:16:30,692 main.py:103] epoch 85, training loss: 7253.08, average training loss: 9804.12
[INFO 2017-06-15 15:16:32,187 main.py:103] epoch 86, training loss: 8166.46, average training loss: 9785.30
[INFO 2017-06-15 15:16:33,682 main.py:103] epoch 87, training loss: 7973.17, average training loss: 9764.71
[INFO 2017-06-15 15:16:35,177 main.py:103] epoch 88, training loss: 8598.56, average training loss: 9751.60
[INFO 2017-06-15 15:16:36,673 main.py:103] epoch 89, training loss: 7815.92, average training loss: 9730.10
[INFO 2017-06-15 15:16:38,168 main.py:103] epoch 90, training loss: 7145.14, average training loss: 9701.69
[INFO 2017-06-15 15:16:39,664 main.py:103] epoch 91, training loss: 8198.80, average training loss: 9685.35
[INFO 2017-06-15 15:16:41,159 main.py:103] epoch 92, training loss: 6889.91, average training loss: 9655.30
[INFO 2017-06-15 15:16:42,656 main.py:103] epoch 93, training loss: 7250.69, average training loss: 9629.71
[INFO 2017-06-15 15:16:44,151 main.py:103] epoch 94, training loss: 7945.79, average training loss: 9611.99
[INFO 2017-06-15 15:16:45,648 main.py:103] epoch 95, training loss: 7105.35, average training loss: 9585.88
[INFO 2017-06-15 15:16:47,147 main.py:103] epoch 96, training loss: 9196.68, average training loss: 9581.87
[INFO 2017-06-15 15:16:48,644 main.py:103] epoch 97, training loss: 8556.84, average training loss: 9571.41
[INFO 2017-06-15 15:16:50,142 main.py:103] epoch 98, training loss: 7732.32, average training loss: 9552.83
[INFO 2017-06-15 15:16:51,641 main.py:103] epoch 99, training loss: 7530.87, average training loss: 9532.61
[INFO 2017-06-15 15:16:51,641 main.py:105] epoch 99, testing
[INFO 2017-06-15 15:18:07,224 main.py:54] average testing loss: 7652.69
[INFO 2017-06-15 15:18:07,228 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:18:07,236 main.py:25] current best accuracy: 7652.69
[INFO 2017-06-15 15:18:08,731 main.py:103] epoch 100, training loss: 7291.35, average training loss: 9510.42
[INFO 2017-06-15 15:18:10,228 main.py:103] epoch 101, training loss: 6899.50, average training loss: 9484.82
[INFO 2017-06-15 15:18:11,725 main.py:103] epoch 102, training loss: 6998.68, average training loss: 9460.69
[INFO 2017-06-15 15:18:13,226 main.py:103] epoch 103, training loss: 9052.48, average training loss: 9456.76
[INFO 2017-06-15 15:18:14,725 main.py:103] epoch 104, training loss: 7514.82, average training loss: 9438.27
[INFO 2017-06-15 15:18:16,226 main.py:103] epoch 105, training loss: 7693.72, average training loss: 9421.81
[INFO 2017-06-15 15:18:17,725 main.py:103] epoch 106, training loss: 7493.16, average training loss: 9403.78
[INFO 2017-06-15 15:18:19,229 main.py:103] epoch 107, training loss: 8041.72, average training loss: 9391.17
[INFO 2017-06-15 15:18:20,729 main.py:103] epoch 108, training loss: 6929.20, average training loss: 9368.58
[INFO 2017-06-15 15:18:22,227 main.py:103] epoch 109, training loss: 8350.14, average training loss: 9359.33
[INFO 2017-06-15 15:18:23,725 main.py:103] epoch 110, training loss: 7359.51, average training loss: 9341.31
[INFO 2017-06-15 15:18:25,223 main.py:103] epoch 111, training loss: 7677.76, average training loss: 9326.46
[INFO 2017-06-15 15:18:26,742 main.py:103] epoch 112, training loss: 7287.51, average training loss: 9308.41
[INFO 2017-06-15 15:18:28,239 main.py:103] epoch 113, training loss: 7001.97, average training loss: 9288.18
[INFO 2017-06-15 15:18:29,737 main.py:103] epoch 114, training loss: 7788.88, average training loss: 9275.14
[INFO 2017-06-15 15:18:31,233 main.py:103] epoch 115, training loss: 8283.54, average training loss: 9266.59
[INFO 2017-06-15 15:18:32,731 main.py:103] epoch 116, training loss: 7753.75, average training loss: 9253.66
[INFO 2017-06-15 15:18:34,229 main.py:103] epoch 117, training loss: 7299.87, average training loss: 9237.11
[INFO 2017-06-15 15:18:35,727 main.py:103] epoch 118, training loss: 7898.10, average training loss: 9225.85
[INFO 2017-06-15 15:18:37,224 main.py:103] epoch 119, training loss: 7254.24, average training loss: 9209.42
[INFO 2017-06-15 15:18:38,725 main.py:103] epoch 120, training loss: 6844.66, average training loss: 9189.88
[INFO 2017-06-15 15:18:40,227 main.py:103] epoch 121, training loss: 7515.22, average training loss: 9176.15
[INFO 2017-06-15 15:18:41,728 main.py:103] epoch 122, training loss: 7324.70, average training loss: 9161.10
[INFO 2017-06-15 15:18:43,229 main.py:103] epoch 123, training loss: 8293.51, average training loss: 9154.11
[INFO 2017-06-15 15:18:44,747 main.py:103] epoch 124, training loss: 6918.44, average training loss: 9136.22
[INFO 2017-06-15 15:18:46,250 main.py:103] epoch 125, training loss: 7165.78, average training loss: 9120.58
[INFO 2017-06-15 15:18:47,748 main.py:103] epoch 126, training loss: 6928.30, average training loss: 9103.32
[INFO 2017-06-15 15:18:49,255 main.py:103] epoch 127, training loss: 6714.36, average training loss: 9084.66
[INFO 2017-06-15 15:18:50,758 main.py:103] epoch 128, training loss: 7385.45, average training loss: 9071.48
[INFO 2017-06-15 15:18:52,265 main.py:103] epoch 129, training loss: 7678.39, average training loss: 9060.77
[INFO 2017-06-15 15:18:53,766 main.py:103] epoch 130, training loss: 7128.65, average training loss: 9046.02
[INFO 2017-06-15 15:18:55,267 main.py:103] epoch 131, training loss: 7395.24, average training loss: 9033.51
[INFO 2017-06-15 15:18:56,769 main.py:103] epoch 132, training loss: 7666.41, average training loss: 9023.23
[INFO 2017-06-15 15:18:58,269 main.py:103] epoch 133, training loss: 7296.36, average training loss: 9010.35
[INFO 2017-06-15 15:18:59,769 main.py:103] epoch 134, training loss: 7688.78, average training loss: 9000.56
[INFO 2017-06-15 15:19:01,269 main.py:103] epoch 135, training loss: 6956.87, average training loss: 8985.53
[INFO 2017-06-15 15:19:02,768 main.py:103] epoch 136, training loss: 6943.29, average training loss: 8970.62
[INFO 2017-06-15 15:19:04,268 main.py:103] epoch 137, training loss: 7382.64, average training loss: 8959.12
[INFO 2017-06-15 15:19:05,768 main.py:103] epoch 138, training loss: 8224.06, average training loss: 8953.83
[INFO 2017-06-15 15:19:07,268 main.py:103] epoch 139, training loss: 7518.86, average training loss: 8943.58
[INFO 2017-06-15 15:19:08,767 main.py:103] epoch 140, training loss: 7398.85, average training loss: 8932.62
[INFO 2017-06-15 15:19:10,266 main.py:103] epoch 141, training loss: 7212.79, average training loss: 8920.51
[INFO 2017-06-15 15:19:11,766 main.py:103] epoch 142, training loss: 8282.81, average training loss: 8916.05
[INFO 2017-06-15 15:19:13,266 main.py:103] epoch 143, training loss: 7204.59, average training loss: 8904.17
[INFO 2017-06-15 15:19:14,766 main.py:103] epoch 144, training loss: 7166.40, average training loss: 8892.18
[INFO 2017-06-15 15:19:16,266 main.py:103] epoch 145, training loss: 7758.25, average training loss: 8884.41
[INFO 2017-06-15 15:19:17,766 main.py:103] epoch 146, training loss: 8505.09, average training loss: 8881.83
[INFO 2017-06-15 15:19:19,266 main.py:103] epoch 147, training loss: 7388.29, average training loss: 8871.74
[INFO 2017-06-15 15:19:20,766 main.py:103] epoch 148, training loss: 7664.55, average training loss: 8863.64
[INFO 2017-06-15 15:19:22,265 main.py:103] epoch 149, training loss: 6782.20, average training loss: 8849.76
[INFO 2017-06-15 15:19:23,765 main.py:103] epoch 150, training loss: 7689.95, average training loss: 8842.08
[INFO 2017-06-15 15:19:25,264 main.py:103] epoch 151, training loss: 6825.22, average training loss: 8828.82
[INFO 2017-06-15 15:19:26,764 main.py:103] epoch 152, training loss: 7256.84, average training loss: 8818.54
[INFO 2017-06-15 15:19:28,265 main.py:103] epoch 153, training loss: 7788.78, average training loss: 8811.85
[INFO 2017-06-15 15:19:29,766 main.py:103] epoch 154, training loss: 7981.57, average training loss: 8806.50
[INFO 2017-06-15 15:19:31,263 main.py:103] epoch 155, training loss: 7942.75, average training loss: 8800.96
[INFO 2017-06-15 15:19:32,760 main.py:103] epoch 156, training loss: 6858.93, average training loss: 8788.59
[INFO 2017-06-15 15:19:34,258 main.py:103] epoch 157, training loss: 7209.26, average training loss: 8778.60
[INFO 2017-06-15 15:19:35,756 main.py:103] epoch 158, training loss: 6976.69, average training loss: 8767.26
[INFO 2017-06-15 15:19:37,256 main.py:103] epoch 159, training loss: 7045.48, average training loss: 8756.50
[INFO 2017-06-15 15:19:38,754 main.py:103] epoch 160, training loss: 7367.41, average training loss: 8747.87
[INFO 2017-06-15 15:19:40,252 main.py:103] epoch 161, training loss: 7139.17, average training loss: 8737.94
[INFO 2017-06-15 15:19:41,754 main.py:103] epoch 162, training loss: 7511.19, average training loss: 8730.42
[INFO 2017-06-15 15:19:43,251 main.py:103] epoch 163, training loss: 6896.05, average training loss: 8719.23
[INFO 2017-06-15 15:19:44,748 main.py:103] epoch 164, training loss: 7383.76, average training loss: 8711.14
[INFO 2017-06-15 15:19:46,244 main.py:103] epoch 165, training loss: 7174.03, average training loss: 8701.88
[INFO 2017-06-15 15:19:47,743 main.py:103] epoch 166, training loss: 7237.94, average training loss: 8693.11
[INFO 2017-06-15 15:19:49,241 main.py:103] epoch 167, training loss: 7202.98, average training loss: 8684.24
[INFO 2017-06-15 15:19:50,738 main.py:103] epoch 168, training loss: 7186.16, average training loss: 8675.38
[INFO 2017-06-15 15:19:52,236 main.py:103] epoch 169, training loss: 7162.46, average training loss: 8666.48
[INFO 2017-06-15 15:19:53,733 main.py:103] epoch 170, training loss: 7902.27, average training loss: 8662.01
[INFO 2017-06-15 15:19:55,231 main.py:103] epoch 171, training loss: 7624.87, average training loss: 8655.98
[INFO 2017-06-15 15:19:56,728 main.py:103] epoch 172, training loss: 7523.37, average training loss: 8649.43
[INFO 2017-06-15 15:19:58,224 main.py:103] epoch 173, training loss: 6904.09, average training loss: 8639.40
[INFO 2017-06-15 15:19:59,721 main.py:103] epoch 174, training loss: 6711.41, average training loss: 8628.38
[INFO 2017-06-15 15:20:01,217 main.py:103] epoch 175, training loss: 7158.04, average training loss: 8620.03
[INFO 2017-06-15 15:20:02,714 main.py:103] epoch 176, training loss: 7711.13, average training loss: 8614.90
[INFO 2017-06-15 15:20:04,211 main.py:103] epoch 177, training loss: 7068.33, average training loss: 8606.21
[INFO 2017-06-15 15:20:05,708 main.py:103] epoch 178, training loss: 7454.01, average training loss: 8599.77
[INFO 2017-06-15 15:20:07,204 main.py:103] epoch 179, training loss: 7138.97, average training loss: 8591.65
[INFO 2017-06-15 15:20:08,699 main.py:103] epoch 180, training loss: 7294.14, average training loss: 8584.49
[INFO 2017-06-15 15:20:10,197 main.py:103] epoch 181, training loss: 7542.82, average training loss: 8578.76
[INFO 2017-06-15 15:20:11,693 main.py:103] epoch 182, training loss: 7338.00, average training loss: 8571.98
[INFO 2017-06-15 15:20:13,190 main.py:103] epoch 183, training loss: 7192.42, average training loss: 8564.48
[INFO 2017-06-15 15:20:14,688 main.py:103] epoch 184, training loss: 7014.66, average training loss: 8556.11
[INFO 2017-06-15 15:20:16,185 main.py:103] epoch 185, training loss: 7818.57, average training loss: 8552.14
[INFO 2017-06-15 15:20:17,682 main.py:103] epoch 186, training loss: 7604.23, average training loss: 8547.07
[INFO 2017-06-15 15:20:19,179 main.py:103] epoch 187, training loss: 7009.94, average training loss: 8538.90
[INFO 2017-06-15 15:20:20,676 main.py:103] epoch 188, training loss: 7117.45, average training loss: 8531.38
[INFO 2017-06-15 15:20:22,172 main.py:103] epoch 189, training loss: 6850.31, average training loss: 8522.53
[INFO 2017-06-15 15:20:23,669 main.py:103] epoch 190, training loss: 7325.80, average training loss: 8516.26
[INFO 2017-06-15 15:20:25,167 main.py:103] epoch 191, training loss: 7171.15, average training loss: 8509.26
[INFO 2017-06-15 15:20:26,664 main.py:103] epoch 192, training loss: 6775.04, average training loss: 8500.27
[INFO 2017-06-15 15:20:28,165 main.py:103] epoch 193, training loss: 7397.25, average training loss: 8494.59
[INFO 2017-06-15 15:20:29,663 main.py:103] epoch 194, training loss: 6922.13, average training loss: 8486.52
[INFO 2017-06-15 15:20:31,161 main.py:103] epoch 195, training loss: 7608.96, average training loss: 8482.04
[INFO 2017-06-15 15:20:32,658 main.py:103] epoch 196, training loss: 7513.34, average training loss: 8477.13
[INFO 2017-06-15 15:20:34,155 main.py:103] epoch 197, training loss: 6616.00, average training loss: 8467.73
[INFO 2017-06-15 15:20:35,657 main.py:103] epoch 198, training loss: 7570.57, average training loss: 8463.22
[INFO 2017-06-15 15:20:37,158 main.py:103] epoch 199, training loss: 6869.39, average training loss: 8455.25
[INFO 2017-06-15 15:20:37,159 main.py:105] epoch 199, testing
[INFO 2017-06-15 15:21:53,773 main.py:54] average testing loss: 7243.50
[INFO 2017-06-15 15:21:53,777 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:21:53,786 main.py:25] current best accuracy: 7243.50
[INFO 2017-06-15 15:21:55,288 main.py:103] epoch 200, training loss: 7446.13, average training loss: 8450.23
[INFO 2017-06-15 15:21:56,788 main.py:103] epoch 201, training loss: 8154.21, average training loss: 8448.76
[INFO 2017-06-15 15:21:58,291 main.py:103] epoch 202, training loss: 6483.32, average training loss: 8439.08
[INFO 2017-06-15 15:21:59,790 main.py:103] epoch 203, training loss: 8195.53, average training loss: 8437.89
[INFO 2017-06-15 15:22:01,292 main.py:103] epoch 204, training loss: 7271.21, average training loss: 8432.20
[INFO 2017-06-15 15:22:02,791 main.py:103] epoch 205, training loss: 7013.59, average training loss: 8425.31
[INFO 2017-06-15 15:22:04,290 main.py:103] epoch 206, training loss: 7143.85, average training loss: 8419.12
[INFO 2017-06-15 15:22:05,789 main.py:103] epoch 207, training loss: 7432.83, average training loss: 8414.38
[INFO 2017-06-15 15:22:07,327 main.py:103] epoch 208, training loss: 8073.86, average training loss: 8412.75
[INFO 2017-06-15 15:22:08,833 main.py:103] epoch 209, training loss: 7487.57, average training loss: 8408.34
[INFO 2017-06-15 15:22:10,373 main.py:103] epoch 210, training loss: 6523.12, average training loss: 8399.41
[INFO 2017-06-15 15:22:11,876 main.py:103] epoch 211, training loss: 6726.29, average training loss: 8391.52
[INFO 2017-06-15 15:22:13,377 main.py:103] epoch 212, training loss: 7594.57, average training loss: 8387.78
[INFO 2017-06-15 15:22:14,879 main.py:103] epoch 213, training loss: 7188.96, average training loss: 8382.17
[INFO 2017-06-15 15:22:16,378 main.py:103] epoch 214, training loss: 7660.53, average training loss: 8378.82
[INFO 2017-06-15 15:22:17,878 main.py:103] epoch 215, training loss: 6574.94, average training loss: 8370.47
[INFO 2017-06-15 15:22:19,378 main.py:103] epoch 216, training loss: 7258.45, average training loss: 8365.34
[INFO 2017-06-15 15:22:20,878 main.py:103] epoch 217, training loss: 7949.78, average training loss: 8363.43
[INFO 2017-06-15 15:22:22,379 main.py:103] epoch 218, training loss: 6447.33, average training loss: 8354.69
[INFO 2017-06-15 15:22:23,879 main.py:103] epoch 219, training loss: 7095.80, average training loss: 8348.96
[INFO 2017-06-15 15:22:25,377 main.py:103] epoch 220, training loss: 7116.24, average training loss: 8343.39
[INFO 2017-06-15 15:22:26,877 main.py:103] epoch 221, training loss: 6239.25, average training loss: 8333.91
[INFO 2017-06-15 15:22:28,374 main.py:103] epoch 222, training loss: 7242.57, average training loss: 8329.01
[INFO 2017-06-15 15:22:29,874 main.py:103] epoch 223, training loss: 6770.75, average training loss: 8322.06
[INFO 2017-06-15 15:22:31,375 main.py:103] epoch 224, training loss: 7552.00, average training loss: 8318.63
[INFO 2017-06-15 15:22:32,877 main.py:103] epoch 225, training loss: 6852.70, average training loss: 8312.15
[INFO 2017-06-15 15:22:34,381 main.py:103] epoch 226, training loss: 6339.35, average training loss: 8303.46
[INFO 2017-06-15 15:22:35,883 main.py:103] epoch 227, training loss: 6789.52, average training loss: 8296.82
[INFO 2017-06-15 15:22:37,385 main.py:103] epoch 228, training loss: 6997.93, average training loss: 8291.14
[INFO 2017-06-15 15:22:38,910 main.py:103] epoch 229, training loss: 6506.84, average training loss: 8283.39
[INFO 2017-06-15 15:22:40,411 main.py:103] epoch 230, training loss: 6796.56, average training loss: 8276.95
[INFO 2017-06-15 15:22:41,914 main.py:103] epoch 231, training loss: 7740.20, average training loss: 8274.64
[INFO 2017-06-15 15:22:43,418 main.py:103] epoch 232, training loss: 7943.44, average training loss: 8273.22
[INFO 2017-06-15 15:22:44,920 main.py:103] epoch 233, training loss: 7037.44, average training loss: 8267.93
[INFO 2017-06-15 15:22:46,422 main.py:103] epoch 234, training loss: 7764.85, average training loss: 8265.79
[INFO 2017-06-15 15:22:47,924 main.py:103] epoch 235, training loss: 7741.48, average training loss: 8263.57
[INFO 2017-06-15 15:22:49,460 main.py:103] epoch 236, training loss: 6727.33, average training loss: 8257.09
[INFO 2017-06-15 15:22:50,986 main.py:103] epoch 237, training loss: 6949.96, average training loss: 8251.60
[INFO 2017-06-15 15:22:52,511 main.py:103] epoch 238, training loss: 7672.61, average training loss: 8249.18
[INFO 2017-06-15 15:22:54,032 main.py:103] epoch 239, training loss: 6493.65, average training loss: 8241.86
[INFO 2017-06-15 15:22:55,533 main.py:103] epoch 240, training loss: 7396.37, average training loss: 8238.35
[INFO 2017-06-15 15:22:57,034 main.py:103] epoch 241, training loss: 6979.13, average training loss: 8233.15
[INFO 2017-06-15 15:22:58,537 main.py:103] epoch 242, training loss: 7940.91, average training loss: 8231.95
[INFO 2017-06-15 15:23:00,037 main.py:103] epoch 243, training loss: 7869.34, average training loss: 8230.46
[INFO 2017-06-15 15:23:01,540 main.py:103] epoch 244, training loss: 7037.91, average training loss: 8225.59
[INFO 2017-06-15 15:23:03,040 main.py:103] epoch 245, training loss: 6733.46, average training loss: 8219.53
[INFO 2017-06-15 15:23:04,540 main.py:103] epoch 246, training loss: 6716.37, average training loss: 8213.44
[INFO 2017-06-15 15:23:06,040 main.py:103] epoch 247, training loss: 7023.92, average training loss: 8208.65
[INFO 2017-06-15 15:23:07,540 main.py:103] epoch 248, training loss: 7116.33, average training loss: 8204.26
[INFO 2017-06-15 15:23:09,041 main.py:103] epoch 249, training loss: 6696.78, average training loss: 8198.23
[INFO 2017-06-15 15:23:10,541 main.py:103] epoch 250, training loss: 7421.34, average training loss: 8195.13
[INFO 2017-06-15 15:23:12,042 main.py:103] epoch 251, training loss: 7523.67, average training loss: 8192.47
[INFO 2017-06-15 15:23:13,543 main.py:103] epoch 252, training loss: 6436.01, average training loss: 8185.53
[INFO 2017-06-15 15:23:15,043 main.py:103] epoch 253, training loss: 7516.04, average training loss: 8182.89
[INFO 2017-06-15 15:23:16,542 main.py:103] epoch 254, training loss: 7540.03, average training loss: 8180.37
[INFO 2017-06-15 15:23:18,042 main.py:103] epoch 255, training loss: 7205.70, average training loss: 8176.56
[INFO 2017-06-15 15:23:19,542 main.py:103] epoch 256, training loss: 7730.21, average training loss: 8174.83
[INFO 2017-06-15 15:23:21,055 main.py:103] epoch 257, training loss: 6887.96, average training loss: 8169.84
[INFO 2017-06-15 15:23:22,593 main.py:103] epoch 258, training loss: 6863.74, average training loss: 8164.79
[INFO 2017-06-15 15:23:24,132 main.py:103] epoch 259, training loss: 7001.23, average training loss: 8160.32
[INFO 2017-06-15 15:23:25,634 main.py:103] epoch 260, training loss: 6485.41, average training loss: 8153.90
[INFO 2017-06-15 15:23:27,155 main.py:103] epoch 261, training loss: 7204.62, average training loss: 8150.28
[INFO 2017-06-15 15:23:28,654 main.py:103] epoch 262, training loss: 7137.43, average training loss: 8146.43
[INFO 2017-06-15 15:23:30,175 main.py:103] epoch 263, training loss: 7735.97, average training loss: 8144.87
[INFO 2017-06-15 15:23:31,677 main.py:103] epoch 264, training loss: 6597.28, average training loss: 8139.03
[INFO 2017-06-15 15:23:33,176 main.py:103] epoch 265, training loss: 6966.75, average training loss: 8134.63
[INFO 2017-06-15 15:23:34,681 main.py:103] epoch 266, training loss: 6939.26, average training loss: 8130.15
[INFO 2017-06-15 15:23:36,181 main.py:103] epoch 267, training loss: 7371.94, average training loss: 8127.32
[INFO 2017-06-15 15:23:37,679 main.py:103] epoch 268, training loss: 7890.55, average training loss: 8126.44
[INFO 2017-06-15 15:23:39,179 main.py:103] epoch 269, training loss: 6602.60, average training loss: 8120.80
[INFO 2017-06-15 15:23:40,678 main.py:103] epoch 270, training loss: 7485.22, average training loss: 8118.45
[INFO 2017-06-15 15:23:42,178 main.py:103] epoch 271, training loss: 7030.70, average training loss: 8114.45
[INFO 2017-06-15 15:23:43,678 main.py:103] epoch 272, training loss: 6501.61, average training loss: 8108.54
[INFO 2017-06-15 15:23:45,178 main.py:103] epoch 273, training loss: 6408.69, average training loss: 8102.34
[INFO 2017-06-15 15:23:46,678 main.py:103] epoch 274, training loss: 6193.93, average training loss: 8095.40
[INFO 2017-06-15 15:23:48,180 main.py:103] epoch 275, training loss: 7663.57, average training loss: 8093.84
[INFO 2017-06-15 15:23:49,679 main.py:103] epoch 276, training loss: 7207.91, average training loss: 8090.64
[INFO 2017-06-15 15:23:51,179 main.py:103] epoch 277, training loss: 6629.08, average training loss: 8085.38
[INFO 2017-06-15 15:23:52,681 main.py:103] epoch 278, training loss: 7616.91, average training loss: 8083.70
[INFO 2017-06-15 15:23:54,181 main.py:103] epoch 279, training loss: 7273.04, average training loss: 8080.81
[INFO 2017-06-15 15:23:55,679 main.py:103] epoch 280, training loss: 7435.19, average training loss: 8078.51
[INFO 2017-06-15 15:23:57,180 main.py:103] epoch 281, training loss: 6800.02, average training loss: 8073.97
[INFO 2017-06-15 15:23:58,680 main.py:103] epoch 282, training loss: 7607.28, average training loss: 8072.33
[INFO 2017-06-15 15:24:00,221 main.py:103] epoch 283, training loss: 7354.89, average training loss: 8069.80
[INFO 2017-06-15 15:24:01,724 main.py:103] epoch 284, training loss: 6866.46, average training loss: 8065.58
[INFO 2017-06-15 15:24:03,264 main.py:103] epoch 285, training loss: 7329.94, average training loss: 8063.00
[INFO 2017-06-15 15:24:04,786 main.py:103] epoch 286, training loss: 7079.51, average training loss: 8059.58
[INFO 2017-06-15 15:24:06,289 main.py:103] epoch 287, training loss: 7274.31, average training loss: 8056.85
[INFO 2017-06-15 15:24:07,797 main.py:103] epoch 288, training loss: 7403.27, average training loss: 8054.59
[INFO 2017-06-15 15:24:09,310 main.py:103] epoch 289, training loss: 6510.51, average training loss: 8049.27
[INFO 2017-06-15 15:24:10,812 main.py:103] epoch 290, training loss: 6444.92, average training loss: 8043.75
[INFO 2017-06-15 15:24:12,314 main.py:103] epoch 291, training loss: 7095.31, average training loss: 8040.50
[INFO 2017-06-15 15:24:13,812 main.py:103] epoch 292, training loss: 7740.61, average training loss: 8039.48
[INFO 2017-06-15 15:24:15,313 main.py:103] epoch 293, training loss: 6345.00, average training loss: 8033.72
[INFO 2017-06-15 15:24:16,839 main.py:103] epoch 294, training loss: 7205.98, average training loss: 8030.91
[INFO 2017-06-15 15:24:18,339 main.py:103] epoch 295, training loss: 7208.02, average training loss: 8028.13
[INFO 2017-06-15 15:24:19,838 main.py:103] epoch 296, training loss: 7609.81, average training loss: 8026.72
[INFO 2017-06-15 15:24:21,343 main.py:103] epoch 297, training loss: 6753.57, average training loss: 8022.45
[INFO 2017-06-15 15:24:22,846 main.py:103] epoch 298, training loss: 7104.85, average training loss: 8019.38
[INFO 2017-06-15 15:24:24,351 main.py:103] epoch 299, training loss: 6844.66, average training loss: 8015.47
[INFO 2017-06-15 15:24:24,351 main.py:105] epoch 299, testing
[INFO 2017-06-15 15:25:40,286 main.py:54] average testing loss: 7111.50
[INFO 2017-06-15 15:25:40,289 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:25:40,297 main.py:25] current best accuracy: 7111.50
[INFO 2017-06-15 15:25:41,794 main.py:103] epoch 300, training loss: 7121.29, average training loss: 8012.49
[INFO 2017-06-15 15:25:43,296 main.py:103] epoch 301, training loss: 7424.12, average training loss: 8010.55
[INFO 2017-06-15 15:25:44,797 main.py:103] epoch 302, training loss: 6462.81, average training loss: 8005.44
[INFO 2017-06-15 15:25:46,296 main.py:103] epoch 303, training loss: 7531.08, average training loss: 8003.88
[INFO 2017-06-15 15:25:47,798 main.py:103] epoch 304, training loss: 7239.69, average training loss: 8001.37
[INFO 2017-06-15 15:25:49,306 main.py:103] epoch 305, training loss: 6996.70, average training loss: 7998.09
[INFO 2017-06-15 15:25:50,809 main.py:103] epoch 306, training loss: 7255.44, average training loss: 7995.67
[INFO 2017-06-15 15:25:52,328 main.py:103] epoch 307, training loss: 6280.79, average training loss: 7990.10
[INFO 2017-06-15 15:25:53,830 main.py:103] epoch 308, training loss: 7000.94, average training loss: 7986.90
[INFO 2017-06-15 15:25:55,339 main.py:103] epoch 309, training loss: 6723.52, average training loss: 7982.83
[INFO 2017-06-15 15:25:56,845 main.py:103] epoch 310, training loss: 7574.79, average training loss: 7981.51
[INFO 2017-06-15 15:25:58,353 main.py:103] epoch 311, training loss: 7026.01, average training loss: 7978.45
[INFO 2017-06-15 15:25:59,854 main.py:103] epoch 312, training loss: 6252.07, average training loss: 7972.94
[INFO 2017-06-15 15:26:01,354 main.py:103] epoch 313, training loss: 6732.12, average training loss: 7968.98
[INFO 2017-06-15 15:26:02,857 main.py:103] epoch 314, training loss: 7508.27, average training loss: 7967.52
[INFO 2017-06-15 15:26:04,360 main.py:103] epoch 315, training loss: 7029.01, average training loss: 7964.55
[INFO 2017-06-15 15:26:05,876 main.py:103] epoch 316, training loss: 6600.74, average training loss: 7960.25
[INFO 2017-06-15 15:26:07,375 main.py:103] epoch 317, training loss: 6861.25, average training loss: 7956.79
[INFO 2017-06-15 15:26:08,892 main.py:103] epoch 318, training loss: 6996.67, average training loss: 7953.78
[INFO 2017-06-15 15:26:10,395 main.py:103] epoch 319, training loss: 6769.87, average training loss: 7950.08
[INFO 2017-06-15 15:26:11,894 main.py:103] epoch 320, training loss: 6747.54, average training loss: 7946.34
[INFO 2017-06-15 15:26:13,404 main.py:103] epoch 321, training loss: 7637.90, average training loss: 7945.38
[INFO 2017-06-15 15:26:14,906 main.py:103] epoch 322, training loss: 7692.49, average training loss: 7944.60
[INFO 2017-06-15 15:26:16,406 main.py:103] epoch 323, training loss: 6593.23, average training loss: 7940.43
[INFO 2017-06-15 15:26:17,906 main.py:103] epoch 324, training loss: 6720.56, average training loss: 7936.67
[INFO 2017-06-15 15:26:19,406 main.py:103] epoch 325, training loss: 6607.64, average training loss: 7932.60
[INFO 2017-06-15 15:26:20,906 main.py:103] epoch 326, training loss: 7097.49, average training loss: 7930.04
[INFO 2017-06-15 15:26:22,406 main.py:103] epoch 327, training loss: 6170.64, average training loss: 7924.68
[INFO 2017-06-15 15:26:23,906 main.py:103] epoch 328, training loss: 7403.97, average training loss: 7923.09
[INFO 2017-06-15 15:26:25,406 main.py:103] epoch 329, training loss: 7399.86, average training loss: 7921.51
[INFO 2017-06-15 15:26:26,906 main.py:103] epoch 330, training loss: 7238.36, average training loss: 7919.45
[INFO 2017-06-15 15:26:28,404 main.py:103] epoch 331, training loss: 6015.56, average training loss: 7913.71
[INFO 2017-06-15 15:26:29,905 main.py:103] epoch 332, training loss: 7302.34, average training loss: 7911.87
[INFO 2017-06-15 15:26:31,405 main.py:103] epoch 333, training loss: 6762.95, average training loss: 7908.44
[INFO 2017-06-15 15:26:32,906 main.py:103] epoch 334, training loss: 6644.43, average training loss: 7904.66
[INFO 2017-06-15 15:26:34,406 main.py:103] epoch 335, training loss: 7304.59, average training loss: 7902.88
[INFO 2017-06-15 15:26:35,906 main.py:103] epoch 336, training loss: 6623.08, average training loss: 7899.08
[INFO 2017-06-15 15:26:37,406 main.py:103] epoch 337, training loss: 6999.27, average training loss: 7896.42
[INFO 2017-06-15 15:26:38,905 main.py:103] epoch 338, training loss: 7149.64, average training loss: 7894.21
[INFO 2017-06-15 15:26:40,406 main.py:103] epoch 339, training loss: 7719.79, average training loss: 7893.70
[INFO 2017-06-15 15:26:41,906 main.py:103] epoch 340, training loss: 6588.30, average training loss: 7889.87
[INFO 2017-06-15 15:26:43,407 main.py:103] epoch 341, training loss: 6763.63, average training loss: 7886.58
[INFO 2017-06-15 15:26:44,907 main.py:103] epoch 342, training loss: 6891.57, average training loss: 7883.68
[INFO 2017-06-15 15:26:46,406 main.py:103] epoch 343, training loss: 6741.84, average training loss: 7880.36
[INFO 2017-06-15 15:26:47,909 main.py:103] epoch 344, training loss: 6593.52, average training loss: 7876.63
[INFO 2017-06-15 15:26:49,415 main.py:103] epoch 345, training loss: 8144.58, average training loss: 7877.40
[INFO 2017-06-15 15:26:50,914 main.py:103] epoch 346, training loss: 6872.16, average training loss: 7874.51
[INFO 2017-06-15 15:26:52,413 main.py:103] epoch 347, training loss: 7621.25, average training loss: 7873.78
[INFO 2017-06-15 15:26:53,913 main.py:103] epoch 348, training loss: 7504.15, average training loss: 7872.72
[INFO 2017-06-15 15:26:55,415 main.py:103] epoch 349, training loss: 6557.64, average training loss: 7868.96
[INFO 2017-06-15 15:26:56,915 main.py:103] epoch 350, training loss: 6139.35, average training loss: 7864.03
[INFO 2017-06-15 15:26:58,416 main.py:103] epoch 351, training loss: 7262.25, average training loss: 7862.32
[INFO 2017-06-15 15:26:59,923 main.py:103] epoch 352, training loss: 6002.46, average training loss: 7857.06
[INFO 2017-06-15 15:27:01,425 main.py:103] epoch 353, training loss: 7112.92, average training loss: 7854.95
[INFO 2017-06-15 15:27:02,930 main.py:103] epoch 354, training loss: 7281.66, average training loss: 7853.34
[INFO 2017-06-15 15:27:04,437 main.py:103] epoch 355, training loss: 6796.32, average training loss: 7850.37
[INFO 2017-06-15 15:27:05,940 main.py:103] epoch 356, training loss: 6888.65, average training loss: 7847.68
[INFO 2017-06-15 15:27:07,443 main.py:103] epoch 357, training loss: 6913.11, average training loss: 7845.07
[INFO 2017-06-15 15:27:08,971 main.py:103] epoch 358, training loss: 6321.03, average training loss: 7840.82
[INFO 2017-06-15 15:27:10,472 main.py:103] epoch 359, training loss: 7738.20, average training loss: 7840.54
[INFO 2017-06-15 15:27:11,972 main.py:103] epoch 360, training loss: 6872.35, average training loss: 7837.85
[INFO 2017-06-15 15:27:13,486 main.py:103] epoch 361, training loss: 7682.59, average training loss: 7837.42
[INFO 2017-06-15 15:27:14,987 main.py:103] epoch 362, training loss: 7527.15, average training loss: 7836.57
[INFO 2017-06-15 15:27:16,506 main.py:103] epoch 363, training loss: 7069.80, average training loss: 7834.46
[INFO 2017-06-15 15:27:18,027 main.py:103] epoch 364, training loss: 6762.58, average training loss: 7831.53
[INFO 2017-06-15 15:27:19,535 main.py:103] epoch 365, training loss: 6668.41, average training loss: 7828.35
[INFO 2017-06-15 15:27:21,038 main.py:103] epoch 366, training loss: 6813.06, average training loss: 7825.58
[INFO 2017-06-15 15:27:22,574 main.py:103] epoch 367, training loss: 6858.55, average training loss: 7822.95
[INFO 2017-06-15 15:27:24,079 main.py:103] epoch 368, training loss: 6925.23, average training loss: 7820.52
[INFO 2017-06-15 15:27:25,592 main.py:103] epoch 369, training loss: 7161.20, average training loss: 7818.74
[INFO 2017-06-15 15:27:27,094 main.py:103] epoch 370, training loss: 7465.74, average training loss: 7817.79
[INFO 2017-06-15 15:27:28,598 main.py:103] epoch 371, training loss: 6578.33, average training loss: 7814.46
[INFO 2017-06-15 15:27:30,096 main.py:103] epoch 372, training loss: 6672.06, average training loss: 7811.39
[INFO 2017-06-15 15:27:31,595 main.py:103] epoch 373, training loss: 6242.45, average training loss: 7807.20
[INFO 2017-06-15 15:27:33,094 main.py:103] epoch 374, training loss: 6496.18, average training loss: 7803.70
[INFO 2017-06-15 15:27:34,595 main.py:103] epoch 375, training loss: 7229.83, average training loss: 7802.18
[INFO 2017-06-15 15:27:36,095 main.py:103] epoch 376, training loss: 6817.65, average training loss: 7799.56
[INFO 2017-06-15 15:27:37,596 main.py:103] epoch 377, training loss: 6793.22, average training loss: 7796.90
[INFO 2017-06-15 15:27:39,095 main.py:103] epoch 378, training loss: 6971.99, average training loss: 7794.73
[INFO 2017-06-15 15:27:40,633 main.py:103] epoch 379, training loss: 6523.50, average training loss: 7791.38
[INFO 2017-06-15 15:27:42,180 main.py:103] epoch 380, training loss: 6920.23, average training loss: 7789.09
[INFO 2017-06-15 15:27:43,688 main.py:103] epoch 381, training loss: 7060.91, average training loss: 7787.19
[INFO 2017-06-15 15:27:45,236 main.py:103] epoch 382, training loss: 6224.73, average training loss: 7783.11
[INFO 2017-06-15 15:27:46,740 main.py:103] epoch 383, training loss: 6774.66, average training loss: 7780.48
[INFO 2017-06-15 15:27:48,244 main.py:103] epoch 384, training loss: 7014.08, average training loss: 7778.49
[INFO 2017-06-15 15:27:49,765 main.py:103] epoch 385, training loss: 7048.43, average training loss: 7776.60
[INFO 2017-06-15 15:27:51,319 main.py:103] epoch 386, training loss: 6778.56, average training loss: 7774.02
[INFO 2017-06-15 15:27:52,875 main.py:103] epoch 387, training loss: 6071.11, average training loss: 7769.63
[INFO 2017-06-15 15:27:54,408 main.py:103] epoch 388, training loss: 7895.72, average training loss: 7769.96
[INFO 2017-06-15 15:27:56,007 main.py:103] epoch 389, training loss: 6742.06, average training loss: 7767.32
[INFO 2017-06-15 15:27:57,510 main.py:103] epoch 390, training loss: 7151.60, average training loss: 7765.75
[INFO 2017-06-15 15:27:59,035 main.py:103] epoch 391, training loss: 7343.85, average training loss: 7764.67
[INFO 2017-06-15 15:28:00,535 main.py:103] epoch 392, training loss: 6465.74, average training loss: 7761.36
[INFO 2017-06-15 15:28:02,047 main.py:103] epoch 393, training loss: 6879.06, average training loss: 7759.13
[INFO 2017-06-15 15:28:03,553 main.py:103] epoch 394, training loss: 6943.80, average training loss: 7757.06
[INFO 2017-06-15 15:28:05,053 main.py:103] epoch 395, training loss: 6406.49, average training loss: 7753.65
[INFO 2017-06-15 15:28:06,554 main.py:103] epoch 396, training loss: 6845.09, average training loss: 7751.36
[INFO 2017-06-15 15:28:08,078 main.py:103] epoch 397, training loss: 6472.88, average training loss: 7748.15
[INFO 2017-06-15 15:28:09,577 main.py:103] epoch 398, training loss: 6685.76, average training loss: 7745.49
[INFO 2017-06-15 15:28:11,107 main.py:103] epoch 399, training loss: 6552.79, average training loss: 7742.51
[INFO 2017-06-15 15:28:11,107 main.py:105] epoch 399, testing
[INFO 2017-06-15 15:29:27,878 main.py:54] average testing loss: 7053.73
[INFO 2017-06-15 15:29:27,881 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:29:27,892 main.py:25] current best accuracy: 7053.73
[INFO 2017-06-15 15:29:29,401 main.py:103] epoch 400, training loss: 6822.83, average training loss: 7740.21
[INFO 2017-06-15 15:29:30,925 main.py:103] epoch 401, training loss: 6130.52, average training loss: 7736.21
[INFO 2017-06-15 15:29:32,448 main.py:103] epoch 402, training loss: 7763.04, average training loss: 7736.27
[INFO 2017-06-15 15:29:33,956 main.py:103] epoch 403, training loss: 7899.24, average training loss: 7736.68
[INFO 2017-06-15 15:29:35,455 main.py:103] epoch 404, training loss: 6439.05, average training loss: 7733.47
[INFO 2017-06-15 15:29:36,958 main.py:103] epoch 405, training loss: 6530.46, average training loss: 7730.51
[INFO 2017-06-15 15:29:38,461 main.py:103] epoch 406, training loss: 7638.88, average training loss: 7730.29
[INFO 2017-06-15 15:29:39,968 main.py:103] epoch 407, training loss: 6957.28, average training loss: 7728.39
[INFO 2017-06-15 15:29:41,478 main.py:103] epoch 408, training loss: 7632.59, average training loss: 7728.16
[INFO 2017-06-15 15:29:42,977 main.py:103] epoch 409, training loss: 7007.55, average training loss: 7726.40
[INFO 2017-06-15 15:29:44,491 main.py:103] epoch 410, training loss: 7169.98, average training loss: 7725.05
[INFO 2017-06-15 15:29:46,004 main.py:103] epoch 411, training loss: 6362.45, average training loss: 7721.74
[INFO 2017-06-15 15:29:47,508 main.py:103] epoch 412, training loss: 6817.17, average training loss: 7719.55
[INFO 2017-06-15 15:29:49,033 main.py:103] epoch 413, training loss: 6969.19, average training loss: 7717.74
[INFO 2017-06-15 15:29:50,563 main.py:103] epoch 414, training loss: 5973.75, average training loss: 7713.53
[INFO 2017-06-15 15:29:52,069 main.py:103] epoch 415, training loss: 7220.47, average training loss: 7712.35
[INFO 2017-06-15 15:29:53,576 main.py:103] epoch 416, training loss: 7214.85, average training loss: 7711.15
[INFO 2017-06-15 15:29:55,094 main.py:103] epoch 417, training loss: 7052.21, average training loss: 7709.58
[INFO 2017-06-15 15:29:56,616 main.py:103] epoch 418, training loss: 6700.43, average training loss: 7707.17
[INFO 2017-06-15 15:29:58,147 main.py:103] epoch 419, training loss: 6681.36, average training loss: 7704.73
[INFO 2017-06-15 15:29:59,655 main.py:103] epoch 420, training loss: 7120.73, average training loss: 7703.34
[INFO 2017-06-15 15:30:01,161 main.py:103] epoch 421, training loss: 7189.23, average training loss: 7702.12
[INFO 2017-06-15 15:30:02,667 main.py:103] epoch 422, training loss: 7230.36, average training loss: 7701.01
[INFO 2017-06-15 15:30:04,176 main.py:103] epoch 423, training loss: 6245.12, average training loss: 7697.57
[INFO 2017-06-15 15:30:05,679 main.py:103] epoch 424, training loss: 6614.60, average training loss: 7695.02
[INFO 2017-06-15 15:30:07,185 main.py:103] epoch 425, training loss: 7123.25, average training loss: 7693.68
[INFO 2017-06-15 15:30:08,685 main.py:103] epoch 426, training loss: 7145.87, average training loss: 7692.40
[INFO 2017-06-15 15:30:10,185 main.py:103] epoch 427, training loss: 6753.37, average training loss: 7690.21
[INFO 2017-06-15 15:30:11,686 main.py:103] epoch 428, training loss: 7006.02, average training loss: 7688.61
[INFO 2017-06-15 15:30:13,190 main.py:103] epoch 429, training loss: 6715.12, average training loss: 7686.35
[INFO 2017-06-15 15:30:14,690 main.py:103] epoch 430, training loss: 7011.18, average training loss: 7684.78
[INFO 2017-06-15 15:30:16,191 main.py:103] epoch 431, training loss: 6234.36, average training loss: 7681.42
[INFO 2017-06-15 15:30:17,692 main.py:103] epoch 432, training loss: 6651.44, average training loss: 7679.04
[INFO 2017-06-15 15:30:19,194 main.py:103] epoch 433, training loss: 6671.24, average training loss: 7676.72
[INFO 2017-06-15 15:30:20,696 main.py:103] epoch 434, training loss: 6568.61, average training loss: 7674.17
[INFO 2017-06-15 15:30:22,197 main.py:103] epoch 435, training loss: 6460.89, average training loss: 7671.39
[INFO 2017-06-15 15:30:23,702 main.py:103] epoch 436, training loss: 6706.79, average training loss: 7669.18
[INFO 2017-06-15 15:30:25,219 main.py:103] epoch 437, training loss: 6649.46, average training loss: 7666.86
[INFO 2017-06-15 15:30:26,726 main.py:103] epoch 438, training loss: 6721.88, average training loss: 7664.70
[INFO 2017-06-15 15:30:28,231 main.py:103] epoch 439, training loss: 6735.52, average training loss: 7662.59
[INFO 2017-06-15 15:30:29,733 main.py:103] epoch 440, training loss: 5598.55, average training loss: 7657.91
[INFO 2017-06-15 15:30:31,236 main.py:103] epoch 441, training loss: 6713.15, average training loss: 7655.77
[INFO 2017-06-15 15:30:32,749 main.py:103] epoch 442, training loss: 6673.47, average training loss: 7653.56
[INFO 2017-06-15 15:30:34,251 main.py:103] epoch 443, training loss: 6944.29, average training loss: 7651.96
[INFO 2017-06-15 15:30:35,753 main.py:103] epoch 444, training loss: 7093.71, average training loss: 7650.70
[INFO 2017-06-15 15:30:37,253 main.py:103] epoch 445, training loss: 6875.90, average training loss: 7648.97
[INFO 2017-06-15 15:30:38,755 main.py:103] epoch 446, training loss: 7076.37, average training loss: 7647.69
[INFO 2017-06-15 15:30:40,263 main.py:103] epoch 447, training loss: 7094.25, average training loss: 7646.45
[INFO 2017-06-15 15:30:41,763 main.py:103] epoch 448, training loss: 7348.80, average training loss: 7645.79
[INFO 2017-06-15 15:30:43,263 main.py:103] epoch 449, training loss: 7583.37, average training loss: 7645.65
[INFO 2017-06-15 15:30:44,762 main.py:103] epoch 450, training loss: 6537.45, average training loss: 7643.19
[INFO 2017-06-15 15:30:46,276 main.py:103] epoch 451, training loss: 7164.58, average training loss: 7642.13
[INFO 2017-06-15 15:30:47,776 main.py:103] epoch 452, training loss: 7191.65, average training loss: 7641.14
[INFO 2017-06-15 15:30:49,286 main.py:103] epoch 453, training loss: 6338.92, average training loss: 7638.27
[INFO 2017-06-15 15:30:50,786 main.py:103] epoch 454, training loss: 6432.46, average training loss: 7635.62
[INFO 2017-06-15 15:30:52,286 main.py:103] epoch 455, training loss: 6925.95, average training loss: 7634.06
[INFO 2017-06-15 15:30:53,787 main.py:103] epoch 456, training loss: 7160.99, average training loss: 7633.03
[INFO 2017-06-15 15:30:55,286 main.py:103] epoch 457, training loss: 7788.84, average training loss: 7633.37
[INFO 2017-06-15 15:30:56,785 main.py:103] epoch 458, training loss: 7097.76, average training loss: 7632.20
[INFO 2017-06-15 15:30:58,284 main.py:103] epoch 459, training loss: 6622.91, average training loss: 7630.01
[INFO 2017-06-15 15:30:59,785 main.py:103] epoch 460, training loss: 7908.60, average training loss: 7630.61
[INFO 2017-06-15 15:31:01,284 main.py:103] epoch 461, training loss: 6867.32, average training loss: 7628.96
[INFO 2017-06-15 15:31:02,784 main.py:103] epoch 462, training loss: 6623.67, average training loss: 7626.79
[INFO 2017-06-15 15:31:04,284 main.py:103] epoch 463, training loss: 7069.74, average training loss: 7625.59
[INFO 2017-06-15 15:31:05,784 main.py:103] epoch 464, training loss: 7275.65, average training loss: 7624.84
[INFO 2017-06-15 15:31:07,283 main.py:103] epoch 465, training loss: 6641.43, average training loss: 7622.73
[INFO 2017-06-15 15:31:08,784 main.py:103] epoch 466, training loss: 7267.86, average training loss: 7621.97
[INFO 2017-06-15 15:31:10,282 main.py:103] epoch 467, training loss: 6373.81, average training loss: 7619.30
[INFO 2017-06-15 15:31:11,782 main.py:103] epoch 468, training loss: 6551.96, average training loss: 7617.02
[INFO 2017-06-15 15:31:13,282 main.py:103] epoch 469, training loss: 8040.96, average training loss: 7617.93
[INFO 2017-06-15 15:31:14,782 main.py:103] epoch 470, training loss: 6573.56, average training loss: 7615.71
[INFO 2017-06-15 15:31:16,283 main.py:103] epoch 471, training loss: 7178.76, average training loss: 7614.78
[INFO 2017-06-15 15:31:17,782 main.py:103] epoch 472, training loss: 6722.80, average training loss: 7612.90
[INFO 2017-06-15 15:31:19,284 main.py:103] epoch 473, training loss: 7050.40, average training loss: 7611.71
[INFO 2017-06-15 15:31:20,784 main.py:103] epoch 474, training loss: 7896.43, average training loss: 7612.31
[INFO 2017-06-15 15:31:22,284 main.py:103] epoch 475, training loss: 7022.44, average training loss: 7611.07
[INFO 2017-06-15 15:31:23,783 main.py:103] epoch 476, training loss: 7133.65, average training loss: 7610.07
[INFO 2017-06-15 15:31:25,282 main.py:103] epoch 477, training loss: 7067.54, average training loss: 7608.93
[INFO 2017-06-15 15:31:26,781 main.py:103] epoch 478, training loss: 7706.22, average training loss: 7609.14
[INFO 2017-06-15 15:31:28,281 main.py:103] epoch 479, training loss: 6910.36, average training loss: 7607.68
[INFO 2017-06-15 15:31:29,781 main.py:103] epoch 480, training loss: 6788.16, average training loss: 7605.98
[INFO 2017-06-15 15:31:31,282 main.py:103] epoch 481, training loss: 7338.42, average training loss: 7605.42
[INFO 2017-06-15 15:31:32,782 main.py:103] epoch 482, training loss: 7094.23, average training loss: 7604.36
[INFO 2017-06-15 15:31:34,283 main.py:103] epoch 483, training loss: 6747.68, average training loss: 7602.59
[INFO 2017-06-15 15:31:35,783 main.py:103] epoch 484, training loss: 6569.69, average training loss: 7600.46
[INFO 2017-06-15 15:31:37,285 main.py:103] epoch 485, training loss: 6326.13, average training loss: 7597.84
[INFO 2017-06-15 15:31:38,786 main.py:103] epoch 486, training loss: 6577.51, average training loss: 7595.75
[INFO 2017-06-15 15:31:40,287 main.py:103] epoch 487, training loss: 6461.41, average training loss: 7593.42
[INFO 2017-06-15 15:31:41,786 main.py:103] epoch 488, training loss: 6774.00, average training loss: 7591.75
[INFO 2017-06-15 15:31:43,285 main.py:103] epoch 489, training loss: 7004.68, average training loss: 7590.55
[INFO 2017-06-15 15:31:44,785 main.py:103] epoch 490, training loss: 7153.62, average training loss: 7589.66
[INFO 2017-06-15 15:31:46,285 main.py:103] epoch 491, training loss: 6530.50, average training loss: 7587.51
[INFO 2017-06-15 15:31:47,786 main.py:103] epoch 492, training loss: 6423.21, average training loss: 7585.14
[INFO 2017-06-15 15:31:49,286 main.py:103] epoch 493, training loss: 7305.36, average training loss: 7584.58
[INFO 2017-06-15 15:31:50,787 main.py:103] epoch 494, training loss: 7161.50, average training loss: 7583.72
[INFO 2017-06-15 15:31:52,289 main.py:103] epoch 495, training loss: 6360.37, average training loss: 7581.26
[INFO 2017-06-15 15:31:53,791 main.py:103] epoch 496, training loss: 7884.07, average training loss: 7581.87
[INFO 2017-06-15 15:31:55,292 main.py:103] epoch 497, training loss: 7124.23, average training loss: 7580.95
[INFO 2017-06-15 15:31:56,794 main.py:103] epoch 498, training loss: 6890.56, average training loss: 7579.56
[INFO 2017-06-15 15:31:58,295 main.py:103] epoch 499, training loss: 6862.26, average training loss: 7578.13
[INFO 2017-06-15 15:31:58,295 main.py:105] epoch 499, testing
[INFO 2017-06-15 15:33:14,800 main.py:54] average testing loss: 6807.78
[INFO 2017-06-15 15:33:14,804 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:33:14,812 main.py:25] current best accuracy: 6807.78
[INFO 2017-06-15 15:33:16,312 main.py:103] epoch 500, training loss: 7241.22, average training loss: 7577.46
[INFO 2017-06-15 15:33:17,822 main.py:103] epoch 501, training loss: 6671.78, average training loss: 7575.65
[INFO 2017-06-15 15:33:19,322 main.py:103] epoch 502, training loss: 6252.24, average training loss: 7573.02
[INFO 2017-06-15 15:33:20,822 main.py:103] epoch 503, training loss: 7189.06, average training loss: 7572.26
[INFO 2017-06-15 15:33:22,321 main.py:103] epoch 504, training loss: 6291.84, average training loss: 7569.72
[INFO 2017-06-15 15:33:23,856 main.py:103] epoch 505, training loss: 7116.38, average training loss: 7568.83
[INFO 2017-06-15 15:33:25,355 main.py:103] epoch 506, training loss: 6333.28, average training loss: 7566.39
[INFO 2017-06-15 15:33:26,886 main.py:103] epoch 507, training loss: 6813.32, average training loss: 7564.91
[INFO 2017-06-15 15:33:28,386 main.py:103] epoch 508, training loss: 7003.24, average training loss: 7563.81
[INFO 2017-06-15 15:33:29,896 main.py:103] epoch 509, training loss: 6581.87, average training loss: 7561.88
[INFO 2017-06-15 15:33:31,397 main.py:103] epoch 510, training loss: 6705.59, average training loss: 7560.20
[INFO 2017-06-15 15:33:32,896 main.py:103] epoch 511, training loss: 6584.18, average training loss: 7558.30
[INFO 2017-06-15 15:33:34,401 main.py:103] epoch 512, training loss: 7681.20, average training loss: 7558.54
[INFO 2017-06-15 15:33:35,900 main.py:103] epoch 513, training loss: 6542.01, average training loss: 7556.56
[INFO 2017-06-15 15:33:37,401 main.py:103] epoch 514, training loss: 7332.86, average training loss: 7556.13
[INFO 2017-06-15 15:33:38,938 main.py:103] epoch 515, training loss: 6500.50, average training loss: 7554.08
[INFO 2017-06-15 15:33:40,443 main.py:103] epoch 516, training loss: 7176.20, average training loss: 7553.35
[INFO 2017-06-15 15:33:41,956 main.py:103] epoch 517, training loss: 6935.01, average training loss: 7552.16
[INFO 2017-06-15 15:33:43,456 main.py:103] epoch 518, training loss: 7263.43, average training loss: 7551.60
[INFO 2017-06-15 15:33:44,968 main.py:103] epoch 519, training loss: 7670.16, average training loss: 7551.83
[INFO 2017-06-15 15:33:46,468 main.py:103] epoch 520, training loss: 7062.28, average training loss: 7550.89
[INFO 2017-06-15 15:33:47,992 main.py:103] epoch 521, training loss: 6268.12, average training loss: 7548.43
[INFO 2017-06-15 15:33:49,494 main.py:103] epoch 522, training loss: 6382.32, average training loss: 7546.20
[INFO 2017-06-15 15:33:50,999 main.py:103] epoch 523, training loss: 6489.01, average training loss: 7544.18
[INFO 2017-06-15 15:33:52,500 main.py:103] epoch 524, training loss: 7424.87, average training loss: 7543.96
[INFO 2017-06-15 15:33:54,002 main.py:103] epoch 525, training loss: 7049.29, average training loss: 7543.01
[INFO 2017-06-15 15:33:55,503 main.py:103] epoch 526, training loss: 6230.93, average training loss: 7540.53
[INFO 2017-06-15 15:33:57,004 main.py:103] epoch 527, training loss: 6602.98, average training loss: 7538.75
[INFO 2017-06-15 15:33:58,504 main.py:103] epoch 528, training loss: 7540.07, average training loss: 7538.75
[INFO 2017-06-15 15:34:00,004 main.py:103] epoch 529, training loss: 6827.95, average training loss: 7537.41
[INFO 2017-06-15 15:34:01,506 main.py:103] epoch 530, training loss: 6641.68, average training loss: 7535.72
[INFO 2017-06-15 15:34:03,008 main.py:103] epoch 531, training loss: 6237.29, average training loss: 7533.28
[INFO 2017-06-15 15:34:04,510 main.py:103] epoch 532, training loss: 6363.63, average training loss: 7531.09
[INFO 2017-06-15 15:34:06,011 main.py:103] epoch 533, training loss: 7415.29, average training loss: 7530.87
[INFO 2017-06-15 15:34:07,511 main.py:103] epoch 534, training loss: 7909.95, average training loss: 7531.58
[INFO 2017-06-15 15:34:09,012 main.py:103] epoch 535, training loss: 6740.09, average training loss: 7530.10
[INFO 2017-06-15 15:34:10,515 main.py:103] epoch 536, training loss: 6694.40, average training loss: 7528.55
[INFO 2017-06-15 15:34:12,017 main.py:103] epoch 537, training loss: 7162.99, average training loss: 7527.87
[INFO 2017-06-15 15:34:13,519 main.py:103] epoch 538, training loss: 6845.03, average training loss: 7526.60
[INFO 2017-06-15 15:34:15,034 main.py:103] epoch 539, training loss: 7144.75, average training loss: 7525.89
[INFO 2017-06-15 15:34:16,537 main.py:103] epoch 540, training loss: 6530.79, average training loss: 7524.05
[INFO 2017-06-15 15:34:18,068 main.py:103] epoch 541, training loss: 6606.41, average training loss: 7522.36
[INFO 2017-06-15 15:34:19,568 main.py:103] epoch 542, training loss: 6391.94, average training loss: 7520.28
[INFO 2017-06-15 15:34:21,081 main.py:103] epoch 543, training loss: 6976.98, average training loss: 7519.28
[INFO 2017-06-15 15:34:22,581 main.py:103] epoch 544, training loss: 7354.17, average training loss: 7518.98
[INFO 2017-06-15 15:34:24,083 main.py:103] epoch 545, training loss: 7630.49, average training loss: 7519.18
[INFO 2017-06-15 15:34:25,582 main.py:103] epoch 546, training loss: 6647.91, average training loss: 7517.59
[INFO 2017-06-15 15:34:27,082 main.py:103] epoch 547, training loss: 6943.15, average training loss: 7516.54
[INFO 2017-06-15 15:34:28,582 main.py:103] epoch 548, training loss: 7328.96, average training loss: 7516.20
[INFO 2017-06-15 15:34:30,082 main.py:103] epoch 549, training loss: 6896.82, average training loss: 7515.07
[INFO 2017-06-15 15:34:31,581 main.py:103] epoch 550, training loss: 6397.62, average training loss: 7513.05
[INFO 2017-06-15 15:34:33,092 main.py:103] epoch 551, training loss: 6771.91, average training loss: 7511.70
[INFO 2017-06-15 15:34:34,591 main.py:103] epoch 552, training loss: 6442.41, average training loss: 7509.77
[INFO 2017-06-15 15:34:36,090 main.py:103] epoch 553, training loss: 6502.00, average training loss: 7507.95
[INFO 2017-06-15 15:34:37,590 main.py:103] epoch 554, training loss: 6836.46, average training loss: 7506.74
[INFO 2017-06-15 15:34:39,095 main.py:103] epoch 555, training loss: 6934.58, average training loss: 7505.71
[INFO 2017-06-15 15:34:40,593 main.py:103] epoch 556, training loss: 7147.27, average training loss: 7505.07
[INFO 2017-06-15 15:34:42,093 main.py:103] epoch 557, training loss: 6816.24, average training loss: 7503.83
[INFO 2017-06-15 15:34:43,593 main.py:103] epoch 558, training loss: 7005.80, average training loss: 7502.94
[INFO 2017-06-15 15:34:45,093 main.py:103] epoch 559, training loss: 6896.77, average training loss: 7501.86
[INFO 2017-06-15 15:34:46,594 main.py:103] epoch 560, training loss: 7380.41, average training loss: 7501.64
[INFO 2017-06-15 15:34:48,093 main.py:103] epoch 561, training loss: 7244.08, average training loss: 7501.19
[INFO 2017-06-15 15:34:49,593 main.py:103] epoch 562, training loss: 6684.75, average training loss: 7499.73
[INFO 2017-06-15 15:34:51,092 main.py:103] epoch 563, training loss: 6916.06, average training loss: 7498.70
[INFO 2017-06-15 15:34:52,592 main.py:103] epoch 564, training loss: 6246.07, average training loss: 7496.48
[INFO 2017-06-15 15:34:54,093 main.py:103] epoch 565, training loss: 6969.11, average training loss: 7495.55
[INFO 2017-06-15 15:34:55,593 main.py:103] epoch 566, training loss: 7428.02, average training loss: 7495.43
[INFO 2017-06-15 15:34:57,094 main.py:103] epoch 567, training loss: 6388.65, average training loss: 7493.48
[INFO 2017-06-15 15:34:58,602 main.py:103] epoch 568, training loss: 6616.22, average training loss: 7491.94
[INFO 2017-06-15 15:35:00,102 main.py:103] epoch 569, training loss: 6982.52, average training loss: 7491.05
[INFO 2017-06-15 15:35:01,602 main.py:103] epoch 570, training loss: 6852.59, average training loss: 7489.93
[INFO 2017-06-15 15:35:03,103 main.py:103] epoch 571, training loss: 6552.74, average training loss: 7488.29
[INFO 2017-06-15 15:35:04,603 main.py:103] epoch 572, training loss: 6216.58, average training loss: 7486.07
[INFO 2017-06-15 15:35:06,117 main.py:103] epoch 573, training loss: 6515.07, average training loss: 7484.38
[INFO 2017-06-15 15:35:07,618 main.py:103] epoch 574, training loss: 7509.88, average training loss: 7484.42
[INFO 2017-06-15 15:35:09,117 main.py:103] epoch 575, training loss: 6843.97, average training loss: 7483.31
[INFO 2017-06-15 15:35:10,617 main.py:103] epoch 576, training loss: 7875.99, average training loss: 7483.99
[INFO 2017-06-15 15:35:12,119 main.py:103] epoch 577, training loss: 6112.90, average training loss: 7481.62
[INFO 2017-06-15 15:35:13,619 main.py:103] epoch 578, training loss: 6672.86, average training loss: 7480.22
[INFO 2017-06-15 15:35:15,136 main.py:103] epoch 579, training loss: 6921.79, average training loss: 7479.26
[INFO 2017-06-15 15:35:16,638 main.py:103] epoch 580, training loss: 6003.08, average training loss: 7476.72
[INFO 2017-06-15 15:35:18,138 main.py:103] epoch 581, training loss: 6671.26, average training loss: 7475.34
[INFO 2017-06-15 15:35:19,637 main.py:103] epoch 582, training loss: 6870.98, average training loss: 7474.30
[INFO 2017-06-15 15:35:21,137 main.py:103] epoch 583, training loss: 7203.03, average training loss: 7473.84
[INFO 2017-06-15 15:35:22,636 main.py:103] epoch 584, training loss: 6080.04, average training loss: 7471.45
[INFO 2017-06-15 15:35:24,138 main.py:103] epoch 585, training loss: 6308.03, average training loss: 7469.47
[INFO 2017-06-15 15:35:25,638 main.py:103] epoch 586, training loss: 7006.71, average training loss: 7468.68
[INFO 2017-06-15 15:35:27,139 main.py:103] epoch 587, training loss: 7084.70, average training loss: 7468.03
[INFO 2017-06-15 15:35:28,639 main.py:103] epoch 588, training loss: 6696.45, average training loss: 7466.72
[INFO 2017-06-15 15:35:30,139 main.py:103] epoch 589, training loss: 6065.50, average training loss: 7464.34
[INFO 2017-06-15 15:35:31,639 main.py:103] epoch 590, training loss: 6818.98, average training loss: 7463.25
[INFO 2017-06-15 15:35:33,139 main.py:103] epoch 591, training loss: 7951.40, average training loss: 7464.07
[INFO 2017-06-15 15:35:34,639 main.py:103] epoch 592, training loss: 6726.51, average training loss: 7462.83
[INFO 2017-06-15 15:35:36,142 main.py:103] epoch 593, training loss: 7238.48, average training loss: 7462.45
[INFO 2017-06-15 15:35:37,643 main.py:103] epoch 594, training loss: 7144.89, average training loss: 7461.92
[INFO 2017-06-15 15:35:39,143 main.py:103] epoch 595, training loss: 8022.37, average training loss: 7462.86
[INFO 2017-06-15 15:35:40,643 main.py:103] epoch 596, training loss: 5907.29, average training loss: 7460.25
[INFO 2017-06-15 15:35:42,143 main.py:103] epoch 597, training loss: 6404.22, average training loss: 7458.49
[INFO 2017-06-15 15:35:43,643 main.py:103] epoch 598, training loss: 7577.30, average training loss: 7458.69
[INFO 2017-06-15 15:35:45,143 main.py:103] epoch 599, training loss: 6690.93, average training loss: 7457.41
[INFO 2017-06-15 15:35:45,143 main.py:105] epoch 599, testing
[INFO 2017-06-15 15:37:01,246 main.py:54] average testing loss: 6856.81
[INFO 2017-06-15 15:37:01,250 main.py:25] current best accuracy: 6807.78
[INFO 2017-06-15 15:37:02,757 main.py:103] epoch 600, training loss: 6755.51, average training loss: 7456.24
[INFO 2017-06-15 15:37:04,256 main.py:103] epoch 601, training loss: 6984.05, average training loss: 7455.45
[INFO 2017-06-15 15:37:05,757 main.py:103] epoch 602, training loss: 7005.18, average training loss: 7454.71
[INFO 2017-06-15 15:37:07,257 main.py:103] epoch 603, training loss: 6823.66, average training loss: 7453.66
[INFO 2017-06-15 15:37:08,756 main.py:103] epoch 604, training loss: 7015.80, average training loss: 7452.94
[INFO 2017-06-15 15:37:10,256 main.py:103] epoch 605, training loss: 6416.94, average training loss: 7451.23
[INFO 2017-06-15 15:37:11,755 main.py:103] epoch 606, training loss: 7307.52, average training loss: 7450.99
[INFO 2017-06-15 15:37:13,254 main.py:103] epoch 607, training loss: 6901.04, average training loss: 7450.09
[INFO 2017-06-15 15:37:14,753 main.py:103] epoch 608, training loss: 6604.54, average training loss: 7448.70
[INFO 2017-06-15 15:37:16,252 main.py:103] epoch 609, training loss: 6882.40, average training loss: 7447.77
[INFO 2017-06-15 15:37:17,762 main.py:103] epoch 610, training loss: 7622.79, average training loss: 7448.06
[INFO 2017-06-15 15:37:19,268 main.py:103] epoch 611, training loss: 7152.33, average training loss: 7447.57
[INFO 2017-06-15 15:37:20,776 main.py:103] epoch 612, training loss: 6975.00, average training loss: 7446.80
[INFO 2017-06-15 15:37:22,281 main.py:103] epoch 613, training loss: 7118.97, average training loss: 7446.27
[INFO 2017-06-15 15:37:23,780 main.py:103] epoch 614, training loss: 7296.31, average training loss: 7446.03
[INFO 2017-06-15 15:37:25,279 main.py:103] epoch 615, training loss: 6960.46, average training loss: 7445.24
[INFO 2017-06-15 15:37:26,777 main.py:103] epoch 616, training loss: 7038.64, average training loss: 7444.58
[INFO 2017-06-15 15:37:28,276 main.py:103] epoch 617, training loss: 6556.47, average training loss: 7443.14
[INFO 2017-06-15 15:37:29,773 main.py:103] epoch 618, training loss: 6453.41, average training loss: 7441.54
[INFO 2017-06-15 15:37:31,279 main.py:103] epoch 619, training loss: 6046.65, average training loss: 7439.29
[INFO 2017-06-15 15:37:32,778 main.py:103] epoch 620, training loss: 6851.67, average training loss: 7438.35
[INFO 2017-06-15 15:37:34,276 main.py:103] epoch 621, training loss: 7138.18, average training loss: 7437.86
[INFO 2017-06-15 15:37:35,775 main.py:103] epoch 622, training loss: 5929.67, average training loss: 7435.44
[INFO 2017-06-15 15:37:37,273 main.py:103] epoch 623, training loss: 7174.39, average training loss: 7435.02
[INFO 2017-06-15 15:37:38,787 main.py:103] epoch 624, training loss: 6240.08, average training loss: 7433.11
[INFO 2017-06-15 15:37:40,286 main.py:103] epoch 625, training loss: 6834.11, average training loss: 7432.16
[INFO 2017-06-15 15:37:41,798 main.py:103] epoch 626, training loss: 5845.96, average training loss: 7429.63
[INFO 2017-06-15 15:37:43,306 main.py:103] epoch 627, training loss: 7037.02, average training loss: 7429.00
[INFO 2017-06-15 15:37:44,816 main.py:103] epoch 628, training loss: 8073.20, average training loss: 7430.03
[INFO 2017-06-15 15:37:46,319 main.py:103] epoch 629, training loss: 6556.37, average training loss: 7428.64
[INFO 2017-06-15 15:37:47,819 main.py:103] epoch 630, training loss: 6847.15, average training loss: 7427.72
[INFO 2017-06-15 15:37:49,318 main.py:103] epoch 631, training loss: 6571.50, average training loss: 7426.36
[INFO 2017-06-15 15:37:50,816 main.py:103] epoch 632, training loss: 6191.50, average training loss: 7424.41
[INFO 2017-06-15 15:37:52,333 main.py:103] epoch 633, training loss: 6768.39, average training loss: 7423.38
[INFO 2017-06-15 15:37:53,833 main.py:103] epoch 634, training loss: 6908.63, average training loss: 7422.57
[INFO 2017-06-15 15:37:55,347 main.py:103] epoch 635, training loss: 7552.67, average training loss: 7422.77
[INFO 2017-06-15 15:37:56,848 main.py:103] epoch 636, training loss: 7216.32, average training loss: 7422.45
[INFO 2017-06-15 15:37:58,365 main.py:103] epoch 637, training loss: 6445.71, average training loss: 7420.92
[INFO 2017-06-15 15:37:59,863 main.py:103] epoch 638, training loss: 6638.72, average training loss: 7419.69
[INFO 2017-06-15 15:38:01,361 main.py:103] epoch 639, training loss: 6592.82, average training loss: 7418.40
[INFO 2017-06-15 15:38:02,860 main.py:103] epoch 640, training loss: 6414.60, average training loss: 7416.83
[INFO 2017-06-15 15:38:04,359 main.py:103] epoch 641, training loss: 6689.58, average training loss: 7415.70
[INFO 2017-06-15 15:38:05,858 main.py:103] epoch 642, training loss: 6178.90, average training loss: 7413.78
[INFO 2017-06-15 15:38:07,356 main.py:103] epoch 643, training loss: 6195.06, average training loss: 7411.88
[INFO 2017-06-15 15:38:08,855 main.py:103] epoch 644, training loss: 7101.25, average training loss: 7411.40
[INFO 2017-06-15 15:38:10,354 main.py:103] epoch 645, training loss: 6503.54, average training loss: 7410.00
[INFO 2017-06-15 15:38:11,852 main.py:103] epoch 646, training loss: 7619.24, average training loss: 7410.32
[INFO 2017-06-15 15:38:13,352 main.py:103] epoch 647, training loss: 6615.52, average training loss: 7409.09
[INFO 2017-06-15 15:38:14,850 main.py:103] epoch 648, training loss: 6334.55, average training loss: 7407.44
[INFO 2017-06-15 15:38:16,350 main.py:103] epoch 649, training loss: 6817.56, average training loss: 7406.53
[INFO 2017-06-15 15:38:17,851 main.py:103] epoch 650, training loss: 6492.50, average training loss: 7405.13
[INFO 2017-06-15 15:38:19,349 main.py:103] epoch 651, training loss: 7014.35, average training loss: 7404.53
[INFO 2017-06-15 15:38:20,849 main.py:103] epoch 652, training loss: 6928.01, average training loss: 7403.80
[INFO 2017-06-15 15:38:22,349 main.py:103] epoch 653, training loss: 7505.00, average training loss: 7403.95
[INFO 2017-06-15 15:38:23,853 main.py:103] epoch 654, training loss: 6760.58, average training loss: 7402.97
[INFO 2017-06-15 15:38:25,353 main.py:103] epoch 655, training loss: 7161.31, average training loss: 7402.60
[INFO 2017-06-15 15:38:26,852 main.py:103] epoch 656, training loss: 6331.46, average training loss: 7400.97
[INFO 2017-06-15 15:38:28,356 main.py:103] epoch 657, training loss: 6604.86, average training loss: 7399.76
[INFO 2017-06-15 15:38:29,856 main.py:103] epoch 658, training loss: 6534.26, average training loss: 7398.45
[INFO 2017-06-15 15:38:31,362 main.py:103] epoch 659, training loss: 7092.21, average training loss: 7397.98
[INFO 2017-06-15 15:38:32,860 main.py:103] epoch 660, training loss: 7667.46, average training loss: 7398.39
[INFO 2017-06-15 15:38:34,359 main.py:103] epoch 661, training loss: 6286.32, average training loss: 7396.71
[INFO 2017-06-15 15:38:35,856 main.py:103] epoch 662, training loss: 7005.37, average training loss: 7396.12
[INFO 2017-06-15 15:38:37,355 main.py:103] epoch 663, training loss: 6475.43, average training loss: 7394.74
[INFO 2017-06-15 15:38:38,855 main.py:103] epoch 664, training loss: 6402.73, average training loss: 7393.24
[INFO 2017-06-15 15:38:40,352 main.py:103] epoch 665, training loss: 6870.75, average training loss: 7392.46
[INFO 2017-06-15 15:38:41,852 main.py:103] epoch 666, training loss: 7075.46, average training loss: 7391.98
[INFO 2017-06-15 15:38:43,365 main.py:103] epoch 667, training loss: 6852.26, average training loss: 7391.18
[INFO 2017-06-15 15:38:44,872 main.py:103] epoch 668, training loss: 6213.90, average training loss: 7389.42
[INFO 2017-06-15 15:38:46,384 main.py:103] epoch 669, training loss: 6814.79, average training loss: 7388.56
[INFO 2017-06-15 15:38:47,884 main.py:103] epoch 670, training loss: 6011.92, average training loss: 7386.51
[INFO 2017-06-15 15:38:49,383 main.py:103] epoch 671, training loss: 6045.50, average training loss: 7384.51
[INFO 2017-06-15 15:38:50,882 main.py:103] epoch 672, training loss: 7060.38, average training loss: 7384.03
[INFO 2017-06-15 15:38:52,403 main.py:103] epoch 673, training loss: 6209.81, average training loss: 7382.29
[INFO 2017-06-15 15:38:53,902 main.py:103] epoch 674, training loss: 7121.41, average training loss: 7381.90
[INFO 2017-06-15 15:38:55,401 main.py:103] epoch 675, training loss: 7243.56, average training loss: 7381.70
[INFO 2017-06-15 15:38:56,899 main.py:103] epoch 676, training loss: 7148.38, average training loss: 7381.35
[INFO 2017-06-15 15:38:58,397 main.py:103] epoch 677, training loss: 6963.24, average training loss: 7380.74
[INFO 2017-06-15 15:38:59,898 main.py:103] epoch 678, training loss: 7121.00, average training loss: 7380.35
[INFO 2017-06-15 15:39:01,421 main.py:103] epoch 679, training loss: 6598.82, average training loss: 7379.20
[INFO 2017-06-15 15:39:02,921 main.py:103] epoch 680, training loss: 6895.04, average training loss: 7378.49
[INFO 2017-06-15 15:39:04,419 main.py:103] epoch 681, training loss: 6415.79, average training loss: 7377.08
[INFO 2017-06-15 15:39:05,920 main.py:103] epoch 682, training loss: 6863.91, average training loss: 7376.33
[INFO 2017-06-15 15:39:07,418 main.py:103] epoch 683, training loss: 6487.02, average training loss: 7375.03
[INFO 2017-06-15 15:39:08,949 main.py:103] epoch 684, training loss: 7189.94, average training loss: 7374.76
[INFO 2017-06-15 15:39:10,449 main.py:103] epoch 685, training loss: 6538.93, average training loss: 7373.54
[INFO 2017-06-15 15:39:11,963 main.py:103] epoch 686, training loss: 6697.73, average training loss: 7372.56
[INFO 2017-06-15 15:39:13,468 main.py:103] epoch 687, training loss: 6151.70, average training loss: 7370.78
[INFO 2017-06-15 15:39:14,971 main.py:103] epoch 688, training loss: 6411.81, average training loss: 7369.39
[INFO 2017-06-15 15:39:16,469 main.py:103] epoch 689, training loss: 6485.22, average training loss: 7368.11
[INFO 2017-06-15 15:39:17,969 main.py:103] epoch 690, training loss: 7172.66, average training loss: 7367.83
[INFO 2017-06-15 15:39:19,468 main.py:103] epoch 691, training loss: 6864.21, average training loss: 7367.10
[INFO 2017-06-15 15:39:20,978 main.py:103] epoch 692, training loss: 6336.25, average training loss: 7365.61
[INFO 2017-06-15 15:39:22,495 main.py:103] epoch 693, training loss: 6452.26, average training loss: 7364.30
[INFO 2017-06-15 15:39:23,993 main.py:103] epoch 694, training loss: 6941.94, average training loss: 7363.69
[INFO 2017-06-15 15:39:25,515 main.py:103] epoch 695, training loss: 7273.82, average training loss: 7363.56
[INFO 2017-06-15 15:39:27,021 main.py:103] epoch 696, training loss: 7112.34, average training loss: 7363.20
[INFO 2017-06-15 15:39:28,522 main.py:103] epoch 697, training loss: 6844.43, average training loss: 7362.45
[INFO 2017-06-15 15:39:30,022 main.py:103] epoch 698, training loss: 6573.05, average training loss: 7361.33
[INFO 2017-06-15 15:39:31,520 main.py:103] epoch 699, training loss: 6842.83, average training loss: 7360.58
[INFO 2017-06-15 15:39:31,520 main.py:105] epoch 699, testing
[INFO 2017-06-15 15:40:47,543 main.py:54] average testing loss: 6698.48
[INFO 2017-06-15 15:40:47,547 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:40:47,555 main.py:25] current best accuracy: 6698.48
[INFO 2017-06-15 15:40:49,055 main.py:103] epoch 700, training loss: 7241.09, average training loss: 7360.41
[INFO 2017-06-15 15:40:50,552 main.py:103] epoch 701, training loss: 5968.08, average training loss: 7358.43
[INFO 2017-06-15 15:40:52,070 main.py:103] epoch 702, training loss: 7322.94, average training loss: 7358.38
[INFO 2017-06-15 15:40:53,568 main.py:103] epoch 703, training loss: 7113.99, average training loss: 7358.03
[INFO 2017-06-15 15:40:55,081 main.py:103] epoch 704, training loss: 7426.87, average training loss: 7358.13
[INFO 2017-06-15 15:40:56,581 main.py:103] epoch 705, training loss: 6140.69, average training loss: 7356.41
[INFO 2017-06-15 15:40:58,084 main.py:103] epoch 706, training loss: 6635.86, average training loss: 7355.39
[INFO 2017-06-15 15:40:59,587 main.py:103] epoch 707, training loss: 6679.81, average training loss: 7354.43
[INFO 2017-06-15 15:41:01,104 main.py:103] epoch 708, training loss: 7061.84, average training loss: 7354.02
[INFO 2017-06-15 15:41:02,605 main.py:103] epoch 709, training loss: 6258.33, average training loss: 7352.48
[INFO 2017-06-15 15:41:04,111 main.py:103] epoch 710, training loss: 7265.07, average training loss: 7352.35
[INFO 2017-06-15 15:41:05,616 main.py:103] epoch 711, training loss: 6312.57, average training loss: 7350.89
[INFO 2017-06-15 15:41:07,114 main.py:103] epoch 712, training loss: 7283.83, average training loss: 7350.80
[INFO 2017-06-15 15:41:08,616 main.py:103] epoch 713, training loss: 7304.30, average training loss: 7350.73
[INFO 2017-06-15 15:41:10,118 main.py:103] epoch 714, training loss: 7457.99, average training loss: 7350.88
[INFO 2017-06-15 15:41:11,616 main.py:103] epoch 715, training loss: 6974.96, average training loss: 7350.36
[INFO 2017-06-15 15:41:13,115 main.py:103] epoch 716, training loss: 6731.77, average training loss: 7349.50
[INFO 2017-06-15 15:41:14,612 main.py:103] epoch 717, training loss: 7181.23, average training loss: 7349.26
[INFO 2017-06-15 15:41:16,110 main.py:103] epoch 718, training loss: 6590.78, average training loss: 7348.21
[INFO 2017-06-15 15:41:17,609 main.py:103] epoch 719, training loss: 6289.56, average training loss: 7346.74
[INFO 2017-06-15 15:41:19,107 main.py:103] epoch 720, training loss: 7277.27, average training loss: 7346.64
[INFO 2017-06-15 15:41:20,605 main.py:103] epoch 721, training loss: 7060.65, average training loss: 7346.25
[INFO 2017-06-15 15:41:22,104 main.py:103] epoch 722, training loss: 6700.72, average training loss: 7345.35
[INFO 2017-06-15 15:41:23,609 main.py:103] epoch 723, training loss: 6490.51, average training loss: 7344.17
[INFO 2017-06-15 15:41:25,110 main.py:103] epoch 724, training loss: 6756.45, average training loss: 7343.36
[INFO 2017-06-15 15:41:26,610 main.py:103] epoch 725, training loss: 6479.76, average training loss: 7342.17
[INFO 2017-06-15 15:41:28,109 main.py:103] epoch 726, training loss: 6342.38, average training loss: 7340.80
[INFO 2017-06-15 15:41:29,609 main.py:103] epoch 727, training loss: 7081.35, average training loss: 7340.44
[INFO 2017-06-15 15:41:31,112 main.py:103] epoch 728, training loss: 6303.55, average training loss: 7339.02
[INFO 2017-06-15 15:41:32,612 main.py:103] epoch 729, training loss: 6768.26, average training loss: 7338.24
[INFO 2017-06-15 15:41:34,111 main.py:103] epoch 730, training loss: 6212.08, average training loss: 7336.69
[INFO 2017-06-15 15:41:35,611 main.py:103] epoch 731, training loss: 6180.53, average training loss: 7335.12
[INFO 2017-06-15 15:41:37,110 main.py:103] epoch 732, training loss: 6624.90, average training loss: 7334.15
[INFO 2017-06-15 15:41:38,610 main.py:103] epoch 733, training loss: 6746.19, average training loss: 7333.35
[INFO 2017-06-15 15:41:40,109 main.py:103] epoch 734, training loss: 7164.30, average training loss: 7333.12
[INFO 2017-06-15 15:41:41,609 main.py:103] epoch 735, training loss: 6000.15, average training loss: 7331.30
[INFO 2017-06-15 15:41:43,108 main.py:103] epoch 736, training loss: 7255.41, average training loss: 7331.20
[INFO 2017-06-15 15:41:44,608 main.py:103] epoch 737, training loss: 6686.34, average training loss: 7330.33
[INFO 2017-06-15 15:41:46,107 main.py:103] epoch 738, training loss: 6507.60, average training loss: 7329.21
[INFO 2017-06-15 15:41:47,607 main.py:103] epoch 739, training loss: 6656.01, average training loss: 7328.30
[INFO 2017-06-15 15:41:49,111 main.py:103] epoch 740, training loss: 6281.62, average training loss: 7326.89
[INFO 2017-06-15 15:41:50,611 main.py:103] epoch 741, training loss: 6922.86, average training loss: 7326.35
[INFO 2017-06-15 15:41:52,110 main.py:103] epoch 742, training loss: 6864.26, average training loss: 7325.73
[INFO 2017-06-15 15:41:53,610 main.py:103] epoch 743, training loss: 6847.04, average training loss: 7325.08
[INFO 2017-06-15 15:41:55,110 main.py:103] epoch 744, training loss: 6440.67, average training loss: 7323.90
[INFO 2017-06-15 15:41:56,610 main.py:103] epoch 745, training loss: 6600.01, average training loss: 7322.92
[INFO 2017-06-15 15:41:58,111 main.py:103] epoch 746, training loss: 7136.05, average training loss: 7322.67
[INFO 2017-06-15 15:41:59,610 main.py:103] epoch 747, training loss: 6343.02, average training loss: 7321.36
[INFO 2017-06-15 15:42:01,111 main.py:103] epoch 748, training loss: 6987.58, average training loss: 7320.92
[INFO 2017-06-15 15:42:02,612 main.py:103] epoch 749, training loss: 7188.93, average training loss: 7320.74
[INFO 2017-06-15 15:42:04,114 main.py:103] epoch 750, training loss: 6468.83, average training loss: 7319.61
[INFO 2017-06-15 15:42:05,618 main.py:103] epoch 751, training loss: 6022.40, average training loss: 7317.88
[INFO 2017-06-15 15:42:07,119 main.py:103] epoch 752, training loss: 6385.71, average training loss: 7316.65
[INFO 2017-06-15 15:42:08,619 main.py:103] epoch 753, training loss: 6822.68, average training loss: 7315.99
[INFO 2017-06-15 15:42:10,119 main.py:103] epoch 754, training loss: 6721.49, average training loss: 7315.20
[INFO 2017-06-15 15:42:11,620 main.py:103] epoch 755, training loss: 6870.50, average training loss: 7314.62
[INFO 2017-06-15 15:42:13,121 main.py:103] epoch 756, training loss: 6780.78, average training loss: 7313.91
[INFO 2017-06-15 15:42:14,621 main.py:103] epoch 757, training loss: 7236.68, average training loss: 7313.81
[INFO 2017-06-15 15:42:16,121 main.py:103] epoch 758, training loss: 6881.47, average training loss: 7313.24
[INFO 2017-06-15 15:42:17,622 main.py:103] epoch 759, training loss: 6283.52, average training loss: 7311.88
[INFO 2017-06-15 15:42:19,122 main.py:103] epoch 760, training loss: 6119.90, average training loss: 7310.32
[INFO 2017-06-15 15:42:20,623 main.py:103] epoch 761, training loss: 7305.82, average training loss: 7310.31
[INFO 2017-06-15 15:42:22,124 main.py:103] epoch 762, training loss: 6272.82, average training loss: 7308.95
[INFO 2017-06-15 15:42:23,625 main.py:103] epoch 763, training loss: 7031.54, average training loss: 7308.59
[INFO 2017-06-15 15:42:25,126 main.py:103] epoch 764, training loss: 6935.77, average training loss: 7308.10
[INFO 2017-06-15 15:42:26,628 main.py:103] epoch 765, training loss: 6686.34, average training loss: 7307.29
[INFO 2017-06-15 15:42:28,128 main.py:103] epoch 766, training loss: 6394.44, average training loss: 7306.10
[INFO 2017-06-15 15:42:29,629 main.py:103] epoch 767, training loss: 6677.73, average training loss: 7305.28
[INFO 2017-06-15 15:42:31,130 main.py:103] epoch 768, training loss: 5945.38, average training loss: 7303.51
[INFO 2017-06-15 15:42:32,630 main.py:103] epoch 769, training loss: 7162.04, average training loss: 7303.33
[INFO 2017-06-15 15:42:34,130 main.py:103] epoch 770, training loss: 7511.21, average training loss: 7303.60
[INFO 2017-06-15 15:42:35,631 main.py:103] epoch 771, training loss: 6705.86, average training loss: 7302.82
[INFO 2017-06-15 15:42:37,131 main.py:103] epoch 772, training loss: 6412.96, average training loss: 7301.67
[INFO 2017-06-15 15:42:38,633 main.py:103] epoch 773, training loss: 6457.88, average training loss: 7300.58
[INFO 2017-06-15 15:42:40,133 main.py:103] epoch 774, training loss: 6702.65, average training loss: 7299.81
[INFO 2017-06-15 15:42:41,634 main.py:103] epoch 775, training loss: 6577.20, average training loss: 7298.88
[INFO 2017-06-15 15:42:43,134 main.py:103] epoch 776, training loss: 6451.79, average training loss: 7297.79
[INFO 2017-06-15 15:42:44,634 main.py:103] epoch 777, training loss: 6642.72, average training loss: 7296.95
[INFO 2017-06-15 15:42:46,136 main.py:103] epoch 778, training loss: 6348.75, average training loss: 7295.73
[INFO 2017-06-15 15:42:47,638 main.py:103] epoch 779, training loss: 7141.01, average training loss: 7295.53
[INFO 2017-06-15 15:42:49,138 main.py:103] epoch 780, training loss: 6767.59, average training loss: 7294.86
[INFO 2017-06-15 15:42:50,638 main.py:103] epoch 781, training loss: 6915.97, average training loss: 7294.37
[INFO 2017-06-15 15:42:52,142 main.py:103] epoch 782, training loss: 7364.55, average training loss: 7294.46
[INFO 2017-06-15 15:42:53,643 main.py:103] epoch 783, training loss: 6590.69, average training loss: 7293.56
[INFO 2017-06-15 15:42:55,144 main.py:103] epoch 784, training loss: 6454.84, average training loss: 7292.50
[INFO 2017-06-15 15:42:56,643 main.py:103] epoch 785, training loss: 7228.21, average training loss: 7292.41
[INFO 2017-06-15 15:42:58,143 main.py:103] epoch 786, training loss: 6748.59, average training loss: 7291.72
[INFO 2017-06-15 15:42:59,642 main.py:103] epoch 787, training loss: 7173.57, average training loss: 7291.57
[INFO 2017-06-15 15:43:01,141 main.py:103] epoch 788, training loss: 6151.98, average training loss: 7290.13
[INFO 2017-06-15 15:43:02,639 main.py:103] epoch 789, training loss: 7235.33, average training loss: 7290.06
[INFO 2017-06-15 15:43:04,138 main.py:103] epoch 790, training loss: 6933.35, average training loss: 7289.61
[INFO 2017-06-15 15:43:05,637 main.py:103] epoch 791, training loss: 6490.47, average training loss: 7288.60
[INFO 2017-06-15 15:43:07,135 main.py:103] epoch 792, training loss: 7049.28, average training loss: 7288.30
[INFO 2017-06-15 15:43:08,635 main.py:103] epoch 793, training loss: 6557.02, average training loss: 7287.38
[INFO 2017-06-15 15:43:10,135 main.py:103] epoch 794, training loss: 6639.55, average training loss: 7286.56
[INFO 2017-06-15 15:43:11,635 main.py:103] epoch 795, training loss: 6856.92, average training loss: 7286.02
[INFO 2017-06-15 15:43:13,135 main.py:103] epoch 796, training loss: 6654.84, average training loss: 7285.23
[INFO 2017-06-15 15:43:14,635 main.py:103] epoch 797, training loss: 5868.46, average training loss: 7283.45
[INFO 2017-06-15 15:43:16,132 main.py:103] epoch 798, training loss: 6326.24, average training loss: 7282.26
[INFO 2017-06-15 15:43:17,631 main.py:103] epoch 799, training loss: 6296.36, average training loss: 7281.02
[INFO 2017-06-15 15:43:17,631 main.py:105] epoch 799, testing
[INFO 2017-06-15 15:44:33,596 main.py:54] average testing loss: 6718.98
[INFO 2017-06-15 15:44:33,600 main.py:25] current best accuracy: 6698.48
[INFO 2017-06-15 15:44:35,099 main.py:103] epoch 800, training loss: 6941.75, average training loss: 7280.60
[INFO 2017-06-15 15:44:36,597 main.py:103] epoch 801, training loss: 6448.02, average training loss: 7279.56
[INFO 2017-06-15 15:44:38,095 main.py:103] epoch 802, training loss: 6571.70, average training loss: 7278.68
[INFO 2017-06-15 15:44:39,593 main.py:103] epoch 803, training loss: 6464.29, average training loss: 7277.67
[INFO 2017-06-15 15:44:41,090 main.py:103] epoch 804, training loss: 6622.90, average training loss: 7276.85
[INFO 2017-06-15 15:44:42,590 main.py:103] epoch 805, training loss: 6611.87, average training loss: 7276.03
[INFO 2017-06-15 15:44:44,088 main.py:103] epoch 806, training loss: 6369.13, average training loss: 7274.91
[INFO 2017-06-15 15:44:45,587 main.py:103] epoch 807, training loss: 6312.66, average training loss: 7273.71
[INFO 2017-06-15 15:44:47,085 main.py:103] epoch 808, training loss: 6434.44, average training loss: 7272.68
[INFO 2017-06-15 15:44:48,583 main.py:103] epoch 809, training loss: 6490.46, average training loss: 7271.71
[INFO 2017-06-15 15:44:50,081 main.py:103] epoch 810, training loss: 6535.98, average training loss: 7270.80
[INFO 2017-06-15 15:44:51,579 main.py:103] epoch 811, training loss: 5887.41, average training loss: 7269.10
[INFO 2017-06-15 15:44:53,077 main.py:103] epoch 812, training loss: 7235.61, average training loss: 7269.06
[INFO 2017-06-15 15:44:54,575 main.py:103] epoch 813, training loss: 7563.03, average training loss: 7269.42
[INFO 2017-06-15 15:44:56,073 main.py:103] epoch 814, training loss: 6159.69, average training loss: 7268.06
[INFO 2017-06-15 15:44:57,571 main.py:103] epoch 815, training loss: 6882.63, average training loss: 7267.59
[INFO 2017-06-15 15:44:59,070 main.py:103] epoch 816, training loss: 7092.11, average training loss: 7267.37
[INFO 2017-06-15 15:45:00,568 main.py:103] epoch 817, training loss: 6279.62, average training loss: 7266.16
[INFO 2017-06-15 15:45:02,067 main.py:103] epoch 818, training loss: 7097.40, average training loss: 7265.96
[INFO 2017-06-15 15:45:03,565 main.py:103] epoch 819, training loss: 6334.00, average training loss: 7264.82
[INFO 2017-06-15 15:45:05,063 main.py:103] epoch 820, training loss: 6375.31, average training loss: 7263.74
[INFO 2017-06-15 15:45:06,561 main.py:103] epoch 821, training loss: 7000.28, average training loss: 7263.42
[INFO 2017-06-15 15:45:08,059 main.py:103] epoch 822, training loss: 6939.25, average training loss: 7263.02
[INFO 2017-06-15 15:45:09,557 main.py:103] epoch 823, training loss: 7173.98, average training loss: 7262.92
[INFO 2017-06-15 15:45:11,055 main.py:103] epoch 824, training loss: 6936.91, average training loss: 7262.52
[INFO 2017-06-15 15:45:12,552 main.py:103] epoch 825, training loss: 6568.77, average training loss: 7261.68
[INFO 2017-06-15 15:45:14,050 main.py:103] epoch 826, training loss: 6300.08, average training loss: 7260.52
[INFO 2017-06-15 15:45:15,550 main.py:103] epoch 827, training loss: 6250.18, average training loss: 7259.30
[INFO 2017-06-15 15:45:17,050 main.py:103] epoch 828, training loss: 6770.67, average training loss: 7258.71
[INFO 2017-06-15 15:45:18,550 main.py:103] epoch 829, training loss: 6858.44, average training loss: 7258.23
[INFO 2017-06-15 15:45:20,051 main.py:103] epoch 830, training loss: 6743.21, average training loss: 7257.61
[INFO 2017-06-15 15:45:21,550 main.py:103] epoch 831, training loss: 6414.83, average training loss: 7256.59
[INFO 2017-06-15 15:45:23,049 main.py:103] epoch 832, training loss: 6245.48, average training loss: 7255.38
[INFO 2017-06-15 15:45:24,549 main.py:103] epoch 833, training loss: 6933.13, average training loss: 7254.99
[INFO 2017-06-15 15:45:26,049 main.py:103] epoch 834, training loss: 6719.15, average training loss: 7254.35
[INFO 2017-06-15 15:45:27,549 main.py:103] epoch 835, training loss: 6030.63, average training loss: 7252.89
[INFO 2017-06-15 15:45:29,048 main.py:103] epoch 836, training loss: 6790.54, average training loss: 7252.34
[INFO 2017-06-15 15:45:30,547 main.py:103] epoch 837, training loss: 6697.86, average training loss: 7251.67
[INFO 2017-06-15 15:45:32,047 main.py:103] epoch 838, training loss: 5882.23, average training loss: 7250.04
[INFO 2017-06-15 15:45:33,545 main.py:103] epoch 839, training loss: 6277.05, average training loss: 7248.88
[INFO 2017-06-15 15:45:35,045 main.py:103] epoch 840, training loss: 6937.94, average training loss: 7248.51
[INFO 2017-06-15 15:45:36,544 main.py:103] epoch 841, training loss: 6435.33, average training loss: 7247.55
[INFO 2017-06-15 15:45:38,043 main.py:103] epoch 842, training loss: 6878.00, average training loss: 7247.11
[INFO 2017-06-15 15:45:39,548 main.py:103] epoch 843, training loss: 7225.73, average training loss: 7247.08
[INFO 2017-06-15 15:45:41,047 main.py:103] epoch 844, training loss: 6882.63, average training loss: 7246.65
[INFO 2017-06-15 15:45:42,545 main.py:103] epoch 845, training loss: 6950.97, average training loss: 7246.30
[INFO 2017-06-15 15:45:44,045 main.py:103] epoch 846, training loss: 6625.22, average training loss: 7245.57
[INFO 2017-06-15 15:45:45,545 main.py:103] epoch 847, training loss: 6614.48, average training loss: 7244.83
[INFO 2017-06-15 15:45:47,044 main.py:103] epoch 848, training loss: 6520.42, average training loss: 7243.97
[INFO 2017-06-15 15:45:48,542 main.py:103] epoch 849, training loss: 6532.59, average training loss: 7243.14
[INFO 2017-06-15 15:45:50,042 main.py:103] epoch 850, training loss: 6743.53, average training loss: 7242.55
[INFO 2017-06-15 15:45:51,540 main.py:103] epoch 851, training loss: 6098.52, average training loss: 7241.21
[INFO 2017-06-15 15:45:53,038 main.py:103] epoch 852, training loss: 5904.54, average training loss: 7239.64
[INFO 2017-06-15 15:45:54,537 main.py:103] epoch 853, training loss: 7096.27, average training loss: 7239.47
[INFO 2017-06-15 15:45:56,035 main.py:103] epoch 854, training loss: 6506.30, average training loss: 7238.61
[INFO 2017-06-15 15:45:57,533 main.py:103] epoch 855, training loss: 6418.71, average training loss: 7237.66
[INFO 2017-06-15 15:45:59,031 main.py:103] epoch 856, training loss: 6515.52, average training loss: 7236.81
[INFO 2017-06-15 15:46:00,530 main.py:103] epoch 857, training loss: 6353.21, average training loss: 7235.78
[INFO 2017-06-15 15:46:02,029 main.py:103] epoch 858, training loss: 6628.94, average training loss: 7235.08
[INFO 2017-06-15 15:46:03,528 main.py:103] epoch 859, training loss: 6408.24, average training loss: 7234.12
[INFO 2017-06-15 15:46:05,028 main.py:103] epoch 860, training loss: 5904.97, average training loss: 7232.57
[INFO 2017-06-15 15:46:06,527 main.py:103] epoch 861, training loss: 7216.17, average training loss: 7232.55
[INFO 2017-06-15 15:46:08,031 main.py:103] epoch 862, training loss: 6922.82, average training loss: 7232.19
[INFO 2017-06-15 15:46:09,534 main.py:103] epoch 863, training loss: 6747.74, average training loss: 7231.63
[INFO 2017-06-15 15:46:11,032 main.py:103] epoch 864, training loss: 6351.73, average training loss: 7230.62
[INFO 2017-06-15 15:46:12,531 main.py:103] epoch 865, training loss: 6667.05, average training loss: 7229.96
[INFO 2017-06-15 15:46:14,031 main.py:103] epoch 866, training loss: 6950.14, average training loss: 7229.64
[INFO 2017-06-15 15:46:15,530 main.py:103] epoch 867, training loss: 7111.30, average training loss: 7229.51
[INFO 2017-06-15 15:46:17,029 main.py:103] epoch 868, training loss: 5998.54, average training loss: 7228.09
[INFO 2017-06-15 15:46:18,530 main.py:103] epoch 869, training loss: 6331.63, average training loss: 7227.06
[INFO 2017-06-15 15:46:20,028 main.py:103] epoch 870, training loss: 6481.35, average training loss: 7226.20
[INFO 2017-06-15 15:46:21,526 main.py:103] epoch 871, training loss: 6771.84, average training loss: 7225.68
[INFO 2017-06-15 15:46:23,024 main.py:103] epoch 872, training loss: 6303.92, average training loss: 7224.63
[INFO 2017-06-15 15:46:24,531 main.py:103] epoch 873, training loss: 6164.86, average training loss: 7223.41
[INFO 2017-06-15 15:46:26,036 main.py:103] epoch 874, training loss: 6050.00, average training loss: 7222.07
[INFO 2017-06-15 15:46:27,538 main.py:103] epoch 875, training loss: 6598.55, average training loss: 7221.36
[INFO 2017-06-15 15:46:29,046 main.py:103] epoch 876, training loss: 6480.53, average training loss: 7220.52
[INFO 2017-06-15 15:46:30,555 main.py:103] epoch 877, training loss: 6611.31, average training loss: 7219.82
[INFO 2017-06-15 15:46:32,058 main.py:103] epoch 878, training loss: 6335.27, average training loss: 7218.82
[INFO 2017-06-15 15:46:33,627 main.py:103] epoch 879, training loss: 6144.33, average training loss: 7217.59
[INFO 2017-06-15 15:46:35,126 main.py:103] epoch 880, training loss: 6589.47, average training loss: 7216.88
[INFO 2017-06-15 15:46:36,666 main.py:103] epoch 881, training loss: 6530.70, average training loss: 7216.10
[INFO 2017-06-15 15:46:38,170 main.py:103] epoch 882, training loss: 6007.08, average training loss: 7214.73
[INFO 2017-06-15 15:46:39,673 main.py:103] epoch 883, training loss: 6513.43, average training loss: 7213.94
[INFO 2017-06-15 15:46:41,231 main.py:103] epoch 884, training loss: 6963.60, average training loss: 7213.66
[INFO 2017-06-15 15:46:42,733 main.py:103] epoch 885, training loss: 6827.09, average training loss: 7213.22
[INFO 2017-06-15 15:46:44,270 main.py:103] epoch 886, training loss: 6027.83, average training loss: 7211.89
[INFO 2017-06-15 15:46:45,773 main.py:103] epoch 887, training loss: 6711.94, average training loss: 7211.32
[INFO 2017-06-15 15:46:47,307 main.py:103] epoch 888, training loss: 7051.29, average training loss: 7211.14
[INFO 2017-06-15 15:46:48,846 main.py:103] epoch 889, training loss: 6789.61, average training loss: 7210.67
[INFO 2017-06-15 15:46:50,393 main.py:103] epoch 890, training loss: 6578.77, average training loss: 7209.96
[INFO 2017-06-15 15:46:51,893 main.py:103] epoch 891, training loss: 6429.64, average training loss: 7209.08
[INFO 2017-06-15 15:46:53,464 main.py:103] epoch 892, training loss: 6510.15, average training loss: 7208.30
[INFO 2017-06-15 15:46:55,017 main.py:103] epoch 893, training loss: 7060.51, average training loss: 7208.14
[INFO 2017-06-15 15:46:56,519 main.py:103] epoch 894, training loss: 7250.32, average training loss: 7208.18
[INFO 2017-06-15 15:46:58,018 main.py:103] epoch 895, training loss: 6438.45, average training loss: 7207.32
[INFO 2017-06-15 15:46:59,551 main.py:103] epoch 896, training loss: 6442.10, average training loss: 7206.47
[INFO 2017-06-15 15:47:01,103 main.py:103] epoch 897, training loss: 6666.96, average training loss: 7205.87
[INFO 2017-06-15 15:47:02,620 main.py:103] epoch 898, training loss: 6222.02, average training loss: 7204.78
[INFO 2017-06-15 15:47:04,188 main.py:103] epoch 899, training loss: 6609.25, average training loss: 7204.11
[INFO 2017-06-15 15:47:04,188 main.py:105] epoch 899, testing
[INFO 2017-06-15 15:48:20,985 main.py:54] average testing loss: 6693.49
[INFO 2017-06-15 15:48:20,989 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:48:20,997 main.py:25] current best accuracy: 6693.49
[INFO 2017-06-15 15:48:22,506 main.py:103] epoch 900, training loss: 6533.58, average training loss: 7203.37
[INFO 2017-06-15 15:48:24,005 main.py:103] epoch 901, training loss: 6622.95, average training loss: 7202.73
[INFO 2017-06-15 15:48:25,505 main.py:103] epoch 902, training loss: 7170.24, average training loss: 7202.69
[INFO 2017-06-15 15:48:27,029 main.py:103] epoch 903, training loss: 6482.80, average training loss: 7201.89
[INFO 2017-06-15 15:48:28,527 main.py:103] epoch 904, training loss: 6419.88, average training loss: 7201.03
[INFO 2017-06-15 15:48:30,040 main.py:103] epoch 905, training loss: 6029.38, average training loss: 7199.74
[INFO 2017-06-15 15:48:31,542 main.py:103] epoch 906, training loss: 7564.88, average training loss: 7200.14
[INFO 2017-06-15 15:48:33,043 main.py:103] epoch 907, training loss: 6725.04, average training loss: 7199.62
[INFO 2017-06-15 15:48:34,580 main.py:103] epoch 908, training loss: 6359.12, average training loss: 7198.69
[INFO 2017-06-15 15:48:36,099 main.py:103] epoch 909, training loss: 7359.09, average training loss: 7198.87
[INFO 2017-06-15 15:48:37,597 main.py:103] epoch 910, training loss: 6466.29, average training loss: 7198.06
[INFO 2017-06-15 15:48:39,097 main.py:103] epoch 911, training loss: 6726.60, average training loss: 7197.55
[INFO 2017-06-15 15:48:40,595 main.py:103] epoch 912, training loss: 6409.34, average training loss: 7196.68
[INFO 2017-06-15 15:48:42,094 main.py:103] epoch 913, training loss: 6619.46, average training loss: 7196.05
[INFO 2017-06-15 15:48:43,593 main.py:103] epoch 914, training loss: 6271.83, average training loss: 7195.04
[INFO 2017-06-15 15:48:45,093 main.py:103] epoch 915, training loss: 5864.80, average training loss: 7193.59
[INFO 2017-06-15 15:48:46,591 main.py:103] epoch 916, training loss: 6894.65, average training loss: 7193.26
[INFO 2017-06-15 15:48:48,093 main.py:103] epoch 917, training loss: 6508.98, average training loss: 7192.52
[INFO 2017-06-15 15:48:49,627 main.py:103] epoch 918, training loss: 6450.87, average training loss: 7191.71
[INFO 2017-06-15 15:48:51,151 main.py:103] epoch 919, training loss: 6237.15, average training loss: 7190.67
[INFO 2017-06-15 15:48:52,650 main.py:103] epoch 920, training loss: 6871.22, average training loss: 7190.33
[INFO 2017-06-15 15:48:54,149 main.py:103] epoch 921, training loss: 6220.75, average training loss: 7189.28
[INFO 2017-06-15 15:48:55,653 main.py:103] epoch 922, training loss: 5606.27, average training loss: 7187.56
[INFO 2017-06-15 15:48:57,152 main.py:103] epoch 923, training loss: 7216.02, average training loss: 7187.59
[INFO 2017-06-15 15:48:58,650 main.py:103] epoch 924, training loss: 6104.62, average training loss: 7186.42
[INFO 2017-06-15 15:49:00,148 main.py:103] epoch 925, training loss: 6748.71, average training loss: 7185.95
[INFO 2017-06-15 15:49:01,656 main.py:103] epoch 926, training loss: 7583.84, average training loss: 7186.38
[INFO 2017-06-15 15:49:03,156 main.py:103] epoch 927, training loss: 6945.33, average training loss: 7186.12
[INFO 2017-06-15 15:49:04,655 main.py:103] epoch 928, training loss: 6038.44, average training loss: 7184.88
[INFO 2017-06-15 15:49:06,158 main.py:103] epoch 929, training loss: 6714.43, average training loss: 7184.38
[INFO 2017-06-15 15:49:07,663 main.py:103] epoch 930, training loss: 6649.82, average training loss: 7183.80
[INFO 2017-06-15 15:49:09,161 main.py:103] epoch 931, training loss: 6216.03, average training loss: 7182.76
[INFO 2017-06-15 15:49:10,664 main.py:103] epoch 932, training loss: 6462.05, average training loss: 7181.99
[INFO 2017-06-15 15:49:12,164 main.py:103] epoch 933, training loss: 6260.13, average training loss: 7181.00
[INFO 2017-06-15 15:49:13,664 main.py:103] epoch 934, training loss: 6177.91, average training loss: 7179.93
[INFO 2017-06-15 15:49:15,163 main.py:103] epoch 935, training loss: 7509.65, average training loss: 7180.28
[INFO 2017-06-15 15:49:16,663 main.py:103] epoch 936, training loss: 6318.23, average training loss: 7179.36
[INFO 2017-06-15 15:49:18,163 main.py:103] epoch 937, training loss: 6681.91, average training loss: 7178.83
[INFO 2017-06-15 15:49:19,664 main.py:103] epoch 938, training loss: 6841.76, average training loss: 7178.47
[INFO 2017-06-15 15:49:21,164 main.py:103] epoch 939, training loss: 6670.60, average training loss: 7177.93
[INFO 2017-06-15 15:49:22,663 main.py:103] epoch 940, training loss: 5744.99, average training loss: 7176.41
[INFO 2017-06-15 15:49:24,161 main.py:103] epoch 941, training loss: 6720.30, average training loss: 7175.93
[INFO 2017-06-15 15:49:25,662 main.py:103] epoch 942, training loss: 6623.21, average training loss: 7175.34
[INFO 2017-06-15 15:49:27,162 main.py:103] epoch 943, training loss: 7208.93, average training loss: 7175.38
[INFO 2017-06-15 15:49:28,660 main.py:103] epoch 944, training loss: 5627.09, average training loss: 7173.74
[INFO 2017-06-15 15:49:30,158 main.py:103] epoch 945, training loss: 6695.73, average training loss: 7173.23
[INFO 2017-06-15 15:49:31,655 main.py:103] epoch 946, training loss: 6271.62, average training loss: 7172.28
[INFO 2017-06-15 15:49:33,153 main.py:103] epoch 947, training loss: 6202.62, average training loss: 7171.26
[INFO 2017-06-15 15:49:34,651 main.py:103] epoch 948, training loss: 6261.92, average training loss: 7170.30
[INFO 2017-06-15 15:49:36,148 main.py:103] epoch 949, training loss: 6941.73, average training loss: 7170.06
[INFO 2017-06-15 15:49:37,648 main.py:103] epoch 950, training loss: 6391.09, average training loss: 7169.24
[INFO 2017-06-15 15:49:39,152 main.py:103] epoch 951, training loss: 6715.21, average training loss: 7168.76
[INFO 2017-06-15 15:49:40,655 main.py:103] epoch 952, training loss: 6924.88, average training loss: 7168.51
[INFO 2017-06-15 15:49:42,160 main.py:103] epoch 953, training loss: 6365.21, average training loss: 7167.67
[INFO 2017-06-15 15:49:43,659 main.py:103] epoch 954, training loss: 6496.80, average training loss: 7166.96
[INFO 2017-06-15 15:49:45,157 main.py:103] epoch 955, training loss: 7129.96, average training loss: 7166.92
[INFO 2017-06-15 15:49:46,657 main.py:103] epoch 956, training loss: 7428.29, average training loss: 7167.20
[INFO 2017-06-15 15:49:48,155 main.py:103] epoch 957, training loss: 6387.19, average training loss: 7166.38
[INFO 2017-06-15 15:49:49,653 main.py:103] epoch 958, training loss: 6950.01, average training loss: 7166.16
[INFO 2017-06-15 15:49:51,152 main.py:103] epoch 959, training loss: 6620.36, average training loss: 7165.59
[INFO 2017-06-15 15:49:52,650 main.py:103] epoch 960, training loss: 7435.80, average training loss: 7165.87
[INFO 2017-06-15 15:49:54,149 main.py:103] epoch 961, training loss: 5890.71, average training loss: 7164.54
[INFO 2017-06-15 15:49:55,648 main.py:103] epoch 962, training loss: 6341.56, average training loss: 7163.69
[INFO 2017-06-15 15:49:57,149 main.py:103] epoch 963, training loss: 5814.51, average training loss: 7162.29
[INFO 2017-06-15 15:49:58,649 main.py:103] epoch 964, training loss: 5555.52, average training loss: 7160.63
[INFO 2017-06-15 15:50:00,147 main.py:103] epoch 965, training loss: 6854.73, average training loss: 7160.31
[INFO 2017-06-15 15:50:01,647 main.py:103] epoch 966, training loss: 6387.19, average training loss: 7159.51
[INFO 2017-06-15 15:50:03,145 main.py:103] epoch 967, training loss: 6612.94, average training loss: 7158.94
[INFO 2017-06-15 15:50:04,644 main.py:103] epoch 968, training loss: 7250.38, average training loss: 7159.04
[INFO 2017-06-15 15:50:06,142 main.py:103] epoch 969, training loss: 6298.61, average training loss: 7158.15
[INFO 2017-06-15 15:50:07,643 main.py:103] epoch 970, training loss: 6651.52, average training loss: 7157.63
[INFO 2017-06-15 15:50:09,143 main.py:103] epoch 971, training loss: 6531.29, average training loss: 7156.99
[INFO 2017-06-15 15:50:10,640 main.py:103] epoch 972, training loss: 7312.56, average training loss: 7157.15
[INFO 2017-06-15 15:50:12,138 main.py:103] epoch 973, training loss: 5949.50, average training loss: 7155.91
[INFO 2017-06-15 15:50:13,634 main.py:103] epoch 974, training loss: 6955.74, average training loss: 7155.70
[INFO 2017-06-15 15:50:15,133 main.py:103] epoch 975, training loss: 6667.31, average training loss: 7155.20
[INFO 2017-06-15 15:50:16,631 main.py:103] epoch 976, training loss: 6119.87, average training loss: 7154.14
[INFO 2017-06-15 15:50:18,128 main.py:103] epoch 977, training loss: 6214.73, average training loss: 7153.18
[INFO 2017-06-15 15:50:19,626 main.py:103] epoch 978, training loss: 6187.40, average training loss: 7152.19
[INFO 2017-06-15 15:50:21,123 main.py:103] epoch 979, training loss: 6613.40, average training loss: 7151.64
[INFO 2017-06-15 15:50:22,620 main.py:103] epoch 980, training loss: 7070.97, average training loss: 7151.56
[INFO 2017-06-15 15:50:24,118 main.py:103] epoch 981, training loss: 6735.29, average training loss: 7151.14
[INFO 2017-06-15 15:50:25,620 main.py:103] epoch 982, training loss: 6067.15, average training loss: 7150.03
[INFO 2017-06-15 15:50:27,119 main.py:103] epoch 983, training loss: 6405.54, average training loss: 7149.28
[INFO 2017-06-15 15:50:28,618 main.py:103] epoch 984, training loss: 7060.13, average training loss: 7149.19
[INFO 2017-06-15 15:50:30,116 main.py:103] epoch 985, training loss: 6427.84, average training loss: 7148.46
[INFO 2017-06-15 15:50:31,615 main.py:103] epoch 986, training loss: 5867.06, average training loss: 7147.16
[INFO 2017-06-15 15:50:33,122 main.py:103] epoch 987, training loss: 6397.09, average training loss: 7146.40
[INFO 2017-06-15 15:50:34,620 main.py:103] epoch 988, training loss: 6876.04, average training loss: 7146.12
[INFO 2017-06-15 15:50:36,118 main.py:103] epoch 989, training loss: 5764.77, average training loss: 7144.73
[INFO 2017-06-15 15:50:37,615 main.py:103] epoch 990, training loss: 7226.46, average training loss: 7144.81
[INFO 2017-06-15 15:50:39,112 main.py:103] epoch 991, training loss: 6066.83, average training loss: 7143.73
[INFO 2017-06-15 15:50:40,619 main.py:103] epoch 992, training loss: 7771.40, average training loss: 7144.36
[INFO 2017-06-15 15:50:42,118 main.py:103] epoch 993, training loss: 6451.65, average training loss: 7143.66
[INFO 2017-06-15 15:50:43,615 main.py:103] epoch 994, training loss: 7534.25, average training loss: 7144.05
[INFO 2017-06-15 15:50:45,113 main.py:103] epoch 995, training loss: 7184.60, average training loss: 7144.09
[INFO 2017-06-15 15:50:46,610 main.py:103] epoch 996, training loss: 6957.89, average training loss: 7143.91
[INFO 2017-06-15 15:50:48,107 main.py:103] epoch 997, training loss: 7074.68, average training loss: 7143.84
[INFO 2017-06-15 15:50:49,606 main.py:103] epoch 998, training loss: 6754.89, average training loss: 7143.45
[INFO 2017-06-15 15:50:51,104 main.py:103] epoch 999, training loss: 6358.46, average training loss: 7142.66
[INFO 2017-06-15 15:50:51,105 main.py:105] epoch 999, testing
[INFO 2017-06-15 15:52:06,872 main.py:54] average testing loss: 6660.22
[INFO 2017-06-15 15:52:06,875 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:52:06,883 main.py:25] current best accuracy: 6660.22
[INFO 2017-06-15 15:52:08,383 main.py:103] epoch 1000, training loss: 6142.06, average training loss: 7119.09
[INFO 2017-06-15 15:52:09,883 main.py:103] epoch 1001, training loss: 6264.09, average training loss: 7100.24
[INFO 2017-06-15 15:52:11,380 main.py:103] epoch 1002, training loss: 7311.52, average training loss: 7084.55
[INFO 2017-06-15 15:52:12,878 main.py:103] epoch 1003, training loss: 5623.04, average training loss: 7070.12
[INFO 2017-06-15 15:52:14,376 main.py:103] epoch 1004, training loss: 6751.38, average training loss: 7058.08
[INFO 2017-06-15 15:52:15,874 main.py:103] epoch 1005, training loss: 6639.02, average training loss: 7047.78
[INFO 2017-06-15 15:52:17,371 main.py:103] epoch 1006, training loss: 6593.68, average training loss: 7039.11
[INFO 2017-06-15 15:52:18,868 main.py:103] epoch 1007, training loss: 6851.94, average training loss: 7030.82
[INFO 2017-06-15 15:52:20,365 main.py:103] epoch 1008, training loss: 6172.69, average training loss: 7022.76
[INFO 2017-06-15 15:52:21,863 main.py:103] epoch 1009, training loss: 6481.49, average training loss: 7015.44
[INFO 2017-06-15 15:52:23,361 main.py:103] epoch 1010, training loss: 6659.81, average training loss: 7009.92
[INFO 2017-06-15 15:52:24,859 main.py:103] epoch 1011, training loss: 6349.38, average training loss: 7003.68
[INFO 2017-06-15 15:52:26,356 main.py:103] epoch 1012, training loss: 6448.01, average training loss: 6997.90
[INFO 2017-06-15 15:52:27,854 main.py:103] epoch 1013, training loss: 6800.08, average training loss: 6993.00
[INFO 2017-06-15 15:52:29,351 main.py:103] epoch 1014, training loss: 6768.42, average training loss: 6988.31
[INFO 2017-06-15 15:52:30,849 main.py:103] epoch 1015, training loss: 6761.98, average training loss: 6984.96
[INFO 2017-06-15 15:52:32,347 main.py:103] epoch 1016, training loss: 6693.25, average training loss: 6982.03
[INFO 2017-06-15 15:52:33,843 main.py:103] epoch 1017, training loss: 6290.16, average training loss: 6978.87
[INFO 2017-06-15 15:52:35,341 main.py:103] epoch 1018, training loss: 6959.90, average training loss: 6975.81
[INFO 2017-06-15 15:52:36,843 main.py:103] epoch 1019, training loss: 7075.03, average training loss: 6973.18
[INFO 2017-06-15 15:52:38,342 main.py:103] epoch 1020, training loss: 6429.98, average training loss: 6969.05
[INFO 2017-06-15 15:52:39,840 main.py:103] epoch 1021, training loss: 6432.00, average training loss: 6965.36
[INFO 2017-06-15 15:52:41,337 main.py:103] epoch 1022, training loss: 6319.06, average training loss: 6962.79
[INFO 2017-06-15 15:52:42,834 main.py:103] epoch 1023, training loss: 7060.57, average training loss: 6960.33
[INFO 2017-06-15 15:52:44,332 main.py:103] epoch 1024, training loss: 6704.81, average training loss: 6957.95
[INFO 2017-06-15 15:52:45,829 main.py:103] epoch 1025, training loss: 6569.19, average training loss: 6955.53
[INFO 2017-06-15 15:52:47,327 main.py:103] epoch 1026, training loss: 6892.16, average training loss: 6953.97
[INFO 2017-06-15 15:52:48,825 main.py:103] epoch 1027, training loss: 6198.92, average training loss: 6951.21
[INFO 2017-06-15 15:52:50,322 main.py:103] epoch 1028, training loss: 7377.87, average training loss: 6950.12
[INFO 2017-06-15 15:52:51,820 main.py:103] epoch 1029, training loss: 6054.81, average training loss: 6948.29
[INFO 2017-06-15 15:52:53,317 main.py:103] epoch 1030, training loss: 7275.57, average training loss: 6947.14
[INFO 2017-06-15 15:52:54,815 main.py:103] epoch 1031, training loss: 6984.64, average training loss: 6945.18
[INFO 2017-06-15 15:52:56,312 main.py:103] epoch 1032, training loss: 6457.99, average training loss: 6943.23
[INFO 2017-06-15 15:52:57,810 main.py:103] epoch 1033, training loss: 7382.89, average training loss: 6942.53
[INFO 2017-06-15 15:52:59,308 main.py:103] epoch 1034, training loss: 6537.58, average training loss: 6941.11
[INFO 2017-06-15 15:53:00,806 main.py:103] epoch 1035, training loss: 6821.37, average training loss: 6940.03
[INFO 2017-06-15 15:53:02,304 main.py:103] epoch 1036, training loss: 6458.79, average training loss: 6937.26
[INFO 2017-06-15 15:53:03,802 main.py:103] epoch 1037, training loss: 6622.50, average training loss: 6935.66
[INFO 2017-06-15 15:53:05,300 main.py:103] epoch 1038, training loss: 6719.63, average training loss: 6934.52
[INFO 2017-06-15 15:53:06,798 main.py:103] epoch 1039, training loss: 6626.65, average training loss: 6933.28
[INFO 2017-06-15 15:53:08,296 main.py:103] epoch 1040, training loss: 7089.39, average training loss: 6932.55
[INFO 2017-06-15 15:53:09,793 main.py:103] epoch 1041, training loss: 6159.05, average training loss: 6930.88
[INFO 2017-06-15 15:53:11,291 main.py:103] epoch 1042, training loss: 6222.04, average training loss: 6928.65
[INFO 2017-06-15 15:53:12,788 main.py:103] epoch 1043, training loss: 5920.72, average training loss: 6926.53
[INFO 2017-06-15 15:53:14,285 main.py:103] epoch 1044, training loss: 6852.31, average training loss: 6924.17
[INFO 2017-06-15 15:53:15,783 main.py:103] epoch 1045, training loss: 5896.87, average training loss: 6922.22
[INFO 2017-06-15 15:53:17,281 main.py:103] epoch 1046, training loss: 5869.37, average training loss: 6919.86
[INFO 2017-06-15 15:53:18,779 main.py:103] epoch 1047, training loss: 7167.57, average training loss: 6919.54
[INFO 2017-06-15 15:53:20,278 main.py:103] epoch 1048, training loss: 6463.91, average training loss: 6918.01
[INFO 2017-06-15 15:53:21,774 main.py:103] epoch 1049, training loss: 6215.24, average training loss: 6916.10
[INFO 2017-06-15 15:53:23,272 main.py:103] epoch 1050, training loss: 6612.41, average training loss: 6913.54
[INFO 2017-06-15 15:53:24,770 main.py:103] epoch 1051, training loss: 6850.10, average training loss: 6911.02
[INFO 2017-06-15 15:53:26,267 main.py:103] epoch 1052, training loss: 6175.98, average training loss: 6909.50
[INFO 2017-06-15 15:53:27,766 main.py:103] epoch 1053, training loss: 6387.18, average training loss: 6908.00
[INFO 2017-06-15 15:53:29,264 main.py:103] epoch 1054, training loss: 7143.70, average training loss: 6906.90
[INFO 2017-06-15 15:53:30,761 main.py:103] epoch 1055, training loss: 7102.11, average training loss: 6905.71
[INFO 2017-06-15 15:53:32,259 main.py:103] epoch 1056, training loss: 6888.59, average training loss: 6904.73
[INFO 2017-06-15 15:53:33,757 main.py:103] epoch 1057, training loss: 6785.52, average training loss: 6903.41
[INFO 2017-06-15 15:53:35,254 main.py:103] epoch 1058, training loss: 6459.12, average training loss: 6902.07
[INFO 2017-06-15 15:53:36,754 main.py:103] epoch 1059, training loss: 6565.28, average training loss: 6900.31
[INFO 2017-06-15 15:53:38,251 main.py:103] epoch 1060, training loss: 6352.14, average training loss: 6899.25
[INFO 2017-06-15 15:53:39,749 main.py:103] epoch 1061, training loss: 7309.88, average training loss: 6898.38
[INFO 2017-06-15 15:53:41,248 main.py:103] epoch 1062, training loss: 6616.34, average training loss: 6896.67
[INFO 2017-06-15 15:53:42,748 main.py:103] epoch 1063, training loss: 6705.54, average training loss: 6894.82
[INFO 2017-06-15 15:53:44,250 main.py:103] epoch 1064, training loss: 6491.75, average training loss: 6893.51
[INFO 2017-06-15 15:53:45,749 main.py:103] epoch 1065, training loss: 7015.15, average training loss: 6892.30
[INFO 2017-06-15 15:53:47,248 main.py:103] epoch 1066, training loss: 7043.71, average training loss: 6891.45
[INFO 2017-06-15 15:53:48,746 main.py:103] epoch 1067, training loss: 6756.94, average training loss: 6890.25
[INFO 2017-06-15 15:53:50,249 main.py:103] epoch 1068, training loss: 6273.31, average training loss: 6888.66
[INFO 2017-06-15 15:53:51,746 main.py:103] epoch 1069, training loss: 5942.73, average training loss: 6886.59
[INFO 2017-06-15 15:53:53,243 main.py:103] epoch 1070, training loss: 6147.44, average training loss: 6885.30
[INFO 2017-06-15 15:53:54,741 main.py:103] epoch 1071, training loss: 7031.26, average training loss: 6884.56
[INFO 2017-06-15 15:53:56,238 main.py:103] epoch 1072, training loss: 6198.57, average training loss: 6882.90
[INFO 2017-06-15 15:53:57,735 main.py:103] epoch 1073, training loss: 5840.24, average training loss: 6880.63
[INFO 2017-06-15 15:53:59,234 main.py:103] epoch 1074, training loss: 7864.39, average training loss: 6881.68
[INFO 2017-06-15 15:54:00,732 main.py:103] epoch 1075, training loss: 6997.98, average training loss: 6880.81
[INFO 2017-06-15 15:54:02,235 main.py:103] epoch 1076, training loss: 6293.45, average training loss: 6878.89
[INFO 2017-06-15 15:54:03,733 main.py:103] epoch 1077, training loss: 7192.43, average training loss: 6877.88
[INFO 2017-06-15 15:54:05,230 main.py:103] epoch 1078, training loss: 6130.43, average training loss: 6875.96
[INFO 2017-06-15 15:54:06,730 main.py:103] epoch 1079, training loss: 6832.66, average training loss: 6875.08
[INFO 2017-06-15 15:54:08,229 main.py:103] epoch 1080, training loss: 6752.96, average training loss: 6875.03
[INFO 2017-06-15 15:54:09,728 main.py:103] epoch 1081, training loss: 5939.84, average training loss: 6872.84
[INFO 2017-06-15 15:54:11,226 main.py:103] epoch 1082, training loss: 6369.54, average training loss: 6870.67
[INFO 2017-06-15 15:54:12,725 main.py:103] epoch 1083, training loss: 6638.99, average training loss: 6869.69
[INFO 2017-06-15 15:54:14,223 main.py:103] epoch 1084, training loss: 6331.89, average training loss: 6868.22
[INFO 2017-06-15 15:54:15,722 main.py:103] epoch 1085, training loss: 6850.34, average training loss: 6867.82
[INFO 2017-06-15 15:54:17,220 main.py:103] epoch 1086, training loss: 6732.37, average training loss: 6866.38
[INFO 2017-06-15 15:54:18,720 main.py:103] epoch 1087, training loss: 7121.28, average training loss: 6865.53
[INFO 2017-06-15 15:54:20,218 main.py:103] epoch 1088, training loss: 7282.83, average training loss: 6864.22
[INFO 2017-06-15 15:54:21,715 main.py:103] epoch 1089, training loss: 6474.06, average training loss: 6862.88
[INFO 2017-06-15 15:54:23,213 main.py:103] epoch 1090, training loss: 6787.88, average training loss: 6862.52
[INFO 2017-06-15 15:54:24,711 main.py:103] epoch 1091, training loss: 6428.75, average training loss: 6860.75
[INFO 2017-06-15 15:54:26,208 main.py:103] epoch 1092, training loss: 6168.34, average training loss: 6860.03
[INFO 2017-06-15 15:54:27,706 main.py:103] epoch 1093, training loss: 7432.88, average training loss: 6860.21
[INFO 2017-06-15 15:54:29,204 main.py:103] epoch 1094, training loss: 6155.89, average training loss: 6858.42
[INFO 2017-06-15 15:54:30,704 main.py:103] epoch 1095, training loss: 6254.66, average training loss: 6857.57
[INFO 2017-06-15 15:54:32,202 main.py:103] epoch 1096, training loss: 6134.56, average training loss: 6854.51
[INFO 2017-06-15 15:54:33,704 main.py:103] epoch 1097, training loss: 6763.41, average training loss: 6852.71
[INFO 2017-06-15 15:54:35,204 main.py:103] epoch 1098, training loss: 6921.44, average training loss: 6851.90
[INFO 2017-06-15 15:54:36,706 main.py:103] epoch 1099, training loss: 6134.44, average training loss: 6850.51
[INFO 2017-06-15 15:54:36,706 main.py:105] epoch 1099, testing
[INFO 2017-06-15 15:55:52,390 main.py:54] average testing loss: 6574.05
[INFO 2017-06-15 15:55:52,393 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:55:52,401 main.py:25] current best accuracy: 6574.05
[INFO 2017-06-15 15:55:53,898 main.py:103] epoch 1100, training loss: 6827.30, average training loss: 6850.04
[INFO 2017-06-15 15:55:55,396 main.py:103] epoch 1101, training loss: 6334.73, average training loss: 6849.48
[INFO 2017-06-15 15:55:56,893 main.py:103] epoch 1102, training loss: 6312.29, average training loss: 6848.79
[INFO 2017-06-15 15:55:58,392 main.py:103] epoch 1103, training loss: 6419.00, average training loss: 6846.16
[INFO 2017-06-15 15:55:59,891 main.py:103] epoch 1104, training loss: 6564.40, average training loss: 6845.21
[INFO 2017-06-15 15:56:01,389 main.py:103] epoch 1105, training loss: 6394.88, average training loss: 6843.91
[INFO 2017-06-15 15:56:02,891 main.py:103] epoch 1106, training loss: 7033.07, average training loss: 6843.45
[INFO 2017-06-15 15:56:04,391 main.py:103] epoch 1107, training loss: 5989.28, average training loss: 6841.39
[INFO 2017-06-15 15:56:05,889 main.py:103] epoch 1108, training loss: 6265.37, average training loss: 6840.73
[INFO 2017-06-15 15:56:07,388 main.py:103] epoch 1109, training loss: 6764.40, average training loss: 6839.15
[INFO 2017-06-15 15:56:08,888 main.py:103] epoch 1110, training loss: 6772.47, average training loss: 6838.56
[INFO 2017-06-15 15:56:10,387 main.py:103] epoch 1111, training loss: 7286.76, average training loss: 6838.17
[INFO 2017-06-15 15:56:11,887 main.py:103] epoch 1112, training loss: 6880.16, average training loss: 6837.76
[INFO 2017-06-15 15:56:13,384 main.py:103] epoch 1113, training loss: 6260.70, average training loss: 6837.02
[INFO 2017-06-15 15:56:14,882 main.py:103] epoch 1114, training loss: 6265.96, average training loss: 6835.50
[INFO 2017-06-15 15:56:16,382 main.py:103] epoch 1115, training loss: 6616.76, average training loss: 6833.83
[INFO 2017-06-15 15:56:17,879 main.py:103] epoch 1116, training loss: 6488.60, average training loss: 6832.56
[INFO 2017-06-15 15:56:19,379 main.py:103] epoch 1117, training loss: 6643.68, average training loss: 6831.91
[INFO 2017-06-15 15:56:20,878 main.py:103] epoch 1118, training loss: 7013.49, average training loss: 6831.02
[INFO 2017-06-15 15:56:22,378 main.py:103] epoch 1119, training loss: 6508.52, average training loss: 6830.28
[INFO 2017-06-15 15:56:23,889 main.py:103] epoch 1120, training loss: 6996.22, average training loss: 6830.43
[INFO 2017-06-15 15:56:25,421 main.py:103] epoch 1121, training loss: 6752.42, average training loss: 6829.67
[INFO 2017-06-15 15:56:26,926 main.py:103] epoch 1122, training loss: 6009.17, average training loss: 6828.35
[INFO 2017-06-15 15:56:28,452 main.py:103] epoch 1123, training loss: 6157.75, average training loss: 6826.21
[INFO 2017-06-15 15:56:29,981 main.py:103] epoch 1124, training loss: 6084.03, average training loss: 6825.38
[INFO 2017-06-15 15:56:31,504 main.py:103] epoch 1125, training loss: 6648.48, average training loss: 6824.86
[INFO 2017-06-15 15:56:33,007 main.py:103] epoch 1126, training loss: 5958.76, average training loss: 6823.89
[INFO 2017-06-15 15:56:34,514 main.py:103] epoch 1127, training loss: 6240.49, average training loss: 6823.42
[INFO 2017-06-15 15:56:36,022 main.py:103] epoch 1128, training loss: 6145.97, average training loss: 6822.18
[INFO 2017-06-15 15:56:37,527 main.py:103] epoch 1129, training loss: 6066.31, average training loss: 6820.57
[INFO 2017-06-15 15:56:39,031 main.py:103] epoch 1130, training loss: 6783.14, average training loss: 6820.22
[INFO 2017-06-15 15:56:40,536 main.py:103] epoch 1131, training loss: 6168.77, average training loss: 6819.00
[INFO 2017-06-15 15:56:42,042 main.py:103] epoch 1132, training loss: 5948.00, average training loss: 6817.28
[INFO 2017-06-15 15:56:43,543 main.py:103] epoch 1133, training loss: 6467.11, average training loss: 6816.45
[INFO 2017-06-15 15:56:45,050 main.py:103] epoch 1134, training loss: 6606.98, average training loss: 6815.37
[INFO 2017-06-15 15:56:46,559 main.py:103] epoch 1135, training loss: 6868.81, average training loss: 6815.28
[INFO 2017-06-15 15:56:48,060 main.py:103] epoch 1136, training loss: 6616.45, average training loss: 6814.95
[INFO 2017-06-15 15:56:49,571 main.py:103] epoch 1137, training loss: 6578.00, average training loss: 6814.15
[INFO 2017-06-15 15:56:51,095 main.py:103] epoch 1138, training loss: 6304.48, average training loss: 6812.23
[INFO 2017-06-15 15:56:52,628 main.py:103] epoch 1139, training loss: 7067.49, average training loss: 6811.78
[INFO 2017-06-15 15:56:54,161 main.py:103] epoch 1140, training loss: 6336.56, average training loss: 6810.71
[INFO 2017-06-15 15:56:55,784 main.py:103] epoch 1141, training loss: 6817.64, average training loss: 6810.32
[INFO 2017-06-15 15:56:57,310 main.py:103] epoch 1142, training loss: 7664.24, average training loss: 6809.70
[INFO 2017-06-15 15:56:58,906 main.py:103] epoch 1143, training loss: 6780.96, average training loss: 6809.28
[INFO 2017-06-15 15:57:00,475 main.py:103] epoch 1144, training loss: 6464.71, average training loss: 6808.57
[INFO 2017-06-15 15:57:01,987 main.py:103] epoch 1145, training loss: 6264.83, average training loss: 6807.08
[INFO 2017-06-15 15:57:03,534 main.py:103] epoch 1146, training loss: 6045.48, average training loss: 6804.62
[INFO 2017-06-15 15:57:05,056 main.py:103] epoch 1147, training loss: 6720.77, average training loss: 6803.95
[INFO 2017-06-15 15:57:06,584 main.py:103] epoch 1148, training loss: 6547.34, average training loss: 6802.84
[INFO 2017-06-15 15:57:08,118 main.py:103] epoch 1149, training loss: 7077.57, average training loss: 6803.13
[INFO 2017-06-15 15:57:09,619 main.py:103] epoch 1150, training loss: 6638.28, average training loss: 6802.08
[INFO 2017-06-15 15:57:11,116 main.py:103] epoch 1151, training loss: 6431.00, average training loss: 6801.69
[INFO 2017-06-15 15:57:12,616 main.py:103] epoch 1152, training loss: 6409.42, average training loss: 6800.84
[INFO 2017-06-15 15:57:14,114 main.py:103] epoch 1153, training loss: 6461.31, average training loss: 6799.51
[INFO 2017-06-15 15:57:15,629 main.py:103] epoch 1154, training loss: 6268.79, average training loss: 6797.80
[INFO 2017-06-15 15:57:17,138 main.py:103] epoch 1155, training loss: 6640.52, average training loss: 6796.50
[INFO 2017-06-15 15:57:18,638 main.py:103] epoch 1156, training loss: 7007.87, average training loss: 6796.65
[INFO 2017-06-15 15:57:20,169 main.py:103] epoch 1157, training loss: 6606.26, average training loss: 6796.04
[INFO 2017-06-15 15:57:21,668 main.py:103] epoch 1158, training loss: 6594.20, average training loss: 6795.66
[INFO 2017-06-15 15:57:23,169 main.py:103] epoch 1159, training loss: 6522.77, average training loss: 6795.14
[INFO 2017-06-15 15:57:24,675 main.py:103] epoch 1160, training loss: 7963.34, average training loss: 6795.73
[INFO 2017-06-15 15:57:26,174 main.py:103] epoch 1161, training loss: 7539.55, average training loss: 6796.13
[INFO 2017-06-15 15:57:27,673 main.py:103] epoch 1162, training loss: 6909.33, average training loss: 6795.53
[INFO 2017-06-15 15:57:29,173 main.py:103] epoch 1163, training loss: 7096.14, average training loss: 6795.73
[INFO 2017-06-15 15:57:30,671 main.py:103] epoch 1164, training loss: 6759.49, average training loss: 6795.11
[INFO 2017-06-15 15:57:32,186 main.py:103] epoch 1165, training loss: 6085.89, average training loss: 6794.02
[INFO 2017-06-15 15:57:33,685 main.py:103] epoch 1166, training loss: 7011.12, average training loss: 6793.79
[INFO 2017-06-15 15:57:35,189 main.py:103] epoch 1167, training loss: 5859.71, average training loss: 6792.45
[INFO 2017-06-15 15:57:36,697 main.py:103] epoch 1168, training loss: 6158.15, average training loss: 6791.42
[INFO 2017-06-15 15:57:38,199 main.py:103] epoch 1169, training loss: 5845.13, average training loss: 6790.10
[INFO 2017-06-15 15:57:39,698 main.py:103] epoch 1170, training loss: 7131.90, average training loss: 6789.33
[INFO 2017-06-15 15:57:41,225 main.py:103] epoch 1171, training loss: 5854.93, average training loss: 6787.56
[INFO 2017-06-15 15:57:42,723 main.py:103] epoch 1172, training loss: 6156.05, average training loss: 6786.20
[INFO 2017-06-15 15:57:44,223 main.py:103] epoch 1173, training loss: 6669.50, average training loss: 6785.96
[INFO 2017-06-15 15:57:45,747 main.py:103] epoch 1174, training loss: 6794.53, average training loss: 6786.04
[INFO 2017-06-15 15:57:47,248 main.py:103] epoch 1175, training loss: 6587.70, average training loss: 6785.47
[INFO 2017-06-15 15:57:48,747 main.py:103] epoch 1176, training loss: 6997.75, average training loss: 6784.76
[INFO 2017-06-15 15:57:50,270 main.py:103] epoch 1177, training loss: 6087.15, average training loss: 6783.78
[INFO 2017-06-15 15:57:51,772 main.py:103] epoch 1178, training loss: 6343.19, average training loss: 6782.67
[INFO 2017-06-15 15:57:53,273 main.py:103] epoch 1179, training loss: 5942.34, average training loss: 6781.47
[INFO 2017-06-15 15:57:54,797 main.py:103] epoch 1180, training loss: 6923.73, average training loss: 6781.10
[INFO 2017-06-15 15:57:56,297 main.py:103] epoch 1181, training loss: 6006.30, average training loss: 6779.57
[INFO 2017-06-15 15:57:57,808 main.py:103] epoch 1182, training loss: 6174.56, average training loss: 6778.40
[INFO 2017-06-15 15:57:59,308 main.py:103] epoch 1183, training loss: 7662.27, average training loss: 6778.87
[INFO 2017-06-15 15:58:00,807 main.py:103] epoch 1184, training loss: 6520.39, average training loss: 6778.38
[INFO 2017-06-15 15:58:02,306 main.py:103] epoch 1185, training loss: 6417.54, average training loss: 6776.98
[INFO 2017-06-15 15:58:03,824 main.py:103] epoch 1186, training loss: 6330.04, average training loss: 6775.70
[INFO 2017-06-15 15:58:05,326 main.py:103] epoch 1187, training loss: 6017.04, average training loss: 6774.71
[INFO 2017-06-15 15:58:06,825 main.py:103] epoch 1188, training loss: 7057.97, average training loss: 6774.65
[INFO 2017-06-15 15:58:08,325 main.py:103] epoch 1189, training loss: 6411.64, average training loss: 6774.21
[INFO 2017-06-15 15:58:09,823 main.py:103] epoch 1190, training loss: 6577.19, average training loss: 6773.46
[INFO 2017-06-15 15:58:11,322 main.py:103] epoch 1191, training loss: 6452.91, average training loss: 6772.74
[INFO 2017-06-15 15:58:12,822 main.py:103] epoch 1192, training loss: 7034.80, average training loss: 6773.00
[INFO 2017-06-15 15:58:14,323 main.py:103] epoch 1193, training loss: 6296.38, average training loss: 6771.90
[INFO 2017-06-15 15:58:15,823 main.py:103] epoch 1194, training loss: 7129.20, average training loss: 6772.11
[INFO 2017-06-15 15:58:17,322 main.py:103] epoch 1195, training loss: 7368.64, average training loss: 6771.87
[INFO 2017-06-15 15:58:18,821 main.py:103] epoch 1196, training loss: 6643.60, average training loss: 6771.00
[INFO 2017-06-15 15:58:20,320 main.py:103] epoch 1197, training loss: 6584.35, average training loss: 6770.97
[INFO 2017-06-15 15:58:21,817 main.py:103] epoch 1198, training loss: 6489.92, average training loss: 6769.89
[INFO 2017-06-15 15:58:23,317 main.py:103] epoch 1199, training loss: 6263.57, average training loss: 6769.28
[INFO 2017-06-15 15:58:23,317 main.py:105] epoch 1199, testing
[INFO 2017-06-15 15:59:39,081 main.py:54] average testing loss: 6552.64
[INFO 2017-06-15 15:59:39,083 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 15:59:39,092 main.py:25] current best accuracy: 6552.64
[INFO 2017-06-15 15:59:40,591 main.py:103] epoch 1200, training loss: 6615.31, average training loss: 6768.45
[INFO 2017-06-15 15:59:42,091 main.py:103] epoch 1201, training loss: 7106.51, average training loss: 6767.40
[INFO 2017-06-15 15:59:43,589 main.py:103] epoch 1202, training loss: 6076.87, average training loss: 6767.00
[INFO 2017-06-15 15:59:45,090 main.py:103] epoch 1203, training loss: 5868.77, average training loss: 6764.67
[INFO 2017-06-15 15:59:46,588 main.py:103] epoch 1204, training loss: 6638.71, average training loss: 6764.04
[INFO 2017-06-15 15:59:48,086 main.py:103] epoch 1205, training loss: 5859.45, average training loss: 6762.88
[INFO 2017-06-15 15:59:49,585 main.py:103] epoch 1206, training loss: 6050.06, average training loss: 6761.79
[INFO 2017-06-15 15:59:51,083 main.py:103] epoch 1207, training loss: 6510.03, average training loss: 6760.87
[INFO 2017-06-15 15:59:52,581 main.py:103] epoch 1208, training loss: 6681.29, average training loss: 6759.47
[INFO 2017-06-15 15:59:54,079 main.py:103] epoch 1209, training loss: 6687.19, average training loss: 6758.67
[INFO 2017-06-15 15:59:55,578 main.py:103] epoch 1210, training loss: 7193.96, average training loss: 6759.35
[INFO 2017-06-15 15:59:57,076 main.py:103] epoch 1211, training loss: 7209.44, average training loss: 6759.83
[INFO 2017-06-15 15:59:58,575 main.py:103] epoch 1212, training loss: 6880.54, average training loss: 6759.11
[INFO 2017-06-15 16:00:00,075 main.py:103] epoch 1213, training loss: 7196.77, average training loss: 6759.12
[INFO 2017-06-15 16:00:01,576 main.py:103] epoch 1214, training loss: 6348.27, average training loss: 6757.81
[INFO 2017-06-15 16:00:03,077 main.py:103] epoch 1215, training loss: 6414.11, average training loss: 6757.65
[INFO 2017-06-15 16:00:04,577 main.py:103] epoch 1216, training loss: 6897.19, average training loss: 6757.29
[INFO 2017-06-15 16:00:06,077 main.py:103] epoch 1217, training loss: 6746.33, average training loss: 6756.08
[INFO 2017-06-15 16:00:07,577 main.py:103] epoch 1218, training loss: 6131.15, average training loss: 6755.77
[INFO 2017-06-15 16:00:09,076 main.py:103] epoch 1219, training loss: 7499.66, average training loss: 6756.17
[INFO 2017-06-15 16:00:10,575 main.py:103] epoch 1220, training loss: 6545.62, average training loss: 6755.60
[INFO 2017-06-15 16:00:12,074 main.py:103] epoch 1221, training loss: 6795.09, average training loss: 6756.16
[INFO 2017-06-15 16:00:13,572 main.py:103] epoch 1222, training loss: 6838.14, average training loss: 6755.75
[INFO 2017-06-15 16:00:15,072 main.py:103] epoch 1223, training loss: 6426.01, average training loss: 6755.41
[INFO 2017-06-15 16:00:16,570 main.py:103] epoch 1224, training loss: 5882.97, average training loss: 6753.74
[INFO 2017-06-15 16:00:18,070 main.py:103] epoch 1225, training loss: 6433.14, average training loss: 6753.32
[INFO 2017-06-15 16:00:19,568 main.py:103] epoch 1226, training loss: 6607.61, average training loss: 6753.59
[INFO 2017-06-15 16:00:21,067 main.py:103] epoch 1227, training loss: 6952.69, average training loss: 6753.75
[INFO 2017-06-15 16:00:22,566 main.py:103] epoch 1228, training loss: 6769.69, average training loss: 6753.52
[INFO 2017-06-15 16:00:24,065 main.py:103] epoch 1229, training loss: 6777.55, average training loss: 6753.79
[INFO 2017-06-15 16:00:25,564 main.py:103] epoch 1230, training loss: 7488.52, average training loss: 6754.49
[INFO 2017-06-15 16:00:27,063 main.py:103] epoch 1231, training loss: 6493.37, average training loss: 6753.24
[INFO 2017-06-15 16:00:28,563 main.py:103] epoch 1232, training loss: 7208.75, average training loss: 6752.50
[INFO 2017-06-15 16:00:30,062 main.py:103] epoch 1233, training loss: 6551.37, average training loss: 6752.02
[INFO 2017-06-15 16:00:31,562 main.py:103] epoch 1234, training loss: 6755.53, average training loss: 6751.01
[INFO 2017-06-15 16:00:33,062 main.py:103] epoch 1235, training loss: 6229.65, average training loss: 6749.50
[INFO 2017-06-15 16:00:34,561 main.py:103] epoch 1236, training loss: 6245.83, average training loss: 6749.02
[INFO 2017-06-15 16:00:36,059 main.py:103] epoch 1237, training loss: 6431.68, average training loss: 6748.50
[INFO 2017-06-15 16:00:37,558 main.py:103] epoch 1238, training loss: 6826.55, average training loss: 6747.65
[INFO 2017-06-15 16:00:39,056 main.py:103] epoch 1239, training loss: 7506.48, average training loss: 6748.66
[INFO 2017-06-15 16:00:40,555 main.py:103] epoch 1240, training loss: 6855.61, average training loss: 6748.12
[INFO 2017-06-15 16:00:42,053 main.py:103] epoch 1241, training loss: 5980.88, average training loss: 6747.12
[INFO 2017-06-15 16:00:43,552 main.py:103] epoch 1242, training loss: 7053.42, average training loss: 6746.24
[INFO 2017-06-15 16:00:45,052 main.py:103] epoch 1243, training loss: 6677.39, average training loss: 6745.05
[INFO 2017-06-15 16:00:46,551 main.py:103] epoch 1244, training loss: 6553.03, average training loss: 6744.56
[INFO 2017-06-15 16:00:48,049 main.py:103] epoch 1245, training loss: 6369.27, average training loss: 6744.20
[INFO 2017-06-15 16:00:49,549 main.py:103] epoch 1246, training loss: 6529.17, average training loss: 6744.01
[INFO 2017-06-15 16:00:51,049 main.py:103] epoch 1247, training loss: 6492.12, average training loss: 6743.48
[INFO 2017-06-15 16:00:52,548 main.py:103] epoch 1248, training loss: 6315.29, average training loss: 6742.68
[INFO 2017-06-15 16:00:54,048 main.py:103] epoch 1249, training loss: 6665.43, average training loss: 6742.64
[INFO 2017-06-15 16:00:55,548 main.py:103] epoch 1250, training loss: 6327.57, average training loss: 6741.55
[INFO 2017-06-15 16:00:57,048 main.py:103] epoch 1251, training loss: 6465.28, average training loss: 6740.49
[INFO 2017-06-15 16:00:58,548 main.py:103] epoch 1252, training loss: 7080.36, average training loss: 6741.14
[INFO 2017-06-15 16:01:00,048 main.py:103] epoch 1253, training loss: 6185.24, average training loss: 6739.81
[INFO 2017-06-15 16:01:01,548 main.py:103] epoch 1254, training loss: 7152.01, average training loss: 6739.42
[INFO 2017-06-15 16:01:03,049 main.py:103] epoch 1255, training loss: 6841.87, average training loss: 6739.05
[INFO 2017-06-15 16:01:04,549 main.py:103] epoch 1256, training loss: 6450.96, average training loss: 6737.78
[INFO 2017-06-15 16:01:06,048 main.py:103] epoch 1257, training loss: 6435.87, average training loss: 6737.32
[INFO 2017-06-15 16:01:07,547 main.py:103] epoch 1258, training loss: 7035.81, average training loss: 6737.50
[INFO 2017-06-15 16:01:09,047 main.py:103] epoch 1259, training loss: 7261.41, average training loss: 6737.76
[INFO 2017-06-15 16:01:10,547 main.py:103] epoch 1260, training loss: 6429.49, average training loss: 6737.70
[INFO 2017-06-15 16:01:12,048 main.py:103] epoch 1261, training loss: 7178.04, average training loss: 6737.67
[INFO 2017-06-15 16:01:13,551 main.py:103] epoch 1262, training loss: 7210.91, average training loss: 6737.75
[INFO 2017-06-15 16:01:15,051 main.py:103] epoch 1263, training loss: 6920.79, average training loss: 6736.93
[INFO 2017-06-15 16:01:16,550 main.py:103] epoch 1264, training loss: 6325.72, average training loss: 6736.66
[INFO 2017-06-15 16:01:18,050 main.py:103] epoch 1265, training loss: 6697.94, average training loss: 6736.39
[INFO 2017-06-15 16:01:19,550 main.py:103] epoch 1266, training loss: 6787.74, average training loss: 6736.24
[INFO 2017-06-15 16:01:21,049 main.py:103] epoch 1267, training loss: 6793.71, average training loss: 6735.66
[INFO 2017-06-15 16:01:22,548 main.py:103] epoch 1268, training loss: 6105.27, average training loss: 6733.88
[INFO 2017-06-15 16:01:24,046 main.py:103] epoch 1269, training loss: 6549.25, average training loss: 6733.82
[INFO 2017-06-15 16:01:25,546 main.py:103] epoch 1270, training loss: 6523.48, average training loss: 6732.86
[INFO 2017-06-15 16:01:27,045 main.py:103] epoch 1271, training loss: 5612.60, average training loss: 6731.44
[INFO 2017-06-15 16:01:28,546 main.py:103] epoch 1272, training loss: 6987.66, average training loss: 6731.93
[INFO 2017-06-15 16:01:30,046 main.py:103] epoch 1273, training loss: 6142.71, average training loss: 6731.66
[INFO 2017-06-15 16:01:31,546 main.py:103] epoch 1274, training loss: 6329.52, average training loss: 6731.80
[INFO 2017-06-15 16:01:33,046 main.py:103] epoch 1275, training loss: 6692.08, average training loss: 6730.83
[INFO 2017-06-15 16:01:34,546 main.py:103] epoch 1276, training loss: 6300.60, average training loss: 6729.92
[INFO 2017-06-15 16:01:36,046 main.py:103] epoch 1277, training loss: 6972.66, average training loss: 6730.26
[INFO 2017-06-15 16:01:37,544 main.py:103] epoch 1278, training loss: 6133.44, average training loss: 6728.78
[INFO 2017-06-15 16:01:39,043 main.py:103] epoch 1279, training loss: 6421.80, average training loss: 6727.93
[INFO 2017-06-15 16:01:40,541 main.py:103] epoch 1280, training loss: 6281.29, average training loss: 6726.77
[INFO 2017-06-15 16:01:42,040 main.py:103] epoch 1281, training loss: 6466.79, average training loss: 6726.44
[INFO 2017-06-15 16:01:43,539 main.py:103] epoch 1282, training loss: 6341.93, average training loss: 6725.18
[INFO 2017-06-15 16:01:45,039 main.py:103] epoch 1283, training loss: 6660.81, average training loss: 6724.48
[INFO 2017-06-15 16:01:46,538 main.py:103] epoch 1284, training loss: 6933.17, average training loss: 6724.55
[INFO 2017-06-15 16:01:48,037 main.py:103] epoch 1285, training loss: 7794.87, average training loss: 6725.01
[INFO 2017-06-15 16:01:49,536 main.py:103] epoch 1286, training loss: 6760.32, average training loss: 6724.69
[INFO 2017-06-15 16:01:51,035 main.py:103] epoch 1287, training loss: 6104.20, average training loss: 6723.52
[INFO 2017-06-15 16:01:52,532 main.py:103] epoch 1288, training loss: 5925.06, average training loss: 6722.05
[INFO 2017-06-15 16:01:54,031 main.py:103] epoch 1289, training loss: 6314.81, average training loss: 6721.85
[INFO 2017-06-15 16:01:55,530 main.py:103] epoch 1290, training loss: 6221.81, average training loss: 6721.63
[INFO 2017-06-15 16:01:57,030 main.py:103] epoch 1291, training loss: 6328.86, average training loss: 6720.86
[INFO 2017-06-15 16:01:58,528 main.py:103] epoch 1292, training loss: 5962.34, average training loss: 6719.08
[INFO 2017-06-15 16:02:00,026 main.py:103] epoch 1293, training loss: 6571.21, average training loss: 6719.31
[INFO 2017-06-15 16:02:01,526 main.py:103] epoch 1294, training loss: 6445.88, average training loss: 6718.55
[INFO 2017-06-15 16:02:03,026 main.py:103] epoch 1295, training loss: 6382.52, average training loss: 6717.72
[INFO 2017-06-15 16:02:04,525 main.py:103] epoch 1296, training loss: 6466.42, average training loss: 6716.58
[INFO 2017-06-15 16:02:06,024 main.py:103] epoch 1297, training loss: 6912.46, average training loss: 6716.74
[INFO 2017-06-15 16:02:07,523 main.py:103] epoch 1298, training loss: 6364.71, average training loss: 6716.00
[INFO 2017-06-15 16:02:09,022 main.py:103] epoch 1299, training loss: 7036.52, average training loss: 6716.19
[INFO 2017-06-15 16:02:09,023 main.py:105] epoch 1299, testing
[INFO 2017-06-15 16:03:24,577 main.py:54] average testing loss: 6604.50
[INFO 2017-06-15 16:03:24,580 main.py:25] current best accuracy: 6552.64
[INFO 2017-06-15 16:03:26,076 main.py:103] epoch 1300, training loss: 7090.00, average training loss: 6716.16
[INFO 2017-06-15 16:03:27,574 main.py:103] epoch 1301, training loss: 6149.57, average training loss: 6714.88
[INFO 2017-06-15 16:03:29,073 main.py:103] epoch 1302, training loss: 6636.65, average training loss: 6715.06
[INFO 2017-06-15 16:03:30,572 main.py:103] epoch 1303, training loss: 6391.58, average training loss: 6713.92
[INFO 2017-06-15 16:03:32,070 main.py:103] epoch 1304, training loss: 6603.47, average training loss: 6713.28
[INFO 2017-06-15 16:03:33,569 main.py:103] epoch 1305, training loss: 7089.62, average training loss: 6713.38
[INFO 2017-06-15 16:03:35,067 main.py:103] epoch 1306, training loss: 6790.30, average training loss: 6712.91
[INFO 2017-06-15 16:03:36,565 main.py:103] epoch 1307, training loss: 6116.00, average training loss: 6712.75
[INFO 2017-06-15 16:03:38,064 main.py:103] epoch 1308, training loss: 5617.85, average training loss: 6711.36
[INFO 2017-06-15 16:03:39,563 main.py:103] epoch 1309, training loss: 6007.31, average training loss: 6710.65
[INFO 2017-06-15 16:03:41,062 main.py:103] epoch 1310, training loss: 7022.25, average training loss: 6710.09
[INFO 2017-06-15 16:03:42,560 main.py:103] epoch 1311, training loss: 6711.76, average training loss: 6709.78
[INFO 2017-06-15 16:03:44,059 main.py:103] epoch 1312, training loss: 6268.41, average training loss: 6709.80
[INFO 2017-06-15 16:03:45,558 main.py:103] epoch 1313, training loss: 7242.81, average training loss: 6710.31
[INFO 2017-06-15 16:03:47,058 main.py:103] epoch 1314, training loss: 6337.61, average training loss: 6709.14
[INFO 2017-06-15 16:03:48,557 main.py:103] epoch 1315, training loss: 6184.57, average training loss: 6708.29
[INFO 2017-06-15 16:03:50,058 main.py:103] epoch 1316, training loss: 5984.26, average training loss: 6707.67
[INFO 2017-06-15 16:03:51,557 main.py:103] epoch 1317, training loss: 6462.33, average training loss: 6707.28
[INFO 2017-06-15 16:03:53,058 main.py:103] epoch 1318, training loss: 6511.76, average training loss: 6706.79
[INFO 2017-06-15 16:03:54,559 main.py:103] epoch 1319, training loss: 6326.34, average training loss: 6706.35
[INFO 2017-06-15 16:03:56,056 main.py:103] epoch 1320, training loss: 6539.65, average training loss: 6706.14
[INFO 2017-06-15 16:03:57,554 main.py:103] epoch 1321, training loss: 7569.41, average training loss: 6706.07
[INFO 2017-06-15 16:03:59,052 main.py:103] epoch 1322, training loss: 5779.67, average training loss: 6704.16
[INFO 2017-06-15 16:04:00,550 main.py:103] epoch 1323, training loss: 6689.28, average training loss: 6704.25
[INFO 2017-06-15 16:04:02,049 main.py:103] epoch 1324, training loss: 6700.76, average training loss: 6704.23
[INFO 2017-06-15 16:04:03,548 main.py:103] epoch 1325, training loss: 6611.29, average training loss: 6704.24
[INFO 2017-06-15 16:04:05,046 main.py:103] epoch 1326, training loss: 7193.16, average training loss: 6704.33
[INFO 2017-06-15 16:04:06,542 main.py:103] epoch 1327, training loss: 6524.97, average training loss: 6704.69
[INFO 2017-06-15 16:04:08,041 main.py:103] epoch 1328, training loss: 6542.35, average training loss: 6703.83
[INFO 2017-06-15 16:04:09,539 main.py:103] epoch 1329, training loss: 5901.65, average training loss: 6702.33
[INFO 2017-06-15 16:04:11,037 main.py:103] epoch 1330, training loss: 6218.69, average training loss: 6701.31
[INFO 2017-06-15 16:04:12,535 main.py:103] epoch 1331, training loss: 6496.17, average training loss: 6701.79
[INFO 2017-06-15 16:04:14,034 main.py:103] epoch 1332, training loss: 6426.28, average training loss: 6700.91
[INFO 2017-06-15 16:04:15,532 main.py:103] epoch 1333, training loss: 6543.08, average training loss: 6700.69
[INFO 2017-06-15 16:04:17,030 main.py:103] epoch 1334, training loss: 6157.75, average training loss: 6700.21
[INFO 2017-06-15 16:04:18,527 main.py:103] epoch 1335, training loss: 6351.44, average training loss: 6699.25
[INFO 2017-06-15 16:04:20,027 main.py:103] epoch 1336, training loss: 6438.37, average training loss: 6699.07
[INFO 2017-06-15 16:04:21,526 main.py:103] epoch 1337, training loss: 6262.34, average training loss: 6698.33
[INFO 2017-06-15 16:04:23,025 main.py:103] epoch 1338, training loss: 5835.19, average training loss: 6697.02
[INFO 2017-06-15 16:04:24,524 main.py:103] epoch 1339, training loss: 6426.00, average training loss: 6695.72
[INFO 2017-06-15 16:04:26,022 main.py:103] epoch 1340, training loss: 6008.07, average training loss: 6695.14
[INFO 2017-06-15 16:04:27,522 main.py:103] epoch 1341, training loss: 6770.83, average training loss: 6695.15
[INFO 2017-06-15 16:04:29,021 main.py:103] epoch 1342, training loss: 6706.07, average training loss: 6694.96
[INFO 2017-06-15 16:04:30,518 main.py:103] epoch 1343, training loss: 6497.90, average training loss: 6694.72
[INFO 2017-06-15 16:04:32,019 main.py:103] epoch 1344, training loss: 7095.60, average training loss: 6695.22
[INFO 2017-06-15 16:04:33,518 main.py:103] epoch 1345, training loss: 7123.74, average training loss: 6694.20
[INFO 2017-06-15 16:04:35,017 main.py:103] epoch 1346, training loss: 6160.82, average training loss: 6693.49
[INFO 2017-06-15 16:04:36,517 main.py:103] epoch 1347, training loss: 6400.76, average training loss: 6692.27
[INFO 2017-06-15 16:04:38,015 main.py:103] epoch 1348, training loss: 6602.90, average training loss: 6691.37
[INFO 2017-06-15 16:04:39,513 main.py:103] epoch 1349, training loss: 6413.87, average training loss: 6691.23
[INFO 2017-06-15 16:04:41,011 main.py:103] epoch 1350, training loss: 6270.61, average training loss: 6691.36
[INFO 2017-06-15 16:04:42,509 main.py:103] epoch 1351, training loss: 6062.79, average training loss: 6690.16
[INFO 2017-06-15 16:04:44,009 main.py:103] epoch 1352, training loss: 6351.29, average training loss: 6690.51
[INFO 2017-06-15 16:04:45,507 main.py:103] epoch 1353, training loss: 5835.17, average training loss: 6689.23
[INFO 2017-06-15 16:04:47,006 main.py:103] epoch 1354, training loss: 6038.44, average training loss: 6687.99
[INFO 2017-06-15 16:04:48,507 main.py:103] epoch 1355, training loss: 6194.26, average training loss: 6687.38
[INFO 2017-06-15 16:04:50,008 main.py:103] epoch 1356, training loss: 6820.65, average training loss: 6687.32
[INFO 2017-06-15 16:04:51,507 main.py:103] epoch 1357, training loss: 7110.55, average training loss: 6687.51
[INFO 2017-06-15 16:04:53,006 main.py:103] epoch 1358, training loss: 7499.71, average training loss: 6688.69
[INFO 2017-06-15 16:04:54,505 main.py:103] epoch 1359, training loss: 6902.57, average training loss: 6687.86
[INFO 2017-06-15 16:04:56,004 main.py:103] epoch 1360, training loss: 6930.07, average training loss: 6687.91
[INFO 2017-06-15 16:04:57,504 main.py:103] epoch 1361, training loss: 6504.24, average training loss: 6686.73
[INFO 2017-06-15 16:04:59,003 main.py:103] epoch 1362, training loss: 7086.42, average training loss: 6686.29
[INFO 2017-06-15 16:05:00,501 main.py:103] epoch 1363, training loss: 6297.51, average training loss: 6685.52
[INFO 2017-06-15 16:05:01,999 main.py:103] epoch 1364, training loss: 6537.63, average training loss: 6685.30
[INFO 2017-06-15 16:05:03,496 main.py:103] epoch 1365, training loss: 6807.22, average training loss: 6685.44
[INFO 2017-06-15 16:05:04,995 main.py:103] epoch 1366, training loss: 6791.12, average training loss: 6685.41
[INFO 2017-06-15 16:05:06,495 main.py:103] epoch 1367, training loss: 6769.42, average training loss: 6685.32
[INFO 2017-06-15 16:05:07,994 main.py:103] epoch 1368, training loss: 6979.61, average training loss: 6685.38
[INFO 2017-06-15 16:05:09,493 main.py:103] epoch 1369, training loss: 6984.24, average training loss: 6685.20
[INFO 2017-06-15 16:05:10,993 main.py:103] epoch 1370, training loss: 6625.39, average training loss: 6684.36
[INFO 2017-06-15 16:05:12,492 main.py:103] epoch 1371, training loss: 6116.59, average training loss: 6683.90
[INFO 2017-06-15 16:05:13,991 main.py:103] epoch 1372, training loss: 6952.43, average training loss: 6684.18
[INFO 2017-06-15 16:05:15,491 main.py:103] epoch 1373, training loss: 6293.26, average training loss: 6684.23
[INFO 2017-06-15 16:05:16,990 main.py:103] epoch 1374, training loss: 6823.23, average training loss: 6684.56
[INFO 2017-06-15 16:05:18,488 main.py:103] epoch 1375, training loss: 6568.03, average training loss: 6683.90
[INFO 2017-06-15 16:05:19,987 main.py:103] epoch 1376, training loss: 6401.62, average training loss: 6683.48
[INFO 2017-06-15 16:05:21,518 main.py:103] epoch 1377, training loss: 7052.65, average training loss: 6683.74
[INFO 2017-06-15 16:05:23,017 main.py:103] epoch 1378, training loss: 7112.86, average training loss: 6683.88
[INFO 2017-06-15 16:05:24,517 main.py:103] epoch 1379, training loss: 6863.80, average training loss: 6684.22
[INFO 2017-06-15 16:05:26,030 main.py:103] epoch 1380, training loss: 6382.73, average training loss: 6683.68
[INFO 2017-06-15 16:05:27,529 main.py:103] epoch 1381, training loss: 5998.00, average training loss: 6682.62
[INFO 2017-06-15 16:05:29,028 main.py:103] epoch 1382, training loss: 6678.33, average training loss: 6683.07
[INFO 2017-06-15 16:05:30,526 main.py:103] epoch 1383, training loss: 6580.73, average training loss: 6682.88
[INFO 2017-06-15 16:05:32,026 main.py:103] epoch 1384, training loss: 6724.67, average training loss: 6682.59
[INFO 2017-06-15 16:05:33,525 main.py:103] epoch 1385, training loss: 6763.16, average training loss: 6682.31
[INFO 2017-06-15 16:05:35,024 main.py:103] epoch 1386, training loss: 6217.23, average training loss: 6681.74
[INFO 2017-06-15 16:05:36,523 main.py:103] epoch 1387, training loss: 6740.85, average training loss: 6682.41
[INFO 2017-06-15 16:05:38,021 main.py:103] epoch 1388, training loss: 6475.57, average training loss: 6680.99
[INFO 2017-06-15 16:05:39,519 main.py:103] epoch 1389, training loss: 6239.66, average training loss: 6680.49
[INFO 2017-06-15 16:05:41,018 main.py:103] epoch 1390, training loss: 6560.67, average training loss: 6679.90
[INFO 2017-06-15 16:05:42,518 main.py:103] epoch 1391, training loss: 5968.30, average training loss: 6678.52
[INFO 2017-06-15 16:05:44,017 main.py:103] epoch 1392, training loss: 5734.88, average training loss: 6677.79
[INFO 2017-06-15 16:05:45,516 main.py:103] epoch 1393, training loss: 6585.18, average training loss: 6677.50
[INFO 2017-06-15 16:05:47,015 main.py:103] epoch 1394, training loss: 6388.44, average training loss: 6676.94
[INFO 2017-06-15 16:05:48,515 main.py:103] epoch 1395, training loss: 6928.73, average training loss: 6677.47
[INFO 2017-06-15 16:05:50,014 main.py:103] epoch 1396, training loss: 6421.93, average training loss: 6677.04
[INFO 2017-06-15 16:05:51,513 main.py:103] epoch 1397, training loss: 6215.82, average training loss: 6676.79
[INFO 2017-06-15 16:05:53,013 main.py:103] epoch 1398, training loss: 6034.55, average training loss: 6676.14
[INFO 2017-06-15 16:05:54,511 main.py:103] epoch 1399, training loss: 6643.81, average training loss: 6676.23
[INFO 2017-06-15 16:05:54,511 main.py:105] epoch 1399, testing
[INFO 2017-06-15 16:07:10,299 main.py:54] average testing loss: 6468.31
[INFO 2017-06-15 16:07:10,302 main.py:21] model save to ./model/final.pth
[INFO 2017-06-15 16:07:10,311 main.py:25] current best accuracy: 6468.31
[INFO 2017-06-15 16:07:11,810 main.py:103] epoch 1400, training loss: 6923.40, average training loss: 6676.33
[INFO 2017-06-15 16:07:13,335 main.py:103] epoch 1401, training loss: 7021.61, average training loss: 6677.22
[INFO 2017-06-15 16:07:14,832 main.py:103] epoch 1402, training loss: 6490.26, average training loss: 6675.95
[INFO 2017-06-15 16:07:16,333 main.py:103] epoch 1403, training loss: 5821.74, average training loss: 6673.87
[INFO 2017-06-15 16:07:17,855 main.py:103] epoch 1404, training loss: 6808.32, average training loss: 6674.24
[INFO 2017-06-15 16:07:19,354 main.py:103] epoch 1405, training loss: 6293.35, average training loss: 6674.00
[INFO 2017-06-15 16:07:20,854 main.py:103] epoch 1406, training loss: 6089.38, average training loss: 6672.45
[INFO 2017-06-15 16:07:22,352 main.py:103] epoch 1407, training loss: 6466.75, average training loss: 6671.96
[INFO 2017-06-15 16:07:23,854 main.py:103] epoch 1408, training loss: 6528.74, average training loss: 6670.86
[INFO 2017-06-15 16:07:25,365 main.py:103] epoch 1409, training loss: 6513.55, average training loss: 6670.36
[INFO 2017-06-15 16:07:26,866 main.py:103] epoch 1410, training loss: 6922.41, average training loss: 6670.11
[INFO 2017-06-15 16:07:28,363 main.py:103] epoch 1411, training loss: 6145.70, average training loss: 6669.90
[INFO 2017-06-15 16:07:29,861 main.py:103] epoch 1412, training loss: 6624.52, average training loss: 6669.71
[INFO 2017-06-15 16:07:31,360 main.py:103] epoch 1413, training loss: 6321.15, average training loss: 6669.06
[INFO 2017-06-15 16:07:32,858 main.py:103] epoch 1414, training loss: 5922.66, average training loss: 6669.01
[INFO 2017-06-15 16:07:34,356 main.py:103] epoch 1415, training loss: 6696.15, average training loss: 6668.48
[INFO 2017-06-15 16:07:35,855 main.py:103] epoch 1416, training loss: 6369.90, average training loss: 6667.64
[INFO 2017-06-15 16:07:37,352 main.py:103] epoch 1417, training loss: 5776.40, average training loss: 6666.36
[INFO 2017-06-15 16:07:38,850 main.py:103] epoch 1418, training loss: 6921.97, average training loss: 6666.58
[INFO 2017-06-15 16:07:40,348 main.py:103] epoch 1419, training loss: 6741.54, average training loss: 6666.64
[INFO 2017-06-15 16:07:41,846 main.py:103] epoch 1420, training loss: 6435.58, average training loss: 6665.96
[INFO 2017-06-15 16:07:43,346 main.py:103] epoch 1421, training loss: 6454.43, average training loss: 6665.22
[INFO 2017-06-15 16:07:44,845 main.py:103] epoch 1422, training loss: 5958.35, average training loss: 6663.95
[INFO 2017-06-15 16:07:46,347 main.py:103] epoch 1423, training loss: 6483.70, average training loss: 6664.19
[INFO 2017-06-15 16:07:47,846 main.py:103] epoch 1424, training loss: 6789.07, average training loss: 6664.36
[INFO 2017-06-15 16:07:49,344 main.py:103] epoch 1425, training loss: 6236.64, average training loss: 6663.48
[INFO 2017-06-15 16:07:50,848 main.py:103] epoch 1426, training loss: 6269.54, average training loss: 6662.60
[INFO 2017-06-15 16:07:52,347 main.py:103] epoch 1427, training loss: 6499.95, average training loss: 6662.35
[INFO 2017-06-15 16:07:53,845 main.py:103] epoch 1428, training loss: 6434.67, average training loss: 6661.78
[INFO 2017-06-15 16:07:55,347 main.py:103] epoch 1429, training loss: 6794.54, average training loss: 6661.86
[INFO 2017-06-15 16:07:56,856 main.py:103] epoch 1430, training loss: 6432.14, average training loss: 6661.28
[INFO 2017-06-15 16:07:58,360 main.py:103] epoch 1431, training loss: 5659.13, average training loss: 6660.70
[INFO 2017-06-15 16:07:59,860 main.py:103] epoch 1432, training loss: 5898.62, average training loss: 6659.95
[INFO 2017-06-15 16:08:01,361 main.py:103] epoch 1433, training loss: 6427.07, average training loss: 6659.70
[INFO 2017-06-15 16:08:02,861 main.py:103] epoch 1434, training loss: 6537.82, average training loss: 6659.67
[INFO 2017-06-15 16:08:04,359 main.py:103] epoch 1435, training loss: 6449.83, average training loss: 6659.66
[INFO 2017-06-15 16:08:05,858 main.py:103] epoch 1436, training loss: 5950.80, average training loss: 6658.91
[INFO 2017-06-15 16:08:07,357 main.py:103] epoch 1437, training loss: 5906.54, average training loss: 6658.16
[INFO 2017-06-15 16:08:08,858 main.py:103] epoch 1438, training loss: 6338.10, average training loss: 6657.78
[INFO 2017-06-15 16:08:10,357 main.py:103] epoch 1439, training loss: 6327.39, average training loss: 6657.37
[INFO 2017-06-15 16:08:11,857 main.py:103] epoch 1440, training loss: 5938.69, average training loss: 6657.71
[INFO 2017-06-15 16:08:13,357 main.py:103] epoch 1441, training loss: 6466.55, average training loss: 6657.47
[INFO 2017-06-15 16:08:14,857 main.py:103] epoch 1442, training loss: 5678.91, average training loss: 6656.47
[INFO 2017-06-15 16:08:16,360 main.py:103] epoch 1443, training loss: 6237.02, average training loss: 6655.76
[INFO 2017-06-15 16:08:17,859 main.py:103] epoch 1444, training loss: 6552.79, average training loss: 6655.22
[INFO 2017-06-15 16:08:19,360 main.py:103] epoch 1445, training loss: 6450.34, average training loss: 6654.80
[INFO 2017-06-15 16:08:20,858 main.py:103] epoch 1446, training loss: 6874.48, average training loss: 6654.60
[INFO 2017-06-15 16:08:22,358 main.py:103] epoch 1447, training loss: 6115.34, average training loss: 6653.62
[INFO 2017-06-15 16:08:23,856 main.py:103] epoch 1448, training loss: 7166.69, average training loss: 6653.43
[INFO 2017-06-15 16:08:25,355 main.py:103] epoch 1449, training loss: 6082.88, average training loss: 6651.93
[INFO 2017-06-15 16:08:26,856 main.py:103] epoch 1450, training loss: 7405.09, average training loss: 6652.80
[INFO 2017-06-15 16:08:28,354 main.py:103] epoch 1451, training loss: 6409.56, average training loss: 6652.05
[INFO 2017-06-15 16:08:29,852 main.py:103] epoch 1452, training loss: 6654.21, average training loss: 6651.51
[INFO 2017-06-15 16:08:31,362 main.py:103] epoch 1453, training loss: 6365.58, average training loss: 6651.54
[INFO 2017-06-15 16:08:32,860 main.py:103] epoch 1454, training loss: 6640.13, average training loss: 6651.74
[INFO 2017-06-15 16:08:34,358 main.py:103] epoch 1455, training loss: 6134.28, average training loss: 6650.95
[INFO 2017-06-15 16:08:35,856 main.py:103] epoch 1456, training loss: 6466.55, average training loss: 6650.26
[INFO 2017-06-15 16:08:37,355 main.py:103] epoch 1457, training loss: 5971.57, average training loss: 6648.44
[INFO 2017-06-15 16:08:38,852 main.py:103] epoch 1458, training loss: 7096.52, average training loss: 6648.44
[INFO 2017-06-15 16:08:40,350 main.py:103] epoch 1459, training loss: 6527.81, average training loss: 6648.34
[INFO 2017-06-15 16:08:41,849 main.py:103] epoch 1460, training loss: 6077.65, average training loss: 6646.51
[INFO 2017-06-15 16:08:43,346 main.py:103] epoch 1461, training loss: 6655.44, average training loss: 6646.30
[INFO 2017-06-15 16:08:44,847 main.py:103] epoch 1462, training loss: 7034.96, average training loss: 6646.71
[INFO 2017-06-15 16:08:46,348 main.py:103] epoch 1463, training loss: 7271.37, average training loss: 6646.91
[INFO 2017-06-15 16:08:47,852 main.py:103] epoch 1464, training loss: 6854.21, average training loss: 6646.49
[INFO 2017-06-15 16:08:49,353 main.py:103] epoch 1465, training loss: 6161.88, average training loss: 6646.01
[INFO 2017-06-15 16:08:50,852 main.py:103] epoch 1466, training loss: 6937.88, average training loss: 6645.68
[INFO 2017-06-15 16:08:52,349 main.py:103] epoch 1467, training loss: 6662.43, average training loss: 6645.97
[INFO 2017-06-15 16:08:53,854 main.py:103] epoch 1468, training loss: 6234.14, average training loss: 6645.65
[INFO 2017-06-15 16:08:55,354 main.py:103] epoch 1469, training loss: 7028.55, average training loss: 6644.64
[INFO 2017-06-15 16:08:56,854 main.py:103] epoch 1470, training loss: 6223.76, average training loss: 6644.29
[INFO 2017-06-15 16:08:58,351 main.py:103] epoch 1471, training loss: 6265.90, average training loss: 6643.38
[INFO 2017-06-15 16:08:59,848 main.py:103] epoch 1472, training loss: 6404.68, average training loss: 6643.06
[INFO 2017-06-15 16:09:01,353 main.py:103] epoch 1473, training loss: 6583.12, average training loss: 6642.59
[INFO 2017-06-15 16:09:02,872 main.py:103] epoch 1474, training loss: 7325.74, average training loss: 6642.02
[INFO 2017-06-15 16:09:04,370 main.py:103] epoch 1475, training loss: 6751.94, average training loss: 6641.75
[INFO 2017-06-15 16:09:05,867 main.py:103] epoch 1476, training loss: 6579.66, average training loss: 6641.20
[INFO 2017-06-15 16:09:07,363 main.py:103] epoch 1477, training loss: 6403.75, average training loss: 6640.53
[INFO 2017-06-15 16:09:08,859 main.py:103] epoch 1478, training loss: 6403.54, average training loss: 6639.23
[INFO 2017-06-15 16:09:10,360 main.py:103] epoch 1479, training loss: 7000.70, average training loss: 6639.32
[INFO 2017-06-15 16:09:11,857 main.py:103] epoch 1480, training loss: 6364.61, average training loss: 6638.90
[INFO 2017-06-15 16:09:13,355 main.py:103] epoch 1481, training loss: 6260.06, average training loss: 6637.82
[INFO 2017-06-15 16:09:14,852 main.py:103] epoch 1482, training loss: 6884.05, average training loss: 6637.61
[INFO 2017-06-15 16:09:16,351 main.py:103] epoch 1483, training loss: 6370.68, average training loss: 6637.23
[INFO 2017-06-15 16:09:17,850 main.py:103] epoch 1484, training loss: 7685.01, average training loss: 6638.35
[INFO 2017-06-15 16:09:19,347 main.py:103] epoch 1485, training loss: 6625.08, average training loss: 6638.65
[INFO 2017-06-15 16:09:20,845 main.py:103] epoch 1486, training loss: 6457.32, average training loss: 6638.53
[INFO 2017-06-15 16:09:22,340 main.py:103] epoch 1487, training loss: 6974.50, average training loss: 6639.04
[INFO 2017-06-15 16:09:23,837 main.py:103] epoch 1488, training loss: 7198.15, average training loss: 6639.46
[INFO 2017-06-15 16:09:25,334 main.py:103] epoch 1489, training loss: 6330.42, average training loss: 6638.79
[INFO 2017-06-15 16:09:26,831 main.py:103] epoch 1490, training loss: 6105.32, average training loss: 6637.74
[INFO 2017-06-15 16:09:28,326 main.py:103] epoch 1491, training loss: 6634.58, average training loss: 6637.85
[INFO 2017-06-15 16:09:29,823 main.py:103] epoch 1492, training loss: 5656.68, average training loss: 6637.08
[INFO 2017-06-15 16:09:31,319 main.py:103] epoch 1493, training loss: 6764.53, average training loss: 6636.54
[INFO 2017-06-15 16:09:32,816 main.py:103] epoch 1494, training loss: 5904.80, average training loss: 6635.28
[INFO 2017-06-15 16:09:34,313 main.py:103] epoch 1495, training loss: 7710.14, average training loss: 6636.63
[INFO 2017-06-15 16:09:35,810 main.py:103] epoch 1496, training loss: 7013.57, average training loss: 6635.76
[INFO 2017-06-15 16:09:37,306 main.py:103] epoch 1497, training loss: 6558.36, average training loss: 6635.19
[INFO 2017-06-15 16:09:38,802 main.py:103] epoch 1498, training loss: 6712.87, average training loss: 6635.02
[INFO 2017-06-15 16:09:40,299 main.py:103] epoch 1499, training loss: 6841.48, average training loss: 6635.00
[INFO 2017-06-15 16:09:40,299 main.py:105] epoch 1499, testing
[INFO 2017-06-15 16:10:56,580 main.py:54] average testing loss: 6532.96
[INFO 2017-06-15 16:10:56,583 main.py:25] current best accuracy: 6468.31
[INFO 2017-06-15 16:10:58,080 main.py:103] epoch 1500, training loss: 6263.57, average training loss: 6634.02
