[INFO 2017-06-26 18:32:44,055 main.py:123] Namespace(batch_size=32, display=False, image_size=64, init_model_path='', learning_rate=0.001, method='unsupervised', motion_range=2, num_channel=1, num_inputs=3, save_dir='./model', test=False, test_dir='/home/yi/Downloads/robot-64', test_epoch=10, test_interval=100, train=True, train_dir='/home/yi/Downloads/robot-64', train_epoch=10000)
[INFO 2017-06-26 18:32:49,185 main.py:47] epoch 0, training loss: 35643.29, average training loss: 35643.29, base loss: 2819.26
[INFO 2017-06-26 18:32:49,441 main.py:47] epoch 1, training loss: 29064.65, average training loss: 32353.97, base loss: 2715.09
[INFO 2017-06-26 18:32:49,687 main.py:47] epoch 2, training loss: 24407.34, average training loss: 29705.09, base loss: 2809.36
[INFO 2017-06-26 18:32:49,938 main.py:47] epoch 3, training loss: 20556.34, average training loss: 27417.90, base loss: 2679.54
[INFO 2017-06-26 18:32:50,187 main.py:47] epoch 4, training loss: 18469.84, average training loss: 25628.29, base loss: 2714.48
[INFO 2017-06-26 18:32:50,442 main.py:47] epoch 5, training loss: 15463.31, average training loss: 23934.13, base loss: 2683.57
[INFO 2017-06-26 18:32:50,691 main.py:47] epoch 6, training loss: 13926.73, average training loss: 22504.50, base loss: 2712.35
[INFO 2017-06-26 18:32:50,944 main.py:47] epoch 7, training loss: 11739.28, average training loss: 21158.85, base loss: 2713.15
[INFO 2017-06-26 18:32:51,193 main.py:47] epoch 8, training loss: 10712.62, average training loss: 19998.15, base loss: 2697.61
[INFO 2017-06-26 18:32:51,446 main.py:47] epoch 9, training loss: 8986.43, average training loss: 18896.98, base loss: 2683.46
[INFO 2017-06-26 18:32:51,697 main.py:47] epoch 10, training loss: 7899.90, average training loss: 17897.25, base loss: 2667.83
[INFO 2017-06-26 18:32:51,949 main.py:47] epoch 11, training loss: 6804.57, average training loss: 16972.86, base loss: 2645.88
[INFO 2017-06-26 18:32:52,198 main.py:47] epoch 12, training loss: 6315.72, average training loss: 16153.08, base loss: 2662.75
[INFO 2017-06-26 18:32:52,450 main.py:47] epoch 13, training loss: 5571.42, average training loss: 15397.25, base loss: 2682.88
[INFO 2017-06-26 18:32:52,699 main.py:47] epoch 14, training loss: 4838.69, average training loss: 14693.34, base loss: 2675.79
[INFO 2017-06-26 18:32:52,950 main.py:47] epoch 15, training loss: 4619.33, average training loss: 14063.72, base loss: 2689.41
[INFO 2017-06-26 18:32:53,201 main.py:47] epoch 16, training loss: 4219.75, average training loss: 13484.66, base loss: 2690.58
[INFO 2017-06-26 18:32:53,454 main.py:47] epoch 17, training loss: 3953.26, average training loss: 12955.14, base loss: 2695.10
[INFO 2017-06-26 18:32:53,700 main.py:47] epoch 18, training loss: 3309.02, average training loss: 12447.45, base loss: 2675.25
[INFO 2017-06-26 18:32:53,953 main.py:47] epoch 19, training loss: 3373.34, average training loss: 11993.74, base loss: 2667.93
[INFO 2017-06-26 18:32:54,204 main.py:47] epoch 20, training loss: 3409.18, average training loss: 11584.95, base loss: 2675.15
[INFO 2017-06-26 18:32:54,458 main.py:47] epoch 21, training loss: 2960.96, average training loss: 11192.95, base loss: 2667.96
[INFO 2017-06-26 18:32:54,709 main.py:47] epoch 22, training loss: 2832.45, average training loss: 10829.45, base loss: 2657.61
[INFO 2017-06-26 18:32:54,963 main.py:47] epoch 23, training loss: 2386.31, average training loss: 10477.65, base loss: 2632.01
[INFO 2017-06-26 18:32:55,213 main.py:47] epoch 24, training loss: 2438.88, average training loss: 10156.10, base loss: 2613.99
[INFO 2017-06-26 18:32:55,466 main.py:47] epoch 25, training loss: 3071.51, average training loss: 9883.62, base loss: 2625.79
[INFO 2017-06-26 18:32:55,714 main.py:47] epoch 26, training loss: 2812.99, average training loss: 9621.74, base loss: 2626.20
[INFO 2017-06-26 18:32:55,958 main.py:47] epoch 27, training loss: 2806.90, average training loss: 9378.36, base loss: 2628.45
[INFO 2017-06-26 18:32:56,205 main.py:47] epoch 28, training loss: 2663.51, average training loss: 9146.81, base loss: 2625.73
[INFO 2017-06-26 18:32:56,457 main.py:47] epoch 29, training loss: 3005.79, average training loss: 8942.11, base loss: 2635.22
[INFO 2017-06-26 18:32:56,703 main.py:47] epoch 30, training loss: 2487.05, average training loss: 8733.88, base loss: 2628.56
[INFO 2017-06-26 18:32:56,958 main.py:47] epoch 31, training loss: 2759.98, average training loss: 8547.20, base loss: 2631.28
[INFO 2017-06-26 18:32:57,204 main.py:47] epoch 32, training loss: 2584.65, average training loss: 8366.51, base loss: 2628.36
[INFO 2017-06-26 18:32:57,460 main.py:47] epoch 33, training loss: 2482.72, average training loss: 8193.46, base loss: 2622.38
[INFO 2017-06-26 18:32:57,707 main.py:47] epoch 34, training loss: 2890.67, average training loss: 8041.95, base loss: 2629.93
[INFO 2017-06-26 18:32:57,963 main.py:47] epoch 35, training loss: 2974.06, average training loss: 7901.18, base loss: 2638.91
[INFO 2017-06-26 18:32:58,213 main.py:47] epoch 36, training loss: 2393.32, average training loss: 7752.32, base loss: 2631.65
[INFO 2017-06-26 18:32:58,468 main.py:47] epoch 37, training loss: 2634.34, average training loss: 7617.63, base loss: 2631.04
[INFO 2017-06-26 18:32:58,718 main.py:47] epoch 38, training loss: 2776.60, average training loss: 7493.51, base loss: 2634.32
[INFO 2017-06-26 18:32:58,975 main.py:47] epoch 39, training loss: 2051.38, average training loss: 7357.45, base loss: 2618.84
[INFO 2017-06-26 18:32:59,220 main.py:47] epoch 40, training loss: 2373.31, average training loss: 7235.89, base loss: 2612.33
[INFO 2017-06-26 18:32:59,475 main.py:47] epoch 41, training loss: 2758.40, average training loss: 7129.28, base loss: 2615.93
[INFO 2017-06-26 18:32:59,726 main.py:47] epoch 42, training loss: 2603.77, average training loss: 7024.04, base loss: 2615.91
[INFO 2017-06-26 18:32:59,981 main.py:47] epoch 43, training loss: 2464.74, average training loss: 6920.42, base loss: 2612.28
[INFO 2017-06-26 18:33:00,232 main.py:47] epoch 44, training loss: 2305.43, average training loss: 6817.86, base loss: 2605.30
[INFO 2017-06-26 18:33:00,485 main.py:47] epoch 45, training loss: 2831.41, average training loss: 6731.20, base loss: 2610.83
[INFO 2017-06-26 18:33:00,736 main.py:47] epoch 46, training loss: 2243.33, average training loss: 6635.71, base loss: 2602.75
[INFO 2017-06-26 18:33:00,990 main.py:47] epoch 47, training loss: 3034.05, average training loss: 6560.68, base loss: 2612.24
[INFO 2017-06-26 18:33:01,241 main.py:47] epoch 48, training loss: 2295.59, average training loss: 6473.63, base loss: 2605.50
[INFO 2017-06-26 18:33:01,493 main.py:47] epoch 49, training loss: 2474.84, average training loss: 6393.66, base loss: 2603.16
[INFO 2017-06-26 18:33:01,743 main.py:47] epoch 50, training loss: 2644.43, average training loss: 6320.14, base loss: 2604.43
[INFO 2017-06-26 18:33:01,995 main.py:47] epoch 51, training loss: 2655.62, average training loss: 6249.67, base loss: 2605.88
[INFO 2017-06-26 18:33:02,245 main.py:47] epoch 52, training loss: 2800.10, average training loss: 6184.59, base loss: 2610.11
[INFO 2017-06-26 18:33:02,496 main.py:47] epoch 53, training loss: 2154.17, average training loss: 6109.95, base loss: 2602.01
[INFO 2017-06-26 18:33:02,741 main.py:47] epoch 54, training loss: 2852.80, average training loss: 6050.73, base loss: 2607.30
[INFO 2017-06-26 18:33:02,995 main.py:47] epoch 55, training loss: 2097.89, average training loss: 5980.14, base loss: 2598.33
[INFO 2017-06-26 18:33:03,247 main.py:47] epoch 56, training loss: 2694.88, average training loss: 5922.51, base loss: 2600.86
[INFO 2017-06-26 18:33:03,499 main.py:47] epoch 57, training loss: 2614.41, average training loss: 5865.47, base loss: 2601.92
[INFO 2017-06-26 18:33:03,749 main.py:47] epoch 58, training loss: 2367.23, average training loss: 5806.18, base loss: 2598.59
[INFO 2017-06-26 18:33:04,002 main.py:47] epoch 59, training loss: 2787.31, average training loss: 5755.86, base loss: 2602.64
[INFO 2017-06-26 18:33:04,253 main.py:47] epoch 60, training loss: 2737.94, average training loss: 5706.39, base loss: 2606.02
[INFO 2017-06-26 18:33:04,505 main.py:47] epoch 61, training loss: 2115.45, average training loss: 5648.47, base loss: 2598.37
[INFO 2017-06-26 18:33:04,755 main.py:47] epoch 62, training loss: 2396.10, average training loss: 5596.85, base loss: 2595.30
[INFO 2017-06-26 18:33:05,009 main.py:47] epoch 63, training loss: 2317.76, average training loss: 5545.61, base loss: 2591.26
[INFO 2017-06-26 18:33:05,259 main.py:47] epoch 64, training loss: 2488.02, average training loss: 5498.57, base loss: 2590.33
[INFO 2017-06-26 18:33:05,509 main.py:47] epoch 65, training loss: 3049.07, average training loss: 5461.46, base loss: 2598.16
[INFO 2017-06-26 18:33:05,756 main.py:47] epoch 66, training loss: 2774.79, average training loss: 5421.36, base loss: 2601.77
[INFO 2017-06-26 18:33:06,012 main.py:47] epoch 67, training loss: 2147.13, average training loss: 5373.21, base loss: 2595.45
[INFO 2017-06-26 18:33:06,261 main.py:47] epoch 68, training loss: 2247.76, average training loss: 5327.91, base loss: 2591.05
[INFO 2017-06-26 18:33:06,508 main.py:47] epoch 69, training loss: 2416.47, average training loss: 5286.32, base loss: 2589.50
[INFO 2017-06-26 18:33:06,758 main.py:47] epoch 70, training loss: 3008.40, average training loss: 5254.23, base loss: 2597.02
[INFO 2017-06-26 18:33:07,016 main.py:47] epoch 71, training loss: 2273.23, average training loss: 5212.83, base loss: 2593.00
[INFO 2017-06-26 18:33:07,265 main.py:47] epoch 72, training loss: 2636.49, average training loss: 5177.54, base loss: 2594.62
[INFO 2017-06-26 18:33:07,516 main.py:47] epoch 73, training loss: 2333.19, average training loss: 5139.10, base loss: 2591.66
[INFO 2017-06-26 18:33:07,767 main.py:47] epoch 74, training loss: 2652.37, average training loss: 5105.95, base loss: 2593.74
[INFO 2017-06-26 18:33:08,018 main.py:47] epoch 75, training loss: 2463.02, average training loss: 5071.17, base loss: 2593.21
[INFO 2017-06-26 18:33:08,269 main.py:47] epoch 76, training loss: 2490.46, average training loss: 5037.66, base loss: 2592.92
[INFO 2017-06-26 18:33:08,520 main.py:47] epoch 77, training loss: 2423.78, average training loss: 5004.14, base loss: 2591.43
[INFO 2017-06-26 18:33:08,770 main.py:47] epoch 78, training loss: 2898.67, average training loss: 4977.49, base loss: 2596.43
[INFO 2017-06-26 18:33:09,016 main.py:47] epoch 79, training loss: 2432.86, average training loss: 4945.68, base loss: 2594.58
[INFO 2017-06-26 18:33:09,265 main.py:47] epoch 80, training loss: 2630.54, average training loss: 4917.10, base loss: 2596.22
[INFO 2017-06-26 18:33:09,513 main.py:47] epoch 81, training loss: 2707.42, average training loss: 4890.15, base loss: 2598.38
[INFO 2017-06-26 18:33:09,764 main.py:47] epoch 82, training loss: 2279.68, average training loss: 4858.70, base loss: 2595.29
[INFO 2017-06-26 18:33:10,009 main.py:47] epoch 83, training loss: 2531.47, average training loss: 4831.00, base loss: 2595.89
[INFO 2017-06-26 18:33:10,253 main.py:47] epoch 84, training loss: 2419.34, average training loss: 4802.63, base loss: 2594.59
[INFO 2017-06-26 18:33:10,498 main.py:47] epoch 85, training loss: 2659.71, average training loss: 4777.71, base loss: 2596.28
[INFO 2017-06-26 18:33:10,748 main.py:47] epoch 86, training loss: 2121.02, average training loss: 4747.17, base loss: 2591.55
[INFO 2017-06-26 18:33:10,997 main.py:47] epoch 87, training loss: 2525.38, average training loss: 4721.92, base loss: 2592.00
[INFO 2017-06-26 18:33:11,245 main.py:47] epoch 88, training loss: 2910.57, average training loss: 4701.57, base loss: 2596.76
[INFO 2017-06-26 18:33:11,497 main.py:47] epoch 89, training loss: 2542.72, average training loss: 4677.58, base loss: 2597.31
[INFO 2017-06-26 18:33:11,749 main.py:47] epoch 90, training loss: 2503.24, average training loss: 4653.69, base loss: 2597.42
[INFO 2017-06-26 18:33:12,002 main.py:47] epoch 91, training loss: 2416.68, average training loss: 4629.38, base loss: 2596.43
[INFO 2017-06-26 18:33:12,255 main.py:47] epoch 92, training loss: 2298.85, average training loss: 4604.32, base loss: 2594.11
[INFO 2017-06-26 18:33:12,509 main.py:47] epoch 93, training loss: 2481.53, average training loss: 4581.73, base loss: 2593.98
[INFO 2017-06-26 18:33:12,760 main.py:47] epoch 94, training loss: 2133.07, average training loss: 4555.96, base loss: 2590.01
[INFO 2017-06-26 18:33:13,009 main.py:47] epoch 95, training loss: 2320.89, average training loss: 4532.68, base loss: 2588.36
[INFO 2017-06-26 18:33:13,258 main.py:47] epoch 96, training loss: 2210.81, average training loss: 4508.74, base loss: 2585.45
[INFO 2017-06-26 18:33:13,504 main.py:47] epoch 97, training loss: 2984.87, average training loss: 4493.19, base loss: 2591.28
[INFO 2017-06-26 18:33:13,752 main.py:47] epoch 98, training loss: 3073.13, average training loss: 4478.85, base loss: 2597.86
[INFO 2017-06-26 18:33:14,003 main.py:47] epoch 99, training loss: 2937.66, average training loss: 4463.43, base loss: 2603.14
[INFO 2017-06-26 18:33:14,003 main.py:49] epoch 99, testing
[INFO 2017-06-26 18:33:17,972 main.py:100] average testing loss: 2544.08, base loss: 2666.91
[INFO 2017-06-26 18:33:17,995 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:33:18,008 main.py:73] current best accuracy: 2544.08
[INFO 2017-06-26 18:33:18,256 main.py:47] epoch 100, training loss: 2737.98, average training loss: 4446.35, base loss: 2606.00
[INFO 2017-06-26 18:33:18,501 main.py:47] epoch 101, training loss: 2597.26, average training loss: 4428.22, base loss: 2607.14
[INFO 2017-06-26 18:33:18,752 main.py:47] epoch 102, training loss: 2618.97, average training loss: 4410.66, base loss: 2608.19
[INFO 2017-06-26 18:33:19,004 main.py:47] epoch 103, training loss: 2370.66, average training loss: 4391.04, base loss: 2606.95
[INFO 2017-06-26 18:33:19,261 main.py:47] epoch 104, training loss: 2704.06, average training loss: 4374.97, base loss: 2608.81
[INFO 2017-06-26 18:33:19,513 main.py:47] epoch 105, training loss: 2902.24, average training loss: 4361.08, base loss: 2613.17
[INFO 2017-06-26 18:33:19,762 main.py:47] epoch 106, training loss: 2300.68, average training loss: 4341.82, base loss: 2611.52
[INFO 2017-06-26 18:33:20,010 main.py:47] epoch 107, training loss: 2558.83, average training loss: 4325.31, base loss: 2612.05
[INFO 2017-06-26 18:33:20,267 main.py:47] epoch 108, training loss: 2376.09, average training loss: 4307.43, base loss: 2611.11
[INFO 2017-06-26 18:33:20,514 main.py:47] epoch 109, training loss: 2496.61, average training loss: 4290.97, base loss: 2610.98
[INFO 2017-06-26 18:33:20,760 main.py:47] epoch 110, training loss: 2425.96, average training loss: 4274.17, base loss: 2610.91
[INFO 2017-06-26 18:33:21,006 main.py:47] epoch 111, training loss: 2261.15, average training loss: 4256.19, base loss: 2608.38
[INFO 2017-06-26 18:33:21,261 main.py:47] epoch 112, training loss: 2732.33, average training loss: 4242.71, base loss: 2610.68
[INFO 2017-06-26 18:33:21,510 main.py:47] epoch 113, training loss: 2982.31, average training loss: 4231.65, base loss: 2615.08
[INFO 2017-06-26 18:33:21,769 main.py:47] epoch 114, training loss: 2892.60, average training loss: 4220.01, base loss: 2618.62
[INFO 2017-06-26 18:33:22,019 main.py:47] epoch 115, training loss: 2740.89, average training loss: 4207.26, base loss: 2621.05
[INFO 2017-06-26 18:33:22,276 main.py:47] epoch 116, training loss: 2340.08, average training loss: 4191.30, base loss: 2619.62
[INFO 2017-06-26 18:33:22,529 main.py:47] epoch 117, training loss: 2339.70, average training loss: 4175.61, base loss: 2618.05
[INFO 2017-06-26 18:33:22,785 main.py:47] epoch 118, training loss: 2582.94, average training loss: 4162.22, base loss: 2618.71
[INFO 2017-06-26 18:33:23,034 main.py:47] epoch 119, training loss: 2403.75, average training loss: 4147.57, base loss: 2618.03
[INFO 2017-06-26 18:33:23,286 main.py:47] epoch 120, training loss: 2404.36, average training loss: 4133.16, base loss: 2617.12
[INFO 2017-06-26 18:33:23,539 main.py:47] epoch 121, training loss: 2659.03, average training loss: 4121.08, base loss: 2618.87
[INFO 2017-06-26 18:33:23,794 main.py:47] epoch 122, training loss: 2336.88, average training loss: 4106.57, base loss: 2617.88
[INFO 2017-06-26 18:33:24,043 main.py:47] epoch 123, training loss: 2543.31, average training loss: 4093.97, base loss: 2618.61
[INFO 2017-06-26 18:33:24,295 main.py:47] epoch 124, training loss: 2556.74, average training loss: 4081.67, base loss: 2619.06
[INFO 2017-06-26 18:33:24,547 main.py:47] epoch 125, training loss: 2036.40, average training loss: 4065.44, base loss: 2614.87
[INFO 2017-06-26 18:33:24,797 main.py:47] epoch 126, training loss: 2354.74, average training loss: 4051.97, base loss: 2613.95
[INFO 2017-06-26 18:33:25,045 main.py:47] epoch 127, training loss: 2245.72, average training loss: 4037.86, base loss: 2612.05
[INFO 2017-06-26 18:33:25,298 main.py:47] epoch 128, training loss: 2311.07, average training loss: 4024.47, base loss: 2610.91
[INFO 2017-06-26 18:33:25,550 main.py:47] epoch 129, training loss: 2649.23, average training loss: 4013.89, base loss: 2612.52
[INFO 2017-06-26 18:33:25,802 main.py:47] epoch 130, training loss: 2370.19, average training loss: 4001.34, base loss: 2611.33
[INFO 2017-06-26 18:33:26,049 main.py:47] epoch 131, training loss: 2468.27, average training loss: 3989.73, base loss: 2611.14
[INFO 2017-06-26 18:33:26,303 main.py:47] epoch 132, training loss: 2171.93, average training loss: 3976.06, base loss: 2608.60
[INFO 2017-06-26 18:33:26,552 main.py:47] epoch 133, training loss: 2074.35, average training loss: 3961.87, base loss: 2605.41
[INFO 2017-06-26 18:33:26,804 main.py:47] epoch 134, training loss: 2490.35, average training loss: 3950.97, base loss: 2605.60
[INFO 2017-06-26 18:33:27,058 main.py:47] epoch 135, training loss: 2472.39, average training loss: 3940.10, base loss: 2605.39
[INFO 2017-06-26 18:33:27,311 main.py:47] epoch 136, training loss: 2618.99, average training loss: 3930.46, base loss: 2606.59
[INFO 2017-06-26 18:33:27,564 main.py:47] epoch 137, training loss: 2371.47, average training loss: 3919.16, base loss: 2605.91
[INFO 2017-06-26 18:33:27,815 main.py:47] epoch 138, training loss: 2733.68, average training loss: 3910.63, base loss: 2608.20
[INFO 2017-06-26 18:33:28,067 main.py:47] epoch 139, training loss: 2370.50, average training loss: 3899.63, base loss: 2607.13
[INFO 2017-06-26 18:33:28,318 main.py:47] epoch 140, training loss: 2443.62, average training loss: 3889.30, base loss: 2607.16
[INFO 2017-06-26 18:33:28,576 main.py:47] epoch 141, training loss: 2684.83, average training loss: 3880.82, base loss: 2609.36
[INFO 2017-06-26 18:33:28,828 main.py:47] epoch 142, training loss: 2364.47, average training loss: 3870.22, base loss: 2609.22
[INFO 2017-06-26 18:33:29,079 main.py:47] epoch 143, training loss: 2247.03, average training loss: 3858.94, base loss: 2607.85
[INFO 2017-06-26 18:33:29,331 main.py:47] epoch 144, training loss: 2417.21, average training loss: 3849.00, base loss: 2608.22
[INFO 2017-06-26 18:33:29,579 main.py:47] epoch 145, training loss: 2313.14, average training loss: 3838.48, base loss: 2607.41
[INFO 2017-06-26 18:33:29,826 main.py:47] epoch 146, training loss: 2710.48, average training loss: 3830.81, base loss: 2609.07
[INFO 2017-06-26 18:33:30,070 main.py:47] epoch 147, training loss: 2495.05, average training loss: 3821.78, base loss: 2609.55
[INFO 2017-06-26 18:33:30,325 main.py:47] epoch 148, training loss: 2327.66, average training loss: 3811.76, base loss: 2608.74
[INFO 2017-06-26 18:33:30,576 main.py:47] epoch 149, training loss: 2717.99, average training loss: 3804.46, base loss: 2610.63
[INFO 2017-06-26 18:33:30,827 main.py:47] epoch 150, training loss: 2309.51, average training loss: 3794.56, base loss: 2609.74
[INFO 2017-06-26 18:33:31,078 main.py:47] epoch 151, training loss: 2376.97, average training loss: 3785.24, base loss: 2608.95
[INFO 2017-06-26 18:33:31,328 main.py:47] epoch 152, training loss: 2726.62, average training loss: 3778.32, base loss: 2611.48
[INFO 2017-06-26 18:33:31,589 main.py:47] epoch 153, training loss: 2638.90, average training loss: 3770.92, base loss: 2612.56
[INFO 2017-06-26 18:33:31,841 main.py:47] epoch 154, training loss: 3003.26, average training loss: 3765.97, base loss: 2616.79
[INFO 2017-06-26 18:33:32,092 main.py:47] epoch 155, training loss: 2720.51, average training loss: 3759.26, base loss: 2618.73
[INFO 2017-06-26 18:33:32,344 main.py:47] epoch 156, training loss: 2354.93, average training loss: 3750.32, base loss: 2618.20
[INFO 2017-06-26 18:33:32,596 main.py:47] epoch 157, training loss: 2372.78, average training loss: 3741.60, base loss: 2618.29
[INFO 2017-06-26 18:33:32,851 main.py:47] epoch 158, training loss: 2584.70, average training loss: 3734.33, base loss: 2619.53
[INFO 2017-06-26 18:33:33,105 main.py:47] epoch 159, training loss: 2589.61, average training loss: 3727.17, base loss: 2620.78
[INFO 2017-06-26 18:33:33,363 main.py:47] epoch 160, training loss: 2100.92, average training loss: 3717.07, base loss: 2617.98
[INFO 2017-06-26 18:33:33,615 main.py:47] epoch 161, training loss: 2344.95, average training loss: 3708.60, base loss: 2617.46
[INFO 2017-06-26 18:33:33,870 main.py:47] epoch 162, training loss: 2482.84, average training loss: 3701.08, base loss: 2617.77
[INFO 2017-06-26 18:33:34,115 main.py:47] epoch 163, training loss: 2334.71, average training loss: 3692.75, base loss: 2617.19
[INFO 2017-06-26 18:33:34,371 main.py:47] epoch 164, training loss: 2233.16, average training loss: 3683.90, base loss: 2616.02
[INFO 2017-06-26 18:33:34,621 main.py:47] epoch 165, training loss: 2231.87, average training loss: 3675.16, base loss: 2614.68
[INFO 2017-06-26 18:33:34,873 main.py:47] epoch 166, training loss: 2826.68, average training loss: 3670.07, base loss: 2617.66
[INFO 2017-06-26 18:33:35,128 main.py:47] epoch 167, training loss: 2167.30, average training loss: 3661.13, base loss: 2615.98
[INFO 2017-06-26 18:33:35,377 main.py:47] epoch 168, training loss: 2753.16, average training loss: 3655.76, base loss: 2618.50
[INFO 2017-06-26 18:33:35,629 main.py:47] epoch 169, training loss: 2209.31, average training loss: 3647.25, base loss: 2616.97
[INFO 2017-06-26 18:33:35,878 main.py:47] epoch 170, training loss: 2364.37, average training loss: 3639.75, base loss: 2616.56
[INFO 2017-06-26 18:33:36,127 main.py:47] epoch 171, training loss: 2222.42, average training loss: 3631.51, base loss: 2615.54
[INFO 2017-06-26 18:33:36,387 main.py:47] epoch 172, training loss: 2480.26, average training loss: 3624.85, base loss: 2616.06
[INFO 2017-06-26 18:33:36,645 main.py:47] epoch 173, training loss: 2235.68, average training loss: 3616.87, base loss: 2614.60
[INFO 2017-06-26 18:33:36,898 main.py:47] epoch 174, training loss: 1735.46, average training loss: 3606.12, base loss: 2610.37
[INFO 2017-06-26 18:33:37,150 main.py:47] epoch 175, training loss: 2169.72, average training loss: 3597.96, base loss: 2609.04
[INFO 2017-06-26 18:33:37,405 main.py:47] epoch 176, training loss: 1903.60, average training loss: 3588.38, base loss: 2606.19
[INFO 2017-06-26 18:33:37,662 main.py:47] epoch 177, training loss: 2133.11, average training loss: 3580.21, base loss: 2604.55
[INFO 2017-06-26 18:33:37,923 main.py:47] epoch 178, training loss: 2587.23, average training loss: 3574.66, base loss: 2606.07
[INFO 2017-06-26 18:33:38,172 main.py:47] epoch 179, training loss: 2388.80, average training loss: 3568.07, base loss: 2606.28
[INFO 2017-06-26 18:33:38,429 main.py:47] epoch 180, training loss: 2086.86, average training loss: 3559.89, base loss: 2604.11
[INFO 2017-06-26 18:33:38,680 main.py:47] epoch 181, training loss: 2541.28, average training loss: 3554.29, base loss: 2605.83
[INFO 2017-06-26 18:33:38,938 main.py:47] epoch 182, training loss: 2061.30, average training loss: 3546.13, base loss: 2604.02
[INFO 2017-06-26 18:33:39,190 main.py:47] epoch 183, training loss: 2587.58, average training loss: 3540.92, base loss: 2605.48
[INFO 2017-06-26 18:33:39,446 main.py:47] epoch 184, training loss: 1914.40, average training loss: 3532.13, base loss: 2602.76
[INFO 2017-06-26 18:33:39,699 main.py:47] epoch 185, training loss: 2332.55, average training loss: 3525.68, base loss: 2602.15
[INFO 2017-06-26 18:33:39,954 main.py:47] epoch 186, training loss: 2399.52, average training loss: 3519.66, base loss: 2602.34
[INFO 2017-06-26 18:33:40,205 main.py:47] epoch 187, training loss: 2215.75, average training loss: 3512.72, base loss: 2601.50
[INFO 2017-06-26 18:33:40,465 main.py:47] epoch 188, training loss: 2447.39, average training loss: 3507.09, base loss: 2601.90
[INFO 2017-06-26 18:33:40,720 main.py:47] epoch 189, training loss: 2439.98, average training loss: 3501.47, base loss: 2602.55
[INFO 2017-06-26 18:33:40,975 main.py:47] epoch 190, training loss: 2713.66, average training loss: 3497.35, base loss: 2604.55
[INFO 2017-06-26 18:33:41,225 main.py:47] epoch 191, training loss: 2723.72, average training loss: 3493.32, base loss: 2606.60
[INFO 2017-06-26 18:33:41,481 main.py:47] epoch 192, training loss: 2283.59, average training loss: 3487.05, base loss: 2605.71
[INFO 2017-06-26 18:33:41,734 main.py:47] epoch 193, training loss: 2021.62, average training loss: 3479.49, base loss: 2603.40
[INFO 2017-06-26 18:33:41,989 main.py:47] epoch 194, training loss: 2016.88, average training loss: 3471.99, base loss: 2601.32
[INFO 2017-06-26 18:33:42,248 main.py:47] epoch 195, training loss: 2445.42, average training loss: 3466.76, base loss: 2601.82
[INFO 2017-06-26 18:33:42,503 main.py:47] epoch 196, training loss: 2057.13, average training loss: 3459.60, base loss: 2600.26
[INFO 2017-06-26 18:33:42,755 main.py:47] epoch 197, training loss: 2148.87, average training loss: 3452.98, base loss: 2599.06
[INFO 2017-06-26 18:33:43,004 main.py:47] epoch 198, training loss: 2459.98, average training loss: 3447.99, base loss: 2600.01
[INFO 2017-06-26 18:33:43,259 main.py:47] epoch 199, training loss: 2133.21, average training loss: 3441.42, base loss: 2598.50
[INFO 2017-06-26 18:33:43,259 main.py:49] epoch 199, testing
[INFO 2017-06-26 18:33:47,057 main.py:100] average testing loss: 2337.66, base loss: 2580.72
[INFO 2017-06-26 18:33:47,082 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:33:47,096 main.py:73] current best accuracy: 2337.66
[INFO 2017-06-26 18:33:47,350 main.py:47] epoch 200, training loss: 2302.79, average training loss: 3435.75, base loss: 2598.09
[INFO 2017-06-26 18:33:47,604 main.py:47] epoch 201, training loss: 2504.87, average training loss: 3431.14, base loss: 2599.13
[INFO 2017-06-26 18:33:47,852 main.py:47] epoch 202, training loss: 2094.43, average training loss: 3424.56, base loss: 2598.00
[INFO 2017-06-26 18:33:48,104 main.py:47] epoch 203, training loss: 2024.38, average training loss: 3417.70, base loss: 2596.28
[INFO 2017-06-26 18:33:48,358 main.py:47] epoch 204, training loss: 2038.98, average training loss: 3410.97, base loss: 2594.61
[INFO 2017-06-26 18:33:48,611 main.py:47] epoch 205, training loss: 2183.61, average training loss: 3405.01, base loss: 2594.24
[INFO 2017-06-26 18:33:48,863 main.py:47] epoch 206, training loss: 2760.92, average training loss: 3401.90, base loss: 2596.27
[INFO 2017-06-26 18:33:49,115 main.py:47] epoch 207, training loss: 2149.05, average training loss: 3395.88, base loss: 2595.23
[INFO 2017-06-26 18:33:49,367 main.py:47] epoch 208, training loss: 2120.16, average training loss: 3389.77, base loss: 2594.10
[INFO 2017-06-26 18:33:49,620 main.py:47] epoch 209, training loss: 2775.90, average training loss: 3386.85, base loss: 2596.75
[INFO 2017-06-26 18:33:49,872 main.py:47] epoch 210, training loss: 2024.51, average training loss: 3380.39, base loss: 2595.33
[INFO 2017-06-26 18:33:50,125 main.py:47] epoch 211, training loss: 2255.14, average training loss: 3375.09, base loss: 2595.34
[INFO 2017-06-26 18:33:50,374 main.py:47] epoch 212, training loss: 2252.63, average training loss: 3369.82, base loss: 2594.53
[INFO 2017-06-26 18:33:50,626 main.py:47] epoch 213, training loss: 2099.36, average training loss: 3363.88, base loss: 2593.40
[INFO 2017-06-26 18:33:50,877 main.py:47] epoch 214, training loss: 2392.79, average training loss: 3359.36, base loss: 2593.51
[INFO 2017-06-26 18:33:51,130 main.py:47] epoch 215, training loss: 2324.25, average training loss: 3354.57, base loss: 2593.56
[INFO 2017-06-26 18:33:51,385 main.py:47] epoch 216, training loss: 2346.51, average training loss: 3349.93, base loss: 2593.52
[INFO 2017-06-26 18:33:51,640 main.py:47] epoch 217, training loss: 2425.80, average training loss: 3345.69, base loss: 2594.05
[INFO 2017-06-26 18:33:51,894 main.py:47] epoch 218, training loss: 2378.01, average training loss: 3341.27, base loss: 2594.09
[INFO 2017-06-26 18:33:52,154 main.py:47] epoch 219, training loss: 2845.46, average training loss: 3339.01, base loss: 2596.71
[INFO 2017-06-26 18:33:52,414 main.py:47] epoch 220, training loss: 2149.10, average training loss: 3333.63, base loss: 2595.03
[INFO 2017-06-26 18:33:52,698 main.py:47] epoch 221, training loss: 2723.67, average training loss: 3330.88, base loss: 2597.16
[INFO 2017-06-26 18:33:52,968 main.py:47] epoch 222, training loss: 2668.13, average training loss: 3327.91, base loss: 2599.61
[INFO 2017-06-26 18:33:53,242 main.py:47] epoch 223, training loss: 2387.57, average training loss: 3323.71, base loss: 2600.15
[INFO 2017-06-26 18:33:53,520 main.py:47] epoch 224, training loss: 2050.99, average training loss: 3318.06, base loss: 2598.52
[INFO 2017-06-26 18:33:53,795 main.py:47] epoch 225, training loss: 2377.43, average training loss: 3313.89, base loss: 2598.15
[INFO 2017-06-26 18:33:54,071 main.py:47] epoch 226, training loss: 2316.39, average training loss: 3309.50, base loss: 2598.27
[INFO 2017-06-26 18:33:54,344 main.py:47] epoch 227, training loss: 2105.15, average training loss: 3304.22, base loss: 2596.97
[INFO 2017-06-26 18:33:54,618 main.py:47] epoch 228, training loss: 2318.36, average training loss: 3299.91, base loss: 2596.99
[INFO 2017-06-26 18:33:54,892 main.py:47] epoch 229, training loss: 2436.50, average training loss: 3296.16, base loss: 2597.54
[INFO 2017-06-26 18:33:55,162 main.py:47] epoch 230, training loss: 2372.13, average training loss: 3292.16, base loss: 2597.45
[INFO 2017-06-26 18:33:55,431 main.py:47] epoch 231, training loss: 2385.31, average training loss: 3288.25, base loss: 2597.67
[INFO 2017-06-26 18:33:55,701 main.py:47] epoch 232, training loss: 2473.52, average training loss: 3284.75, base loss: 2598.12
[INFO 2017-06-26 18:33:55,971 main.py:47] epoch 233, training loss: 2260.63, average training loss: 3280.38, base loss: 2597.78
[INFO 2017-06-26 18:33:56,240 main.py:47] epoch 234, training loss: 2882.62, average training loss: 3278.68, base loss: 2600.95
[INFO 2017-06-26 18:33:56,510 main.py:47] epoch 235, training loss: 2283.60, average training loss: 3274.47, base loss: 2600.69
[INFO 2017-06-26 18:33:56,780 main.py:47] epoch 236, training loss: 2382.19, average training loss: 3270.70, base loss: 2600.90
[INFO 2017-06-26 18:33:57,050 main.py:47] epoch 237, training loss: 2263.70, average training loss: 3266.47, base loss: 2600.42
[INFO 2017-06-26 18:33:57,320 main.py:47] epoch 238, training loss: 2291.59, average training loss: 3262.39, base loss: 2599.94
[INFO 2017-06-26 18:33:57,590 main.py:47] epoch 239, training loss: 1983.97, average training loss: 3257.07, base loss: 2598.26
[INFO 2017-06-26 18:33:57,864 main.py:47] epoch 240, training loss: 2227.53, average training loss: 3252.79, base loss: 2597.61
[INFO 2017-06-26 18:33:58,194 main.py:47] epoch 241, training loss: 2059.99, average training loss: 3247.86, base loss: 2596.23
[INFO 2017-06-26 18:33:58,498 main.py:47] epoch 242, training loss: 2273.07, average training loss: 3243.85, base loss: 2596.11
[INFO 2017-06-26 18:33:58,814 main.py:47] epoch 243, training loss: 2125.46, average training loss: 3239.27, base loss: 2595.08
[INFO 2017-06-26 18:33:59,120 main.py:47] epoch 244, training loss: 2257.74, average training loss: 3235.26, base loss: 2594.95
[INFO 2017-06-26 18:33:59,435 main.py:47] epoch 245, training loss: 2535.95, average training loss: 3232.42, base loss: 2596.54
[INFO 2017-06-26 18:33:59,742 main.py:47] epoch 246, training loss: 2297.04, average training loss: 3228.63, base loss: 2596.36
[INFO 2017-06-26 18:34:00,033 main.py:47] epoch 247, training loss: 2325.15, average training loss: 3224.99, base loss: 2596.82
[INFO 2017-06-26 18:34:00,310 main.py:47] epoch 248, training loss: 2448.32, average training loss: 3221.87, base loss: 2597.30
[INFO 2017-06-26 18:34:00,635 main.py:47] epoch 249, training loss: 2420.88, average training loss: 3218.67, base loss: 2597.83
[INFO 2017-06-26 18:34:00,963 main.py:47] epoch 250, training loss: 2280.72, average training loss: 3214.93, base loss: 2598.19
[INFO 2017-06-26 18:34:01,280 main.py:47] epoch 251, training loss: 2304.60, average training loss: 3211.32, base loss: 2598.64
[INFO 2017-06-26 18:34:01,572 main.py:47] epoch 252, training loss: 2673.09, average training loss: 3209.19, base loss: 2600.33
[INFO 2017-06-26 18:34:01,842 main.py:47] epoch 253, training loss: 2280.99, average training loss: 3205.54, base loss: 2600.72
[INFO 2017-06-26 18:34:02,106 main.py:47] epoch 254, training loss: 2216.41, average training loss: 3201.66, base loss: 2600.22
[INFO 2017-06-26 18:34:02,375 main.py:47] epoch 255, training loss: 2431.61, average training loss: 3198.65, base loss: 2600.86
[INFO 2017-06-26 18:34:02,645 main.py:47] epoch 256, training loss: 2194.65, average training loss: 3194.74, base loss: 2599.76
[INFO 2017-06-26 18:34:02,914 main.py:47] epoch 257, training loss: 2909.31, average training loss: 3193.64, base loss: 2602.15
[INFO 2017-06-26 18:34:03,181 main.py:47] epoch 258, training loss: 2679.51, average training loss: 3191.65, base loss: 2603.72
[INFO 2017-06-26 18:34:03,447 main.py:47] epoch 259, training loss: 2345.77, average training loss: 3188.40, base loss: 2603.83
[INFO 2017-06-26 18:34:03,713 main.py:47] epoch 260, training loss: 2069.17, average training loss: 3184.11, base loss: 2602.77
[INFO 2017-06-26 18:34:03,983 main.py:47] epoch 261, training loss: 2510.81, average training loss: 3181.54, base loss: 2603.98
[INFO 2017-06-26 18:34:04,251 main.py:47] epoch 262, training loss: 2142.67, average training loss: 3177.59, base loss: 2603.50
[INFO 2017-06-26 18:34:04,517 main.py:47] epoch 263, training loss: 2065.55, average training loss: 3173.38, base loss: 2602.22
[INFO 2017-06-26 18:34:04,785 main.py:47] epoch 264, training loss: 2528.91, average training loss: 3170.95, base loss: 2603.28
[INFO 2017-06-26 18:34:05,056 main.py:47] epoch 265, training loss: 2160.61, average training loss: 3167.15, base loss: 2602.06
[INFO 2017-06-26 18:34:05,326 main.py:47] epoch 266, training loss: 2174.95, average training loss: 3163.43, base loss: 2601.61
[INFO 2017-06-26 18:34:05,599 main.py:47] epoch 267, training loss: 2065.62, average training loss: 3159.33, base loss: 2600.94
[INFO 2017-06-26 18:34:05,882 main.py:47] epoch 268, training loss: 2891.18, average training loss: 3158.34, base loss: 2603.40
[INFO 2017-06-26 18:34:06,157 main.py:47] epoch 269, training loss: 2274.94, average training loss: 3155.07, base loss: 2603.32
[INFO 2017-06-26 18:34:06,427 main.py:47] epoch 270, training loss: 2169.02, average training loss: 3151.43, base loss: 2602.71
[INFO 2017-06-26 18:34:06,698 main.py:47] epoch 271, training loss: 2009.36, average training loss: 3147.23, base loss: 2601.62
[INFO 2017-06-26 18:34:06,967 main.py:47] epoch 272, training loss: 2243.43, average training loss: 3143.92, base loss: 2601.75
[INFO 2017-06-26 18:34:07,232 main.py:47] epoch 273, training loss: 2404.43, average training loss: 3141.22, base loss: 2602.48
[INFO 2017-06-26 18:34:07,503 main.py:47] epoch 274, training loss: 1943.56, average training loss: 3136.86, base loss: 2601.06
[INFO 2017-06-26 18:34:07,779 main.py:47] epoch 275, training loss: 2259.12, average training loss: 3133.68, base loss: 2600.85
[INFO 2017-06-26 18:34:08,055 main.py:47] epoch 276, training loss: 2222.00, average training loss: 3130.39, base loss: 2600.49
[INFO 2017-06-26 18:34:08,328 main.py:47] epoch 277, training loss: 2150.51, average training loss: 3126.87, base loss: 2600.04
[INFO 2017-06-26 18:34:08,609 main.py:47] epoch 278, training loss: 2451.78, average training loss: 3124.45, base loss: 2600.86
[INFO 2017-06-26 18:34:08,887 main.py:47] epoch 279, training loss: 2053.00, average training loss: 3120.62, base loss: 2600.02
[INFO 2017-06-26 18:34:09,164 main.py:47] epoch 280, training loss: 2249.44, average training loss: 3117.52, base loss: 2600.33
[INFO 2017-06-26 18:34:09,448 main.py:47] epoch 281, training loss: 2687.58, average training loss: 3116.00, base loss: 2602.09
[INFO 2017-06-26 18:34:09,727 main.py:47] epoch 282, training loss: 2275.37, average training loss: 3113.03, base loss: 2602.26
[INFO 2017-06-26 18:34:10,010 main.py:47] epoch 283, training loss: 2581.45, average training loss: 3111.15, base loss: 2603.05
[INFO 2017-06-26 18:34:10,290 main.py:47] epoch 284, training loss: 2151.49, average training loss: 3107.79, base loss: 2602.67
[INFO 2017-06-26 18:34:10,571 main.py:47] epoch 285, training loss: 2275.28, average training loss: 3104.88, base loss: 2602.80
[INFO 2017-06-26 18:34:10,852 main.py:47] epoch 286, training loss: 2254.79, average training loss: 3101.91, base loss: 2603.25
[INFO 2017-06-26 18:34:11,129 main.py:47] epoch 287, training loss: 2202.08, average training loss: 3098.79, base loss: 2602.83
[INFO 2017-06-26 18:34:11,411 main.py:47] epoch 288, training loss: 2047.99, average training loss: 3095.15, base loss: 2601.40
[INFO 2017-06-26 18:34:11,696 main.py:47] epoch 289, training loss: 2454.86, average training loss: 3092.95, base loss: 2602.06
[INFO 2017-06-26 18:34:11,977 main.py:47] epoch 290, training loss: 1987.03, average training loss: 3089.15, base loss: 2601.12
[INFO 2017-06-26 18:34:12,254 main.py:47] epoch 291, training loss: 2136.06, average training loss: 3085.88, base loss: 2600.73
[INFO 2017-06-26 18:34:12,528 main.py:47] epoch 292, training loss: 2259.18, average training loss: 3083.06, base loss: 2600.39
[INFO 2017-06-26 18:34:12,804 main.py:47] epoch 293, training loss: 2276.81, average training loss: 3080.32, base loss: 2600.22
[INFO 2017-06-26 18:34:13,086 main.py:47] epoch 294, training loss: 2228.12, average training loss: 3077.43, base loss: 2599.94
[INFO 2017-06-26 18:34:13,366 main.py:47] epoch 295, training loss: 2514.96, average training loss: 3075.53, base loss: 2600.64
[INFO 2017-06-26 18:34:13,647 main.py:47] epoch 296, training loss: 2256.46, average training loss: 3072.77, base loss: 2600.88
[INFO 2017-06-26 18:34:13,930 main.py:47] epoch 297, training loss: 2219.67, average training loss: 3069.91, base loss: 2601.15
[INFO 2017-06-26 18:34:14,216 main.py:47] epoch 298, training loss: 2459.92, average training loss: 3067.87, base loss: 2601.44
[INFO 2017-06-26 18:34:14,501 main.py:47] epoch 299, training loss: 2053.23, average training loss: 3064.49, base loss: 2600.35
[INFO 2017-06-26 18:34:14,501 main.py:49] epoch 299, testing
[INFO 2017-06-26 18:34:18,283 main.py:100] average testing loss: 2387.22, base loss: 2796.39
[INFO 2017-06-26 18:34:18,311 main.py:73] current best accuracy: 2337.66
[INFO 2017-06-26 18:34:18,568 main.py:47] epoch 300, training loss: 2132.39, average training loss: 3061.39, base loss: 2599.61
[INFO 2017-06-26 18:34:18,822 main.py:47] epoch 301, training loss: 2017.19, average training loss: 3057.93, base loss: 2598.83
[INFO 2017-06-26 18:34:19,074 main.py:47] epoch 302, training loss: 3070.50, average training loss: 3057.97, base loss: 2601.73
[INFO 2017-06-26 18:34:19,324 main.py:47] epoch 303, training loss: 1995.54, average training loss: 3054.48, base loss: 2600.64
[INFO 2017-06-26 18:34:19,576 main.py:47] epoch 304, training loss: 1893.92, average training loss: 3050.67, base loss: 2599.21
[INFO 2017-06-26 18:34:19,829 main.py:47] epoch 305, training loss: 2615.24, average training loss: 3049.25, base loss: 2600.67
[INFO 2017-06-26 18:34:20,084 main.py:47] epoch 306, training loss: 2479.58, average training loss: 3047.39, base loss: 2601.95
[INFO 2017-06-26 18:34:20,333 main.py:47] epoch 307, training loss: 2190.74, average training loss: 3044.61, base loss: 2601.90
[INFO 2017-06-26 18:34:20,588 main.py:47] epoch 308, training loss: 2392.16, average training loss: 3042.50, base loss: 2602.65
[INFO 2017-06-26 18:34:20,841 main.py:47] epoch 309, training loss: 2144.57, average training loss: 3039.61, base loss: 2602.13
[INFO 2017-06-26 18:34:21,096 main.py:47] epoch 310, training loss: 2218.34, average training loss: 3036.96, base loss: 2602.21
[INFO 2017-06-26 18:34:21,360 main.py:47] epoch 311, training loss: 2371.89, average training loss: 3034.83, base loss: 2602.58
[INFO 2017-06-26 18:34:21,630 main.py:47] epoch 312, training loss: 2266.06, average training loss: 3032.38, base loss: 2602.98
[INFO 2017-06-26 18:34:21,960 main.py:47] epoch 313, training loss: 2345.19, average training loss: 3030.19, base loss: 2603.37
[INFO 2017-06-26 18:34:22,247 main.py:47] epoch 314, training loss: 1971.23, average training loss: 3026.83, base loss: 2602.01
[INFO 2017-06-26 18:34:22,536 main.py:47] epoch 315, training loss: 2380.62, average training loss: 3024.78, base loss: 2602.81
[INFO 2017-06-26 18:34:22,829 main.py:47] epoch 316, training loss: 2184.54, average training loss: 3022.13, base loss: 2602.56
[INFO 2017-06-26 18:34:23,122 main.py:47] epoch 317, training loss: 2114.40, average training loss: 3019.28, base loss: 2602.01
[INFO 2017-06-26 18:34:23,414 main.py:47] epoch 318, training loss: 2230.46, average training loss: 3016.80, base loss: 2601.71
[INFO 2017-06-26 18:34:23,710 main.py:47] epoch 319, training loss: 2321.01, average training loss: 3014.63, base loss: 2601.82
[INFO 2017-06-26 18:34:24,010 main.py:47] epoch 320, training loss: 2276.37, average training loss: 3012.33, base loss: 2601.80
[INFO 2017-06-26 18:34:24,308 main.py:47] epoch 321, training loss: 2153.70, average training loss: 3009.66, base loss: 2601.41
[INFO 2017-06-26 18:34:24,605 main.py:47] epoch 322, training loss: 2379.62, average training loss: 3007.71, base loss: 2601.79
[INFO 2017-06-26 18:34:24,906 main.py:47] epoch 323, training loss: 2448.93, average training loss: 3005.99, base loss: 2602.78
[INFO 2017-06-26 18:34:25,203 main.py:47] epoch 324, training loss: 2048.48, average training loss: 3003.04, base loss: 2601.95
[INFO 2017-06-26 18:34:25,504 main.py:47] epoch 325, training loss: 2048.82, average training loss: 3000.11, base loss: 2601.37
[INFO 2017-06-26 18:34:25,802 main.py:47] epoch 326, training loss: 1866.03, average training loss: 2996.65, base loss: 2600.16
[INFO 2017-06-26 18:34:26,102 main.py:47] epoch 327, training loss: 2402.70, average training loss: 2994.84, base loss: 2600.93
[INFO 2017-06-26 18:34:26,401 main.py:47] epoch 328, training loss: 1914.12, average training loss: 2991.55, base loss: 2599.97
[INFO 2017-06-26 18:34:26,706 main.py:47] epoch 329, training loss: 2387.15, average training loss: 2989.72, base loss: 2600.71
[INFO 2017-06-26 18:34:27,008 main.py:47] epoch 330, training loss: 2290.11, average training loss: 2987.61, base loss: 2600.26
[INFO 2017-06-26 18:34:27,310 main.py:47] epoch 331, training loss: 2307.54, average training loss: 2985.56, base loss: 2600.49
[INFO 2017-06-26 18:34:27,619 main.py:47] epoch 332, training loss: 2570.63, average training loss: 2984.31, base loss: 2601.76
[INFO 2017-06-26 18:34:27,919 main.py:47] epoch 333, training loss: 2338.79, average training loss: 2982.38, base loss: 2601.80
[INFO 2017-06-26 18:34:28,217 main.py:47] epoch 334, training loss: 1786.22, average training loss: 2978.81, base loss: 2600.08
[INFO 2017-06-26 18:34:28,522 main.py:47] epoch 335, training loss: 2075.45, average training loss: 2976.12, base loss: 2599.22
[INFO 2017-06-26 18:34:28,830 main.py:47] epoch 336, training loss: 2563.26, average training loss: 2974.89, base loss: 2600.44
[INFO 2017-06-26 18:34:29,137 main.py:47] epoch 337, training loss: 2208.70, average training loss: 2972.63, base loss: 2600.38
[INFO 2017-06-26 18:34:29,446 main.py:47] epoch 338, training loss: 2016.37, average training loss: 2969.81, base loss: 2599.60
[INFO 2017-06-26 18:34:29,749 main.py:47] epoch 339, training loss: 2301.37, average training loss: 2967.84, base loss: 2599.82
[INFO 2017-06-26 18:34:30,058 main.py:47] epoch 340, training loss: 2114.51, average training loss: 2965.34, base loss: 2599.34
[INFO 2017-06-26 18:34:30,362 main.py:47] epoch 341, training loss: 1842.29, average training loss: 2962.05, base loss: 2598.21
[INFO 2017-06-26 18:34:30,669 main.py:47] epoch 342, training loss: 2462.05, average training loss: 2960.60, base loss: 2599.00
[INFO 2017-06-26 18:34:30,972 main.py:47] epoch 343, training loss: 2561.93, average training loss: 2959.44, base loss: 2600.13
[INFO 2017-06-26 18:34:31,273 main.py:47] epoch 344, training loss: 2183.16, average training loss: 2957.19, base loss: 2599.68
[INFO 2017-06-26 18:34:31,573 main.py:47] epoch 345, training loss: 1982.63, average training loss: 2954.37, base loss: 2598.76
[INFO 2017-06-26 18:34:31,876 main.py:47] epoch 346, training loss: 2101.42, average training loss: 2951.91, base loss: 2598.31
[INFO 2017-06-26 18:34:32,179 main.py:47] epoch 347, training loss: 2213.59, average training loss: 2949.79, base loss: 2598.37
[INFO 2017-06-26 18:34:32,481 main.py:47] epoch 348, training loss: 2043.48, average training loss: 2947.19, base loss: 2597.74
[INFO 2017-06-26 18:34:32,786 main.py:47] epoch 349, training loss: 1952.13, average training loss: 2944.35, base loss: 2596.98
[INFO 2017-06-26 18:34:33,088 main.py:47] epoch 350, training loss: 2308.11, average training loss: 2942.54, base loss: 2596.83
[INFO 2017-06-26 18:34:33,392 main.py:47] epoch 351, training loss: 2169.29, average training loss: 2940.34, base loss: 2596.42
[INFO 2017-06-26 18:34:33,696 main.py:47] epoch 352, training loss: 2147.11, average training loss: 2938.09, base loss: 2596.19
[INFO 2017-06-26 18:34:34,017 main.py:47] epoch 353, training loss: 2364.39, average training loss: 2936.47, base loss: 2596.51
[INFO 2017-06-26 18:34:34,325 main.py:47] epoch 354, training loss: 1985.31, average training loss: 2933.79, base loss: 2595.29
[INFO 2017-06-26 18:34:34,640 main.py:47] epoch 355, training loss: 2305.17, average training loss: 2932.03, base loss: 2595.32
[INFO 2017-06-26 18:34:34,945 main.py:47] epoch 356, training loss: 2519.15, average training loss: 2930.87, base loss: 2596.49
[INFO 2017-06-26 18:34:35,247 main.py:47] epoch 357, training loss: 2285.11, average training loss: 2929.07, base loss: 2596.59
[INFO 2017-06-26 18:34:35,568 main.py:47] epoch 358, training loss: 2342.18, average training loss: 2927.43, base loss: 2597.07
[INFO 2017-06-26 18:34:35,872 main.py:47] epoch 359, training loss: 2110.01, average training loss: 2925.16, base loss: 2596.83
[INFO 2017-06-26 18:34:36,191 main.py:47] epoch 360, training loss: 2198.92, average training loss: 2923.15, base loss: 2596.81
[INFO 2017-06-26 18:34:36,494 main.py:47] epoch 361, training loss: 2095.18, average training loss: 2920.86, base loss: 2596.47
[INFO 2017-06-26 18:34:36,801 main.py:47] epoch 362, training loss: 2026.32, average training loss: 2918.40, base loss: 2595.56
[INFO 2017-06-26 18:34:37,143 main.py:47] epoch 363, training loss: 2085.17, average training loss: 2916.11, base loss: 2594.79
[INFO 2017-06-26 18:34:37,451 main.py:47] epoch 364, training loss: 2228.86, average training loss: 2914.23, base loss: 2594.86
[INFO 2017-06-26 18:34:37,759 main.py:47] epoch 365, training loss: 1988.11, average training loss: 2911.70, base loss: 2593.78
[INFO 2017-06-26 18:34:38,066 main.py:47] epoch 366, training loss: 2011.45, average training loss: 2909.24, base loss: 2593.18
[INFO 2017-06-26 18:34:38,374 main.py:47] epoch 367, training loss: 2481.28, average training loss: 2908.08, base loss: 2593.92
[INFO 2017-06-26 18:34:38,682 main.py:47] epoch 368, training loss: 1929.81, average training loss: 2905.43, base loss: 2593.24
[INFO 2017-06-26 18:34:38,993 main.py:47] epoch 369, training loss: 2337.02, average training loss: 2903.89, base loss: 2593.38
[INFO 2017-06-26 18:34:39,301 main.py:47] epoch 370, training loss: 2308.45, average training loss: 2902.29, base loss: 2593.52
[INFO 2017-06-26 18:34:39,610 main.py:47] epoch 371, training loss: 2417.14, average training loss: 2900.99, base loss: 2594.29
[INFO 2017-06-26 18:34:39,919 main.py:47] epoch 372, training loss: 2395.77, average training loss: 2899.63, base loss: 2594.82
[INFO 2017-06-26 18:34:40,226 main.py:47] epoch 373, training loss: 2457.96, average training loss: 2898.45, base loss: 2595.82
[INFO 2017-06-26 18:34:40,534 main.py:47] epoch 374, training loss: 2134.63, average training loss: 2896.41, base loss: 2595.85
[INFO 2017-06-26 18:34:40,861 main.py:47] epoch 375, training loss: 2399.10, average training loss: 2895.09, base loss: 2596.59
[INFO 2017-06-26 18:34:41,169 main.py:47] epoch 376, training loss: 2089.48, average training loss: 2892.95, base loss: 2596.30
[INFO 2017-06-26 18:34:41,479 main.py:47] epoch 377, training loss: 2425.89, average training loss: 2891.72, base loss: 2597.08
[INFO 2017-06-26 18:34:41,786 main.py:47] epoch 378, training loss: 2674.15, average training loss: 2891.14, base loss: 2598.60
[INFO 2017-06-26 18:34:42,097 main.py:47] epoch 379, training loss: 2323.04, average training loss: 2889.65, base loss: 2599.10
[INFO 2017-06-26 18:34:42,404 main.py:47] epoch 380, training loss: 2377.19, average training loss: 2888.30, base loss: 2599.62
[INFO 2017-06-26 18:34:42,711 main.py:47] epoch 381, training loss: 2104.30, average training loss: 2886.25, base loss: 2599.65
[INFO 2017-06-26 18:34:43,021 main.py:47] epoch 382, training loss: 2535.87, average training loss: 2885.34, base loss: 2601.09
[INFO 2017-06-26 18:34:43,325 main.py:47] epoch 383, training loss: 2171.55, average training loss: 2883.48, base loss: 2600.99
[INFO 2017-06-26 18:34:43,630 main.py:47] epoch 384, training loss: 2150.37, average training loss: 2881.57, base loss: 2600.73
[INFO 2017-06-26 18:34:43,936 main.py:47] epoch 385, training loss: 2385.41, average training loss: 2880.29, base loss: 2601.46
[INFO 2017-06-26 18:34:44,244 main.py:47] epoch 386, training loss: 2416.54, average training loss: 2879.09, base loss: 2602.48
[INFO 2017-06-26 18:34:44,549 main.py:47] epoch 387, training loss: 2782.95, average training loss: 2878.84, base loss: 2604.34
[INFO 2017-06-26 18:34:44,855 main.py:47] epoch 388, training loss: 2519.62, average training loss: 2877.92, base loss: 2605.27
[INFO 2017-06-26 18:34:45,163 main.py:47] epoch 389, training loss: 2499.87, average training loss: 2876.95, base loss: 2606.37
[INFO 2017-06-26 18:34:45,480 main.py:47] epoch 390, training loss: 2412.75, average training loss: 2875.76, base loss: 2607.32
[INFO 2017-06-26 18:34:45,789 main.py:47] epoch 391, training loss: 2099.13, average training loss: 2873.78, base loss: 2606.60
[INFO 2017-06-26 18:34:46,093 main.py:47] epoch 392, training loss: 2037.07, average training loss: 2871.65, base loss: 2606.05
[INFO 2017-06-26 18:34:46,399 main.py:47] epoch 393, training loss: 1948.09, average training loss: 2869.31, base loss: 2605.50
[INFO 2017-06-26 18:34:46,710 main.py:47] epoch 394, training loss: 2166.30, average training loss: 2867.53, base loss: 2605.33
[INFO 2017-06-26 18:34:47,014 main.py:47] epoch 395, training loss: 2201.27, average training loss: 2865.85, base loss: 2605.07
[INFO 2017-06-26 18:34:47,318 main.py:47] epoch 396, training loss: 2495.72, average training loss: 2864.91, base loss: 2606.00
[INFO 2017-06-26 18:34:47,621 main.py:47] epoch 397, training loss: 2334.08, average training loss: 2863.58, base loss: 2606.44
[INFO 2017-06-26 18:34:47,929 main.py:47] epoch 398, training loss: 2061.00, average training loss: 2861.57, base loss: 2606.16
[INFO 2017-06-26 18:34:48,236 main.py:47] epoch 399, training loss: 2179.46, average training loss: 2859.86, base loss: 2605.95
[INFO 2017-06-26 18:34:48,236 main.py:49] epoch 399, testing
[INFO 2017-06-26 18:34:52,256 main.py:100] average testing loss: 2230.21, base loss: 2669.59
[INFO 2017-06-26 18:34:52,279 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:34:52,292 main.py:73] current best accuracy: 2230.21
[INFO 2017-06-26 18:34:52,542 main.py:47] epoch 400, training loss: 2410.51, average training loss: 2858.74, base loss: 2606.86
[INFO 2017-06-26 18:34:52,798 main.py:47] epoch 401, training loss: 1781.98, average training loss: 2856.06, base loss: 2605.74
[INFO 2017-06-26 18:34:53,056 main.py:47] epoch 402, training loss: 1964.73, average training loss: 2853.85, base loss: 2605.29
[INFO 2017-06-26 18:34:53,311 main.py:47] epoch 403, training loss: 1876.76, average training loss: 2851.43, base loss: 2604.35
[INFO 2017-06-26 18:34:53,565 main.py:47] epoch 404, training loss: 2299.46, average training loss: 2850.07, base loss: 2605.06
[INFO 2017-06-26 18:34:53,820 main.py:47] epoch 405, training loss: 2024.48, average training loss: 2848.04, base loss: 2604.64
[INFO 2017-06-26 18:34:54,075 main.py:47] epoch 406, training loss: 2231.11, average training loss: 2846.52, base loss: 2604.89
[INFO 2017-06-26 18:34:54,386 main.py:47] epoch 407, training loss: 2354.09, average training loss: 2845.31, base loss: 2605.77
[INFO 2017-06-26 18:34:54,687 main.py:47] epoch 408, training loss: 2092.55, average training loss: 2843.47, base loss: 2605.28
[INFO 2017-06-26 18:34:55,005 main.py:47] epoch 409, training loss: 2505.44, average training loss: 2842.65, base loss: 2606.08
[INFO 2017-06-26 18:34:55,335 main.py:47] epoch 410, training loss: 2663.96, average training loss: 2842.21, base loss: 2607.40
[INFO 2017-06-26 18:34:55,662 main.py:47] epoch 411, training loss: 2550.98, average training loss: 2841.51, base loss: 2608.33
[INFO 2017-06-26 18:34:56,013 main.py:47] epoch 412, training loss: 2261.88, average training loss: 2840.10, base loss: 2608.42
[INFO 2017-06-26 18:34:56,328 main.py:47] epoch 413, training loss: 2027.90, average training loss: 2838.14, base loss: 2607.66
[INFO 2017-06-26 18:34:56,626 main.py:47] epoch 414, training loss: 1902.41, average training loss: 2835.89, base loss: 2606.47
[INFO 2017-06-26 18:34:56,968 main.py:47] epoch 415, training loss: 2154.09, average training loss: 2834.25, base loss: 2606.38
[INFO 2017-06-26 18:34:57,361 main.py:47] epoch 416, training loss: 1981.04, average training loss: 2832.20, base loss: 2605.62
[INFO 2017-06-26 18:34:57,685 main.py:47] epoch 417, training loss: 1918.37, average training loss: 2830.02, base loss: 2604.60
[INFO 2017-06-26 18:34:58,003 main.py:47] epoch 418, training loss: 1852.57, average training loss: 2827.68, base loss: 2603.43
[INFO 2017-06-26 18:34:58,317 main.py:47] epoch 419, training loss: 2533.84, average training loss: 2826.98, base loss: 2604.39
[INFO 2017-06-26 18:34:58,626 main.py:47] epoch 420, training loss: 2253.09, average training loss: 2825.62, base loss: 2604.67
[INFO 2017-06-26 18:34:58,934 main.py:47] epoch 421, training loss: 2198.36, average training loss: 2824.13, base loss: 2604.39
[INFO 2017-06-26 18:34:59,241 main.py:47] epoch 422, training loss: 2476.50, average training loss: 2823.31, base loss: 2605.03
[INFO 2017-06-26 18:34:59,550 main.py:47] epoch 423, training loss: 2310.82, average training loss: 2822.10, base loss: 2605.25
[INFO 2017-06-26 18:34:59,861 main.py:47] epoch 424, training loss: 2158.91, average training loss: 2820.54, base loss: 2605.30
[INFO 2017-06-26 18:35:00,168 main.py:47] epoch 425, training loss: 2088.63, average training loss: 2818.83, base loss: 2605.14
[INFO 2017-06-26 18:35:00,477 main.py:47] epoch 426, training loss: 2217.98, average training loss: 2817.42, base loss: 2605.23
[INFO 2017-06-26 18:35:00,783 main.py:47] epoch 427, training loss: 2168.74, average training loss: 2815.90, base loss: 2605.17
[INFO 2017-06-26 18:35:01,088 main.py:47] epoch 428, training loss: 2405.88, average training loss: 2814.95, base loss: 2605.71
[INFO 2017-06-26 18:35:01,394 main.py:47] epoch 429, training loss: 2384.34, average training loss: 2813.95, base loss: 2606.39
[INFO 2017-06-26 18:35:01,700 main.py:47] epoch 430, training loss: 2187.77, average training loss: 2812.49, base loss: 2606.52
[INFO 2017-06-26 18:35:02,007 main.py:47] epoch 431, training loss: 2059.52, average training loss: 2810.75, base loss: 2606.37
[INFO 2017-06-26 18:35:02,314 main.py:47] epoch 432, training loss: 2278.06, average training loss: 2809.52, base loss: 2606.78
[INFO 2017-06-26 18:35:02,620 main.py:47] epoch 433, training loss: 2279.37, average training loss: 2808.30, base loss: 2607.24
[INFO 2017-06-26 18:35:02,927 main.py:47] epoch 434, training loss: 2165.77, average training loss: 2806.82, base loss: 2607.38
[INFO 2017-06-26 18:35:03,235 main.py:47] epoch 435, training loss: 1899.30, average training loss: 2804.74, base loss: 2606.77
[INFO 2017-06-26 18:35:03,544 main.py:47] epoch 436, training loss: 2145.00, average training loss: 2803.23, base loss: 2606.74
[INFO 2017-06-26 18:35:03,849 main.py:47] epoch 437, training loss: 2121.02, average training loss: 2801.67, base loss: 2606.45
[INFO 2017-06-26 18:35:04,157 main.py:47] epoch 438, training loss: 2195.75, average training loss: 2800.29, base loss: 2606.65
[INFO 2017-06-26 18:35:04,501 main.py:47] epoch 439, training loss: 2050.76, average training loss: 2798.59, base loss: 2606.31
[INFO 2017-06-26 18:35:04,893 main.py:47] epoch 440, training loss: 2046.15, average training loss: 2796.88, base loss: 2606.12
[INFO 2017-06-26 18:35:05,205 main.py:47] epoch 441, training loss: 1913.97, average training loss: 2794.88, base loss: 2605.31
[INFO 2017-06-26 18:35:05,518 main.py:47] epoch 442, training loss: 1961.33, average training loss: 2793.00, base loss: 2605.03
[INFO 2017-06-26 18:35:05,827 main.py:47] epoch 443, training loss: 2126.09, average training loss: 2791.50, base loss: 2604.76
[INFO 2017-06-26 18:35:06,149 main.py:47] epoch 444, training loss: 2440.76, average training loss: 2790.71, base loss: 2605.11
[INFO 2017-06-26 18:35:06,468 main.py:47] epoch 445, training loss: 2213.50, average training loss: 2789.42, base loss: 2605.14
[INFO 2017-06-26 18:35:06,790 main.py:47] epoch 446, training loss: 2156.97, average training loss: 2788.00, base loss: 2604.96
[INFO 2017-06-26 18:35:07,104 main.py:47] epoch 447, training loss: 2265.51, average training loss: 2786.84, base loss: 2605.32
[INFO 2017-06-26 18:35:07,425 main.py:47] epoch 448, training loss: 2301.78, average training loss: 2785.76, base loss: 2605.55
[INFO 2017-06-26 18:35:07,733 main.py:47] epoch 449, training loss: 2300.50, average training loss: 2784.68, base loss: 2605.89
[INFO 2017-06-26 18:35:08,038 main.py:47] epoch 450, training loss: 2593.79, average training loss: 2784.26, base loss: 2607.15
[INFO 2017-06-26 18:35:08,342 main.py:47] epoch 451, training loss: 1985.29, average training loss: 2782.49, base loss: 2606.52
[INFO 2017-06-26 18:35:08,649 main.py:47] epoch 452, training loss: 2519.00, average training loss: 2781.91, base loss: 2607.71
[INFO 2017-06-26 18:35:09,009 main.py:47] epoch 453, training loss: 2067.87, average training loss: 2780.33, base loss: 2607.36
[INFO 2017-06-26 18:35:09,364 main.py:47] epoch 454, training loss: 2400.87, average training loss: 2779.50, base loss: 2608.03
[INFO 2017-06-26 18:35:09,673 main.py:47] epoch 455, training loss: 1988.42, average training loss: 2777.76, base loss: 2607.85
[INFO 2017-06-26 18:35:10,067 main.py:47] epoch 456, training loss: 2191.35, average training loss: 2776.48, base loss: 2607.66
[INFO 2017-06-26 18:35:10,392 main.py:47] epoch 457, training loss: 2503.98, average training loss: 2775.89, base loss: 2608.75
[INFO 2017-06-26 18:35:10,703 main.py:47] epoch 458, training loss: 2477.03, average training loss: 2775.24, base loss: 2609.79
[INFO 2017-06-26 18:35:11,015 main.py:47] epoch 459, training loss: 2385.81, average training loss: 2774.39, base loss: 2610.51
[INFO 2017-06-26 18:35:11,379 main.py:47] epoch 460, training loss: 2043.40, average training loss: 2772.80, base loss: 2610.31
[INFO 2017-06-26 18:35:11,698 main.py:47] epoch 461, training loss: 2460.08, average training loss: 2772.13, base loss: 2610.83
[INFO 2017-06-26 18:35:12,017 main.py:47] epoch 462, training loss: 2776.82, average training loss: 2772.14, base loss: 2612.25
[INFO 2017-06-26 18:35:12,330 main.py:47] epoch 463, training loss: 2419.23, average training loss: 2771.38, base loss: 2612.84
[INFO 2017-06-26 18:35:12,691 main.py:47] epoch 464, training loss: 2104.03, average training loss: 2769.94, base loss: 2612.76
[INFO 2017-06-26 18:35:13,006 main.py:47] epoch 465, training loss: 2181.07, average training loss: 2768.68, base loss: 2612.62
[INFO 2017-06-26 18:35:13,319 main.py:47] epoch 466, training loss: 2205.96, average training loss: 2767.47, base loss: 2612.70
[INFO 2017-06-26 18:35:13,695 main.py:47] epoch 467, training loss: 2246.06, average training loss: 2766.36, base loss: 2613.07
[INFO 2017-06-26 18:35:14,016 main.py:47] epoch 468, training loss: 2447.88, average training loss: 2765.68, base loss: 2614.10
[INFO 2017-06-26 18:35:14,344 main.py:47] epoch 469, training loss: 2339.98, average training loss: 2764.77, base loss: 2614.61
[INFO 2017-06-26 18:35:14,721 main.py:47] epoch 470, training loss: 2006.76, average training loss: 2763.16, base loss: 2613.89
[INFO 2017-06-26 18:35:15,074 main.py:47] epoch 471, training loss: 1844.64, average training loss: 2761.22, base loss: 2612.99
[INFO 2017-06-26 18:35:15,471 main.py:47] epoch 472, training loss: 2392.86, average training loss: 2760.44, base loss: 2613.77
[INFO 2017-06-26 18:35:15,817 main.py:47] epoch 473, training loss: 2067.03, average training loss: 2758.98, base loss: 2613.64
[INFO 2017-06-26 18:35:16,141 main.py:47] epoch 474, training loss: 2417.38, average training loss: 2758.26, base loss: 2614.22
[INFO 2017-06-26 18:35:16,522 main.py:47] epoch 475, training loss: 2290.05, average training loss: 2757.27, base loss: 2614.52
[INFO 2017-06-26 18:35:16,848 main.py:47] epoch 476, training loss: 2032.93, average training loss: 2755.75, base loss: 2614.38
[INFO 2017-06-26 18:35:17,155 main.py:47] epoch 477, training loss: 2109.43, average training loss: 2754.40, base loss: 2614.22
[INFO 2017-06-26 18:35:17,477 main.py:47] epoch 478, training loss: 2039.82, average training loss: 2752.91, base loss: 2613.75
[INFO 2017-06-26 18:35:17,785 main.py:47] epoch 479, training loss: 2330.94, average training loss: 2752.03, base loss: 2614.16
[INFO 2017-06-26 18:35:18,093 main.py:47] epoch 480, training loss: 2469.11, average training loss: 2751.44, base loss: 2615.48
[INFO 2017-06-26 18:35:18,399 main.py:47] epoch 481, training loss: 2329.11, average training loss: 2750.57, base loss: 2615.49
[INFO 2017-06-26 18:35:18,708 main.py:47] epoch 482, training loss: 2369.48, average training loss: 2749.78, base loss: 2615.90
[INFO 2017-06-26 18:35:19,014 main.py:47] epoch 483, training loss: 1962.00, average training loss: 2748.15, base loss: 2615.11
[INFO 2017-06-26 18:35:19,397 main.py:47] epoch 484, training loss: 2020.78, average training loss: 2746.65, base loss: 2614.44
[INFO 2017-06-26 18:35:19,742 main.py:47] epoch 485, training loss: 1962.55, average training loss: 2745.04, base loss: 2614.06
[INFO 2017-06-26 18:35:20,059 main.py:47] epoch 486, training loss: 2196.75, average training loss: 2743.91, base loss: 2614.13
[INFO 2017-06-26 18:35:20,424 main.py:47] epoch 487, training loss: 1983.91, average training loss: 2742.35, base loss: 2613.54
[INFO 2017-06-26 18:35:20,821 main.py:47] epoch 488, training loss: 2383.88, average training loss: 2741.62, base loss: 2614.16
[INFO 2017-06-26 18:35:21,142 main.py:47] epoch 489, training loss: 2152.74, average training loss: 2740.42, base loss: 2613.93
[INFO 2017-06-26 18:35:21,450 main.py:47] epoch 490, training loss: 2735.95, average training loss: 2740.41, base loss: 2615.23
[INFO 2017-06-26 18:35:21,766 main.py:47] epoch 491, training loss: 2316.02, average training loss: 2739.55, base loss: 2615.30
[INFO 2017-06-26 18:35:22,074 main.py:47] epoch 492, training loss: 2221.56, average training loss: 2738.50, base loss: 2615.24
[INFO 2017-06-26 18:35:22,381 main.py:47] epoch 493, training loss: 2120.34, average training loss: 2737.25, base loss: 2614.88
[INFO 2017-06-26 18:35:22,688 main.py:47] epoch 494, training loss: 2629.55, average training loss: 2737.03, base loss: 2615.93
[INFO 2017-06-26 18:35:22,992 main.py:47] epoch 495, training loss: 2024.85, average training loss: 2735.59, base loss: 2615.66
[INFO 2017-06-26 18:35:23,299 main.py:47] epoch 496, training loss: 2270.90, average training loss: 2734.66, base loss: 2615.97
[INFO 2017-06-26 18:35:23,607 main.py:47] epoch 497, training loss: 2126.99, average training loss: 2733.44, base loss: 2616.03
[INFO 2017-06-26 18:35:23,915 main.py:47] epoch 498, training loss: 2060.59, average training loss: 2732.09, base loss: 2615.74
[INFO 2017-06-26 18:35:24,277 main.py:47] epoch 499, training loss: 2077.17, average training loss: 2730.78, base loss: 2615.45
[INFO 2017-06-26 18:35:24,278 main.py:49] epoch 499, testing
[INFO 2017-06-26 18:35:28,893 main.py:100] average testing loss: 2216.66, base loss: 2721.62
[INFO 2017-06-26 18:35:28,934 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:35:28,949 main.py:73] current best accuracy: 2216.66
[INFO 2017-06-26 18:35:29,224 main.py:47] epoch 500, training loss: 2573.99, average training loss: 2730.47, base loss: 2616.39
[INFO 2017-06-26 18:35:29,480 main.py:47] epoch 501, training loss: 2085.68, average training loss: 2729.18, base loss: 2616.12
[INFO 2017-06-26 18:35:29,750 main.py:47] epoch 502, training loss: 2567.92, average training loss: 2728.86, base loss: 2617.10
[INFO 2017-06-26 18:35:30,059 main.py:47] epoch 503, training loss: 2213.98, average training loss: 2727.84, base loss: 2617.39
[INFO 2017-06-26 18:35:30,386 main.py:47] epoch 504, training loss: 2132.51, average training loss: 2726.66, base loss: 2616.93
[INFO 2017-06-26 18:35:30,659 main.py:47] epoch 505, training loss: 2290.09, average training loss: 2725.80, base loss: 2617.43
[INFO 2017-06-26 18:35:30,938 main.py:47] epoch 506, training loss: 2686.54, average training loss: 2725.72, base loss: 2619.08
[INFO 2017-06-26 18:35:31,230 main.py:47] epoch 507, training loss: 2068.63, average training loss: 2724.43, base loss: 2618.72
[INFO 2017-06-26 18:35:31,541 main.py:47] epoch 508, training loss: 2417.78, average training loss: 2723.82, base loss: 2619.32
[INFO 2017-06-26 18:35:31,840 main.py:47] epoch 509, training loss: 2224.80, average training loss: 2722.85, base loss: 2619.25
[INFO 2017-06-26 18:35:32,158 main.py:47] epoch 510, training loss: 2157.09, average training loss: 2721.74, base loss: 2619.20
[INFO 2017-06-26 18:35:32,522 main.py:47] epoch 511, training loss: 2298.87, average training loss: 2720.91, base loss: 2619.40
[INFO 2017-06-26 18:35:32,834 main.py:47] epoch 512, training loss: 1815.71, average training loss: 2719.15, base loss: 2618.51
[INFO 2017-06-26 18:35:33,232 main.py:47] epoch 513, training loss: 2022.33, average training loss: 2717.79, base loss: 2618.26
[INFO 2017-06-26 18:35:33,607 main.py:47] epoch 514, training loss: 2389.14, average training loss: 2717.15, base loss: 2618.79
[INFO 2017-06-26 18:35:33,919 main.py:47] epoch 515, training loss: 2148.26, average training loss: 2716.05, base loss: 2618.78
[INFO 2017-06-26 18:35:34,230 main.py:47] epoch 516, training loss: 2201.94, average training loss: 2715.06, base loss: 2618.87
[INFO 2017-06-26 18:35:34,541 main.py:47] epoch 517, training loss: 2558.31, average training loss: 2714.75, base loss: 2619.96
[INFO 2017-06-26 18:35:34,850 main.py:47] epoch 518, training loss: 2122.01, average training loss: 2713.61, base loss: 2619.96
[INFO 2017-06-26 18:35:35,158 main.py:47] epoch 519, training loss: 2129.86, average training loss: 2712.49, base loss: 2619.91
[INFO 2017-06-26 18:35:35,465 main.py:47] epoch 520, training loss: 1948.44, average training loss: 2711.02, base loss: 2619.25
[INFO 2017-06-26 18:35:35,776 main.py:47] epoch 521, training loss: 2242.70, average training loss: 2710.13, base loss: 2619.27
[INFO 2017-06-26 18:35:36,140 main.py:47] epoch 522, training loss: 2693.38, average training loss: 2710.09, base loss: 2620.65
[INFO 2017-06-26 18:35:36,449 main.py:47] epoch 523, training loss: 2193.54, average training loss: 2709.11, base loss: 2620.74
[INFO 2017-06-26 18:35:36,758 main.py:47] epoch 524, training loss: 2137.54, average training loss: 2708.02, base loss: 2620.93
[INFO 2017-06-26 18:35:37,068 main.py:47] epoch 525, training loss: 2170.36, average training loss: 2707.00, base loss: 2621.06
[INFO 2017-06-26 18:35:37,377 main.py:47] epoch 526, training loss: 2159.90, average training loss: 2705.96, base loss: 2621.08
[INFO 2017-06-26 18:35:37,688 main.py:47] epoch 527, training loss: 2029.51, average training loss: 2704.68, base loss: 2620.61
[INFO 2017-06-26 18:35:37,998 main.py:47] epoch 528, training loss: 2282.63, average training loss: 2703.88, base loss: 2621.11
[INFO 2017-06-26 18:35:38,308 main.py:47] epoch 529, training loss: 2363.78, average training loss: 2703.24, base loss: 2621.78
[INFO 2017-06-26 18:35:38,620 main.py:47] epoch 530, training loss: 2196.56, average training loss: 2702.28, base loss: 2622.03
[INFO 2017-06-26 18:35:38,934 main.py:47] epoch 531, training loss: 1986.76, average training loss: 2700.94, base loss: 2621.71
[INFO 2017-06-26 18:35:39,246 main.py:47] epoch 532, training loss: 2404.33, average training loss: 2700.38, base loss: 2622.20
[INFO 2017-06-26 18:35:39,559 main.py:47] epoch 533, training loss: 2422.51, average training loss: 2699.86, base loss: 2622.94
[INFO 2017-06-26 18:35:39,883 main.py:47] epoch 534, training loss: 2041.29, average training loss: 2698.63, base loss: 2622.45
[INFO 2017-06-26 18:35:40,195 main.py:47] epoch 535, training loss: 2093.00, average training loss: 2697.50, base loss: 2622.03
[INFO 2017-06-26 18:35:40,504 main.py:47] epoch 536, training loss: 2021.74, average training loss: 2696.24, base loss: 2621.69
[INFO 2017-06-26 18:35:40,809 main.py:47] epoch 537, training loss: 2014.49, average training loss: 2694.98, base loss: 2621.58
[INFO 2017-06-26 18:35:41,117 main.py:47] epoch 538, training loss: 2344.00, average training loss: 2694.33, base loss: 2621.94
[INFO 2017-06-26 18:35:41,426 main.py:47] epoch 539, training loss: 2656.21, average training loss: 2694.25, base loss: 2622.96
[INFO 2017-06-26 18:35:41,734 main.py:47] epoch 540, training loss: 2301.69, average training loss: 2693.53, base loss: 2623.31
[INFO 2017-06-26 18:35:42,041 main.py:47] epoch 541, training loss: 2013.92, average training loss: 2692.28, base loss: 2622.93
[INFO 2017-06-26 18:35:42,349 main.py:47] epoch 542, training loss: 2285.48, average training loss: 2691.53, base loss: 2622.99
[INFO 2017-06-26 18:35:42,658 main.py:47] epoch 543, training loss: 2271.16, average training loss: 2690.75, base loss: 2623.06
[INFO 2017-06-26 18:35:42,983 main.py:47] epoch 544, training loss: 2217.15, average training loss: 2689.88, base loss: 2622.97
[INFO 2017-06-26 18:35:43,342 main.py:47] epoch 545, training loss: 1933.55, average training loss: 2688.50, base loss: 2622.37
[INFO 2017-06-26 18:35:43,700 main.py:47] epoch 546, training loss: 2063.34, average training loss: 2687.36, base loss: 2622.09
[INFO 2017-06-26 18:35:44,063 main.py:47] epoch 547, training loss: 1981.37, average training loss: 2686.07, base loss: 2621.58
[INFO 2017-06-26 18:35:44,427 main.py:47] epoch 548, training loss: 2042.25, average training loss: 2684.90, base loss: 2621.39
[INFO 2017-06-26 18:35:44,786 main.py:47] epoch 549, training loss: 2020.38, average training loss: 2683.69, base loss: 2621.05
[INFO 2017-06-26 18:35:45,110 main.py:47] epoch 550, training loss: 2017.70, average training loss: 2682.48, base loss: 2620.80
[INFO 2017-06-26 18:35:45,432 main.py:47] epoch 551, training loss: 2042.29, average training loss: 2681.32, base loss: 2620.51
[INFO 2017-06-26 18:35:45,800 main.py:47] epoch 552, training loss: 2129.24, average training loss: 2680.32, base loss: 2620.73
[INFO 2017-06-26 18:35:46,203 main.py:47] epoch 553, training loss: 1961.19, average training loss: 2679.02, base loss: 2620.02
[INFO 2017-06-26 18:35:46,532 main.py:47] epoch 554, training loss: 2499.39, average training loss: 2678.70, base loss: 2621.01
[INFO 2017-06-26 18:35:46,845 main.py:47] epoch 555, training loss: 1886.16, average training loss: 2677.27, base loss: 2620.38
[INFO 2017-06-26 18:35:47,151 main.py:47] epoch 556, training loss: 2140.88, average training loss: 2676.31, base loss: 2620.55
[INFO 2017-06-26 18:35:47,457 main.py:47] epoch 557, training loss: 2266.24, average training loss: 2675.57, base loss: 2620.83
[INFO 2017-06-26 18:35:47,764 main.py:47] epoch 558, training loss: 2247.06, average training loss: 2674.81, base loss: 2621.12
[INFO 2017-06-26 18:35:48,072 main.py:47] epoch 559, training loss: 1958.53, average training loss: 2673.53, base loss: 2620.48
[INFO 2017-06-26 18:35:48,379 main.py:47] epoch 560, training loss: 2206.10, average training loss: 2672.70, base loss: 2620.64
[INFO 2017-06-26 18:35:48,686 main.py:47] epoch 561, training loss: 1915.23, average training loss: 2671.35, base loss: 2620.07
[INFO 2017-06-26 18:35:48,995 main.py:47] epoch 562, training loss: 1992.43, average training loss: 2670.14, base loss: 2619.78
[INFO 2017-06-26 18:35:49,304 main.py:47] epoch 563, training loss: 1964.13, average training loss: 2668.89, base loss: 2619.30
[INFO 2017-06-26 18:35:49,611 main.py:47] epoch 564, training loss: 2038.40, average training loss: 2667.77, base loss: 2619.01
[INFO 2017-06-26 18:35:49,919 main.py:47] epoch 565, training loss: 2180.74, average training loss: 2666.91, base loss: 2619.00
[INFO 2017-06-26 18:35:50,222 main.py:47] epoch 566, training loss: 2259.73, average training loss: 2666.20, base loss: 2619.29
[INFO 2017-06-26 18:35:50,545 main.py:47] epoch 567, training loss: 2197.79, average training loss: 2665.37, base loss: 2619.32
[INFO 2017-06-26 18:35:50,854 main.py:47] epoch 568, training loss: 2078.69, average training loss: 2664.34, base loss: 2619.08
[INFO 2017-06-26 18:35:51,165 main.py:47] epoch 569, training loss: 2037.04, average training loss: 2663.24, base loss: 2618.56
[INFO 2017-06-26 18:35:51,472 main.py:47] epoch 570, training loss: 2520.00, average training loss: 2662.99, base loss: 2619.27
[INFO 2017-06-26 18:35:51,779 main.py:47] epoch 571, training loss: 2334.73, average training loss: 2662.42, base loss: 2619.62
[INFO 2017-06-26 18:35:52,088 main.py:47] epoch 572, training loss: 2035.04, average training loss: 2661.32, base loss: 2618.99
[INFO 2017-06-26 18:35:52,392 main.py:47] epoch 573, training loss: 2214.56, average training loss: 2660.54, base loss: 2619.13
[INFO 2017-06-26 18:35:52,699 main.py:47] epoch 574, training loss: 1937.31, average training loss: 2659.28, base loss: 2618.56
[INFO 2017-06-26 18:35:53,008 main.py:47] epoch 575, training loss: 2076.71, average training loss: 2658.27, base loss: 2618.35
[INFO 2017-06-26 18:35:53,315 main.py:47] epoch 576, training loss: 2505.39, average training loss: 2658.01, base loss: 2619.07
[INFO 2017-06-26 18:35:53,623 main.py:47] epoch 577, training loss: 1909.16, average training loss: 2656.71, base loss: 2618.52
[INFO 2017-06-26 18:35:53,928 main.py:47] epoch 578, training loss: 2100.28, average training loss: 2655.75, base loss: 2618.31
[INFO 2017-06-26 18:35:54,235 main.py:47] epoch 579, training loss: 2876.41, average training loss: 2656.13, base loss: 2619.76
[INFO 2017-06-26 18:35:54,542 main.py:47] epoch 580, training loss: 2317.24, average training loss: 2655.55, base loss: 2620.30
[INFO 2017-06-26 18:35:54,850 main.py:47] epoch 581, training loss: 2382.84, average training loss: 2655.08, base loss: 2620.95
[INFO 2017-06-26 18:35:55,159 main.py:47] epoch 582, training loss: 2207.19, average training loss: 2654.31, base loss: 2621.31
[INFO 2017-06-26 18:35:55,468 main.py:47] epoch 583, training loss: 2453.12, average training loss: 2653.97, base loss: 2621.91
[INFO 2017-06-26 18:35:55,777 main.py:47] epoch 584, training loss: 2118.55, average training loss: 2653.05, base loss: 2621.61
[INFO 2017-06-26 18:35:56,086 main.py:47] epoch 585, training loss: 2029.52, average training loss: 2651.99, base loss: 2621.34
[INFO 2017-06-26 18:35:56,391 main.py:47] epoch 586, training loss: 1931.81, average training loss: 2650.76, base loss: 2620.74
[INFO 2017-06-26 18:35:56,776 main.py:47] epoch 587, training loss: 2059.29, average training loss: 2649.75, base loss: 2620.68
[INFO 2017-06-26 18:35:57,101 main.py:47] epoch 588, training loss: 2125.82, average training loss: 2648.87, base loss: 2620.76
[INFO 2017-06-26 18:35:57,412 main.py:47] epoch 589, training loss: 2221.47, average training loss: 2648.14, base loss: 2620.88
[INFO 2017-06-26 18:35:57,729 main.py:47] epoch 590, training loss: 2051.33, average training loss: 2647.13, base loss: 2620.51
[INFO 2017-06-26 18:35:58,037 main.py:47] epoch 591, training loss: 2379.52, average training loss: 2646.68, base loss: 2620.96
[INFO 2017-06-26 18:35:58,345 main.py:47] epoch 592, training loss: 2153.78, average training loss: 2645.85, base loss: 2621.04
[INFO 2017-06-26 18:35:58,712 main.py:47] epoch 593, training loss: 1679.58, average training loss: 2644.22, base loss: 2619.88
[INFO 2017-06-26 18:35:59,046 main.py:47] epoch 594, training loss: 2194.44, average training loss: 2643.47, base loss: 2619.94
[INFO 2017-06-26 18:35:59,360 main.py:47] epoch 595, training loss: 2373.50, average training loss: 2643.01, base loss: 2620.38
[INFO 2017-06-26 18:35:59,672 main.py:47] epoch 596, training loss: 2016.64, average training loss: 2641.96, base loss: 2620.26
[INFO 2017-06-26 18:35:59,978 main.py:47] epoch 597, training loss: 1986.54, average training loss: 2640.87, base loss: 2619.77
[INFO 2017-06-26 18:36:00,283 main.py:47] epoch 598, training loss: 2009.54, average training loss: 2639.81, base loss: 2619.53
[INFO 2017-06-26 18:36:00,660 main.py:47] epoch 599, training loss: 2015.40, average training loss: 2638.77, base loss: 2619.35
[INFO 2017-06-26 18:36:00,660 main.py:49] epoch 599, testing
[INFO 2017-06-26 18:36:05,009 main.py:100] average testing loss: 2201.75, base loss: 2679.57
[INFO 2017-06-26 18:36:05,033 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:36:05,047 main.py:73] current best accuracy: 2201.75
[INFO 2017-06-26 18:36:05,352 main.py:47] epoch 600, training loss: 2073.06, average training loss: 2637.83, base loss: 2619.24
[INFO 2017-06-26 18:36:05,660 main.py:47] epoch 601, training loss: 2105.37, average training loss: 2636.95, base loss: 2619.20
[INFO 2017-06-26 18:36:06,029 main.py:47] epoch 602, training loss: 2060.78, average training loss: 2635.99, base loss: 2619.29
[INFO 2017-06-26 18:36:06,366 main.py:47] epoch 603, training loss: 2200.98, average training loss: 2635.27, base loss: 2619.46
[INFO 2017-06-26 18:36:06,675 main.py:47] epoch 604, training loss: 2115.00, average training loss: 2634.41, base loss: 2619.53
[INFO 2017-06-26 18:36:07,061 main.py:47] epoch 605, training loss: 2139.96, average training loss: 2633.59, base loss: 2619.54
[INFO 2017-06-26 18:36:07,461 main.py:47] epoch 606, training loss: 2203.47, average training loss: 2632.89, base loss: 2619.51
[INFO 2017-06-26 18:36:07,770 main.py:47] epoch 607, training loss: 2357.36, average training loss: 2632.43, base loss: 2620.02
[INFO 2017-06-26 18:36:08,108 main.py:47] epoch 608, training loss: 2524.07, average training loss: 2632.26, base loss: 2620.81
[INFO 2017-06-26 18:36:08,434 main.py:47] epoch 609, training loss: 2105.15, average training loss: 2631.39, base loss: 2620.79
[INFO 2017-06-26 18:36:08,752 main.py:47] epoch 610, training loss: 1971.34, average training loss: 2630.31, base loss: 2620.48
[INFO 2017-06-26 18:36:09,132 main.py:47] epoch 611, training loss: 2088.09, average training loss: 2629.42, base loss: 2620.31
[INFO 2017-06-26 18:36:09,498 main.py:47] epoch 612, training loss: 2315.47, average training loss: 2628.91, base loss: 2620.87
[INFO 2017-06-26 18:36:09,812 main.py:47] epoch 613, training loss: 1873.27, average training loss: 2627.68, base loss: 2620.43
[INFO 2017-06-26 18:36:10,122 main.py:47] epoch 614, training loss: 2043.59, average training loss: 2626.73, base loss: 2620.45
[INFO 2017-06-26 18:36:10,429 main.py:47] epoch 615, training loss: 2185.89, average training loss: 2626.02, base loss: 2620.57
[INFO 2017-06-26 18:36:10,777 main.py:47] epoch 616, training loss: 2232.85, average training loss: 2625.38, base loss: 2620.98
[INFO 2017-06-26 18:36:11,121 main.py:47] epoch 617, training loss: 2112.83, average training loss: 2624.55, base loss: 2620.75
[INFO 2017-06-26 18:36:11,443 main.py:47] epoch 618, training loss: 2019.79, average training loss: 2623.57, base loss: 2620.48
[INFO 2017-06-26 18:36:11,752 main.py:47] epoch 619, training loss: 1837.28, average training loss: 2622.30, base loss: 2619.68
[INFO 2017-06-26 18:36:12,063 main.py:47] epoch 620, training loss: 2213.15, average training loss: 2621.65, base loss: 2619.81
[INFO 2017-06-26 18:36:12,419 main.py:47] epoch 621, training loss: 2053.81, average training loss: 2620.73, base loss: 2619.58
[INFO 2017-06-26 18:36:12,759 main.py:47] epoch 622, training loss: 1694.30, average training loss: 2619.25, base loss: 2618.52
[INFO 2017-06-26 18:36:13,068 main.py:47] epoch 623, training loss: 2373.56, average training loss: 2618.85, base loss: 2618.98
[INFO 2017-06-26 18:36:13,384 main.py:47] epoch 624, training loss: 2058.18, average training loss: 2617.96, base loss: 2618.81
[INFO 2017-06-26 18:36:13,695 main.py:47] epoch 625, training loss: 1909.27, average training loss: 2616.82, base loss: 2618.47
[INFO 2017-06-26 18:36:14,002 main.py:47] epoch 626, training loss: 2237.84, average training loss: 2616.22, base loss: 2618.45
[INFO 2017-06-26 18:36:14,398 main.py:47] epoch 627, training loss: 1679.66, average training loss: 2614.73, base loss: 2617.35
[INFO 2017-06-26 18:36:14,727 main.py:47] epoch 628, training loss: 2034.17, average training loss: 2613.80, base loss: 2617.52
[INFO 2017-06-26 18:36:15,036 main.py:47] epoch 629, training loss: 2070.27, average training loss: 2612.94, base loss: 2617.41
[INFO 2017-06-26 18:36:15,347 main.py:47] epoch 630, training loss: 1997.39, average training loss: 2611.97, base loss: 2616.99
[INFO 2017-06-26 18:36:15,652 main.py:47] epoch 631, training loss: 2350.12, average training loss: 2611.55, base loss: 2617.50
[INFO 2017-06-26 18:36:16,019 main.py:47] epoch 632, training loss: 2165.77, average training loss: 2610.85, base loss: 2617.64
[INFO 2017-06-26 18:36:16,363 main.py:47] epoch 633, training loss: 1946.85, average training loss: 2609.80, base loss: 2617.08
[INFO 2017-06-26 18:36:16,675 main.py:47] epoch 634, training loss: 2317.22, average training loss: 2609.34, base loss: 2617.18
[INFO 2017-06-26 18:36:17,261 main.py:47] epoch 635, training loss: 2748.58, average training loss: 2609.56, base loss: 2618.42
[INFO 2017-06-26 18:36:17,583 main.py:47] epoch 636, training loss: 1962.81, average training loss: 2608.54, base loss: 2617.96
[INFO 2017-06-26 18:36:17,887 main.py:47] epoch 637, training loss: 2198.24, average training loss: 2607.90, base loss: 2618.09
[INFO 2017-06-26 18:36:18,195 main.py:47] epoch 638, training loss: 2120.90, average training loss: 2607.14, base loss: 2618.11
[INFO 2017-06-26 18:36:18,502 main.py:47] epoch 639, training loss: 2138.04, average training loss: 2606.40, base loss: 2618.26
[INFO 2017-06-26 18:36:18,809 main.py:47] epoch 640, training loss: 1834.73, average training loss: 2605.20, base loss: 2617.61
[INFO 2017-06-26 18:36:19,117 main.py:47] epoch 641, training loss: 2124.14, average training loss: 2604.45, base loss: 2617.84
[INFO 2017-06-26 18:36:19,435 main.py:47] epoch 642, training loss: 2394.94, average training loss: 2604.13, base loss: 2618.35
[INFO 2017-06-26 18:36:19,750 main.py:47] epoch 643, training loss: 2030.95, average training loss: 2603.24, base loss: 2618.05
[INFO 2017-06-26 18:36:20,067 main.py:47] epoch 644, training loss: 2119.51, average training loss: 2602.49, base loss: 2618.00
[INFO 2017-06-26 18:36:20,385 main.py:47] epoch 645, training loss: 2175.48, average training loss: 2601.82, base loss: 2618.05
[INFO 2017-06-26 18:36:20,695 main.py:47] epoch 646, training loss: 1839.68, average training loss: 2600.65, base loss: 2617.58
[INFO 2017-06-26 18:36:21,000 main.py:47] epoch 647, training loss: 2332.83, average training loss: 2600.23, base loss: 2618.07
[INFO 2017-06-26 18:36:21,309 main.py:47] epoch 648, training loss: 2010.51, average training loss: 2599.32, base loss: 2618.06
[INFO 2017-06-26 18:36:21,620 main.py:47] epoch 649, training loss: 1781.00, average training loss: 2598.07, base loss: 2617.50
[INFO 2017-06-26 18:36:21,926 main.py:47] epoch 650, training loss: 1883.45, average training loss: 2596.97, base loss: 2616.78
[INFO 2017-06-26 18:36:22,235 main.py:47] epoch 651, training loss: 2405.97, average training loss: 2596.68, base loss: 2617.25
[INFO 2017-06-26 18:36:22,552 main.py:47] epoch 652, training loss: 2272.67, average training loss: 2596.18, base loss: 2617.63
[INFO 2017-06-26 18:36:22,875 main.py:47] epoch 653, training loss: 2495.01, average training loss: 2596.02, base loss: 2618.25
[INFO 2017-06-26 18:36:23,186 main.py:47] epoch 654, training loss: 2821.53, average training loss: 2596.37, base loss: 2619.37
[INFO 2017-06-26 18:36:23,504 main.py:47] epoch 655, training loss: 2174.97, average training loss: 2595.73, base loss: 2619.43
[INFO 2017-06-26 18:36:23,817 main.py:47] epoch 656, training loss: 1818.98, average training loss: 2594.54, base loss: 2618.75
[INFO 2017-06-26 18:36:24,136 main.py:47] epoch 657, training loss: 2153.23, average training loss: 2593.87, base loss: 2618.72
[INFO 2017-06-26 18:36:24,446 main.py:47] epoch 658, training loss: 2091.16, average training loss: 2593.11, base loss: 2618.47
[INFO 2017-06-26 18:36:24,755 main.py:47] epoch 659, training loss: 2181.69, average training loss: 2592.49, base loss: 2618.59
[INFO 2017-06-26 18:36:25,064 main.py:47] epoch 660, training loss: 2436.74, average training loss: 2592.25, base loss: 2619.03
[INFO 2017-06-26 18:36:25,375 main.py:47] epoch 661, training loss: 2772.85, average training loss: 2592.52, base loss: 2620.38
[INFO 2017-06-26 18:36:25,685 main.py:47] epoch 662, training loss: 2029.86, average training loss: 2591.68, base loss: 2620.23
[INFO 2017-06-26 18:36:25,993 main.py:47] epoch 663, training loss: 2054.80, average training loss: 2590.87, base loss: 2620.06
[INFO 2017-06-26 18:36:26,302 main.py:47] epoch 664, training loss: 2014.28, average training loss: 2590.00, base loss: 2619.77
[INFO 2017-06-26 18:36:26,613 main.py:47] epoch 665, training loss: 2245.44, average training loss: 2589.48, base loss: 2619.88
[INFO 2017-06-26 18:36:26,923 main.py:47] epoch 666, training loss: 2159.48, average training loss: 2588.84, base loss: 2619.83
[INFO 2017-06-26 18:36:27,287 main.py:47] epoch 667, training loss: 1872.11, average training loss: 2587.77, base loss: 2619.45
[INFO 2017-06-26 18:36:27,665 main.py:47] epoch 668, training loss: 2737.79, average training loss: 2587.99, base loss: 2620.50
[INFO 2017-06-26 18:36:28,025 main.py:47] epoch 669, training loss: 2301.98, average training loss: 2587.56, base loss: 2620.73
[INFO 2017-06-26 18:36:28,380 main.py:47] epoch 670, training loss: 2179.58, average training loss: 2586.95, base loss: 2620.85
[INFO 2017-06-26 18:36:28,744 main.py:47] epoch 671, training loss: 2135.55, average training loss: 2586.28, base loss: 2620.83
[INFO 2017-06-26 18:36:29,082 main.py:47] epoch 672, training loss: 2099.88, average training loss: 2585.56, base loss: 2620.63
[INFO 2017-06-26 18:36:29,409 main.py:47] epoch 673, training loss: 2179.17, average training loss: 2584.96, base loss: 2620.78
[INFO 2017-06-26 18:36:29,776 main.py:47] epoch 674, training loss: 2241.44, average training loss: 2584.45, base loss: 2620.95
[INFO 2017-06-26 18:36:30,175 main.py:47] epoch 675, training loss: 2099.93, average training loss: 2583.73, base loss: 2620.93
[INFO 2017-06-26 18:36:30,504 main.py:47] epoch 676, training loss: 2322.08, average training loss: 2583.34, base loss: 2621.25
[INFO 2017-06-26 18:36:30,823 main.py:47] epoch 677, training loss: 2170.35, average training loss: 2582.74, base loss: 2621.12
[INFO 2017-06-26 18:36:31,132 main.py:47] epoch 678, training loss: 2183.58, average training loss: 2582.15, base loss: 2621.19
[INFO 2017-06-26 18:36:31,439 main.py:47] epoch 679, training loss: 2118.48, average training loss: 2581.47, base loss: 2621.32
[INFO 2017-06-26 18:36:31,748 main.py:47] epoch 680, training loss: 2065.06, average training loss: 2580.71, base loss: 2621.34
[INFO 2017-06-26 18:36:32,056 main.py:47] epoch 681, training loss: 1879.65, average training loss: 2579.68, base loss: 2620.75
[INFO 2017-06-26 18:36:32,365 main.py:47] epoch 682, training loss: 2118.48, average training loss: 2579.00, base loss: 2620.78
[INFO 2017-06-26 18:36:32,673 main.py:47] epoch 683, training loss: 1894.34, average training loss: 2578.00, base loss: 2620.14
[INFO 2017-06-26 18:36:32,995 main.py:47] epoch 684, training loss: 1878.22, average training loss: 2576.98, base loss: 2619.77
[INFO 2017-06-26 18:36:33,308 main.py:47] epoch 685, training loss: 2362.08, average training loss: 2576.67, base loss: 2620.31
[INFO 2017-06-26 18:36:33,616 main.py:47] epoch 686, training loss: 2162.65, average training loss: 2576.07, base loss: 2620.50
[INFO 2017-06-26 18:36:33,924 main.py:47] epoch 687, training loss: 2094.01, average training loss: 2575.37, base loss: 2620.45
[INFO 2017-06-26 18:36:34,228 main.py:47] epoch 688, training loss: 1749.03, average training loss: 2574.17, base loss: 2619.66
[INFO 2017-06-26 18:36:34,535 main.py:47] epoch 689, training loss: 2129.87, average training loss: 2573.52, base loss: 2619.59
[INFO 2017-06-26 18:36:34,844 main.py:47] epoch 690, training loss: 2372.46, average training loss: 2573.23, base loss: 2619.93
[INFO 2017-06-26 18:36:35,151 main.py:47] epoch 691, training loss: 1993.91, average training loss: 2572.39, base loss: 2619.52
[INFO 2017-06-26 18:36:35,456 main.py:47] epoch 692, training loss: 1916.59, average training loss: 2571.45, base loss: 2619.33
[INFO 2017-06-26 18:36:35,763 main.py:47] epoch 693, training loss: 1847.10, average training loss: 2570.40, base loss: 2618.79
[INFO 2017-06-26 18:36:36,068 main.py:47] epoch 694, training loss: 2219.89, average training loss: 2569.90, base loss: 2619.06
[INFO 2017-06-26 18:36:36,372 main.py:47] epoch 695, training loss: 1883.70, average training loss: 2568.91, base loss: 2618.58
[INFO 2017-06-26 18:36:36,682 main.py:47] epoch 696, training loss: 2050.21, average training loss: 2568.17, base loss: 2618.68
[INFO 2017-06-26 18:36:36,987 main.py:47] epoch 697, training loss: 2455.91, average training loss: 2568.01, base loss: 2619.30
[INFO 2017-06-26 18:36:37,293 main.py:47] epoch 698, training loss: 2194.35, average training loss: 2567.47, base loss: 2619.34
[INFO 2017-06-26 18:36:37,604 main.py:47] epoch 699, training loss: 1840.35, average training loss: 2566.44, base loss: 2618.65
[INFO 2017-06-26 18:36:37,604 main.py:49] epoch 699, testing
[INFO 2017-06-26 18:36:41,679 main.py:100] average testing loss: 2111.90, base loss: 2649.06
[INFO 2017-06-26 18:36:41,702 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:36:41,716 main.py:73] current best accuracy: 2111.90
[INFO 2017-06-26 18:36:42,022 main.py:47] epoch 700, training loss: 2480.10, average training loss: 2566.31, base loss: 2619.25
[INFO 2017-06-26 18:36:42,390 main.py:47] epoch 701, training loss: 2046.84, average training loss: 2565.57, base loss: 2619.32
[INFO 2017-06-26 18:36:42,721 main.py:47] epoch 702, training loss: 2155.21, average training loss: 2564.99, base loss: 2619.61
[INFO 2017-06-26 18:36:43,037 main.py:47] epoch 703, training loss: 2018.68, average training loss: 2564.21, base loss: 2619.42
[INFO 2017-06-26 18:36:43,347 main.py:47] epoch 704, training loss: 2029.79, average training loss: 2563.45, base loss: 2619.27
[INFO 2017-06-26 18:36:43,655 main.py:47] epoch 705, training loss: 1904.58, average training loss: 2562.52, base loss: 2619.00
[INFO 2017-06-26 18:36:43,961 main.py:47] epoch 706, training loss: 2154.19, average training loss: 2561.94, base loss: 2619.18
[INFO 2017-06-26 18:36:44,267 main.py:47] epoch 707, training loss: 2024.68, average training loss: 2561.18, base loss: 2618.95
[INFO 2017-06-26 18:36:44,572 main.py:47] epoch 708, training loss: 2303.72, average training loss: 2560.82, base loss: 2619.38
[INFO 2017-06-26 18:36:44,882 main.py:47] epoch 709, training loss: 2181.18, average training loss: 2560.29, base loss: 2619.68
[INFO 2017-06-26 18:36:45,189 main.py:47] epoch 710, training loss: 1882.40, average training loss: 2559.33, base loss: 2619.32
[INFO 2017-06-26 18:36:45,498 main.py:47] epoch 711, training loss: 2490.26, average training loss: 2559.24, base loss: 2620.07
[INFO 2017-06-26 18:36:45,805 main.py:47] epoch 712, training loss: 1946.18, average training loss: 2558.38, base loss: 2619.71
[INFO 2017-06-26 18:36:46,112 main.py:47] epoch 713, training loss: 2060.67, average training loss: 2557.68, base loss: 2619.77
[INFO 2017-06-26 18:36:46,420 main.py:47] epoch 714, training loss: 2096.64, average training loss: 2557.03, base loss: 2619.83
[INFO 2017-06-26 18:36:46,726 main.py:47] epoch 715, training loss: 1959.43, average training loss: 2556.20, base loss: 2619.57
[INFO 2017-06-26 18:36:47,039 main.py:47] epoch 716, training loss: 1793.06, average training loss: 2555.14, base loss: 2619.13
[INFO 2017-06-26 18:36:47,378 main.py:47] epoch 717, training loss: 2271.71, average training loss: 2554.74, base loss: 2619.54
[INFO 2017-06-26 18:36:47,693 main.py:47] epoch 718, training loss: 2181.71, average training loss: 2554.22, base loss: 2619.49
[INFO 2017-06-26 18:36:48,002 main.py:47] epoch 719, training loss: 2070.95, average training loss: 2553.55, base loss: 2619.36
[INFO 2017-06-26 18:36:48,311 main.py:47] epoch 720, training loss: 2017.77, average training loss: 2552.81, base loss: 2619.10
[INFO 2017-06-26 18:36:48,616 main.py:47] epoch 721, training loss: 2365.77, average training loss: 2552.55, base loss: 2619.66
[INFO 2017-06-26 18:36:48,922 main.py:47] epoch 722, training loss: 1991.41, average training loss: 2551.77, base loss: 2619.37
[INFO 2017-06-26 18:36:49,230 main.py:47] epoch 723, training loss: 2329.94, average training loss: 2551.47, base loss: 2619.61
[INFO 2017-06-26 18:36:49,536 main.py:47] epoch 724, training loss: 2169.85, average training loss: 2550.94, base loss: 2619.66
[INFO 2017-06-26 18:36:49,839 main.py:47] epoch 725, training loss: 2080.06, average training loss: 2550.29, base loss: 2619.64
[INFO 2017-06-26 18:36:50,147 main.py:47] epoch 726, training loss: 2227.10, average training loss: 2549.85, base loss: 2619.83
[INFO 2017-06-26 18:36:50,454 main.py:47] epoch 727, training loss: 2060.73, average training loss: 2549.17, base loss: 2619.76
[INFO 2017-06-26 18:36:50,761 main.py:47] epoch 728, training loss: 2046.06, average training loss: 2548.48, base loss: 2619.65
[INFO 2017-06-26 18:36:51,068 main.py:47] epoch 729, training loss: 1899.10, average training loss: 2547.60, base loss: 2619.36
[INFO 2017-06-26 18:36:51,371 main.py:47] epoch 730, training loss: 2309.82, average training loss: 2547.27, base loss: 2619.74
[INFO 2017-06-26 18:36:51,681 main.py:47] epoch 731, training loss: 1951.83, average training loss: 2546.46, base loss: 2619.39
[INFO 2017-06-26 18:36:51,987 main.py:47] epoch 732, training loss: 2159.53, average training loss: 2545.93, base loss: 2619.36
[INFO 2017-06-26 18:36:52,292 main.py:47] epoch 733, training loss: 2034.01, average training loss: 2545.23, base loss: 2619.09
[INFO 2017-06-26 18:36:52,600 main.py:47] epoch 734, training loss: 2531.88, average training loss: 2545.21, base loss: 2619.96
[INFO 2017-06-26 18:36:52,907 main.py:47] epoch 735, training loss: 2231.24, average training loss: 2544.79, base loss: 2620.50
[INFO 2017-06-26 18:36:53,214 main.py:47] epoch 736, training loss: 2278.86, average training loss: 2544.43, base loss: 2620.80
[INFO 2017-06-26 18:36:53,522 main.py:47] epoch 737, training loss: 2209.19, average training loss: 2543.97, base loss: 2620.85
[INFO 2017-06-26 18:36:53,829 main.py:47] epoch 738, training loss: 2072.34, average training loss: 2543.33, base loss: 2620.39
[INFO 2017-06-26 18:36:54,136 main.py:47] epoch 739, training loss: 2103.76, average training loss: 2542.74, base loss: 2620.27
[INFO 2017-06-26 18:36:54,441 main.py:47] epoch 740, training loss: 2020.79, average training loss: 2542.03, base loss: 2620.30
[INFO 2017-06-26 18:36:54,742 main.py:47] epoch 741, training loss: 2027.63, average training loss: 2541.34, base loss: 2620.25
[INFO 2017-06-26 18:36:55,046 main.py:47] epoch 742, training loss: 1875.91, average training loss: 2540.45, base loss: 2619.89
[INFO 2017-06-26 18:36:55,352 main.py:47] epoch 743, training loss: 2529.66, average training loss: 2540.43, base loss: 2620.62
[INFO 2017-06-26 18:36:55,659 main.py:47] epoch 744, training loss: 2194.84, average training loss: 2539.97, base loss: 2620.54
[INFO 2017-06-26 18:36:55,964 main.py:47] epoch 745, training loss: 1960.09, average training loss: 2539.19, base loss: 2620.25
[INFO 2017-06-26 18:36:56,271 main.py:47] epoch 746, training loss: 1942.95, average training loss: 2538.39, base loss: 2620.17
[INFO 2017-06-26 18:36:56,578 main.py:47] epoch 747, training loss: 1955.07, average training loss: 2537.61, base loss: 2620.05
[INFO 2017-06-26 18:36:56,881 main.py:47] epoch 748, training loss: 2126.64, average training loss: 2537.06, base loss: 2620.08
[INFO 2017-06-26 18:36:57,186 main.py:47] epoch 749, training loss: 1896.38, average training loss: 2536.21, base loss: 2619.76
[INFO 2017-06-26 18:36:57,494 main.py:47] epoch 750, training loss: 1947.55, average training loss: 2535.43, base loss: 2619.31
[INFO 2017-06-26 18:36:57,802 main.py:47] epoch 751, training loss: 1942.57, average training loss: 2534.64, base loss: 2619.10
[INFO 2017-06-26 18:36:58,109 main.py:47] epoch 752, training loss: 2233.52, average training loss: 2534.24, base loss: 2619.22
[INFO 2017-06-26 18:36:58,418 main.py:47] epoch 753, training loss: 1797.32, average training loss: 2533.26, base loss: 2618.63
[INFO 2017-06-26 18:36:58,726 main.py:47] epoch 754, training loss: 2175.17, average training loss: 2532.79, base loss: 2618.44
[INFO 2017-06-26 18:36:59,033 main.py:47] epoch 755, training loss: 1863.26, average training loss: 2531.90, base loss: 2617.92
[INFO 2017-06-26 18:36:59,339 main.py:47] epoch 756, training loss: 2053.56, average training loss: 2531.27, base loss: 2617.65
[INFO 2017-06-26 18:36:59,642 main.py:47] epoch 757, training loss: 1799.75, average training loss: 2530.30, base loss: 2617.01
[INFO 2017-06-26 18:36:59,948 main.py:47] epoch 758, training loss: 2105.93, average training loss: 2529.74, base loss: 2616.85
[INFO 2017-06-26 18:37:00,255 main.py:47] epoch 759, training loss: 2015.36, average training loss: 2529.07, base loss: 2616.62
[INFO 2017-06-26 18:37:00,560 main.py:47] epoch 760, training loss: 1987.60, average training loss: 2528.36, base loss: 2616.33
[INFO 2017-06-26 18:37:00,869 main.py:47] epoch 761, training loss: 1904.43, average training loss: 2527.54, base loss: 2615.88
[INFO 2017-06-26 18:37:01,177 main.py:47] epoch 762, training loss: 1861.64, average training loss: 2526.66, base loss: 2615.20
[INFO 2017-06-26 18:37:01,482 main.py:47] epoch 763, training loss: 1846.42, average training loss: 2525.77, base loss: 2614.72
[INFO 2017-06-26 18:37:01,794 main.py:47] epoch 764, training loss: 2131.10, average training loss: 2525.26, base loss: 2614.79
[INFO 2017-06-26 18:37:02,102 main.py:47] epoch 765, training loss: 2055.77, average training loss: 2524.64, base loss: 2614.69
[INFO 2017-06-26 18:37:02,409 main.py:47] epoch 766, training loss: 1802.61, average training loss: 2523.70, base loss: 2614.08
[INFO 2017-06-26 18:37:02,718 main.py:47] epoch 767, training loss: 2055.02, average training loss: 2523.09, base loss: 2614.05
[INFO 2017-06-26 18:37:03,027 main.py:47] epoch 768, training loss: 2335.68, average training loss: 2522.85, base loss: 2614.47
[INFO 2017-06-26 18:37:03,337 main.py:47] epoch 769, training loss: 1867.65, average training loss: 2522.00, base loss: 2614.00
[INFO 2017-06-26 18:37:03,642 main.py:47] epoch 770, training loss: 1984.40, average training loss: 2521.30, base loss: 2613.47
[INFO 2017-06-26 18:37:03,948 main.py:47] epoch 771, training loss: 2069.46, average training loss: 2520.72, base loss: 2613.34
[INFO 2017-06-26 18:37:04,257 main.py:47] epoch 772, training loss: 2114.00, average training loss: 2520.19, base loss: 2613.52
[INFO 2017-06-26 18:37:04,564 main.py:47] epoch 773, training loss: 2240.55, average training loss: 2519.83, base loss: 2613.74
[INFO 2017-06-26 18:37:04,873 main.py:47] epoch 774, training loss: 1999.37, average training loss: 2519.16, base loss: 2613.59
[INFO 2017-06-26 18:37:05,181 main.py:47] epoch 775, training loss: 1985.13, average training loss: 2518.47, base loss: 2613.32
[INFO 2017-06-26 18:37:05,490 main.py:47] epoch 776, training loss: 2198.75, average training loss: 2518.06, base loss: 2613.59
[INFO 2017-06-26 18:37:05,799 main.py:47] epoch 777, training loss: 1982.96, average training loss: 2517.37, base loss: 2613.40
[INFO 2017-06-26 18:37:06,107 main.py:47] epoch 778, training loss: 2206.85, average training loss: 2516.97, base loss: 2613.47
[INFO 2017-06-26 18:37:06,415 main.py:47] epoch 779, training loss: 1768.11, average training loss: 2516.01, base loss: 2612.83
[INFO 2017-06-26 18:37:06,725 main.py:47] epoch 780, training loss: 2111.77, average training loss: 2515.49, base loss: 2612.73
[INFO 2017-06-26 18:37:07,032 main.py:47] epoch 781, training loss: 2091.80, average training loss: 2514.95, base loss: 2612.63
[INFO 2017-06-26 18:37:07,340 main.py:47] epoch 782, training loss: 1992.41, average training loss: 2514.28, base loss: 2612.50
[INFO 2017-06-26 18:37:07,651 main.py:47] epoch 783, training loss: 1795.66, average training loss: 2513.37, base loss: 2611.95
[INFO 2017-06-26 18:37:07,960 main.py:47] epoch 784, training loss: 1677.76, average training loss: 2512.30, base loss: 2611.18
[INFO 2017-06-26 18:37:08,267 main.py:47] epoch 785, training loss: 1999.31, average training loss: 2511.65, base loss: 2610.83
[INFO 2017-06-26 18:37:08,572 main.py:47] epoch 786, training loss: 2151.20, average training loss: 2511.19, base loss: 2610.84
[INFO 2017-06-26 18:37:08,881 main.py:47] epoch 787, training loss: 2321.85, average training loss: 2510.95, base loss: 2611.29
[INFO 2017-06-26 18:37:09,189 main.py:47] epoch 788, training loss: 2249.95, average training loss: 2510.62, base loss: 2611.49
[INFO 2017-06-26 18:37:09,496 main.py:47] epoch 789, training loss: 2297.86, average training loss: 2510.35, base loss: 2611.87
[INFO 2017-06-26 18:37:09,801 main.py:47] epoch 790, training loss: 1914.15, average training loss: 2509.60, base loss: 2611.80
[INFO 2017-06-26 18:37:10,106 main.py:47] epoch 791, training loss: 2021.82, average training loss: 2508.98, base loss: 2611.82
[INFO 2017-06-26 18:37:10,414 main.py:47] epoch 792, training loss: 1984.34, average training loss: 2508.32, base loss: 2611.68
[INFO 2017-06-26 18:37:10,724 main.py:47] epoch 793, training loss: 2116.05, average training loss: 2507.83, base loss: 2611.76
[INFO 2017-06-26 18:37:11,033 main.py:47] epoch 794, training loss: 2133.60, average training loss: 2507.36, base loss: 2611.94
[INFO 2017-06-26 18:37:11,342 main.py:47] epoch 795, training loss: 2447.37, average training loss: 2507.28, base loss: 2612.71
[INFO 2017-06-26 18:37:11,648 main.py:47] epoch 796, training loss: 2191.89, average training loss: 2506.88, base loss: 2612.74
[INFO 2017-06-26 18:37:11,959 main.py:47] epoch 797, training loss: 2210.21, average training loss: 2506.51, base loss: 2612.85
[INFO 2017-06-26 18:37:12,268 main.py:47] epoch 798, training loss: 2036.29, average training loss: 2505.92, base loss: 2612.65
[INFO 2017-06-26 18:37:12,573 main.py:47] epoch 799, training loss: 2435.92, average training loss: 2505.84, base loss: 2613.09
[INFO 2017-06-26 18:37:12,573 main.py:49] epoch 799, testing
[INFO 2017-06-26 18:37:16,542 main.py:100] average testing loss: 2203.72, base loss: 2715.63
[INFO 2017-06-26 18:37:16,570 main.py:73] current best accuracy: 2111.90
[INFO 2017-06-26 18:37:16,881 main.py:47] epoch 800, training loss: 2276.93, average training loss: 2505.55, base loss: 2613.36
[INFO 2017-06-26 18:37:17,189 main.py:47] epoch 801, training loss: 1841.72, average training loss: 2504.72, base loss: 2612.89
[INFO 2017-06-26 18:37:17,497 main.py:47] epoch 802, training loss: 2249.27, average training loss: 2504.41, base loss: 2613.19
[INFO 2017-06-26 18:37:17,809 main.py:47] epoch 803, training loss: 1947.91, average training loss: 2503.71, base loss: 2612.93
[INFO 2017-06-26 18:37:18,114 main.py:47] epoch 804, training loss: 2079.01, average training loss: 2503.19, base loss: 2612.90
[INFO 2017-06-26 18:37:18,422 main.py:47] epoch 805, training loss: 2287.13, average training loss: 2502.92, base loss: 2613.09
[INFO 2017-06-26 18:37:18,732 main.py:47] epoch 806, training loss: 2166.00, average training loss: 2502.50, base loss: 2613.35
[INFO 2017-06-26 18:37:19,039 main.py:47] epoch 807, training loss: 2051.68, average training loss: 2501.94, base loss: 2613.21
[INFO 2017-06-26 18:37:19,344 main.py:47] epoch 808, training loss: 2113.40, average training loss: 2501.46, base loss: 2613.35
[INFO 2017-06-26 18:37:19,654 main.py:47] epoch 809, training loss: 2243.78, average training loss: 2501.14, base loss: 2613.82
[INFO 2017-06-26 18:37:19,962 main.py:47] epoch 810, training loss: 2327.19, average training loss: 2500.93, base loss: 2614.00
[INFO 2017-06-26 18:37:20,266 main.py:47] epoch 811, training loss: 1937.98, average training loss: 2500.24, base loss: 2613.49
[INFO 2017-06-26 18:37:20,573 main.py:47] epoch 812, training loss: 1813.08, average training loss: 2499.39, base loss: 2612.86
[INFO 2017-06-26 18:37:20,881 main.py:47] epoch 813, training loss: 2007.40, average training loss: 2498.79, base loss: 2612.45
[INFO 2017-06-26 18:37:21,187 main.py:47] epoch 814, training loss: 2170.10, average training loss: 2498.38, base loss: 2612.37
[INFO 2017-06-26 18:37:21,495 main.py:47] epoch 815, training loss: 2224.13, average training loss: 2498.05, base loss: 2612.52
[INFO 2017-06-26 18:37:21,798 main.py:47] epoch 816, training loss: 2568.60, average training loss: 2498.13, base loss: 2613.18
[INFO 2017-06-26 18:37:22,107 main.py:47] epoch 817, training loss: 1948.59, average training loss: 2497.46, base loss: 2613.01
[INFO 2017-06-26 18:37:22,414 main.py:47] epoch 818, training loss: 1953.91, average training loss: 2496.80, base loss: 2612.89
[INFO 2017-06-26 18:37:22,720 main.py:47] epoch 819, training loss: 1883.96, average training loss: 2496.05, base loss: 2612.47
[INFO 2017-06-26 18:37:23,028 main.py:47] epoch 820, training loss: 1968.50, average training loss: 2495.41, base loss: 2612.25
[INFO 2017-06-26 18:37:23,336 main.py:47] epoch 821, training loss: 1837.80, average training loss: 2494.61, base loss: 2611.71
[INFO 2017-06-26 18:37:23,645 main.py:47] epoch 822, training loss: 2007.28, average training loss: 2494.02, base loss: 2611.73
[INFO 2017-06-26 18:37:23,953 main.py:47] epoch 823, training loss: 2232.62, average training loss: 2493.70, base loss: 2611.88
[INFO 2017-06-26 18:37:24,263 main.py:47] epoch 824, training loss: 1951.91, average training loss: 2493.04, base loss: 2611.48
[INFO 2017-06-26 18:37:24,572 main.py:47] epoch 825, training loss: 2017.25, average training loss: 2492.47, base loss: 2611.43
[INFO 2017-06-26 18:37:24,880 main.py:47] epoch 826, training loss: 2100.18, average training loss: 2491.99, base loss: 2611.29
[INFO 2017-06-26 18:37:25,188 main.py:47] epoch 827, training loss: 1994.19, average training loss: 2491.39, base loss: 2611.04
[INFO 2017-06-26 18:37:25,497 main.py:47] epoch 828, training loss: 2565.07, average training loss: 2491.48, base loss: 2611.80
[INFO 2017-06-26 18:37:25,807 main.py:47] epoch 829, training loss: 2009.22, average training loss: 2490.90, base loss: 2611.66
[INFO 2017-06-26 18:37:26,112 main.py:47] epoch 830, training loss: 2069.39, average training loss: 2490.39, base loss: 2611.65
[INFO 2017-06-26 18:37:26,417 main.py:47] epoch 831, training loss: 2142.24, average training loss: 2489.97, base loss: 2611.71
[INFO 2017-06-26 18:37:26,727 main.py:47] epoch 832, training loss: 1902.61, average training loss: 2489.27, base loss: 2611.38
[INFO 2017-06-26 18:37:27,033 main.py:47] epoch 833, training loss: 2060.31, average training loss: 2488.75, base loss: 2611.41
[INFO 2017-06-26 18:37:27,340 main.py:47] epoch 834, training loss: 2045.62, average training loss: 2488.22, base loss: 2611.29
[INFO 2017-06-26 18:37:27,646 main.py:47] epoch 835, training loss: 1876.10, average training loss: 2487.49, base loss: 2610.82
[INFO 2017-06-26 18:37:27,954 main.py:47] epoch 836, training loss: 2108.93, average training loss: 2487.04, base loss: 2610.78
[INFO 2017-06-26 18:37:28,260 main.py:47] epoch 837, training loss: 1891.73, average training loss: 2486.33, base loss: 2610.38
[INFO 2017-06-26 18:37:28,566 main.py:47] epoch 838, training loss: 1893.53, average training loss: 2485.62, base loss: 2610.16
[INFO 2017-06-26 18:37:28,876 main.py:47] epoch 839, training loss: 1767.23, average training loss: 2484.77, base loss: 2609.51
[INFO 2017-06-26 18:37:29,185 main.py:47] epoch 840, training loss: 2141.58, average training loss: 2484.36, base loss: 2609.60
[INFO 2017-06-26 18:37:29,494 main.py:47] epoch 841, training loss: 1916.27, average training loss: 2483.68, base loss: 2609.36
[INFO 2017-06-26 18:37:29,804 main.py:47] epoch 842, training loss: 2013.07, average training loss: 2483.12, base loss: 2609.29
[INFO 2017-06-26 18:37:30,112 main.py:47] epoch 843, training loss: 2210.13, average training loss: 2482.80, base loss: 2609.51
[INFO 2017-06-26 18:37:30,420 main.py:47] epoch 844, training loss: 2041.87, average training loss: 2482.28, base loss: 2609.43
[INFO 2017-06-26 18:37:30,730 main.py:47] epoch 845, training loss: 2078.17, average training loss: 2481.80, base loss: 2609.35
[INFO 2017-06-26 18:37:31,039 main.py:47] epoch 846, training loss: 2237.19, average training loss: 2481.51, base loss: 2609.69
[INFO 2017-06-26 18:37:31,346 main.py:47] epoch 847, training loss: 1960.06, average training loss: 2480.90, base loss: 2609.32
[INFO 2017-06-26 18:37:31,666 main.py:47] epoch 848, training loss: 1998.24, average training loss: 2480.33, base loss: 2609.29
[INFO 2017-06-26 18:37:31,983 main.py:47] epoch 849, training loss: 1977.27, average training loss: 2479.74, base loss: 2609.18
[INFO 2017-06-26 18:37:32,292 main.py:47] epoch 850, training loss: 2152.60, average training loss: 2479.35, base loss: 2609.40
[INFO 2017-06-26 18:37:32,601 main.py:47] epoch 851, training loss: 2179.38, average training loss: 2479.00, base loss: 2609.48
[INFO 2017-06-26 18:37:32,906 main.py:47] epoch 852, training loss: 2014.74, average training loss: 2478.46, base loss: 2609.28
[INFO 2017-06-26 18:37:33,213 main.py:47] epoch 853, training loss: 2103.18, average training loss: 2478.02, base loss: 2609.37
[INFO 2017-06-26 18:37:33,521 main.py:47] epoch 854, training loss: 2035.26, average training loss: 2477.50, base loss: 2609.37
[INFO 2017-06-26 18:37:33,825 main.py:47] epoch 855, training loss: 2311.42, average training loss: 2477.31, base loss: 2609.68
[INFO 2017-06-26 18:37:34,128 main.py:47] epoch 856, training loss: 2564.52, average training loss: 2477.41, base loss: 2610.42
[INFO 2017-06-26 18:37:34,436 main.py:47] epoch 857, training loss: 2119.87, average training loss: 2476.99, base loss: 2610.65
[INFO 2017-06-26 18:37:34,741 main.py:47] epoch 858, training loss: 2266.10, average training loss: 2476.75, base loss: 2610.86
[INFO 2017-06-26 18:37:35,044 main.py:47] epoch 859, training loss: 2398.93, average training loss: 2476.65, base loss: 2611.33
[INFO 2017-06-26 18:37:35,352 main.py:47] epoch 860, training loss: 2009.51, average training loss: 2476.11, base loss: 2611.35
[INFO 2017-06-26 18:37:35,659 main.py:47] epoch 861, training loss: 2037.60, average training loss: 2475.60, base loss: 2611.38
[INFO 2017-06-26 18:37:35,966 main.py:47] epoch 862, training loss: 1956.38, average training loss: 2475.00, base loss: 2611.26
[INFO 2017-06-26 18:37:36,273 main.py:47] epoch 863, training loss: 2242.89, average training loss: 2474.73, base loss: 2611.57
[INFO 2017-06-26 18:37:36,581 main.py:47] epoch 864, training loss: 2270.06, average training loss: 2474.50, base loss: 2611.97
[INFO 2017-06-26 18:37:36,889 main.py:47] epoch 865, training loss: 1762.12, average training loss: 2473.67, base loss: 2611.32
[INFO 2017-06-26 18:37:37,196 main.py:47] epoch 866, training loss: 1818.16, average training loss: 2472.92, base loss: 2611.09
[INFO 2017-06-26 18:37:37,502 main.py:47] epoch 867, training loss: 1958.98, average training loss: 2472.33, base loss: 2610.91
[INFO 2017-06-26 18:37:37,810 main.py:47] epoch 868, training loss: 2221.59, average training loss: 2472.04, base loss: 2611.19
[INFO 2017-06-26 18:37:38,113 main.py:47] epoch 869, training loss: 1722.45, average training loss: 2471.18, base loss: 2610.67
[INFO 2017-06-26 18:37:38,420 main.py:47] epoch 870, training loss: 2042.82, average training loss: 2470.68, base loss: 2610.50
[INFO 2017-06-26 18:37:38,729 main.py:47] epoch 871, training loss: 2210.21, average training loss: 2470.38, base loss: 2610.82
[INFO 2017-06-26 18:37:39,038 main.py:47] epoch 872, training loss: 1891.94, average training loss: 2469.72, base loss: 2610.67
[INFO 2017-06-26 18:37:39,343 main.py:47] epoch 873, training loss: 1955.48, average training loss: 2469.13, base loss: 2610.39
[INFO 2017-06-26 18:37:39,650 main.py:47] epoch 874, training loss: 1951.25, average training loss: 2468.54, base loss: 2610.30
[INFO 2017-06-26 18:37:39,954 main.py:47] epoch 875, training loss: 1943.89, average training loss: 2467.94, base loss: 2610.11
[INFO 2017-06-26 18:37:40,260 main.py:47] epoch 876, training loss: 2053.12, average training loss: 2467.47, base loss: 2609.92
[INFO 2017-06-26 18:37:40,567 main.py:47] epoch 877, training loss: 2102.66, average training loss: 2467.05, base loss: 2610.01
[INFO 2017-06-26 18:37:40,875 main.py:47] epoch 878, training loss: 2052.95, average training loss: 2466.58, base loss: 2610.01
[INFO 2017-06-26 18:37:41,181 main.py:47] epoch 879, training loss: 2138.38, average training loss: 2466.21, base loss: 2609.97
[INFO 2017-06-26 18:37:41,487 main.py:47] epoch 880, training loss: 2226.11, average training loss: 2465.94, base loss: 2610.18
[INFO 2017-06-26 18:37:41,797 main.py:47] epoch 881, training loss: 2133.60, average training loss: 2465.56, base loss: 2610.38
[INFO 2017-06-26 18:37:42,100 main.py:47] epoch 882, training loss: 1960.32, average training loss: 2464.99, base loss: 2610.28
[INFO 2017-06-26 18:37:42,404 main.py:47] epoch 883, training loss: 1976.28, average training loss: 2464.44, base loss: 2610.14
[INFO 2017-06-26 18:37:42,711 main.py:47] epoch 884, training loss: 1924.11, average training loss: 2463.83, base loss: 2609.95
[INFO 2017-06-26 18:37:43,017 main.py:47] epoch 885, training loss: 2435.91, average training loss: 2463.79, base loss: 2610.57
[INFO 2017-06-26 18:37:43,326 main.py:47] epoch 886, training loss: 2288.40, average training loss: 2463.60, base loss: 2610.70
[INFO 2017-06-26 18:37:43,636 main.py:47] epoch 887, training loss: 1790.68, average training loss: 2462.84, base loss: 2610.06
[INFO 2017-06-26 18:37:43,943 main.py:47] epoch 888, training loss: 2214.03, average training loss: 2462.56, base loss: 2610.19
[INFO 2017-06-26 18:37:44,249 main.py:47] epoch 889, training loss: 1824.32, average training loss: 2461.84, base loss: 2609.90
[INFO 2017-06-26 18:37:44,554 main.py:47] epoch 890, training loss: 2055.37, average training loss: 2461.39, base loss: 2609.88
[INFO 2017-06-26 18:37:44,862 main.py:47] epoch 891, training loss: 2314.90, average training loss: 2461.22, base loss: 2610.09
[INFO 2017-06-26 18:37:45,166 main.py:47] epoch 892, training loss: 1897.67, average training loss: 2460.59, base loss: 2609.84
[INFO 2017-06-26 18:37:45,470 main.py:47] epoch 893, training loss: 2014.17, average training loss: 2460.09, base loss: 2609.70
[INFO 2017-06-26 18:37:45,776 main.py:47] epoch 894, training loss: 1930.56, average training loss: 2459.50, base loss: 2609.44
[INFO 2017-06-26 18:37:46,079 main.py:47] epoch 895, training loss: 1922.06, average training loss: 2458.90, base loss: 2609.31
[INFO 2017-06-26 18:37:46,383 main.py:47] epoch 896, training loss: 1883.14, average training loss: 2458.26, base loss: 2608.98
[INFO 2017-06-26 18:37:46,691 main.py:47] epoch 897, training loss: 2009.98, average training loss: 2457.76, base loss: 2608.89
[INFO 2017-06-26 18:37:47,000 main.py:47] epoch 898, training loss: 2318.31, average training loss: 2457.60, base loss: 2609.27
[INFO 2017-06-26 18:37:47,307 main.py:47] epoch 899, training loss: 2052.09, average training loss: 2457.15, base loss: 2609.09
[INFO 2017-06-26 18:37:47,307 main.py:49] epoch 899, testing
[INFO 2017-06-26 18:37:51,266 main.py:100] average testing loss: 2021.30, base loss: 2557.80
[INFO 2017-06-26 18:37:51,292 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:37:51,305 main.py:73] current best accuracy: 2021.30
[INFO 2017-06-26 18:37:51,616 main.py:47] epoch 900, training loss: 2334.05, average training loss: 2457.02, base loss: 2609.56
[INFO 2017-06-26 18:37:51,924 main.py:47] epoch 901, training loss: 2040.80, average training loss: 2456.55, base loss: 2609.52
[INFO 2017-06-26 18:37:52,229 main.py:47] epoch 902, training loss: 2179.78, average training loss: 2456.25, base loss: 2609.67
[INFO 2017-06-26 18:37:52,536 main.py:47] epoch 903, training loss: 1989.21, average training loss: 2455.73, base loss: 2609.61
[INFO 2017-06-26 18:37:52,842 main.py:47] epoch 904, training loss: 2523.95, average training loss: 2455.81, base loss: 2610.36
[INFO 2017-06-26 18:37:53,147 main.py:47] epoch 905, training loss: 1987.48, average training loss: 2455.29, base loss: 2610.14
[INFO 2017-06-26 18:37:53,453 main.py:47] epoch 906, training loss: 1965.87, average training loss: 2454.75, base loss: 2610.07
[INFO 2017-06-26 18:37:53,762 main.py:47] epoch 907, training loss: 2246.84, average training loss: 2454.52, base loss: 2610.40
[INFO 2017-06-26 18:37:54,068 main.py:47] epoch 908, training loss: 1868.03, average training loss: 2453.88, base loss: 2610.13
[INFO 2017-06-26 18:37:54,377 main.py:47] epoch 909, training loss: 1820.99, average training loss: 2453.18, base loss: 2609.76
[INFO 2017-06-26 18:37:54,684 main.py:47] epoch 910, training loss: 2325.90, average training loss: 2453.04, base loss: 2610.13
[INFO 2017-06-26 18:37:54,992 main.py:47] epoch 911, training loss: 1906.08, average training loss: 2452.44, base loss: 2609.79
[INFO 2017-06-26 18:37:55,304 main.py:47] epoch 912, training loss: 2009.85, average training loss: 2451.96, base loss: 2609.77
[INFO 2017-06-26 18:37:55,610 main.py:47] epoch 913, training loss: 2120.75, average training loss: 2451.59, base loss: 2609.89
[INFO 2017-06-26 18:37:55,919 main.py:47] epoch 914, training loss: 1877.96, average training loss: 2450.97, base loss: 2609.71
[INFO 2017-06-26 18:37:56,224 main.py:47] epoch 915, training loss: 2772.95, average training loss: 2451.32, base loss: 2610.70
[INFO 2017-06-26 18:37:56,532 main.py:47] epoch 916, training loss: 2056.54, average training loss: 2450.89, base loss: 2610.54
[INFO 2017-06-26 18:37:56,841 main.py:47] epoch 917, training loss: 1752.33, average training loss: 2450.13, base loss: 2610.14
[INFO 2017-06-26 18:37:57,149 main.py:47] epoch 918, training loss: 2137.88, average training loss: 2449.79, base loss: 2610.18
[INFO 2017-06-26 18:37:57,456 main.py:47] epoch 919, training loss: 2110.61, average training loss: 2449.42, base loss: 2610.09
[INFO 2017-06-26 18:37:57,763 main.py:47] epoch 920, training loss: 1835.37, average training loss: 2448.75, base loss: 2609.66
[INFO 2017-06-26 18:37:58,071 main.py:47] epoch 921, training loss: 2049.62, average training loss: 2448.32, base loss: 2609.61
[INFO 2017-06-26 18:37:58,376 main.py:47] epoch 922, training loss: 1989.98, average training loss: 2447.82, base loss: 2609.17
[INFO 2017-06-26 18:37:58,685 main.py:47] epoch 923, training loss: 2146.72, average training loss: 2447.50, base loss: 2609.15
[INFO 2017-06-26 18:37:58,992 main.py:47] epoch 924, training loss: 2088.45, average training loss: 2447.11, base loss: 2608.94
[INFO 2017-06-26 18:37:59,300 main.py:47] epoch 925, training loss: 2042.98, average training loss: 2446.67, base loss: 2608.80
[INFO 2017-06-26 18:37:59,607 main.py:47] epoch 926, training loss: 1757.84, average training loss: 2445.93, base loss: 2608.21
[INFO 2017-06-26 18:37:59,915 main.py:47] epoch 927, training loss: 2114.35, average training loss: 2445.57, base loss: 2608.19
[INFO 2017-06-26 18:38:00,219 main.py:47] epoch 928, training loss: 2488.37, average training loss: 2445.62, base loss: 2608.62
[INFO 2017-06-26 18:38:00,526 main.py:47] epoch 929, training loss: 1707.00, average training loss: 2444.82, base loss: 2608.04
[INFO 2017-06-26 18:38:00,834 main.py:47] epoch 930, training loss: 2033.38, average training loss: 2444.38, base loss: 2607.97
[INFO 2017-06-26 18:38:01,140 main.py:47] epoch 931, training loss: 1719.05, average training loss: 2443.60, base loss: 2607.32
[INFO 2017-06-26 18:38:01,444 main.py:47] epoch 932, training loss: 2046.61, average training loss: 2443.18, base loss: 2607.33
[INFO 2017-06-26 18:38:01,752 main.py:47] epoch 933, training loss: 1910.08, average training loss: 2442.61, base loss: 2607.14
[INFO 2017-06-26 18:38:02,059 main.py:47] epoch 934, training loss: 2286.36, average training loss: 2442.44, base loss: 2607.63
[INFO 2017-06-26 18:38:02,367 main.py:47] epoch 935, training loss: 1959.61, average training loss: 2441.92, base loss: 2607.58
[INFO 2017-06-26 18:38:02,675 main.py:47] epoch 936, training loss: 2146.45, average training loss: 2441.61, base loss: 2607.68
[INFO 2017-06-26 18:38:02,982 main.py:47] epoch 937, training loss: 2499.41, average training loss: 2441.67, base loss: 2608.57
[INFO 2017-06-26 18:38:03,289 main.py:47] epoch 938, training loss: 2005.29, average training loss: 2441.21, base loss: 2608.44
[INFO 2017-06-26 18:38:03,596 main.py:47] epoch 939, training loss: 1768.88, average training loss: 2440.49, base loss: 2607.93
[INFO 2017-06-26 18:38:03,905 main.py:47] epoch 940, training loss: 2169.85, average training loss: 2440.20, base loss: 2608.06
[INFO 2017-06-26 18:38:04,215 main.py:47] epoch 941, training loss: 2347.71, average training loss: 2440.10, base loss: 2608.32
[INFO 2017-06-26 18:38:04,519 main.py:47] epoch 942, training loss: 2384.48, average training loss: 2440.05, base loss: 2608.72
[INFO 2017-06-26 18:38:04,824 main.py:47] epoch 943, training loss: 1908.01, average training loss: 2439.48, base loss: 2608.35
[INFO 2017-06-26 18:38:05,132 main.py:47] epoch 944, training loss: 2137.19, average training loss: 2439.16, base loss: 2608.51
[INFO 2017-06-26 18:38:05,440 main.py:47] epoch 945, training loss: 1714.62, average training loss: 2438.40, base loss: 2608.02
[INFO 2017-06-26 18:38:05,744 main.py:47] epoch 946, training loss: 2161.38, average training loss: 2438.10, base loss: 2607.97
[INFO 2017-06-26 18:38:06,051 main.py:47] epoch 947, training loss: 1954.59, average training loss: 2437.59, base loss: 2607.78
[INFO 2017-06-26 18:38:06,357 main.py:47] epoch 948, training loss: 2107.41, average training loss: 2437.25, base loss: 2607.85
[INFO 2017-06-26 18:38:06,664 main.py:47] epoch 949, training loss: 1783.48, average training loss: 2436.56, base loss: 2607.46
[INFO 2017-06-26 18:38:06,971 main.py:47] epoch 950, training loss: 2216.02, average training loss: 2436.33, base loss: 2607.59
[INFO 2017-06-26 18:38:07,277 main.py:47] epoch 951, training loss: 1679.21, average training loss: 2435.53, base loss: 2606.82
[INFO 2017-06-26 18:38:07,583 main.py:47] epoch 952, training loss: 1899.36, average training loss: 2434.97, base loss: 2606.43
[INFO 2017-06-26 18:38:07,887 main.py:47] epoch 953, training loss: 2446.16, average training loss: 2434.98, base loss: 2606.94
[INFO 2017-06-26 18:38:08,193 main.py:47] epoch 954, training loss: 2017.38, average training loss: 2434.54, base loss: 2606.87
[INFO 2017-06-26 18:38:08,501 main.py:47] epoch 955, training loss: 2009.77, average training loss: 2434.10, base loss: 2606.82
[INFO 2017-06-26 18:38:08,809 main.py:47] epoch 956, training loss: 1738.17, average training loss: 2433.37, base loss: 2606.26
[INFO 2017-06-26 18:38:09,116 main.py:47] epoch 957, training loss: 1927.41, average training loss: 2432.84, base loss: 2606.09
[INFO 2017-06-26 18:38:09,423 main.py:47] epoch 958, training loss: 1996.86, average training loss: 2432.39, base loss: 2606.01
[INFO 2017-06-26 18:38:09,729 main.py:47] epoch 959, training loss: 2017.03, average training loss: 2431.96, base loss: 2606.00
[INFO 2017-06-26 18:38:10,032 main.py:47] epoch 960, training loss: 1770.67, average training loss: 2431.27, base loss: 2605.73
[INFO 2017-06-26 18:38:10,339 main.py:47] epoch 961, training loss: 2005.76, average training loss: 2430.82, base loss: 2605.51
[INFO 2017-06-26 18:38:10,646 main.py:47] epoch 962, training loss: 2421.76, average training loss: 2430.82, base loss: 2606.05
[INFO 2017-06-26 18:38:10,953 main.py:47] epoch 963, training loss: 2530.65, average training loss: 2430.92, base loss: 2606.67
[INFO 2017-06-26 18:38:11,261 main.py:47] epoch 964, training loss: 2961.81, average training loss: 2431.47, base loss: 2607.83
[INFO 2017-06-26 18:38:11,568 main.py:47] epoch 965, training loss: 1945.21, average training loss: 2430.97, base loss: 2607.67
[INFO 2017-06-26 18:38:11,874 main.py:47] epoch 966, training loss: 2185.72, average training loss: 2430.71, base loss: 2607.83
[INFO 2017-06-26 18:38:12,181 main.py:47] epoch 967, training loss: 2026.65, average training loss: 2430.29, base loss: 2607.74
[INFO 2017-06-26 18:38:12,487 main.py:47] epoch 968, training loss: 2055.21, average training loss: 2429.91, base loss: 2607.76
[INFO 2017-06-26 18:38:12,795 main.py:47] epoch 969, training loss: 2129.97, average training loss: 2429.60, base loss: 2607.84
[INFO 2017-06-26 18:38:13,101 main.py:47] epoch 970, training loss: 2247.58, average training loss: 2429.41, base loss: 2608.03
[INFO 2017-06-26 18:38:13,409 main.py:47] epoch 971, training loss: 1801.02, average training loss: 2428.76, base loss: 2607.62
[INFO 2017-06-26 18:38:13,717 main.py:47] epoch 972, training loss: 2332.51, average training loss: 2428.67, base loss: 2607.97
[INFO 2017-06-26 18:38:14,022 main.py:47] epoch 973, training loss: 2029.91, average training loss: 2428.26, base loss: 2607.74
[INFO 2017-06-26 18:38:14,328 main.py:47] epoch 974, training loss: 2212.08, average training loss: 2428.03, base loss: 2607.95
[INFO 2017-06-26 18:38:14,636 main.py:47] epoch 975, training loss: 1787.22, average training loss: 2427.38, base loss: 2607.55
[INFO 2017-06-26 18:38:14,944 main.py:47] epoch 976, training loss: 2369.26, average training loss: 2427.32, base loss: 2608.05
[INFO 2017-06-26 18:38:15,251 main.py:47] epoch 977, training loss: 2096.24, average training loss: 2426.98, base loss: 2608.03
[INFO 2017-06-26 18:38:15,555 main.py:47] epoch 978, training loss: 2228.64, average training loss: 2426.78, base loss: 2608.26
[INFO 2017-06-26 18:38:15,862 main.py:47] epoch 979, training loss: 2303.04, average training loss: 2426.65, base loss: 2608.54
[INFO 2017-06-26 18:38:16,168 main.py:47] epoch 980, training loss: 2124.68, average training loss: 2426.34, base loss: 2608.71
[INFO 2017-06-26 18:38:16,475 main.py:47] epoch 981, training loss: 2042.36, average training loss: 2425.95, base loss: 2608.75
[INFO 2017-06-26 18:38:16,782 main.py:47] epoch 982, training loss: 2146.79, average training loss: 2425.67, base loss: 2608.94
[INFO 2017-06-26 18:38:17,089 main.py:47] epoch 983, training loss: 1896.48, average training loss: 2425.13, base loss: 2608.78
[INFO 2017-06-26 18:38:17,392 main.py:47] epoch 984, training loss: 1858.60, average training loss: 2424.56, base loss: 2608.37
[INFO 2017-06-26 18:38:17,699 main.py:47] epoch 985, training loss: 2275.94, average training loss: 2424.40, base loss: 2608.55
[INFO 2017-06-26 18:38:18,007 main.py:47] epoch 986, training loss: 2353.95, average training loss: 2424.33, base loss: 2608.81
[INFO 2017-06-26 18:38:18,311 main.py:47] epoch 987, training loss: 1919.04, average training loss: 2423.82, base loss: 2608.55
[INFO 2017-06-26 18:38:18,619 main.py:47] epoch 988, training loss: 2212.63, average training loss: 2423.61, base loss: 2608.81
[INFO 2017-06-26 18:38:18,927 main.py:47] epoch 989, training loss: 1583.67, average training loss: 2422.76, base loss: 2608.18
[INFO 2017-06-26 18:38:19,235 main.py:47] epoch 990, training loss: 2119.26, average training loss: 2422.45, base loss: 2608.41
[INFO 2017-06-26 18:38:19,543 main.py:47] epoch 991, training loss: 2005.77, average training loss: 2422.03, base loss: 2608.29
[INFO 2017-06-26 18:38:19,849 main.py:47] epoch 992, training loss: 2040.26, average training loss: 2421.65, base loss: 2608.12
[INFO 2017-06-26 18:38:20,153 main.py:47] epoch 993, training loss: 2058.43, average training loss: 2421.28, base loss: 2608.02
[INFO 2017-06-26 18:38:20,460 main.py:47] epoch 994, training loss: 2243.93, average training loss: 2421.11, base loss: 2608.11
[INFO 2017-06-26 18:38:20,765 main.py:47] epoch 995, training loss: 1600.77, average training loss: 2420.28, base loss: 2607.38
[INFO 2017-06-26 18:38:21,071 main.py:47] epoch 996, training loss: 1913.48, average training loss: 2419.77, base loss: 2607.20
[INFO 2017-06-26 18:38:21,378 main.py:47] epoch 997, training loss: 1933.31, average training loss: 2419.29, base loss: 2607.00
[INFO 2017-06-26 18:38:21,685 main.py:47] epoch 998, training loss: 2110.80, average training loss: 2418.98, base loss: 2607.07
[INFO 2017-06-26 18:38:21,989 main.py:47] epoch 999, training loss: 2107.54, average training loss: 2418.67, base loss: 2607.11
[INFO 2017-06-26 18:38:21,990 main.py:49] epoch 999, testing
[INFO 2017-06-26 18:38:25,937 main.py:100] average testing loss: 2119.74, base loss: 2641.93
[INFO 2017-06-26 18:38:25,963 main.py:73] current best accuracy: 2021.30
[INFO 2017-06-26 18:38:26,270 main.py:47] epoch 1000, training loss: 1864.68, average training loss: 2384.89, base loss: 2606.71
[INFO 2017-06-26 18:38:26,577 main.py:47] epoch 1001, training loss: 2303.83, average training loss: 2358.13, base loss: 2607.09
[INFO 2017-06-26 18:38:26,884 main.py:47] epoch 1002, training loss: 2229.20, average training loss: 2335.95, base loss: 2606.81
[INFO 2017-06-26 18:38:27,194 main.py:47] epoch 1003, training loss: 2047.39, average training loss: 2317.44, base loss: 2607.06
[INFO 2017-06-26 18:38:27,502 main.py:47] epoch 1004, training loss: 1943.17, average training loss: 2300.91, base loss: 2606.68
[INFO 2017-06-26 18:38:27,809 main.py:47] epoch 1005, training loss: 2028.85, average training loss: 2287.48, base loss: 2606.79
[INFO 2017-06-26 18:38:28,117 main.py:47] epoch 1006, training loss: 1914.49, average training loss: 2275.47, base loss: 2606.28
[INFO 2017-06-26 18:38:28,424 main.py:47] epoch 1007, training loss: 2122.08, average training loss: 2265.85, base loss: 2606.35
[INFO 2017-06-26 18:38:28,729 main.py:47] epoch 1008, training loss: 2296.84, average training loss: 2257.43, base loss: 2606.68
[INFO 2017-06-26 18:38:29,036 main.py:47] epoch 1009, training loss: 2105.84, average training loss: 2250.55, base loss: 2606.86
[INFO 2017-06-26 18:38:29,341 main.py:47] epoch 1010, training loss: 2430.08, average training loss: 2245.08, base loss: 2607.43
[INFO 2017-06-26 18:38:29,650 main.py:47] epoch 1011, training loss: 1992.71, average training loss: 2240.27, base loss: 2607.69
[INFO 2017-06-26 18:38:29,958 main.py:47] epoch 1012, training loss: 2342.31, average training loss: 2236.30, base loss: 2607.69
[INFO 2017-06-26 18:38:30,261 main.py:47] epoch 1013, training loss: 1858.76, average training loss: 2232.58, base loss: 2606.94
[INFO 2017-06-26 18:38:30,565 main.py:47] epoch 1014, training loss: 2102.84, average training loss: 2229.85, base loss: 2606.92
[INFO 2017-06-26 18:38:30,868 main.py:47] epoch 1015, training loss: 2106.99, average training loss: 2227.34, base loss: 2606.78
[INFO 2017-06-26 18:38:31,176 main.py:47] epoch 1016, training loss: 1988.32, average training loss: 2225.10, base loss: 2606.59
[INFO 2017-06-26 18:38:31,484 main.py:47] epoch 1017, training loss: 2314.61, average training loss: 2223.47, base loss: 2606.89
[INFO 2017-06-26 18:38:31,789 main.py:47] epoch 1018, training loss: 2192.74, average training loss: 2222.35, base loss: 2607.33
[INFO 2017-06-26 18:38:32,097 main.py:47] epoch 1019, training loss: 2133.42, average training loss: 2221.11, base loss: 2607.52
[INFO 2017-06-26 18:38:32,406 main.py:47] epoch 1020, training loss: 2436.76, average training loss: 2220.14, base loss: 2607.91
[INFO 2017-06-26 18:38:32,712 main.py:47] epoch 1021, training loss: 1788.52, average training loss: 2218.97, base loss: 2607.63
[INFO 2017-06-26 18:38:33,015 main.py:47] epoch 1022, training loss: 1913.64, average training loss: 2218.05, base loss: 2607.80
[INFO 2017-06-26 18:38:33,321 main.py:47] epoch 1023, training loss: 1896.76, average training loss: 2217.56, base loss: 2608.22
[INFO 2017-06-26 18:38:33,629 main.py:47] epoch 1024, training loss: 1904.79, average training loss: 2217.02, base loss: 2608.41
[INFO 2017-06-26 18:38:33,936 main.py:47] epoch 1025, training loss: 2034.82, average training loss: 2215.99, base loss: 2607.90
[INFO 2017-06-26 18:38:34,244 main.py:47] epoch 1026, training loss: 1997.99, average training loss: 2215.17, base loss: 2607.76
[INFO 2017-06-26 18:38:34,552 main.py:47] epoch 1027, training loss: 2190.78, average training loss: 2214.55, base loss: 2607.87
[INFO 2017-06-26 18:38:34,859 main.py:47] epoch 1028, training loss: 1978.45, average training loss: 2213.87, base loss: 2607.81
[INFO 2017-06-26 18:38:35,165 main.py:47] epoch 1029, training loss: 1784.27, average training loss: 2212.65, base loss: 2607.13
[INFO 2017-06-26 18:38:35,473 main.py:47] epoch 1030, training loss: 2004.35, average training loss: 2212.17, base loss: 2607.25
[INFO 2017-06-26 18:38:35,780 main.py:47] epoch 1031, training loss: 1966.52, average training loss: 2211.37, base loss: 2607.01
[INFO 2017-06-26 18:38:36,088 main.py:47] epoch 1032, training loss: 2351.15, average training loss: 2211.14, base loss: 2607.38
[INFO 2017-06-26 18:38:36,395 main.py:47] epoch 1033, training loss: 2163.29, average training loss: 2210.82, base loss: 2607.59
[INFO 2017-06-26 18:38:36,705 main.py:47] epoch 1034, training loss: 1933.17, average training loss: 2209.86, base loss: 2607.07
[INFO 2017-06-26 18:38:37,010 main.py:47] epoch 1035, training loss: 1913.24, average training loss: 2208.80, base loss: 2606.59
[INFO 2017-06-26 18:38:37,315 main.py:47] epoch 1036, training loss: 2231.49, average training loss: 2208.64, base loss: 2607.04
[INFO 2017-06-26 18:38:37,625 main.py:47] epoch 1037, training loss: 2040.71, average training loss: 2208.05, base loss: 2606.99
[INFO 2017-06-26 18:38:37,932 main.py:47] epoch 1038, training loss: 2558.54, average training loss: 2207.83, base loss: 2607.46
[INFO 2017-06-26 18:38:38,237 main.py:47] epoch 1039, training loss: 2128.41, average training loss: 2207.90, base loss: 2608.09
[INFO 2017-06-26 18:38:38,541 main.py:47] epoch 1040, training loss: 2170.70, average training loss: 2207.70, base loss: 2608.52
[INFO 2017-06-26 18:38:38,850 main.py:47] epoch 1041, training loss: 2293.92, average training loss: 2207.24, base loss: 2608.66
[INFO 2017-06-26 18:38:39,155 main.py:47] epoch 1042, training loss: 2205.84, average training loss: 2206.84, base loss: 2608.88
[INFO 2017-06-26 18:38:39,461 main.py:47] epoch 1043, training loss: 2232.59, average training loss: 2206.61, base loss: 2609.18
[INFO 2017-06-26 18:38:39,768 main.py:47] epoch 1044, training loss: 2150.25, average training loss: 2206.45, base loss: 2609.75
[INFO 2017-06-26 18:38:40,077 main.py:47] epoch 1045, training loss: 2199.03, average training loss: 2205.82, base loss: 2609.63
[INFO 2017-06-26 18:38:40,383 main.py:47] epoch 1046, training loss: 1763.60, average training loss: 2205.34, base loss: 2609.54
[INFO 2017-06-26 18:38:40,688 main.py:47] epoch 1047, training loss: 2415.65, average training loss: 2204.72, base loss: 2609.45
[INFO 2017-06-26 18:38:40,997 main.py:47] epoch 1048, training loss: 2241.28, average training loss: 2204.67, base loss: 2610.01
[INFO 2017-06-26 18:38:41,301 main.py:47] epoch 1049, training loss: 1966.60, average training loss: 2204.16, base loss: 2609.98
[INFO 2017-06-26 18:38:41,612 main.py:47] epoch 1050, training loss: 1929.35, average training loss: 2203.44, base loss: 2609.70
[INFO 2017-06-26 18:38:41,920 main.py:47] epoch 1051, training loss: 2374.85, average training loss: 2203.16, base loss: 2609.86
[INFO 2017-06-26 18:38:42,226 main.py:47] epoch 1052, training loss: 1896.18, average training loss: 2202.26, base loss: 2609.41
[INFO 2017-06-26 18:38:42,536 main.py:47] epoch 1053, training loss: 2742.57, average training loss: 2202.85, base loss: 2610.57
[INFO 2017-06-26 18:38:42,846 main.py:47] epoch 1054, training loss: 2315.70, average training loss: 2202.31, base loss: 2610.64
[INFO 2017-06-26 18:38:43,153 main.py:47] epoch 1055, training loss: 2135.37, average training loss: 2202.35, base loss: 2611.35
[INFO 2017-06-26 18:38:43,462 main.py:47] epoch 1056, training loss: 1953.74, average training loss: 2201.61, base loss: 2610.84
[INFO 2017-06-26 18:38:43,770 main.py:47] epoch 1057, training loss: 2119.67, average training loss: 2201.11, base loss: 2610.88
[INFO 2017-06-26 18:38:44,080 main.py:47] epoch 1058, training loss: 2286.45, average training loss: 2201.03, base loss: 2611.27
[INFO 2017-06-26 18:38:44,388 main.py:47] epoch 1059, training loss: 2039.39, average training loss: 2200.28, base loss: 2611.30
[INFO 2017-06-26 18:38:44,697 main.py:47] epoch 1060, training loss: 2116.65, average training loss: 2199.66, base loss: 2611.03
[INFO 2017-06-26 18:38:45,003 main.py:47] epoch 1061, training loss: 2265.50, average training loss: 2199.81, base loss: 2611.71
[INFO 2017-06-26 18:38:45,307 main.py:47] epoch 1062, training loss: 2098.30, average training loss: 2199.51, base loss: 2611.88
[INFO 2017-06-26 18:38:45,615 main.py:47] epoch 1063, training loss: 2304.33, average training loss: 2199.50, base loss: 2612.53
[INFO 2017-06-26 18:38:45,922 main.py:47] epoch 1064, training loss: 1870.74, average training loss: 2198.88, base loss: 2612.52
[INFO 2017-06-26 18:38:46,232 main.py:47] epoch 1065, training loss: 1976.69, average training loss: 2197.81, base loss: 2611.86
[INFO 2017-06-26 18:38:46,539 main.py:47] epoch 1066, training loss: 2040.33, average training loss: 2197.08, base loss: 2611.42
[INFO 2017-06-26 18:38:46,846 main.py:47] epoch 1067, training loss: 1895.99, average training loss: 2196.83, base loss: 2611.66
[INFO 2017-06-26 18:38:47,153 main.py:47] epoch 1068, training loss: 2791.69, average training loss: 2197.37, base loss: 2612.94
[INFO 2017-06-26 18:38:47,457 main.py:47] epoch 1069, training loss: 1859.66, average training loss: 2196.81, base loss: 2612.77
[INFO 2017-06-26 18:38:47,765 main.py:47] epoch 1070, training loss: 1941.82, average training loss: 2195.75, base loss: 2612.26
[INFO 2017-06-26 18:38:48,074 main.py:47] epoch 1071, training loss: 1821.11, average training loss: 2195.29, base loss: 2612.25
[INFO 2017-06-26 18:38:48,381 main.py:47] epoch 1072, training loss: 1979.37, average training loss: 2194.64, base loss: 2612.03
[INFO 2017-06-26 18:38:48,688 main.py:47] epoch 1073, training loss: 2255.93, average training loss: 2194.56, base loss: 2612.65
[INFO 2017-06-26 18:38:48,997 main.py:47] epoch 1074, training loss: 1826.59, average training loss: 2193.73, base loss: 2612.03
[INFO 2017-06-26 18:38:49,304 main.py:47] epoch 1075, training loss: 1980.28, average training loss: 2193.25, base loss: 2611.85
[INFO 2017-06-26 18:38:49,612 main.py:47] epoch 1076, training loss: 2386.89, average training loss: 2193.15, base loss: 2612.26
[INFO 2017-06-26 18:38:49,919 main.py:47] epoch 1077, training loss: 2290.16, average training loss: 2193.01, base loss: 2612.75
[INFO 2017-06-26 18:38:50,226 main.py:47] epoch 1078, training loss: 1907.45, average training loss: 2192.02, base loss: 2612.09
[INFO 2017-06-26 18:38:50,529 main.py:47] epoch 1079, training loss: 2396.66, average training loss: 2191.99, base loss: 2612.68
[INFO 2017-06-26 18:38:50,837 main.py:47] epoch 1080, training loss: 2559.23, average training loss: 2191.92, base loss: 2613.05
[INFO 2017-06-26 18:38:51,142 main.py:47] epoch 1081, training loss: 2134.09, average training loss: 2191.34, base loss: 2612.80
[INFO 2017-06-26 18:38:51,450 main.py:47] epoch 1082, training loss: 2169.23, average training loss: 2191.23, base loss: 2613.09
[INFO 2017-06-26 18:38:51,759 main.py:47] epoch 1083, training loss: 2037.20, average training loss: 2190.74, base loss: 2612.96
[INFO 2017-06-26 18:38:52,066 main.py:47] epoch 1084, training loss: 2008.00, average training loss: 2190.33, base loss: 2613.01
[INFO 2017-06-26 18:38:52,369 main.py:47] epoch 1085, training loss: 2046.03, average training loss: 2189.71, base loss: 2612.98
[INFO 2017-06-26 18:38:52,674 main.py:47] epoch 1086, training loss: 2398.83, average training loss: 2189.99, base loss: 2613.84
[INFO 2017-06-26 18:38:52,981 main.py:47] epoch 1087, training loss: 2288.17, average training loss: 2189.75, base loss: 2614.23
[INFO 2017-06-26 18:38:53,287 main.py:47] epoch 1088, training loss: 2379.18, average training loss: 2189.22, base loss: 2614.22
[INFO 2017-06-26 18:38:53,594 main.py:47] epoch 1089, training loss: 2280.81, average training loss: 2188.96, base loss: 2614.53
[INFO 2017-06-26 18:38:53,901 main.py:47] epoch 1090, training loss: 2236.50, average training loss: 2188.69, base loss: 2614.92
[INFO 2017-06-26 18:38:54,209 main.py:47] epoch 1091, training loss: 1942.74, average training loss: 2188.22, base loss: 2614.86
[INFO 2017-06-26 18:38:54,518 main.py:47] epoch 1092, training loss: 2278.77, average training loss: 2188.20, base loss: 2615.16
[INFO 2017-06-26 18:38:54,824 main.py:47] epoch 1093, training loss: 2280.44, average training loss: 2188.00, base loss: 2615.45
[INFO 2017-06-26 18:38:55,133 main.py:47] epoch 1094, training loss: 1810.87, average training loss: 2187.68, base loss: 2615.53
[INFO 2017-06-26 18:38:55,441 main.py:47] epoch 1095, training loss: 1963.32, average training loss: 2187.32, base loss: 2615.62
[INFO 2017-06-26 18:38:55,751 main.py:47] epoch 1096, training loss: 1798.95, average training loss: 2186.91, base loss: 2615.63
[INFO 2017-06-26 18:38:56,058 main.py:47] epoch 1097, training loss: 2059.64, average training loss: 2185.98, base loss: 2615.06
[INFO 2017-06-26 18:38:56,366 main.py:47] epoch 1098, training loss: 1693.26, average training loss: 2184.60, base loss: 2614.00
[INFO 2017-06-26 18:38:56,673 main.py:47] epoch 1099, training loss: 1780.07, average training loss: 2183.44, base loss: 2613.21
[INFO 2017-06-26 18:38:56,674 main.py:49] epoch 1099, testing
[INFO 2017-06-26 18:39:00,630 main.py:100] average testing loss: 2089.81, base loss: 2634.06
[INFO 2017-06-26 18:39:00,655 main.py:73] current best accuracy: 2021.30
[INFO 2017-06-26 18:39:00,963 main.py:47] epoch 1100, training loss: 1949.43, average training loss: 2182.65, base loss: 2612.77
[INFO 2017-06-26 18:39:01,268 main.py:47] epoch 1101, training loss: 2095.85, average training loss: 2182.15, base loss: 2612.51
[INFO 2017-06-26 18:39:01,574 main.py:47] epoch 1102, training loss: 1944.83, average training loss: 2181.48, base loss: 2612.18
[INFO 2017-06-26 18:39:01,882 main.py:47] epoch 1103, training loss: 1981.82, average training loss: 2181.09, base loss: 2612.13
[INFO 2017-06-26 18:39:02,187 main.py:47] epoch 1104, training loss: 2172.22, average training loss: 2180.56, base loss: 2612.16
[INFO 2017-06-26 18:39:02,496 main.py:47] epoch 1105, training loss: 1923.77, average training loss: 2179.58, base loss: 2611.25
[INFO 2017-06-26 18:39:02,802 main.py:47] epoch 1106, training loss: 2088.96, average training loss: 2179.37, base loss: 2611.40
[INFO 2017-06-26 18:39:03,108 main.py:47] epoch 1107, training loss: 2197.15, average training loss: 2179.01, base loss: 2611.71
[INFO 2017-06-26 18:39:03,417 main.py:47] epoch 1108, training loss: 2144.05, average training loss: 2178.77, base loss: 2611.95
[INFO 2017-06-26 18:39:03,726 main.py:47] epoch 1109, training loss: 1997.62, average training loss: 2178.28, base loss: 2611.89
[INFO 2017-06-26 18:39:04,035 main.py:47] epoch 1110, training loss: 2043.08, average training loss: 2177.89, base loss: 2611.81
[INFO 2017-06-26 18:39:04,341 main.py:47] epoch 1111, training loss: 2077.78, average training loss: 2177.71, base loss: 2612.16
[INFO 2017-06-26 18:39:04,653 main.py:47] epoch 1112, training loss: 2089.58, average training loss: 2177.07, base loss: 2611.91
[INFO 2017-06-26 18:39:04,959 main.py:47] epoch 1113, training loss: 1961.01, average training loss: 2176.05, base loss: 2611.38
[INFO 2017-06-26 18:39:05,266 main.py:47] epoch 1114, training loss: 1871.24, average training loss: 2175.02, base loss: 2610.80
[INFO 2017-06-26 18:39:05,571 main.py:47] epoch 1115, training loss: 1872.27, average training loss: 2174.16, base loss: 2610.25
[INFO 2017-06-26 18:39:05,875 main.py:47] epoch 1116, training loss: 1668.37, average training loss: 2173.48, base loss: 2610.00
[INFO 2017-06-26 18:39:06,181 main.py:47] epoch 1117, training loss: 1850.19, average training loss: 2172.99, base loss: 2610.00
[INFO 2017-06-26 18:39:06,486 main.py:47] epoch 1118, training loss: 2228.16, average training loss: 2172.64, base loss: 2610.31
[INFO 2017-06-26 18:39:06,791 main.py:47] epoch 1119, training loss: 2271.89, average training loss: 2172.51, base loss: 2610.57
[INFO 2017-06-26 18:39:07,099 main.py:47] epoch 1120, training loss: 1685.62, average training loss: 2171.79, base loss: 2610.24
[INFO 2017-06-26 18:39:07,407 main.py:47] epoch 1121, training loss: 1907.79, average training loss: 2171.04, base loss: 2609.65
[INFO 2017-06-26 18:39:07,716 main.py:47] epoch 1122, training loss: 1977.81, average training loss: 2170.68, base loss: 2609.86
[INFO 2017-06-26 18:39:08,021 main.py:47] epoch 1123, training loss: 2392.21, average training loss: 2170.53, base loss: 2610.21
[INFO 2017-06-26 18:39:08,328 main.py:47] epoch 1124, training loss: 2220.09, average training loss: 2170.19, base loss: 2610.50
[INFO 2017-06-26 18:39:08,636 main.py:47] epoch 1125, training loss: 2207.83, average training loss: 2170.36, base loss: 2611.20
[INFO 2017-06-26 18:39:08,944 main.py:47] epoch 1126, training loss: 1788.00, average training loss: 2169.80, base loss: 2610.96
[INFO 2017-06-26 18:39:09,247 main.py:47] epoch 1127, training loss: 1815.86, average training loss: 2169.37, base loss: 2610.73
[INFO 2017-06-26 18:39:09,556 main.py:47] epoch 1128, training loss: 1774.69, average training loss: 2168.83, base loss: 2610.29
[INFO 2017-06-26 18:39:09,864 main.py:47] epoch 1129, training loss: 2015.08, average training loss: 2168.20, base loss: 2610.00
[INFO 2017-06-26 18:39:10,171 main.py:47] epoch 1130, training loss: 2168.46, average training loss: 2167.99, base loss: 2610.36
[INFO 2017-06-26 18:39:10,478 main.py:47] epoch 1131, training loss: 1897.96, average training loss: 2167.42, base loss: 2610.12
[INFO 2017-06-26 18:39:10,787 main.py:47] epoch 1132, training loss: 1909.81, average training loss: 2167.16, base loss: 2610.23
[INFO 2017-06-26 18:39:11,093 main.py:47] epoch 1133, training loss: 2018.78, average training loss: 2167.11, base loss: 2610.62
[INFO 2017-06-26 18:39:11,399 main.py:47] epoch 1134, training loss: 2089.95, average training loss: 2166.70, base loss: 2610.69
[INFO 2017-06-26 18:39:11,707 main.py:47] epoch 1135, training loss: 2129.86, average training loss: 2166.36, base loss: 2610.89
[INFO 2017-06-26 18:39:12,015 main.py:47] epoch 1136, training loss: 2266.53, average training loss: 2166.01, base loss: 2610.94
[INFO 2017-06-26 18:39:12,319 main.py:47] epoch 1137, training loss: 1709.64, average training loss: 2165.35, base loss: 2610.56
[INFO 2017-06-26 18:39:12,626 main.py:47] epoch 1138, training loss: 1825.77, average training loss: 2164.44, base loss: 2609.98
[INFO 2017-06-26 18:39:12,932 main.py:47] epoch 1139, training loss: 2139.94, average training loss: 2164.21, base loss: 2610.19
[INFO 2017-06-26 18:39:13,238 main.py:47] epoch 1140, training loss: 1938.76, average training loss: 2163.70, base loss: 2610.10
[INFO 2017-06-26 18:39:13,543 main.py:47] epoch 1141, training loss: 1867.72, average training loss: 2162.89, base loss: 2609.45
[INFO 2017-06-26 18:39:13,848 main.py:47] epoch 1142, training loss: 2191.01, average training loss: 2162.71, base loss: 2609.75
[INFO 2017-06-26 18:39:14,152 main.py:47] epoch 1143, training loss: 2235.71, average training loss: 2162.70, base loss: 2610.26
[INFO 2017-06-26 18:39:14,457 main.py:47] epoch 1144, training loss: 2010.32, average training loss: 2162.30, base loss: 2610.11
[INFO 2017-06-26 18:39:14,765 main.py:47] epoch 1145, training loss: 2134.02, average training loss: 2162.12, base loss: 2610.30
[INFO 2017-06-26 18:39:15,072 main.py:47] epoch 1146, training loss: 1918.55, average training loss: 2161.32, base loss: 2609.91
[INFO 2017-06-26 18:39:15,379 main.py:47] epoch 1147, training loss: 2499.26, average training loss: 2161.33, base loss: 2610.34
[INFO 2017-06-26 18:39:15,686 main.py:47] epoch 1148, training loss: 2237.08, average training loss: 2161.24, base loss: 2610.73
[INFO 2017-06-26 18:39:15,993 main.py:47] epoch 1149, training loss: 1928.74, average training loss: 2160.45, base loss: 2610.04
[INFO 2017-06-26 18:39:16,296 main.py:47] epoch 1150, training loss: 1781.96, average training loss: 2159.92, base loss: 2609.86
[INFO 2017-06-26 18:39:16,602 main.py:47] epoch 1151, training loss: 2373.98, average training loss: 2159.92, base loss: 2610.33
[INFO 2017-06-26 18:39:16,909 main.py:47] epoch 1152, training loss: 1789.97, average training loss: 2158.98, base loss: 2609.54
[INFO 2017-06-26 18:39:17,212 main.py:47] epoch 1153, training loss: 2185.77, average training loss: 2158.53, base loss: 2609.57
[INFO 2017-06-26 18:39:17,517 main.py:47] epoch 1154, training loss: 1935.41, average training loss: 2157.46, base loss: 2608.53
[INFO 2017-06-26 18:39:17,822 main.py:47] epoch 1155, training loss: 1964.94, average training loss: 2156.71, base loss: 2608.04
[INFO 2017-06-26 18:39:18,130 main.py:47] epoch 1156, training loss: 2213.94, average training loss: 2156.56, base loss: 2608.32
[INFO 2017-06-26 18:39:18,438 main.py:47] epoch 1157, training loss: 2278.31, average training loss: 2156.47, base loss: 2608.55
[INFO 2017-06-26 18:39:18,745 main.py:47] epoch 1158, training loss: 2119.88, average training loss: 2156.01, base loss: 2608.25
[INFO 2017-06-26 18:39:19,054 main.py:47] epoch 1159, training loss: 2474.12, average training loss: 2155.89, base loss: 2608.53
[INFO 2017-06-26 18:39:19,359 main.py:47] epoch 1160, training loss: 2308.87, average training loss: 2156.10, base loss: 2609.38
[INFO 2017-06-26 18:39:19,668 main.py:47] epoch 1161, training loss: 2013.62, average training loss: 2155.77, base loss: 2609.25
[INFO 2017-06-26 18:39:19,974 main.py:47] epoch 1162, training loss: 2202.54, average training loss: 2155.49, base loss: 2609.37
[INFO 2017-06-26 18:39:20,277 main.py:47] epoch 1163, training loss: 2319.84, average training loss: 2155.47, base loss: 2610.01
[INFO 2017-06-26 18:39:20,583 main.py:47] epoch 1164, training loss: 2232.06, average training loss: 2155.47, base loss: 2610.39
[INFO 2017-06-26 18:39:20,890 main.py:47] epoch 1165, training loss: 1981.22, average training loss: 2155.22, base loss: 2610.52
[INFO 2017-06-26 18:39:21,197 main.py:47] epoch 1166, training loss: 1958.60, average training loss: 2154.35, base loss: 2609.89
[INFO 2017-06-26 18:39:21,504 main.py:47] epoch 1167, training loss: 1777.67, average training loss: 2153.96, base loss: 2609.61
[INFO 2017-06-26 18:39:21,811 main.py:47] epoch 1168, training loss: 2017.68, average training loss: 2153.23, base loss: 2609.18
[INFO 2017-06-26 18:39:22,119 main.py:47] epoch 1169, training loss: 2010.81, average training loss: 2153.03, base loss: 2609.42
[INFO 2017-06-26 18:39:22,423 main.py:47] epoch 1170, training loss: 2281.52, average training loss: 2152.95, base loss: 2609.82
[INFO 2017-06-26 18:39:22,728 main.py:47] epoch 1171, training loss: 1782.40, average training loss: 2152.50, base loss: 2609.63
[INFO 2017-06-26 18:39:23,032 main.py:47] epoch 1172, training loss: 2333.63, average training loss: 2152.36, base loss: 2609.86
[INFO 2017-06-26 18:39:23,340 main.py:47] epoch 1173, training loss: 1951.53, average training loss: 2152.07, base loss: 2610.02
[INFO 2017-06-26 18:39:23,648 main.py:47] epoch 1174, training loss: 1959.65, average training loss: 2152.30, base loss: 2610.71
[INFO 2017-06-26 18:39:23,953 main.py:47] epoch 1175, training loss: 2260.00, average training loss: 2152.39, base loss: 2611.18
[INFO 2017-06-26 18:39:24,262 main.py:47] epoch 1176, training loss: 2088.10, average training loss: 2152.57, base loss: 2611.75
[INFO 2017-06-26 18:39:24,568 main.py:47] epoch 1177, training loss: 2034.31, average training loss: 2152.47, base loss: 2612.17
[INFO 2017-06-26 18:39:24,875 main.py:47] epoch 1178, training loss: 1741.68, average training loss: 2151.63, base loss: 2611.47
[INFO 2017-06-26 18:39:25,182 main.py:47] epoch 1179, training loss: 2036.46, average training loss: 2151.28, base loss: 2611.43
[INFO 2017-06-26 18:39:25,489 main.py:47] epoch 1180, training loss: 2002.32, average training loss: 2151.19, base loss: 2611.76
[INFO 2017-06-26 18:39:25,796 main.py:47] epoch 1181, training loss: 1893.77, average training loss: 2150.54, base loss: 2611.23
[INFO 2017-06-26 18:39:26,104 main.py:47] epoch 1182, training loss: 2185.70, average training loss: 2150.67, base loss: 2611.70
[INFO 2017-06-26 18:39:26,409 main.py:47] epoch 1183, training loss: 2426.08, average training loss: 2150.51, base loss: 2611.89
[INFO 2017-06-26 18:39:26,713 main.py:47] epoch 1184, training loss: 2372.61, average training loss: 2150.97, base loss: 2612.73
[INFO 2017-06-26 18:39:27,022 main.py:47] epoch 1185, training loss: 1977.81, average training loss: 2150.61, base loss: 2612.85
[INFO 2017-06-26 18:39:27,330 main.py:47] epoch 1186, training loss: 2151.01, average training loss: 2150.36, base loss: 2612.79
[INFO 2017-06-26 18:39:27,638 main.py:47] epoch 1187, training loss: 1900.77, average training loss: 2150.05, base loss: 2612.72
[INFO 2017-06-26 18:39:27,945 main.py:47] epoch 1188, training loss: 1917.85, average training loss: 2149.52, base loss: 2612.51
[INFO 2017-06-26 18:39:28,253 main.py:47] epoch 1189, training loss: 1768.96, average training loss: 2148.85, base loss: 2612.18
[INFO 2017-06-26 18:39:28,558 main.py:47] epoch 1190, training loss: 2116.58, average training loss: 2148.25, base loss: 2611.90
[INFO 2017-06-26 18:39:28,865 main.py:47] epoch 1191, training loss: 2451.81, average training loss: 2147.98, base loss: 2612.08
[INFO 2017-06-26 18:39:29,173 main.py:47] epoch 1192, training loss: 2016.62, average training loss: 2147.71, base loss: 2612.32
[INFO 2017-06-26 18:39:29,481 main.py:47] epoch 1193, training loss: 2173.64, average training loss: 2147.86, base loss: 2612.83
[INFO 2017-06-26 18:39:29,789 main.py:47] epoch 1194, training loss: 2310.69, average training loss: 2148.16, base loss: 2613.55
[INFO 2017-06-26 18:39:30,096 main.py:47] epoch 1195, training loss: 2151.68, average training loss: 2147.86, base loss: 2613.46
[INFO 2017-06-26 18:39:30,403 main.py:47] epoch 1196, training loss: 2091.38, average training loss: 2147.90, base loss: 2613.89
[INFO 2017-06-26 18:39:30,710 main.py:47] epoch 1197, training loss: 1997.98, average training loss: 2147.75, base loss: 2614.23
[INFO 2017-06-26 18:39:31,016 main.py:47] epoch 1198, training loss: 2679.78, average training loss: 2147.97, base loss: 2614.73
[INFO 2017-06-26 18:39:31,323 main.py:47] epoch 1199, training loss: 2186.24, average training loss: 2148.02, base loss: 2615.13
[INFO 2017-06-26 18:39:31,324 main.py:49] epoch 1199, testing
[INFO 2017-06-26 18:39:35,320 main.py:100] average testing loss: 2017.92, base loss: 2540.07
[INFO 2017-06-26 18:39:35,344 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:39:35,357 main.py:73] current best accuracy: 2017.92
[INFO 2017-06-26 18:39:35,663 main.py:47] epoch 1200, training loss: 2557.65, average training loss: 2148.27, base loss: 2615.99
[INFO 2017-06-26 18:39:35,970 main.py:47] epoch 1201, training loss: 2199.00, average training loss: 2147.97, base loss: 2615.88
[INFO 2017-06-26 18:39:36,275 main.py:47] epoch 1202, training loss: 1989.76, average training loss: 2147.86, base loss: 2616.10
[INFO 2017-06-26 18:39:36,579 main.py:47] epoch 1203, training loss: 2151.79, average training loss: 2147.99, base loss: 2616.64
[INFO 2017-06-26 18:39:36,888 main.py:47] epoch 1204, training loss: 2160.26, average training loss: 2148.11, base loss: 2617.01
[INFO 2017-06-26 18:39:37,193 main.py:47] epoch 1205, training loss: 2151.57, average training loss: 2148.08, base loss: 2617.06
[INFO 2017-06-26 18:39:37,501 main.py:47] epoch 1206, training loss: 2014.94, average training loss: 2147.33, base loss: 2616.56
[INFO 2017-06-26 18:39:37,808 main.py:47] epoch 1207, training loss: 1884.86, average training loss: 2147.07, base loss: 2616.65
[INFO 2017-06-26 18:39:38,115 main.py:47] epoch 1208, training loss: 1901.52, average training loss: 2146.85, base loss: 2616.66
[INFO 2017-06-26 18:39:38,421 main.py:47] epoch 1209, training loss: 2057.99, average training loss: 2146.13, base loss: 2616.26
[INFO 2017-06-26 18:39:38,726 main.py:47] epoch 1210, training loss: 1889.74, average training loss: 2146.00, base loss: 2616.32
[INFO 2017-06-26 18:39:39,033 main.py:47] epoch 1211, training loss: 2188.14, average training loss: 2145.93, base loss: 2616.55
[INFO 2017-06-26 18:39:39,340 main.py:47] epoch 1212, training loss: 2278.43, average training loss: 2145.96, base loss: 2617.02
[INFO 2017-06-26 18:39:39,647 main.py:47] epoch 1213, training loss: 2117.32, average training loss: 2145.98, base loss: 2617.17
[INFO 2017-06-26 18:39:39,952 main.py:47] epoch 1214, training loss: 1824.69, average training loss: 2145.41, base loss: 2616.91
[INFO 2017-06-26 18:39:40,259 main.py:47] epoch 1215, training loss: 1672.19, average training loss: 2144.76, base loss: 2616.43
[INFO 2017-06-26 18:39:40,564 main.py:47] epoch 1216, training loss: 1917.70, average training loss: 2144.33, base loss: 2616.27
[INFO 2017-06-26 18:39:40,872 main.py:47] epoch 1217, training loss: 1992.28, average training loss: 2143.89, base loss: 2616.13
[INFO 2017-06-26 18:39:41,179 main.py:47] epoch 1218, training loss: 1936.78, average training loss: 2143.45, base loss: 2615.88
[INFO 2017-06-26 18:39:41,482 main.py:47] epoch 1219, training loss: 1929.36, average training loss: 2142.54, base loss: 2615.22
[INFO 2017-06-26 18:39:41,788 main.py:47] epoch 1220, training loss: 2198.56, average training loss: 2142.58, base loss: 2615.78
[INFO 2017-06-26 18:39:42,095 main.py:47] epoch 1221, training loss: 2240.45, average training loss: 2142.10, base loss: 2615.46
[INFO 2017-06-26 18:39:42,399 main.py:47] epoch 1222, training loss: 2052.36, average training loss: 2141.49, base loss: 2614.81
[INFO 2017-06-26 18:39:42,705 main.py:47] epoch 1223, training loss: 1858.53, average training loss: 2140.96, base loss: 2614.28
[INFO 2017-06-26 18:39:43,009 main.py:47] epoch 1224, training loss: 2260.90, average training loss: 2141.17, base loss: 2614.72
[INFO 2017-06-26 18:39:43,316 main.py:47] epoch 1225, training loss: 1942.56, average training loss: 2140.73, base loss: 2614.75
[INFO 2017-06-26 18:39:43,623 main.py:47] epoch 1226, training loss: 1893.69, average training loss: 2140.31, base loss: 2614.42
[INFO 2017-06-26 18:39:43,930 main.py:47] epoch 1227, training loss: 1852.21, average training loss: 2140.06, base loss: 2614.44
[INFO 2017-06-26 18:39:44,236 main.py:47] epoch 1228, training loss: 2081.07, average training loss: 2139.82, base loss: 2614.58
[INFO 2017-06-26 18:39:44,542 main.py:47] epoch 1229, training loss: 2316.28, average training loss: 2139.70, base loss: 2614.81
[INFO 2017-06-26 18:39:44,850 main.py:47] epoch 1230, training loss: 2095.26, average training loss: 2139.42, base loss: 2614.87
[INFO 2017-06-26 18:39:45,155 main.py:47] epoch 1231, training loss: 1943.30, average training loss: 2138.98, base loss: 2614.71
[INFO 2017-06-26 18:39:45,461 main.py:47] epoch 1232, training loss: 2136.09, average training loss: 2138.64, base loss: 2614.75
[INFO 2017-06-26 18:39:45,766 main.py:47] epoch 1233, training loss: 2063.97, average training loss: 2138.45, base loss: 2614.84
[INFO 2017-06-26 18:39:46,073 main.py:47] epoch 1234, training loss: 2109.12, average training loss: 2137.67, base loss: 2614.21
[INFO 2017-06-26 18:39:46,381 main.py:47] epoch 1235, training loss: 2384.59, average training loss: 2137.77, base loss: 2614.77
[INFO 2017-06-26 18:39:46,687 main.py:47] epoch 1236, training loss: 2081.38, average training loss: 2137.47, base loss: 2614.64
[INFO 2017-06-26 18:39:46,990 main.py:47] epoch 1237, training loss: 2290.39, average training loss: 2137.50, base loss: 2615.21
[INFO 2017-06-26 18:39:47,298 main.py:47] epoch 1238, training loss: 2150.04, average training loss: 2137.36, base loss: 2615.28
[INFO 2017-06-26 18:39:47,603 main.py:47] epoch 1239, training loss: 1917.04, average training loss: 2137.29, base loss: 2615.50
[INFO 2017-06-26 18:39:47,908 main.py:47] epoch 1240, training loss: 2261.26, average training loss: 2137.32, base loss: 2615.93
[INFO 2017-06-26 18:39:48,216 main.py:47] epoch 1241, training loss: 1909.88, average training loss: 2137.17, base loss: 2616.33
[INFO 2017-06-26 18:39:48,523 main.py:47] epoch 1242, training loss: 2187.76, average training loss: 2137.09, base loss: 2616.48
[INFO 2017-06-26 18:39:48,828 main.py:47] epoch 1243, training loss: 1886.24, average training loss: 2136.85, base loss: 2616.50
[INFO 2017-06-26 18:39:49,138 main.py:47] epoch 1244, training loss: 2092.47, average training loss: 2136.68, base loss: 2616.43
[INFO 2017-06-26 18:39:49,443 main.py:47] epoch 1245, training loss: 1825.32, average training loss: 2135.97, base loss: 2615.80
[INFO 2017-06-26 18:39:49,749 main.py:47] epoch 1246, training loss: 2109.69, average training loss: 2135.79, base loss: 2615.83
[INFO 2017-06-26 18:39:50,057 main.py:47] epoch 1247, training loss: 2110.34, average training loss: 2135.57, base loss: 2615.92
[INFO 2017-06-26 18:39:50,364 main.py:47] epoch 1248, training loss: 1992.35, average training loss: 2135.12, base loss: 2615.71
[INFO 2017-06-26 18:39:50,672 main.py:47] epoch 1249, training loss: 2177.53, average training loss: 2134.87, base loss: 2615.79
[INFO 2017-06-26 18:39:50,977 main.py:47] epoch 1250, training loss: 2097.44, average training loss: 2134.69, base loss: 2615.78
[INFO 2017-06-26 18:39:51,280 main.py:47] epoch 1251, training loss: 2144.31, average training loss: 2134.53, base loss: 2615.73
[INFO 2017-06-26 18:39:51,587 main.py:47] epoch 1252, training loss: 2385.48, average training loss: 2134.24, base loss: 2615.73
[INFO 2017-06-26 18:39:51,895 main.py:47] epoch 1253, training loss: 1987.37, average training loss: 2133.95, base loss: 2615.49
[INFO 2017-06-26 18:39:52,201 main.py:47] epoch 1254, training loss: 2030.64, average training loss: 2133.76, base loss: 2615.52
[INFO 2017-06-26 18:39:52,510 main.py:47] epoch 1255, training loss: 2234.31, average training loss: 2133.56, base loss: 2615.47
[INFO 2017-06-26 18:39:52,817 main.py:47] epoch 1256, training loss: 1925.12, average training loss: 2133.30, base loss: 2615.46
[INFO 2017-06-26 18:39:53,124 main.py:47] epoch 1257, training loss: 2108.84, average training loss: 2132.49, base loss: 2614.95
[INFO 2017-06-26 18:39:53,433 main.py:47] epoch 1258, training loss: 1874.60, average training loss: 2131.69, base loss: 2614.26
[INFO 2017-06-26 18:39:53,741 main.py:47] epoch 1259, training loss: 2230.87, average training loss: 2131.57, base loss: 2614.39
[INFO 2017-06-26 18:39:54,047 main.py:47] epoch 1260, training loss: 2319.34, average training loss: 2131.82, base loss: 2614.97
[INFO 2017-06-26 18:39:54,354 main.py:47] epoch 1261, training loss: 1890.74, average training loss: 2131.20, base loss: 2614.52
[INFO 2017-06-26 18:39:54,662 main.py:47] epoch 1262, training loss: 1915.82, average training loss: 2130.98, base loss: 2614.47
[INFO 2017-06-26 18:39:54,969 main.py:47] epoch 1263, training loss: 2074.62, average training loss: 2130.99, base loss: 2614.64
[INFO 2017-06-26 18:39:55,277 main.py:47] epoch 1264, training loss: 1959.92, average training loss: 2130.42, base loss: 2614.19
[INFO 2017-06-26 18:39:55,585 main.py:47] epoch 1265, training loss: 2346.18, average training loss: 2130.60, base loss: 2614.91
[INFO 2017-06-26 18:39:55,891 main.py:47] epoch 1266, training loss: 2016.08, average training loss: 2130.44, base loss: 2614.98
[INFO 2017-06-26 18:39:56,199 main.py:47] epoch 1267, training loss: 1998.28, average training loss: 2130.38, base loss: 2615.29
[INFO 2017-06-26 18:39:56,504 main.py:47] epoch 1268, training loss: 1931.57, average training loss: 2129.42, base loss: 2614.61
[INFO 2017-06-26 18:39:56,813 main.py:47] epoch 1269, training loss: 1861.55, average training loss: 2129.00, base loss: 2614.32
[INFO 2017-06-26 18:39:57,117 main.py:47] epoch 1270, training loss: 2276.35, average training loss: 2129.11, base loss: 2614.72
[INFO 2017-06-26 18:39:57,423 main.py:47] epoch 1271, training loss: 1821.54, average training loss: 2128.92, base loss: 2614.76
[INFO 2017-06-26 18:39:57,729 main.py:47] epoch 1272, training loss: 1755.75, average training loss: 2128.44, base loss: 2614.43
[INFO 2017-06-26 18:39:58,034 main.py:47] epoch 1273, training loss: 2167.98, average training loss: 2128.20, base loss: 2614.35
[INFO 2017-06-26 18:39:58,338 main.py:47] epoch 1274, training loss: 1783.35, average training loss: 2128.04, base loss: 2614.48
[INFO 2017-06-26 18:39:58,642 main.py:47] epoch 1275, training loss: 1952.44, average training loss: 2127.73, base loss: 2614.45
[INFO 2017-06-26 18:39:58,948 main.py:47] epoch 1276, training loss: 2140.19, average training loss: 2127.65, base loss: 2614.55
[INFO 2017-06-26 18:39:59,253 main.py:47] epoch 1277, training loss: 1684.45, average training loss: 2127.19, base loss: 2614.23
[INFO 2017-06-26 18:39:59,556 main.py:47] epoch 1278, training loss: 2326.00, average training loss: 2127.06, base loss: 2614.53
[INFO 2017-06-26 18:39:59,860 main.py:47] epoch 1279, training loss: 2173.46, average training loss: 2127.18, base loss: 2615.00
[INFO 2017-06-26 18:40:00,165 main.py:47] epoch 1280, training loss: 1861.57, average training loss: 2126.79, base loss: 2614.78
[INFO 2017-06-26 18:40:00,469 main.py:47] epoch 1281, training loss: 1982.68, average training loss: 2126.09, base loss: 2614.37
[INFO 2017-06-26 18:40:00,778 main.py:47] epoch 1282, training loss: 2444.46, average training loss: 2126.26, base loss: 2614.93
[INFO 2017-06-26 18:40:01,087 main.py:47] epoch 1283, training loss: 1948.21, average training loss: 2125.62, base loss: 2614.49
[INFO 2017-06-26 18:40:01,392 main.py:47] epoch 1284, training loss: 1938.04, average training loss: 2125.41, base loss: 2614.45
[INFO 2017-06-26 18:40:01,704 main.py:47] epoch 1285, training loss: 2131.51, average training loss: 2125.27, base loss: 2614.61
[INFO 2017-06-26 18:40:02,014 main.py:47] epoch 1286, training loss: 2282.91, average training loss: 2125.29, base loss: 2614.65
[INFO 2017-06-26 18:40:02,322 main.py:47] epoch 1287, training loss: 2269.96, average training loss: 2125.36, base loss: 2615.03
[INFO 2017-06-26 18:40:02,631 main.py:47] epoch 1288, training loss: 2257.29, average training loss: 2125.57, base loss: 2615.86
[INFO 2017-06-26 18:40:02,938 main.py:47] epoch 1289, training loss: 1940.30, average training loss: 2125.06, base loss: 2615.32
[INFO 2017-06-26 18:40:03,245 main.py:47] epoch 1290, training loss: 1673.61, average training loss: 2124.74, base loss: 2615.11
[INFO 2017-06-26 18:40:03,554 main.py:47] epoch 1291, training loss: 2062.68, average training loss: 2124.67, base loss: 2615.20
[INFO 2017-06-26 18:40:03,862 main.py:47] epoch 1292, training loss: 2114.35, average training loss: 2124.52, base loss: 2615.36
[INFO 2017-06-26 18:40:04,175 main.py:47] epoch 1293, training loss: 1980.89, average training loss: 2124.23, base loss: 2615.25
[INFO 2017-06-26 18:40:04,482 main.py:47] epoch 1294, training loss: 1798.66, average training loss: 2123.80, base loss: 2615.01
[INFO 2017-06-26 18:40:04,790 main.py:47] epoch 1295, training loss: 1797.09, average training loss: 2123.08, base loss: 2614.47
[INFO 2017-06-26 18:40:05,097 main.py:47] epoch 1296, training loss: 2115.20, average training loss: 2122.94, base loss: 2614.50
[INFO 2017-06-26 18:40:05,403 main.py:47] epoch 1297, training loss: 2102.58, average training loss: 2122.82, base loss: 2614.56
[INFO 2017-06-26 18:40:05,713 main.py:47] epoch 1298, training loss: 2193.67, average training loss: 2122.56, base loss: 2614.69
[INFO 2017-06-26 18:40:06,020 main.py:47] epoch 1299, training loss: 1852.80, average training loss: 2122.36, base loss: 2614.74
[INFO 2017-06-26 18:40:06,020 main.py:49] epoch 1299, testing
[INFO 2017-06-26 18:40:09,985 main.py:100] average testing loss: 2121.39, base loss: 2746.64
[INFO 2017-06-26 18:40:10,011 main.py:73] current best accuracy: 2017.92
[INFO 2017-06-26 18:40:10,319 main.py:47] epoch 1300, training loss: 2133.48, average training loss: 2122.36, base loss: 2615.19
[INFO 2017-06-26 18:40:10,625 main.py:47] epoch 1301, training loss: 2278.90, average training loss: 2122.62, base loss: 2615.72
[INFO 2017-06-26 18:40:10,931 main.py:47] epoch 1302, training loss: 2012.46, average training loss: 2121.56, base loss: 2614.78
[INFO 2017-06-26 18:40:11,237 main.py:47] epoch 1303, training loss: 1958.87, average training loss: 2121.52, base loss: 2614.99
[INFO 2017-06-26 18:40:11,544 main.py:47] epoch 1304, training loss: 1974.97, average training loss: 2121.61, base loss: 2615.52
[INFO 2017-06-26 18:40:11,851 main.py:47] epoch 1305, training loss: 1943.49, average training loss: 2120.93, base loss: 2614.93
[INFO 2017-06-26 18:40:12,160 main.py:47] epoch 1306, training loss: 1852.09, average training loss: 2120.31, base loss: 2614.39
[INFO 2017-06-26 18:40:12,468 main.py:47] epoch 1307, training loss: 2276.92, average training loss: 2120.39, base loss: 2614.71
[INFO 2017-06-26 18:40:12,773 main.py:47] epoch 1308, training loss: 1969.55, average training loss: 2119.97, base loss: 2614.41
[INFO 2017-06-26 18:40:13,078 main.py:47] epoch 1309, training loss: 1981.27, average training loss: 2119.81, base loss: 2614.47
[INFO 2017-06-26 18:40:13,385 main.py:47] epoch 1310, training loss: 2096.26, average training loss: 2119.68, base loss: 2614.55
[INFO 2017-06-26 18:40:13,690 main.py:47] epoch 1311, training loss: 2255.23, average training loss: 2119.57, base loss: 2614.63
[INFO 2017-06-26 18:40:13,998 main.py:47] epoch 1312, training loss: 1871.62, average training loss: 2119.17, base loss: 2614.21
[INFO 2017-06-26 18:40:14,303 main.py:47] epoch 1313, training loss: 2666.62, average training loss: 2119.49, base loss: 2614.75
[INFO 2017-06-26 18:40:14,611 main.py:47] epoch 1314, training loss: 1808.85, average training loss: 2119.33, base loss: 2614.75
[INFO 2017-06-26 18:40:14,917 main.py:47] epoch 1315, training loss: 2267.07, average training loss: 2119.22, base loss: 2614.90
[INFO 2017-06-26 18:40:15,227 main.py:47] epoch 1316, training loss: 1903.52, average training loss: 2118.94, base loss: 2614.84
[INFO 2017-06-26 18:40:15,537 main.py:47] epoch 1317, training loss: 2237.01, average training loss: 2119.06, base loss: 2615.38
[INFO 2017-06-26 18:40:15,844 main.py:47] epoch 1318, training loss: 2007.73, average training loss: 2118.84, base loss: 2615.43
[INFO 2017-06-26 18:40:16,148 main.py:47] epoch 1319, training loss: 2085.50, average training loss: 2118.60, base loss: 2615.54
[INFO 2017-06-26 18:40:16,451 main.py:47] epoch 1320, training loss: 2129.28, average training loss: 2118.46, base loss: 2615.72
[INFO 2017-06-26 18:40:16,752 main.py:47] epoch 1321, training loss: 2106.99, average training loss: 2118.41, base loss: 2615.88
[INFO 2017-06-26 18:40:17,057 main.py:47] epoch 1322, training loss: 1922.22, average training loss: 2117.95, base loss: 2615.61
[INFO 2017-06-26 18:40:17,361 main.py:47] epoch 1323, training loss: 2199.83, average training loss: 2117.70, base loss: 2615.39
[INFO 2017-06-26 18:40:17,669 main.py:47] epoch 1324, training loss: 2068.18, average training loss: 2117.72, base loss: 2615.67
[INFO 2017-06-26 18:40:17,976 main.py:47] epoch 1325, training loss: 2240.38, average training loss: 2117.91, base loss: 2616.00
[INFO 2017-06-26 18:40:18,281 main.py:47] epoch 1326, training loss: 2064.81, average training loss: 2118.11, base loss: 2616.52
[INFO 2017-06-26 18:40:18,587 main.py:47] epoch 1327, training loss: 2044.72, average training loss: 2117.75, base loss: 2616.27
[INFO 2017-06-26 18:40:18,893 main.py:47] epoch 1328, training loss: 1971.71, average training loss: 2117.81, base loss: 2616.56
[INFO 2017-06-26 18:40:19,202 main.py:47] epoch 1329, training loss: 2127.43, average training loss: 2117.55, base loss: 2616.33
[INFO 2017-06-26 18:40:19,506 main.py:47] epoch 1330, training loss: 2032.26, average training loss: 2117.29, base loss: 2616.44
[INFO 2017-06-26 18:40:19,814 main.py:47] epoch 1331, training loss: 2256.12, average training loss: 2117.24, base loss: 2616.87
[INFO 2017-06-26 18:40:20,121 main.py:47] epoch 1332, training loss: 2172.80, average training loss: 2116.84, base loss: 2616.65
[INFO 2017-06-26 18:40:20,428 main.py:47] epoch 1333, training loss: 2011.31, average training loss: 2116.52, base loss: 2616.65
[INFO 2017-06-26 18:40:20,735 main.py:47] epoch 1334, training loss: 2378.16, average training loss: 2117.11, base loss: 2618.03
[INFO 2017-06-26 18:40:21,044 main.py:47] epoch 1335, training loss: 1907.20, average training loss: 2116.94, base loss: 2618.10
[INFO 2017-06-26 18:40:21,353 main.py:47] epoch 1336, training loss: 2094.57, average training loss: 2116.47, base loss: 2617.67
[INFO 2017-06-26 18:40:21,656 main.py:47] epoch 1337, training loss: 1873.42, average training loss: 2116.14, base loss: 2617.41
[INFO 2017-06-26 18:40:21,961 main.py:47] epoch 1338, training loss: 1986.33, average training loss: 2116.11, base loss: 2617.54
[INFO 2017-06-26 18:40:22,266 main.py:47] epoch 1339, training loss: 2106.58, average training loss: 2115.91, base loss: 2617.59
[INFO 2017-06-26 18:40:22,572 main.py:47] epoch 1340, training loss: 2071.56, average training loss: 2115.87, base loss: 2617.72
[INFO 2017-06-26 18:40:22,879 main.py:47] epoch 1341, training loss: 2135.95, average training loss: 2116.16, base loss: 2618.07
[INFO 2017-06-26 18:40:23,187 main.py:47] epoch 1342, training loss: 2275.47, average training loss: 2115.98, base loss: 2618.14
[INFO 2017-06-26 18:40:23,495 main.py:47] epoch 1343, training loss: 2014.30, average training loss: 2115.43, base loss: 2617.85
[INFO 2017-06-26 18:40:23,802 main.py:47] epoch 1344, training loss: 1713.93, average training loss: 2114.96, base loss: 2617.42
[INFO 2017-06-26 18:40:24,110 main.py:47] epoch 1345, training loss: 2365.65, average training loss: 2115.34, base loss: 2618.07
[INFO 2017-06-26 18:40:24,414 main.py:47] epoch 1346, training loss: 1826.73, average training loss: 2115.07, base loss: 2618.01
[INFO 2017-06-26 18:40:24,724 main.py:47] epoch 1347, training loss: 2038.36, average training loss: 2114.89, base loss: 2617.63
[INFO 2017-06-26 18:40:25,033 main.py:47] epoch 1348, training loss: 1928.00, average training loss: 2114.78, base loss: 2617.65
[INFO 2017-06-26 18:40:25,345 main.py:47] epoch 1349, training loss: 2011.15, average training loss: 2114.84, base loss: 2617.93
[INFO 2017-06-26 18:40:25,654 main.py:47] epoch 1350, training loss: 1774.55, average training loss: 2114.30, base loss: 2617.58
[INFO 2017-06-26 18:40:25,964 main.py:47] epoch 1351, training loss: 1649.01, average training loss: 2113.78, base loss: 2617.27
[INFO 2017-06-26 18:40:26,271 main.py:47] epoch 1352, training loss: 2022.82, average training loss: 2113.66, base loss: 2617.46
[INFO 2017-06-26 18:40:26,580 main.py:47] epoch 1353, training loss: 2174.63, average training loss: 2113.47, base loss: 2617.49
[INFO 2017-06-26 18:40:26,887 main.py:47] epoch 1354, training loss: 1883.83, average training loss: 2113.37, base loss: 2617.70
[INFO 2017-06-26 18:40:27,193 main.py:47] epoch 1355, training loss: 2148.12, average training loss: 2113.21, base loss: 2617.83
[INFO 2017-06-26 18:40:27,499 main.py:47] epoch 1356, training loss: 1933.84, average training loss: 2112.62, base loss: 2617.21
[INFO 2017-06-26 18:40:27,807 main.py:47] epoch 1357, training loss: 1900.11, average training loss: 2112.24, base loss: 2617.11
[INFO 2017-06-26 18:40:28,114 main.py:47] epoch 1358, training loss: 2207.25, average training loss: 2112.10, base loss: 2617.15
[INFO 2017-06-26 18:40:28,420 main.py:47] epoch 1359, training loss: 1978.84, average training loss: 2111.97, base loss: 2617.08
[INFO 2017-06-26 18:40:28,728 main.py:47] epoch 1360, training loss: 2273.22, average training loss: 2112.05, base loss: 2617.46
[INFO 2017-06-26 18:40:29,035 main.py:47] epoch 1361, training loss: 2142.06, average training loss: 2112.09, base loss: 2617.93
[INFO 2017-06-26 18:40:29,340 main.py:47] epoch 1362, training loss: 1907.99, average training loss: 2111.98, base loss: 2617.85
[INFO 2017-06-26 18:40:29,649 main.py:47] epoch 1363, training loss: 2288.84, average training loss: 2112.18, base loss: 2618.57
[INFO 2017-06-26 18:40:29,956 main.py:47] epoch 1364, training loss: 1886.32, average training loss: 2111.84, base loss: 2618.48
[INFO 2017-06-26 18:40:30,264 main.py:47] epoch 1365, training loss: 2069.06, average training loss: 2111.92, base loss: 2619.03
[INFO 2017-06-26 18:40:30,572 main.py:47] epoch 1366, training loss: 1816.82, average training loss: 2111.72, base loss: 2619.12
[INFO 2017-06-26 18:40:30,880 main.py:47] epoch 1367, training loss: 2158.64, average training loss: 2111.40, base loss: 2619.02
[INFO 2017-06-26 18:40:31,186 main.py:47] epoch 1368, training loss: 1795.83, average training loss: 2111.27, base loss: 2618.75
[INFO 2017-06-26 18:40:31,492 main.py:47] epoch 1369, training loss: 1932.60, average training loss: 2110.86, base loss: 2618.50
[INFO 2017-06-26 18:40:31,800 main.py:47] epoch 1370, training loss: 2025.90, average training loss: 2110.58, base loss: 2618.54
[INFO 2017-06-26 18:40:32,104 main.py:47] epoch 1371, training loss: 1920.82, average training loss: 2110.08, base loss: 2618.07
[INFO 2017-06-26 18:40:32,410 main.py:47] epoch 1372, training loss: 1770.96, average training loss: 2109.46, base loss: 2617.59
[INFO 2017-06-26 18:40:32,717 main.py:47] epoch 1373, training loss: 1823.98, average training loss: 2108.82, base loss: 2616.97
[INFO 2017-06-26 18:40:33,024 main.py:47] epoch 1374, training loss: 2236.67, average training loss: 2108.93, base loss: 2617.07
[INFO 2017-06-26 18:40:33,328 main.py:47] epoch 1375, training loss: 2152.44, average training loss: 2108.68, base loss: 2617.04
[INFO 2017-06-26 18:40:33,636 main.py:47] epoch 1376, training loss: 1863.29, average training loss: 2108.45, base loss: 2616.99
[INFO 2017-06-26 18:40:33,942 main.py:47] epoch 1377, training loss: 2010.23, average training loss: 2108.04, base loss: 2616.85
[INFO 2017-06-26 18:40:34,254 main.py:47] epoch 1378, training loss: 1948.11, average training loss: 2107.31, base loss: 2616.29
[INFO 2017-06-26 18:40:34,561 main.py:47] epoch 1379, training loss: 2047.88, average training loss: 2107.04, base loss: 2616.12
[INFO 2017-06-26 18:40:34,872 main.py:47] epoch 1380, training loss: 1828.67, average training loss: 2106.49, base loss: 2615.55
[INFO 2017-06-26 18:40:35,181 main.py:47] epoch 1381, training loss: 1897.28, average training loss: 2106.28, base loss: 2615.08
[INFO 2017-06-26 18:40:35,492 main.py:47] epoch 1382, training loss: 2238.92, average training loss: 2105.98, base loss: 2614.82
[INFO 2017-06-26 18:40:35,800 main.py:47] epoch 1383, training loss: 2501.01, average training loss: 2106.31, base loss: 2615.70
[INFO 2017-06-26 18:40:36,107 main.py:47] epoch 1384, training loss: 1893.60, average training loss: 2106.06, base loss: 2615.69
[INFO 2017-06-26 18:40:36,416 main.py:47] epoch 1385, training loss: 1993.80, average training loss: 2105.67, base loss: 2615.34
[INFO 2017-06-26 18:40:36,724 main.py:47] epoch 1386, training loss: 1974.24, average training loss: 2105.22, base loss: 2615.00
[INFO 2017-06-26 18:40:37,028 main.py:47] epoch 1387, training loss: 1952.20, average training loss: 2104.39, base loss: 2614.26
[INFO 2017-06-26 18:40:37,334 main.py:47] epoch 1388, training loss: 2013.80, average training loss: 2103.89, base loss: 2614.04
[INFO 2017-06-26 18:40:37,641 main.py:47] epoch 1389, training loss: 1997.80, average training loss: 2103.38, base loss: 2613.64
[INFO 2017-06-26 18:40:37,947 main.py:47] epoch 1390, training loss: 1918.78, average training loss: 2102.89, base loss: 2613.20
[INFO 2017-06-26 18:40:38,257 main.py:47] epoch 1391, training loss: 1776.06, average training loss: 2102.57, base loss: 2613.09
[INFO 2017-06-26 18:40:38,567 main.py:47] epoch 1392, training loss: 1925.35, average training loss: 2102.46, base loss: 2612.87
[INFO 2017-06-26 18:40:38,875 main.py:47] epoch 1393, training loss: 1840.57, average training loss: 2102.35, base loss: 2612.95
[INFO 2017-06-26 18:40:39,184 main.py:47] epoch 1394, training loss: 2512.00, average training loss: 2102.69, base loss: 2613.70
[INFO 2017-06-26 18:40:39,492 main.py:47] epoch 1395, training loss: 1928.54, average training loss: 2102.42, base loss: 2613.55
[INFO 2017-06-26 18:40:39,801 main.py:47] epoch 1396, training loss: 2277.17, average training loss: 2102.20, base loss: 2613.49
[INFO 2017-06-26 18:40:40,106 main.py:47] epoch 1397, training loss: 1908.12, average training loss: 2101.78, base loss: 2613.31
[INFO 2017-06-26 18:40:40,415 main.py:47] epoch 1398, training loss: 2057.31, average training loss: 2101.77, base loss: 2613.55
[INFO 2017-06-26 18:40:40,723 main.py:47] epoch 1399, training loss: 2024.94, average training loss: 2101.62, base loss: 2613.71
[INFO 2017-06-26 18:40:40,723 main.py:49] epoch 1399, testing
[INFO 2017-06-26 18:40:44,684 main.py:100] average testing loss: 2162.05, base loss: 2874.84
[INFO 2017-06-26 18:40:44,710 main.py:73] current best accuracy: 2017.92
[INFO 2017-06-26 18:40:45,021 main.py:47] epoch 1400, training loss: 2340.82, average training loss: 2101.55, base loss: 2613.85
[INFO 2017-06-26 18:40:45,328 main.py:47] epoch 1401, training loss: 2183.16, average training loss: 2101.95, base loss: 2614.61
[INFO 2017-06-26 18:40:45,633 main.py:47] epoch 1402, training loss: 1805.98, average training loss: 2101.79, base loss: 2614.55
[INFO 2017-06-26 18:40:45,940 main.py:47] epoch 1403, training loss: 1752.97, average training loss: 2101.67, base loss: 2614.53
[INFO 2017-06-26 18:40:46,245 main.py:47] epoch 1404, training loss: 1990.35, average training loss: 2101.36, base loss: 2614.23
[INFO 2017-06-26 18:40:46,552 main.py:47] epoch 1405, training loss: 1951.04, average training loss: 2101.29, base loss: 2614.29
[INFO 2017-06-26 18:40:46,859 main.py:47] epoch 1406, training loss: 2218.49, average training loss: 2101.27, base loss: 2614.27
[INFO 2017-06-26 18:40:47,164 main.py:47] epoch 1407, training loss: 1783.62, average training loss: 2100.70, base loss: 2613.68
[INFO 2017-06-26 18:40:47,468 main.py:47] epoch 1408, training loss: 2083.43, average training loss: 2100.69, base loss: 2613.97
[INFO 2017-06-26 18:40:47,774 main.py:47] epoch 1409, training loss: 1913.80, average training loss: 2100.10, base loss: 2613.47
[INFO 2017-06-26 18:40:48,084 main.py:47] epoch 1410, training loss: 2113.50, average training loss: 2099.55, base loss: 2613.02
[INFO 2017-06-26 18:40:48,391 main.py:47] epoch 1411, training loss: 1850.78, average training loss: 2098.85, base loss: 2612.40
[INFO 2017-06-26 18:40:48,696 main.py:47] epoch 1412, training loss: 1766.23, average training loss: 2098.36, base loss: 2612.08
[INFO 2017-06-26 18:40:49,000 main.py:47] epoch 1413, training loss: 2331.80, average training loss: 2098.66, base loss: 2612.70
[INFO 2017-06-26 18:40:49,307 main.py:47] epoch 1414, training loss: 1640.31, average training loss: 2098.40, base loss: 2612.76
[INFO 2017-06-26 18:40:49,613 main.py:47] epoch 1415, training loss: 2148.82, average training loss: 2098.39, base loss: 2612.97
[INFO 2017-06-26 18:40:49,922 main.py:47] epoch 1416, training loss: 2290.59, average training loss: 2098.70, base loss: 2613.67
[INFO 2017-06-26 18:40:50,229 main.py:47] epoch 1417, training loss: 1752.89, average training loss: 2098.54, base loss: 2613.60
[INFO 2017-06-26 18:40:50,538 main.py:47] epoch 1418, training loss: 1837.84, average training loss: 2098.52, base loss: 2613.71
[INFO 2017-06-26 18:40:50,844 main.py:47] epoch 1419, training loss: 1745.67, average training loss: 2097.73, base loss: 2612.85
[INFO 2017-06-26 18:40:51,151 main.py:47] epoch 1420, training loss: 1851.72, average training loss: 2097.33, base loss: 2612.43
[INFO 2017-06-26 18:40:51,459 main.py:47] epoch 1421, training loss: 2136.39, average training loss: 2097.27, base loss: 2612.55
[INFO 2017-06-26 18:40:51,767 main.py:47] epoch 1422, training loss: 2410.43, average training loss: 2097.20, base loss: 2612.94
[INFO 2017-06-26 18:40:52,075 main.py:47] epoch 1423, training loss: 1852.56, average training loss: 2096.75, base loss: 2612.59
[INFO 2017-06-26 18:40:52,382 main.py:47] epoch 1424, training loss: 1979.70, average training loss: 2096.57, base loss: 2612.62
[INFO 2017-06-26 18:40:52,693 main.py:47] epoch 1425, training loss: 2291.97, average training loss: 2096.77, base loss: 2613.14
[INFO 2017-06-26 18:40:53,000 main.py:47] epoch 1426, training loss: 2074.20, average training loss: 2096.63, base loss: 2613.18
[INFO 2017-06-26 18:40:53,305 main.py:47] epoch 1427, training loss: 2091.49, average training loss: 2096.55, base loss: 2613.35
[INFO 2017-06-26 18:40:53,614 main.py:47] epoch 1428, training loss: 1977.58, average training loss: 2096.12, base loss: 2613.14
[INFO 2017-06-26 18:40:53,919 main.py:47] epoch 1429, training loss: 1889.97, average training loss: 2095.63, base loss: 2612.54
[INFO 2017-06-26 18:40:54,223 main.py:47] epoch 1430, training loss: 1669.96, average training loss: 2095.11, base loss: 2611.89
[INFO 2017-06-26 18:40:54,530 main.py:47] epoch 1431, training loss: 2257.29, average training loss: 2095.31, base loss: 2612.18
[INFO 2017-06-26 18:40:54,837 main.py:47] epoch 1432, training loss: 1698.71, average training loss: 2094.73, base loss: 2611.37
[INFO 2017-06-26 18:40:55,143 main.py:47] epoch 1433, training loss: 1777.81, average training loss: 2094.22, base loss: 2610.83
[INFO 2017-06-26 18:40:55,451 main.py:47] epoch 1434, training loss: 2060.61, average training loss: 2094.12, base loss: 2610.65
[INFO 2017-06-26 18:40:55,757 main.py:47] epoch 1435, training loss: 2197.24, average training loss: 2094.42, base loss: 2610.96
[INFO 2017-06-26 18:40:56,063 main.py:47] epoch 1436, training loss: 1887.91, average training loss: 2094.16, base loss: 2610.78
[INFO 2017-06-26 18:40:56,367 main.py:47] epoch 1437, training loss: 2015.20, average training loss: 2094.05, base loss: 2610.77
[INFO 2017-06-26 18:40:56,673 main.py:47] epoch 1438, training loss: 2099.54, average training loss: 2093.96, base loss: 2610.76
[INFO 2017-06-26 18:40:56,981 main.py:47] epoch 1439, training loss: 2370.71, average training loss: 2094.28, base loss: 2611.45
[INFO 2017-06-26 18:40:57,285 main.py:47] epoch 1440, training loss: 1879.02, average training loss: 2094.11, base loss: 2611.49
[INFO 2017-06-26 18:40:57,593 main.py:47] epoch 1441, training loss: 2015.29, average training loss: 2094.21, base loss: 2611.87
[INFO 2017-06-26 18:40:57,900 main.py:47] epoch 1442, training loss: 1836.26, average training loss: 2094.09, base loss: 2611.81
[INFO 2017-06-26 18:40:58,206 main.py:47] epoch 1443, training loss: 1904.94, average training loss: 2093.87, base loss: 2611.38
[INFO 2017-06-26 18:40:58,510 main.py:47] epoch 1444, training loss: 2220.72, average training loss: 2093.65, base loss: 2611.40
[INFO 2017-06-26 18:40:58,815 main.py:47] epoch 1445, training loss: 2123.48, average training loss: 2093.56, base loss: 2611.57
[INFO 2017-06-26 18:40:59,122 main.py:47] epoch 1446, training loss: 1977.13, average training loss: 2093.38, base loss: 2611.50
[INFO 2017-06-26 18:40:59,427 main.py:47] epoch 1447, training loss: 2326.78, average training loss: 2093.44, base loss: 2611.57
[INFO 2017-06-26 18:40:59,735 main.py:47] epoch 1448, training loss: 2235.18, average training loss: 2093.37, base loss: 2611.76
[INFO 2017-06-26 18:41:00,038 main.py:47] epoch 1449, training loss: 2038.21, average training loss: 2093.11, base loss: 2611.65
[INFO 2017-06-26 18:41:00,343 main.py:47] epoch 1450, training loss: 2016.04, average training loss: 2092.53, base loss: 2610.95
[INFO 2017-06-26 18:41:00,651 main.py:47] epoch 1451, training loss: 1994.60, average training loss: 2092.54, base loss: 2611.30
[INFO 2017-06-26 18:41:00,955 main.py:47] epoch 1452, training loss: 2220.72, average training loss: 2092.24, base loss: 2611.02
[INFO 2017-06-26 18:41:01,259 main.py:47] epoch 1453, training loss: 2375.26, average training loss: 2092.55, base loss: 2611.81
[INFO 2017-06-26 18:41:01,569 main.py:47] epoch 1454, training loss: 2101.75, average training loss: 2092.25, base loss: 2611.75
[INFO 2017-06-26 18:41:01,876 main.py:47] epoch 1455, training loss: 1908.44, average training loss: 2092.17, base loss: 2611.65
[INFO 2017-06-26 18:41:02,184 main.py:47] epoch 1456, training loss: 1919.99, average training loss: 2091.90, base loss: 2611.57
[INFO 2017-06-26 18:41:02,490 main.py:47] epoch 1457, training loss: 2002.36, average training loss: 2091.40, base loss: 2611.15
[INFO 2017-06-26 18:41:02,799 main.py:47] epoch 1458, training loss: 1883.47, average training loss: 2090.80, base loss: 2610.38
[INFO 2017-06-26 18:41:03,103 main.py:47] epoch 1459, training loss: 1923.22, average training loss: 2090.34, base loss: 2609.71
[INFO 2017-06-26 18:41:03,412 main.py:47] epoch 1460, training loss: 2212.25, average training loss: 2090.51, base loss: 2610.01
[INFO 2017-06-26 18:41:03,721 main.py:47] epoch 1461, training loss: 1845.22, average training loss: 2089.90, base loss: 2609.50
[INFO 2017-06-26 18:41:04,026 main.py:47] epoch 1462, training loss: 1980.86, average training loss: 2089.10, base loss: 2608.73
[INFO 2017-06-26 18:41:04,333 main.py:47] epoch 1463, training loss: 2034.88, average training loss: 2088.71, base loss: 2608.40
[INFO 2017-06-26 18:41:04,640 main.py:47] epoch 1464, training loss: 2252.09, average training loss: 2088.86, base loss: 2608.73
[INFO 2017-06-26 18:41:04,946 main.py:47] epoch 1465, training loss: 1837.67, average training loss: 2088.52, base loss: 2608.49
[INFO 2017-06-26 18:41:05,253 main.py:47] epoch 1466, training loss: 2375.51, average training loss: 2088.69, base loss: 2608.96
[INFO 2017-06-26 18:41:05,562 main.py:47] epoch 1467, training loss: 1711.48, average training loss: 2088.15, base loss: 2608.39
[INFO 2017-06-26 18:41:05,866 main.py:47] epoch 1468, training loss: 1943.51, average training loss: 2087.65, base loss: 2607.70
[INFO 2017-06-26 18:41:06,177 main.py:47] epoch 1469, training loss: 2084.70, average training loss: 2087.39, base loss: 2607.59
[INFO 2017-06-26 18:41:06,482 main.py:47] epoch 1470, training loss: 2146.36, average training loss: 2087.53, base loss: 2608.11
[INFO 2017-06-26 18:41:06,789 main.py:47] epoch 1471, training loss: 2324.94, average training loss: 2088.01, base loss: 2608.75
[INFO 2017-06-26 18:41:07,094 main.py:47] epoch 1472, training loss: 1906.74, average training loss: 2087.53, base loss: 2608.38
[INFO 2017-06-26 18:41:07,398 main.py:47] epoch 1473, training loss: 1961.90, average training loss: 2087.42, base loss: 2608.48
[INFO 2017-06-26 18:41:07,706 main.py:47] epoch 1474, training loss: 2049.30, average training loss: 2087.06, base loss: 2608.22
[INFO 2017-06-26 18:41:08,014 main.py:47] epoch 1475, training loss: 1807.46, average training loss: 2086.57, base loss: 2607.68
[INFO 2017-06-26 18:41:08,322 main.py:47] epoch 1476, training loss: 2174.51, average training loss: 2086.71, base loss: 2607.98
[INFO 2017-06-26 18:41:08,629 main.py:47] epoch 1477, training loss: 1800.65, average training loss: 2086.41, base loss: 2607.73
[INFO 2017-06-26 18:41:08,934 main.py:47] epoch 1478, training loss: 2455.05, average training loss: 2086.82, base loss: 2608.50
[INFO 2017-06-26 18:41:09,239 main.py:47] epoch 1479, training loss: 2048.54, average training loss: 2086.54, base loss: 2608.49
[INFO 2017-06-26 18:41:09,547 main.py:47] epoch 1480, training loss: 2009.39, average training loss: 2086.08, base loss: 2607.84
[INFO 2017-06-26 18:41:09,854 main.py:47] epoch 1481, training loss: 2339.35, average training loss: 2086.09, base loss: 2608.11
[INFO 2017-06-26 18:41:10,163 main.py:47] epoch 1482, training loss: 2145.94, average training loss: 2085.87, base loss: 2608.22
[INFO 2017-06-26 18:41:10,469 main.py:47] epoch 1483, training loss: 2150.43, average training loss: 2086.05, base loss: 2608.67
[INFO 2017-06-26 18:41:10,776 main.py:47] epoch 1484, training loss: 1776.09, average training loss: 2085.81, base loss: 2608.54
[INFO 2017-06-26 18:41:11,082 main.py:47] epoch 1485, training loss: 2080.75, average training loss: 2085.93, base loss: 2608.71
[INFO 2017-06-26 18:41:11,386 main.py:47] epoch 1486, training loss: 1889.83, average training loss: 2085.62, base loss: 2608.53
[INFO 2017-06-26 18:41:11,696 main.py:47] epoch 1487, training loss: 1910.94, average training loss: 2085.55, base loss: 2608.69
[INFO 2017-06-26 18:41:12,000 main.py:47] epoch 1488, training loss: 1904.65, average training loss: 2085.07, base loss: 2608.24
[INFO 2017-06-26 18:41:12,305 main.py:47] epoch 1489, training loss: 2311.37, average training loss: 2085.23, base loss: 2608.82
[INFO 2017-06-26 18:41:12,613 main.py:47] epoch 1490, training loss: 2074.00, average training loss: 2084.56, base loss: 2608.33
[INFO 2017-06-26 18:41:12,921 main.py:47] epoch 1491, training loss: 2036.61, average training loss: 2084.29, base loss: 2608.28
[INFO 2017-06-26 18:41:13,227 main.py:47] epoch 1492, training loss: 1930.64, average training loss: 2083.99, base loss: 2608.24
[INFO 2017-06-26 18:41:13,531 main.py:47] epoch 1493, training loss: 1933.61, average training loss: 2083.81, base loss: 2608.29
[INFO 2017-06-26 18:41:13,836 main.py:47] epoch 1494, training loss: 1923.19, average training loss: 2083.10, base loss: 2607.46
[INFO 2017-06-26 18:41:14,141 main.py:47] epoch 1495, training loss: 1843.76, average training loss: 2082.92, base loss: 2607.36
[INFO 2017-06-26 18:41:14,448 main.py:47] epoch 1496, training loss: 2382.74, average training loss: 2083.03, base loss: 2607.84
[INFO 2017-06-26 18:41:14,757 main.py:47] epoch 1497, training loss: 1930.27, average training loss: 2082.84, base loss: 2607.72
[INFO 2017-06-26 18:41:15,064 main.py:47] epoch 1498, training loss: 1926.70, average training loss: 2082.70, base loss: 2607.70
[INFO 2017-06-26 18:41:15,369 main.py:47] epoch 1499, training loss: 1899.61, average training loss: 2082.52, base loss: 2607.79
[INFO 2017-06-26 18:41:15,369 main.py:49] epoch 1499, testing
[INFO 2017-06-26 18:41:19,344 main.py:100] average testing loss: 2088.16, base loss: 2729.71
[INFO 2017-06-26 18:41:19,370 main.py:73] current best accuracy: 2017.92
[INFO 2017-06-26 18:41:19,679 main.py:47] epoch 1500, training loss: 1996.41, average training loss: 2081.95, base loss: 2607.32
[INFO 2017-06-26 18:41:19,988 main.py:47] epoch 1501, training loss: 2201.39, average training loss: 2082.06, base loss: 2607.88
[INFO 2017-06-26 18:41:20,296 main.py:47] epoch 1502, training loss: 1960.20, average training loss: 2081.45, base loss: 2607.22
[INFO 2017-06-26 18:41:20,605 main.py:47] epoch 1503, training loss: 1955.39, average training loss: 2081.20, base loss: 2607.00
[INFO 2017-06-26 18:41:20,911 main.py:47] epoch 1504, training loss: 2446.65, average training loss: 2081.51, base loss: 2607.81
[INFO 2017-06-26 18:41:21,224 main.py:47] epoch 1505, training loss: 1783.62, average training loss: 2081.00, base loss: 2607.17
[INFO 2017-06-26 18:41:21,534 main.py:47] epoch 1506, training loss: 1586.98, average training loss: 2079.90, base loss: 2605.84
[INFO 2017-06-26 18:41:21,844 main.py:47] epoch 1507, training loss: 1990.03, average training loss: 2079.83, base loss: 2606.01
[INFO 2017-06-26 18:41:22,150 main.py:47] epoch 1508, training loss: 1986.44, average training loss: 2079.39, base loss: 2605.65
[INFO 2017-06-26 18:41:22,460 main.py:47] epoch 1509, training loss: 1943.72, average training loss: 2079.11, base loss: 2605.58
[INFO 2017-06-26 18:41:22,767 main.py:47] epoch 1510, training loss: 1907.48, average training loss: 2078.86, base loss: 2605.55
[INFO 2017-06-26 18:41:23,076 main.py:47] epoch 1511, training loss: 1791.97, average training loss: 2078.36, base loss: 2605.24
[INFO 2017-06-26 18:41:23,391 main.py:47] epoch 1512, training loss: 1822.84, average training loss: 2078.36, base loss: 2605.34
[INFO 2017-06-26 18:41:23,699 main.py:47] epoch 1513, training loss: 1970.96, average training loss: 2078.31, base loss: 2605.44
[INFO 2017-06-26 18:41:24,006 main.py:47] epoch 1514, training loss: 1992.14, average training loss: 2077.92, base loss: 2605.05
[INFO 2017-06-26 18:41:24,313 main.py:47] epoch 1515, training loss: 2179.31, average training loss: 2077.95, base loss: 2605.51
[INFO 2017-06-26 18:41:24,618 main.py:47] epoch 1516, training loss: 1910.74, average training loss: 2077.66, base loss: 2605.36
[INFO 2017-06-26 18:41:24,925 main.py:47] epoch 1517, training loss: 2096.08, average training loss: 2077.19, base loss: 2604.84
[INFO 2017-06-26 18:41:25,229 main.py:47] epoch 1518, training loss: 2386.05, average training loss: 2077.46, base loss: 2605.18
[INFO 2017-06-26 18:41:25,533 main.py:47] epoch 1519, training loss: 2002.92, average training loss: 2077.33, base loss: 2605.21
[INFO 2017-06-26 18:41:25,837 main.py:47] epoch 1520, training loss: 2474.84, average training loss: 2077.86, base loss: 2606.09
[INFO 2017-06-26 18:41:26,141 main.py:47] epoch 1521, training loss: 2069.03, average training loss: 2077.68, base loss: 2606.28
[INFO 2017-06-26 18:41:26,447 main.py:47] epoch 1522, training loss: 2037.07, average training loss: 2077.03, base loss: 2605.64
[INFO 2017-06-26 18:41:26,761 main.py:47] epoch 1523, training loss: 1909.12, average training loss: 2076.74, base loss: 2605.36
[INFO 2017-06-26 18:41:27,069 main.py:47] epoch 1524, training loss: 1776.30, average training loss: 2076.38, base loss: 2604.73
[INFO 2017-06-26 18:41:27,373 main.py:47] epoch 1525, training loss: 2093.72, average training loss: 2076.30, base loss: 2604.95
[INFO 2017-06-26 18:41:27,683 main.py:47] epoch 1526, training loss: 2161.42, average training loss: 2076.31, base loss: 2605.22
[INFO 2017-06-26 18:41:27,990 main.py:47] epoch 1527, training loss: 1983.31, average training loss: 2076.26, base loss: 2605.22
[INFO 2017-06-26 18:41:28,299 main.py:47] epoch 1528, training loss: 2033.15, average training loss: 2076.01, base loss: 2605.02
[INFO 2017-06-26 18:41:28,603 main.py:47] epoch 1529, training loss: 1744.43, average training loss: 2075.39, base loss: 2604.40
[INFO 2017-06-26 18:41:28,909 main.py:47] epoch 1530, training loss: 1899.85, average training loss: 2075.09, base loss: 2603.94
[INFO 2017-06-26 18:41:29,213 main.py:47] epoch 1531, training loss: 2321.19, average training loss: 2075.43, base loss: 2604.56
[INFO 2017-06-26 18:41:29,517 main.py:47] epoch 1532, training loss: 2045.75, average training loss: 2075.07, base loss: 2604.51
[INFO 2017-06-26 18:41:29,826 main.py:47] epoch 1533, training loss: 2084.73, average training loss: 2074.73, base loss: 2604.13
[INFO 2017-06-26 18:41:30,133 main.py:47] epoch 1534, training loss: 2020.50, average training loss: 2074.71, base loss: 2604.34
[INFO 2017-06-26 18:41:30,439 main.py:47] epoch 1535, training loss: 2002.26, average training loss: 2074.62, base loss: 2604.57
[INFO 2017-06-26 18:41:30,746 main.py:47] epoch 1536, training loss: 1898.60, average training loss: 2074.50, base loss: 2604.70
[INFO 2017-06-26 18:41:31,050 main.py:47] epoch 1537, training loss: 2165.27, average training loss: 2074.65, base loss: 2604.99
[INFO 2017-06-26 18:41:31,358 main.py:47] epoch 1538, training loss: 1913.38, average training loss: 2074.22, base loss: 2604.62
[INFO 2017-06-26 18:41:31,665 main.py:47] epoch 1539, training loss: 1902.35, average training loss: 2073.46, base loss: 2603.94
[INFO 2017-06-26 18:41:31,970 main.py:47] epoch 1540, training loss: 2380.05, average training loss: 2073.54, base loss: 2604.30
[INFO 2017-06-26 18:41:32,273 main.py:47] epoch 1541, training loss: 2306.31, average training loss: 2073.83, base loss: 2605.14
[INFO 2017-06-26 18:41:32,576 main.py:47] epoch 1542, training loss: 2024.00, average training loss: 2073.57, base loss: 2605.01
[INFO 2017-06-26 18:41:32,882 main.py:47] epoch 1543, training loss: 2049.89, average training loss: 2073.35, base loss: 2605.22
[INFO 2017-06-26 18:41:33,188 main.py:47] epoch 1544, training loss: 1989.00, average training loss: 2073.12, base loss: 2605.03
[INFO 2017-06-26 18:41:33,496 main.py:47] epoch 1545, training loss: 2555.05, average training loss: 2073.74, base loss: 2606.07
[INFO 2017-06-26 18:41:33,803 main.py:47] epoch 1546, training loss: 2022.79, average training loss: 2073.70, base loss: 2606.19
[INFO 2017-06-26 18:41:34,109 main.py:47] epoch 1547, training loss: 1974.88, average training loss: 2073.70, base loss: 2606.33
[INFO 2017-06-26 18:41:34,417 main.py:47] epoch 1548, training loss: 2161.44, average training loss: 2073.82, base loss: 2606.69
[INFO 2017-06-26 18:41:34,726 main.py:47] epoch 1549, training loss: 2045.02, average training loss: 2073.84, base loss: 2607.06
[INFO 2017-06-26 18:41:35,032 main.py:47] epoch 1550, training loss: 1932.35, average training loss: 2073.76, base loss: 2607.00
[INFO 2017-06-26 18:41:35,339 main.py:47] epoch 1551, training loss: 2036.62, average training loss: 2073.75, base loss: 2607.34
[INFO 2017-06-26 18:41:35,649 main.py:47] epoch 1552, training loss: 1959.82, average training loss: 2073.58, base loss: 2607.12
[INFO 2017-06-26 18:41:35,952 main.py:47] epoch 1553, training loss: 1918.64, average training loss: 2073.54, base loss: 2607.35
[INFO 2017-06-26 18:41:36,256 main.py:47] epoch 1554, training loss: 1883.71, average training loss: 2072.92, base loss: 2606.44
[INFO 2017-06-26 18:41:36,564 main.py:47] epoch 1555, training loss: 2036.82, average training loss: 2073.07, base loss: 2606.99
[INFO 2017-06-26 18:41:36,867 main.py:47] epoch 1556, training loss: 2110.80, average training loss: 2073.04, base loss: 2607.01
[INFO 2017-06-26 18:41:37,171 main.py:47] epoch 1557, training loss: 1995.27, average training loss: 2072.77, base loss: 2606.87
[INFO 2017-06-26 18:41:37,479 main.py:47] epoch 1558, training loss: 2086.99, average training loss: 2072.61, base loss: 2606.63
[INFO 2017-06-26 18:41:37,787 main.py:47] epoch 1559, training loss: 1796.16, average training loss: 2072.45, base loss: 2606.77
[INFO 2017-06-26 18:41:38,094 main.py:47] epoch 1560, training loss: 1803.94, average training loss: 2072.05, base loss: 2606.50
[INFO 2017-06-26 18:41:38,400 main.py:47] epoch 1561, training loss: 2080.44, average training loss: 2072.21, base loss: 2606.70
[INFO 2017-06-26 18:41:38,705 main.py:47] epoch 1562, training loss: 1751.41, average training loss: 2071.97, base loss: 2606.59
[INFO 2017-06-26 18:41:39,010 main.py:47] epoch 1563, training loss: 1843.18, average training loss: 2071.85, base loss: 2606.84
[INFO 2017-06-26 18:41:39,316 main.py:47] epoch 1564, training loss: 2113.53, average training loss: 2071.93, base loss: 2607.08
[INFO 2017-06-26 18:41:39,624 main.py:47] epoch 1565, training loss: 1881.68, average training loss: 2071.63, base loss: 2606.88
[INFO 2017-06-26 18:41:39,933 main.py:47] epoch 1566, training loss: 2186.37, average training loss: 2071.55, base loss: 2606.90
[INFO 2017-06-26 18:41:40,240 main.py:47] epoch 1567, training loss: 1981.51, average training loss: 2071.34, base loss: 2606.77
[INFO 2017-06-26 18:41:40,543 main.py:47] epoch 1568, training loss: 1929.56, average training loss: 2071.19, base loss: 2606.97
[INFO 2017-06-26 18:41:40,851 main.py:47] epoch 1569, training loss: 1989.35, average training loss: 2071.14, base loss: 2607.32
[INFO 2017-06-26 18:41:41,159 main.py:47] epoch 1570, training loss: 2415.70, average training loss: 2071.04, base loss: 2607.46
[INFO 2017-06-26 18:41:41,461 main.py:47] epoch 1571, training loss: 1786.52, average training loss: 2070.49, base loss: 2606.86
[INFO 2017-06-26 18:41:41,766 main.py:47] epoch 1572, training loss: 1914.35, average training loss: 2070.37, base loss: 2607.03
[INFO 2017-06-26 18:41:42,074 main.py:47] epoch 1573, training loss: 1951.34, average training loss: 2070.10, base loss: 2606.89
[INFO 2017-06-26 18:41:42,378 main.py:47] epoch 1574, training loss: 1806.04, average training loss: 2069.97, base loss: 2606.80
[INFO 2017-06-26 18:41:42,688 main.py:47] epoch 1575, training loss: 1908.91, average training loss: 2069.81, base loss: 2606.79
[INFO 2017-06-26 18:41:42,996 main.py:47] epoch 1576, training loss: 2201.02, average training loss: 2069.50, base loss: 2606.64
[INFO 2017-06-26 18:41:43,301 main.py:47] epoch 1577, training loss: 2031.00, average training loss: 2069.62, base loss: 2607.13
[INFO 2017-06-26 18:41:43,608 main.py:47] epoch 1578, training loss: 2008.37, average training loss: 2069.53, base loss: 2607.25
[INFO 2017-06-26 18:41:43,916 main.py:47] epoch 1579, training loss: 2136.66, average training loss: 2068.79, base loss: 2606.60
[INFO 2017-06-26 18:41:44,218 main.py:47] epoch 1580, training loss: 1929.77, average training loss: 2068.40, base loss: 2606.25
[INFO 2017-06-26 18:41:44,526 main.py:47] epoch 1581, training loss: 1782.16, average training loss: 2067.80, base loss: 2605.51
[INFO 2017-06-26 18:41:44,833 main.py:47] epoch 1582, training loss: 1987.44, average training loss: 2067.58, base loss: 2605.26
[INFO 2017-06-26 18:41:45,140 main.py:47] epoch 1583, training loss: 2023.85, average training loss: 2067.15, base loss: 2604.95
[INFO 2017-06-26 18:41:45,448 main.py:47] epoch 1584, training loss: 2262.14, average training loss: 2067.30, base loss: 2605.72
[INFO 2017-06-26 18:41:45,751 main.py:47] epoch 1585, training loss: 2428.97, average training loss: 2067.70, base loss: 2606.53
[INFO 2017-06-26 18:41:46,055 main.py:47] epoch 1586, training loss: 2198.16, average training loss: 2067.96, base loss: 2607.13
[INFO 2017-06-26 18:41:46,361 main.py:47] epoch 1587, training loss: 1812.37, average training loss: 2067.72, base loss: 2606.60
[INFO 2017-06-26 18:41:46,669 main.py:47] epoch 1588, training loss: 2197.63, average training loss: 2067.79, base loss: 2607.09
[INFO 2017-06-26 18:41:46,974 main.py:47] epoch 1589, training loss: 2086.97, average training loss: 2067.65, base loss: 2607.13
[INFO 2017-06-26 18:41:47,283 main.py:47] epoch 1590, training loss: 2221.65, average training loss: 2067.82, base loss: 2607.55
[INFO 2017-06-26 18:41:47,592 main.py:47] epoch 1591, training loss: 1960.28, average training loss: 2067.40, base loss: 2607.26
[INFO 2017-06-26 18:41:47,898 main.py:47] epoch 1592, training loss: 2099.18, average training loss: 2067.35, base loss: 2607.46
[INFO 2017-06-26 18:41:48,207 main.py:47] epoch 1593, training loss: 1944.09, average training loss: 2067.61, base loss: 2608.08
[INFO 2017-06-26 18:41:48,515 main.py:47] epoch 1594, training loss: 1795.71, average training loss: 2067.22, base loss: 2607.73
[INFO 2017-06-26 18:41:48,819 main.py:47] epoch 1595, training loss: 2089.63, average training loss: 2066.93, base loss: 2607.61
[INFO 2017-06-26 18:41:49,127 main.py:47] epoch 1596, training loss: 2061.24, average training loss: 2066.98, base loss: 2607.79
[INFO 2017-06-26 18:41:49,434 main.py:47] epoch 1597, training loss: 1752.96, average training loss: 2066.74, base loss: 2607.89
[INFO 2017-06-26 18:41:49,739 main.py:47] epoch 1598, training loss: 1858.69, average training loss: 2066.59, base loss: 2607.77
[INFO 2017-06-26 18:41:50,048 main.py:47] epoch 1599, training loss: 1910.22, average training loss: 2066.49, base loss: 2607.80
[INFO 2017-06-26 18:41:50,048 main.py:49] epoch 1599, testing
[INFO 2017-06-26 18:41:54,007 main.py:100] average testing loss: 2030.50, base loss: 2644.74
[INFO 2017-06-26 18:41:54,033 main.py:73] current best accuracy: 2017.92
[INFO 2017-06-26 18:41:54,341 main.py:47] epoch 1600, training loss: 2008.22, average training loss: 2066.42, base loss: 2607.69
[INFO 2017-06-26 18:41:54,655 main.py:47] epoch 1601, training loss: 2193.11, average training loss: 2066.51, base loss: 2607.87
[INFO 2017-06-26 18:41:54,964 main.py:47] epoch 1602, training loss: 1863.58, average training loss: 2066.31, base loss: 2607.56
[INFO 2017-06-26 18:41:55,272 main.py:47] epoch 1603, training loss: 2023.91, average training loss: 2066.14, base loss: 2607.61
[INFO 2017-06-26 18:41:55,578 main.py:47] epoch 1604, training loss: 1901.36, average training loss: 2065.92, base loss: 2607.44
[INFO 2017-06-26 18:41:55,887 main.py:47] epoch 1605, training loss: 2213.74, average training loss: 2066.00, base loss: 2607.54
[INFO 2017-06-26 18:41:56,191 main.py:47] epoch 1606, training loss: 1948.44, average training loss: 2065.74, base loss: 2607.57
[INFO 2017-06-26 18:41:56,499 main.py:47] epoch 1607, training loss: 2012.96, average training loss: 2065.40, base loss: 2607.03
[INFO 2017-06-26 18:41:56,805 main.py:47] epoch 1608, training loss: 2348.20, average training loss: 2065.22, base loss: 2606.84
[INFO 2017-06-26 18:41:57,113 main.py:47] epoch 1609, training loss: 2001.07, average training loss: 2065.12, base loss: 2606.75
[INFO 2017-06-26 18:41:57,419 main.py:47] epoch 1610, training loss: 2105.29, average training loss: 2065.25, base loss: 2606.92
[INFO 2017-06-26 18:41:57,726 main.py:47] epoch 1611, training loss: 2005.64, average training loss: 2065.17, base loss: 2606.83
[INFO 2017-06-26 18:41:58,033 main.py:47] epoch 1612, training loss: 1741.15, average training loss: 2064.59, base loss: 2606.06
[INFO 2017-06-26 18:41:58,364 main.py:47] epoch 1613, training loss: 1866.63, average training loss: 2064.59, base loss: 2606.13
[INFO 2017-06-26 18:41:58,677 main.py:47] epoch 1614, training loss: 2280.65, average training loss: 2064.82, base loss: 2606.64
[INFO 2017-06-26 18:41:59,005 main.py:47] epoch 1615, training loss: 2155.12, average training loss: 2064.79, base loss: 2606.66
[INFO 2017-06-26 18:41:59,315 main.py:47] epoch 1616, training loss: 2010.46, average training loss: 2064.57, base loss: 2606.35
[INFO 2017-06-26 18:41:59,620 main.py:47] epoch 1617, training loss: 2162.72, average training loss: 2064.62, base loss: 2606.72
[INFO 2017-06-26 18:41:59,928 main.py:47] epoch 1618, training loss: 1890.82, average training loss: 2064.49, base loss: 2606.97
[INFO 2017-06-26 18:42:00,235 main.py:47] epoch 1619, training loss: 2047.26, average training loss: 2064.70, base loss: 2607.57
[INFO 2017-06-26 18:42:00,538 main.py:47] epoch 1620, training loss: 1780.02, average training loss: 2064.27, base loss: 2607.18
[INFO 2017-06-26 18:42:00,848 main.py:47] epoch 1621, training loss: 1906.21, average training loss: 2064.12, base loss: 2606.94
[INFO 2017-06-26 18:42:01,153 main.py:47] epoch 1622, training loss: 1938.56, average training loss: 2064.37, base loss: 2607.29
[INFO 2017-06-26 18:42:01,458 main.py:47] epoch 1623, training loss: 1842.72, average training loss: 2063.83, base loss: 2606.68
[INFO 2017-06-26 18:42:01,767 main.py:47] epoch 1624, training loss: 1804.55, average training loss: 2063.58, base loss: 2606.44
[INFO 2017-06-26 18:42:02,075 main.py:47] epoch 1625, training loss: 1884.33, average training loss: 2063.56, base loss: 2606.45
[INFO 2017-06-26 18:42:02,382 main.py:47] epoch 1626, training loss: 2234.74, average training loss: 2063.55, base loss: 2606.71
[INFO 2017-06-26 18:42:02,691 main.py:47] epoch 1627, training loss: 2039.41, average training loss: 2063.91, base loss: 2607.37
[INFO 2017-06-26 18:42:03,000 main.py:47] epoch 1628, training loss: 1980.72, average training loss: 2063.86, base loss: 2607.17
[INFO 2017-06-26 18:42:03,307 main.py:47] epoch 1629, training loss: 2021.36, average training loss: 2063.81, base loss: 2607.16
[INFO 2017-06-26 18:42:03,614 main.py:47] epoch 1630, training loss: 2081.02, average training loss: 2063.89, base loss: 2607.53
[INFO 2017-06-26 18:42:03,920 main.py:47] epoch 1631, training loss: 2291.79, average training loss: 2063.84, base loss: 2607.63
[INFO 2017-06-26 18:42:04,227 main.py:47] epoch 1632, training loss: 2107.07, average training loss: 2063.78, base loss: 2607.75
[INFO 2017-06-26 18:42:04,532 main.py:47] epoch 1633, training loss: 2016.80, average training loss: 2063.85, base loss: 2608.07
[INFO 2017-06-26 18:42:04,841 main.py:47] epoch 1634, training loss: 2110.33, average training loss: 2063.64, base loss: 2608.21
[INFO 2017-06-26 18:42:05,144 main.py:47] epoch 1635, training loss: 2346.23, average training loss: 2063.24, base loss: 2607.74
[INFO 2017-06-26 18:42:05,450 main.py:47] epoch 1636, training loss: 2336.27, average training loss: 2063.61, base loss: 2608.32
[INFO 2017-06-26 18:42:05,759 main.py:47] epoch 1637, training loss: 2282.48, average training loss: 2063.70, base loss: 2608.58
[INFO 2017-06-26 18:42:06,066 main.py:47] epoch 1638, training loss: 2052.04, average training loss: 2063.63, base loss: 2608.56
[INFO 2017-06-26 18:42:06,374 main.py:47] epoch 1639, training loss: 2154.27, average training loss: 2063.64, base loss: 2608.70
[INFO 2017-06-26 18:42:06,681 main.py:47] epoch 1640, training loss: 1932.44, average training loss: 2063.74, base loss: 2608.96
[INFO 2017-06-26 18:42:06,988 main.py:47] epoch 1641, training loss: 1827.22, average training loss: 2063.44, base loss: 2608.53
[INFO 2017-06-26 18:42:07,297 main.py:47] epoch 1642, training loss: 1901.25, average training loss: 2062.95, base loss: 2608.11
[INFO 2017-06-26 18:42:07,600 main.py:47] epoch 1643, training loss: 1719.71, average training loss: 2062.64, base loss: 2607.90
[INFO 2017-06-26 18:42:07,907 main.py:47] epoch 1644, training loss: 2058.35, average training loss: 2062.58, base loss: 2607.73
[INFO 2017-06-26 18:42:08,211 main.py:47] epoch 1645, training loss: 2312.50, average training loss: 2062.71, base loss: 2608.20
[INFO 2017-06-26 18:42:08,517 main.py:47] epoch 1646, training loss: 1763.47, average training loss: 2062.64, base loss: 2608.07
[INFO 2017-06-26 18:42:08,826 main.py:47] epoch 1647, training loss: 1898.00, average training loss: 2062.20, base loss: 2607.37
[INFO 2017-06-26 18:42:09,133 main.py:47] epoch 1648, training loss: 1943.69, average training loss: 2062.14, base loss: 2607.24
[INFO 2017-06-26 18:42:09,442 main.py:47] epoch 1649, training loss: 1964.67, average training loss: 2062.32, base loss: 2607.55
[INFO 2017-06-26 18:42:09,750 main.py:47] epoch 1650, training loss: 2081.13, average training loss: 2062.52, base loss: 2608.16
[INFO 2017-06-26 18:42:10,059 main.py:47] epoch 1651, training loss: 1995.59, average training loss: 2062.11, base loss: 2607.74
[INFO 2017-06-26 18:42:10,363 main.py:47] epoch 1652, training loss: 2012.04, average training loss: 2061.85, base loss: 2607.53
[INFO 2017-06-26 18:42:10,672 main.py:47] epoch 1653, training loss: 2071.18, average training loss: 2061.42, base loss: 2607.21
[INFO 2017-06-26 18:42:10,987 main.py:47] epoch 1654, training loss: 2006.59, average training loss: 2060.61, base loss: 2606.57
[INFO 2017-06-26 18:42:11,296 main.py:47] epoch 1655, training loss: 1911.04, average training loss: 2060.34, base loss: 2606.40
[INFO 2017-06-26 18:42:11,603 main.py:47] epoch 1656, training loss: 2054.58, average training loss: 2060.58, base loss: 2606.96
[INFO 2017-06-26 18:42:11,911 main.py:47] epoch 1657, training loss: 2253.69, average training loss: 2060.68, base loss: 2607.27
[INFO 2017-06-26 18:42:12,217 main.py:47] epoch 1658, training loss: 1939.65, average training loss: 2060.53, base loss: 2607.39
[INFO 2017-06-26 18:42:12,521 main.py:47] epoch 1659, training loss: 2247.38, average training loss: 2060.59, base loss: 2607.64
[INFO 2017-06-26 18:42:12,830 main.py:47] epoch 1660, training loss: 1997.90, average training loss: 2060.16, base loss: 2607.65
[INFO 2017-06-26 18:42:13,138 main.py:47] epoch 1661, training loss: 2021.67, average training loss: 2059.40, base loss: 2606.75
[INFO 2017-06-26 18:42:13,448 main.py:47] epoch 1662, training loss: 1991.95, average training loss: 2059.37, base loss: 2606.90
[INFO 2017-06-26 18:42:13,756 main.py:47] epoch 1663, training loss: 2061.55, average training loss: 2059.37, base loss: 2607.07
[INFO 2017-06-26 18:42:14,061 main.py:47] epoch 1664, training loss: 2127.53, average training loss: 2059.49, base loss: 2607.59
[INFO 2017-06-26 18:42:14,368 main.py:47] epoch 1665, training loss: 2001.67, average training loss: 2059.24, base loss: 2607.40
[INFO 2017-06-26 18:42:14,675 main.py:47] epoch 1666, training loss: 1930.85, average training loss: 2059.01, base loss: 2607.07
[INFO 2017-06-26 18:42:14,982 main.py:47] epoch 1667, training loss: 2043.49, average training loss: 2059.19, base loss: 2607.37
[INFO 2017-06-26 18:42:15,290 main.py:47] epoch 1668, training loss: 1842.99, average training loss: 2058.29, base loss: 2606.36
[INFO 2017-06-26 18:42:15,595 main.py:47] epoch 1669, training loss: 2280.49, average training loss: 2058.27, base loss: 2606.40
[INFO 2017-06-26 18:42:15,901 main.py:47] epoch 1670, training loss: 1901.84, average training loss: 2057.99, base loss: 2606.30
[INFO 2017-06-26 18:42:16,207 main.py:47] epoch 1671, training loss: 2175.77, average training loss: 2058.03, base loss: 2606.56
[INFO 2017-06-26 18:42:16,515 main.py:47] epoch 1672, training loss: 2127.12, average training loss: 2058.06, base loss: 2606.79
[INFO 2017-06-26 18:42:16,826 main.py:47] epoch 1673, training loss: 2005.93, average training loss: 2057.89, base loss: 2606.60
[INFO 2017-06-26 18:42:17,132 main.py:47] epoch 1674, training loss: 2077.09, average training loss: 2057.72, base loss: 2606.50
[INFO 2017-06-26 18:42:17,439 main.py:47] epoch 1675, training loss: 1904.33, average training loss: 2057.53, base loss: 2606.38
[INFO 2017-06-26 18:42:17,748 main.py:47] epoch 1676, training loss: 2116.28, average training loss: 2057.32, base loss: 2606.29
[INFO 2017-06-26 18:42:18,051 main.py:47] epoch 1677, training loss: 1869.93, average training loss: 2057.02, base loss: 2606.02
[INFO 2017-06-26 18:42:18,358 main.py:47] epoch 1678, training loss: 2034.12, average training loss: 2056.87, base loss: 2605.98
[INFO 2017-06-26 18:42:18,664 main.py:47] epoch 1679, training loss: 2298.95, average training loss: 2057.05, base loss: 2606.37
[INFO 2017-06-26 18:42:18,972 main.py:47] epoch 1680, training loss: 2399.07, average training loss: 2057.38, base loss: 2606.73
[INFO 2017-06-26 18:42:19,276 main.py:47] epoch 1681, training loss: 1857.12, average training loss: 2057.36, base loss: 2607.03
[INFO 2017-06-26 18:42:19,580 main.py:47] epoch 1682, training loss: 1960.70, average training loss: 2057.20, base loss: 2606.85
[INFO 2017-06-26 18:42:19,885 main.py:47] epoch 1683, training loss: 1954.10, average training loss: 2057.26, base loss: 2607.36
[INFO 2017-06-26 18:42:20,190 main.py:47] epoch 1684, training loss: 2202.30, average training loss: 2057.59, base loss: 2608.02
[INFO 2017-06-26 18:42:20,497 main.py:47] epoch 1685, training loss: 2097.31, average training loss: 2057.32, base loss: 2607.75
[INFO 2017-06-26 18:42:20,802 main.py:47] epoch 1686, training loss: 2010.96, average training loss: 2057.17, base loss: 2607.37
[INFO 2017-06-26 18:42:21,111 main.py:47] epoch 1687, training loss: 1940.96, average training loss: 2057.02, base loss: 2607.11
[INFO 2017-06-26 18:42:21,420 main.py:47] epoch 1688, training loss: 1949.61, average training loss: 2057.22, base loss: 2607.49
[INFO 2017-06-26 18:42:21,725 main.py:47] epoch 1689, training loss: 2102.64, average training loss: 2057.19, base loss: 2607.69
[INFO 2017-06-26 18:42:22,033 main.py:47] epoch 1690, training loss: 1989.49, average training loss: 2056.81, base loss: 2607.47
[INFO 2017-06-26 18:42:22,339 main.py:47] epoch 1691, training loss: 2285.64, average training loss: 2057.10, base loss: 2608.27
[INFO 2017-06-26 18:42:22,647 main.py:47] epoch 1692, training loss: 1984.32, average training loss: 2057.17, base loss: 2608.27
[INFO 2017-06-26 18:42:22,954 main.py:47] epoch 1693, training loss: 1863.58, average training loss: 2057.18, base loss: 2608.30
[INFO 2017-06-26 18:42:23,261 main.py:47] epoch 1694, training loss: 2220.57, average training loss: 2057.19, base loss: 2608.38
[INFO 2017-06-26 18:42:23,568 main.py:47] epoch 1695, training loss: 1764.76, average training loss: 2057.07, base loss: 2608.35
[INFO 2017-06-26 18:42:23,873 main.py:47] epoch 1696, training loss: 1862.59, average training loss: 2056.88, base loss: 2608.03
[INFO 2017-06-26 18:42:24,181 main.py:47] epoch 1697, training loss: 2181.47, average training loss: 2056.60, base loss: 2607.92
[INFO 2017-06-26 18:42:24,489 main.py:47] epoch 1698, training loss: 2001.88, average training loss: 2056.41, base loss: 2607.68
[INFO 2017-06-26 18:42:24,798 main.py:47] epoch 1699, training loss: 1959.74, average training loss: 2056.53, base loss: 2608.06
[INFO 2017-06-26 18:42:24,798 main.py:49] epoch 1699, testing
[INFO 2017-06-26 18:42:28,752 main.py:100] average testing loss: 1945.80, base loss: 2501.69
[INFO 2017-06-26 18:42:28,777 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:42:28,791 main.py:73] current best accuracy: 1945.80
[INFO 2017-06-26 18:42:29,096 main.py:47] epoch 1700, training loss: 1961.92, average training loss: 2056.01, base loss: 2607.43
[INFO 2017-06-26 18:42:29,399 main.py:47] epoch 1701, training loss: 1849.95, average training loss: 2055.82, base loss: 2607.31
[INFO 2017-06-26 18:42:29,707 main.py:47] epoch 1702, training loss: 1987.58, average training loss: 2055.65, base loss: 2607.04
[INFO 2017-06-26 18:42:30,013 main.py:47] epoch 1703, training loss: 2129.15, average training loss: 2055.76, base loss: 2607.40
[INFO 2017-06-26 18:42:30,320 main.py:47] epoch 1704, training loss: 1788.68, average training loss: 2055.52, base loss: 2607.06
[INFO 2017-06-26 18:42:30,627 main.py:47] epoch 1705, training loss: 1917.46, average training loss: 2055.53, base loss: 2607.06
[INFO 2017-06-26 18:42:30,934 main.py:47] epoch 1706, training loss: 2205.98, average training loss: 2055.58, base loss: 2607.23
[INFO 2017-06-26 18:42:31,241 main.py:47] epoch 1707, training loss: 1800.88, average training loss: 2055.36, base loss: 2607.13
[INFO 2017-06-26 18:42:31,544 main.py:47] epoch 1708, training loss: 2068.18, average training loss: 2055.12, base loss: 2606.67
[INFO 2017-06-26 18:42:31,849 main.py:47] epoch 1709, training loss: 2016.72, average training loss: 2054.96, base loss: 2606.42
[INFO 2017-06-26 18:42:32,156 main.py:47] epoch 1710, training loss: 2400.08, average training loss: 2055.48, base loss: 2607.36
[INFO 2017-06-26 18:42:32,459 main.py:47] epoch 1711, training loss: 2020.85, average training loss: 2055.01, base loss: 2606.77
[INFO 2017-06-26 18:42:32,767 main.py:47] epoch 1712, training loss: 2220.14, average training loss: 2055.28, base loss: 2607.19
[INFO 2017-06-26 18:42:33,074 main.py:47] epoch 1713, training loss: 1984.43, average training loss: 2055.21, base loss: 2607.16
[INFO 2017-06-26 18:42:33,381 main.py:47] epoch 1714, training loss: 1936.59, average training loss: 2055.05, base loss: 2606.99
[INFO 2017-06-26 18:42:33,688 main.py:47] epoch 1715, training loss: 1892.13, average training loss: 2054.98, base loss: 2607.00
[INFO 2017-06-26 18:42:33,994 main.py:47] epoch 1716, training loss: 1977.47, average training loss: 2055.16, base loss: 2607.18
[INFO 2017-06-26 18:42:34,302 main.py:47] epoch 1717, training loss: 2017.08, average training loss: 2054.91, base loss: 2606.96
[INFO 2017-06-26 18:42:34,609 main.py:47] epoch 1718, training loss: 2028.36, average training loss: 2054.75, base loss: 2607.20
[INFO 2017-06-26 18:42:34,916 main.py:47] epoch 1719, training loss: 2367.51, average training loss: 2055.05, base loss: 2607.65
[INFO 2017-06-26 18:42:35,224 main.py:47] epoch 1720, training loss: 1761.08, average training loss: 2054.79, base loss: 2607.46
[INFO 2017-06-26 18:42:35,531 main.py:47] epoch 1721, training loss: 1956.31, average training loss: 2054.38, base loss: 2606.91
[INFO 2017-06-26 18:42:35,835 main.py:47] epoch 1722, training loss: 1933.59, average training loss: 2054.33, base loss: 2607.03
[INFO 2017-06-26 18:42:36,143 main.py:47] epoch 1723, training loss: 2054.03, average training loss: 2054.05, base loss: 2606.89
[INFO 2017-06-26 18:42:36,450 main.py:47] epoch 1724, training loss: 2042.52, average training loss: 2053.92, base loss: 2606.77
[INFO 2017-06-26 18:42:36,759 main.py:47] epoch 1725, training loss: 1983.47, average training loss: 2053.83, base loss: 2606.79
[INFO 2017-06-26 18:42:37,065 main.py:47] epoch 1726, training loss: 1948.92, average training loss: 2053.55, base loss: 2606.73
[INFO 2017-06-26 18:42:37,368 main.py:47] epoch 1727, training loss: 1878.72, average training loss: 2053.37, base loss: 2606.67
[INFO 2017-06-26 18:42:37,676 main.py:47] epoch 1728, training loss: 1935.99, average training loss: 2053.26, base loss: 2606.71
[INFO 2017-06-26 18:42:37,985 main.py:47] epoch 1729, training loss: 2355.36, average training loss: 2053.71, base loss: 2607.36
[INFO 2017-06-26 18:42:38,291 main.py:47] epoch 1730, training loss: 2221.60, average training loss: 2053.62, base loss: 2607.33
[INFO 2017-06-26 18:42:38,598 main.py:47] epoch 1731, training loss: 2239.27, average training loss: 2053.91, base loss: 2607.84
[INFO 2017-06-26 18:42:38,905 main.py:47] epoch 1732, training loss: 2173.44, average training loss: 2053.93, base loss: 2608.13
[INFO 2017-06-26 18:42:39,212 main.py:47] epoch 1733, training loss: 1785.04, average training loss: 2053.68, base loss: 2607.90
[INFO 2017-06-26 18:42:39,519 main.py:47] epoch 1734, training loss: 1978.00, average training loss: 2053.12, base loss: 2607.28
[INFO 2017-06-26 18:42:39,823 main.py:47] epoch 1735, training loss: 1909.07, average training loss: 2052.80, base loss: 2606.61
[INFO 2017-06-26 18:42:40,130 main.py:47] epoch 1736, training loss: 2485.68, average training loss: 2053.01, base loss: 2607.01
[INFO 2017-06-26 18:42:40,435 main.py:47] epoch 1737, training loss: 1924.83, average training loss: 2052.72, base loss: 2606.88
[INFO 2017-06-26 18:42:40,741 main.py:47] epoch 1738, training loss: 2069.66, average training loss: 2052.72, base loss: 2607.37
[INFO 2017-06-26 18:42:41,045 main.py:47] epoch 1739, training loss: 1919.62, average training loss: 2052.54, base loss: 2607.22
[INFO 2017-06-26 18:42:41,349 main.py:47] epoch 1740, training loss: 2081.75, average training loss: 2052.60, base loss: 2607.37
[INFO 2017-06-26 18:42:41,654 main.py:47] epoch 1741, training loss: 1859.38, average training loss: 2052.43, base loss: 2607.29
[INFO 2017-06-26 18:42:41,960 main.py:47] epoch 1742, training loss: 2209.33, average training loss: 2052.76, base loss: 2607.72
[INFO 2017-06-26 18:42:42,267 main.py:47] epoch 1743, training loss: 1932.73, average training loss: 2052.17, base loss: 2607.20
[INFO 2017-06-26 18:42:42,574 main.py:47] epoch 1744, training loss: 1679.26, average training loss: 2051.65, base loss: 2606.74
[INFO 2017-06-26 18:42:42,877 main.py:47] epoch 1745, training loss: 1818.63, average training loss: 2051.51, base loss: 2606.49
[INFO 2017-06-26 18:42:43,189 main.py:47] epoch 1746, training loss: 2027.62, average training loss: 2051.59, base loss: 2606.50
[INFO 2017-06-26 18:42:43,497 main.py:47] epoch 1747, training loss: 1936.94, average training loss: 2051.58, base loss: 2606.47
[INFO 2017-06-26 18:42:43,801 main.py:47] epoch 1748, training loss: 1804.16, average training loss: 2051.25, base loss: 2606.15
[INFO 2017-06-26 18:42:44,110 main.py:47] epoch 1749, training loss: 1885.06, average training loss: 2051.24, base loss: 2606.20
[INFO 2017-06-26 18:42:44,417 main.py:47] epoch 1750, training loss: 1953.14, average training loss: 2051.25, base loss: 2606.36
[INFO 2017-06-26 18:42:44,721 main.py:47] epoch 1751, training loss: 2603.54, average training loss: 2051.91, base loss: 2607.29
[INFO 2017-06-26 18:42:45,025 main.py:47] epoch 1752, training loss: 2147.44, average training loss: 2051.82, base loss: 2607.35
[INFO 2017-06-26 18:42:45,329 main.py:47] epoch 1753, training loss: 2155.29, average training loss: 2052.18, base loss: 2608.06
[INFO 2017-06-26 18:42:45,637 main.py:47] epoch 1754, training loss: 1844.92, average training loss: 2051.85, base loss: 2607.89
[INFO 2017-06-26 18:42:45,944 main.py:47] epoch 1755, training loss: 1849.55, average training loss: 2051.84, base loss: 2608.16
[INFO 2017-06-26 18:42:46,250 main.py:47] epoch 1756, training loss: 1808.51, average training loss: 2051.59, base loss: 2608.02
[INFO 2017-06-26 18:42:46,556 main.py:47] epoch 1757, training loss: 1941.11, average training loss: 2051.73, base loss: 2608.21
[INFO 2017-06-26 18:42:46,862 main.py:47] epoch 1758, training loss: 2147.78, average training loss: 2051.77, base loss: 2608.46
[INFO 2017-06-26 18:42:47,165 main.py:47] epoch 1759, training loss: 2006.78, average training loss: 2051.77, base loss: 2608.32
[INFO 2017-06-26 18:42:47,474 main.py:47] epoch 1760, training loss: 2479.35, average training loss: 2052.26, base loss: 2609.28
[INFO 2017-06-26 18:42:47,781 main.py:47] epoch 1761, training loss: 2187.67, average training loss: 2052.54, base loss: 2610.11
[INFO 2017-06-26 18:42:48,084 main.py:47] epoch 1762, training loss: 2034.23, average training loss: 2052.71, base loss: 2610.67
[INFO 2017-06-26 18:42:48,391 main.py:47] epoch 1763, training loss: 1806.46, average training loss: 2052.67, base loss: 2610.78
[INFO 2017-06-26 18:42:48,698 main.py:47] epoch 1764, training loss: 2095.87, average training loss: 2052.64, base loss: 2610.84
[INFO 2017-06-26 18:42:49,002 main.py:47] epoch 1765, training loss: 1947.40, average training loss: 2052.53, base loss: 2610.77
[INFO 2017-06-26 18:42:49,305 main.py:47] epoch 1766, training loss: 2093.80, average training loss: 2052.82, base loss: 2611.29
[INFO 2017-06-26 18:42:49,612 main.py:47] epoch 1767, training loss: 1924.71, average training loss: 2052.69, base loss: 2611.29
[INFO 2017-06-26 18:42:49,919 main.py:47] epoch 1768, training loss: 2278.98, average training loss: 2052.63, base loss: 2611.39
[INFO 2017-06-26 18:42:50,222 main.py:47] epoch 1769, training loss: 1856.69, average training loss: 2052.62, base loss: 2611.52
[INFO 2017-06-26 18:42:50,525 main.py:47] epoch 1770, training loss: 2196.50, average training loss: 2052.84, base loss: 2612.14
[INFO 2017-06-26 18:42:50,828 main.py:47] epoch 1771, training loss: 1813.80, average training loss: 2052.58, base loss: 2612.10
[INFO 2017-06-26 18:42:51,133 main.py:47] epoch 1772, training loss: 2074.72, average training loss: 2052.54, base loss: 2612.00
[INFO 2017-06-26 18:42:51,438 main.py:47] epoch 1773, training loss: 1774.78, average training loss: 2052.07, base loss: 2611.49
[INFO 2017-06-26 18:42:51,744 main.py:47] epoch 1774, training loss: 1993.69, average training loss: 2052.07, base loss: 2611.64
[INFO 2017-06-26 18:42:52,049 main.py:47] epoch 1775, training loss: 1968.18, average training loss: 2052.05, base loss: 2611.74
[INFO 2017-06-26 18:42:52,356 main.py:47] epoch 1776, training loss: 2100.67, average training loss: 2051.95, base loss: 2611.54
[INFO 2017-06-26 18:42:52,664 main.py:47] epoch 1777, training loss: 2135.46, average training loss: 2052.11, base loss: 2611.85
[INFO 2017-06-26 18:42:52,971 main.py:47] epoch 1778, training loss: 1843.48, average training loss: 2051.74, base loss: 2611.78
[INFO 2017-06-26 18:42:53,272 main.py:47] epoch 1779, training loss: 1929.17, average training loss: 2051.90, base loss: 2612.18
[INFO 2017-06-26 18:42:53,582 main.py:47] epoch 1780, training loss: 1783.93, average training loss: 2051.58, base loss: 2611.92
[INFO 2017-06-26 18:42:53,886 main.py:47] epoch 1781, training loss: 2244.40, average training loss: 2051.73, base loss: 2612.15
[INFO 2017-06-26 18:42:54,191 main.py:47] epoch 1782, training loss: 2054.17, average training loss: 2051.79, base loss: 2612.38
[INFO 2017-06-26 18:42:54,496 main.py:47] epoch 1783, training loss: 1786.03, average training loss: 2051.78, base loss: 2612.51
[INFO 2017-06-26 18:42:54,801 main.py:47] epoch 1784, training loss: 2058.93, average training loss: 2052.16, base loss: 2613.14
[INFO 2017-06-26 18:42:55,105 main.py:47] epoch 1785, training loss: 2537.86, average training loss: 2052.70, base loss: 2614.20
[INFO 2017-06-26 18:42:55,413 main.py:47] epoch 1786, training loss: 1984.40, average training loss: 2052.53, base loss: 2614.16
[INFO 2017-06-26 18:42:55,721 main.py:47] epoch 1787, training loss: 1765.73, average training loss: 2051.98, base loss: 2613.43
[INFO 2017-06-26 18:42:56,025 main.py:47] epoch 1788, training loss: 2296.23, average training loss: 2052.02, base loss: 2613.63
[INFO 2017-06-26 18:42:56,330 main.py:47] epoch 1789, training loss: 2115.09, average training loss: 2051.84, base loss: 2613.48
[INFO 2017-06-26 18:42:56,634 main.py:47] epoch 1790, training loss: 2095.94, average training loss: 2052.02, base loss: 2613.83
[INFO 2017-06-26 18:42:56,941 main.py:47] epoch 1791, training loss: 2042.81, average training loss: 2052.04, base loss: 2613.80
[INFO 2017-06-26 18:42:57,248 main.py:47] epoch 1792, training loss: 1830.58, average training loss: 2051.89, base loss: 2613.78
[INFO 2017-06-26 18:42:57,554 main.py:47] epoch 1793, training loss: 1769.37, average training loss: 2051.54, base loss: 2613.28
[INFO 2017-06-26 18:42:57,860 main.py:47] epoch 1794, training loss: 2147.30, average training loss: 2051.56, base loss: 2613.43
[INFO 2017-06-26 18:42:58,168 main.py:47] epoch 1795, training loss: 1770.07, average training loss: 2050.88, base loss: 2612.54
[INFO 2017-06-26 18:42:58,473 main.py:47] epoch 1796, training loss: 2149.70, average training loss: 2050.84, base loss: 2612.79
[INFO 2017-06-26 18:42:58,782 main.py:47] epoch 1797, training loss: 2069.09, average training loss: 2050.70, base loss: 2612.74
[INFO 2017-06-26 18:42:59,113 main.py:47] epoch 1798, training loss: 2114.97, average training loss: 2050.78, base loss: 2612.92
[INFO 2017-06-26 18:42:59,416 main.py:47] epoch 1799, training loss: 1908.99, average training loss: 2050.25, base loss: 2612.42
[INFO 2017-06-26 18:42:59,416 main.py:49] epoch 1799, testing
[INFO 2017-06-26 18:43:03,425 main.py:100] average testing loss: 2059.89, base loss: 2691.19
[INFO 2017-06-26 18:43:03,449 main.py:73] current best accuracy: 1945.80
[INFO 2017-06-26 18:43:03,752 main.py:47] epoch 1800, training loss: 2117.15, average training loss: 2050.09, base loss: 2612.33
[INFO 2017-06-26 18:43:04,059 main.py:47] epoch 1801, training loss: 1829.48, average training loss: 2050.08, base loss: 2612.52
[INFO 2017-06-26 18:43:04,365 main.py:47] epoch 1802, training loss: 1772.14, average training loss: 2049.60, base loss: 2611.94
[INFO 2017-06-26 18:43:04,667 main.py:47] epoch 1803, training loss: 1878.31, average training loss: 2049.53, base loss: 2611.94
[INFO 2017-06-26 18:43:04,970 main.py:47] epoch 1804, training loss: 1993.28, average training loss: 2049.44, base loss: 2611.91
[INFO 2017-06-26 18:43:05,276 main.py:47] epoch 1805, training loss: 1949.75, average training loss: 2049.11, base loss: 2611.66
[INFO 2017-06-26 18:43:05,582 main.py:47] epoch 1806, training loss: 2209.03, average training loss: 2049.15, base loss: 2611.80
[INFO 2017-06-26 18:43:05,891 main.py:47] epoch 1807, training loss: 2107.51, average training loss: 2049.21, base loss: 2612.06
[INFO 2017-06-26 18:43:06,195 main.py:47] epoch 1808, training loss: 1864.60, average training loss: 2048.96, base loss: 2611.91
[INFO 2017-06-26 18:43:06,502 main.py:47] epoch 1809, training loss: 1947.07, average training loss: 2048.66, base loss: 2611.46
[INFO 2017-06-26 18:43:06,807 main.py:47] epoch 1810, training loss: 2011.10, average training loss: 2048.34, base loss: 2611.47
[INFO 2017-06-26 18:43:07,112 main.py:47] epoch 1811, training loss: 2264.52, average training loss: 2048.67, base loss: 2612.19
[INFO 2017-06-26 18:43:07,420 main.py:47] epoch 1812, training loss: 2286.77, average training loss: 2049.14, base loss: 2613.01
[INFO 2017-06-26 18:43:07,727 main.py:47] epoch 1813, training loss: 1877.30, average training loss: 2049.01, base loss: 2613.05
[INFO 2017-06-26 18:43:08,032 main.py:47] epoch 1814, training loss: 1977.89, average training loss: 2048.82, base loss: 2613.20
[INFO 2017-06-26 18:43:08,339 main.py:47] epoch 1815, training loss: 1706.29, average training loss: 2048.30, base loss: 2612.68
[INFO 2017-06-26 18:43:08,645 main.py:47] epoch 1816, training loss: 2177.76, average training loss: 2047.91, base loss: 2612.31
[INFO 2017-06-26 18:43:08,953 main.py:47] epoch 1817, training loss: 1857.88, average training loss: 2047.82, base loss: 2612.39
[INFO 2017-06-26 18:43:09,258 main.py:47] epoch 1818, training loss: 2165.37, average training loss: 2048.03, base loss: 2612.77
[INFO 2017-06-26 18:43:09,566 main.py:47] epoch 1819, training loss: 1985.72, average training loss: 2048.14, base loss: 2613.14
[INFO 2017-06-26 18:43:09,874 main.py:47] epoch 1820, training loss: 2301.59, average training loss: 2048.47, base loss: 2613.87
[INFO 2017-06-26 18:43:10,182 main.py:47] epoch 1821, training loss: 2108.12, average training loss: 2048.74, base loss: 2614.54
[INFO 2017-06-26 18:43:10,488 main.py:47] epoch 1822, training loss: 1986.79, average training loss: 2048.72, base loss: 2614.51
[INFO 2017-06-26 18:43:10,795 main.py:47] epoch 1823, training loss: 2104.32, average training loss: 2048.59, base loss: 2614.24
[INFO 2017-06-26 18:43:11,101 main.py:47] epoch 1824, training loss: 1930.14, average training loss: 2048.57, base loss: 2614.64
[INFO 2017-06-26 18:43:11,408 main.py:47] epoch 1825, training loss: 2105.04, average training loss: 2048.66, base loss: 2614.86
[INFO 2017-06-26 18:43:11,714 main.py:47] epoch 1826, training loss: 1753.08, average training loss: 2048.31, base loss: 2614.73
[INFO 2017-06-26 18:43:12,021 main.py:47] epoch 1827, training loss: 2106.46, average training loss: 2048.42, base loss: 2615.08
[INFO 2017-06-26 18:43:12,325 main.py:47] epoch 1828, training loss: 1881.27, average training loss: 2047.74, base loss: 2614.18
[INFO 2017-06-26 18:43:12,629 main.py:47] epoch 1829, training loss: 1685.98, average training loss: 2047.41, base loss: 2613.83
[INFO 2017-06-26 18:43:12,935 main.py:47] epoch 1830, training loss: 2204.99, average training loss: 2047.55, base loss: 2614.02
[INFO 2017-06-26 18:43:13,238 main.py:47] epoch 1831, training loss: 1891.47, average training loss: 2047.30, base loss: 2613.89
[INFO 2017-06-26 18:43:13,546 main.py:47] epoch 1832, training loss: 1843.73, average training loss: 2047.24, base loss: 2613.78
[INFO 2017-06-26 18:43:13,851 main.py:47] epoch 1833, training loss: 1958.62, average training loss: 2047.14, base loss: 2613.80
[INFO 2017-06-26 18:43:14,152 main.py:47] epoch 1834, training loss: 2029.34, average training loss: 2047.12, base loss: 2613.97
[INFO 2017-06-26 18:43:14,459 main.py:47] epoch 1835, training loss: 2129.15, average training loss: 2047.38, base loss: 2614.55
[INFO 2017-06-26 18:43:14,762 main.py:47] epoch 1836, training loss: 1872.27, average training loss: 2047.14, base loss: 2614.34
[INFO 2017-06-26 18:43:15,070 main.py:47] epoch 1837, training loss: 1818.01, average training loss: 2047.06, base loss: 2614.48
[INFO 2017-06-26 18:43:15,373 main.py:47] epoch 1838, training loss: 1992.69, average training loss: 2047.16, base loss: 2614.80
[INFO 2017-06-26 18:43:15,681 main.py:47] epoch 1839, training loss: 2497.74, average training loss: 2047.89, base loss: 2616.07
[INFO 2017-06-26 18:43:15,990 main.py:47] epoch 1840, training loss: 2131.78, average training loss: 2047.88, base loss: 2616.28
[INFO 2017-06-26 18:43:16,296 main.py:47] epoch 1841, training loss: 1862.25, average training loss: 2047.83, base loss: 2616.37
[INFO 2017-06-26 18:43:16,604 main.py:47] epoch 1842, training loss: 1912.48, average training loss: 2047.73, base loss: 2616.40
[INFO 2017-06-26 18:43:16,910 main.py:47] epoch 1843, training loss: 2344.37, average training loss: 2047.86, base loss: 2616.69
[INFO 2017-06-26 18:43:17,215 main.py:47] epoch 1844, training loss: 2123.13, average training loss: 2047.95, base loss: 2616.86
[INFO 2017-06-26 18:43:17,518 main.py:47] epoch 1845, training loss: 2032.47, average training loss: 2047.90, base loss: 2616.94
[INFO 2017-06-26 18:43:17,823 main.py:47] epoch 1846, training loss: 2064.51, average training loss: 2047.73, base loss: 2616.82
[INFO 2017-06-26 18:43:18,127 main.py:47] epoch 1847, training loss: 2279.00, average training loss: 2048.05, base loss: 2617.18
[INFO 2017-06-26 18:43:18,436 main.py:47] epoch 1848, training loss: 2006.61, average training loss: 2048.05, base loss: 2617.15
[INFO 2017-06-26 18:43:18,741 main.py:47] epoch 1849, training loss: 1985.11, average training loss: 2048.06, base loss: 2617.28
[INFO 2017-06-26 18:43:19,046 main.py:47] epoch 1850, training loss: 2048.03, average training loss: 2047.96, base loss: 2617.13
[INFO 2017-06-26 18:43:19,350 main.py:47] epoch 1851, training loss: 2125.49, average training loss: 2047.90, base loss: 2617.22
[INFO 2017-06-26 18:43:19,653 main.py:47] epoch 1852, training loss: 2125.06, average training loss: 2048.01, base loss: 2617.54
[INFO 2017-06-26 18:43:19,959 main.py:47] epoch 1853, training loss: 1749.04, average training loss: 2047.66, base loss: 2617.09
[INFO 2017-06-26 18:43:20,263 main.py:47] epoch 1854, training loss: 2210.50, average training loss: 2047.84, base loss: 2617.30
[INFO 2017-06-26 18:43:20,569 main.py:47] epoch 1855, training loss: 2019.59, average training loss: 2047.54, base loss: 2617.10
[INFO 2017-06-26 18:43:20,873 main.py:47] epoch 1856, training loss: 2379.45, average training loss: 2047.36, base loss: 2616.87
[INFO 2017-06-26 18:43:21,179 main.py:47] epoch 1857, training loss: 2018.71, average training loss: 2047.26, base loss: 2616.75
[INFO 2017-06-26 18:43:21,487 main.py:47] epoch 1858, training loss: 2017.46, average training loss: 2047.01, base loss: 2616.59
[INFO 2017-06-26 18:43:21,793 main.py:47] epoch 1859, training loss: 2147.79, average training loss: 2046.76, base loss: 2616.12
[INFO 2017-06-26 18:43:22,097 main.py:47] epoch 1860, training loss: 2066.73, average training loss: 2046.81, base loss: 2616.26
[INFO 2017-06-26 18:43:22,400 main.py:47] epoch 1861, training loss: 1842.06, average training loss: 2046.62, base loss: 2616.21
[INFO 2017-06-26 18:43:22,709 main.py:47] epoch 1862, training loss: 1898.49, average training loss: 2046.56, base loss: 2616.17
[INFO 2017-06-26 18:43:23,017 main.py:47] epoch 1863, training loss: 1887.92, average training loss: 2046.21, base loss: 2615.81
[INFO 2017-06-26 18:43:23,324 main.py:47] epoch 1864, training loss: 2056.18, average training loss: 2045.99, base loss: 2615.70
[INFO 2017-06-26 18:43:23,628 main.py:47] epoch 1865, training loss: 1866.81, average training loss: 2046.10, base loss: 2616.19
[INFO 2017-06-26 18:43:23,936 main.py:47] epoch 1866, training loss: 1622.66, average training loss: 2045.90, base loss: 2615.67
[INFO 2017-06-26 18:43:24,244 main.py:47] epoch 1867, training loss: 1771.19, average training loss: 2045.71, base loss: 2615.49
[INFO 2017-06-26 18:43:24,548 main.py:47] epoch 1868, training loss: 1930.44, average training loss: 2045.42, base loss: 2615.15
[INFO 2017-06-26 18:43:24,853 main.py:47] epoch 1869, training loss: 2616.00, average training loss: 2046.32, base loss: 2616.43
[INFO 2017-06-26 18:43:25,157 main.py:47] epoch 1870, training loss: 2057.10, average training loss: 2046.33, base loss: 2616.78
[INFO 2017-06-26 18:43:25,464 main.py:47] epoch 1871, training loss: 1961.83, average training loss: 2046.08, base loss: 2616.34
[INFO 2017-06-26 18:43:25,772 main.py:47] epoch 1872, training loss: 1882.39, average training loss: 2046.07, base loss: 2616.26
[INFO 2017-06-26 18:43:26,076 main.py:47] epoch 1873, training loss: 1899.07, average training loss: 2046.02, base loss: 2616.31
[INFO 2017-06-26 18:43:26,381 main.py:47] epoch 1874, training loss: 2196.60, average training loss: 2046.26, base loss: 2616.62
[INFO 2017-06-26 18:43:26,689 main.py:47] epoch 1875, training loss: 2310.31, average training loss: 2046.63, base loss: 2617.23
[INFO 2017-06-26 18:43:26,993 main.py:47] epoch 1876, training loss: 1919.61, average training loss: 2046.49, base loss: 2617.37
[INFO 2017-06-26 18:43:27,301 main.py:47] epoch 1877, training loss: 1958.20, average training loss: 2046.35, base loss: 2617.31
[INFO 2017-06-26 18:43:27,608 main.py:47] epoch 1878, training loss: 2014.47, average training loss: 2046.31, base loss: 2617.38
[INFO 2017-06-26 18:43:27,915 main.py:47] epoch 1879, training loss: 1770.72, average training loss: 2045.94, base loss: 2616.95
[INFO 2017-06-26 18:43:28,224 main.py:47] epoch 1880, training loss: 1872.50, average training loss: 2045.59, base loss: 2616.48
[INFO 2017-06-26 18:43:28,531 main.py:47] epoch 1881, training loss: 2066.82, average training loss: 2045.52, base loss: 2616.48
[INFO 2017-06-26 18:43:28,837 main.py:47] epoch 1882, training loss: 2267.04, average training loss: 2045.83, base loss: 2617.03
[INFO 2017-06-26 18:43:29,141 main.py:47] epoch 1883, training loss: 2048.99, average training loss: 2045.90, base loss: 2617.30
[INFO 2017-06-26 18:43:29,448 main.py:47] epoch 1884, training loss: 2146.71, average training loss: 2046.13, base loss: 2617.56
[INFO 2017-06-26 18:43:29,753 main.py:47] epoch 1885, training loss: 1963.23, average training loss: 2045.65, base loss: 2616.90
[INFO 2017-06-26 18:43:30,061 main.py:47] epoch 1886, training loss: 1937.53, average training loss: 2045.30, base loss: 2616.84
[INFO 2017-06-26 18:43:30,367 main.py:47] epoch 1887, training loss: 2023.91, average training loss: 2045.54, base loss: 2617.58
[INFO 2017-06-26 18:43:30,674 main.py:47] epoch 1888, training loss: 2104.81, average training loss: 2045.43, base loss: 2617.43
[INFO 2017-06-26 18:43:30,978 main.py:47] epoch 1889, training loss: 1926.77, average training loss: 2045.53, base loss: 2617.67
[INFO 2017-06-26 18:43:31,285 main.py:47] epoch 1890, training loss: 1730.18, average training loss: 2045.20, base loss: 2617.23
[INFO 2017-06-26 18:43:31,591 main.py:47] epoch 1891, training loss: 1696.54, average training loss: 2044.58, base loss: 2616.57
[INFO 2017-06-26 18:43:31,900 main.py:47] epoch 1892, training loss: 2024.14, average training loss: 2044.71, base loss: 2616.95
[INFO 2017-06-26 18:43:32,207 main.py:47] epoch 1893, training loss: 2376.74, average training loss: 2045.07, base loss: 2617.67
[INFO 2017-06-26 18:43:32,514 main.py:47] epoch 1894, training loss: 2013.59, average training loss: 2045.16, base loss: 2618.01
[INFO 2017-06-26 18:43:32,821 main.py:47] epoch 1895, training loss: 2353.23, average training loss: 2045.59, base loss: 2618.77
[INFO 2017-06-26 18:43:33,127 main.py:47] epoch 1896, training loss: 1810.50, average training loss: 2045.52, base loss: 2618.78
[INFO 2017-06-26 18:43:33,436 main.py:47] epoch 1897, training loss: 2294.96, average training loss: 2045.80, base loss: 2619.27
[INFO 2017-06-26 18:43:33,741 main.py:47] epoch 1898, training loss: 2594.02, average training loss: 2046.08, base loss: 2619.92
[INFO 2017-06-26 18:43:34,047 main.py:47] epoch 1899, training loss: 1808.35, average training loss: 2045.83, base loss: 2619.83
[INFO 2017-06-26 18:43:34,047 main.py:49] epoch 1899, testing
[INFO 2017-06-26 18:43:38,032 main.py:100] average testing loss: 2016.79, base loss: 2608.33
[INFO 2017-06-26 18:43:38,058 main.py:73] current best accuracy: 1945.80
[INFO 2017-06-26 18:43:38,367 main.py:47] epoch 1900, training loss: 2138.91, average training loss: 2045.64, base loss: 2619.69
[INFO 2017-06-26 18:43:38,674 main.py:47] epoch 1901, training loss: 1898.94, average training loss: 2045.50, base loss: 2619.57
[INFO 2017-06-26 18:43:38,979 main.py:47] epoch 1902, training loss: 1827.49, average training loss: 2045.14, base loss: 2619.18
[INFO 2017-06-26 18:43:39,286 main.py:47] epoch 1903, training loss: 2205.23, average training loss: 2045.36, base loss: 2619.49
[INFO 2017-06-26 18:43:39,592 main.py:47] epoch 1904, training loss: 1800.99, average training loss: 2044.64, base loss: 2618.50
[INFO 2017-06-26 18:43:39,899 main.py:47] epoch 1905, training loss: 2001.82, average training loss: 2044.65, base loss: 2618.71
[INFO 2017-06-26 18:43:40,206 main.py:47] epoch 1906, training loss: 2095.42, average training loss: 2044.78, base loss: 2618.92
[INFO 2017-06-26 18:43:40,514 main.py:47] epoch 1907, training loss: 1993.03, average training loss: 2044.53, base loss: 2618.54
[INFO 2017-06-26 18:43:40,820 main.py:47] epoch 1908, training loss: 2079.02, average training loss: 2044.74, base loss: 2618.92
[INFO 2017-06-26 18:43:41,127 main.py:47] epoch 1909, training loss: 2054.58, average training loss: 2044.97, base loss: 2619.33
[INFO 2017-06-26 18:43:41,433 main.py:47] epoch 1910, training loss: 1828.85, average training loss: 2044.47, base loss: 2618.79
[INFO 2017-06-26 18:43:41,740 main.py:47] epoch 1911, training loss: 2227.81, average training loss: 2044.80, base loss: 2619.42
[INFO 2017-06-26 18:43:42,047 main.py:47] epoch 1912, training loss: 2503.77, average training loss: 2045.29, base loss: 2620.19
[INFO 2017-06-26 18:43:42,349 main.py:47] epoch 1913, training loss: 1853.02, average training loss: 2045.02, base loss: 2619.84
[INFO 2017-06-26 18:43:42,657 main.py:47] epoch 1914, training loss: 1832.55, average training loss: 2044.98, base loss: 2619.65
[INFO 2017-06-26 18:43:42,964 main.py:47] epoch 1915, training loss: 2157.64, average training loss: 2044.36, base loss: 2618.83
[INFO 2017-06-26 18:43:43,271 main.py:47] epoch 1916, training loss: 2297.94, average training loss: 2044.60, base loss: 2619.37
[INFO 2017-06-26 18:43:43,576 main.py:47] epoch 1917, training loss: 2003.95, average training loss: 2044.85, base loss: 2619.58
[INFO 2017-06-26 18:43:43,885 main.py:47] epoch 1918, training loss: 2087.24, average training loss: 2044.80, base loss: 2619.43
[INFO 2017-06-26 18:43:44,191 main.py:47] epoch 1919, training loss: 1891.59, average training loss: 2044.58, base loss: 2619.42
[INFO 2017-06-26 18:43:44,497 main.py:47] epoch 1920, training loss: 2256.28, average training loss: 2045.01, base loss: 2620.15
[INFO 2017-06-26 18:43:44,803 main.py:47] epoch 1921, training loss: 2241.45, average training loss: 2045.20, base loss: 2620.51
[INFO 2017-06-26 18:43:45,107 main.py:47] epoch 1922, training loss: 1925.99, average training loss: 2045.13, base loss: 2620.81
[INFO 2017-06-26 18:43:45,411 main.py:47] epoch 1923, training loss: 2486.27, average training loss: 2045.47, base loss: 2621.39
[INFO 2017-06-26 18:43:45,720 main.py:47] epoch 1924, training loss: 2149.82, average training loss: 2045.53, base loss: 2621.83
[INFO 2017-06-26 18:43:46,025 main.py:47] epoch 1925, training loss: 2475.56, average training loss: 2045.97, base loss: 2622.49
[INFO 2017-06-26 18:43:46,331 main.py:47] epoch 1926, training loss: 2021.61, average training loss: 2046.23, base loss: 2623.05
[INFO 2017-06-26 18:43:46,638 main.py:47] epoch 1927, training loss: 1805.52, average training loss: 2045.92, base loss: 2622.72
[INFO 2017-06-26 18:43:46,942 main.py:47] epoch 1928, training loss: 2203.20, average training loss: 2045.64, base loss: 2622.60
[INFO 2017-06-26 18:43:47,247 main.py:47] epoch 1929, training loss: 1859.60, average training loss: 2045.79, base loss: 2622.97
[INFO 2017-06-26 18:43:47,551 main.py:47] epoch 1930, training loss: 2156.93, average training loss: 2045.91, base loss: 2623.14
[INFO 2017-06-26 18:43:47,858 main.py:47] epoch 1931, training loss: 1814.25, average training loss: 2046.01, base loss: 2623.54
[INFO 2017-06-26 18:43:48,163 main.py:47] epoch 1932, training loss: 1847.38, average training loss: 2045.81, base loss: 2623.16
[INFO 2017-06-26 18:43:48,467 main.py:47] epoch 1933, training loss: 2132.82, average training loss: 2046.03, base loss: 2623.49
[INFO 2017-06-26 18:43:48,772 main.py:47] epoch 1934, training loss: 2195.27, average training loss: 2045.94, base loss: 2623.37
[INFO 2017-06-26 18:43:49,078 main.py:47] epoch 1935, training loss: 1696.73, average training loss: 2045.68, base loss: 2622.93
[INFO 2017-06-26 18:43:49,384 main.py:47] epoch 1936, training loss: 1920.58, average training loss: 2045.45, base loss: 2622.72
[INFO 2017-06-26 18:43:49,692 main.py:47] epoch 1937, training loss: 2290.82, average training loss: 2045.24, base loss: 2622.37
[INFO 2017-06-26 18:43:49,997 main.py:47] epoch 1938, training loss: 2032.60, average training loss: 2045.27, base loss: 2622.43
[INFO 2017-06-26 18:43:50,302 main.py:47] epoch 1939, training loss: 1879.71, average training loss: 2045.38, base loss: 2622.61
[INFO 2017-06-26 18:43:50,609 main.py:47] epoch 1940, training loss: 1994.94, average training loss: 2045.21, base loss: 2622.42
[INFO 2017-06-26 18:43:50,917 main.py:47] epoch 1941, training loss: 1858.11, average training loss: 2044.72, base loss: 2622.01
[INFO 2017-06-26 18:43:51,224 main.py:47] epoch 1942, training loss: 2230.56, average training loss: 2044.56, base loss: 2622.05
[INFO 2017-06-26 18:43:51,531 main.py:47] epoch 1943, training loss: 2009.69, average training loss: 2044.66, base loss: 2622.58
[INFO 2017-06-26 18:43:51,838 main.py:47] epoch 1944, training loss: 1819.95, average training loss: 2044.35, base loss: 2622.06
[INFO 2017-06-26 18:43:52,143 main.py:47] epoch 1945, training loss: 2007.99, average training loss: 2044.64, base loss: 2622.72
[INFO 2017-06-26 18:43:52,450 main.py:47] epoch 1946, training loss: 1861.72, average training loss: 2044.34, base loss: 2622.60
[INFO 2017-06-26 18:43:52,756 main.py:47] epoch 1947, training loss: 2033.88, average training loss: 2044.42, base loss: 2622.79
[INFO 2017-06-26 18:43:53,062 main.py:47] epoch 1948, training loss: 1761.46, average training loss: 2044.07, base loss: 2622.30
[INFO 2017-06-26 18:43:53,370 main.py:47] epoch 1949, training loss: 1924.59, average training loss: 2044.21, base loss: 2622.51
[INFO 2017-06-26 18:43:53,678 main.py:47] epoch 1950, training loss: 2069.42, average training loss: 2044.07, base loss: 2622.44
[INFO 2017-06-26 18:43:53,984 main.py:47] epoch 1951, training loss: 2060.63, average training loss: 2044.45, base loss: 2623.29
[INFO 2017-06-26 18:43:54,294 main.py:47] epoch 1952, training loss: 1794.98, average training loss: 2044.35, base loss: 2623.11
[INFO 2017-06-26 18:43:54,604 main.py:47] epoch 1953, training loss: 1938.08, average training loss: 2043.84, base loss: 2622.40
[INFO 2017-06-26 18:43:54,911 main.py:47] epoch 1954, training loss: 2378.06, average training loss: 2044.20, base loss: 2622.93
[INFO 2017-06-26 18:43:55,219 main.py:47] epoch 1955, training loss: 2086.89, average training loss: 2044.28, base loss: 2622.98
[INFO 2017-06-26 18:43:55,523 main.py:47] epoch 1956, training loss: 1859.58, average training loss: 2044.40, base loss: 2623.24
[INFO 2017-06-26 18:43:55,828 main.py:47] epoch 1957, training loss: 2020.04, average training loss: 2044.49, base loss: 2623.41
[INFO 2017-06-26 18:43:56,134 main.py:47] epoch 1958, training loss: 1905.19, average training loss: 2044.40, base loss: 2623.34
[INFO 2017-06-26 18:43:56,439 main.py:47] epoch 1959, training loss: 1690.16, average training loss: 2044.07, base loss: 2622.87
[INFO 2017-06-26 18:43:56,747 main.py:47] epoch 1960, training loss: 1717.67, average training loss: 2044.02, base loss: 2622.77
[INFO 2017-06-26 18:43:57,051 main.py:47] epoch 1961, training loss: 2070.66, average training loss: 2044.08, base loss: 2623.18
[INFO 2017-06-26 18:43:57,357 main.py:47] epoch 1962, training loss: 1925.68, average training loss: 2043.59, base loss: 2622.63
[INFO 2017-06-26 18:43:57,664 main.py:47] epoch 1963, training loss: 2126.73, average training loss: 2043.18, base loss: 2622.34
[INFO 2017-06-26 18:43:57,970 main.py:47] epoch 1964, training loss: 2003.00, average training loss: 2042.22, base loss: 2621.20
[INFO 2017-06-26 18:43:58,276 main.py:47] epoch 1965, training loss: 2076.08, average training loss: 2042.35, base loss: 2621.57
[INFO 2017-06-26 18:43:58,586 main.py:47] epoch 1966, training loss: 1876.53, average training loss: 2042.05, base loss: 2621.24
[INFO 2017-06-26 18:43:58,899 main.py:47] epoch 1967, training loss: 2064.00, average training loss: 2042.08, base loss: 2621.30
[INFO 2017-06-26 18:43:59,207 main.py:47] epoch 1968, training loss: 1688.11, average training loss: 2041.72, base loss: 2620.83
[INFO 2017-06-26 18:43:59,515 main.py:47] epoch 1969, training loss: 1913.44, average training loss: 2041.50, base loss: 2620.68
[INFO 2017-06-26 18:43:59,824 main.py:47] epoch 1970, training loss: 1814.27, average training loss: 2041.07, base loss: 2620.25
[INFO 2017-06-26 18:44:00,130 main.py:47] epoch 1971, training loss: 1782.05, average training loss: 2041.05, base loss: 2620.44
[INFO 2017-06-26 18:44:00,436 main.py:47] epoch 1972, training loss: 1976.61, average training loss: 2040.69, base loss: 2620.09
[INFO 2017-06-26 18:44:00,744 main.py:47] epoch 1973, training loss: 1943.91, average training loss: 2040.60, base loss: 2620.16
[INFO 2017-06-26 18:44:01,055 main.py:47] epoch 1974, training loss: 2513.00, average training loss: 2040.91, base loss: 2620.67
[INFO 2017-06-26 18:44:01,364 main.py:47] epoch 1975, training loss: 2308.95, average training loss: 2041.43, base loss: 2621.47
[INFO 2017-06-26 18:44:01,672 main.py:47] epoch 1976, training loss: 2035.68, average training loss: 2041.09, base loss: 2621.10
[INFO 2017-06-26 18:44:01,985 main.py:47] epoch 1977, training loss: 2021.93, average training loss: 2041.02, base loss: 2621.20
[INFO 2017-06-26 18:44:02,294 main.py:47] epoch 1978, training loss: 1812.09, average training loss: 2040.60, base loss: 2620.44
[INFO 2017-06-26 18:44:02,605 main.py:47] epoch 1979, training loss: 1960.00, average training loss: 2040.26, base loss: 2620.24
[INFO 2017-06-26 18:44:02,913 main.py:47] epoch 1980, training loss: 2490.27, average training loss: 2040.63, base loss: 2620.84
[INFO 2017-06-26 18:44:03,223 main.py:47] epoch 1981, training loss: 1905.99, average training loss: 2040.49, base loss: 2620.76
[INFO 2017-06-26 18:44:03,533 main.py:47] epoch 1982, training loss: 2191.27, average training loss: 2040.53, base loss: 2620.98
[INFO 2017-06-26 18:44:03,838 main.py:47] epoch 1983, training loss: 1922.03, average training loss: 2040.56, base loss: 2620.94
[INFO 2017-06-26 18:44:04,147 main.py:47] epoch 1984, training loss: 1832.97, average training loss: 2040.53, base loss: 2621.04
[INFO 2017-06-26 18:44:04,455 main.py:47] epoch 1985, training loss: 2005.67, average training loss: 2040.26, base loss: 2620.93
[INFO 2017-06-26 18:44:04,760 main.py:47] epoch 1986, training loss: 1954.79, average training loss: 2039.86, base loss: 2620.74
[INFO 2017-06-26 18:44:05,066 main.py:47] epoch 1987, training loss: 1958.66, average training loss: 2039.90, base loss: 2621.07
[INFO 2017-06-26 18:44:05,375 main.py:47] epoch 1988, training loss: 2078.66, average training loss: 2039.77, base loss: 2620.94
[INFO 2017-06-26 18:44:05,684 main.py:47] epoch 1989, training loss: 2067.46, average training loss: 2040.25, base loss: 2621.54
[INFO 2017-06-26 18:44:05,991 main.py:47] epoch 1990, training loss: 1960.34, average training loss: 2040.09, base loss: 2621.16
[INFO 2017-06-26 18:44:06,299 main.py:47] epoch 1991, training loss: 2305.55, average training loss: 2040.39, base loss: 2621.74
[INFO 2017-06-26 18:44:06,606 main.py:47] epoch 1992, training loss: 2246.68, average training loss: 2040.60, base loss: 2622.39
[INFO 2017-06-26 18:44:06,914 main.py:47] epoch 1993, training loss: 1999.99, average training loss: 2040.54, base loss: 2622.48
[INFO 2017-06-26 18:44:07,218 main.py:47] epoch 1994, training loss: 2136.09, average training loss: 2040.43, base loss: 2622.49
[INFO 2017-06-26 18:44:07,526 main.py:47] epoch 1995, training loss: 1995.30, average training loss: 2040.83, base loss: 2623.08
[INFO 2017-06-26 18:44:07,830 main.py:47] epoch 1996, training loss: 2049.11, average training loss: 2040.96, base loss: 2623.46
[INFO 2017-06-26 18:44:08,137 main.py:47] epoch 1997, training loss: 2233.80, average training loss: 2041.27, base loss: 2623.97
[INFO 2017-06-26 18:44:08,442 main.py:47] epoch 1998, training loss: 1998.20, average training loss: 2041.15, base loss: 2623.84
[INFO 2017-06-26 18:44:08,747 main.py:47] epoch 1999, training loss: 2147.82, average training loss: 2041.19, base loss: 2623.98
[INFO 2017-06-26 18:44:08,747 main.py:49] epoch 1999, testing
[INFO 2017-06-26 18:44:12,728 main.py:100] average testing loss: 2048.21, base loss: 2688.26
[INFO 2017-06-26 18:44:12,754 main.py:73] current best accuracy: 1945.80
[INFO 2017-06-26 18:44:13,059 main.py:47] epoch 2000, training loss: 1969.45, average training loss: 2041.30, base loss: 2624.19
[INFO 2017-06-26 18:44:13,367 main.py:47] epoch 2001, training loss: 1859.51, average training loss: 2040.85, base loss: 2623.72
[INFO 2017-06-26 18:44:13,673 main.py:47] epoch 2002, training loss: 1948.63, average training loss: 2040.57, base loss: 2623.65
[INFO 2017-06-26 18:44:13,978 main.py:47] epoch 2003, training loss: 1693.32, average training loss: 2040.22, base loss: 2623.31
[INFO 2017-06-26 18:44:14,284 main.py:47] epoch 2004, training loss: 2068.98, average training loss: 2040.34, base loss: 2623.49
[INFO 2017-06-26 18:44:14,589 main.py:47] epoch 2005, training loss: 2094.28, average training loss: 2040.41, base loss: 2623.53
[INFO 2017-06-26 18:44:14,894 main.py:47] epoch 2006, training loss: 2047.04, average training loss: 2040.54, base loss: 2623.94
[INFO 2017-06-26 18:44:15,202 main.py:47] epoch 2007, training loss: 1933.47, average training loss: 2040.35, base loss: 2623.68
[INFO 2017-06-26 18:44:15,508 main.py:47] epoch 2008, training loss: 1752.48, average training loss: 2039.81, base loss: 2623.06
[INFO 2017-06-26 18:44:15,815 main.py:47] epoch 2009, training loss: 2194.78, average training loss: 2039.90, base loss: 2623.42
[INFO 2017-06-26 18:44:16,123 main.py:47] epoch 2010, training loss: 2094.17, average training loss: 2039.56, base loss: 2623.21
[INFO 2017-06-26 18:44:16,428 main.py:47] epoch 2011, training loss: 2040.18, average training loss: 2039.61, base loss: 2623.34
[INFO 2017-06-26 18:44:16,733 main.py:47] epoch 2012, training loss: 1979.97, average training loss: 2039.25, base loss: 2623.31
[INFO 2017-06-26 18:44:17,043 main.py:47] epoch 2013, training loss: 1810.43, average training loss: 2039.20, base loss: 2623.47
[INFO 2017-06-26 18:44:17,353 main.py:47] epoch 2014, training loss: 1873.75, average training loss: 2038.97, base loss: 2623.46
[INFO 2017-06-26 18:44:17,661 main.py:47] epoch 2015, training loss: 1774.54, average training loss: 2038.64, base loss: 2622.70
[INFO 2017-06-26 18:44:17,974 main.py:47] epoch 2016, training loss: 1766.07, average training loss: 2038.42, base loss: 2622.52
[INFO 2017-06-26 18:44:18,286 main.py:47] epoch 2017, training loss: 1696.24, average training loss: 2037.80, base loss: 2621.66
[INFO 2017-06-26 18:44:18,599 main.py:47] epoch 2018, training loss: 1804.20, average training loss: 2037.41, base loss: 2621.29
[INFO 2017-06-26 18:44:18,914 main.py:47] epoch 2019, training loss: 1970.60, average training loss: 2037.25, base loss: 2621.20
[INFO 2017-06-26 18:44:19,227 main.py:47] epoch 2020, training loss: 2182.67, average training loss: 2036.99, base loss: 2620.87
[INFO 2017-06-26 18:44:19,540 main.py:47] epoch 2021, training loss: 2049.27, average training loss: 2037.25, base loss: 2621.35
[INFO 2017-06-26 18:44:19,850 main.py:47] epoch 2022, training loss: 1902.17, average training loss: 2037.24, base loss: 2621.10
[INFO 2017-06-26 18:44:20,159 main.py:47] epoch 2023, training loss: 1662.87, average training loss: 2037.01, base loss: 2620.81
[INFO 2017-06-26 18:44:20,469 main.py:47] epoch 2024, training loss: 1952.97, average training loss: 2037.06, base loss: 2620.90
[INFO 2017-06-26 18:44:20,781 main.py:47] epoch 2025, training loss: 2124.22, average training loss: 2037.14, base loss: 2621.35
[INFO 2017-06-26 18:44:21,091 main.py:47] epoch 2026, training loss: 2074.34, average training loss: 2037.22, base loss: 2621.55
[INFO 2017-06-26 18:44:21,401 main.py:47] epoch 2027, training loss: 1852.06, average training loss: 2036.88, base loss: 2621.10
[INFO 2017-06-26 18:44:21,712 main.py:47] epoch 2028, training loss: 1866.12, average training loss: 2036.77, base loss: 2621.17
[INFO 2017-06-26 18:44:22,022 main.py:47] epoch 2029, training loss: 2140.23, average training loss: 2037.13, base loss: 2621.73
[INFO 2017-06-26 18:44:22,350 main.py:47] epoch 2030, training loss: 2174.30, average training loss: 2037.30, base loss: 2622.12
[INFO 2017-06-26 18:44:22,717 main.py:47] epoch 2031, training loss: 1764.28, average training loss: 2037.09, base loss: 2621.96
[INFO 2017-06-26 18:44:23,081 main.py:47] epoch 2032, training loss: 2219.16, average training loss: 2036.96, base loss: 2622.03
[INFO 2017-06-26 18:44:23,430 main.py:47] epoch 2033, training loss: 1857.98, average training loss: 2036.66, base loss: 2621.80
[INFO 2017-06-26 18:44:23,785 main.py:47] epoch 2034, training loss: 2039.58, average training loss: 2036.76, base loss: 2622.18
[INFO 2017-06-26 18:44:24,144 main.py:47] epoch 2035, training loss: 1742.61, average training loss: 2036.59, base loss: 2621.96
[INFO 2017-06-26 18:44:24,479 main.py:47] epoch 2036, training loss: 1808.40, average training loss: 2036.17, base loss: 2621.42
[INFO 2017-06-26 18:44:24,801 main.py:47] epoch 2037, training loss: 1762.75, average training loss: 2035.89, base loss: 2621.02
[INFO 2017-06-26 18:44:25,169 main.py:47] epoch 2038, training loss: 1838.67, average training loss: 2035.17, base loss: 2620.32
[INFO 2017-06-26 18:44:25,560 main.py:47] epoch 2039, training loss: 1920.16, average training loss: 2034.96, base loss: 2620.28
[INFO 2017-06-26 18:44:25,885 main.py:47] epoch 2040, training loss: 2124.62, average training loss: 2034.92, base loss: 2620.27
[INFO 2017-06-26 18:44:26,196 main.py:47] epoch 2041, training loss: 1975.00, average training loss: 2034.60, base loss: 2620.06
[INFO 2017-06-26 18:44:26,503 main.py:47] epoch 2042, training loss: 1919.61, average training loss: 2034.31, base loss: 2619.76
[INFO 2017-06-26 18:44:26,812 main.py:47] epoch 2043, training loss: 2070.94, average training loss: 2034.15, base loss: 2619.81
[INFO 2017-06-26 18:44:27,120 main.py:47] epoch 2044, training loss: 1715.18, average training loss: 2033.72, base loss: 2619.16
[INFO 2017-06-26 18:44:27,429 main.py:47] epoch 2045, training loss: 1770.45, average training loss: 2033.29, base loss: 2618.73
[INFO 2017-06-26 18:44:27,737 main.py:47] epoch 2046, training loss: 1978.78, average training loss: 2033.50, base loss: 2619.16
[INFO 2017-06-26 18:44:28,044 main.py:47] epoch 2047, training loss: 2112.60, average training loss: 2033.20, base loss: 2618.90
[INFO 2017-06-26 18:44:28,350 main.py:47] epoch 2048, training loss: 2152.89, average training loss: 2033.11, base loss: 2618.78
[INFO 2017-06-26 18:44:28,658 main.py:47] epoch 2049, training loss: 2311.02, average training loss: 2033.45, base loss: 2619.35
[INFO 2017-06-26 18:44:28,964 main.py:47] epoch 2050, training loss: 1839.01, average training loss: 2033.36, base loss: 2619.29
[INFO 2017-06-26 18:44:29,271 main.py:47] epoch 2051, training loss: 2243.55, average training loss: 2033.23, base loss: 2619.42
[INFO 2017-06-26 18:44:29,580 main.py:47] epoch 2052, training loss: 1918.87, average training loss: 2033.26, base loss: 2619.60
[INFO 2017-06-26 18:44:29,886 main.py:47] epoch 2053, training loss: 1782.40, average training loss: 2032.30, base loss: 2618.63
[INFO 2017-06-26 18:44:30,197 main.py:47] epoch 2054, training loss: 2286.22, average training loss: 2032.27, base loss: 2618.57
[INFO 2017-06-26 18:44:30,502 main.py:47] epoch 2055, training loss: 2222.44, average training loss: 2032.35, base loss: 2618.80
[INFO 2017-06-26 18:44:30,809 main.py:47] epoch 2056, training loss: 2188.54, average training loss: 2032.59, base loss: 2619.39
[INFO 2017-06-26 18:44:31,113 main.py:47] epoch 2057, training loss: 1944.50, average training loss: 2032.41, base loss: 2619.26
[INFO 2017-06-26 18:44:31,421 main.py:47] epoch 2058, training loss: 1770.51, average training loss: 2031.90, base loss: 2618.76
[INFO 2017-06-26 18:44:31,730 main.py:47] epoch 2059, training loss: 1974.26, average training loss: 2031.83, base loss: 2618.53
[INFO 2017-06-26 18:44:32,038 main.py:47] epoch 2060, training loss: 2042.86, average training loss: 2031.76, base loss: 2618.71
[INFO 2017-06-26 18:44:32,346 main.py:47] epoch 2061, training loss: 1970.02, average training loss: 2031.46, base loss: 2618.44
[INFO 2017-06-26 18:44:32,656 main.py:47] epoch 2062, training loss: 1826.43, average training loss: 2031.19, base loss: 2618.26
[INFO 2017-06-26 18:44:32,964 main.py:47] epoch 2063, training loss: 1952.16, average training loss: 2030.84, base loss: 2617.92
[INFO 2017-06-26 18:44:33,270 main.py:47] epoch 2064, training loss: 2175.27, average training loss: 2031.14, base loss: 2618.26
[INFO 2017-06-26 18:44:33,574 main.py:47] epoch 2065, training loss: 2024.81, average training loss: 2031.19, base loss: 2618.34
[INFO 2017-06-26 18:44:33,882 main.py:47] epoch 2066, training loss: 1661.28, average training loss: 2030.81, base loss: 2618.12
[INFO 2017-06-26 18:44:34,188 main.py:47] epoch 2067, training loss: 2186.97, average training loss: 2031.10, base loss: 2618.53
[INFO 2017-06-26 18:44:34,495 main.py:47] epoch 2068, training loss: 1977.20, average training loss: 2030.29, base loss: 2617.52
[INFO 2017-06-26 18:44:34,800 main.py:47] epoch 2069, training loss: 2021.73, average training loss: 2030.45, base loss: 2617.92
[INFO 2017-06-26 18:44:35,106 main.py:47] epoch 2070, training loss: 1877.28, average training loss: 2030.39, base loss: 2617.75
[INFO 2017-06-26 18:44:35,414 main.py:47] epoch 2071, training loss: 1654.74, average training loss: 2030.22, base loss: 2617.60
[INFO 2017-06-26 18:44:35,721 main.py:47] epoch 2072, training loss: 2098.74, average training loss: 2030.34, base loss: 2617.86
[INFO 2017-06-26 18:44:36,026 main.py:47] epoch 2073, training loss: 1702.48, average training loss: 2029.79, base loss: 2617.17
[INFO 2017-06-26 18:44:36,399 main.py:47] epoch 2074, training loss: 2111.63, average training loss: 2030.07, base loss: 2617.96
[INFO 2017-06-26 18:44:36,718 main.py:47] epoch 2075, training loss: 1740.42, average training loss: 2029.83, base loss: 2617.91
[INFO 2017-06-26 18:44:37,030 main.py:47] epoch 2076, training loss: 1861.12, average training loss: 2029.31, base loss: 2617.46
[INFO 2017-06-26 18:44:37,340 main.py:47] epoch 2077, training loss: 2057.02, average training loss: 2029.07, base loss: 2617.30
[INFO 2017-06-26 18:44:37,647 main.py:47] epoch 2078, training loss: 2382.81, average training loss: 2029.55, base loss: 2618.10
[INFO 2017-06-26 18:44:37,956 main.py:47] epoch 2079, training loss: 2052.31, average training loss: 2029.20, base loss: 2617.64
[INFO 2017-06-26 18:44:38,265 main.py:47] epoch 2080, training loss: 2062.78, average training loss: 2028.71, base loss: 2617.43
[INFO 2017-06-26 18:44:38,572 main.py:47] epoch 2081, training loss: 2016.96, average training loss: 2028.59, base loss: 2617.51
[INFO 2017-06-26 18:44:38,881 main.py:47] epoch 2082, training loss: 2158.40, average training loss: 2028.58, base loss: 2617.71
[INFO 2017-06-26 18:44:39,199 main.py:47] epoch 2083, training loss: 2096.14, average training loss: 2028.64, base loss: 2617.76
[INFO 2017-06-26 18:44:39,501 main.py:47] epoch 2084, training loss: 2082.91, average training loss: 2028.71, base loss: 2617.90
[INFO 2017-06-26 18:44:39,808 main.py:47] epoch 2085, training loss: 1787.15, average training loss: 2028.45, base loss: 2617.52
[INFO 2017-06-26 18:44:40,117 main.py:47] epoch 2086, training loss: 2227.70, average training loss: 2028.28, base loss: 2617.61
[INFO 2017-06-26 18:44:40,423 main.py:47] epoch 2087, training loss: 2213.53, average training loss: 2028.21, base loss: 2617.36
[INFO 2017-06-26 18:44:40,732 main.py:47] epoch 2088, training loss: 2086.47, average training loss: 2027.92, base loss: 2617.04
[INFO 2017-06-26 18:44:41,040 main.py:47] epoch 2089, training loss: 1770.29, average training loss: 2027.40, base loss: 2616.35
[INFO 2017-06-26 18:44:41,347 main.py:47] epoch 2090, training loss: 2046.30, average training loss: 2027.21, base loss: 2616.04
[INFO 2017-06-26 18:44:41,654 main.py:47] epoch 2091, training loss: 1966.31, average training loss: 2027.24, base loss: 2616.20
[INFO 2017-06-26 18:44:41,960 main.py:47] epoch 2092, training loss: 1688.73, average training loss: 2026.65, base loss: 2615.76
[INFO 2017-06-26 18:44:42,268 main.py:47] epoch 2093, training loss: 1970.04, average training loss: 2026.34, base loss: 2615.39
[INFO 2017-06-26 18:44:42,578 main.py:47] epoch 2094, training loss: 2112.16, average training loss: 2026.64, base loss: 2615.89
[INFO 2017-06-26 18:44:43,055 main.py:47] epoch 2095, training loss: 2242.05, average training loss: 2026.92, base loss: 2616.40
[INFO 2017-06-26 18:44:43,365 main.py:47] epoch 2096, training loss: 2195.09, average training loss: 2027.31, base loss: 2617.02
[INFO 2017-06-26 18:44:43,675 main.py:47] epoch 2097, training loss: 2289.90, average training loss: 2027.54, base loss: 2617.50
[INFO 2017-06-26 18:44:43,982 main.py:47] epoch 2098, training loss: 2200.43, average training loss: 2028.05, base loss: 2618.06
[INFO 2017-06-26 18:44:44,291 main.py:47] epoch 2099, training loss: 2055.57, average training loss: 2028.33, base loss: 2618.23
[INFO 2017-06-26 18:44:44,291 main.py:49] epoch 2099, testing
[INFO 2017-06-26 18:44:48,349 main.py:100] average testing loss: 1999.09, base loss: 2600.14
[INFO 2017-06-26 18:44:48,375 main.py:73] current best accuracy: 1945.80
[INFO 2017-06-26 18:44:48,684 main.py:47] epoch 2100, training loss: 1837.33, average training loss: 2028.21, base loss: 2618.12
[INFO 2017-06-26 18:44:48,994 main.py:47] epoch 2101, training loss: 2071.31, average training loss: 2028.19, base loss: 2618.38
[INFO 2017-06-26 18:44:49,303 main.py:47] epoch 2102, training loss: 1892.74, average training loss: 2028.14, base loss: 2618.39
[INFO 2017-06-26 18:44:49,611 main.py:47] epoch 2103, training loss: 1847.58, average training loss: 2028.00, base loss: 2618.43
[INFO 2017-06-26 18:44:49,923 main.py:47] epoch 2104, training loss: 1724.81, average training loss: 2027.56, base loss: 2617.79
[INFO 2017-06-26 18:44:50,235 main.py:47] epoch 2105, training loss: 1805.09, average training loss: 2027.44, base loss: 2617.85
[INFO 2017-06-26 18:44:50,543 main.py:47] epoch 2106, training loss: 1892.97, average training loss: 2027.24, base loss: 2617.71
[INFO 2017-06-26 18:44:50,852 main.py:47] epoch 2107, training loss: 2473.41, average training loss: 2027.52, base loss: 2617.84
[INFO 2017-06-26 18:44:51,161 main.py:47] epoch 2108, training loss: 2254.05, average training loss: 2027.63, base loss: 2618.10
[INFO 2017-06-26 18:44:51,468 main.py:47] epoch 2109, training loss: 2177.93, average training loss: 2027.81, base loss: 2618.36
[INFO 2017-06-26 18:44:51,772 main.py:47] epoch 2110, training loss: 2187.48, average training loss: 2027.95, base loss: 2618.77
[INFO 2017-06-26 18:44:52,080 main.py:47] epoch 2111, training loss: 2104.53, average training loss: 2027.98, base loss: 2618.72
[INFO 2017-06-26 18:44:52,388 main.py:47] epoch 2112, training loss: 2101.36, average training loss: 2027.99, base loss: 2618.92
[INFO 2017-06-26 18:44:52,692 main.py:47] epoch 2113, training loss: 1853.40, average training loss: 2027.88, base loss: 2618.80
[INFO 2017-06-26 18:44:52,999 main.py:47] epoch 2114, training loss: 1859.44, average training loss: 2027.87, base loss: 2618.69
[INFO 2017-06-26 18:44:53,309 main.py:47] epoch 2115, training loss: 2083.44, average training loss: 2028.08, base loss: 2618.93
[INFO 2017-06-26 18:44:53,618 main.py:47] epoch 2116, training loss: 2155.40, average training loss: 2028.57, base loss: 2619.60
[INFO 2017-06-26 18:44:53,928 main.py:47] epoch 2117, training loss: 1748.17, average training loss: 2028.47, base loss: 2619.66
[INFO 2017-06-26 18:44:54,237 main.py:47] epoch 2118, training loss: 1956.54, average training loss: 2028.20, base loss: 2619.40
[INFO 2017-06-26 18:44:54,544 main.py:47] epoch 2119, training loss: 1900.65, average training loss: 2027.82, base loss: 2619.27
[INFO 2017-06-26 18:44:54,853 main.py:47] epoch 2120, training loss: 1920.11, average training loss: 2028.06, base loss: 2619.68
[INFO 2017-06-26 18:44:55,162 main.py:47] epoch 2121, training loss: 1726.35, average training loss: 2027.88, base loss: 2619.44
[INFO 2017-06-26 18:44:55,470 main.py:47] epoch 2122, training loss: 1959.46, average training loss: 2027.86, base loss: 2619.26
[INFO 2017-06-26 18:44:55,778 main.py:47] epoch 2123, training loss: 1892.32, average training loss: 2027.36, base loss: 2618.79
[INFO 2017-06-26 18:44:56,091 main.py:47] epoch 2124, training loss: 1752.92, average training loss: 2026.89, base loss: 2618.13
[INFO 2017-06-26 18:44:56,399 main.py:47] epoch 2125, training loss: 2151.21, average training loss: 2026.84, base loss: 2618.15
[INFO 2017-06-26 18:44:56,709 main.py:47] epoch 2126, training loss: 2064.90, average training loss: 2027.11, base loss: 2618.71
[INFO 2017-06-26 18:44:57,018 main.py:47] epoch 2127, training loss: 1718.79, average training loss: 2027.02, base loss: 2618.71
[INFO 2017-06-26 18:44:57,325 main.py:47] epoch 2128, training loss: 1960.09, average training loss: 2027.20, base loss: 2619.32
[INFO 2017-06-26 18:44:57,633 main.py:47] epoch 2129, training loss: 2014.86, average training loss: 2027.20, base loss: 2619.48
[INFO 2017-06-26 18:44:57,942 main.py:47] epoch 2130, training loss: 1770.99, average training loss: 2026.80, base loss: 2618.85
[INFO 2017-06-26 18:44:58,249 main.py:47] epoch 2131, training loss: 1879.40, average training loss: 2026.78, base loss: 2619.03
[INFO 2017-06-26 18:44:58,554 main.py:47] epoch 2132, training loss: 1850.38, average training loss: 2026.73, base loss: 2619.00
[INFO 2017-06-26 18:44:58,861 main.py:47] epoch 2133, training loss: 1778.32, average training loss: 2026.49, base loss: 2618.83
[INFO 2017-06-26 18:44:59,168 main.py:47] epoch 2134, training loss: 1966.54, average training loss: 2026.36, base loss: 2618.51
[INFO 2017-06-26 18:44:59,475 main.py:47] epoch 2135, training loss: 2420.77, average training loss: 2026.65, base loss: 2619.05
[INFO 2017-06-26 18:44:59,783 main.py:47] epoch 2136, training loss: 1603.94, average training loss: 2025.99, base loss: 2618.36
[INFO 2017-06-26 18:45:00,091 main.py:47] epoch 2137, training loss: 1993.31, average training loss: 2026.27, base loss: 2618.70
[INFO 2017-06-26 18:45:00,398 main.py:47] epoch 2138, training loss: 2046.17, average training loss: 2026.49, base loss: 2619.13
[INFO 2017-06-26 18:45:00,707 main.py:47] epoch 2139, training loss: 2073.05, average training loss: 2026.43, base loss: 2619.18
[INFO 2017-06-26 18:45:01,016 main.py:47] epoch 2140, training loss: 1839.55, average training loss: 2026.33, base loss: 2619.28
[INFO 2017-06-26 18:45:01,324 main.py:47] epoch 2141, training loss: 1764.13, average training loss: 2026.22, base loss: 2619.28
[INFO 2017-06-26 18:45:01,632 main.py:47] epoch 2142, training loss: 2169.72, average training loss: 2026.20, base loss: 2619.29
[INFO 2017-06-26 18:45:01,941 main.py:47] epoch 2143, training loss: 2021.29, average training loss: 2025.99, base loss: 2619.06
[INFO 2017-06-26 18:45:02,245 main.py:47] epoch 2144, training loss: 2003.39, average training loss: 2025.98, base loss: 2619.41
[INFO 2017-06-26 18:45:02,552 main.py:47] epoch 2145, training loss: 1777.12, average training loss: 2025.62, base loss: 2619.03
[INFO 2017-06-26 18:45:02,861 main.py:47] epoch 2146, training loss: 2032.58, average training loss: 2025.74, base loss: 2619.10
[INFO 2017-06-26 18:45:03,170 main.py:47] epoch 2147, training loss: 1994.12, average training loss: 2025.23, base loss: 2618.66
[INFO 2017-06-26 18:45:03,477 main.py:47] epoch 2148, training loss: 2179.90, average training loss: 2025.18, base loss: 2618.58
[INFO 2017-06-26 18:45:03,782 main.py:47] epoch 2149, training loss: 2042.72, average training loss: 2025.29, base loss: 2619.19
[INFO 2017-06-26 18:45:04,088 main.py:47] epoch 2150, training loss: 2146.21, average training loss: 2025.65, base loss: 2619.60
[INFO 2017-06-26 18:45:04,395 main.py:47] epoch 2151, training loss: 1812.43, average training loss: 2025.09, base loss: 2619.19
[INFO 2017-06-26 18:45:04,701 main.py:47] epoch 2152, training loss: 1956.44, average training loss: 2025.26, base loss: 2619.68
[INFO 2017-06-26 18:45:05,009 main.py:47] epoch 2153, training loss: 2082.41, average training loss: 2025.16, base loss: 2619.45
[INFO 2017-06-26 18:45:05,316 main.py:47] epoch 2154, training loss: 1900.70, average training loss: 2025.12, base loss: 2619.89
[INFO 2017-06-26 18:45:05,621 main.py:47] epoch 2155, training loss: 1980.05, average training loss: 2025.14, base loss: 2619.91
[INFO 2017-06-26 18:45:05,927 main.py:47] epoch 2156, training loss: 1982.44, average training loss: 2024.91, base loss: 2619.72
[INFO 2017-06-26 18:45:06,233 main.py:47] epoch 2157, training loss: 1932.19, average training loss: 2024.56, base loss: 2619.56
[INFO 2017-06-26 18:45:06,538 main.py:47] epoch 2158, training loss: 2238.53, average training loss: 2024.68, base loss: 2620.03
[INFO 2017-06-26 18:45:06,844 main.py:47] epoch 2159, training loss: 2196.56, average training loss: 2024.40, base loss: 2619.65
[INFO 2017-06-26 18:45:07,152 main.py:47] epoch 2160, training loss: 1875.95, average training loss: 2023.97, base loss: 2619.07
[INFO 2017-06-26 18:45:07,458 main.py:47] epoch 2161, training loss: 1852.73, average training loss: 2023.81, base loss: 2619.15
[INFO 2017-06-26 18:45:07,764 main.py:47] epoch 2162, training loss: 2090.25, average training loss: 2023.69, base loss: 2619.24
[INFO 2017-06-26 18:45:08,071 main.py:47] epoch 2163, training loss: 1816.44, average training loss: 2023.19, base loss: 2618.67
[INFO 2017-06-26 18:45:08,374 main.py:47] epoch 2164, training loss: 2441.89, average training loss: 2023.40, base loss: 2619.20
[INFO 2017-06-26 18:45:08,682 main.py:47] epoch 2165, training loss: 1925.74, average training loss: 2023.35, base loss: 2619.40
[INFO 2017-06-26 18:45:08,990 main.py:47] epoch 2166, training loss: 2100.66, average training loss: 2023.49, base loss: 2619.62
[INFO 2017-06-26 18:45:09,295 main.py:47] epoch 2167, training loss: 2130.03, average training loss: 2023.84, base loss: 2620.67
[INFO 2017-06-26 18:45:09,603 main.py:47] epoch 2168, training loss: 2225.42, average training loss: 2024.05, base loss: 2621.10
[INFO 2017-06-26 18:45:09,909 main.py:47] epoch 2169, training loss: 1855.64, average training loss: 2023.89, base loss: 2620.84
[INFO 2017-06-26 18:45:10,217 main.py:47] epoch 2170, training loss: 2318.58, average training loss: 2023.93, base loss: 2620.94
[INFO 2017-06-26 18:45:10,525 main.py:47] epoch 2171, training loss: 2270.40, average training loss: 2024.42, base loss: 2621.61
[INFO 2017-06-26 18:45:10,833 main.py:47] epoch 2172, training loss: 2017.87, average training loss: 2024.10, base loss: 2621.52
[INFO 2017-06-26 18:45:11,139 main.py:47] epoch 2173, training loss: 1898.50, average training loss: 2024.05, base loss: 2621.43
[INFO 2017-06-26 18:45:11,447 main.py:47] epoch 2174, training loss: 2143.09, average training loss: 2024.23, base loss: 2621.65
[INFO 2017-06-26 18:45:11,754 main.py:47] epoch 2175, training loss: 1757.94, average training loss: 2023.73, base loss: 2621.08
[INFO 2017-06-26 18:45:12,060 main.py:47] epoch 2176, training loss: 1805.63, average training loss: 2023.45, base loss: 2620.71
[INFO 2017-06-26 18:45:12,365 main.py:47] epoch 2177, training loss: 1800.61, average training loss: 2023.21, base loss: 2620.35
[INFO 2017-06-26 18:45:12,675 main.py:47] epoch 2178, training loss: 2039.24, average training loss: 2023.51, base loss: 2621.02
[INFO 2017-06-26 18:45:12,983 main.py:47] epoch 2179, training loss: 2496.32, average training loss: 2023.97, base loss: 2621.59
[INFO 2017-06-26 18:45:13,290 main.py:47] epoch 2180, training loss: 1995.61, average training loss: 2023.96, base loss: 2621.70
[INFO 2017-06-26 18:45:13,599 main.py:47] epoch 2181, training loss: 1923.21, average training loss: 2023.99, base loss: 2621.99
[INFO 2017-06-26 18:45:13,905 main.py:47] epoch 2182, training loss: 1830.29, average training loss: 2023.64, base loss: 2621.86
[INFO 2017-06-26 18:45:14,213 main.py:47] epoch 2183, training loss: 2371.86, average training loss: 2023.58, base loss: 2621.87
[INFO 2017-06-26 18:45:14,521 main.py:47] epoch 2184, training loss: 1740.93, average training loss: 2022.95, base loss: 2621.33
[INFO 2017-06-26 18:45:14,828 main.py:47] epoch 2185, training loss: 2223.81, average training loss: 2023.20, base loss: 2621.62
[INFO 2017-06-26 18:45:15,135 main.py:47] epoch 2186, training loss: 2162.00, average training loss: 2023.21, base loss: 2621.90
[INFO 2017-06-26 18:45:15,444 main.py:47] epoch 2187, training loss: 2117.59, average training loss: 2023.43, base loss: 2622.40
[INFO 2017-06-26 18:45:15,750 main.py:47] epoch 2188, training loss: 1927.51, average training loss: 2023.44, base loss: 2622.41
[INFO 2017-06-26 18:45:16,059 main.py:47] epoch 2189, training loss: 2001.61, average training loss: 2023.67, base loss: 2622.70
[INFO 2017-06-26 18:45:16,367 main.py:47] epoch 2190, training loss: 1934.15, average training loss: 2023.49, base loss: 2622.46
[INFO 2017-06-26 18:45:16,677 main.py:47] epoch 2191, training loss: 1850.53, average training loss: 2022.88, base loss: 2621.86
[INFO 2017-06-26 18:45:16,982 main.py:47] epoch 2192, training loss: 2005.06, average training loss: 2022.87, base loss: 2621.96
[INFO 2017-06-26 18:45:17,287 main.py:47] epoch 2193, training loss: 2295.18, average training loss: 2022.99, base loss: 2622.49
[INFO 2017-06-26 18:45:17,593 main.py:47] epoch 2194, training loss: 1979.40, average training loss: 2022.66, base loss: 2622.24
[INFO 2017-06-26 18:45:18,019 main.py:47] epoch 2195, training loss: 1755.80, average training loss: 2022.27, base loss: 2621.69
[INFO 2017-06-26 18:45:18,324 main.py:47] epoch 2196, training loss: 2003.30, average training loss: 2022.18, base loss: 2621.64
[INFO 2017-06-26 18:45:18,632 main.py:47] epoch 2197, training loss: 1966.05, average training loss: 2022.15, base loss: 2621.52
[INFO 2017-06-26 18:45:18,938 main.py:47] epoch 2198, training loss: 1717.18, average training loss: 2021.18, base loss: 2620.52
[INFO 2017-06-26 18:45:19,245 main.py:47] epoch 2199, training loss: 2132.18, average training loss: 2021.13, base loss: 2620.83
[INFO 2017-06-26 18:45:19,245 main.py:49] epoch 2199, testing
[INFO 2017-06-26 18:45:23,241 main.py:100] average testing loss: 2070.87, base loss: 2708.56
[INFO 2017-06-26 18:45:23,267 main.py:73] current best accuracy: 1945.80
[INFO 2017-06-26 18:45:23,576 main.py:47] epoch 2200, training loss: 2116.55, average training loss: 2020.69, base loss: 2620.31
[INFO 2017-06-26 18:45:23,883 main.py:47] epoch 2201, training loss: 1793.26, average training loss: 2020.28, base loss: 2620.07
[INFO 2017-06-26 18:45:24,187 main.py:47] epoch 2202, training loss: 1879.44, average training loss: 2020.17, base loss: 2619.96
[INFO 2017-06-26 18:45:24,494 main.py:47] epoch 2203, training loss: 2107.92, average training loss: 2020.13, base loss: 2620.04
[INFO 2017-06-26 18:45:24,801 main.py:47] epoch 2204, training loss: 1870.41, average training loss: 2019.84, base loss: 2619.81
[INFO 2017-06-26 18:45:25,108 main.py:47] epoch 2205, training loss: 2066.55, average training loss: 2019.76, base loss: 2619.98
[INFO 2017-06-26 18:45:25,415 main.py:47] epoch 2206, training loss: 2163.19, average training loss: 2019.90, base loss: 2620.35
[INFO 2017-06-26 18:45:25,722 main.py:47] epoch 2207, training loss: 1744.83, average training loss: 2019.76, base loss: 2620.11
[INFO 2017-06-26 18:45:26,029 main.py:47] epoch 2208, training loss: 1943.94, average training loss: 2019.81, base loss: 2620.21
[INFO 2017-06-26 18:45:26,338 main.py:47] epoch 2209, training loss: 1741.61, average training loss: 2019.49, base loss: 2619.76
[INFO 2017-06-26 18:45:26,646 main.py:47] epoch 2210, training loss: 1987.69, average training loss: 2019.59, base loss: 2620.03
[INFO 2017-06-26 18:45:26,954 main.py:47] epoch 2211, training loss: 1732.36, average training loss: 2019.13, base loss: 2619.28
[INFO 2017-06-26 18:45:27,261 main.py:47] epoch 2212, training loss: 1837.73, average training loss: 2018.69, base loss: 2618.86
[INFO 2017-06-26 18:45:27,569 main.py:47] epoch 2213, training loss: 2198.04, average training loss: 2018.77, base loss: 2619.27
[INFO 2017-06-26 18:45:27,874 main.py:47] epoch 2214, training loss: 1861.23, average training loss: 2018.81, base loss: 2619.34
[INFO 2017-06-26 18:45:28,181 main.py:47] epoch 2215, training loss: 2036.61, average training loss: 2019.17, base loss: 2619.86
[INFO 2017-06-26 18:45:28,488 main.py:47] epoch 2216, training loss: 1955.88, average training loss: 2019.21, base loss: 2620.11
[INFO 2017-06-26 18:45:28,795 main.py:47] epoch 2217, training loss: 1903.84, average training loss: 2019.12, base loss: 2619.99
[INFO 2017-06-26 18:45:29,103 main.py:47] epoch 2218, training loss: 1738.06, average training loss: 2018.92, base loss: 2619.87
[INFO 2017-06-26 18:45:29,409 main.py:47] epoch 2219, training loss: 1529.84, average training loss: 2018.52, base loss: 2619.15
[INFO 2017-06-26 18:45:29,715 main.py:47] epoch 2220, training loss: 1785.71, average training loss: 2018.11, base loss: 2618.81
[INFO 2017-06-26 18:45:30,020 main.py:47] epoch 2221, training loss: 2076.93, average training loss: 2017.95, base loss: 2618.73
[INFO 2017-06-26 18:45:30,326 main.py:47] epoch 2222, training loss: 1990.02, average training loss: 2017.89, base loss: 2618.81
[INFO 2017-06-26 18:45:30,634 main.py:47] epoch 2223, training loss: 2116.21, average training loss: 2018.14, base loss: 2619.48
[INFO 2017-06-26 18:45:30,942 main.py:47] epoch 2224, training loss: 1871.06, average training loss: 2017.75, base loss: 2619.30
[INFO 2017-06-26 18:45:31,249 main.py:47] epoch 2225, training loss: 1799.65, average training loss: 2017.61, base loss: 2619.13
[INFO 2017-06-26 18:45:31,557 main.py:47] epoch 2226, training loss: 2073.22, average training loss: 2017.79, base loss: 2619.66
[INFO 2017-06-26 18:45:31,864 main.py:47] epoch 2227, training loss: 2058.51, average training loss: 2018.00, base loss: 2620.13
[INFO 2017-06-26 18:45:32,171 main.py:47] epoch 2228, training loss: 2039.20, average training loss: 2017.95, base loss: 2620.13
[INFO 2017-06-26 18:45:32,479 main.py:47] epoch 2229, training loss: 2143.92, average training loss: 2017.78, base loss: 2620.03
[INFO 2017-06-26 18:45:32,786 main.py:47] epoch 2230, training loss: 1870.81, average training loss: 2017.56, base loss: 2619.76
[INFO 2017-06-26 18:45:33,092 main.py:47] epoch 2231, training loss: 2051.19, average training loss: 2017.67, base loss: 2619.98
[INFO 2017-06-26 18:45:33,398 main.py:47] epoch 2232, training loss: 1980.53, average training loss: 2017.51, base loss: 2619.75
[INFO 2017-06-26 18:45:33,706 main.py:47] epoch 2233, training loss: 2008.70, average training loss: 2017.45, base loss: 2619.78
[INFO 2017-06-26 18:45:34,014 main.py:47] epoch 2234, training loss: 2023.20, average training loss: 2017.37, base loss: 2619.75
[INFO 2017-06-26 18:45:34,320 main.py:47] epoch 2235, training loss: 1880.77, average training loss: 2016.86, base loss: 2619.09
[INFO 2017-06-26 18:45:34,625 main.py:47] epoch 2236, training loss: 1759.87, average training loss: 2016.54, base loss: 2618.88
[INFO 2017-06-26 18:45:34,932 main.py:47] epoch 2237, training loss: 1935.09, average training loss: 2016.19, base loss: 2618.56
[INFO 2017-06-26 18:45:35,238 main.py:47] epoch 2238, training loss: 1700.97, average training loss: 2015.74, base loss: 2618.16
[INFO 2017-06-26 18:45:35,545 main.py:47] epoch 2239, training loss: 1922.10, average training loss: 2015.74, base loss: 2618.18
[INFO 2017-06-26 18:45:35,853 main.py:47] epoch 2240, training loss: 2083.15, average training loss: 2015.57, base loss: 2617.99
[INFO 2017-06-26 18:45:36,164 main.py:47] epoch 2241, training loss: 1860.40, average training loss: 2015.52, base loss: 2617.73
[INFO 2017-06-26 18:45:36,474 main.py:47] epoch 2242, training loss: 2064.89, average training loss: 2015.39, base loss: 2617.80
[INFO 2017-06-26 18:45:36,780 main.py:47] epoch 2243, training loss: 2040.53, average training loss: 2015.55, base loss: 2618.24
[INFO 2017-06-26 18:45:37,089 main.py:47] epoch 2244, training loss: 1794.71, average training loss: 2015.25, base loss: 2618.13
[INFO 2017-06-26 18:45:37,397 main.py:47] epoch 2245, training loss: 1890.21, average training loss: 2015.31, base loss: 2618.30
[INFO 2017-06-26 18:45:37,708 main.py:47] epoch 2246, training loss: 1970.54, average training loss: 2015.18, base loss: 2618.31
[INFO 2017-06-26 18:45:38,015 main.py:47] epoch 2247, training loss: 1947.11, average training loss: 2015.01, base loss: 2618.09
[INFO 2017-06-26 18:45:38,322 main.py:47] epoch 2248, training loss: 1624.00, average training loss: 2014.64, base loss: 2617.51
[INFO 2017-06-26 18:45:38,632 main.py:47] epoch 2249, training loss: 2064.75, average training loss: 2014.53, base loss: 2617.41
[INFO 2017-06-26 18:45:38,937 main.py:47] epoch 2250, training loss: 1858.46, average training loss: 2014.29, base loss: 2617.14
[INFO 2017-06-26 18:45:39,244 main.py:47] epoch 2251, training loss: 1836.84, average training loss: 2013.98, base loss: 2616.87
[INFO 2017-06-26 18:45:39,554 main.py:47] epoch 2252, training loss: 2308.32, average training loss: 2013.91, base loss: 2616.99
[INFO 2017-06-26 18:45:39,860 main.py:47] epoch 2253, training loss: 2296.53, average training loss: 2014.22, base loss: 2617.54
[INFO 2017-06-26 18:45:40,171 main.py:47] epoch 2254, training loss: 1943.64, average training loss: 2014.13, base loss: 2617.63
[INFO 2017-06-26 18:45:40,480 main.py:47] epoch 2255, training loss: 2052.50, average training loss: 2013.95, base loss: 2617.76
[INFO 2017-06-26 18:45:40,789 main.py:47] epoch 2256, training loss: 2133.13, average training loss: 2014.16, base loss: 2618.31
[INFO 2017-06-26 18:45:41,098 main.py:47] epoch 2257, training loss: 1983.56, average training loss: 2014.03, base loss: 2618.25
[INFO 2017-06-26 18:45:41,403 main.py:47] epoch 2258, training loss: 2230.04, average training loss: 2014.39, base loss: 2618.75
[INFO 2017-06-26 18:45:41,708 main.py:47] epoch 2259, training loss: 1935.08, average training loss: 2014.09, base loss: 2618.65
[INFO 2017-06-26 18:45:42,019 main.py:47] epoch 2260, training loss: 2057.74, average training loss: 2013.83, base loss: 2618.41
[INFO 2017-06-26 18:45:42,326 main.py:47] epoch 2261, training loss: 2102.46, average training loss: 2014.04, base loss: 2618.63
[INFO 2017-06-26 18:45:42,634 main.py:47] epoch 2262, training loss: 1954.52, average training loss: 2014.08, base loss: 2618.86
[INFO 2017-06-26 18:45:42,943 main.py:47] epoch 2263, training loss: 2179.25, average training loss: 2014.18, base loss: 2619.28
[INFO 2017-06-26 18:45:43,255 main.py:47] epoch 2264, training loss: 2067.03, average training loss: 2014.29, base loss: 2619.71
[INFO 2017-06-26 18:45:43,564 main.py:47] epoch 2265, training loss: 1941.04, average training loss: 2013.89, base loss: 2619.35
[INFO 2017-06-26 18:45:43,871 main.py:47] epoch 2266, training loss: 1888.43, average training loss: 2013.76, base loss: 2619.37
[INFO 2017-06-26 18:45:44,178 main.py:47] epoch 2267, training loss: 1485.96, average training loss: 2013.25, base loss: 2618.67
[INFO 2017-06-26 18:45:44,484 main.py:47] epoch 2268, training loss: 1962.59, average training loss: 2013.28, base loss: 2618.71
[INFO 2017-06-26 18:45:44,791 main.py:47] epoch 2269, training loss: 2147.21, average training loss: 2013.56, base loss: 2619.43
[INFO 2017-06-26 18:45:45,098 main.py:47] epoch 2270, training loss: 2001.56, average training loss: 2013.29, base loss: 2619.24
[INFO 2017-06-26 18:45:45,403 main.py:47] epoch 2271, training loss: 1982.38, average training loss: 2013.45, base loss: 2619.54
[INFO 2017-06-26 18:45:45,713 main.py:47] epoch 2272, training loss: 2132.77, average training loss: 2013.83, base loss: 2620.05
[INFO 2017-06-26 18:45:46,022 main.py:47] epoch 2273, training loss: 1870.79, average training loss: 2013.53, base loss: 2619.69
[INFO 2017-06-26 18:45:46,330 main.py:47] epoch 2274, training loss: 2126.00, average training loss: 2013.87, base loss: 2620.08
[INFO 2017-06-26 18:45:46,639 main.py:47] epoch 2275, training loss: 1981.47, average training loss: 2013.90, base loss: 2620.34
[INFO 2017-06-26 18:45:46,943 main.py:47] epoch 2276, training loss: 2000.39, average training loss: 2013.76, base loss: 2620.36
[INFO 2017-06-26 18:45:47,249 main.py:47] epoch 2277, training loss: 1792.27, average training loss: 2013.87, base loss: 2620.62
[INFO 2017-06-26 18:45:47,555 main.py:47] epoch 2278, training loss: 2190.58, average training loss: 2013.73, base loss: 2620.45
[INFO 2017-06-26 18:45:47,862 main.py:47] epoch 2279, training loss: 1951.60, average training loss: 2013.51, base loss: 2620.32
[INFO 2017-06-26 18:45:48,171 main.py:47] epoch 2280, training loss: 2008.15, average training loss: 2013.66, base loss: 2620.62
[INFO 2017-06-26 18:45:48,479 main.py:47] epoch 2281, training loss: 2091.93, average training loss: 2013.77, base loss: 2620.77
[INFO 2017-06-26 18:45:48,785 main.py:47] epoch 2282, training loss: 2069.67, average training loss: 2013.39, base loss: 2620.30
[INFO 2017-06-26 18:45:49,092 main.py:47] epoch 2283, training loss: 2100.08, average training loss: 2013.54, base loss: 2620.79
[INFO 2017-06-26 18:45:49,400 main.py:47] epoch 2284, training loss: 1936.12, average training loss: 2013.54, base loss: 2620.95
[INFO 2017-06-26 18:45:49,707 main.py:47] epoch 2285, training loss: 2147.37, average training loss: 2013.56, base loss: 2621.18
[INFO 2017-06-26 18:45:50,013 main.py:47] epoch 2286, training loss: 2028.39, average training loss: 2013.30, base loss: 2621.02
[INFO 2017-06-26 18:45:50,316 main.py:47] epoch 2287, training loss: 2249.02, average training loss: 2013.28, base loss: 2621.16
[INFO 2017-06-26 18:45:50,621 main.py:47] epoch 2288, training loss: 2270.02, average training loss: 2013.29, base loss: 2621.18
[INFO 2017-06-26 18:45:50,929 main.py:47] epoch 2289, training loss: 1856.62, average training loss: 2013.21, base loss: 2621.25
[INFO 2017-06-26 18:45:51,242 main.py:47] epoch 2290, training loss: 2118.23, average training loss: 2013.66, base loss: 2621.83
[INFO 2017-06-26 18:45:51,549 main.py:47] epoch 2291, training loss: 2082.81, average training loss: 2013.68, base loss: 2621.91
[INFO 2017-06-26 18:45:51,857 main.py:47] epoch 2292, training loss: 1773.44, average training loss: 2013.34, base loss: 2621.37
[INFO 2017-06-26 18:45:52,161 main.py:47] epoch 2293, training loss: 1883.73, average training loss: 2013.24, base loss: 2621.35
[INFO 2017-06-26 18:45:52,469 main.py:47] epoch 2294, training loss: 1927.15, average training loss: 2013.37, base loss: 2621.64
[INFO 2017-06-26 18:45:52,777 main.py:47] epoch 2295, training loss: 1903.15, average training loss: 2013.47, base loss: 2621.98
[INFO 2017-06-26 18:45:53,082 main.py:47] epoch 2296, training loss: 1774.28, average training loss: 2013.13, base loss: 2621.57
[INFO 2017-06-26 18:45:53,390 main.py:47] epoch 2297, training loss: 1949.01, average training loss: 2012.98, base loss: 2621.52
[INFO 2017-06-26 18:45:53,699 main.py:47] epoch 2298, training loss: 1892.50, average training loss: 2012.68, base loss: 2621.10
[INFO 2017-06-26 18:45:54,003 main.py:47] epoch 2299, training loss: 1933.27, average training loss: 2012.76, base loss: 2621.39
[INFO 2017-06-26 18:45:54,003 main.py:49] epoch 2299, testing
[INFO 2017-06-26 18:45:57,967 main.py:100] average testing loss: 2003.77, base loss: 2673.25
[INFO 2017-06-26 18:45:57,991 main.py:73] current best accuracy: 1945.80
[INFO 2017-06-26 18:45:58,296 main.py:47] epoch 2300, training loss: 1950.02, average training loss: 2012.57, base loss: 2621.22
[INFO 2017-06-26 18:45:58,600 main.py:47] epoch 2301, training loss: 2044.65, average training loss: 2012.34, base loss: 2621.04
[INFO 2017-06-26 18:45:58,904 main.py:47] epoch 2302, training loss: 2314.24, average training loss: 2012.64, base loss: 2621.66
[INFO 2017-06-26 18:45:59,212 main.py:47] epoch 2303, training loss: 2397.72, average training loss: 2013.08, base loss: 2622.34
[INFO 2017-06-26 18:45:59,518 main.py:47] epoch 2304, training loss: 1993.28, average training loss: 2013.10, base loss: 2622.02
[INFO 2017-06-26 18:45:59,828 main.py:47] epoch 2305, training loss: 1984.37, average training loss: 2013.14, base loss: 2621.98
[INFO 2017-06-26 18:46:00,136 main.py:47] epoch 2306, training loss: 2367.25, average training loss: 2013.65, base loss: 2622.63
[INFO 2017-06-26 18:46:00,437 main.py:47] epoch 2307, training loss: 2263.63, average training loss: 2013.64, base loss: 2622.65
[INFO 2017-06-26 18:46:00,745 main.py:47] epoch 2308, training loss: 2007.08, average training loss: 2013.68, base loss: 2622.81
[INFO 2017-06-26 18:46:01,054 main.py:47] epoch 2309, training loss: 2148.36, average training loss: 2013.85, base loss: 2622.98
[INFO 2017-06-26 18:46:01,365 main.py:47] epoch 2310, training loss: 2322.64, average training loss: 2014.07, base loss: 2623.44
[INFO 2017-06-26 18:46:01,674 main.py:47] epoch 2311, training loss: 2582.78, average training loss: 2014.40, base loss: 2623.97
[INFO 2017-06-26 18:46:01,981 main.py:47] epoch 2312, training loss: 2057.04, average training loss: 2014.59, base loss: 2624.20
[INFO 2017-06-26 18:46:02,292 main.py:47] epoch 2313, training loss: 1913.37, average training loss: 2013.83, base loss: 2623.46
[INFO 2017-06-26 18:46:02,604 main.py:47] epoch 2314, training loss: 1987.95, average training loss: 2014.01, base loss: 2623.82
[INFO 2017-06-26 18:46:02,912 main.py:47] epoch 2315, training loss: 1916.03, average training loss: 2013.66, base loss: 2623.29
[INFO 2017-06-26 18:46:03,221 main.py:47] epoch 2316, training loss: 1827.98, average training loss: 2013.58, base loss: 2623.07
[INFO 2017-06-26 18:46:03,529 main.py:47] epoch 2317, training loss: 1919.08, average training loss: 2013.27, base loss: 2622.55
[INFO 2017-06-26 18:46:03,840 main.py:47] epoch 2318, training loss: 2091.18, average training loss: 2013.35, base loss: 2622.68
[INFO 2017-06-26 18:46:04,151 main.py:47] epoch 2319, training loss: 1815.42, average training loss: 2013.08, base loss: 2622.21
[INFO 2017-06-26 18:46:04,463 main.py:47] epoch 2320, training loss: 1807.08, average training loss: 2012.76, base loss: 2621.74
[INFO 2017-06-26 18:46:04,774 main.py:47] epoch 2321, training loss: 1722.08, average training loss: 2012.37, base loss: 2621.29
[INFO 2017-06-26 18:46:05,083 main.py:47] epoch 2322, training loss: 2326.85, average training loss: 2012.78, base loss: 2621.81
[INFO 2017-06-26 18:46:05,394 main.py:47] epoch 2323, training loss: 2101.31, average training loss: 2012.68, base loss: 2621.84
[INFO 2017-06-26 18:46:05,704 main.py:47] epoch 2324, training loss: 2050.46, average training loss: 2012.66, base loss: 2621.99
[INFO 2017-06-26 18:46:06,009 main.py:47] epoch 2325, training loss: 1928.09, average training loss: 2012.35, base loss: 2621.75
[INFO 2017-06-26 18:46:06,314 main.py:47] epoch 2326, training loss: 1787.82, average training loss: 2012.07, base loss: 2621.39
[INFO 2017-06-26 18:46:06,623 main.py:47] epoch 2327, training loss: 1973.52, average training loss: 2012.00, base loss: 2621.33
[INFO 2017-06-26 18:46:06,931 main.py:47] epoch 2328, training loss: 1917.10, average training loss: 2011.95, base loss: 2621.39
[INFO 2017-06-26 18:46:07,238 main.py:47] epoch 2329, training loss: 1810.83, average training loss: 2011.63, base loss: 2620.97
[INFO 2017-06-26 18:46:07,542 main.py:47] epoch 2330, training loss: 2087.65, average training loss: 2011.68, base loss: 2621.28
[INFO 2017-06-26 18:46:07,848 main.py:47] epoch 2331, training loss: 1966.25, average training loss: 2011.39, base loss: 2620.37
[INFO 2017-06-26 18:46:08,153 main.py:47] epoch 2332, training loss: 2049.72, average training loss: 2011.27, base loss: 2620.34
[INFO 2017-06-26 18:46:08,461 main.py:47] epoch 2333, training loss: 1977.11, average training loss: 2011.24, base loss: 2620.15
[INFO 2017-06-26 18:46:08,767 main.py:47] epoch 2334, training loss: 2061.33, average training loss: 2010.92, base loss: 2619.46
[INFO 2017-06-26 18:46:09,073 main.py:47] epoch 2335, training loss: 2186.49, average training loss: 2011.20, base loss: 2620.12
[INFO 2017-06-26 18:46:09,375 main.py:47] epoch 2336, training loss: 1960.17, average training loss: 2011.07, base loss: 2619.98
[INFO 2017-06-26 18:46:09,684 main.py:47] epoch 2337, training loss: 2289.29, average training loss: 2011.48, base loss: 2620.65
[INFO 2017-06-26 18:46:09,991 main.py:47] epoch 2338, training loss: 1847.69, average training loss: 2011.34, base loss: 2620.57
[INFO 2017-06-26 18:46:10,295 main.py:47] epoch 2339, training loss: 1939.70, average training loss: 2011.18, base loss: 2620.43
[INFO 2017-06-26 18:46:10,602 main.py:47] epoch 2340, training loss: 1534.88, average training loss: 2010.64, base loss: 2619.96
[INFO 2017-06-26 18:46:10,907 main.py:47] epoch 2341, training loss: 2288.31, average training loss: 2010.79, base loss: 2620.40
[INFO 2017-06-26 18:46:11,214 main.py:47] epoch 2342, training loss: 2087.31, average training loss: 2010.60, base loss: 2620.18
[INFO 2017-06-26 18:46:11,518 main.py:47] epoch 2343, training loss: 1817.32, average training loss: 2010.41, base loss: 2619.73
[INFO 2017-06-26 18:46:11,824 main.py:47] epoch 2344, training loss: 1863.30, average training loss: 2010.56, base loss: 2620.10
[INFO 2017-06-26 18:46:12,132 main.py:47] epoch 2345, training loss: 2452.58, average training loss: 2010.64, base loss: 2620.52
[INFO 2017-06-26 18:46:12,441 main.py:47] epoch 2346, training loss: 1986.85, average training loss: 2010.80, base loss: 2620.97
[INFO 2017-06-26 18:46:12,746 main.py:47] epoch 2347, training loss: 1975.02, average training loss: 2010.74, base loss: 2621.35
[INFO 2017-06-26 18:46:13,055 main.py:47] epoch 2348, training loss: 1755.91, average training loss: 2010.57, base loss: 2621.18
[INFO 2017-06-26 18:46:13,366 main.py:47] epoch 2349, training loss: 1841.36, average training loss: 2010.40, base loss: 2621.19
[INFO 2017-06-26 18:46:13,678 main.py:47] epoch 2350, training loss: 2219.67, average training loss: 2010.84, base loss: 2622.02
[INFO 2017-06-26 18:46:13,988 main.py:47] epoch 2351, training loss: 1893.62, average training loss: 2011.09, base loss: 2622.55
[INFO 2017-06-26 18:46:14,298 main.py:47] epoch 2352, training loss: 1831.13, average training loss: 2010.90, base loss: 2622.13
[INFO 2017-06-26 18:46:14,607 main.py:47] epoch 2353, training loss: 2152.06, average training loss: 2010.87, base loss: 2622.10
[INFO 2017-06-26 18:46:14,913 main.py:47] epoch 2354, training loss: 1957.13, average training loss: 2010.95, base loss: 2622.39
[INFO 2017-06-26 18:46:15,220 main.py:47] epoch 2355, training loss: 2011.69, average training loss: 2010.81, base loss: 2622.20
[INFO 2017-06-26 18:46:15,529 main.py:47] epoch 2356, training loss: 1820.57, average training loss: 2010.70, base loss: 2622.24
[INFO 2017-06-26 18:46:15,836 main.py:47] epoch 2357, training loss: 2006.78, average training loss: 2010.80, base loss: 2622.27
[INFO 2017-06-26 18:46:16,140 main.py:47] epoch 2358, training loss: 1785.66, average training loss: 2010.38, base loss: 2621.75
[INFO 2017-06-26 18:46:16,449 main.py:47] epoch 2359, training loss: 2188.83, average training loss: 2010.59, base loss: 2622.28
[INFO 2017-06-26 18:46:16,754 main.py:47] epoch 2360, training loss: 1633.56, average training loss: 2009.95, base loss: 2621.47
[INFO 2017-06-26 18:46:17,062 main.py:47] epoch 2361, training loss: 2043.35, average training loss: 2009.85, base loss: 2621.25
[INFO 2017-06-26 18:46:17,368 main.py:47] epoch 2362, training loss: 1566.82, average training loss: 2009.51, base loss: 2621.17
[INFO 2017-06-26 18:46:17,675 main.py:47] epoch 2363, training loss: 2105.43, average training loss: 2009.33, base loss: 2620.61
[INFO 2017-06-26 18:46:17,980 main.py:47] epoch 2364, training loss: 1960.30, average training loss: 2009.40, base loss: 2620.72
[INFO 2017-06-26 18:46:18,286 main.py:47] epoch 2365, training loss: 2087.89, average training loss: 2009.42, base loss: 2620.86
[INFO 2017-06-26 18:46:18,593 main.py:47] epoch 2366, training loss: 2127.54, average training loss: 2009.73, base loss: 2621.36
[INFO 2017-06-26 18:46:18,901 main.py:47] epoch 2367, training loss: 2249.92, average training loss: 2009.82, base loss: 2621.30
[INFO 2017-06-26 18:46:19,209 main.py:47] epoch 2368, training loss: 2083.72, average training loss: 2010.11, base loss: 2622.25
[INFO 2017-06-26 18:46:19,517 main.py:47] epoch 2369, training loss: 1721.69, average training loss: 2009.90, base loss: 2622.18
[INFO 2017-06-26 18:46:19,824 main.py:47] epoch 2370, training loss: 1921.44, average training loss: 2009.80, base loss: 2621.99
[INFO 2017-06-26 18:46:20,128 main.py:47] epoch 2371, training loss: 2156.63, average training loss: 2010.03, base loss: 2622.45
[INFO 2017-06-26 18:46:20,434 main.py:47] epoch 2372, training loss: 2236.94, average training loss: 2010.50, base loss: 2623.40
[INFO 2017-06-26 18:46:20,739 main.py:47] epoch 2373, training loss: 1905.30, average training loss: 2010.58, base loss: 2623.54
[INFO 2017-06-26 18:46:21,044 main.py:47] epoch 2374, training loss: 1920.23, average training loss: 2010.26, base loss: 2623.25
[INFO 2017-06-26 18:46:21,349 main.py:47] epoch 2375, training loss: 2273.50, average training loss: 2010.38, base loss: 2623.58
[INFO 2017-06-26 18:46:21,657 main.py:47] epoch 2376, training loss: 2538.58, average training loss: 2011.06, base loss: 2624.53
[INFO 2017-06-26 18:46:21,961 main.py:47] epoch 2377, training loss: 2162.00, average training loss: 2011.21, base loss: 2624.85
[INFO 2017-06-26 18:46:22,266 main.py:47] epoch 2378, training loss: 2040.16, average training loss: 2011.30, base loss: 2624.97
[INFO 2017-06-26 18:46:22,570 main.py:47] epoch 2379, training loss: 2075.60, average training loss: 2011.33, base loss: 2625.01
[INFO 2017-06-26 18:46:22,874 main.py:47] epoch 2380, training loss: 2164.01, average training loss: 2011.67, base loss: 2625.55
[INFO 2017-06-26 18:46:23,176 main.py:47] epoch 2381, training loss: 1970.04, average training loss: 2011.74, base loss: 2626.12
[INFO 2017-06-26 18:46:23,484 main.py:47] epoch 2382, training loss: 2165.63, average training loss: 2011.67, base loss: 2625.90
[INFO 2017-06-26 18:46:23,789 main.py:47] epoch 2383, training loss: 1813.32, average training loss: 2010.98, base loss: 2624.82
[INFO 2017-06-26 18:46:24,091 main.py:47] epoch 2384, training loss: 1970.22, average training loss: 2011.05, base loss: 2625.03
[INFO 2017-06-26 18:46:24,398 main.py:47] epoch 2385, training loss: 2086.67, average training loss: 2011.15, base loss: 2625.30
[INFO 2017-06-26 18:46:24,704 main.py:47] epoch 2386, training loss: 2106.84, average training loss: 2011.28, base loss: 2625.37
[INFO 2017-06-26 18:46:25,010 main.py:47] epoch 2387, training loss: 1855.81, average training loss: 2011.18, base loss: 2625.17
[INFO 2017-06-26 18:46:25,317 main.py:47] epoch 2388, training loss: 1895.72, average training loss: 2011.07, base loss: 2624.93
[INFO 2017-06-26 18:46:25,626 main.py:47] epoch 2389, training loss: 2220.52, average training loss: 2011.29, base loss: 2625.29
[INFO 2017-06-26 18:46:25,933 main.py:47] epoch 2390, training loss: 2063.34, average training loss: 2011.43, base loss: 2625.45
[INFO 2017-06-26 18:46:26,242 main.py:47] epoch 2391, training loss: 2108.27, average training loss: 2011.77, base loss: 2626.02
[INFO 2017-06-26 18:46:26,548 main.py:47] epoch 2392, training loss: 1990.48, average training loss: 2011.83, base loss: 2626.35
[INFO 2017-06-26 18:46:26,855 main.py:47] epoch 2393, training loss: 2004.42, average training loss: 2011.99, base loss: 2626.60
[INFO 2017-06-26 18:46:27,162 main.py:47] epoch 2394, training loss: 1916.51, average training loss: 2011.40, base loss: 2625.81
[INFO 2017-06-26 18:46:27,469 main.py:47] epoch 2395, training loss: 1666.56, average training loss: 2011.14, base loss: 2625.58
[INFO 2017-06-26 18:46:27,778 main.py:47] epoch 2396, training loss: 1882.56, average training loss: 2010.74, base loss: 2625.02
[INFO 2017-06-26 18:46:28,085 main.py:47] epoch 2397, training loss: 1916.61, average training loss: 2010.75, base loss: 2624.94
[INFO 2017-06-26 18:46:28,392 main.py:47] epoch 2398, training loss: 2264.43, average training loss: 2010.96, base loss: 2625.30
[INFO 2017-06-26 18:46:28,698 main.py:47] epoch 2399, training loss: 2052.13, average training loss: 2010.98, base loss: 2625.30
[INFO 2017-06-26 18:46:28,699 main.py:49] epoch 2399, testing
[INFO 2017-06-26 18:46:32,725 main.py:100] average testing loss: 1892.94, base loss: 2521.99
[INFO 2017-06-26 18:46:32,748 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:46:32,761 main.py:73] current best accuracy: 1892.94
[INFO 2017-06-26 18:46:33,067 main.py:47] epoch 2400, training loss: 1941.54, average training loss: 2010.59, base loss: 2624.70
[INFO 2017-06-26 18:46:33,372 main.py:47] epoch 2401, training loss: 2234.87, average training loss: 2010.64, base loss: 2624.65
[INFO 2017-06-26 18:46:33,677 main.py:47] epoch 2402, training loss: 1779.16, average training loss: 2010.61, base loss: 2624.67
[INFO 2017-06-26 18:46:33,984 main.py:47] epoch 2403, training loss: 2191.02, average training loss: 2011.05, base loss: 2625.52
[INFO 2017-06-26 18:46:34,290 main.py:47] epoch 2404, training loss: 2049.61, average training loss: 2011.11, base loss: 2625.71
[INFO 2017-06-26 18:46:34,594 main.py:47] epoch 2405, training loss: 1828.10, average training loss: 2010.98, base loss: 2625.56
[INFO 2017-06-26 18:46:34,900 main.py:47] epoch 2406, training loss: 2180.32, average training loss: 2010.95, base loss: 2625.82
[INFO 2017-06-26 18:46:35,203 main.py:47] epoch 2407, training loss: 1856.75, average training loss: 2011.02, base loss: 2625.93
[INFO 2017-06-26 18:46:35,510 main.py:47] epoch 2408, training loss: 1841.52, average training loss: 2010.78, base loss: 2625.66
[INFO 2017-06-26 18:46:35,815 main.py:47] epoch 2409, training loss: 2103.82, average training loss: 2010.97, base loss: 2626.05
[INFO 2017-06-26 18:46:36,123 main.py:47] epoch 2410, training loss: 2059.39, average training loss: 2010.91, base loss: 2626.18
[INFO 2017-06-26 18:46:36,430 main.py:47] epoch 2411, training loss: 1809.80, average training loss: 2010.87, base loss: 2626.02
[INFO 2017-06-26 18:46:36,734 main.py:47] epoch 2412, training loss: 1908.57, average training loss: 2011.02, base loss: 2626.23
[INFO 2017-06-26 18:46:37,040 main.py:47] epoch 2413, training loss: 1938.33, average training loss: 2010.62, base loss: 2625.77
[INFO 2017-06-26 18:46:37,346 main.py:47] epoch 2414, training loss: 2129.64, average training loss: 2011.11, base loss: 2626.44
[INFO 2017-06-26 18:46:37,653 main.py:47] epoch 2415, training loss: 1889.94, average training loss: 2010.85, base loss: 2626.16
[INFO 2017-06-26 18:46:37,958 main.py:47] epoch 2416, training loss: 1746.48, average training loss: 2010.31, base loss: 2625.53
[INFO 2017-06-26 18:46:38,263 main.py:47] epoch 2417, training loss: 2019.57, average training loss: 2010.57, base loss: 2626.24
[INFO 2017-06-26 18:46:38,566 main.py:47] epoch 2418, training loss: 2031.71, average training loss: 2010.77, base loss: 2626.81
[INFO 2017-06-26 18:46:38,923 main.py:47] epoch 2419, training loss: 1936.91, average training loss: 2010.96, base loss: 2627.23
[INFO 2017-06-26 18:46:39,273 main.py:47] epoch 2420, training loss: 1936.80, average training loss: 2011.04, base loss: 2627.40
[INFO 2017-06-26 18:46:39,582 main.py:47] epoch 2421, training loss: 2089.11, average training loss: 2011.00, base loss: 2627.48
[INFO 2017-06-26 18:46:39,891 main.py:47] epoch 2422, training loss: 2112.38, average training loss: 2010.70, base loss: 2626.95
[INFO 2017-06-26 18:46:40,201 main.py:47] epoch 2423, training loss: 1979.82, average training loss: 2010.83, base loss: 2627.28
[INFO 2017-06-26 18:46:40,509 main.py:47] epoch 2424, training loss: 2237.63, average training loss: 2011.08, base loss: 2627.39
[INFO 2017-06-26 18:46:40,813 main.py:47] epoch 2425, training loss: 2220.70, average training loss: 2011.01, base loss: 2627.35
[INFO 2017-06-26 18:46:41,117 main.py:47] epoch 2426, training loss: 1880.88, average training loss: 2010.82, base loss: 2627.22
[INFO 2017-06-26 18:46:41,421 main.py:47] epoch 2427, training loss: 1649.90, average training loss: 2010.38, base loss: 2626.74
[INFO 2017-06-26 18:46:41,728 main.py:47] epoch 2428, training loss: 2310.51, average training loss: 2010.71, base loss: 2627.17
[INFO 2017-06-26 18:46:42,036 main.py:47] epoch 2429, training loss: 1949.25, average training loss: 2010.77, base loss: 2627.42
[INFO 2017-06-26 18:46:42,375 main.py:47] epoch 2430, training loss: 2085.64, average training loss: 2011.19, base loss: 2628.23
[INFO 2017-06-26 18:46:42,710 main.py:47] epoch 2431, training loss: 1837.14, average training loss: 2010.77, base loss: 2627.78
[INFO 2017-06-26 18:46:43,015 main.py:47] epoch 2432, training loss: 1989.18, average training loss: 2011.06, base loss: 2628.43
[INFO 2017-06-26 18:46:43,334 main.py:47] epoch 2433, training loss: 1725.01, average training loss: 2011.00, base loss: 2628.33
[INFO 2017-06-26 18:46:43,642 main.py:47] epoch 2434, training loss: 1902.61, average training loss: 2010.85, base loss: 2628.34
[INFO 2017-06-26 18:46:43,948 main.py:47] epoch 2435, training loss: 1757.80, average training loss: 2010.41, base loss: 2628.04
[INFO 2017-06-26 18:46:44,255 main.py:47] epoch 2436, training loss: 1931.30, average training loss: 2010.45, base loss: 2628.23
[INFO 2017-06-26 18:46:44,561 main.py:47] epoch 2437, training loss: 1929.22, average training loss: 2010.36, base loss: 2628.56
[INFO 2017-06-26 18:46:44,867 main.py:47] epoch 2438, training loss: 1688.06, average training loss: 2009.95, base loss: 2628.09
[INFO 2017-06-26 18:46:45,219 main.py:47] epoch 2439, training loss: 2283.84, average training loss: 2009.87, base loss: 2628.02
[INFO 2017-06-26 18:46:45,566 main.py:47] epoch 2440, training loss: 1773.22, average training loss: 2009.76, base loss: 2627.77
[INFO 2017-06-26 18:46:45,875 main.py:47] epoch 2441, training loss: 2500.84, average training loss: 2010.25, base loss: 2628.50
[INFO 2017-06-26 18:46:46,183 main.py:47] epoch 2442, training loss: 1989.29, average training loss: 2010.40, base loss: 2628.83
[INFO 2017-06-26 18:46:46,488 main.py:47] epoch 2443, training loss: 1905.27, average training loss: 2010.40, base loss: 2629.39
[INFO 2017-06-26 18:46:46,791 main.py:47] epoch 2444, training loss: 1967.19, average training loss: 2010.15, base loss: 2629.25
[INFO 2017-06-26 18:46:47,099 main.py:47] epoch 2445, training loss: 2186.74, average training loss: 2010.21, base loss: 2629.08
[INFO 2017-06-26 18:46:47,403 main.py:47] epoch 2446, training loss: 1930.39, average training loss: 2010.16, base loss: 2629.33
[INFO 2017-06-26 18:46:47,707 main.py:47] epoch 2447, training loss: 2320.95, average training loss: 2010.16, base loss: 2629.63
[INFO 2017-06-26 18:46:48,015 main.py:47] epoch 2448, training loss: 1782.30, average training loss: 2009.70, base loss: 2629.07
[INFO 2017-06-26 18:46:48,321 main.py:47] epoch 2449, training loss: 2064.16, average training loss: 2009.73, base loss: 2629.23
[INFO 2017-06-26 18:46:48,628 main.py:47] epoch 2450, training loss: 2120.56, average training loss: 2009.83, base loss: 2629.41
[INFO 2017-06-26 18:46:48,935 main.py:47] epoch 2451, training loss: 1963.25, average training loss: 2009.80, base loss: 2629.40
[INFO 2017-06-26 18:46:49,238 main.py:47] epoch 2452, training loss: 2371.03, average training loss: 2009.95, base loss: 2629.80
[INFO 2017-06-26 18:46:49,541 main.py:47] epoch 2453, training loss: 2038.45, average training loss: 2009.62, base loss: 2629.38
[INFO 2017-06-26 18:46:49,847 main.py:47] epoch 2454, training loss: 1898.96, average training loss: 2009.41, base loss: 2629.14
[INFO 2017-06-26 18:46:50,150 main.py:47] epoch 2455, training loss: 1863.65, average training loss: 2009.37, base loss: 2629.03
[INFO 2017-06-26 18:46:50,452 main.py:47] epoch 2456, training loss: 1827.98, average training loss: 2009.28, base loss: 2629.12
[INFO 2017-06-26 18:46:50,842 main.py:47] epoch 2457, training loss: 2029.49, average training loss: 2009.30, base loss: 2629.09
[INFO 2017-06-26 18:46:51,168 main.py:47] epoch 2458, training loss: 1962.08, average training loss: 2009.38, base loss: 2629.30
[INFO 2017-06-26 18:46:51,478 main.py:47] epoch 2459, training loss: 1967.08, average training loss: 2009.43, base loss: 2629.70
[INFO 2017-06-26 18:46:51,788 main.py:47] epoch 2460, training loss: 1820.80, average training loss: 2009.03, base loss: 2629.21
[INFO 2017-06-26 18:46:52,093 main.py:47] epoch 2461, training loss: 2327.18, average training loss: 2009.52, base loss: 2630.00
[INFO 2017-06-26 18:46:52,486 main.py:47] epoch 2462, training loss: 1901.35, average training loss: 2009.44, base loss: 2629.99
[INFO 2017-06-26 18:46:52,871 main.py:47] epoch 2463, training loss: 1781.90, average training loss: 2009.18, base loss: 2629.93
[INFO 2017-06-26 18:46:53,181 main.py:47] epoch 2464, training loss: 2038.53, average training loss: 2008.97, base loss: 2629.71
[INFO 2017-06-26 18:46:53,494 main.py:47] epoch 2465, training loss: 1937.24, average training loss: 2009.07, base loss: 2630.04
[INFO 2017-06-26 18:46:53,808 main.py:47] epoch 2466, training loss: 2059.93, average training loss: 2008.75, base loss: 2629.56
[INFO 2017-06-26 18:46:54,115 main.py:47] epoch 2467, training loss: 1855.92, average training loss: 2008.90, base loss: 2629.80
[INFO 2017-06-26 18:46:54,507 main.py:47] epoch 2468, training loss: 2215.22, average training loss: 2009.17, base loss: 2630.21
[INFO 2017-06-26 18:46:54,835 main.py:47] epoch 2469, training loss: 1932.50, average training loss: 2009.02, base loss: 2630.07
[INFO 2017-06-26 18:46:55,145 main.py:47] epoch 2470, training loss: 2145.86, average training loss: 2009.02, base loss: 2630.10
[INFO 2017-06-26 18:46:55,458 main.py:47] epoch 2471, training loss: 1925.40, average training loss: 2008.62, base loss: 2629.80
[INFO 2017-06-26 18:46:55,767 main.py:47] epoch 2472, training loss: 1968.28, average training loss: 2008.68, base loss: 2629.85
[INFO 2017-06-26 18:46:56,075 main.py:47] epoch 2473, training loss: 1964.91, average training loss: 2008.68, base loss: 2629.76
[INFO 2017-06-26 18:46:56,382 main.py:47] epoch 2474, training loss: 1972.44, average training loss: 2008.61, base loss: 2629.78
[INFO 2017-06-26 18:46:56,691 main.py:47] epoch 2475, training loss: 1898.37, average training loss: 2008.70, base loss: 2630.24
[INFO 2017-06-26 18:46:56,997 main.py:47] epoch 2476, training loss: 1814.15, average training loss: 2008.34, base loss: 2629.69
[INFO 2017-06-26 18:46:57,322 main.py:47] epoch 2477, training loss: 1863.63, average training loss: 2008.40, base loss: 2629.91
[INFO 2017-06-26 18:46:57,651 main.py:47] epoch 2478, training loss: 1781.55, average training loss: 2007.73, base loss: 2629.05
[INFO 2017-06-26 18:46:57,958 main.py:47] epoch 2479, training loss: 2042.00, average training loss: 2007.72, base loss: 2628.93
[INFO 2017-06-26 18:46:58,274 main.py:47] epoch 2480, training loss: 2210.20, average training loss: 2007.92, base loss: 2629.22
[INFO 2017-06-26 18:46:58,583 main.py:47] epoch 2481, training loss: 1787.13, average training loss: 2007.37, base loss: 2628.70
[INFO 2017-06-26 18:46:58,892 main.py:47] epoch 2482, training loss: 2223.75, average training loss: 2007.45, base loss: 2628.67
[INFO 2017-06-26 18:46:59,197 main.py:47] epoch 2483, training loss: 1918.28, average training loss: 2007.21, base loss: 2628.43
[INFO 2017-06-26 18:46:59,572 main.py:47] epoch 2484, training loss: 2243.40, average training loss: 2007.68, base loss: 2629.25
[INFO 2017-06-26 18:46:59,918 main.py:47] epoch 2485, training loss: 2234.77, average training loss: 2007.83, base loss: 2629.67
[INFO 2017-06-26 18:47:00,231 main.py:47] epoch 2486, training loss: 2038.49, average training loss: 2007.98, base loss: 2629.87
[INFO 2017-06-26 18:47:00,591 main.py:47] epoch 2487, training loss: 1876.64, average training loss: 2007.95, base loss: 2629.90
[INFO 2017-06-26 18:47:00,925 main.py:47] epoch 2488, training loss: 1748.05, average training loss: 2007.79, base loss: 2629.74
[INFO 2017-06-26 18:47:01,245 main.py:47] epoch 2489, training loss: 1719.68, average training loss: 2007.20, base loss: 2628.80
[INFO 2017-06-26 18:47:01,553 main.py:47] epoch 2490, training loss: 1944.98, average training loss: 2007.07, base loss: 2628.88
[INFO 2017-06-26 18:47:01,927 main.py:47] epoch 2491, training loss: 1805.78, average training loss: 2006.84, base loss: 2628.63
[INFO 2017-06-26 18:47:02,249 main.py:47] epoch 2492, training loss: 1940.81, average training loss: 2006.85, base loss: 2628.73
[INFO 2017-06-26 18:47:02,570 main.py:47] epoch 2493, training loss: 1730.45, average training loss: 2006.65, base loss: 2628.64
[INFO 2017-06-26 18:47:02,960 main.py:47] epoch 2494, training loss: 2217.48, average training loss: 2006.94, base loss: 2629.38
[INFO 2017-06-26 18:47:03,282 main.py:47] epoch 2495, training loss: 1980.03, average training loss: 2007.08, base loss: 2629.55
[INFO 2017-06-26 18:47:03,604 main.py:47] epoch 2496, training loss: 2204.63, average training loss: 2006.90, base loss: 2629.20
[INFO 2017-06-26 18:47:03,913 main.py:47] epoch 2497, training loss: 2057.92, average training loss: 2007.03, base loss: 2629.23
[INFO 2017-06-26 18:47:04,218 main.py:47] epoch 2498, training loss: 1968.98, average training loss: 2007.07, base loss: 2629.35
[INFO 2017-06-26 18:47:04,534 main.py:47] epoch 2499, training loss: 1765.46, average training loss: 2006.94, base loss: 2629.10
[INFO 2017-06-26 18:47:04,535 main.py:49] epoch 2499, testing
[INFO 2017-06-26 18:47:08,508 main.py:100] average testing loss: 1860.32, base loss: 2394.84
[INFO 2017-06-26 18:47:08,534 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:47:08,548 main.py:73] current best accuracy: 1860.32
[INFO 2017-06-26 18:47:08,855 main.py:47] epoch 2500, training loss: 2074.18, average training loss: 2007.01, base loss: 2629.41
[INFO 2017-06-26 18:47:09,160 main.py:47] epoch 2501, training loss: 2481.40, average training loss: 2007.29, base loss: 2629.78
[INFO 2017-06-26 18:47:09,465 main.py:47] epoch 2502, training loss: 1943.37, average training loss: 2007.28, base loss: 2629.99
[INFO 2017-06-26 18:47:09,769 main.py:47] epoch 2503, training loss: 2027.40, average training loss: 2007.35, base loss: 2630.10
[INFO 2017-06-26 18:47:10,077 main.py:47] epoch 2504, training loss: 2008.69, average training loss: 2006.91, base loss: 2629.62
[INFO 2017-06-26 18:47:10,383 main.py:47] epoch 2505, training loss: 1903.61, average training loss: 2007.03, base loss: 2630.04
[INFO 2017-06-26 18:47:10,706 main.py:47] epoch 2506, training loss: 2042.41, average training loss: 2007.49, base loss: 2630.77
[INFO 2017-06-26 18:47:11,013 main.py:47] epoch 2507, training loss: 2300.46, average training loss: 2007.80, base loss: 2631.25
[INFO 2017-06-26 18:47:11,318 main.py:47] epoch 2508, training loss: 2100.12, average training loss: 2007.91, base loss: 2631.38
[INFO 2017-06-26 18:47:11,626 main.py:47] epoch 2509, training loss: 1930.11, average training loss: 2007.90, base loss: 2631.35
[INFO 2017-06-26 18:47:11,933 main.py:47] epoch 2510, training loss: 2024.32, average training loss: 2008.01, base loss: 2631.46
[INFO 2017-06-26 18:47:12,236 main.py:47] epoch 2511, training loss: 2089.30, average training loss: 2008.31, base loss: 2632.13
[INFO 2017-06-26 18:47:12,542 main.py:47] epoch 2512, training loss: 2002.09, average training loss: 2008.49, base loss: 2632.70
[INFO 2017-06-26 18:47:12,849 main.py:47] epoch 2513, training loss: 2097.82, average training loss: 2008.62, base loss: 2632.73
[INFO 2017-06-26 18:47:13,156 main.py:47] epoch 2514, training loss: 2169.57, average training loss: 2008.79, base loss: 2633.16
[INFO 2017-06-26 18:47:13,460 main.py:47] epoch 2515, training loss: 2100.68, average training loss: 2008.72, base loss: 2632.80
[INFO 2017-06-26 18:47:13,768 main.py:47] epoch 2516, training loss: 1819.92, average training loss: 2008.63, base loss: 2632.63
[INFO 2017-06-26 18:47:14,072 main.py:47] epoch 2517, training loss: 2144.63, average training loss: 2008.67, base loss: 2632.71
[INFO 2017-06-26 18:47:14,376 main.py:47] epoch 2518, training loss: 1889.64, average training loss: 2008.18, base loss: 2632.14
[INFO 2017-06-26 18:47:14,680 main.py:47] epoch 2519, training loss: 1797.91, average training loss: 2007.97, base loss: 2631.86
[INFO 2017-06-26 18:47:14,986 main.py:47] epoch 2520, training loss: 1724.67, average training loss: 2007.22, base loss: 2630.92
[INFO 2017-06-26 18:47:15,290 main.py:47] epoch 2521, training loss: 1968.15, average training loss: 2007.12, base loss: 2630.74
[INFO 2017-06-26 18:47:15,596 main.py:47] epoch 2522, training loss: 2122.51, average training loss: 2007.21, base loss: 2630.71
[INFO 2017-06-26 18:47:15,904 main.py:47] epoch 2523, training loss: 2224.94, average training loss: 2007.52, base loss: 2631.22
[INFO 2017-06-26 18:47:16,211 main.py:47] epoch 2524, training loss: 1937.95, average training loss: 2007.68, base loss: 2631.63
[INFO 2017-06-26 18:47:16,519 main.py:47] epoch 2525, training loss: 1828.84, average training loss: 2007.42, base loss: 2630.96
[INFO 2017-06-26 18:47:16,826 main.py:47] epoch 2526, training loss: 1734.11, average training loss: 2006.99, base loss: 2630.31
[INFO 2017-06-26 18:47:17,131 main.py:47] epoch 2527, training loss: 1934.93, average training loss: 2006.94, base loss: 2630.48
[INFO 2017-06-26 18:47:17,441 main.py:47] epoch 2528, training loss: 1637.24, average training loss: 2006.55, base loss: 2629.93
[INFO 2017-06-26 18:47:17,748 main.py:47] epoch 2529, training loss: 1813.03, average training loss: 2006.62, base loss: 2629.98
[INFO 2017-06-26 18:47:18,054 main.py:47] epoch 2530, training loss: 1640.54, average training loss: 2006.36, base loss: 2629.79
[INFO 2017-06-26 18:47:18,360 main.py:47] epoch 2531, training loss: 2361.74, average training loss: 2006.40, base loss: 2629.83
[INFO 2017-06-26 18:47:18,667 main.py:47] epoch 2532, training loss: 2183.94, average training loss: 2006.54, base loss: 2629.93
[INFO 2017-06-26 18:47:18,976 main.py:47] epoch 2533, training loss: 1708.00, average training loss: 2006.16, base loss: 2629.51
[INFO 2017-06-26 18:47:19,283 main.py:47] epoch 2534, training loss: 2135.08, average training loss: 2006.27, base loss: 2629.92
[INFO 2017-06-26 18:47:19,588 main.py:47] epoch 2535, training loss: 2334.04, average training loss: 2006.61, base loss: 2630.42
[INFO 2017-06-26 18:47:19,892 main.py:47] epoch 2536, training loss: 2090.61, average training loss: 2006.80, base loss: 2630.59
[INFO 2017-06-26 18:47:20,197 main.py:47] epoch 2537, training loss: 2061.82, average training loss: 2006.69, base loss: 2630.51
[INFO 2017-06-26 18:47:20,506 main.py:47] epoch 2538, training loss: 1764.93, average training loss: 2006.55, base loss: 2630.37
[INFO 2017-06-26 18:47:20,814 main.py:47] epoch 2539, training loss: 2556.16, average training loss: 2007.20, base loss: 2631.21
[INFO 2017-06-26 18:47:21,123 main.py:47] epoch 2540, training loss: 2234.57, average training loss: 2007.05, base loss: 2631.04
[INFO 2017-06-26 18:47:21,430 main.py:47] epoch 2541, training loss: 2040.78, average training loss: 2006.79, base loss: 2630.50
[INFO 2017-06-26 18:47:21,737 main.py:47] epoch 2542, training loss: 1914.86, average training loss: 2006.68, base loss: 2630.60
[INFO 2017-06-26 18:47:22,043 main.py:47] epoch 2543, training loss: 2481.47, average training loss: 2007.11, base loss: 2630.98
[INFO 2017-06-26 18:47:22,343 main.py:47] epoch 2544, training loss: 1854.68, average training loss: 2006.98, base loss: 2631.12
[INFO 2017-06-26 18:47:22,651 main.py:47] epoch 2545, training loss: 1989.13, average training loss: 2006.41, base loss: 2630.63
[INFO 2017-06-26 18:47:22,960 main.py:47] epoch 2546, training loss: 1975.79, average training loss: 2006.36, base loss: 2630.61
[INFO 2017-06-26 18:47:23,269 main.py:47] epoch 2547, training loss: 1819.54, average training loss: 2006.21, base loss: 2630.59
[INFO 2017-06-26 18:47:23,574 main.py:47] epoch 2548, training loss: 1786.97, average training loss: 2005.83, base loss: 2630.18
[INFO 2017-06-26 18:47:23,880 main.py:47] epoch 2549, training loss: 2135.00, average training loss: 2005.92, base loss: 2630.18
[INFO 2017-06-26 18:47:24,188 main.py:47] epoch 2550, training loss: 2102.78, average training loss: 2006.09, base loss: 2630.54
[INFO 2017-06-26 18:47:24,493 main.py:47] epoch 2551, training loss: 2032.99, average training loss: 2006.09, base loss: 2630.44
[INFO 2017-06-26 18:47:24,799 main.py:47] epoch 2552, training loss: 2264.99, average training loss: 2006.40, base loss: 2630.77
[INFO 2017-06-26 18:47:25,109 main.py:47] epoch 2553, training loss: 1927.30, average training loss: 2006.40, base loss: 2630.98
[INFO 2017-06-26 18:47:25,414 main.py:47] epoch 2554, training loss: 1890.12, average training loss: 2006.41, base loss: 2631.28
[INFO 2017-06-26 18:47:25,719 main.py:47] epoch 2555, training loss: 1956.06, average training loss: 2006.33, base loss: 2631.03
[INFO 2017-06-26 18:47:26,024 main.py:47] epoch 2556, training loss: 1846.40, average training loss: 2006.07, base loss: 2630.63
[INFO 2017-06-26 18:47:26,329 main.py:47] epoch 2557, training loss: 1827.76, average training loss: 2005.90, base loss: 2630.37
[INFO 2017-06-26 18:47:26,635 main.py:47] epoch 2558, training loss: 1712.98, average training loss: 2005.52, base loss: 2630.19
[INFO 2017-06-26 18:47:26,940 main.py:47] epoch 2559, training loss: 1943.91, average training loss: 2005.67, base loss: 2630.29
[INFO 2017-06-26 18:47:27,246 main.py:47] epoch 2560, training loss: 1802.60, average training loss: 2005.67, base loss: 2630.17
[INFO 2017-06-26 18:47:27,550 main.py:47] epoch 2561, training loss: 1991.09, average training loss: 2005.58, base loss: 2630.17
[INFO 2017-06-26 18:47:27,852 main.py:47] epoch 2562, training loss: 1947.17, average training loss: 2005.78, base loss: 2630.34
[INFO 2017-06-26 18:47:28,158 main.py:47] epoch 2563, training loss: 1956.84, average training loss: 2005.89, base loss: 2630.34
[INFO 2017-06-26 18:47:28,463 main.py:47] epoch 2564, training loss: 1919.50, average training loss: 2005.70, base loss: 2630.11
[INFO 2017-06-26 18:47:28,767 main.py:47] epoch 2565, training loss: 2004.53, average training loss: 2005.82, base loss: 2630.49
[INFO 2017-06-26 18:47:29,074 main.py:47] epoch 2566, training loss: 1768.97, average training loss: 2005.40, base loss: 2630.15
[INFO 2017-06-26 18:47:29,383 main.py:47] epoch 2567, training loss: 2094.08, average training loss: 2005.51, base loss: 2630.47
[INFO 2017-06-26 18:47:29,690 main.py:47] epoch 2568, training loss: 2052.40, average training loss: 2005.64, base loss: 2630.53
[INFO 2017-06-26 18:47:29,995 main.py:47] epoch 2569, training loss: 1667.33, average training loss: 2005.32, base loss: 2630.00
[INFO 2017-06-26 18:47:30,295 main.py:47] epoch 2570, training loss: 2013.76, average training loss: 2004.91, base loss: 2629.55
[INFO 2017-06-26 18:47:30,603 main.py:47] epoch 2571, training loss: 1836.13, average training loss: 2004.96, base loss: 2629.92
[INFO 2017-06-26 18:47:30,908 main.py:47] epoch 2572, training loss: 1875.04, average training loss: 2004.92, base loss: 2630.03
[INFO 2017-06-26 18:47:31,211 main.py:47] epoch 2573, training loss: 2148.60, average training loss: 2005.12, base loss: 2630.40
[INFO 2017-06-26 18:47:31,518 main.py:47] epoch 2574, training loss: 1869.87, average training loss: 2005.18, base loss: 2630.84
[INFO 2017-06-26 18:47:31,822 main.py:47] epoch 2575, training loss: 2391.59, average training loss: 2005.67, base loss: 2631.58
[INFO 2017-06-26 18:47:32,130 main.py:47] epoch 2576, training loss: 2138.44, average training loss: 2005.60, base loss: 2631.49
[INFO 2017-06-26 18:47:32,437 main.py:47] epoch 2577, training loss: 1880.46, average training loss: 2005.45, base loss: 2631.07
[INFO 2017-06-26 18:47:32,742 main.py:47] epoch 2578, training loss: 1771.86, average training loss: 2005.22, base loss: 2630.80
[INFO 2017-06-26 18:47:33,044 main.py:47] epoch 2579, training loss: 2090.66, average training loss: 2005.17, base loss: 2630.78
[INFO 2017-06-26 18:47:33,349 main.py:47] epoch 2580, training loss: 2227.80, average training loss: 2005.47, base loss: 2631.20
[INFO 2017-06-26 18:47:33,654 main.py:47] epoch 2581, training loss: 1691.07, average training loss: 2005.38, base loss: 2631.12
[INFO 2017-06-26 18:47:33,961 main.py:47] epoch 2582, training loss: 1983.41, average training loss: 2005.37, base loss: 2631.19
[INFO 2017-06-26 18:47:34,269 main.py:47] epoch 2583, training loss: 2126.75, average training loss: 2005.48, base loss: 2631.32
[INFO 2017-06-26 18:47:34,576 main.py:47] epoch 2584, training loss: 1591.38, average training loss: 2004.81, base loss: 2630.11
[INFO 2017-06-26 18:47:34,883 main.py:47] epoch 2585, training loss: 1990.67, average training loss: 2004.37, base loss: 2629.60
[INFO 2017-06-26 18:47:35,190 main.py:47] epoch 2586, training loss: 2495.55, average training loss: 2004.67, base loss: 2629.80
[INFO 2017-06-26 18:47:35,495 main.py:47] epoch 2587, training loss: 1855.44, average training loss: 2004.71, base loss: 2630.16
[INFO 2017-06-26 18:47:35,803 main.py:47] epoch 2588, training loss: 2123.23, average training loss: 2004.63, base loss: 2629.79
[INFO 2017-06-26 18:47:36,109 main.py:47] epoch 2589, training loss: 2075.41, average training loss: 2004.62, base loss: 2629.79
[INFO 2017-06-26 18:47:36,413 main.py:47] epoch 2590, training loss: 1771.47, average training loss: 2004.17, base loss: 2629.27
[INFO 2017-06-26 18:47:36,721 main.py:47] epoch 2591, training loss: 1941.99, average training loss: 2004.15, base loss: 2629.26
[INFO 2017-06-26 18:47:37,027 main.py:47] epoch 2592, training loss: 1987.84, average training loss: 2004.04, base loss: 2629.05
[INFO 2017-06-26 18:47:37,332 main.py:47] epoch 2593, training loss: 1649.61, average training loss: 2003.75, base loss: 2628.81
[INFO 2017-06-26 18:47:37,640 main.py:47] epoch 2594, training loss: 2083.07, average training loss: 2004.04, base loss: 2629.13
[INFO 2017-06-26 18:47:37,947 main.py:47] epoch 2595, training loss: 1805.79, average training loss: 2003.75, base loss: 2628.78
[INFO 2017-06-26 18:47:38,254 main.py:47] epoch 2596, training loss: 2112.71, average training loss: 2003.80, base loss: 2628.76
[INFO 2017-06-26 18:47:38,561 main.py:47] epoch 2597, training loss: 2125.97, average training loss: 2004.18, base loss: 2629.36
[INFO 2017-06-26 18:47:38,868 main.py:47] epoch 2598, training loss: 2127.69, average training loss: 2004.45, base loss: 2629.98
[INFO 2017-06-26 18:47:39,172 main.py:47] epoch 2599, training loss: 2140.55, average training loss: 2004.68, base loss: 2630.27
[INFO 2017-06-26 18:47:39,172 main.py:49] epoch 2599, testing
[INFO 2017-06-26 18:47:43,374 main.py:100] average testing loss: 1995.95, base loss: 2611.87
[INFO 2017-06-26 18:47:43,400 main.py:73] current best accuracy: 1860.32
[INFO 2017-06-26 18:47:43,709 main.py:47] epoch 2600, training loss: 1828.17, average training loss: 2004.50, base loss: 2630.05
[INFO 2017-06-26 18:47:44,016 main.py:47] epoch 2601, training loss: 2126.39, average training loss: 2004.43, base loss: 2629.90
[INFO 2017-06-26 18:47:44,325 main.py:47] epoch 2602, training loss: 2201.91, average training loss: 2004.77, base loss: 2630.42
[INFO 2017-06-26 18:47:44,632 main.py:47] epoch 2603, training loss: 2035.32, average training loss: 2004.78, base loss: 2630.55
[INFO 2017-06-26 18:47:44,935 main.py:47] epoch 2604, training loss: 1794.99, average training loss: 2004.67, base loss: 2630.39
[INFO 2017-06-26 18:47:45,240 main.py:47] epoch 2605, training loss: 1990.34, average training loss: 2004.45, base loss: 2630.31
[INFO 2017-06-26 18:47:45,545 main.py:47] epoch 2606, training loss: 1758.93, average training loss: 2004.26, base loss: 2629.75
[INFO 2017-06-26 18:47:45,853 main.py:47] epoch 2607, training loss: 1696.49, average training loss: 2003.94, base loss: 2629.57
[INFO 2017-06-26 18:47:46,161 main.py:47] epoch 2608, training loss: 1804.98, average training loss: 2003.40, base loss: 2629.02
[INFO 2017-06-26 18:47:46,467 main.py:47] epoch 2609, training loss: 2102.56, average training loss: 2003.50, base loss: 2629.34
[INFO 2017-06-26 18:47:46,773 main.py:47] epoch 2610, training loss: 2011.75, average training loss: 2003.41, base loss: 2629.48
[INFO 2017-06-26 18:47:47,079 main.py:47] epoch 2611, training loss: 2057.14, average training loss: 2003.46, base loss: 2629.74
[INFO 2017-06-26 18:47:47,384 main.py:47] epoch 2612, training loss: 1841.15, average training loss: 2003.56, base loss: 2629.88
[INFO 2017-06-26 18:47:47,690 main.py:47] epoch 2613, training loss: 1850.88, average training loss: 2003.54, base loss: 2629.75
[INFO 2017-06-26 18:47:47,997 main.py:47] epoch 2614, training loss: 2122.58, average training loss: 2003.39, base loss: 2629.52
[INFO 2017-06-26 18:47:48,302 main.py:47] epoch 2615, training loss: 2056.12, average training loss: 2003.29, base loss: 2629.71
[INFO 2017-06-26 18:47:48,611 main.py:47] epoch 2616, training loss: 1835.35, average training loss: 2003.11, base loss: 2629.49
[INFO 2017-06-26 18:47:48,915 main.py:47] epoch 2617, training loss: 1947.14, average training loss: 2002.90, base loss: 2629.33
[INFO 2017-06-26 18:47:49,224 main.py:47] epoch 2618, training loss: 1940.76, average training loss: 2002.95, base loss: 2629.20
[INFO 2017-06-26 18:47:49,532 main.py:47] epoch 2619, training loss: 1863.16, average training loss: 2002.76, base loss: 2628.91
[INFO 2017-06-26 18:47:49,838 main.py:47] epoch 2620, training loss: 2050.21, average training loss: 2003.03, base loss: 2629.41
[INFO 2017-06-26 18:47:50,143 main.py:47] epoch 2621, training loss: 2021.90, average training loss: 2003.15, base loss: 2629.92
[INFO 2017-06-26 18:47:50,450 main.py:47] epoch 2622, training loss: 1856.83, average training loss: 2003.07, base loss: 2630.00
[INFO 2017-06-26 18:47:50,758 main.py:47] epoch 2623, training loss: 1885.22, average training loss: 2003.11, base loss: 2630.01
[INFO 2017-06-26 18:47:51,064 main.py:47] epoch 2624, training loss: 2080.45, average training loss: 2003.38, base loss: 2630.57
[INFO 2017-06-26 18:47:51,371 main.py:47] epoch 2625, training loss: 2205.02, average training loss: 2003.71, base loss: 2631.09
[INFO 2017-06-26 18:47:51,677 main.py:47] epoch 2626, training loss: 1872.32, average training loss: 2003.34, base loss: 2630.68
[INFO 2017-06-26 18:47:51,985 main.py:47] epoch 2627, training loss: 1958.50, average training loss: 2003.26, base loss: 2630.42
[INFO 2017-06-26 18:47:52,293 main.py:47] epoch 2628, training loss: 2005.12, average training loss: 2003.29, base loss: 2630.66
[INFO 2017-06-26 18:47:52,602 main.py:47] epoch 2629, training loss: 2067.04, average training loss: 2003.33, base loss: 2630.98
[INFO 2017-06-26 18:47:52,909 main.py:47] epoch 2630, training loss: 1922.93, average training loss: 2003.17, base loss: 2630.79
[INFO 2017-06-26 18:47:53,214 main.py:47] epoch 2631, training loss: 1656.83, average training loss: 2002.54, base loss: 2629.85
[INFO 2017-06-26 18:47:53,519 main.py:47] epoch 2632, training loss: 2057.14, average training loss: 2002.49, base loss: 2629.80
[INFO 2017-06-26 18:47:53,827 main.py:47] epoch 2633, training loss: 1997.90, average training loss: 2002.47, base loss: 2629.96
[INFO 2017-06-26 18:47:54,133 main.py:47] epoch 2634, training loss: 1977.58, average training loss: 2002.34, base loss: 2629.77
[INFO 2017-06-26 18:47:54,441 main.py:47] epoch 2635, training loss: 2117.02, average training loss: 2002.11, base loss: 2629.66
[INFO 2017-06-26 18:47:54,742 main.py:47] epoch 2636, training loss: 2059.32, average training loss: 2001.83, base loss: 2629.40
[INFO 2017-06-26 18:47:55,044 main.py:47] epoch 2637, training loss: 2424.88, average training loss: 2001.97, base loss: 2629.59
[INFO 2017-06-26 18:47:55,349 main.py:47] epoch 2638, training loss: 2069.28, average training loss: 2001.99, base loss: 2629.82
[INFO 2017-06-26 18:47:55,657 main.py:47] epoch 2639, training loss: 1818.83, average training loss: 2001.66, base loss: 2628.97
[INFO 2017-06-26 18:47:55,964 main.py:47] epoch 2640, training loss: 2107.12, average training loss: 2001.83, base loss: 2629.29
[INFO 2017-06-26 18:47:56,273 main.py:47] epoch 2641, training loss: 2200.73, average training loss: 2002.20, base loss: 2629.82
[INFO 2017-06-26 18:47:56,576 main.py:47] epoch 2642, training loss: 1654.41, average training loss: 2001.96, base loss: 2629.44
[INFO 2017-06-26 18:47:56,883 main.py:47] epoch 2643, training loss: 2055.63, average training loss: 2002.29, base loss: 2629.94
[INFO 2017-06-26 18:47:57,190 main.py:47] epoch 2644, training loss: 1867.22, average training loss: 2002.10, base loss: 2630.10
[INFO 2017-06-26 18:47:57,498 main.py:47] epoch 2645, training loss: 1574.96, average training loss: 2001.36, base loss: 2629.00
[INFO 2017-06-26 18:47:57,804 main.py:47] epoch 2646, training loss: 2114.45, average training loss: 2001.71, base loss: 2629.49
[INFO 2017-06-26 18:47:58,109 main.py:47] epoch 2647, training loss: 1887.32, average training loss: 2001.70, base loss: 2629.86
[INFO 2017-06-26 18:47:58,416 main.py:47] epoch 2648, training loss: 2151.80, average training loss: 2001.91, base loss: 2630.30
[INFO 2017-06-26 18:47:58,724 main.py:47] epoch 2649, training loss: 1851.41, average training loss: 2001.80, base loss: 2630.30
[INFO 2017-06-26 18:47:59,030 main.py:47] epoch 2650, training loss: 1855.15, average training loss: 2001.57, base loss: 2629.91
[INFO 2017-06-26 18:47:59,333 main.py:47] epoch 2651, training loss: 1932.82, average training loss: 2001.51, base loss: 2630.06
[INFO 2017-06-26 18:47:59,637 main.py:47] epoch 2652, training loss: 2005.79, average training loss: 2001.50, base loss: 2630.06
[INFO 2017-06-26 18:47:59,944 main.py:47] epoch 2653, training loss: 2086.48, average training loss: 2001.52, base loss: 2629.93
[INFO 2017-06-26 18:48:00,252 main.py:47] epoch 2654, training loss: 1999.54, average training loss: 2001.51, base loss: 2629.84
[INFO 2017-06-26 18:48:00,559 main.py:47] epoch 2655, training loss: 1698.43, average training loss: 2001.30, base loss: 2629.44
[INFO 2017-06-26 18:48:00,867 main.py:47] epoch 2656, training loss: 2080.52, average training loss: 2001.33, base loss: 2629.49
[INFO 2017-06-26 18:48:01,174 main.py:47] epoch 2657, training loss: 2371.50, average training loss: 2001.44, base loss: 2629.60
[INFO 2017-06-26 18:48:01,481 main.py:47] epoch 2658, training loss: 1857.58, average training loss: 2001.36, base loss: 2629.59
[INFO 2017-06-26 18:48:01,790 main.py:47] epoch 2659, training loss: 1951.44, average training loss: 2001.07, base loss: 2629.19
[INFO 2017-06-26 18:48:02,097 main.py:47] epoch 2660, training loss: 2263.21, average training loss: 2001.33, base loss: 2629.25
[INFO 2017-06-26 18:48:02,402 main.py:47] epoch 2661, training loss: 2032.14, average training loss: 2001.34, base loss: 2629.27
[INFO 2017-06-26 18:48:02,707 main.py:47] epoch 2662, training loss: 1783.00, average training loss: 2001.13, base loss: 2628.94
[INFO 2017-06-26 18:48:03,011 main.py:47] epoch 2663, training loss: 2034.28, average training loss: 2001.11, base loss: 2628.95
[INFO 2017-06-26 18:48:03,321 main.py:47] epoch 2664, training loss: 2010.30, average training loss: 2000.99, base loss: 2628.56
[INFO 2017-06-26 18:48:03,628 main.py:47] epoch 2665, training loss: 1907.03, average training loss: 2000.89, base loss: 2628.58
[INFO 2017-06-26 18:48:03,937 main.py:47] epoch 2666, training loss: 1767.41, average training loss: 2000.73, base loss: 2628.82
[INFO 2017-06-26 18:48:04,244 main.py:47] epoch 2667, training loss: 2057.34, average training loss: 2000.74, base loss: 2629.09
[INFO 2017-06-26 18:48:04,550 main.py:47] epoch 2668, training loss: 2089.46, average training loss: 2000.99, base loss: 2629.50
[INFO 2017-06-26 18:48:04,856 main.py:47] epoch 2669, training loss: 2181.41, average training loss: 2000.89, base loss: 2629.56
[INFO 2017-06-26 18:48:05,161 main.py:47] epoch 2670, training loss: 2073.31, average training loss: 2001.06, base loss: 2629.80
[INFO 2017-06-26 18:48:05,466 main.py:47] epoch 2671, training loss: 2047.34, average training loss: 2000.93, base loss: 2629.79
[INFO 2017-06-26 18:48:05,771 main.py:47] epoch 2672, training loss: 2117.85, average training loss: 2000.92, base loss: 2629.93
[INFO 2017-06-26 18:48:06,076 main.py:47] epoch 2673, training loss: 1866.06, average training loss: 2000.78, base loss: 2630.02
[INFO 2017-06-26 18:48:06,380 main.py:47] epoch 2674, training loss: 1793.08, average training loss: 2000.50, base loss: 2629.84
[INFO 2017-06-26 18:48:06,686 main.py:47] epoch 2675, training loss: 2228.56, average training loss: 2000.83, base loss: 2630.32
[INFO 2017-06-26 18:48:06,994 main.py:47] epoch 2676, training loss: 1829.09, average training loss: 2000.54, base loss: 2629.93
[INFO 2017-06-26 18:48:07,301 main.py:47] epoch 2677, training loss: 1944.71, average training loss: 2000.61, base loss: 2630.11
[INFO 2017-06-26 18:48:07,610 main.py:47] epoch 2678, training loss: 1942.08, average training loss: 2000.52, base loss: 2630.19
[INFO 2017-06-26 18:48:07,919 main.py:47] epoch 2679, training loss: 2034.85, average training loss: 2000.26, base loss: 2629.88
[INFO 2017-06-26 18:48:08,228 main.py:47] epoch 2680, training loss: 1921.00, average training loss: 1999.78, base loss: 2629.45
[INFO 2017-06-26 18:48:08,536 main.py:47] epoch 2681, training loss: 2027.04, average training loss: 1999.95, base loss: 2629.86
[INFO 2017-06-26 18:48:08,839 main.py:47] epoch 2682, training loss: 1891.08, average training loss: 1999.88, base loss: 2629.94
[INFO 2017-06-26 18:48:09,150 main.py:47] epoch 2683, training loss: 2091.87, average training loss: 2000.02, base loss: 2630.16
[INFO 2017-06-26 18:48:09,455 main.py:47] epoch 2684, training loss: 2057.47, average training loss: 1999.87, base loss: 2629.88
[INFO 2017-06-26 18:48:09,764 main.py:47] epoch 2685, training loss: 2201.85, average training loss: 1999.98, base loss: 2630.14
[INFO 2017-06-26 18:48:10,073 main.py:47] epoch 2686, training loss: 1946.05, average training loss: 1999.91, base loss: 2630.40
[INFO 2017-06-26 18:48:10,378 main.py:47] epoch 2687, training loss: 2084.75, average training loss: 2000.06, base loss: 2630.60
[INFO 2017-06-26 18:48:10,686 main.py:47] epoch 2688, training loss: 2092.98, average training loss: 2000.20, base loss: 2630.94
[INFO 2017-06-26 18:48:10,994 main.py:47] epoch 2689, training loss: 1900.71, average training loss: 2000.00, base loss: 2630.59
[INFO 2017-06-26 18:48:11,299 main.py:47] epoch 2690, training loss: 2214.25, average training loss: 2000.22, base loss: 2630.94
[INFO 2017-06-26 18:48:11,608 main.py:47] epoch 2691, training loss: 2215.56, average training loss: 2000.15, base loss: 2630.80
[INFO 2017-06-26 18:48:11,916 main.py:47] epoch 2692, training loss: 2152.38, average training loss: 2000.32, base loss: 2631.27
[INFO 2017-06-26 18:48:12,221 main.py:47] epoch 2693, training loss: 1747.69, average training loss: 2000.20, base loss: 2631.33
[INFO 2017-06-26 18:48:12,531 main.py:47] epoch 2694, training loss: 1956.73, average training loss: 1999.94, base loss: 2631.12
[INFO 2017-06-26 18:48:12,837 main.py:47] epoch 2695, training loss: 2108.59, average training loss: 2000.28, base loss: 2631.70
[INFO 2017-06-26 18:48:13,144 main.py:47] epoch 2696, training loss: 2189.55, average training loss: 2000.61, base loss: 2632.30
[INFO 2017-06-26 18:48:13,452 main.py:47] epoch 2697, training loss: 2023.27, average training loss: 2000.45, base loss: 2632.06
[INFO 2017-06-26 18:48:13,763 main.py:47] epoch 2698, training loss: 1742.44, average training loss: 2000.19, base loss: 2631.99
[INFO 2017-06-26 18:48:14,071 main.py:47] epoch 2699, training loss: 2071.84, average training loss: 2000.30, base loss: 2632.29
[INFO 2017-06-26 18:48:14,071 main.py:49] epoch 2699, testing
[INFO 2017-06-26 18:48:18,057 main.py:100] average testing loss: 1985.49, base loss: 2642.24
[INFO 2017-06-26 18:48:18,082 main.py:73] current best accuracy: 1860.32
[INFO 2017-06-26 18:48:18,390 main.py:47] epoch 2700, training loss: 2061.46, average training loss: 2000.40, base loss: 2632.71
[INFO 2017-06-26 18:48:18,698 main.py:47] epoch 2701, training loss: 1784.08, average training loss: 2000.34, base loss: 2632.58
[INFO 2017-06-26 18:48:19,009 main.py:47] epoch 2702, training loss: 1993.46, average training loss: 2000.34, base loss: 2632.60
[INFO 2017-06-26 18:48:19,312 main.py:47] epoch 2703, training loss: 1893.71, average training loss: 2000.11, base loss: 2632.32
[INFO 2017-06-26 18:48:19,619 main.py:47] epoch 2704, training loss: 2025.02, average training loss: 2000.35, base loss: 2632.73
[INFO 2017-06-26 18:48:19,924 main.py:47] epoch 2705, training loss: 2023.75, average training loss: 2000.45, base loss: 2632.90
[INFO 2017-06-26 18:48:20,228 main.py:47] epoch 2706, training loss: 2040.00, average training loss: 2000.29, base loss: 2632.72
[INFO 2017-06-26 18:48:20,537 main.py:47] epoch 2707, training loss: 1926.50, average training loss: 2000.41, base loss: 2633.06
[INFO 2017-06-26 18:48:20,844 main.py:47] epoch 2708, training loss: 1933.56, average training loss: 2000.28, base loss: 2633.28
[INFO 2017-06-26 18:48:21,150 main.py:47] epoch 2709, training loss: 2025.59, average training loss: 2000.29, base loss: 2633.16
[INFO 2017-06-26 18:48:21,454 main.py:47] epoch 2710, training loss: 1847.16, average training loss: 1999.73, base loss: 2632.21
[INFO 2017-06-26 18:48:21,763 main.py:47] epoch 2711, training loss: 2195.99, average training loss: 1999.91, base loss: 2632.67
[INFO 2017-06-26 18:48:22,071 main.py:47] epoch 2712, training loss: 1888.37, average training loss: 1999.58, base loss: 2632.39
[INFO 2017-06-26 18:48:22,379 main.py:47] epoch 2713, training loss: 2254.46, average training loss: 1999.85, base loss: 2632.79
[INFO 2017-06-26 18:48:22,686 main.py:47] epoch 2714, training loss: 2082.78, average training loss: 1999.99, base loss: 2632.99
[INFO 2017-06-26 18:48:23,004 main.py:47] epoch 2715, training loss: 1912.44, average training loss: 2000.01, base loss: 2633.17
[INFO 2017-06-26 18:48:23,314 main.py:47] epoch 2716, training loss: 1818.85, average training loss: 1999.85, base loss: 2633.09
[INFO 2017-06-26 18:48:23,621 main.py:47] epoch 2717, training loss: 1945.10, average training loss: 1999.78, base loss: 2633.00
[INFO 2017-06-26 18:48:23,925 main.py:47] epoch 2718, training loss: 1943.72, average training loss: 1999.70, base loss: 2632.84
[INFO 2017-06-26 18:48:24,229 main.py:47] epoch 2719, training loss: 2027.52, average training loss: 1999.36, base loss: 2632.72
[INFO 2017-06-26 18:48:24,533 main.py:47] epoch 2720, training loss: 1949.73, average training loss: 1999.55, base loss: 2633.08
[INFO 2017-06-26 18:48:24,840 main.py:47] epoch 2721, training loss: 1776.34, average training loss: 1999.37, base loss: 2632.91
[INFO 2017-06-26 18:48:25,146 main.py:47] epoch 2722, training loss: 1864.03, average training loss: 1999.30, base loss: 2632.78
[INFO 2017-06-26 18:48:25,453 main.py:47] epoch 2723, training loss: 2636.69, average training loss: 1999.88, base loss: 2633.73
[INFO 2017-06-26 18:48:25,758 main.py:47] epoch 2724, training loss: 2103.01, average training loss: 1999.94, base loss: 2633.96
[INFO 2017-06-26 18:48:26,068 main.py:47] epoch 2725, training loss: 2018.24, average training loss: 1999.97, base loss: 2634.07
[INFO 2017-06-26 18:48:26,375 main.py:47] epoch 2726, training loss: 1741.56, average training loss: 1999.77, base loss: 2633.42
[INFO 2017-06-26 18:48:26,684 main.py:47] epoch 2727, training loss: 2107.67, average training loss: 2000.00, base loss: 2633.75
[INFO 2017-06-26 18:48:26,991 main.py:47] epoch 2728, training loss: 2016.48, average training loss: 2000.08, base loss: 2633.89
[INFO 2017-06-26 18:48:27,294 main.py:47] epoch 2729, training loss: 2007.34, average training loss: 1999.73, base loss: 2633.73
[INFO 2017-06-26 18:48:27,602 main.py:47] epoch 2730, training loss: 2037.65, average training loss: 1999.54, base loss: 2633.51
[INFO 2017-06-26 18:48:27,911 main.py:47] epoch 2731, training loss: 1989.21, average training loss: 1999.29, base loss: 2633.11
[INFO 2017-06-26 18:48:28,215 main.py:47] epoch 2732, training loss: 1762.83, average training loss: 1998.88, base loss: 2632.62
[INFO 2017-06-26 18:48:28,519 main.py:47] epoch 2733, training loss: 2189.94, average training loss: 1999.29, base loss: 2633.45
[INFO 2017-06-26 18:48:28,825 main.py:47] epoch 2734, training loss: 1902.06, average training loss: 1999.21, base loss: 2633.21
[INFO 2017-06-26 18:48:29,132 main.py:47] epoch 2735, training loss: 1845.12, average training loss: 1999.15, base loss: 2633.39
[INFO 2017-06-26 18:48:29,439 main.py:47] epoch 2736, training loss: 1907.42, average training loss: 1998.57, base loss: 2632.78
[INFO 2017-06-26 18:48:29,744 main.py:47] epoch 2737, training loss: 1784.17, average training loss: 1998.43, base loss: 2632.53
[INFO 2017-06-26 18:48:30,050 main.py:47] epoch 2738, training loss: 1709.96, average training loss: 1998.07, base loss: 2632.11
[INFO 2017-06-26 18:48:30,356 main.py:47] epoch 2739, training loss: 1912.92, average training loss: 1998.06, base loss: 2632.22
[INFO 2017-06-26 18:48:30,665 main.py:47] epoch 2740, training loss: 1818.52, average training loss: 1997.80, base loss: 2631.80
[INFO 2017-06-26 18:48:30,970 main.py:47] epoch 2741, training loss: 1866.72, average training loss: 1997.81, base loss: 2631.69
[INFO 2017-06-26 18:48:31,275 main.py:47] epoch 2742, training loss: 1865.96, average training loss: 1997.46, base loss: 2631.36
[INFO 2017-06-26 18:48:31,583 main.py:47] epoch 2743, training loss: 2084.72, average training loss: 1997.62, base loss: 2631.47
[INFO 2017-06-26 18:48:31,890 main.py:47] epoch 2744, training loss: 1922.05, average training loss: 1997.86, base loss: 2632.02
[INFO 2017-06-26 18:48:32,198 main.py:47] epoch 2745, training loss: 2065.20, average training loss: 1998.11, base loss: 2632.73
[INFO 2017-06-26 18:48:32,504 main.py:47] epoch 2746, training loss: 1842.72, average training loss: 1997.92, base loss: 2632.60
[INFO 2017-06-26 18:48:32,810 main.py:47] epoch 2747, training loss: 1794.05, average training loss: 1997.78, base loss: 2632.31
[INFO 2017-06-26 18:48:33,117 main.py:47] epoch 2748, training loss: 2256.50, average training loss: 1998.23, base loss: 2633.19
[INFO 2017-06-26 18:48:33,424 main.py:47] epoch 2749, training loss: 1721.66, average training loss: 1998.07, base loss: 2632.92
[INFO 2017-06-26 18:48:33,731 main.py:47] epoch 2750, training loss: 1842.68, average training loss: 1997.96, base loss: 2633.09
[INFO 2017-06-26 18:48:34,038 main.py:47] epoch 2751, training loss: 1830.26, average training loss: 1997.18, base loss: 2632.02
[INFO 2017-06-26 18:48:34,346 main.py:47] epoch 2752, training loss: 2107.48, average training loss: 1997.14, base loss: 2632.14
[INFO 2017-06-26 18:48:34,657 main.py:47] epoch 2753, training loss: 1718.51, average training loss: 1996.71, base loss: 2631.63
[INFO 2017-06-26 18:48:34,965 main.py:47] epoch 2754, training loss: 1875.92, average training loss: 1996.74, base loss: 2631.79
[INFO 2017-06-26 18:48:35,273 main.py:47] epoch 2755, training loss: 1808.14, average training loss: 1996.70, base loss: 2632.02
[INFO 2017-06-26 18:48:35,580 main.py:47] epoch 2756, training loss: 2014.24, average training loss: 1996.90, base loss: 2632.50
[INFO 2017-06-26 18:48:35,892 main.py:47] epoch 2757, training loss: 2097.16, average training loss: 1997.06, base loss: 2632.81
[INFO 2017-06-26 18:48:36,199 main.py:47] epoch 2758, training loss: 1780.41, average training loss: 1996.69, base loss: 2632.54
[INFO 2017-06-26 18:48:36,505 main.py:47] epoch 2759, training loss: 1972.34, average training loss: 1996.66, base loss: 2632.78
[INFO 2017-06-26 18:48:36,814 main.py:47] epoch 2760, training loss: 2651.07, average training loss: 1996.83, base loss: 2632.90
[INFO 2017-06-26 18:48:37,169 main.py:47] epoch 2761, training loss: 1810.66, average training loss: 1996.45, base loss: 2632.28
[INFO 2017-06-26 18:48:37,504 main.py:47] epoch 2762, training loss: 1916.75, average training loss: 1996.33, base loss: 2632.17
[INFO 2017-06-26 18:48:37,816 main.py:47] epoch 2763, training loss: 2312.68, average training loss: 1996.84, base loss: 2633.07
[INFO 2017-06-26 18:48:38,134 main.py:47] epoch 2764, training loss: 2215.30, average training loss: 1996.96, base loss: 2633.07
[INFO 2017-06-26 18:48:38,441 main.py:47] epoch 2765, training loss: 2271.27, average training loss: 1997.28, base loss: 2633.64
[INFO 2017-06-26 18:48:38,813 main.py:47] epoch 2766, training loss: 1768.33, average training loss: 1996.96, base loss: 2633.35
[INFO 2017-06-26 18:48:39,157 main.py:47] epoch 2767, training loss: 2391.24, average training loss: 1997.42, base loss: 2633.95
[INFO 2017-06-26 18:48:39,466 main.py:47] epoch 2768, training loss: 2004.20, average training loss: 1997.15, base loss: 2633.69
[INFO 2017-06-26 18:48:39,774 main.py:47] epoch 2769, training loss: 1977.72, average training loss: 1997.27, base loss: 2633.97
[INFO 2017-06-26 18:48:40,084 main.py:47] epoch 2770, training loss: 2406.76, average training loss: 1997.48, base loss: 2634.19
[INFO 2017-06-26 18:48:40,389 main.py:47] epoch 2771, training loss: 2245.35, average training loss: 1997.91, base loss: 2634.67
[INFO 2017-06-26 18:48:40,696 main.py:47] epoch 2772, training loss: 1743.70, average training loss: 1997.58, base loss: 2634.16
[INFO 2017-06-26 18:48:41,000 main.py:47] epoch 2773, training loss: 2117.16, average training loss: 1997.92, base loss: 2634.84
[INFO 2017-06-26 18:48:41,303 main.py:47] epoch 2774, training loss: 1933.93, average training loss: 1997.86, base loss: 2634.94
[INFO 2017-06-26 18:48:41,610 main.py:47] epoch 2775, training loss: 1868.36, average training loss: 1997.76, base loss: 2634.96
[INFO 2017-06-26 18:48:41,918 main.py:47] epoch 2776, training loss: 1894.84, average training loss: 1997.56, base loss: 2634.90
[INFO 2017-06-26 18:48:42,224 main.py:47] epoch 2777, training loss: 2197.11, average training loss: 1997.62, base loss: 2635.20
[INFO 2017-06-26 18:48:42,529 main.py:47] epoch 2778, training loss: 1797.64, average training loss: 1997.57, base loss: 2635.01
[INFO 2017-06-26 18:48:42,835 main.py:47] epoch 2779, training loss: 1965.43, average training loss: 1997.61, base loss: 2635.00
[INFO 2017-06-26 18:48:43,143 main.py:47] epoch 2780, training loss: 2105.32, average training loss: 1997.93, base loss: 2635.47
[INFO 2017-06-26 18:48:43,451 main.py:47] epoch 2781, training loss: 1995.05, average training loss: 1997.68, base loss: 2635.56
[INFO 2017-06-26 18:48:43,769 main.py:47] epoch 2782, training loss: 1716.38, average training loss: 1997.34, base loss: 2635.17
[INFO 2017-06-26 18:48:44,094 main.py:47] epoch 2783, training loss: 1943.92, average training loss: 1997.50, base loss: 2635.49
[INFO 2017-06-26 18:48:44,406 main.py:47] epoch 2784, training loss: 1954.43, average training loss: 1997.40, base loss: 2635.32
[INFO 2017-06-26 18:48:44,723 main.py:47] epoch 2785, training loss: 1927.65, average training loss: 1996.79, base loss: 2634.59
[INFO 2017-06-26 18:48:45,033 main.py:47] epoch 2786, training loss: 2184.61, average training loss: 1996.99, base loss: 2634.96
[INFO 2017-06-26 18:48:45,336 main.py:47] epoch 2787, training loss: 1690.85, average training loss: 1996.91, base loss: 2634.97
[INFO 2017-06-26 18:48:45,644 main.py:47] epoch 2788, training loss: 1764.25, average training loss: 1996.38, base loss: 2634.30
[INFO 2017-06-26 18:48:45,948 main.py:47] epoch 2789, training loss: 2055.93, average training loss: 1996.32, base loss: 2634.25
[INFO 2017-06-26 18:48:46,251 main.py:47] epoch 2790, training loss: 1864.17, average training loss: 1996.09, base loss: 2633.85
[INFO 2017-06-26 18:48:46,556 main.py:47] epoch 2791, training loss: 1894.34, average training loss: 1995.94, base loss: 2633.80
[INFO 2017-06-26 18:48:46,862 main.py:47] epoch 2792, training loss: 1913.08, average training loss: 1996.02, base loss: 2633.63
[INFO 2017-06-26 18:48:47,171 main.py:47] epoch 2793, training loss: 1954.38, average training loss: 1996.21, base loss: 2634.01
[INFO 2017-06-26 18:48:47,475 main.py:47] epoch 2794, training loss: 1908.93, average training loss: 1995.97, base loss: 2633.64
[INFO 2017-06-26 18:48:47,783 main.py:47] epoch 2795, training loss: 1879.78, average training loss: 1996.08, base loss: 2633.89
[INFO 2017-06-26 18:48:48,086 main.py:47] epoch 2796, training loss: 2010.20, average training loss: 1995.94, base loss: 2633.55
[INFO 2017-06-26 18:48:48,393 main.py:47] epoch 2797, training loss: 1922.00, average training loss: 1995.79, base loss: 2633.36
[INFO 2017-06-26 18:48:48,702 main.py:47] epoch 2798, training loss: 2004.39, average training loss: 1995.68, base loss: 2633.28
[INFO 2017-06-26 18:48:49,005 main.py:47] epoch 2799, training loss: 1919.21, average training loss: 1995.69, base loss: 2633.35
[INFO 2017-06-26 18:48:49,005 main.py:49] epoch 2799, testing
[INFO 2017-06-26 18:48:52,996 main.py:100] average testing loss: 2018.80, base loss: 2688.71
[INFO 2017-06-26 18:48:53,021 main.py:73] current best accuracy: 1860.32
[INFO 2017-06-26 18:48:53,329 main.py:47] epoch 2800, training loss: 2050.39, average training loss: 1995.63, base loss: 2633.24
[INFO 2017-06-26 18:48:53,637 main.py:47] epoch 2801, training loss: 1819.92, average training loss: 1995.62, base loss: 2633.32
[INFO 2017-06-26 18:48:53,941 main.py:47] epoch 2802, training loss: 1952.01, average training loss: 1995.80, base loss: 2633.81
[INFO 2017-06-26 18:48:54,244 main.py:47] epoch 2803, training loss: 1955.32, average training loss: 1995.87, base loss: 2633.99
[INFO 2017-06-26 18:48:54,552 main.py:47] epoch 2804, training loss: 2121.03, average training loss: 1996.00, base loss: 2634.32
[INFO 2017-06-26 18:48:54,857 main.py:47] epoch 2805, training loss: 1985.45, average training loss: 1996.04, base loss: 2634.33
[INFO 2017-06-26 18:48:55,161 main.py:47] epoch 2806, training loss: 1900.43, average training loss: 1995.73, base loss: 2633.84
[INFO 2017-06-26 18:48:55,464 main.py:47] epoch 2807, training loss: 1922.40, average training loss: 1995.54, base loss: 2633.68
[INFO 2017-06-26 18:48:55,765 main.py:47] epoch 2808, training loss: 1828.77, average training loss: 1995.51, base loss: 2633.64
[INFO 2017-06-26 18:48:56,070 main.py:47] epoch 2809, training loss: 2046.35, average training loss: 1995.61, base loss: 2633.91
[INFO 2017-06-26 18:48:56,376 main.py:47] epoch 2810, training loss: 1984.34, average training loss: 1995.58, base loss: 2633.81
[INFO 2017-06-26 18:48:56,680 main.py:47] epoch 2811, training loss: 2086.01, average training loss: 1995.40, base loss: 2633.76
[INFO 2017-06-26 18:48:56,987 main.py:47] epoch 2812, training loss: 1786.67, average training loss: 1994.90, base loss: 2633.08
[INFO 2017-06-26 18:48:57,292 main.py:47] epoch 2813, training loss: 1843.64, average training loss: 1994.87, base loss: 2633.15
[INFO 2017-06-26 18:48:57,597 main.py:47] epoch 2814, training loss: 2060.71, average training loss: 1994.95, base loss: 2633.10
[INFO 2017-06-26 18:48:57,902 main.py:47] epoch 2815, training loss: 2181.55, average training loss: 1995.43, base loss: 2633.92
[INFO 2017-06-26 18:48:58,207 main.py:47] epoch 2816, training loss: 2025.50, average training loss: 1995.27, base loss: 2633.65
[INFO 2017-06-26 18:48:58,514 main.py:47] epoch 2817, training loss: 2111.08, average training loss: 1995.53, base loss: 2633.91
[INFO 2017-06-26 18:48:58,821 main.py:47] epoch 2818, training loss: 1733.26, average training loss: 1995.09, base loss: 2633.31
[INFO 2017-06-26 18:48:59,123 main.py:47] epoch 2819, training loss: 2071.06, average training loss: 1995.18, base loss: 2633.32
[INFO 2017-06-26 18:48:59,429 main.py:47] epoch 2820, training loss: 1775.67, average training loss: 1994.65, base loss: 2632.54
[INFO 2017-06-26 18:48:59,736 main.py:47] epoch 2821, training loss: 1864.37, average training loss: 1994.41, base loss: 2632.06
[INFO 2017-06-26 18:49:00,042 main.py:47] epoch 2822, training loss: 1767.12, average training loss: 1994.19, base loss: 2631.83
[INFO 2017-06-26 18:49:00,349 main.py:47] epoch 2823, training loss: 2287.78, average training loss: 1994.37, base loss: 2632.56
[INFO 2017-06-26 18:49:00,657 main.py:47] epoch 2824, training loss: 1699.18, average training loss: 1994.14, base loss: 2631.94
[INFO 2017-06-26 18:49:00,964 main.py:47] epoch 2825, training loss: 1962.18, average training loss: 1994.00, base loss: 2631.71
[INFO 2017-06-26 18:49:01,270 main.py:47] epoch 2826, training loss: 2143.94, average training loss: 1994.39, base loss: 2632.36
[INFO 2017-06-26 18:49:01,579 main.py:47] epoch 2827, training loss: 1892.74, average training loss: 1994.18, base loss: 2632.00
[INFO 2017-06-26 18:49:01,885 main.py:47] epoch 2828, training loss: 2052.44, average training loss: 1994.35, base loss: 2632.44
[INFO 2017-06-26 18:49:02,192 main.py:47] epoch 2829, training loss: 2070.68, average training loss: 1994.73, base loss: 2632.81
[INFO 2017-06-26 18:49:02,499 main.py:47] epoch 2830, training loss: 2087.43, average training loss: 1994.62, base loss: 2632.88
[INFO 2017-06-26 18:49:02,805 main.py:47] epoch 2831, training loss: 1850.89, average training loss: 1994.57, base loss: 2632.75
[INFO 2017-06-26 18:49:03,108 main.py:47] epoch 2832, training loss: 2182.81, average training loss: 1994.91, base loss: 2633.28
[INFO 2017-06-26 18:49:03,415 main.py:47] epoch 2833, training loss: 1936.98, average training loss: 1994.89, base loss: 2633.10
[INFO 2017-06-26 18:49:03,723 main.py:47] epoch 2834, training loss: 1876.01, average training loss: 1994.74, base loss: 2633.07
[INFO 2017-06-26 18:49:04,030 main.py:47] epoch 2835, training loss: 1934.69, average training loss: 1994.54, base loss: 2632.84
[INFO 2017-06-26 18:49:04,336 main.py:47] epoch 2836, training loss: 2405.51, average training loss: 1995.08, base loss: 2633.56
[INFO 2017-06-26 18:49:04,642 main.py:47] epoch 2837, training loss: 1914.04, average training loss: 1995.17, base loss: 2633.70
[INFO 2017-06-26 18:49:04,950 main.py:47] epoch 2838, training loss: 2041.73, average training loss: 1995.22, base loss: 2633.66
[INFO 2017-06-26 18:49:05,257 main.py:47] epoch 2839, training loss: 2219.19, average training loss: 1994.94, base loss: 2633.31
[INFO 2017-06-26 18:49:05,564 main.py:47] epoch 2840, training loss: 1887.37, average training loss: 1994.70, base loss: 2633.03
[INFO 2017-06-26 18:49:05,870 main.py:47] epoch 2841, training loss: 1834.47, average training loss: 1994.67, base loss: 2632.81
[INFO 2017-06-26 18:49:06,177 main.py:47] epoch 2842, training loss: 1772.89, average training loss: 1994.53, base loss: 2632.75
[INFO 2017-06-26 18:49:06,483 main.py:47] epoch 2843, training loss: 1973.93, average training loss: 1994.16, base loss: 2632.39
[INFO 2017-06-26 18:49:06,789 main.py:47] epoch 2844, training loss: 1635.72, average training loss: 1993.67, base loss: 2631.87
[INFO 2017-06-26 18:49:07,098 main.py:47] epoch 2845, training loss: 1769.84, average training loss: 1993.41, base loss: 2631.58
[INFO 2017-06-26 18:49:07,401 main.py:47] epoch 2846, training loss: 2114.69, average training loss: 1993.46, base loss: 2631.70
[INFO 2017-06-26 18:49:07,709 main.py:47] epoch 2847, training loss: 1956.12, average training loss: 1993.14, base loss: 2631.64
[INFO 2017-06-26 18:49:08,013 main.py:47] epoch 2848, training loss: 2335.73, average training loss: 1993.47, base loss: 2632.22
[INFO 2017-06-26 18:49:08,421 main.py:47] epoch 2849, training loss: 1877.62, average training loss: 1993.36, base loss: 2632.17
[INFO 2017-06-26 18:49:08,729 main.py:47] epoch 2850, training loss: 1934.24, average training loss: 1993.25, base loss: 2632.05
[INFO 2017-06-26 18:49:09,035 main.py:47] epoch 2851, training loss: 2050.30, average training loss: 1993.17, base loss: 2632.16
[INFO 2017-06-26 18:49:09,343 main.py:47] epoch 2852, training loss: 2209.72, average training loss: 1993.26, base loss: 2632.34
[INFO 2017-06-26 18:49:09,649 main.py:47] epoch 2853, training loss: 2084.91, average training loss: 1993.59, base loss: 2633.01
[INFO 2017-06-26 18:49:09,954 main.py:47] epoch 2854, training loss: 1936.31, average training loss: 1993.32, base loss: 2632.63
[INFO 2017-06-26 18:49:10,260 main.py:47] epoch 2855, training loss: 2074.28, average training loss: 1993.37, base loss: 2632.96
[INFO 2017-06-26 18:49:10,566 main.py:47] epoch 2856, training loss: 1948.72, average training loss: 1992.94, base loss: 2632.56
[INFO 2017-06-26 18:49:10,870 main.py:47] epoch 2857, training loss: 2400.01, average training loss: 1993.32, base loss: 2632.96
[INFO 2017-06-26 18:49:11,174 main.py:47] epoch 2858, training loss: 1910.85, average training loss: 1993.22, base loss: 2632.95
[INFO 2017-06-26 18:49:11,480 main.py:47] epoch 2859, training loss: 1955.06, average training loss: 1993.02, base loss: 2633.02
[INFO 2017-06-26 18:49:11,783 main.py:47] epoch 2860, training loss: 1953.48, average training loss: 1992.91, base loss: 2632.84
[INFO 2017-06-26 18:49:12,086 main.py:47] epoch 2861, training loss: 2143.06, average training loss: 1993.21, base loss: 2632.92
[INFO 2017-06-26 18:49:12,393 main.py:47] epoch 2862, training loss: 1991.58, average training loss: 1993.31, base loss: 2633.17
[INFO 2017-06-26 18:49:12,697 main.py:47] epoch 2863, training loss: 2051.66, average training loss: 1993.47, base loss: 2633.21
[INFO 2017-06-26 18:49:13,008 main.py:47] epoch 2864, training loss: 2275.62, average training loss: 1993.69, base loss: 2633.40
[INFO 2017-06-26 18:49:13,310 main.py:47] epoch 2865, training loss: 2114.23, average training loss: 1993.94, base loss: 2633.76
[INFO 2017-06-26 18:49:13,618 main.py:47] epoch 2866, training loss: 2179.20, average training loss: 1994.49, base loss: 2634.74
[INFO 2017-06-26 18:49:13,926 main.py:47] epoch 2867, training loss: 2191.09, average training loss: 1994.91, base loss: 2635.43
[INFO 2017-06-26 18:49:14,233 main.py:47] epoch 2868, training loss: 1992.39, average training loss: 1994.97, base loss: 2635.53
[INFO 2017-06-26 18:49:14,541 main.py:47] epoch 2869, training loss: 2067.31, average training loss: 1994.43, base loss: 2634.97
[INFO 2017-06-26 18:49:14,847 main.py:47] epoch 2870, training loss: 1946.71, average training loss: 1994.32, base loss: 2634.78
[INFO 2017-06-26 18:49:15,155 main.py:47] epoch 2871, training loss: 1970.12, average training loss: 1994.32, base loss: 2634.95
[INFO 2017-06-26 18:49:15,464 main.py:47] epoch 2872, training loss: 1910.01, average training loss: 1994.35, base loss: 2635.24
[INFO 2017-06-26 18:49:15,772 main.py:47] epoch 2873, training loss: 2084.79, average training loss: 1994.54, base loss: 2635.57
[INFO 2017-06-26 18:49:16,080 main.py:47] epoch 2874, training loss: 2045.02, average training loss: 1994.39, base loss: 2635.44
[INFO 2017-06-26 18:49:16,388 main.py:47] epoch 2875, training loss: 1841.91, average training loss: 1993.92, base loss: 2634.92
[INFO 2017-06-26 18:49:16,696 main.py:47] epoch 2876, training loss: 2023.30, average training loss: 1994.02, base loss: 2635.16
[INFO 2017-06-26 18:49:17,003 main.py:47] epoch 2877, training loss: 2154.61, average training loss: 1994.22, base loss: 2635.60
[INFO 2017-06-26 18:49:17,308 main.py:47] epoch 2878, training loss: 2182.15, average training loss: 1994.38, base loss: 2635.67
[INFO 2017-06-26 18:49:17,615 main.py:47] epoch 2879, training loss: 1737.02, average training loss: 1994.35, base loss: 2635.75
[INFO 2017-06-26 18:49:17,922 main.py:47] epoch 2880, training loss: 2091.58, average training loss: 1994.57, base loss: 2636.26
[INFO 2017-06-26 18:49:18,230 main.py:47] epoch 2881, training loss: 2074.77, average training loss: 1994.58, base loss: 2636.39
[INFO 2017-06-26 18:49:18,533 main.py:47] epoch 2882, training loss: 1987.50, average training loss: 1994.30, base loss: 2635.98
[INFO 2017-06-26 18:49:18,840 main.py:47] epoch 2883, training loss: 2038.05, average training loss: 1994.29, base loss: 2635.99
[INFO 2017-06-26 18:49:19,149 main.py:47] epoch 2884, training loss: 2115.03, average training loss: 1994.26, base loss: 2636.15
[INFO 2017-06-26 18:49:19,456 main.py:47] epoch 2885, training loss: 1884.35, average training loss: 1994.18, base loss: 2636.16
[INFO 2017-06-26 18:49:19,764 main.py:47] epoch 2886, training loss: 2212.47, average training loss: 1994.45, base loss: 2636.43
[INFO 2017-06-26 18:49:20,069 main.py:47] epoch 2887, training loss: 1927.25, average training loss: 1994.36, base loss: 2636.12
[INFO 2017-06-26 18:49:20,377 main.py:47] epoch 2888, training loss: 2181.56, average training loss: 1994.43, base loss: 2636.46
[INFO 2017-06-26 18:49:20,685 main.py:47] epoch 2889, training loss: 1881.17, average training loss: 1994.39, base loss: 2636.50
[INFO 2017-06-26 18:49:20,993 main.py:47] epoch 2890, training loss: 1806.09, average training loss: 1994.46, base loss: 2636.80
[INFO 2017-06-26 18:49:21,301 main.py:47] epoch 2891, training loss: 1854.98, average training loss: 1994.62, base loss: 2637.10
[INFO 2017-06-26 18:49:21,607 main.py:47] epoch 2892, training loss: 1870.22, average training loss: 1994.47, base loss: 2636.97
[INFO 2017-06-26 18:49:21,916 main.py:47] epoch 2893, training loss: 2121.07, average training loss: 1994.21, base loss: 2636.63
[INFO 2017-06-26 18:49:22,225 main.py:47] epoch 2894, training loss: 1716.85, average training loss: 1993.91, base loss: 2636.19
[INFO 2017-06-26 18:49:22,528 main.py:47] epoch 2895, training loss: 1912.13, average training loss: 1993.47, base loss: 2635.52
[INFO 2017-06-26 18:49:22,835 main.py:47] epoch 2896, training loss: 2175.42, average training loss: 1993.84, base loss: 2636.24
[INFO 2017-06-26 18:49:23,142 main.py:47] epoch 2897, training loss: 2511.31, average training loss: 1994.05, base loss: 2636.39
[INFO 2017-06-26 18:49:23,450 main.py:47] epoch 2898, training loss: 2621.22, average training loss: 1994.08, base loss: 2636.16
[INFO 2017-06-26 18:49:23,758 main.py:47] epoch 2899, training loss: 2249.12, average training loss: 1994.52, base loss: 2636.91
[INFO 2017-06-26 18:49:23,758 main.py:49] epoch 2899, testing
[INFO 2017-06-26 18:49:27,752 main.py:100] average testing loss: 1954.50, base loss: 2536.87
[INFO 2017-06-26 18:49:27,778 main.py:73] current best accuracy: 1860.32
[INFO 2017-06-26 18:49:28,088 main.py:47] epoch 2900, training loss: 2045.03, average training loss: 1994.43, base loss: 2636.60
[INFO 2017-06-26 18:49:28,394 main.py:47] epoch 2901, training loss: 2067.00, average training loss: 1994.60, base loss: 2636.59
[INFO 2017-06-26 18:49:28,699 main.py:47] epoch 2902, training loss: 1984.35, average training loss: 1994.75, base loss: 2636.76
[INFO 2017-06-26 18:49:29,006 main.py:47] epoch 2903, training loss: 2096.16, average training loss: 1994.64, base loss: 2636.77
[INFO 2017-06-26 18:49:29,314 main.py:47] epoch 2904, training loss: 2172.55, average training loss: 1995.02, base loss: 2637.43
[INFO 2017-06-26 18:49:29,621 main.py:47] epoch 2905, training loss: 1988.24, average training loss: 1995.00, base loss: 2637.29
[INFO 2017-06-26 18:49:29,930 main.py:47] epoch 2906, training loss: 1637.15, average training loss: 1994.54, base loss: 2636.44
[INFO 2017-06-26 18:49:30,237 main.py:47] epoch 2907, training loss: 2035.15, average training loss: 1994.59, base loss: 2636.50
[INFO 2017-06-26 18:49:30,544 main.py:47] epoch 2908, training loss: 1796.24, average training loss: 1994.30, base loss: 2635.79
[INFO 2017-06-26 18:49:30,853 main.py:47] epoch 2909, training loss: 1636.68, average training loss: 1993.89, base loss: 2635.20
[INFO 2017-06-26 18:49:31,161 main.py:47] epoch 2910, training loss: 2403.15, average training loss: 1994.46, base loss: 2635.80
[INFO 2017-06-26 18:49:31,469 main.py:47] epoch 2911, training loss: 2306.37, average training loss: 1994.54, base loss: 2635.82
[INFO 2017-06-26 18:49:31,775 main.py:47] epoch 2912, training loss: 1942.80, average training loss: 1993.98, base loss: 2634.88
[INFO 2017-06-26 18:49:32,082 main.py:47] epoch 2913, training loss: 2204.13, average training loss: 1994.33, base loss: 2635.33
[INFO 2017-06-26 18:49:32,389 main.py:47] epoch 2914, training loss: 1947.59, average training loss: 1994.44, base loss: 2635.69
[INFO 2017-06-26 18:49:32,696 main.py:47] epoch 2915, training loss: 1947.49, average training loss: 1994.23, base loss: 2635.48
[INFO 2017-06-26 18:49:33,006 main.py:47] epoch 2916, training loss: 1878.55, average training loss: 1993.81, base loss: 2634.96
[INFO 2017-06-26 18:49:33,314 main.py:47] epoch 2917, training loss: 1828.69, average training loss: 1993.64, base loss: 2634.95
[INFO 2017-06-26 18:49:33,620 main.py:47] epoch 2918, training loss: 2176.74, average training loss: 1993.73, base loss: 2635.30
[INFO 2017-06-26 18:49:33,927 main.py:47] epoch 2919, training loss: 1998.80, average training loss: 1993.84, base loss: 2635.38
[INFO 2017-06-26 18:49:34,234 main.py:47] epoch 2920, training loss: 1719.14, average training loss: 1993.30, base loss: 2634.63
[INFO 2017-06-26 18:49:34,537 main.py:47] epoch 2921, training loss: 2074.91, average training loss: 1993.13, base loss: 2634.52
[INFO 2017-06-26 18:49:34,841 main.py:47] epoch 2922, training loss: 1972.74, average training loss: 1993.18, base loss: 2634.53
[INFO 2017-06-26 18:49:35,148 main.py:47] epoch 2923, training loss: 2238.52, average training loss: 1992.93, base loss: 2634.24
[INFO 2017-06-26 18:49:35,455 main.py:47] epoch 2924, training loss: 1752.35, average training loss: 1992.53, base loss: 2633.81
[INFO 2017-06-26 18:49:35,762 main.py:47] epoch 2925, training loss: 2116.24, average training loss: 1992.17, base loss: 2633.49
[INFO 2017-06-26 18:49:36,069 main.py:47] epoch 2926, training loss: 1936.30, average training loss: 1992.09, base loss: 2633.38
[INFO 2017-06-26 18:49:36,377 main.py:47] epoch 2927, training loss: 1912.22, average training loss: 1992.20, base loss: 2633.72
[INFO 2017-06-26 18:49:36,684 main.py:47] epoch 2928, training loss: 1742.14, average training loss: 1991.73, base loss: 2633.27
[INFO 2017-06-26 18:49:36,991 main.py:47] epoch 2929, training loss: 1785.62, average training loss: 1991.66, base loss: 2632.96
[INFO 2017-06-26 18:49:37,301 main.py:47] epoch 2930, training loss: 1651.37, average training loss: 1991.15, base loss: 2632.33
[INFO 2017-06-26 18:49:37,610 main.py:47] epoch 2931, training loss: 1950.64, average training loss: 1991.29, base loss: 2632.50
[INFO 2017-06-26 18:49:37,917 main.py:47] epoch 2932, training loss: 1768.06, average training loss: 1991.21, base loss: 2632.81
[INFO 2017-06-26 18:49:38,224 main.py:47] epoch 2933, training loss: 1910.22, average training loss: 1990.99, base loss: 2632.50
[INFO 2017-06-26 18:49:38,529 main.py:47] epoch 2934, training loss: 1911.33, average training loss: 1990.71, base loss: 2632.21
[INFO 2017-06-26 18:49:38,837 main.py:47] epoch 2935, training loss: 1923.43, average training loss: 1990.93, base loss: 2632.80
[INFO 2017-06-26 18:49:39,142 main.py:47] epoch 2936, training loss: 1979.60, average training loss: 1990.99, base loss: 2632.92
[INFO 2017-06-26 18:49:39,447 main.py:47] epoch 2937, training loss: 1762.44, average training loss: 1990.46, base loss: 2632.14
[INFO 2017-06-26 18:49:39,754 main.py:47] epoch 2938, training loss: 1853.78, average training loss: 1990.28, base loss: 2632.05
[INFO 2017-06-26 18:49:40,062 main.py:47] epoch 2939, training loss: 1713.06, average training loss: 1990.12, base loss: 2632.05
[INFO 2017-06-26 18:49:40,369 main.py:47] epoch 2940, training loss: 1810.34, average training loss: 1989.93, base loss: 2631.79
[INFO 2017-06-26 18:49:40,675 main.py:47] epoch 2941, training loss: 1765.85, average training loss: 1989.84, base loss: 2631.59
[INFO 2017-06-26 18:49:40,982 main.py:47] epoch 2942, training loss: 2198.25, average training loss: 1989.81, base loss: 2631.29
[INFO 2017-06-26 18:49:41,290 main.py:47] epoch 2943, training loss: 1993.90, average training loss: 1989.79, base loss: 2631.29
[INFO 2017-06-26 18:49:41,595 main.py:47] epoch 2944, training loss: 2014.35, average training loss: 1989.99, base loss: 2631.78
[INFO 2017-06-26 18:49:41,899 main.py:47] epoch 2945, training loss: 2084.40, average training loss: 1990.06, base loss: 2631.63
[INFO 2017-06-26 18:49:42,206 main.py:47] epoch 2946, training loss: 1740.17, average training loss: 1989.94, base loss: 2631.37
[INFO 2017-06-26 18:49:42,511 main.py:47] epoch 2947, training loss: 1984.56, average training loss: 1989.89, base loss: 2631.40
[INFO 2017-06-26 18:49:42,818 main.py:47] epoch 2948, training loss: 2429.64, average training loss: 1990.56, base loss: 2632.70
[INFO 2017-06-26 18:49:43,125 main.py:47] epoch 2949, training loss: 1648.18, average training loss: 1990.28, base loss: 2632.32
[INFO 2017-06-26 18:49:43,426 main.py:47] epoch 2950, training loss: 2183.94, average training loss: 1990.40, base loss: 2632.59
[INFO 2017-06-26 18:49:43,730 main.py:47] epoch 2951, training loss: 2362.11, average training loss: 1990.70, base loss: 2633.38
[INFO 2017-06-26 18:49:44,037 main.py:47] epoch 2952, training loss: 1892.61, average training loss: 1990.80, base loss: 2633.98
[INFO 2017-06-26 18:49:44,345 main.py:47] epoch 2953, training loss: 1984.06, average training loss: 1990.84, base loss: 2634.37
[INFO 2017-06-26 18:49:44,652 main.py:47] epoch 2954, training loss: 2145.09, average training loss: 1990.61, base loss: 2634.19
[INFO 2017-06-26 18:49:44,960 main.py:47] epoch 2955, training loss: 1847.01, average training loss: 1990.37, base loss: 2633.97
[INFO 2017-06-26 18:49:45,266 main.py:47] epoch 2956, training loss: 2153.07, average training loss: 1990.66, base loss: 2634.58
[INFO 2017-06-26 18:49:45,574 main.py:47] epoch 2957, training loss: 1800.68, average training loss: 1990.44, base loss: 2634.37
[INFO 2017-06-26 18:49:45,880 main.py:47] epoch 2958, training loss: 2057.06, average training loss: 1990.60, base loss: 2634.61
[INFO 2017-06-26 18:49:46,186 main.py:47] epoch 2959, training loss: 1888.44, average training loss: 1990.79, base loss: 2635.01
[INFO 2017-06-26 18:49:46,491 main.py:47] epoch 2960, training loss: 1681.48, average training loss: 1990.76, base loss: 2635.03
[INFO 2017-06-26 18:49:46,798 main.py:47] epoch 2961, training loss: 1768.83, average training loss: 1990.46, base loss: 2634.66
[INFO 2017-06-26 18:49:47,105 main.py:47] epoch 2962, training loss: 1982.46, average training loss: 1990.51, base loss: 2634.56
[INFO 2017-06-26 18:49:47,410 main.py:47] epoch 2963, training loss: 1820.41, average training loss: 1990.21, base loss: 2633.90
[INFO 2017-06-26 18:49:47,718 main.py:47] epoch 2964, training loss: 1830.20, average training loss: 1990.03, base loss: 2633.88
[INFO 2017-06-26 18:49:48,022 main.py:47] epoch 2965, training loss: 1964.15, average training loss: 1989.92, base loss: 2633.59
[INFO 2017-06-26 18:49:48,328 main.py:47] epoch 2966, training loss: 1874.98, average training loss: 1989.92, base loss: 2633.73
[INFO 2017-06-26 18:49:48,633 main.py:47] epoch 2967, training loss: 1863.42, average training loss: 1989.72, base loss: 2633.55
[INFO 2017-06-26 18:49:48,940 main.py:47] epoch 2968, training loss: 1968.85, average training loss: 1990.00, base loss: 2634.05
[INFO 2017-06-26 18:49:49,247 main.py:47] epoch 2969, training loss: 2123.60, average training loss: 1990.21, base loss: 2634.46
[INFO 2017-06-26 18:49:49,554 main.py:47] epoch 2970, training loss: 1798.73, average training loss: 1990.20, base loss: 2634.45
[INFO 2017-06-26 18:49:49,860 main.py:47] epoch 2971, training loss: 1874.76, average training loss: 1990.29, base loss: 2634.73
[INFO 2017-06-26 18:49:50,169 main.py:47] epoch 2972, training loss: 2175.67, average training loss: 1990.49, base loss: 2634.85
[INFO 2017-06-26 18:49:50,478 main.py:47] epoch 2973, training loss: 2034.86, average training loss: 1990.58, base loss: 2634.97
[INFO 2017-06-26 18:49:50,784 main.py:47] epoch 2974, training loss: 2058.81, average training loss: 1990.12, base loss: 2634.43
[INFO 2017-06-26 18:49:51,089 main.py:47] epoch 2975, training loss: 2059.07, average training loss: 1989.87, base loss: 2634.25
[INFO 2017-06-26 18:49:51,394 main.py:47] epoch 2976, training loss: 1698.84, average training loss: 1989.54, base loss: 2633.75
[INFO 2017-06-26 18:49:51,703 main.py:47] epoch 2977, training loss: 2042.67, average training loss: 1989.56, base loss: 2633.83
[INFO 2017-06-26 18:49:52,011 main.py:47] epoch 2978, training loss: 2147.36, average training loss: 1989.89, base loss: 2634.67
[INFO 2017-06-26 18:49:52,319 main.py:47] epoch 2979, training loss: 1792.91, average training loss: 1989.73, base loss: 2634.36
[INFO 2017-06-26 18:49:52,625 main.py:47] epoch 2980, training loss: 1943.20, average training loss: 1989.18, base loss: 2633.60
[INFO 2017-06-26 18:49:52,931 main.py:47] epoch 2981, training loss: 2051.45, average training loss: 1989.33, base loss: 2633.74
[INFO 2017-06-26 18:49:53,236 main.py:47] epoch 2982, training loss: 2576.86, average training loss: 1989.71, base loss: 2634.06
[INFO 2017-06-26 18:49:53,545 main.py:47] epoch 2983, training loss: 1832.72, average training loss: 1989.62, base loss: 2634.16
[INFO 2017-06-26 18:49:53,851 main.py:47] epoch 2984, training loss: 1865.99, average training loss: 1989.65, base loss: 2634.38
[INFO 2017-06-26 18:49:54,155 main.py:47] epoch 2985, training loss: 2104.08, average training loss: 1989.75, base loss: 2634.54
[INFO 2017-06-26 18:49:54,462 main.py:47] epoch 2986, training loss: 1985.62, average training loss: 1989.78, base loss: 2634.50
[INFO 2017-06-26 18:49:54,770 main.py:47] epoch 2987, training loss: 1885.39, average training loss: 1989.71, base loss: 2634.23
[INFO 2017-06-26 18:49:55,078 main.py:47] epoch 2988, training loss: 2348.80, average training loss: 1989.98, base loss: 2634.67
[INFO 2017-06-26 18:49:55,385 main.py:47] epoch 2989, training loss: 2009.81, average training loss: 1989.92, base loss: 2634.63
[INFO 2017-06-26 18:49:55,692 main.py:47] epoch 2990, training loss: 2060.74, average training loss: 1990.02, base loss: 2635.02
[INFO 2017-06-26 18:49:55,999 main.py:47] epoch 2991, training loss: 1985.24, average training loss: 1989.70, base loss: 2634.56
[INFO 2017-06-26 18:49:56,306 main.py:47] epoch 2992, training loss: 1890.74, average training loss: 1989.35, base loss: 2634.09
[INFO 2017-06-26 18:49:56,614 main.py:47] epoch 2993, training loss: 1958.93, average training loss: 1989.31, base loss: 2634.14
[INFO 2017-06-26 18:49:56,920 main.py:47] epoch 2994, training loss: 2013.48, average training loss: 1989.18, base loss: 2634.34
[INFO 2017-06-26 18:49:57,226 main.py:47] epoch 2995, training loss: 1849.06, average training loss: 1989.04, base loss: 2634.28
[INFO 2017-06-26 18:49:57,534 main.py:47] epoch 2996, training loss: 1650.97, average training loss: 1988.64, base loss: 2633.52
[INFO 2017-06-26 18:49:57,840 main.py:47] epoch 2997, training loss: 1934.22, average training loss: 1988.34, base loss: 2633.24
[INFO 2017-06-26 18:49:58,143 main.py:47] epoch 2998, training loss: 1726.67, average training loss: 1988.07, base loss: 2632.94
[INFO 2017-06-26 18:49:58,450 main.py:47] epoch 2999, training loss: 1670.77, average training loss: 1987.59, base loss: 2632.35
[INFO 2017-06-26 18:49:58,450 main.py:49] epoch 2999, testing
[INFO 2017-06-26 18:50:02,462 main.py:100] average testing loss: 1787.83, base loss: 2334.63
[INFO 2017-06-26 18:50:02,485 main.py:69] model save to ./model/final.pth
[INFO 2017-06-26 18:50:02,498 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:50:02,804 main.py:47] epoch 3000, training loss: 2463.09, average training loss: 1988.08, base loss: 2633.15
[INFO 2017-06-26 18:50:03,110 main.py:47] epoch 3001, training loss: 1839.99, average training loss: 1988.06, base loss: 2633.09
[INFO 2017-06-26 18:50:03,421 main.py:47] epoch 3002, training loss: 1946.86, average training loss: 1988.06, base loss: 2633.02
[INFO 2017-06-26 18:50:03,725 main.py:47] epoch 3003, training loss: 2114.84, average training loss: 1988.48, base loss: 2633.71
[INFO 2017-06-26 18:50:04,031 main.py:47] epoch 3004, training loss: 1957.66, average training loss: 1988.37, base loss: 2633.70
[INFO 2017-06-26 18:50:04,339 main.py:47] epoch 3005, training loss: 1788.30, average training loss: 1988.07, base loss: 2633.43
[INFO 2017-06-26 18:50:04,647 main.py:47] epoch 3006, training loss: 1897.35, average training loss: 1987.92, base loss: 2633.25
[INFO 2017-06-26 18:50:04,952 main.py:47] epoch 3007, training loss: 1714.79, average training loss: 1987.70, base loss: 2633.02
[INFO 2017-06-26 18:50:05,253 main.py:47] epoch 3008, training loss: 2218.88, average training loss: 1988.17, base loss: 2633.78
[INFO 2017-06-26 18:50:05,556 main.py:47] epoch 3009, training loss: 1891.60, average training loss: 1987.86, base loss: 2633.20
[INFO 2017-06-26 18:50:05,861 main.py:47] epoch 3010, training loss: 1744.00, average training loss: 1987.51, base loss: 2632.71
[INFO 2017-06-26 18:50:06,168 main.py:47] epoch 3011, training loss: 1764.05, average training loss: 1987.24, base loss: 2632.18
[INFO 2017-06-26 18:50:06,473 main.py:47] epoch 3012, training loss: 1974.62, average training loss: 1987.23, base loss: 2631.68
[INFO 2017-06-26 18:50:06,782 main.py:47] epoch 3013, training loss: 2068.52, average training loss: 1987.49, base loss: 2632.24
[INFO 2017-06-26 18:50:07,088 main.py:47] epoch 3014, training loss: 1949.34, average training loss: 1987.56, base loss: 2632.40
[INFO 2017-06-26 18:50:07,396 main.py:47] epoch 3015, training loss: 2311.93, average training loss: 1988.10, base loss: 2633.58
[INFO 2017-06-26 18:50:07,772 main.py:47] epoch 3016, training loss: 1979.74, average training loss: 1988.32, base loss: 2633.94
[INFO 2017-06-26 18:50:08,115 main.py:47] epoch 3017, training loss: 1820.41, average training loss: 1988.44, base loss: 2634.10
[INFO 2017-06-26 18:50:08,428 main.py:47] epoch 3018, training loss: 2040.72, average training loss: 1988.68, base loss: 2634.49
[INFO 2017-06-26 18:50:08,737 main.py:47] epoch 3019, training loss: 2025.15, average training loss: 1988.73, base loss: 2634.48
[INFO 2017-06-26 18:50:09,043 main.py:47] epoch 3020, training loss: 1733.75, average training loss: 1988.28, base loss: 2633.95
[INFO 2017-06-26 18:50:09,350 main.py:47] epoch 3021, training loss: 1952.86, average training loss: 1988.19, base loss: 2633.77
[INFO 2017-06-26 18:50:09,657 main.py:47] epoch 3022, training loss: 1966.05, average training loss: 1988.25, base loss: 2633.96
[INFO 2017-06-26 18:50:09,965 main.py:47] epoch 3023, training loss: 1796.55, average training loss: 1988.38, base loss: 2634.12
[INFO 2017-06-26 18:50:10,273 main.py:47] epoch 3024, training loss: 1857.43, average training loss: 1988.29, base loss: 2634.30
[INFO 2017-06-26 18:50:10,580 main.py:47] epoch 3025, training loss: 1859.77, average training loss: 1988.02, base loss: 2633.90
[INFO 2017-06-26 18:50:10,890 main.py:47] epoch 3026, training loss: 2050.47, average training loss: 1988.00, base loss: 2634.04
[INFO 2017-06-26 18:50:11,248 main.py:47] epoch 3027, training loss: 2045.84, average training loss: 1988.19, base loss: 2634.41
[INFO 2017-06-26 18:50:11,557 main.py:47] epoch 3028, training loss: 1900.05, average training loss: 1988.23, base loss: 2634.18
[INFO 2017-06-26 18:50:11,863 main.py:47] epoch 3029, training loss: 2286.31, average training loss: 1988.37, base loss: 2634.46
[INFO 2017-06-26 18:50:12,188 main.py:47] epoch 3030, training loss: 1898.11, average training loss: 1988.10, base loss: 2634.08
[INFO 2017-06-26 18:50:12,493 main.py:47] epoch 3031, training loss: 1973.60, average training loss: 1988.31, base loss: 2634.41
[INFO 2017-06-26 18:50:12,817 main.py:47] epoch 3032, training loss: 1980.08, average training loss: 1988.07, base loss: 2634.15
[INFO 2017-06-26 18:50:13,128 main.py:47] epoch 3033, training loss: 1784.57, average training loss: 1987.99, base loss: 2634.07
[INFO 2017-06-26 18:50:13,467 main.py:47] epoch 3034, training loss: 1741.42, average training loss: 1987.70, base loss: 2633.68
[INFO 2017-06-26 18:50:13,779 main.py:47] epoch 3035, training loss: 1817.14, average training loss: 1987.77, base loss: 2633.84
[INFO 2017-06-26 18:50:14,091 main.py:47] epoch 3036, training loss: 2025.54, average training loss: 1987.99, base loss: 2634.27
[INFO 2017-06-26 18:50:14,403 main.py:47] epoch 3037, training loss: 1645.24, average training loss: 1987.87, base loss: 2634.22
[INFO 2017-06-26 18:50:14,714 main.py:47] epoch 3038, training loss: 2221.57, average training loss: 1988.25, base loss: 2634.81
[INFO 2017-06-26 18:50:15,027 main.py:47] epoch 3039, training loss: 1731.97, average training loss: 1988.06, base loss: 2634.56
[INFO 2017-06-26 18:50:15,335 main.py:47] epoch 3040, training loss: 1550.03, average training loss: 1987.49, base loss: 2633.84
[INFO 2017-06-26 18:50:15,641 main.py:47] epoch 3041, training loss: 1794.33, average training loss: 1987.31, base loss: 2633.51
[INFO 2017-06-26 18:50:15,950 main.py:47] epoch 3042, training loss: 1983.87, average training loss: 1987.37, base loss: 2633.81
[INFO 2017-06-26 18:50:16,258 main.py:47] epoch 3043, training loss: 1895.06, average training loss: 1987.20, base loss: 2633.43
[INFO 2017-06-26 18:50:16,562 main.py:47] epoch 3044, training loss: 2088.82, average training loss: 1987.57, base loss: 2634.02
[INFO 2017-06-26 18:50:16,869 main.py:47] epoch 3045, training loss: 1954.84, average training loss: 1987.76, base loss: 2634.36
[INFO 2017-06-26 18:50:17,177 main.py:47] epoch 3046, training loss: 1819.19, average training loss: 1987.60, base loss: 2634.26
[INFO 2017-06-26 18:50:17,485 main.py:47] epoch 3047, training loss: 2077.71, average training loss: 1987.56, base loss: 2634.39
[INFO 2017-06-26 18:50:17,794 main.py:47] epoch 3048, training loss: 2062.96, average training loss: 1987.47, base loss: 2634.35
[INFO 2017-06-26 18:50:18,194 main.py:47] epoch 3049, training loss: 1797.96, average training loss: 1986.96, base loss: 2633.65
[INFO 2017-06-26 18:50:18,561 main.py:47] epoch 3050, training loss: 2230.36, average training loss: 1987.35, base loss: 2634.43
[INFO 2017-06-26 18:50:18,912 main.py:47] epoch 3051, training loss: 1761.66, average training loss: 1986.87, base loss: 2633.74
[INFO 2017-06-26 18:50:19,277 main.py:47] epoch 3052, training loss: 2077.06, average training loss: 1987.03, base loss: 2634.10
[INFO 2017-06-26 18:50:19,634 main.py:47] epoch 3053, training loss: 2218.95, average training loss: 1987.46, base loss: 2634.90
[INFO 2017-06-26 18:50:19,975 main.py:47] epoch 3054, training loss: 2021.33, average training loss: 1987.20, base loss: 2634.75
[INFO 2017-06-26 18:50:20,294 main.py:47] epoch 3055, training loss: 1851.25, average training loss: 1986.83, base loss: 2634.11
[INFO 2017-06-26 18:50:20,639 main.py:47] epoch 3056, training loss: 1828.82, average training loss: 1986.47, base loss: 2633.87
[INFO 2017-06-26 18:50:21,025 main.py:47] epoch 3057, training loss: 1867.87, average training loss: 1986.39, base loss: 2633.71
[INFO 2017-06-26 18:50:21,365 main.py:47] epoch 3058, training loss: 1982.19, average training loss: 1986.60, base loss: 2634.02
[INFO 2017-06-26 18:50:21,691 main.py:47] epoch 3059, training loss: 2069.55, average training loss: 1986.70, base loss: 2634.00
[INFO 2017-06-26 18:50:22,002 main.py:47] epoch 3060, training loss: 1941.61, average training loss: 1986.60, base loss: 2633.85
[INFO 2017-06-26 18:50:22,308 main.py:47] epoch 3061, training loss: 2025.53, average training loss: 1986.65, base loss: 2633.98
[INFO 2017-06-26 18:50:22,617 main.py:47] epoch 3062, training loss: 1814.90, average training loss: 1986.64, base loss: 2633.85
[INFO 2017-06-26 18:50:22,933 main.py:47] epoch 3063, training loss: 2008.69, average training loss: 1986.70, base loss: 2633.87
[INFO 2017-06-26 18:50:23,240 main.py:47] epoch 3064, training loss: 1813.92, average training loss: 1986.33, base loss: 2633.35
[INFO 2017-06-26 18:50:23,557 main.py:47] epoch 3065, training loss: 1753.80, average training loss: 1986.06, base loss: 2633.17
[INFO 2017-06-26 18:50:23,863 main.py:47] epoch 3066, training loss: 1752.61, average training loss: 1986.15, base loss: 2633.27
[INFO 2017-06-26 18:50:24,189 main.py:47] epoch 3067, training loss: 1899.44, average training loss: 1985.87, base loss: 2632.91
[INFO 2017-06-26 18:50:24,500 main.py:47] epoch 3068, training loss: 1816.07, average training loss: 1985.71, base loss: 2632.84
[INFO 2017-06-26 18:50:24,807 main.py:47] epoch 3069, training loss: 1946.31, average training loss: 1985.63, base loss: 2632.65
[INFO 2017-06-26 18:50:25,121 main.py:47] epoch 3070, training loss: 2083.03, average training loss: 1985.84, base loss: 2633.11
[INFO 2017-06-26 18:50:25,427 main.py:47] epoch 3071, training loss: 2152.44, average training loss: 1986.33, base loss: 2633.79
[INFO 2017-06-26 18:50:25,730 main.py:47] epoch 3072, training loss: 1932.54, average training loss: 1986.17, base loss: 2633.70
[INFO 2017-06-26 18:50:26,052 main.py:47] epoch 3073, training loss: 1768.19, average training loss: 1986.23, base loss: 2633.65
[INFO 2017-06-26 18:50:26,363 main.py:47] epoch 3074, training loss: 1989.47, average training loss: 1986.11, base loss: 2633.48
[INFO 2017-06-26 18:50:26,670 main.py:47] epoch 3075, training loss: 1684.82, average training loss: 1986.06, base loss: 2633.34
[INFO 2017-06-26 18:50:26,986 main.py:47] epoch 3076, training loss: 2084.87, average training loss: 1986.28, base loss: 2633.61
[INFO 2017-06-26 18:50:27,292 main.py:47] epoch 3077, training loss: 2215.80, average training loss: 1986.44, base loss: 2633.98
[INFO 2017-06-26 18:50:27,595 main.py:47] epoch 3078, training loss: 1896.75, average training loss: 1985.95, base loss: 2633.38
[INFO 2017-06-26 18:50:27,903 main.py:47] epoch 3079, training loss: 1723.63, average training loss: 1985.62, base loss: 2633.17
[INFO 2017-06-26 18:50:28,209 main.py:47] epoch 3080, training loss: 1746.50, average training loss: 1985.31, base loss: 2632.53
[INFO 2017-06-26 18:50:28,512 main.py:47] epoch 3081, training loss: 2039.05, average training loss: 1985.33, base loss: 2632.52
[INFO 2017-06-26 18:50:28,821 main.py:47] epoch 3082, training loss: 1887.85, average training loss: 1985.06, base loss: 2632.27
[INFO 2017-06-26 18:50:29,124 main.py:47] epoch 3083, training loss: 2036.30, average training loss: 1985.00, base loss: 2632.47
[INFO 2017-06-26 18:50:29,427 main.py:47] epoch 3084, training loss: 1878.21, average training loss: 1984.79, base loss: 2632.28
[INFO 2017-06-26 18:50:29,732 main.py:47] epoch 3085, training loss: 2390.83, average training loss: 1985.40, base loss: 2633.39
[INFO 2017-06-26 18:50:30,035 main.py:47] epoch 3086, training loss: 2139.49, average training loss: 1985.31, base loss: 2633.05
[INFO 2017-06-26 18:50:30,342 main.py:47] epoch 3087, training loss: 1703.69, average training loss: 1984.80, base loss: 2632.44
[INFO 2017-06-26 18:50:30,648 main.py:47] epoch 3088, training loss: 1922.83, average training loss: 1984.64, base loss: 2632.48
[INFO 2017-06-26 18:50:30,956 main.py:47] epoch 3089, training loss: 1930.88, average training loss: 1984.80, base loss: 2632.90
[INFO 2017-06-26 18:50:31,261 main.py:47] epoch 3090, training loss: 1902.22, average training loss: 1984.65, base loss: 2632.57
[INFO 2017-06-26 18:50:31,568 main.py:47] epoch 3091, training loss: 2045.05, average training loss: 1984.73, base loss: 2632.77
[INFO 2017-06-26 18:50:31,875 main.py:47] epoch 3092, training loss: 1598.19, average training loss: 1984.64, base loss: 2632.61
[INFO 2017-06-26 18:50:32,180 main.py:47] epoch 3093, training loss: 2210.89, average training loss: 1984.88, base loss: 2633.33
[INFO 2017-06-26 18:50:32,484 main.py:47] epoch 3094, training loss: 1886.65, average training loss: 1984.66, base loss: 2633.19
[INFO 2017-06-26 18:50:32,789 main.py:47] epoch 3095, training loss: 1771.89, average training loss: 1984.19, base loss: 2632.52
[INFO 2017-06-26 18:50:33,097 main.py:47] epoch 3096, training loss: 1886.97, average training loss: 1983.88, base loss: 2632.09
[INFO 2017-06-26 18:50:33,405 main.py:47] epoch 3097, training loss: 1789.52, average training loss: 1983.38, base loss: 2631.27
[INFO 2017-06-26 18:50:33,712 main.py:47] epoch 3098, training loss: 2006.98, average training loss: 1983.18, base loss: 2631.29
[INFO 2017-06-26 18:50:34,020 main.py:47] epoch 3099, training loss: 1847.97, average training loss: 1982.98, base loss: 2631.07
[INFO 2017-06-26 18:50:34,020 main.py:49] epoch 3099, testing
[INFO 2017-06-26 18:50:38,020 main.py:100] average testing loss: 2011.31, base loss: 2720.96
[INFO 2017-06-26 18:50:38,045 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:50:38,352 main.py:47] epoch 3100, training loss: 1810.62, average training loss: 1982.95, base loss: 2631.23
[INFO 2017-06-26 18:50:38,657 main.py:47] epoch 3101, training loss: 1934.46, average training loss: 1982.81, base loss: 2631.06
[INFO 2017-06-26 18:50:38,965 main.py:47] epoch 3102, training loss: 2177.82, average training loss: 1983.10, base loss: 2631.77
[INFO 2017-06-26 18:50:39,271 main.py:47] epoch 3103, training loss: 2212.59, average training loss: 1983.46, base loss: 2632.35
[INFO 2017-06-26 18:50:39,580 main.py:47] epoch 3104, training loss: 1913.75, average training loss: 1983.65, base loss: 2632.83
[INFO 2017-06-26 18:50:39,886 main.py:47] epoch 3105, training loss: 2071.77, average training loss: 1983.92, base loss: 2633.28
[INFO 2017-06-26 18:50:40,192 main.py:47] epoch 3106, training loss: 1997.63, average training loss: 1984.02, base loss: 2633.58
[INFO 2017-06-26 18:50:40,496 main.py:47] epoch 3107, training loss: 1935.81, average training loss: 1983.49, base loss: 2632.94
[INFO 2017-06-26 18:50:40,805 main.py:47] epoch 3108, training loss: 1776.29, average training loss: 1983.01, base loss: 2632.12
[INFO 2017-06-26 18:50:41,110 main.py:47] epoch 3109, training loss: 1968.81, average training loss: 1982.80, base loss: 2631.94
[INFO 2017-06-26 18:50:41,415 main.py:47] epoch 3110, training loss: 2007.05, average training loss: 1982.62, base loss: 2631.83
[INFO 2017-06-26 18:50:41,719 main.py:47] epoch 3111, training loss: 1794.73, average training loss: 1982.31, base loss: 2631.44
[INFO 2017-06-26 18:50:42,022 main.py:47] epoch 3112, training loss: 1799.63, average training loss: 1982.01, base loss: 2631.12
[INFO 2017-06-26 18:50:42,327 main.py:47] epoch 3113, training loss: 2043.51, average training loss: 1982.20, base loss: 2631.42
[INFO 2017-06-26 18:50:42,631 main.py:47] epoch 3114, training loss: 1573.79, average training loss: 1981.91, base loss: 2631.13
[INFO 2017-06-26 18:50:42,937 main.py:47] epoch 3115, training loss: 1911.21, average training loss: 1981.74, base loss: 2631.25
[INFO 2017-06-26 18:50:43,244 main.py:47] epoch 3116, training loss: 2146.82, average training loss: 1981.73, base loss: 2631.27
[INFO 2017-06-26 18:50:43,546 main.py:47] epoch 3117, training loss: 1688.65, average training loss: 1981.67, base loss: 2630.92
[INFO 2017-06-26 18:50:43,851 main.py:47] epoch 3118, training loss: 2052.30, average training loss: 1981.77, base loss: 2630.80
[INFO 2017-06-26 18:50:44,155 main.py:47] epoch 3119, training loss: 1971.85, average training loss: 1981.84, base loss: 2630.67
[INFO 2017-06-26 18:50:44,458 main.py:47] epoch 3120, training loss: 2248.10, average training loss: 1982.17, base loss: 2630.98
[INFO 2017-06-26 18:50:44,765 main.py:47] epoch 3121, training loss: 2036.09, average training loss: 1982.48, base loss: 2631.69
[INFO 2017-06-26 18:50:45,073 main.py:47] epoch 3122, training loss: 1733.35, average training loss: 1982.25, base loss: 2631.45
[INFO 2017-06-26 18:50:45,378 main.py:47] epoch 3123, training loss: 1637.06, average training loss: 1981.99, base loss: 2631.09
[INFO 2017-06-26 18:50:45,684 main.py:47] epoch 3124, training loss: 1794.13, average training loss: 1982.04, base loss: 2631.10
[INFO 2017-06-26 18:50:45,991 main.py:47] epoch 3125, training loss: 2182.54, average training loss: 1982.07, base loss: 2631.08
[INFO 2017-06-26 18:50:46,297 main.py:47] epoch 3126, training loss: 2273.58, average training loss: 1982.28, base loss: 2631.39
[INFO 2017-06-26 18:50:46,605 main.py:47] epoch 3127, training loss: 1991.77, average training loss: 1982.55, base loss: 2631.88
[INFO 2017-06-26 18:50:46,914 main.py:47] epoch 3128, training loss: 1801.42, average training loss: 1982.39, base loss: 2631.57
[INFO 2017-06-26 18:50:47,219 main.py:47] epoch 3129, training loss: 1865.00, average training loss: 1982.24, base loss: 2631.49
[INFO 2017-06-26 18:50:47,524 main.py:47] epoch 3130, training loss: 2050.27, average training loss: 1982.52, base loss: 2632.08
[INFO 2017-06-26 18:50:47,829 main.py:47] epoch 3131, training loss: 1687.75, average training loss: 1982.33, base loss: 2631.83
[INFO 2017-06-26 18:50:48,133 main.py:47] epoch 3132, training loss: 2043.55, average training loss: 1982.52, base loss: 2632.28
[INFO 2017-06-26 18:50:48,440 main.py:47] epoch 3133, training loss: 1861.67, average training loss: 1982.60, base loss: 2632.35
[INFO 2017-06-26 18:50:48,748 main.py:47] epoch 3134, training loss: 1867.98, average training loss: 1982.51, base loss: 2632.69
[INFO 2017-06-26 18:50:49,052 main.py:47] epoch 3135, training loss: 1977.93, average training loss: 1982.06, base loss: 2632.21
[INFO 2017-06-26 18:50:49,361 main.py:47] epoch 3136, training loss: 1817.76, average training loss: 1982.28, base loss: 2632.75
[INFO 2017-06-26 18:50:49,668 main.py:47] epoch 3137, training loss: 1913.66, average training loss: 1982.20, base loss: 2632.72
[INFO 2017-06-26 18:50:49,975 main.py:47] epoch 3138, training loss: 1565.71, average training loss: 1981.72, base loss: 2631.95
[INFO 2017-06-26 18:50:50,280 main.py:47] epoch 3139, training loss: 1835.17, average training loss: 1981.48, base loss: 2631.82
[INFO 2017-06-26 18:50:50,582 main.py:47] epoch 3140, training loss: 2075.01, average training loss: 1981.71, base loss: 2632.17
[INFO 2017-06-26 18:50:50,890 main.py:47] epoch 3141, training loss: 1819.36, average training loss: 1981.77, base loss: 2632.58
[INFO 2017-06-26 18:50:51,200 main.py:47] epoch 3142, training loss: 2026.53, average training loss: 1981.63, base loss: 2632.50
[INFO 2017-06-26 18:50:51,506 main.py:47] epoch 3143, training loss: 1723.64, average training loss: 1981.33, base loss: 2632.04
[INFO 2017-06-26 18:50:51,814 main.py:47] epoch 3144, training loss: 2082.89, average training loss: 1981.41, base loss: 2632.22
[INFO 2017-06-26 18:50:52,119 main.py:47] epoch 3145, training loss: 2333.80, average training loss: 1981.96, base loss: 2633.13
[INFO 2017-06-26 18:50:52,424 main.py:47] epoch 3146, training loss: 1791.46, average training loss: 1981.72, base loss: 2632.91
[INFO 2017-06-26 18:50:52,730 main.py:47] epoch 3147, training loss: 1729.59, average training loss: 1981.46, base loss: 2632.64
[INFO 2017-06-26 18:50:53,032 main.py:47] epoch 3148, training loss: 2079.74, average training loss: 1981.36, base loss: 2632.70
[INFO 2017-06-26 18:50:53,341 main.py:47] epoch 3149, training loss: 2125.57, average training loss: 1981.44, base loss: 2632.75
[INFO 2017-06-26 18:50:53,645 main.py:47] epoch 3150, training loss: 1846.50, average training loss: 1981.14, base loss: 2632.52
[INFO 2017-06-26 18:50:53,953 main.py:47] epoch 3151, training loss: 1925.19, average training loss: 1981.25, base loss: 2632.60
[INFO 2017-06-26 18:50:54,259 main.py:47] epoch 3152, training loss: 2169.76, average training loss: 1981.47, base loss: 2632.86
[INFO 2017-06-26 18:50:54,566 main.py:47] epoch 3153, training loss: 1894.29, average training loss: 1981.28, base loss: 2632.92
[INFO 2017-06-26 18:50:54,872 main.py:47] epoch 3154, training loss: 2162.16, average training loss: 1981.54, base loss: 2633.21
[INFO 2017-06-26 18:50:55,175 main.py:47] epoch 3155, training loss: 1931.02, average training loss: 1981.49, base loss: 2633.38
[INFO 2017-06-26 18:50:55,479 main.py:47] epoch 3156, training loss: 2346.31, average training loss: 1981.86, base loss: 2633.87
[INFO 2017-06-26 18:50:55,784 main.py:47] epoch 3157, training loss: 2153.62, average training loss: 1982.08, base loss: 2633.95
[INFO 2017-06-26 18:50:56,088 main.py:47] epoch 3158, training loss: 1838.27, average training loss: 1981.68, base loss: 2633.60
[INFO 2017-06-26 18:50:56,391 main.py:47] epoch 3159, training loss: 1984.82, average training loss: 1981.47, base loss: 2633.64
[INFO 2017-06-26 18:50:56,695 main.py:47] epoch 3160, training loss: 1863.38, average training loss: 1981.45, base loss: 2633.78
[INFO 2017-06-26 18:50:57,003 main.py:47] epoch 3161, training loss: 1904.27, average training loss: 1981.50, base loss: 2633.74
[INFO 2017-06-26 18:50:57,310 main.py:47] epoch 3162, training loss: 2000.33, average training loss: 1981.41, base loss: 2633.69
[INFO 2017-06-26 18:50:57,620 main.py:47] epoch 3163, training loss: 1950.93, average training loss: 1981.55, base loss: 2633.72
[INFO 2017-06-26 18:50:57,928 main.py:47] epoch 3164, training loss: 2002.43, average training loss: 1981.11, base loss: 2632.92
[INFO 2017-06-26 18:50:58,233 main.py:47] epoch 3165, training loss: 2176.41, average training loss: 1981.36, base loss: 2633.05
[INFO 2017-06-26 18:50:58,540 main.py:47] epoch 3166, training loss: 2020.60, average training loss: 1981.28, base loss: 2632.83
[INFO 2017-06-26 18:50:58,847 main.py:47] epoch 3167, training loss: 1735.07, average training loss: 1980.89, base loss: 2631.96
[INFO 2017-06-26 18:50:59,150 main.py:47] epoch 3168, training loss: 2186.11, average training loss: 1980.85, base loss: 2632.07
[INFO 2017-06-26 18:50:59,458 main.py:47] epoch 3169, training loss: 2163.93, average training loss: 1981.15, base loss: 2632.66
[INFO 2017-06-26 18:50:59,764 main.py:47] epoch 3170, training loss: 2023.56, average training loss: 1980.86, base loss: 2632.33
[INFO 2017-06-26 18:51:00,070 main.py:47] epoch 3171, training loss: 2012.35, average training loss: 1980.60, base loss: 2632.02
[INFO 2017-06-26 18:51:00,375 main.py:47] epoch 3172, training loss: 1847.52, average training loss: 1980.43, base loss: 2631.65
[INFO 2017-06-26 18:51:00,682 main.py:47] epoch 3173, training loss: 1668.93, average training loss: 1980.20, base loss: 2631.34
[INFO 2017-06-26 18:51:00,989 main.py:47] epoch 3174, training loss: 1819.57, average training loss: 1979.88, base loss: 2631.04
[INFO 2017-06-26 18:51:01,295 main.py:47] epoch 3175, training loss: 1818.40, average training loss: 1979.94, base loss: 2631.32
[INFO 2017-06-26 18:51:01,603 main.py:47] epoch 3176, training loss: 2111.41, average training loss: 1980.24, base loss: 2631.92
[INFO 2017-06-26 18:51:01,909 main.py:47] epoch 3177, training loss: 1650.07, average training loss: 1980.09, base loss: 2631.62
[INFO 2017-06-26 18:51:02,214 main.py:47] epoch 3178, training loss: 2256.00, average training loss: 1980.31, base loss: 2631.99
[INFO 2017-06-26 18:51:02,518 main.py:47] epoch 3179, training loss: 1716.88, average training loss: 1979.53, base loss: 2631.10
[INFO 2017-06-26 18:51:02,821 main.py:47] epoch 3180, training loss: 1980.22, average training loss: 1979.52, base loss: 2631.34
[INFO 2017-06-26 18:51:03,124 main.py:47] epoch 3181, training loss: 2043.86, average training loss: 1979.64, base loss: 2631.56
[INFO 2017-06-26 18:51:03,425 main.py:47] epoch 3182, training loss: 2372.59, average training loss: 1980.18, base loss: 2632.37
[INFO 2017-06-26 18:51:03,730 main.py:47] epoch 3183, training loss: 2072.56, average training loss: 1979.88, base loss: 2631.95
[INFO 2017-06-26 18:51:04,037 main.py:47] epoch 3184, training loss: 1992.13, average training loss: 1980.13, base loss: 2632.24
[INFO 2017-06-26 18:51:04,343 main.py:47] epoch 3185, training loss: 1848.46, average training loss: 1979.76, base loss: 2631.74
[INFO 2017-06-26 18:51:04,651 main.py:47] epoch 3186, training loss: 2168.62, average training loss: 1979.76, base loss: 2631.83
[INFO 2017-06-26 18:51:04,956 main.py:47] epoch 3187, training loss: 1768.57, average training loss: 1979.41, base loss: 2631.26
[INFO 2017-06-26 18:51:05,263 main.py:47] epoch 3188, training loss: 1890.74, average training loss: 1979.38, base loss: 2631.29
[INFO 2017-06-26 18:51:05,571 main.py:47] epoch 3189, training loss: 1625.08, average training loss: 1979.00, base loss: 2630.88
[INFO 2017-06-26 18:51:05,880 main.py:47] epoch 3190, training loss: 1887.97, average training loss: 1978.95, base loss: 2631.02
[INFO 2017-06-26 18:51:06,188 main.py:47] epoch 3191, training loss: 1899.25, average training loss: 1979.00, base loss: 2631.11
[INFO 2017-06-26 18:51:06,488 main.py:47] epoch 3192, training loss: 2009.41, average training loss: 1979.01, base loss: 2630.99
[INFO 2017-06-26 18:51:06,866 main.py:47] epoch 3193, training loss: 1857.39, average training loss: 1978.57, base loss: 2630.31
[INFO 2017-06-26 18:51:07,202 main.py:47] epoch 3194, training loss: 1601.93, average training loss: 1978.19, base loss: 2629.62
[INFO 2017-06-26 18:51:07,511 main.py:47] epoch 3195, training loss: 1873.44, average training loss: 1978.31, base loss: 2629.93
[INFO 2017-06-26 18:51:07,820 main.py:47] epoch 3196, training loss: 2002.93, average training loss: 1978.31, base loss: 2630.12
[INFO 2017-06-26 18:51:08,130 main.py:47] epoch 3197, training loss: 1781.16, average training loss: 1978.12, base loss: 2629.87
[INFO 2017-06-26 18:51:08,438 main.py:47] epoch 3198, training loss: 2000.95, average training loss: 1978.41, base loss: 2630.18
[INFO 2017-06-26 18:51:08,826 main.py:47] epoch 3199, training loss: 1716.59, average training loss: 1977.99, base loss: 2629.56
[INFO 2017-06-26 18:51:08,826 main.py:49] epoch 3199, testing
[INFO 2017-06-26 18:51:12,981 main.py:100] average testing loss: 1942.55, base loss: 2616.37
[INFO 2017-06-26 18:51:13,005 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:51:13,314 main.py:47] epoch 3200, training loss: 2011.16, average training loss: 1977.89, base loss: 2629.33
[INFO 2017-06-26 18:51:13,617 main.py:47] epoch 3201, training loss: 2018.70, average training loss: 1978.11, base loss: 2629.60
[INFO 2017-06-26 18:51:13,924 main.py:47] epoch 3202, training loss: 2228.30, average training loss: 1978.46, base loss: 2630.28
[INFO 2017-06-26 18:51:14,230 main.py:47] epoch 3203, training loss: 2017.00, average training loss: 1978.37, base loss: 2630.21
[INFO 2017-06-26 18:51:14,532 main.py:47] epoch 3204, training loss: 1918.35, average training loss: 1978.42, base loss: 2630.34
[INFO 2017-06-26 18:51:14,837 main.py:47] epoch 3205, training loss: 1835.96, average training loss: 1978.19, base loss: 2630.05
[INFO 2017-06-26 18:51:15,142 main.py:47] epoch 3206, training loss: 2023.87, average training loss: 1978.05, base loss: 2629.78
[INFO 2017-06-26 18:51:15,446 main.py:47] epoch 3207, training loss: 1866.57, average training loss: 1978.17, base loss: 2630.03
[INFO 2017-06-26 18:51:15,751 main.py:47] epoch 3208, training loss: 1966.68, average training loss: 1978.19, base loss: 2630.11
[INFO 2017-06-26 18:51:16,056 main.py:47] epoch 3209, training loss: 2020.82, average training loss: 1978.47, base loss: 2630.40
[INFO 2017-06-26 18:51:16,363 main.py:47] epoch 3210, training loss: 1858.65, average training loss: 1978.34, base loss: 2630.35
[INFO 2017-06-26 18:51:16,669 main.py:47] epoch 3211, training loss: 1725.80, average training loss: 1978.34, base loss: 2630.65
[INFO 2017-06-26 18:51:16,973 main.py:47] epoch 3212, training loss: 1847.75, average training loss: 1978.35, base loss: 2630.58
[INFO 2017-06-26 18:51:17,280 main.py:47] epoch 3213, training loss: 1687.96, average training loss: 1977.84, base loss: 2629.69
[INFO 2017-06-26 18:51:17,589 main.py:47] epoch 3214, training loss: 2112.38, average training loss: 1978.09, base loss: 2630.22
[INFO 2017-06-26 18:51:17,893 main.py:47] epoch 3215, training loss: 2139.98, average training loss: 1978.19, base loss: 2630.41
[INFO 2017-06-26 18:51:18,196 main.py:47] epoch 3216, training loss: 2239.77, average training loss: 1978.47, base loss: 2630.76
[INFO 2017-06-26 18:51:18,567 main.py:47] epoch 3217, training loss: 2023.35, average training loss: 1978.59, base loss: 2631.10
[INFO 2017-06-26 18:51:18,894 main.py:47] epoch 3218, training loss: 1986.57, average training loss: 1978.84, base loss: 2631.54
[INFO 2017-06-26 18:51:19,207 main.py:47] epoch 3219, training loss: 1829.14, average training loss: 1979.14, base loss: 2632.33
[INFO 2017-06-26 18:51:19,518 main.py:47] epoch 3220, training loss: 1969.14, average training loss: 1979.32, base loss: 2632.47
[INFO 2017-06-26 18:51:19,828 main.py:47] epoch 3221, training loss: 1925.30, average training loss: 1979.17, base loss: 2632.27
[INFO 2017-06-26 18:51:20,151 main.py:47] epoch 3222, training loss: 1936.68, average training loss: 1979.12, base loss: 2632.26
[INFO 2017-06-26 18:51:20,458 main.py:47] epoch 3223, training loss: 1849.12, average training loss: 1978.85, base loss: 2631.88
[INFO 2017-06-26 18:51:20,763 main.py:47] epoch 3224, training loss: 1798.39, average training loss: 1978.78, base loss: 2631.62
[INFO 2017-06-26 18:51:21,067 main.py:47] epoch 3225, training loss: 1885.35, average training loss: 1978.87, base loss: 2631.83
[INFO 2017-06-26 18:51:21,372 main.py:47] epoch 3226, training loss: 2189.21, average training loss: 1978.98, base loss: 2631.93
[INFO 2017-06-26 18:51:21,682 main.py:47] epoch 3227, training loss: 2135.51, average training loss: 1979.06, base loss: 2631.90
[INFO 2017-06-26 18:51:21,985 main.py:47] epoch 3228, training loss: 1944.65, average training loss: 1978.96, base loss: 2631.75
[INFO 2017-06-26 18:51:22,292 main.py:47] epoch 3229, training loss: 1936.05, average training loss: 1978.76, base loss: 2631.59
[INFO 2017-06-26 18:51:22,600 main.py:47] epoch 3230, training loss: 2047.49, average training loss: 1978.93, base loss: 2632.01
[INFO 2017-06-26 18:51:22,915 main.py:47] epoch 3231, training loss: 2160.22, average training loss: 1979.04, base loss: 2632.26
[INFO 2017-06-26 18:51:23,222 main.py:47] epoch 3232, training loss: 1789.17, average training loss: 1978.85, base loss: 2632.17
[INFO 2017-06-26 18:51:23,528 main.py:47] epoch 3233, training loss: 2346.30, average training loss: 1979.19, base loss: 2632.76
[INFO 2017-06-26 18:51:23,835 main.py:47] epoch 3234, training loss: 1882.13, average training loss: 1979.05, base loss: 2632.79
[INFO 2017-06-26 18:51:24,140 main.py:47] epoch 3235, training loss: 1931.06, average training loss: 1979.10, base loss: 2632.99
[INFO 2017-06-26 18:51:24,446 main.py:47] epoch 3236, training loss: 2191.62, average training loss: 1979.53, base loss: 2633.85
[INFO 2017-06-26 18:51:24,755 main.py:47] epoch 3237, training loss: 1893.31, average training loss: 1979.49, base loss: 2633.80
[INFO 2017-06-26 18:51:25,059 main.py:47] epoch 3238, training loss: 1920.56, average training loss: 1979.71, base loss: 2633.90
[INFO 2017-06-26 18:51:25,360 main.py:47] epoch 3239, training loss: 1737.99, average training loss: 1979.52, base loss: 2633.86
[INFO 2017-06-26 18:51:25,668 main.py:47] epoch 3240, training loss: 1831.73, average training loss: 1979.27, base loss: 2633.71
[INFO 2017-06-26 18:51:25,973 main.py:47] epoch 3241, training loss: 2546.25, average training loss: 1979.96, base loss: 2634.75
[INFO 2017-06-26 18:51:26,277 main.py:47] epoch 3242, training loss: 1936.58, average training loss: 1979.83, base loss: 2634.56
[INFO 2017-06-26 18:51:26,582 main.py:47] epoch 3243, training loss: 1793.35, average training loss: 1979.58, base loss: 2634.00
[INFO 2017-06-26 18:51:26,886 main.py:47] epoch 3244, training loss: 2003.03, average training loss: 1979.79, base loss: 2634.35
[INFO 2017-06-26 18:51:27,190 main.py:47] epoch 3245, training loss: 1942.52, average training loss: 1979.84, base loss: 2634.51
[INFO 2017-06-26 18:51:27,493 main.py:47] epoch 3246, training loss: 1988.56, average training loss: 1979.86, base loss: 2634.49
[INFO 2017-06-26 18:51:27,798 main.py:47] epoch 3247, training loss: 1992.26, average training loss: 1979.91, base loss: 2634.73
[INFO 2017-06-26 18:51:28,101 main.py:47] epoch 3248, training loss: 1968.06, average training loss: 1980.25, base loss: 2635.46
[INFO 2017-06-26 18:51:28,406 main.py:47] epoch 3249, training loss: 1659.73, average training loss: 1979.84, base loss: 2634.92
[INFO 2017-06-26 18:51:28,708 main.py:47] epoch 3250, training loss: 1940.10, average training loss: 1979.93, base loss: 2635.19
[INFO 2017-06-26 18:51:29,013 main.py:47] epoch 3251, training loss: 1950.23, average training loss: 1980.04, base loss: 2635.30
[INFO 2017-06-26 18:51:29,318 main.py:47] epoch 3252, training loss: 2002.06, average training loss: 1979.73, base loss: 2634.87
[INFO 2017-06-26 18:51:29,622 main.py:47] epoch 3253, training loss: 2140.78, average training loss: 1979.58, base loss: 2634.80
[INFO 2017-06-26 18:51:29,931 main.py:47] epoch 3254, training loss: 2230.26, average training loss: 1979.86, base loss: 2635.29
[INFO 2017-06-26 18:51:30,238 main.py:47] epoch 3255, training loss: 2058.51, average training loss: 1979.87, base loss: 2635.22
[INFO 2017-06-26 18:51:30,539 main.py:47] epoch 3256, training loss: 1970.25, average training loss: 1979.71, base loss: 2635.06
[INFO 2017-06-26 18:51:30,845 main.py:47] epoch 3257, training loss: 2036.28, average training loss: 1979.76, base loss: 2635.09
[INFO 2017-06-26 18:51:31,151 main.py:47] epoch 3258, training loss: 1924.89, average training loss: 1979.46, base loss: 2634.87
[INFO 2017-06-26 18:51:31,454 main.py:47] epoch 3259, training loss: 1923.84, average training loss: 1979.44, base loss: 2634.63
[INFO 2017-06-26 18:51:31,761 main.py:47] epoch 3260, training loss: 2186.61, average training loss: 1979.57, base loss: 2634.96
[INFO 2017-06-26 18:51:32,066 main.py:47] epoch 3261, training loss: 1840.91, average training loss: 1979.31, base loss: 2634.74
[INFO 2017-06-26 18:51:32,373 main.py:47] epoch 3262, training loss: 1980.40, average training loss: 1979.34, base loss: 2634.74
[INFO 2017-06-26 18:51:32,681 main.py:47] epoch 3263, training loss: 1992.98, average training loss: 1979.15, base loss: 2634.55
[INFO 2017-06-26 18:51:32,990 main.py:47] epoch 3264, training loss: 1957.16, average training loss: 1979.04, base loss: 2634.28
[INFO 2017-06-26 18:51:33,295 main.py:47] epoch 3265, training loss: 1696.44, average training loss: 1978.80, base loss: 2633.88
[INFO 2017-06-26 18:51:33,603 main.py:47] epoch 3266, training loss: 2176.59, average training loss: 1979.08, base loss: 2634.37
[INFO 2017-06-26 18:51:33,906 main.py:47] epoch 3267, training loss: 1651.88, average training loss: 1979.25, base loss: 2634.59
[INFO 2017-06-26 18:51:34,210 main.py:47] epoch 3268, training loss: 2077.64, average training loss: 1979.37, base loss: 2634.70
[INFO 2017-06-26 18:51:34,515 main.py:47] epoch 3269, training loss: 1851.39, average training loss: 1979.07, base loss: 2634.02
[INFO 2017-06-26 18:51:34,818 main.py:47] epoch 3270, training loss: 1733.67, average training loss: 1978.80, base loss: 2633.77
[INFO 2017-06-26 18:51:35,126 main.py:47] epoch 3271, training loss: 2002.19, average training loss: 1978.82, base loss: 2633.89
[INFO 2017-06-26 18:51:35,429 main.py:47] epoch 3272, training loss: 1921.72, average training loss: 1978.61, base loss: 2633.69
[INFO 2017-06-26 18:51:35,733 main.py:47] epoch 3273, training loss: 2220.95, average training loss: 1978.96, base loss: 2634.44
[INFO 2017-06-26 18:51:36,040 main.py:47] epoch 3274, training loss: 1844.30, average training loss: 1978.68, base loss: 2634.15
[INFO 2017-06-26 18:51:36,343 main.py:47] epoch 3275, training loss: 1911.64, average training loss: 1978.61, base loss: 2633.72
[INFO 2017-06-26 18:51:36,648 main.py:47] epoch 3276, training loss: 1709.53, average training loss: 1978.32, base loss: 2633.38
[INFO 2017-06-26 18:51:36,951 main.py:47] epoch 3277, training loss: 1644.87, average training loss: 1978.17, base loss: 2632.97
[INFO 2017-06-26 18:51:37,256 main.py:47] epoch 3278, training loss: 2039.91, average training loss: 1978.02, base loss: 2632.80
[INFO 2017-06-26 18:51:37,560 main.py:47] epoch 3279, training loss: 1902.12, average training loss: 1977.97, base loss: 2632.61
[INFO 2017-06-26 18:51:37,867 main.py:47] epoch 3280, training loss: 2171.50, average training loss: 1978.13, base loss: 2632.77
[INFO 2017-06-26 18:51:38,168 main.py:47] epoch 3281, training loss: 1873.25, average training loss: 1977.92, base loss: 2632.63
[INFO 2017-06-26 18:51:38,475 main.py:47] epoch 3282, training loss: 2042.62, average training loss: 1977.89, base loss: 2632.72
[INFO 2017-06-26 18:51:38,781 main.py:47] epoch 3283, training loss: 2221.51, average training loss: 1978.01, base loss: 2632.93
[INFO 2017-06-26 18:51:39,086 main.py:47] epoch 3284, training loss: 1868.21, average training loss: 1977.94, base loss: 2632.86
[INFO 2017-06-26 18:51:39,393 main.py:47] epoch 3285, training loss: 1898.78, average training loss: 1977.69, base loss: 2632.34
[INFO 2017-06-26 18:51:39,701 main.py:47] epoch 3286, training loss: 1946.84, average training loss: 1977.61, base loss: 2632.33
[INFO 2017-06-26 18:51:40,006 main.py:47] epoch 3287, training loss: 1839.02, average training loss: 1977.20, base loss: 2631.87
[INFO 2017-06-26 18:51:40,312 main.py:47] epoch 3288, training loss: 2018.22, average training loss: 1976.95, base loss: 2631.43
[INFO 2017-06-26 18:51:40,618 main.py:47] epoch 3289, training loss: 1924.60, average training loss: 1977.02, base loss: 2631.65
[INFO 2017-06-26 18:51:40,924 main.py:47] epoch 3290, training loss: 2106.98, average training loss: 1977.01, base loss: 2631.90
[INFO 2017-06-26 18:51:41,228 main.py:47] epoch 3291, training loss: 1648.08, average training loss: 1976.57, base loss: 2631.27
[INFO 2017-06-26 18:51:41,529 main.py:47] epoch 3292, training loss: 1997.15, average training loss: 1976.80, base loss: 2632.00
[INFO 2017-06-26 18:51:41,833 main.py:47] epoch 3293, training loss: 1927.78, average training loss: 1976.84, base loss: 2632.11
[INFO 2017-06-26 18:51:42,140 main.py:47] epoch 3294, training loss: 1881.23, average training loss: 1976.79, base loss: 2631.99
[INFO 2017-06-26 18:51:42,448 main.py:47] epoch 3295, training loss: 2101.26, average training loss: 1976.99, base loss: 2632.16
[INFO 2017-06-26 18:51:42,752 main.py:47] epoch 3296, training loss: 1864.03, average training loss: 1977.08, base loss: 2632.24
[INFO 2017-06-26 18:51:43,059 main.py:47] epoch 3297, training loss: 2084.35, average training loss: 1977.22, base loss: 2632.45
[INFO 2017-06-26 18:51:43,366 main.py:47] epoch 3298, training loss: 1705.10, average training loss: 1977.03, base loss: 2632.34
[INFO 2017-06-26 18:51:43,674 main.py:47] epoch 3299, training loss: 1960.36, average training loss: 1977.06, base loss: 2632.51
[INFO 2017-06-26 18:51:43,674 main.py:49] epoch 3299, testing
[INFO 2017-06-26 18:51:47,641 main.py:100] average testing loss: 2000.59, base loss: 2704.61
[INFO 2017-06-26 18:51:47,666 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:51:47,969 main.py:47] epoch 3300, training loss: 1843.79, average training loss: 1976.95, base loss: 2632.22
[INFO 2017-06-26 18:51:48,272 main.py:47] epoch 3301, training loss: 2071.59, average training loss: 1976.98, base loss: 2632.40
[INFO 2017-06-26 18:51:48,579 main.py:47] epoch 3302, training loss: 1998.35, average training loss: 1976.66, base loss: 2632.01
[INFO 2017-06-26 18:51:48,886 main.py:47] epoch 3303, training loss: 2008.98, average training loss: 1976.27, base loss: 2631.40
[INFO 2017-06-26 18:51:49,191 main.py:47] epoch 3304, training loss: 1811.79, average training loss: 1976.09, base loss: 2631.52
[INFO 2017-06-26 18:51:49,493 main.py:47] epoch 3305, training loss: 2089.18, average training loss: 1976.20, base loss: 2631.89
[INFO 2017-06-26 18:51:49,798 main.py:47] epoch 3306, training loss: 1820.83, average training loss: 1975.65, base loss: 2631.15
[INFO 2017-06-26 18:51:50,101 main.py:47] epoch 3307, training loss: 1807.55, average training loss: 1975.19, base loss: 2630.67
[INFO 2017-06-26 18:51:50,410 main.py:47] epoch 3308, training loss: 1758.34, average training loss: 1974.94, base loss: 2630.24
[INFO 2017-06-26 18:51:50,713 main.py:47] epoch 3309, training loss: 1842.65, average training loss: 1974.64, base loss: 2630.02
[INFO 2017-06-26 18:51:51,016 main.py:47] epoch 3310, training loss: 2442.83, average training loss: 1974.76, base loss: 2630.11
[INFO 2017-06-26 18:51:51,321 main.py:47] epoch 3311, training loss: 1795.61, average training loss: 1973.97, base loss: 2629.20
[INFO 2017-06-26 18:51:51,627 main.py:47] epoch 3312, training loss: 1643.40, average training loss: 1973.56, base loss: 2628.76
[INFO 2017-06-26 18:51:51,933 main.py:47] epoch 3313, training loss: 2100.89, average training loss: 1973.75, base loss: 2629.09
[INFO 2017-06-26 18:51:52,241 main.py:47] epoch 3314, training loss: 1815.99, average training loss: 1973.57, base loss: 2629.11
[INFO 2017-06-26 18:51:52,546 main.py:47] epoch 3315, training loss: 2181.16, average training loss: 1973.84, base loss: 2629.73
[INFO 2017-06-26 18:51:52,853 main.py:47] epoch 3316, training loss: 1937.40, average training loss: 1973.95, base loss: 2630.25
[INFO 2017-06-26 18:51:53,158 main.py:47] epoch 3317, training loss: 1771.32, average training loss: 1973.80, base loss: 2630.33
[INFO 2017-06-26 18:51:53,462 main.py:47] epoch 3318, training loss: 1881.19, average training loss: 1973.59, base loss: 2630.29
[INFO 2017-06-26 18:51:53,768 main.py:47] epoch 3319, training loss: 1853.81, average training loss: 1973.63, base loss: 2630.31
[INFO 2017-06-26 18:51:54,073 main.py:47] epoch 3320, training loss: 1751.02, average training loss: 1973.57, base loss: 2630.33
[INFO 2017-06-26 18:51:54,380 main.py:47] epoch 3321, training loss: 1882.07, average training loss: 1973.73, base loss: 2630.78
[INFO 2017-06-26 18:51:54,686 main.py:47] epoch 3322, training loss: 1834.38, average training loss: 1973.24, base loss: 2630.27
[INFO 2017-06-26 18:51:54,997 main.py:47] epoch 3323, training loss: 1842.55, average training loss: 1972.98, base loss: 2630.15
[INFO 2017-06-26 18:51:55,306 main.py:47] epoch 3324, training loss: 1644.98, average training loss: 1972.58, base loss: 2629.40
[INFO 2017-06-26 18:51:55,614 main.py:47] epoch 3325, training loss: 1857.32, average training loss: 1972.51, base loss: 2629.35
[INFO 2017-06-26 18:51:55,921 main.py:47] epoch 3326, training loss: 2088.54, average training loss: 1972.81, base loss: 2629.68
[INFO 2017-06-26 18:51:56,225 main.py:47] epoch 3327, training loss: 2047.24, average training loss: 1972.88, base loss: 2629.75
[INFO 2017-06-26 18:51:56,531 main.py:47] epoch 3328, training loss: 2174.82, average training loss: 1973.14, base loss: 2630.02
[INFO 2017-06-26 18:51:56,835 main.py:47] epoch 3329, training loss: 1933.12, average training loss: 1973.26, base loss: 2630.47
[INFO 2017-06-26 18:51:57,138 main.py:47] epoch 3330, training loss: 1949.63, average training loss: 1973.12, base loss: 2630.27
[INFO 2017-06-26 18:51:57,442 main.py:47] epoch 3331, training loss: 1868.11, average training loss: 1973.02, base loss: 2630.62
[INFO 2017-06-26 18:51:57,750 main.py:47] epoch 3332, training loss: 1958.97, average training loss: 1972.93, base loss: 2630.30
[INFO 2017-06-26 18:51:58,054 main.py:47] epoch 3333, training loss: 1886.93, average training loss: 1972.84, base loss: 2630.39
[INFO 2017-06-26 18:51:58,359 main.py:47] epoch 3334, training loss: 1846.43, average training loss: 1972.63, base loss: 2630.14
[INFO 2017-06-26 18:51:58,667 main.py:47] epoch 3335, training loss: 1915.05, average training loss: 1972.36, base loss: 2629.55
[INFO 2017-06-26 18:51:58,971 main.py:47] epoch 3336, training loss: 1777.36, average training loss: 1972.17, base loss: 2629.63
[INFO 2017-06-26 18:51:59,274 main.py:47] epoch 3337, training loss: 1889.75, average training loss: 1971.77, base loss: 2629.01
[INFO 2017-06-26 18:51:59,580 main.py:47] epoch 3338, training loss: 1807.82, average training loss: 1971.73, base loss: 2628.96
[INFO 2017-06-26 18:51:59,884 main.py:47] epoch 3339, training loss: 1805.55, average training loss: 1971.60, base loss: 2628.64
[INFO 2017-06-26 18:52:00,190 main.py:47] epoch 3340, training loss: 1956.76, average training loss: 1972.02, base loss: 2628.95
[INFO 2017-06-26 18:52:00,500 main.py:47] epoch 3341, training loss: 2133.97, average training loss: 1971.87, base loss: 2628.93
[INFO 2017-06-26 18:52:00,804 main.py:47] epoch 3342, training loss: 2067.16, average training loss: 1971.85, base loss: 2629.05
[INFO 2017-06-26 18:52:01,107 main.py:47] epoch 3343, training loss: 1948.21, average training loss: 1971.98, base loss: 2629.41
[INFO 2017-06-26 18:52:01,415 main.py:47] epoch 3344, training loss: 2038.54, average training loss: 1972.15, base loss: 2629.96
[INFO 2017-06-26 18:52:01,721 main.py:47] epoch 3345, training loss: 1950.30, average training loss: 1971.65, base loss: 2629.27
[INFO 2017-06-26 18:52:02,027 main.py:47] epoch 3346, training loss: 2207.94, average training loss: 1971.87, base loss: 2629.60
[INFO 2017-06-26 18:52:02,329 main.py:47] epoch 3347, training loss: 1772.41, average training loss: 1971.67, base loss: 2629.38
[INFO 2017-06-26 18:52:02,637 main.py:47] epoch 3348, training loss: 2257.29, average training loss: 1972.17, base loss: 2629.91
[INFO 2017-06-26 18:52:02,944 main.py:47] epoch 3349, training loss: 2110.19, average training loss: 1972.44, base loss: 2630.18
[INFO 2017-06-26 18:52:03,252 main.py:47] epoch 3350, training loss: 2006.20, average training loss: 1972.23, base loss: 2629.67
[INFO 2017-06-26 18:52:03,556 main.py:47] epoch 3351, training loss: 2267.55, average training loss: 1972.60, base loss: 2630.31
[INFO 2017-06-26 18:52:03,863 main.py:47] epoch 3352, training loss: 1833.54, average training loss: 1972.60, base loss: 2630.42
[INFO 2017-06-26 18:52:04,169 main.py:47] epoch 3353, training loss: 1839.82, average training loss: 1972.29, base loss: 2630.21
[INFO 2017-06-26 18:52:04,475 main.py:47] epoch 3354, training loss: 1706.87, average training loss: 1972.04, base loss: 2629.69
[INFO 2017-06-26 18:52:04,780 main.py:47] epoch 3355, training loss: 1783.52, average training loss: 1971.81, base loss: 2629.45
[INFO 2017-06-26 18:52:05,087 main.py:47] epoch 3356, training loss: 1797.23, average training loss: 1971.79, base loss: 2629.45
[INFO 2017-06-26 18:52:05,394 main.py:47] epoch 3357, training loss: 2019.26, average training loss: 1971.80, base loss: 2629.45
[INFO 2017-06-26 18:52:05,698 main.py:47] epoch 3358, training loss: 1601.24, average training loss: 1971.62, base loss: 2629.36
[INFO 2017-06-26 18:52:06,003 main.py:47] epoch 3359, training loss: 1858.83, average training loss: 1971.29, base loss: 2628.82
[INFO 2017-06-26 18:52:06,307 main.py:47] epoch 3360, training loss: 2008.69, average training loss: 1971.66, base loss: 2629.48
[INFO 2017-06-26 18:52:06,613 main.py:47] epoch 3361, training loss: 1830.18, average training loss: 1971.45, base loss: 2629.24
[INFO 2017-06-26 18:52:06,920 main.py:47] epoch 3362, training loss: 2088.98, average training loss: 1971.97, base loss: 2629.85
[INFO 2017-06-26 18:52:07,225 main.py:47] epoch 3363, training loss: 2043.96, average training loss: 1971.91, base loss: 2629.94
[INFO 2017-06-26 18:52:07,537 main.py:47] epoch 3364, training loss: 2043.21, average training loss: 1971.99, base loss: 2630.18
[INFO 2017-06-26 18:52:07,844 main.py:47] epoch 3365, training loss: 1718.12, average training loss: 1971.62, base loss: 2629.38
[INFO 2017-06-26 18:52:08,148 main.py:47] epoch 3366, training loss: 2143.02, average training loss: 1971.64, base loss: 2629.30
[INFO 2017-06-26 18:52:08,452 main.py:47] epoch 3367, training loss: 1918.52, average training loss: 1971.31, base loss: 2629.03
[INFO 2017-06-26 18:52:08,950 main.py:47] epoch 3368, training loss: 1818.80, average training loss: 1971.04, base loss: 2628.57
[INFO 2017-06-26 18:52:09,254 main.py:47] epoch 3369, training loss: 1892.81, average training loss: 1971.21, base loss: 2628.88
[INFO 2017-06-26 18:52:09,557 main.py:47] epoch 3370, training loss: 1779.30, average training loss: 1971.07, base loss: 2628.70
[INFO 2017-06-26 18:52:09,861 main.py:47] epoch 3371, training loss: 1675.14, average training loss: 1970.59, base loss: 2628.12
[INFO 2017-06-26 18:52:10,165 main.py:47] epoch 3372, training loss: 1978.67, average training loss: 1970.33, base loss: 2627.71
[INFO 2017-06-26 18:52:10,468 main.py:47] epoch 3373, training loss: 1901.14, average training loss: 1970.33, base loss: 2627.73
[INFO 2017-06-26 18:52:10,772 main.py:47] epoch 3374, training loss: 2028.15, average training loss: 1970.44, base loss: 2627.82
[INFO 2017-06-26 18:52:11,077 main.py:47] epoch 3375, training loss: 1917.69, average training loss: 1970.08, base loss: 2627.23
[INFO 2017-06-26 18:52:11,380 main.py:47] epoch 3376, training loss: 1926.00, average training loss: 1969.47, base loss: 2626.35
[INFO 2017-06-26 18:52:11,689 main.py:47] epoch 3377, training loss: 2173.70, average training loss: 1969.48, base loss: 2626.17
[INFO 2017-06-26 18:52:11,996 main.py:47] epoch 3378, training loss: 1746.82, average training loss: 1969.19, base loss: 2625.72
[INFO 2017-06-26 18:52:12,300 main.py:47] epoch 3379, training loss: 2005.15, average training loss: 1969.11, base loss: 2625.98
[INFO 2017-06-26 18:52:12,608 main.py:47] epoch 3380, training loss: 2095.98, average training loss: 1969.05, base loss: 2625.95
[INFO 2017-06-26 18:52:12,915 main.py:47] epoch 3381, training loss: 1798.03, average training loss: 1968.87, base loss: 2625.55
[INFO 2017-06-26 18:52:13,219 main.py:47] epoch 3382, training loss: 1895.59, average training loss: 1968.60, base loss: 2625.41
[INFO 2017-06-26 18:52:13,523 main.py:47] epoch 3383, training loss: 2326.20, average training loss: 1969.12, base loss: 2626.15
[INFO 2017-06-26 18:52:13,830 main.py:47] epoch 3384, training loss: 1873.15, average training loss: 1969.02, base loss: 2626.09
[INFO 2017-06-26 18:52:14,135 main.py:47] epoch 3385, training loss: 1587.41, average training loss: 1968.52, base loss: 2625.47
[INFO 2017-06-26 18:52:14,438 main.py:47] epoch 3386, training loss: 2177.09, average training loss: 1968.59, base loss: 2625.59
[INFO 2017-06-26 18:52:14,743 main.py:47] epoch 3387, training loss: 1840.31, average training loss: 1968.58, base loss: 2625.78
[INFO 2017-06-26 18:52:15,047 main.py:47] epoch 3388, training loss: 1997.69, average training loss: 1968.68, base loss: 2625.93
[INFO 2017-06-26 18:52:15,353 main.py:47] epoch 3389, training loss: 2196.23, average training loss: 1968.65, base loss: 2625.80
[INFO 2017-06-26 18:52:15,660 main.py:47] epoch 3390, training loss: 1870.36, average training loss: 1968.46, base loss: 2625.59
[INFO 2017-06-26 18:52:15,966 main.py:47] epoch 3391, training loss: 1988.85, average training loss: 1968.34, base loss: 2625.29
[INFO 2017-06-26 18:52:16,267 main.py:47] epoch 3392, training loss: 1930.32, average training loss: 1968.28, base loss: 2625.47
[INFO 2017-06-26 18:52:16,574 main.py:47] epoch 3393, training loss: 1767.73, average training loss: 1968.04, base loss: 2625.09
[INFO 2017-06-26 18:52:16,878 main.py:47] epoch 3394, training loss: 1979.02, average training loss: 1968.11, base loss: 2624.99
[INFO 2017-06-26 18:52:17,183 main.py:47] epoch 3395, training loss: 1848.44, average training loss: 1968.29, base loss: 2625.44
[INFO 2017-06-26 18:52:17,490 main.py:47] epoch 3396, training loss: 1851.86, average training loss: 1968.26, base loss: 2625.40
[INFO 2017-06-26 18:52:17,799 main.py:47] epoch 3397, training loss: 1956.49, average training loss: 1968.30, base loss: 2625.67
[INFO 2017-06-26 18:52:18,104 main.py:47] epoch 3398, training loss: 1733.44, average training loss: 1967.77, base loss: 2624.91
[INFO 2017-06-26 18:52:18,411 main.py:47] epoch 3399, training loss: 2077.75, average training loss: 1967.79, base loss: 2624.93
[INFO 2017-06-26 18:52:18,411 main.py:49] epoch 3399, testing
[INFO 2017-06-26 18:52:22,381 main.py:100] average testing loss: 1908.23, base loss: 2562.10
[INFO 2017-06-26 18:52:22,405 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:52:22,713 main.py:47] epoch 3400, training loss: 2262.08, average training loss: 1968.11, base loss: 2625.50
[INFO 2017-06-26 18:52:23,020 main.py:47] epoch 3401, training loss: 2228.48, average training loss: 1968.11, base loss: 2625.57
[INFO 2017-06-26 18:52:23,324 main.py:47] epoch 3402, training loss: 2026.16, average training loss: 1968.35, base loss: 2625.91
[INFO 2017-06-26 18:52:23,636 main.py:47] epoch 3403, training loss: 2095.54, average training loss: 1968.26, base loss: 2625.82
[INFO 2017-06-26 18:52:23,942 main.py:47] epoch 3404, training loss: 2047.17, average training loss: 1968.26, base loss: 2625.84
[INFO 2017-06-26 18:52:24,249 main.py:47] epoch 3405, training loss: 1924.13, average training loss: 1968.35, base loss: 2626.16
[INFO 2017-06-26 18:52:24,567 main.py:47] epoch 3406, training loss: 2083.65, average training loss: 1968.26, base loss: 2625.97
[INFO 2017-06-26 18:52:24,872 main.py:47] epoch 3407, training loss: 2045.42, average training loss: 1968.44, base loss: 2626.18
[INFO 2017-06-26 18:52:25,177 main.py:47] epoch 3408, training loss: 2074.29, average training loss: 1968.68, base loss: 2626.65
[INFO 2017-06-26 18:52:25,482 main.py:47] epoch 3409, training loss: 1858.88, average training loss: 1968.43, base loss: 2626.15
[INFO 2017-06-26 18:52:25,786 main.py:47] epoch 3410, training loss: 1773.01, average training loss: 1968.15, base loss: 2625.69
[INFO 2017-06-26 18:52:26,092 main.py:47] epoch 3411, training loss: 2024.06, average training loss: 1968.36, base loss: 2626.11
[INFO 2017-06-26 18:52:26,394 main.py:47] epoch 3412, training loss: 1943.57, average training loss: 1968.39, base loss: 2626.21
[INFO 2017-06-26 18:52:26,699 main.py:47] epoch 3413, training loss: 2015.42, average training loss: 1968.47, base loss: 2626.31
[INFO 2017-06-26 18:52:27,003 main.py:47] epoch 3414, training loss: 2021.77, average training loss: 1968.36, base loss: 2626.27
[INFO 2017-06-26 18:52:27,306 main.py:47] epoch 3415, training loss: 1720.43, average training loss: 1968.19, base loss: 2626.01
[INFO 2017-06-26 18:52:27,613 main.py:47] epoch 3416, training loss: 1923.85, average training loss: 1968.37, base loss: 2626.26
[INFO 2017-06-26 18:52:27,922 main.py:47] epoch 3417, training loss: 2225.04, average training loss: 1968.58, base loss: 2626.49
[INFO 2017-06-26 18:52:28,227 main.py:47] epoch 3418, training loss: 2626.64, average training loss: 1969.17, base loss: 2627.26
[INFO 2017-06-26 18:52:28,533 main.py:47] epoch 3419, training loss: 1909.12, average training loss: 1969.14, base loss: 2627.42
[INFO 2017-06-26 18:52:28,839 main.py:47] epoch 3420, training loss: 1746.36, average training loss: 1968.95, base loss: 2627.08
[INFO 2017-06-26 18:52:29,145 main.py:47] epoch 3421, training loss: 2123.25, average training loss: 1968.99, base loss: 2627.39
[INFO 2017-06-26 18:52:29,449 main.py:47] epoch 3422, training loss: 2073.33, average training loss: 1968.95, base loss: 2627.38
[INFO 2017-06-26 18:52:29,761 main.py:47] epoch 3423, training loss: 1852.36, average training loss: 1968.82, base loss: 2627.27
[INFO 2017-06-26 18:52:30,094 main.py:47] epoch 3424, training loss: 1716.21, average training loss: 1968.30, base loss: 2626.86
[INFO 2017-06-26 18:52:30,399 main.py:47] epoch 3425, training loss: 1881.35, average training loss: 1967.96, base loss: 2626.30
[INFO 2017-06-26 18:52:30,708 main.py:47] epoch 3426, training loss: 1966.28, average training loss: 1968.05, base loss: 2626.52
[INFO 2017-06-26 18:52:31,014 main.py:47] epoch 3427, training loss: 2115.96, average training loss: 1968.51, base loss: 2627.09
[INFO 2017-06-26 18:52:31,322 main.py:47] epoch 3428, training loss: 1781.71, average training loss: 1967.98, base loss: 2626.44
[INFO 2017-06-26 18:52:31,628 main.py:47] epoch 3429, training loss: 1960.80, average training loss: 1967.99, base loss: 2626.62
[INFO 2017-06-26 18:52:31,930 main.py:47] epoch 3430, training loss: 2072.99, average training loss: 1967.98, base loss: 2626.63
[INFO 2017-06-26 18:52:32,237 main.py:47] epoch 3431, training loss: 1716.23, average training loss: 1967.86, base loss: 2626.56
[INFO 2017-06-26 18:52:32,541 main.py:47] epoch 3432, training loss: 1881.01, average training loss: 1967.75, base loss: 2626.61
[INFO 2017-06-26 18:52:32,845 main.py:47] epoch 3433, training loss: 2070.88, average training loss: 1968.10, base loss: 2627.27
[INFO 2017-06-26 18:52:33,151 main.py:47] epoch 3434, training loss: 1738.94, average training loss: 1967.94, base loss: 2627.12
[INFO 2017-06-26 18:52:33,463 main.py:47] epoch 3435, training loss: 1984.92, average training loss: 1968.16, base loss: 2627.10
[INFO 2017-06-26 18:52:33,765 main.py:47] epoch 3436, training loss: 2202.02, average training loss: 1968.43, base loss: 2627.37
[INFO 2017-06-26 18:52:34,069 main.py:47] epoch 3437, training loss: 2153.45, average training loss: 1968.66, base loss: 2627.49
[INFO 2017-06-26 18:52:34,375 main.py:47] epoch 3438, training loss: 1815.03, average training loss: 1968.78, base loss: 2627.79
[INFO 2017-06-26 18:52:34,683 main.py:47] epoch 3439, training loss: 2301.28, average training loss: 1968.80, base loss: 2627.86
[INFO 2017-06-26 18:52:34,988 main.py:47] epoch 3440, training loss: 2196.19, average training loss: 1969.22, base loss: 2628.72
[INFO 2017-06-26 18:52:35,293 main.py:47] epoch 3441, training loss: 1769.29, average training loss: 1968.49, base loss: 2627.79
[INFO 2017-06-26 18:52:35,599 main.py:47] epoch 3442, training loss: 1932.39, average training loss: 1968.44, base loss: 2627.59
[INFO 2017-06-26 18:52:35,905 main.py:47] epoch 3443, training loss: 1856.61, average training loss: 1968.39, base loss: 2627.41
[INFO 2017-06-26 18:52:36,208 main.py:47] epoch 3444, training loss: 1985.08, average training loss: 1968.41, base loss: 2627.43
[INFO 2017-06-26 18:52:36,513 main.py:47] epoch 3445, training loss: 1828.57, average training loss: 1968.05, base loss: 2627.07
[INFO 2017-06-26 18:52:36,818 main.py:47] epoch 3446, training loss: 2171.75, average training loss: 1968.29, base loss: 2627.29
[INFO 2017-06-26 18:52:37,123 main.py:47] epoch 3447, training loss: 2087.03, average training loss: 1968.05, base loss: 2626.85
[INFO 2017-06-26 18:52:37,431 main.py:47] epoch 3448, training loss: 1955.17, average training loss: 1968.23, base loss: 2627.15
[INFO 2017-06-26 18:52:37,738 main.py:47] epoch 3449, training loss: 1876.51, average training loss: 1968.04, base loss: 2626.74
[INFO 2017-06-26 18:52:38,044 main.py:47] epoch 3450, training loss: 2050.82, average training loss: 1967.97, base loss: 2626.83
[INFO 2017-06-26 18:52:38,350 main.py:47] epoch 3451, training loss: 2211.44, average training loss: 1968.22, base loss: 2627.17
[INFO 2017-06-26 18:52:38,657 main.py:47] epoch 3452, training loss: 2190.61, average training loss: 1968.04, base loss: 2626.87
[INFO 2017-06-26 18:52:38,964 main.py:47] epoch 3453, training loss: 2041.35, average training loss: 1968.04, base loss: 2626.89
[INFO 2017-06-26 18:52:39,273 main.py:47] epoch 3454, training loss: 1780.83, average training loss: 1967.92, base loss: 2626.66
[INFO 2017-06-26 18:52:39,581 main.py:47] epoch 3455, training loss: 1825.46, average training loss: 1967.88, base loss: 2626.73
[INFO 2017-06-26 18:52:39,891 main.py:47] epoch 3456, training loss: 1897.10, average training loss: 1967.95, base loss: 2626.72
[INFO 2017-06-26 18:52:40,199 main.py:47] epoch 3457, training loss: 1712.98, average training loss: 1967.64, base loss: 2626.15
[INFO 2017-06-26 18:52:40,507 main.py:47] epoch 3458, training loss: 1777.57, average training loss: 1967.45, base loss: 2625.90
[INFO 2017-06-26 18:52:40,815 main.py:47] epoch 3459, training loss: 1890.52, average training loss: 1967.38, base loss: 2625.64
[INFO 2017-06-26 18:52:41,123 main.py:47] epoch 3460, training loss: 1707.62, average training loss: 1967.26, base loss: 2625.50
[INFO 2017-06-26 18:52:41,429 main.py:47] epoch 3461, training loss: 1775.81, average training loss: 1966.71, base loss: 2624.75
[INFO 2017-06-26 18:52:41,735 main.py:47] epoch 3462, training loss: 2177.40, average training loss: 1966.99, base loss: 2625.18
[INFO 2017-06-26 18:52:42,077 main.py:47] epoch 3463, training loss: 2096.52, average training loss: 1967.30, base loss: 2625.40
[INFO 2017-06-26 18:52:42,414 main.py:47] epoch 3464, training loss: 1997.60, average training loss: 1967.26, base loss: 2625.26
[INFO 2017-06-26 18:52:42,728 main.py:47] epoch 3465, training loss: 2013.96, average training loss: 1967.34, base loss: 2625.33
[INFO 2017-06-26 18:52:43,036 main.py:47] epoch 3466, training loss: 2158.69, average training loss: 1967.44, base loss: 2625.57
[INFO 2017-06-26 18:52:43,344 main.py:47] epoch 3467, training loss: 1873.21, average training loss: 1967.45, base loss: 2625.65
[INFO 2017-06-26 18:52:43,651 main.py:47] epoch 3468, training loss: 1763.09, average training loss: 1967.00, base loss: 2625.31
[INFO 2017-06-26 18:52:43,969 main.py:47] epoch 3469, training loss: 1932.40, average training loss: 1967.00, base loss: 2625.40
[INFO 2017-06-26 18:52:44,276 main.py:47] epoch 3470, training loss: 1861.82, average training loss: 1966.72, base loss: 2625.12
[INFO 2017-06-26 18:52:44,579 main.py:47] epoch 3471, training loss: 2048.44, average training loss: 1966.84, base loss: 2625.33
[INFO 2017-06-26 18:52:44,888 main.py:47] epoch 3472, training loss: 2082.53, average training loss: 1966.96, base loss: 2625.30
[INFO 2017-06-26 18:52:45,191 main.py:47] epoch 3473, training loss: 2076.93, average training loss: 1967.07, base loss: 2625.59
[INFO 2017-06-26 18:52:45,497 main.py:47] epoch 3474, training loss: 2139.52, average training loss: 1967.23, base loss: 2625.92
[INFO 2017-06-26 18:52:45,804 main.py:47] epoch 3475, training loss: 1908.41, average training loss: 1967.24, base loss: 2625.83
[INFO 2017-06-26 18:52:46,110 main.py:47] epoch 3476, training loss: 1837.77, average training loss: 1967.27, base loss: 2625.95
[INFO 2017-06-26 18:52:46,417 main.py:47] epoch 3477, training loss: 1773.29, average training loss: 1967.18, base loss: 2625.80
[INFO 2017-06-26 18:52:46,724 main.py:47] epoch 3478, training loss: 2041.73, average training loss: 1967.44, base loss: 2626.24
[INFO 2017-06-26 18:52:47,030 main.py:47] epoch 3479, training loss: 1891.17, average training loss: 1967.29, base loss: 2625.96
[INFO 2017-06-26 18:52:47,335 main.py:47] epoch 3480, training loss: 1954.99, average training loss: 1967.03, base loss: 2625.79
[INFO 2017-06-26 18:52:47,642 main.py:47] epoch 3481, training loss: 1909.00, average training loss: 1967.15, base loss: 2626.02
[INFO 2017-06-26 18:52:47,948 main.py:47] epoch 3482, training loss: 2193.29, average training loss: 1967.12, base loss: 2626.15
[INFO 2017-06-26 18:52:48,255 main.py:47] epoch 3483, training loss: 1872.25, average training loss: 1967.08, base loss: 2626.20
[INFO 2017-06-26 18:52:48,563 main.py:47] epoch 3484, training loss: 1902.04, average training loss: 1966.74, base loss: 2625.54
[INFO 2017-06-26 18:52:48,869 main.py:47] epoch 3485, training loss: 2323.54, average training loss: 1966.82, base loss: 2625.50
[INFO 2017-06-26 18:52:49,177 main.py:47] epoch 3486, training loss: 2321.89, average training loss: 1967.11, base loss: 2625.88
[INFO 2017-06-26 18:52:49,484 main.py:47] epoch 3487, training loss: 1955.63, average training loss: 1967.19, base loss: 2626.00
[INFO 2017-06-26 18:52:49,790 main.py:47] epoch 3488, training loss: 2179.19, average training loss: 1967.62, base loss: 2626.66
[INFO 2017-06-26 18:52:50,099 main.py:47] epoch 3489, training loss: 2308.12, average training loss: 1968.21, base loss: 2627.60
[INFO 2017-06-26 18:52:50,406 main.py:47] epoch 3490, training loss: 1798.23, average training loss: 1968.06, base loss: 2627.28
[INFO 2017-06-26 18:52:50,713 main.py:47] epoch 3491, training loss: 1904.87, average training loss: 1968.16, base loss: 2627.47
[INFO 2017-06-26 18:52:51,019 main.py:47] epoch 3492, training loss: 1755.99, average training loss: 1967.97, base loss: 2627.08
[INFO 2017-06-26 18:52:51,326 main.py:47] epoch 3493, training loss: 2189.63, average training loss: 1968.43, base loss: 2627.62
[INFO 2017-06-26 18:52:51,632 main.py:47] epoch 3494, training loss: 1883.83, average training loss: 1968.10, base loss: 2627.07
[INFO 2017-06-26 18:52:51,936 main.py:47] epoch 3495, training loss: 2000.79, average training loss: 1968.12, base loss: 2627.35
[INFO 2017-06-26 18:52:52,243 main.py:47] epoch 3496, training loss: 1892.53, average training loss: 1967.81, base loss: 2627.12
[INFO 2017-06-26 18:52:52,548 main.py:47] epoch 3497, training loss: 1909.15, average training loss: 1967.66, base loss: 2627.19
[INFO 2017-06-26 18:52:52,855 main.py:47] epoch 3498, training loss: 1781.55, average training loss: 1967.47, base loss: 2627.00
[INFO 2017-06-26 18:52:53,162 main.py:47] epoch 3499, training loss: 1811.13, average training loss: 1967.52, base loss: 2627.07
[INFO 2017-06-26 18:52:53,162 main.py:49] epoch 3499, testing
[INFO 2017-06-26 18:52:57,181 main.py:100] average testing loss: 1958.50, base loss: 2674.30
[INFO 2017-06-26 18:52:57,204 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:52:57,514 main.py:47] epoch 3500, training loss: 1980.56, average training loss: 1967.42, base loss: 2626.84
[INFO 2017-06-26 18:52:57,822 main.py:47] epoch 3501, training loss: 1984.51, average training loss: 1966.93, base loss: 2626.20
[INFO 2017-06-26 18:52:58,129 main.py:47] epoch 3502, training loss: 1865.29, average training loss: 1966.85, base loss: 2626.13
[INFO 2017-06-26 18:52:58,435 main.py:47] epoch 3503, training loss: 1890.02, average training loss: 1966.71, base loss: 2626.01
[INFO 2017-06-26 18:52:58,742 main.py:47] epoch 3504, training loss: 1785.70, average training loss: 1966.49, base loss: 2625.65
[INFO 2017-06-26 18:52:59,047 main.py:47] epoch 3505, training loss: 2255.55, average training loss: 1966.84, base loss: 2626.04
[INFO 2017-06-26 18:52:59,356 main.py:47] epoch 3506, training loss: 2134.13, average training loss: 1966.93, base loss: 2626.23
[INFO 2017-06-26 18:52:59,663 main.py:47] epoch 3507, training loss: 1665.01, average training loss: 1966.30, base loss: 2625.40
[INFO 2017-06-26 18:52:59,969 main.py:47] epoch 3508, training loss: 1916.02, average training loss: 1966.11, base loss: 2625.15
[INFO 2017-06-26 18:53:00,275 main.py:47] epoch 3509, training loss: 1883.99, average training loss: 1966.07, base loss: 2625.22
[INFO 2017-06-26 18:53:00,584 main.py:47] epoch 3510, training loss: 2100.40, average training loss: 1966.14, base loss: 2625.56
[INFO 2017-06-26 18:53:00,890 main.py:47] epoch 3511, training loss: 2066.38, average training loss: 1966.12, base loss: 2625.18
[INFO 2017-06-26 18:53:01,196 main.py:47] epoch 3512, training loss: 2021.70, average training loss: 1966.14, base loss: 2625.26
[INFO 2017-06-26 18:53:01,502 main.py:47] epoch 3513, training loss: 1804.65, average training loss: 1965.85, base loss: 2624.86
[INFO 2017-06-26 18:53:01,808 main.py:47] epoch 3514, training loss: 2011.17, average training loss: 1965.69, base loss: 2624.65
[INFO 2017-06-26 18:53:02,114 main.py:47] epoch 3515, training loss: 1868.32, average training loss: 1965.46, base loss: 2624.42
[INFO 2017-06-26 18:53:02,423 main.py:47] epoch 3516, training loss: 1966.75, average training loss: 1965.60, base loss: 2624.76
[INFO 2017-06-26 18:53:02,730 main.py:47] epoch 3517, training loss: 2312.07, average training loss: 1965.77, base loss: 2625.27
[INFO 2017-06-26 18:53:03,031 main.py:47] epoch 3518, training loss: 1915.57, average training loss: 1965.80, base loss: 2625.54
[INFO 2017-06-26 18:53:03,339 main.py:47] epoch 3519, training loss: 2098.95, average training loss: 1966.10, base loss: 2626.05
[INFO 2017-06-26 18:53:03,645 main.py:47] epoch 3520, training loss: 1756.33, average training loss: 1966.13, base loss: 2626.24
[INFO 2017-06-26 18:53:03,952 main.py:47] epoch 3521, training loss: 1870.04, average training loss: 1966.03, base loss: 2626.08
[INFO 2017-06-26 18:53:04,260 main.py:47] epoch 3522, training loss: 1666.39, average training loss: 1965.57, base loss: 2625.49
[INFO 2017-06-26 18:53:04,567 main.py:47] epoch 3523, training loss: 2058.60, average training loss: 1965.41, base loss: 2625.52
[INFO 2017-06-26 18:53:04,875 main.py:47] epoch 3524, training loss: 1815.22, average training loss: 1965.29, base loss: 2625.60
[INFO 2017-06-26 18:53:05,183 main.py:47] epoch 3525, training loss: 1806.42, average training loss: 1965.26, base loss: 2625.84
[INFO 2017-06-26 18:53:05,489 main.py:47] epoch 3526, training loss: 1816.28, average training loss: 1965.34, base loss: 2626.04
[INFO 2017-06-26 18:53:05,796 main.py:47] epoch 3527, training loss: 1944.70, average training loss: 1965.35, base loss: 2626.21
[INFO 2017-06-26 18:53:06,103 main.py:47] epoch 3528, training loss: 1939.68, average training loss: 1965.66, base loss: 2626.70
[INFO 2017-06-26 18:53:06,409 main.py:47] epoch 3529, training loss: 1771.19, average training loss: 1965.62, base loss: 2626.78
[INFO 2017-06-26 18:53:06,712 main.py:47] epoch 3530, training loss: 1825.43, average training loss: 1965.80, base loss: 2627.01
[INFO 2017-06-26 18:53:07,020 main.py:47] epoch 3531, training loss: 1715.73, average training loss: 1965.15, base loss: 2626.21
[INFO 2017-06-26 18:53:07,328 main.py:47] epoch 3532, training loss: 1872.40, average training loss: 1964.84, base loss: 2625.91
[INFO 2017-06-26 18:53:07,635 main.py:47] epoch 3533, training loss: 2032.23, average training loss: 1965.17, base loss: 2626.51
[INFO 2017-06-26 18:53:07,942 main.py:47] epoch 3534, training loss: 2098.62, average training loss: 1965.13, base loss: 2626.40
[INFO 2017-06-26 18:53:08,246 main.py:47] epoch 3535, training loss: 2103.16, average training loss: 1964.90, base loss: 2625.95
[INFO 2017-06-26 18:53:08,553 main.py:47] epoch 3536, training loss: 1942.91, average training loss: 1964.75, base loss: 2625.63
[INFO 2017-06-26 18:53:08,861 main.py:47] epoch 3537, training loss: 1932.20, average training loss: 1964.62, base loss: 2625.32
[INFO 2017-06-26 18:53:09,170 main.py:47] epoch 3538, training loss: 2075.90, average training loss: 1964.93, base loss: 2625.77
[INFO 2017-06-26 18:53:09,477 main.py:47] epoch 3539, training loss: 2316.79, average training loss: 1964.69, base loss: 2625.64
[INFO 2017-06-26 18:53:09,780 main.py:47] epoch 3540, training loss: 1907.76, average training loss: 1964.37, base loss: 2625.14
[INFO 2017-06-26 18:53:10,085 main.py:47] epoch 3541, training loss: 2288.26, average training loss: 1964.61, base loss: 2625.54
[INFO 2017-06-26 18:53:10,395 main.py:47] epoch 3542, training loss: 1915.18, average training loss: 1964.61, base loss: 2625.46
[INFO 2017-06-26 18:53:10,702 main.py:47] epoch 3543, training loss: 1771.60, average training loss: 1963.90, base loss: 2624.39
[INFO 2017-06-26 18:53:11,008 main.py:47] epoch 3544, training loss: 1859.13, average training loss: 1963.91, base loss: 2624.55
[INFO 2017-06-26 18:53:11,315 main.py:47] epoch 3545, training loss: 2328.74, average training loss: 1964.25, base loss: 2625.04
[INFO 2017-06-26 18:53:11,621 main.py:47] epoch 3546, training loss: 1738.27, average training loss: 1964.01, base loss: 2624.78
[INFO 2017-06-26 18:53:11,928 main.py:47] epoch 3547, training loss: 1979.35, average training loss: 1964.17, base loss: 2624.97
[INFO 2017-06-26 18:53:12,234 main.py:47] epoch 3548, training loss: 1907.13, average training loss: 1964.29, base loss: 2625.13
[INFO 2017-06-26 18:53:12,541 main.py:47] epoch 3549, training loss: 1849.26, average training loss: 1964.01, base loss: 2624.92
[INFO 2017-06-26 18:53:12,848 main.py:47] epoch 3550, training loss: 1727.46, average training loss: 1963.63, base loss: 2624.43
[INFO 2017-06-26 18:53:13,156 main.py:47] epoch 3551, training loss: 1915.08, average training loss: 1963.51, base loss: 2624.22
[INFO 2017-06-26 18:53:13,460 main.py:47] epoch 3552, training loss: 1791.34, average training loss: 1963.04, base loss: 2623.82
[INFO 2017-06-26 18:53:13,765 main.py:47] epoch 3553, training loss: 2378.37, average training loss: 1963.49, base loss: 2624.21
[INFO 2017-06-26 18:53:14,072 main.py:47] epoch 3554, training loss: 1983.12, average training loss: 1963.58, base loss: 2624.39
[INFO 2017-06-26 18:53:14,378 main.py:47] epoch 3555, training loss: 1991.56, average training loss: 1963.62, base loss: 2624.47
[INFO 2017-06-26 18:53:14,686 main.py:47] epoch 3556, training loss: 2148.78, average training loss: 1963.92, base loss: 2625.05
[INFO 2017-06-26 18:53:14,992 main.py:47] epoch 3557, training loss: 1666.26, average training loss: 1963.76, base loss: 2624.88
[INFO 2017-06-26 18:53:15,302 main.py:47] epoch 3558, training loss: 1809.51, average training loss: 1963.86, base loss: 2624.86
[INFO 2017-06-26 18:53:15,605 main.py:47] epoch 3559, training loss: 2052.51, average training loss: 1963.96, base loss: 2625.26
[INFO 2017-06-26 18:53:15,913 main.py:47] epoch 3560, training loss: 1962.57, average training loss: 1964.12, base loss: 2625.69
[INFO 2017-06-26 18:53:16,219 main.py:47] epoch 3561, training loss: 1743.45, average training loss: 1963.88, base loss: 2625.48
[INFO 2017-06-26 18:53:16,526 main.py:47] epoch 3562, training loss: 1848.72, average training loss: 1963.78, base loss: 2625.34
[INFO 2017-06-26 18:53:16,835 main.py:47] epoch 3563, training loss: 2064.96, average training loss: 1963.89, base loss: 2625.38
[INFO 2017-06-26 18:53:17,141 main.py:47] epoch 3564, training loss: 1871.87, average training loss: 1963.84, base loss: 2625.31
[INFO 2017-06-26 18:53:17,450 main.py:47] epoch 3565, training loss: 2031.26, average training loss: 1963.87, base loss: 2625.07
[INFO 2017-06-26 18:53:17,759 main.py:47] epoch 3566, training loss: 1899.23, average training loss: 1964.00, base loss: 2625.18
[INFO 2017-06-26 18:53:18,066 main.py:47] epoch 3567, training loss: 1935.22, average training loss: 1963.84, base loss: 2624.88
[INFO 2017-06-26 18:53:18,373 main.py:47] epoch 3568, training loss: 2039.37, average training loss: 1963.82, base loss: 2624.75
[INFO 2017-06-26 18:53:18,678 main.py:47] epoch 3569, training loss: 2052.77, average training loss: 1964.21, base loss: 2625.38
[INFO 2017-06-26 18:53:18,985 main.py:47] epoch 3570, training loss: 2221.76, average training loss: 1964.42, base loss: 2625.73
[INFO 2017-06-26 18:53:19,290 main.py:47] epoch 3571, training loss: 1962.07, average training loss: 1964.54, base loss: 2625.97
[INFO 2017-06-26 18:53:19,596 main.py:47] epoch 3572, training loss: 1898.01, average training loss: 1964.57, base loss: 2625.76
[INFO 2017-06-26 18:53:19,903 main.py:47] epoch 3573, training loss: 2022.39, average training loss: 1964.44, base loss: 2625.61
[INFO 2017-06-26 18:53:20,211 main.py:47] epoch 3574, training loss: 2081.20, average training loss: 1964.65, base loss: 2625.79
[INFO 2017-06-26 18:53:20,518 main.py:47] epoch 3575, training loss: 1997.97, average training loss: 1964.26, base loss: 2625.26
[INFO 2017-06-26 18:53:20,825 main.py:47] epoch 3576, training loss: 2126.65, average training loss: 1964.25, base loss: 2625.48
[INFO 2017-06-26 18:53:21,132 main.py:47] epoch 3577, training loss: 1987.76, average training loss: 1964.35, base loss: 2625.80
[INFO 2017-06-26 18:53:21,441 main.py:47] epoch 3578, training loss: 1474.49, average training loss: 1964.06, base loss: 2625.41
[INFO 2017-06-26 18:53:21,752 main.py:47] epoch 3579, training loss: 1930.39, average training loss: 1963.90, base loss: 2625.26
[INFO 2017-06-26 18:53:22,060 main.py:47] epoch 3580, training loss: 1830.55, average training loss: 1963.50, base loss: 2624.84
[INFO 2017-06-26 18:53:22,367 main.py:47] epoch 3581, training loss: 2213.38, average training loss: 1964.02, base loss: 2625.65
[INFO 2017-06-26 18:53:22,673 main.py:47] epoch 3582, training loss: 1918.18, average training loss: 1963.96, base loss: 2625.61
[INFO 2017-06-26 18:53:22,980 main.py:47] epoch 3583, training loss: 2163.50, average training loss: 1963.99, base loss: 2625.95
[INFO 2017-06-26 18:53:23,290 main.py:47] epoch 3584, training loss: 2039.57, average training loss: 1964.44, base loss: 2626.92
[INFO 2017-06-26 18:53:23,598 main.py:47] epoch 3585, training loss: 1902.21, average training loss: 1964.35, base loss: 2626.76
[INFO 2017-06-26 18:53:23,901 main.py:47] epoch 3586, training loss: 1776.21, average training loss: 1963.63, base loss: 2626.03
[INFO 2017-06-26 18:53:24,208 main.py:47] epoch 3587, training loss: 2001.60, average training loss: 1963.78, base loss: 2626.40
[INFO 2017-06-26 18:53:24,514 main.py:47] epoch 3588, training loss: 2131.97, average training loss: 1963.79, base loss: 2626.63
[INFO 2017-06-26 18:53:24,822 main.py:47] epoch 3589, training loss: 2086.25, average training loss: 1963.80, base loss: 2626.63
[INFO 2017-06-26 18:53:25,128 main.py:47] epoch 3590, training loss: 1766.62, average training loss: 1963.79, base loss: 2626.48
[INFO 2017-06-26 18:53:25,434 main.py:47] epoch 3591, training loss: 1675.63, average training loss: 1963.53, base loss: 2626.21
[INFO 2017-06-26 18:53:25,741 main.py:47] epoch 3592, training loss: 1904.43, average training loss: 1963.44, base loss: 2626.07
[INFO 2017-06-26 18:53:26,048 main.py:47] epoch 3593, training loss: 2160.59, average training loss: 1963.95, base loss: 2626.71
[INFO 2017-06-26 18:53:26,355 main.py:47] epoch 3594, training loss: 2167.16, average training loss: 1964.04, base loss: 2627.19
[INFO 2017-06-26 18:53:26,663 main.py:47] epoch 3595, training loss: 2042.21, average training loss: 1964.28, base loss: 2627.72
[INFO 2017-06-26 18:53:26,971 main.py:47] epoch 3596, training loss: 1985.41, average training loss: 1964.15, base loss: 2627.72
[INFO 2017-06-26 18:53:27,280 main.py:47] epoch 3597, training loss: 1931.16, average training loss: 1963.95, base loss: 2627.30
[INFO 2017-06-26 18:53:27,590 main.py:47] epoch 3598, training loss: 1921.25, average training loss: 1963.75, base loss: 2627.00
[INFO 2017-06-26 18:53:27,891 main.py:47] epoch 3599, training loss: 2184.45, average training loss: 1963.79, base loss: 2627.12
[INFO 2017-06-26 18:53:27,891 main.py:49] epoch 3599, testing
[INFO 2017-06-26 18:53:31,878 main.py:100] average testing loss: 2005.58, base loss: 2689.87
[INFO 2017-06-26 18:53:31,903 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:53:32,211 main.py:47] epoch 3600, training loss: 1990.44, average training loss: 1963.95, base loss: 2627.60
[INFO 2017-06-26 18:53:32,518 main.py:47] epoch 3601, training loss: 2128.90, average training loss: 1963.96, base loss: 2627.83
[INFO 2017-06-26 18:53:32,823 main.py:47] epoch 3602, training loss: 2226.64, average training loss: 1963.98, base loss: 2628.02
[INFO 2017-06-26 18:53:33,130 main.py:47] epoch 3603, training loss: 1772.07, average training loss: 1963.72, base loss: 2627.40
[INFO 2017-06-26 18:53:33,437 main.py:47] epoch 3604, training loss: 2125.81, average training loss: 1964.05, base loss: 2628.03
[INFO 2017-06-26 18:53:33,745 main.py:47] epoch 3605, training loss: 1761.08, average training loss: 1963.82, base loss: 2627.87
[INFO 2017-06-26 18:53:34,048 main.py:47] epoch 3606, training loss: 1775.20, average training loss: 1963.83, base loss: 2628.26
[INFO 2017-06-26 18:53:34,356 main.py:47] epoch 3607, training loss: 1819.10, average training loss: 1963.96, base loss: 2628.55
[INFO 2017-06-26 18:53:34,664 main.py:47] epoch 3608, training loss: 1705.46, average training loss: 1963.86, base loss: 2628.54
[INFO 2017-06-26 18:53:34,972 main.py:47] epoch 3609, training loss: 1857.26, average training loss: 1963.61, base loss: 2628.26
[INFO 2017-06-26 18:53:35,275 main.py:47] epoch 3610, training loss: 1891.63, average training loss: 1963.49, base loss: 2628.29
[INFO 2017-06-26 18:53:35,584 main.py:47] epoch 3611, training loss: 1994.75, average training loss: 1963.43, base loss: 2628.29
[INFO 2017-06-26 18:53:35,894 main.py:47] epoch 3612, training loss: 1581.17, average training loss: 1963.17, base loss: 2627.87
[INFO 2017-06-26 18:53:36,200 main.py:47] epoch 3613, training loss: 2068.82, average training loss: 1963.39, base loss: 2628.30
[INFO 2017-06-26 18:53:36,507 main.py:47] epoch 3614, training loss: 1788.43, average training loss: 1963.05, base loss: 2627.87
[INFO 2017-06-26 18:53:36,814 main.py:47] epoch 3615, training loss: 1839.14, average training loss: 1962.84, base loss: 2627.61
[INFO 2017-06-26 18:53:37,120 main.py:47] epoch 3616, training loss: 1904.44, average training loss: 1962.91, base loss: 2627.73
[INFO 2017-06-26 18:53:37,428 main.py:47] epoch 3617, training loss: 2134.82, average training loss: 1963.09, base loss: 2628.01
[INFO 2017-06-26 18:53:37,737 main.py:47] epoch 3618, training loss: 1650.43, average training loss: 1962.80, base loss: 2627.59
[INFO 2017-06-26 18:53:38,047 main.py:47] epoch 3619, training loss: 1881.14, average training loss: 1962.82, base loss: 2627.74
[INFO 2017-06-26 18:53:38,354 main.py:47] epoch 3620, training loss: 1986.90, average training loss: 1962.76, base loss: 2627.85
[INFO 2017-06-26 18:53:38,661 main.py:47] epoch 3621, training loss: 1982.07, average training loss: 1962.72, base loss: 2627.84
[INFO 2017-06-26 18:53:38,969 main.py:47] epoch 3622, training loss: 2051.43, average training loss: 1962.91, base loss: 2628.47
[INFO 2017-06-26 18:53:39,277 main.py:47] epoch 3623, training loss: 2446.87, average training loss: 1963.47, base loss: 2629.58
[INFO 2017-06-26 18:53:39,586 main.py:47] epoch 3624, training loss: 1990.18, average training loss: 1963.38, base loss: 2629.47
[INFO 2017-06-26 18:53:39,893 main.py:47] epoch 3625, training loss: 1622.98, average training loss: 1962.80, base loss: 2628.71
[INFO 2017-06-26 18:53:40,202 main.py:47] epoch 3626, training loss: 1920.60, average training loss: 1962.85, base loss: 2628.97
[INFO 2017-06-26 18:53:40,509 main.py:47] epoch 3627, training loss: 1890.71, average training loss: 1962.78, base loss: 2629.05
[INFO 2017-06-26 18:53:40,814 main.py:47] epoch 3628, training loss: 2010.91, average training loss: 1962.79, base loss: 2629.06
[INFO 2017-06-26 18:53:41,123 main.py:47] epoch 3629, training loss: 2076.59, average training loss: 1962.80, base loss: 2629.17
[INFO 2017-06-26 18:53:41,429 main.py:47] epoch 3630, training loss: 1806.18, average training loss: 1962.68, base loss: 2629.10
[INFO 2017-06-26 18:53:41,736 main.py:47] epoch 3631, training loss: 1953.29, average training loss: 1962.98, base loss: 2629.77
[INFO 2017-06-26 18:53:42,044 main.py:47] epoch 3632, training loss: 2379.42, average training loss: 1963.30, base loss: 2630.28
[INFO 2017-06-26 18:53:42,353 main.py:47] epoch 3633, training loss: 1788.05, average training loss: 1963.09, base loss: 2630.00
[INFO 2017-06-26 18:53:42,659 main.py:47] epoch 3634, training loss: 1626.12, average training loss: 1962.74, base loss: 2629.63
[INFO 2017-06-26 18:53:42,967 main.py:47] epoch 3635, training loss: 2088.01, average training loss: 1962.71, base loss: 2629.87
[INFO 2017-06-26 18:53:43,273 main.py:47] epoch 3636, training loss: 2160.36, average training loss: 1962.81, base loss: 2630.20
[INFO 2017-06-26 18:53:43,579 main.py:47] epoch 3637, training loss: 1926.21, average training loss: 1962.31, base loss: 2629.63
[INFO 2017-06-26 18:53:43,886 main.py:47] epoch 3638, training loss: 2019.70, average training loss: 1962.26, base loss: 2629.65
[INFO 2017-06-26 18:53:44,193 main.py:47] epoch 3639, training loss: 1990.43, average training loss: 1962.43, base loss: 2630.34
[INFO 2017-06-26 18:53:44,501 main.py:47] epoch 3640, training loss: 1935.80, average training loss: 1962.26, base loss: 2630.30
[INFO 2017-06-26 18:53:44,810 main.py:47] epoch 3641, training loss: 1920.55, average training loss: 1961.98, base loss: 2630.14
[INFO 2017-06-26 18:53:45,120 main.py:47] epoch 3642, training loss: 1846.27, average training loss: 1962.17, base loss: 2630.38
[INFO 2017-06-26 18:53:45,426 main.py:47] epoch 3643, training loss: 2004.11, average training loss: 1962.12, base loss: 2630.38
[INFO 2017-06-26 18:53:45,734 main.py:47] epoch 3644, training loss: 1784.33, average training loss: 1962.04, base loss: 2630.25
[INFO 2017-06-26 18:53:46,042 main.py:47] epoch 3645, training loss: 1726.66, average training loss: 1962.19, base loss: 2630.51
[INFO 2017-06-26 18:53:46,352 main.py:47] epoch 3646, training loss: 2203.39, average training loss: 1962.28, base loss: 2630.82
[INFO 2017-06-26 18:53:46,660 main.py:47] epoch 3647, training loss: 1750.00, average training loss: 1962.14, base loss: 2630.58
[INFO 2017-06-26 18:53:46,963 main.py:47] epoch 3648, training loss: 1827.69, average training loss: 1961.82, base loss: 2630.24
[INFO 2017-06-26 18:53:47,272 main.py:47] epoch 3649, training loss: 2067.03, average training loss: 1962.03, base loss: 2630.56
[INFO 2017-06-26 18:53:47,577 main.py:47] epoch 3650, training loss: 1908.30, average training loss: 1962.09, base loss: 2630.92
[INFO 2017-06-26 18:53:47,887 main.py:47] epoch 3651, training loss: 1806.10, average training loss: 1961.96, base loss: 2630.59
[INFO 2017-06-26 18:53:48,193 main.py:47] epoch 3652, training loss: 1714.83, average training loss: 1961.67, base loss: 2630.24
[INFO 2017-06-26 18:53:48,500 main.py:47] epoch 3653, training loss: 1875.70, average training loss: 1961.46, base loss: 2630.20
[INFO 2017-06-26 18:53:48,806 main.py:47] epoch 3654, training loss: 2539.36, average training loss: 1962.00, base loss: 2630.67
[INFO 2017-06-26 18:53:49,115 main.py:47] epoch 3655, training loss: 2074.52, average training loss: 1962.38, base loss: 2631.29
[INFO 2017-06-26 18:53:49,420 main.py:47] epoch 3656, training loss: 1775.89, average training loss: 1962.07, base loss: 2630.91
[INFO 2017-06-26 18:53:49,728 main.py:47] epoch 3657, training loss: 1963.13, average training loss: 1961.66, base loss: 2630.49
[INFO 2017-06-26 18:53:50,037 main.py:47] epoch 3658, training loss: 1996.98, average training loss: 1961.80, base loss: 2630.39
[INFO 2017-06-26 18:53:50,344 main.py:47] epoch 3659, training loss: 1875.10, average training loss: 1961.73, base loss: 2630.31
[INFO 2017-06-26 18:53:50,651 main.py:47] epoch 3660, training loss: 2164.94, average training loss: 1961.63, base loss: 2630.22
[INFO 2017-06-26 18:53:50,957 main.py:47] epoch 3661, training loss: 1922.33, average training loss: 1961.52, base loss: 2630.26
[INFO 2017-06-26 18:53:51,265 main.py:47] epoch 3662, training loss: 2229.67, average training loss: 1961.96, base loss: 2630.75
[INFO 2017-06-26 18:53:51,574 main.py:47] epoch 3663, training loss: 1998.69, average training loss: 1961.93, base loss: 2630.70
[INFO 2017-06-26 18:53:51,881 main.py:47] epoch 3664, training loss: 2105.38, average training loss: 1962.02, base loss: 2630.95
[INFO 2017-06-26 18:53:52,186 main.py:47] epoch 3665, training loss: 2091.56, average training loss: 1962.21, base loss: 2631.34
[INFO 2017-06-26 18:53:52,492 main.py:47] epoch 3666, training loss: 1953.64, average training loss: 1962.39, base loss: 2631.51
[INFO 2017-06-26 18:53:52,800 main.py:47] epoch 3667, training loss: 1782.36, average training loss: 1962.12, base loss: 2630.97
[INFO 2017-06-26 18:53:53,106 main.py:47] epoch 3668, training loss: 1903.29, average training loss: 1961.93, base loss: 2630.71
[INFO 2017-06-26 18:53:53,413 main.py:47] epoch 3669, training loss: 2035.91, average training loss: 1961.79, base loss: 2630.57
[INFO 2017-06-26 18:53:53,721 main.py:47] epoch 3670, training loss: 2136.46, average training loss: 1961.85, base loss: 2630.68
[INFO 2017-06-26 18:53:54,027 main.py:47] epoch 3671, training loss: 2189.54, average training loss: 1961.99, base loss: 2630.82
[INFO 2017-06-26 18:53:54,334 main.py:47] epoch 3672, training loss: 1948.95, average training loss: 1961.82, base loss: 2630.49
[INFO 2017-06-26 18:53:54,642 main.py:47] epoch 3673, training loss: 1858.04, average training loss: 1961.82, base loss: 2630.15
[INFO 2017-06-26 18:53:54,948 main.py:47] epoch 3674, training loss: 1780.86, average training loss: 1961.80, base loss: 2630.12
[INFO 2017-06-26 18:53:55,255 main.py:47] epoch 3675, training loss: 2029.39, average training loss: 1961.60, base loss: 2630.00
[INFO 2017-06-26 18:53:55,560 main.py:47] epoch 3676, training loss: 1983.55, average training loss: 1961.76, base loss: 2630.20
[INFO 2017-06-26 18:53:55,868 main.py:47] epoch 3677, training loss: 2128.09, average training loss: 1961.94, base loss: 2630.79
[INFO 2017-06-26 18:53:56,175 main.py:47] epoch 3678, training loss: 2196.85, average training loss: 1962.20, base loss: 2630.84
[INFO 2017-06-26 18:53:56,484 main.py:47] epoch 3679, training loss: 2096.51, average training loss: 1962.26, base loss: 2630.95
[INFO 2017-06-26 18:53:56,791 main.py:47] epoch 3680, training loss: 1986.74, average training loss: 1962.32, base loss: 2631.16
[INFO 2017-06-26 18:53:57,097 main.py:47] epoch 3681, training loss: 1775.51, average training loss: 1962.07, base loss: 2630.75
[INFO 2017-06-26 18:53:57,404 main.py:47] epoch 3682, training loss: 1846.59, average training loss: 1962.03, base loss: 2630.74
[INFO 2017-06-26 18:53:57,712 main.py:47] epoch 3683, training loss: 1951.50, average training loss: 1961.89, base loss: 2630.39
[INFO 2017-06-26 18:53:58,021 main.py:47] epoch 3684, training loss: 2355.42, average training loss: 1962.19, base loss: 2630.87
[INFO 2017-06-26 18:53:58,328 main.py:47] epoch 3685, training loss: 1862.57, average training loss: 1961.85, base loss: 2630.47
[INFO 2017-06-26 18:53:58,637 main.py:47] epoch 3686, training loss: 1748.38, average training loss: 1961.65, base loss: 2630.16
[INFO 2017-06-26 18:53:58,944 main.py:47] epoch 3687, training loss: 1946.84, average training loss: 1961.51, base loss: 2630.21
[INFO 2017-06-26 18:53:59,253 main.py:47] epoch 3688, training loss: 1909.94, average training loss: 1961.33, base loss: 2630.03
[INFO 2017-06-26 18:53:59,560 main.py:47] epoch 3689, training loss: 2049.14, average training loss: 1961.48, base loss: 2630.48
[INFO 2017-06-26 18:53:59,864 main.py:47] epoch 3690, training loss: 2087.14, average training loss: 1961.35, base loss: 2630.24
[INFO 2017-06-26 18:54:00,171 main.py:47] epoch 3691, training loss: 1964.72, average training loss: 1961.10, base loss: 2629.71
[INFO 2017-06-26 18:54:00,480 main.py:47] epoch 3692, training loss: 1763.17, average training loss: 1960.71, base loss: 2629.12
[INFO 2017-06-26 18:54:00,788 main.py:47] epoch 3693, training loss: 2241.09, average training loss: 1961.20, base loss: 2629.81
[INFO 2017-06-26 18:54:01,096 main.py:47] epoch 3694, training loss: 1953.92, average training loss: 1961.20, base loss: 2629.84
[INFO 2017-06-26 18:54:01,405 main.py:47] epoch 3695, training loss: 1941.52, average training loss: 1961.03, base loss: 2629.69
[INFO 2017-06-26 18:54:01,712 main.py:47] epoch 3696, training loss: 1790.62, average training loss: 1960.63, base loss: 2629.28
[INFO 2017-06-26 18:54:02,016 main.py:47] epoch 3697, training loss: 1549.50, average training loss: 1960.16, base loss: 2628.65
[INFO 2017-06-26 18:54:02,320 main.py:47] epoch 3698, training loss: 1818.60, average training loss: 1960.24, base loss: 2628.63
[INFO 2017-06-26 18:54:02,628 main.py:47] epoch 3699, training loss: 2070.78, average training loss: 1960.24, base loss: 2628.67
[INFO 2017-06-26 18:54:02,628 main.py:49] epoch 3699, testing
[INFO 2017-06-26 18:54:06,596 main.py:100] average testing loss: 1891.17, base loss: 2477.47
[INFO 2017-06-26 18:54:06,621 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:54:06,927 main.py:47] epoch 3700, training loss: 1771.10, average training loss: 1959.94, base loss: 2628.31
[INFO 2017-06-26 18:54:07,234 main.py:47] epoch 3701, training loss: 1858.67, average training loss: 1960.02, base loss: 2628.52
[INFO 2017-06-26 18:54:07,540 main.py:47] epoch 3702, training loss: 1877.20, average training loss: 1959.90, base loss: 2628.59
[INFO 2017-06-26 18:54:07,850 main.py:47] epoch 3703, training loss: 2331.54, average training loss: 1960.34, base loss: 2629.21
[INFO 2017-06-26 18:54:08,157 main.py:47] epoch 3704, training loss: 2010.41, average training loss: 1960.33, base loss: 2629.30
[INFO 2017-06-26 18:54:08,464 main.py:47] epoch 3705, training loss: 1801.57, average training loss: 1960.10, base loss: 2629.04
[INFO 2017-06-26 18:54:08,772 main.py:47] epoch 3706, training loss: 2307.02, average training loss: 1960.37, base loss: 2629.54
[INFO 2017-06-26 18:54:09,077 main.py:47] epoch 3707, training loss: 2158.37, average training loss: 1960.60, base loss: 2629.82
[INFO 2017-06-26 18:54:09,383 main.py:47] epoch 3708, training loss: 2227.61, average training loss: 1960.90, base loss: 2630.35
[INFO 2017-06-26 18:54:09,691 main.py:47] epoch 3709, training loss: 1833.33, average training loss: 1960.70, base loss: 2630.47
[INFO 2017-06-26 18:54:09,998 main.py:47] epoch 3710, training loss: 1799.12, average training loss: 1960.66, base loss: 2630.54
[INFO 2017-06-26 18:54:10,307 main.py:47] epoch 3711, training loss: 1903.62, average training loss: 1960.36, base loss: 2630.07
[INFO 2017-06-26 18:54:10,614 main.py:47] epoch 3712, training loss: 1753.05, average training loss: 1960.23, base loss: 2630.09
[INFO 2017-06-26 18:54:10,922 main.py:47] epoch 3713, training loss: 1806.00, average training loss: 1959.78, base loss: 2629.27
[INFO 2017-06-26 18:54:11,229 main.py:47] epoch 3714, training loss: 1920.36, average training loss: 1959.62, base loss: 2629.07
[INFO 2017-06-26 18:54:11,538 main.py:47] epoch 3715, training loss: 2012.66, average training loss: 1959.72, base loss: 2629.12
[INFO 2017-06-26 18:54:11,846 main.py:47] epoch 3716, training loss: 1833.19, average training loss: 1959.73, base loss: 2629.28
[INFO 2017-06-26 18:54:12,150 main.py:47] epoch 3717, training loss: 1748.20, average training loss: 1959.54, base loss: 2629.03
[INFO 2017-06-26 18:54:12,458 main.py:47] epoch 3718, training loss: 1973.16, average training loss: 1959.57, base loss: 2629.03
[INFO 2017-06-26 18:54:12,768 main.py:47] epoch 3719, training loss: 2033.12, average training loss: 1959.57, base loss: 2628.92
[INFO 2017-06-26 18:54:13,075 main.py:47] epoch 3720, training loss: 2038.11, average training loss: 1959.66, base loss: 2629.21
[INFO 2017-06-26 18:54:13,384 main.py:47] epoch 3721, training loss: 1879.43, average training loss: 1959.76, base loss: 2629.51
[INFO 2017-06-26 18:54:13,687 main.py:47] epoch 3722, training loss: 1770.66, average training loss: 1959.67, base loss: 2629.28
[INFO 2017-06-26 18:54:13,996 main.py:47] epoch 3723, training loss: 1761.44, average training loss: 1958.79, base loss: 2628.15
[INFO 2017-06-26 18:54:14,301 main.py:47] epoch 3724, training loss: 2189.32, average training loss: 1958.88, base loss: 2628.36
[INFO 2017-06-26 18:54:14,609 main.py:47] epoch 3725, training loss: 2085.65, average training loss: 1958.95, base loss: 2628.44
[INFO 2017-06-26 18:54:14,915 main.py:47] epoch 3726, training loss: 2201.55, average training loss: 1959.41, base loss: 2629.51
[INFO 2017-06-26 18:54:15,255 main.py:47] epoch 3727, training loss: 1637.29, average training loss: 1958.94, base loss: 2628.66
[INFO 2017-06-26 18:54:15,594 main.py:47] epoch 3728, training loss: 1668.14, average training loss: 1958.59, base loss: 2628.15
[INFO 2017-06-26 18:54:15,906 main.py:47] epoch 3729, training loss: 1721.29, average training loss: 1958.30, base loss: 2627.48
[INFO 2017-06-26 18:54:16,215 main.py:47] epoch 3730, training loss: 2050.17, average training loss: 1958.32, base loss: 2627.71
[INFO 2017-06-26 18:54:16,519 main.py:47] epoch 3731, training loss: 2536.84, average training loss: 1958.86, base loss: 2628.52
[INFO 2017-06-26 18:54:16,824 main.py:47] epoch 3732, training loss: 1859.06, average training loss: 1958.96, base loss: 2628.67
[INFO 2017-06-26 18:54:17,131 main.py:47] epoch 3733, training loss: 2033.87, average training loss: 1958.80, base loss: 2628.42
[INFO 2017-06-26 18:54:17,440 main.py:47] epoch 3734, training loss: 1929.06, average training loss: 1958.83, base loss: 2628.63
[INFO 2017-06-26 18:54:17,746 main.py:47] epoch 3735, training loss: 1584.31, average training loss: 1958.57, base loss: 2628.36
[INFO 2017-06-26 18:54:18,050 main.py:47] epoch 3736, training loss: 1888.58, average training loss: 1958.55, base loss: 2628.28
[INFO 2017-06-26 18:54:18,357 main.py:47] epoch 3737, training loss: 2407.79, average training loss: 1959.17, base loss: 2629.26
[INFO 2017-06-26 18:54:18,664 main.py:47] epoch 3738, training loss: 2028.49, average training loss: 1959.49, base loss: 2629.56
[INFO 2017-06-26 18:54:18,969 main.py:47] epoch 3739, training loss: 1982.58, average training loss: 1959.56, base loss: 2629.79
[INFO 2017-06-26 18:54:19,275 main.py:47] epoch 3740, training loss: 1941.61, average training loss: 1959.69, base loss: 2630.10
[INFO 2017-06-26 18:54:19,577 main.py:47] epoch 3741, training loss: 1939.06, average training loss: 1959.76, base loss: 2630.54
[INFO 2017-06-26 18:54:19,880 main.py:47] epoch 3742, training loss: 1667.15, average training loss: 1959.56, base loss: 2630.26
[INFO 2017-06-26 18:54:20,187 main.py:47] epoch 3743, training loss: 2112.19, average training loss: 1959.59, base loss: 2630.64
[INFO 2017-06-26 18:54:20,493 main.py:47] epoch 3744, training loss: 2024.90, average training loss: 1959.69, base loss: 2630.68
[INFO 2017-06-26 18:54:20,801 main.py:47] epoch 3745, training loss: 1993.12, average training loss: 1959.62, base loss: 2630.64
[INFO 2017-06-26 18:54:21,106 main.py:47] epoch 3746, training loss: 1821.82, average training loss: 1959.60, base loss: 2630.57
[INFO 2017-06-26 18:54:21,414 main.py:47] epoch 3747, training loss: 2408.60, average training loss: 1960.21, base loss: 2631.59
[INFO 2017-06-26 18:54:21,721 main.py:47] epoch 3748, training loss: 1746.49, average training loss: 1959.70, base loss: 2630.75
[INFO 2017-06-26 18:54:22,094 main.py:47] epoch 3749, training loss: 1960.22, average training loss: 1959.94, base loss: 2631.40
[INFO 2017-06-26 18:54:22,422 main.py:47] epoch 3750, training loss: 1650.58, average training loss: 1959.75, base loss: 2631.01
[INFO 2017-06-26 18:54:22,732 main.py:47] epoch 3751, training loss: 1869.62, average training loss: 1959.79, base loss: 2631.25
[INFO 2017-06-26 18:54:23,056 main.py:47] epoch 3752, training loss: 1977.38, average training loss: 1959.66, base loss: 2631.20
[INFO 2017-06-26 18:54:23,414 main.py:47] epoch 3753, training loss: 2001.31, average training loss: 1959.94, base loss: 2631.74
[INFO 2017-06-26 18:54:23,736 main.py:47] epoch 3754, training loss: 1722.40, average training loss: 1959.79, base loss: 2631.66
[INFO 2017-06-26 18:54:24,047 main.py:47] epoch 3755, training loss: 2196.29, average training loss: 1960.17, base loss: 2631.72
[INFO 2017-06-26 18:54:24,400 main.py:47] epoch 3756, training loss: 1710.69, average training loss: 1959.87, base loss: 2631.33
[INFO 2017-06-26 18:54:24,770 main.py:47] epoch 3757, training loss: 2004.81, average training loss: 1959.78, base loss: 2631.66
[INFO 2017-06-26 18:54:25,081 main.py:47] epoch 3758, training loss: 1955.72, average training loss: 1959.95, base loss: 2631.90
[INFO 2017-06-26 18:54:25,433 main.py:47] epoch 3759, training loss: 1783.82, average training loss: 1959.76, base loss: 2631.74
[INFO 2017-06-26 18:54:25,786 main.py:47] epoch 3760, training loss: 2228.47, average training loss: 1959.34, base loss: 2631.24
[INFO 2017-06-26 18:54:26,098 main.py:47] epoch 3761, training loss: 1911.28, average training loss: 1959.44, base loss: 2631.28
[INFO 2017-06-26 18:54:26,412 main.py:47] epoch 3762, training loss: 2085.60, average training loss: 1959.61, base loss: 2631.72
[INFO 2017-06-26 18:54:26,725 main.py:47] epoch 3763, training loss: 1701.43, average training loss: 1959.00, base loss: 2630.75
[INFO 2017-06-26 18:54:27,110 main.py:47] epoch 3764, training loss: 1733.26, average training loss: 1958.52, base loss: 2630.50
[INFO 2017-06-26 18:54:27,437 main.py:47] epoch 3765, training loss: 1881.45, average training loss: 1958.13, base loss: 2630.08
[INFO 2017-06-26 18:54:27,744 main.py:47] epoch 3766, training loss: 2222.83, average training loss: 1958.58, base loss: 2630.73
[INFO 2017-06-26 18:54:28,051 main.py:47] epoch 3767, training loss: 1859.37, average training loss: 1958.05, base loss: 2630.28
[INFO 2017-06-26 18:54:28,360 main.py:47] epoch 3768, training loss: 1925.10, average training loss: 1957.97, base loss: 2630.09
[INFO 2017-06-26 18:54:28,674 main.py:47] epoch 3769, training loss: 2084.33, average training loss: 1958.08, base loss: 2630.48
[INFO 2017-06-26 18:54:29,002 main.py:47] epoch 3770, training loss: 1905.06, average training loss: 1957.58, base loss: 2629.91
[INFO 2017-06-26 18:54:29,310 main.py:47] epoch 3771, training loss: 2064.48, average training loss: 1957.40, base loss: 2629.88
[INFO 2017-06-26 18:54:29,623 main.py:47] epoch 3772, training loss: 1991.17, average training loss: 1957.64, base loss: 2630.30
[INFO 2017-06-26 18:54:29,934 main.py:47] epoch 3773, training loss: 1819.92, average training loss: 1957.35, base loss: 2629.73
[INFO 2017-06-26 18:54:30,238 main.py:47] epoch 3774, training loss: 1754.80, average training loss: 1957.17, base loss: 2629.30
[INFO 2017-06-26 18:54:30,596 main.py:47] epoch 3775, training loss: 1960.24, average training loss: 1957.26, base loss: 2629.49
[INFO 2017-06-26 18:54:30,924 main.py:47] epoch 3776, training loss: 2397.25, average training loss: 1957.76, base loss: 2630.21
[INFO 2017-06-26 18:54:31,235 main.py:47] epoch 3777, training loss: 2274.68, average training loss: 1957.84, base loss: 2630.11
[INFO 2017-06-26 18:54:31,561 main.py:47] epoch 3778, training loss: 1830.08, average training loss: 1957.87, base loss: 2630.25
[INFO 2017-06-26 18:54:31,957 main.py:47] epoch 3779, training loss: 2197.62, average training loss: 1958.10, base loss: 2630.70
[INFO 2017-06-26 18:54:32,283 main.py:47] epoch 3780, training loss: 1716.57, average training loss: 1957.71, base loss: 2630.29
[INFO 2017-06-26 18:54:32,592 main.py:47] epoch 3781, training loss: 1784.86, average training loss: 1957.50, base loss: 2629.84
[INFO 2017-06-26 18:54:32,960 main.py:47] epoch 3782, training loss: 1800.29, average training loss: 1957.59, base loss: 2629.90
[INFO 2017-06-26 18:54:33,309 main.py:47] epoch 3783, training loss: 1687.92, average training loss: 1957.33, base loss: 2629.65
[INFO 2017-06-26 18:54:33,617 main.py:47] epoch 3784, training loss: 1573.52, average training loss: 1956.95, base loss: 2629.30
[INFO 2017-06-26 18:54:33,987 main.py:47] epoch 3785, training loss: 1895.87, average training loss: 1956.92, base loss: 2629.11
[INFO 2017-06-26 18:54:34,318 main.py:47] epoch 3786, training loss: 2356.98, average training loss: 1957.09, base loss: 2629.44
[INFO 2017-06-26 18:54:34,667 main.py:47] epoch 3787, training loss: 1846.21, average training loss: 1957.25, base loss: 2629.57
[INFO 2017-06-26 18:54:35,047 main.py:47] epoch 3788, training loss: 1963.53, average training loss: 1957.45, base loss: 2629.88
[INFO 2017-06-26 18:54:35,356 main.py:47] epoch 3789, training loss: 1842.35, average training loss: 1957.23, base loss: 2629.54
[INFO 2017-06-26 18:54:35,753 main.py:47] epoch 3790, training loss: 1953.17, average training loss: 1957.32, base loss: 2629.59
[INFO 2017-06-26 18:54:36,080 main.py:47] epoch 3791, training loss: 1811.32, average training loss: 1957.24, base loss: 2629.55
[INFO 2017-06-26 18:54:36,470 main.py:47] epoch 3792, training loss: 2173.19, average training loss: 1957.50, base loss: 2630.02
[INFO 2017-06-26 18:54:36,810 main.py:47] epoch 3793, training loss: 2048.59, average training loss: 1957.59, base loss: 2630.19
[INFO 2017-06-26 18:54:37,131 main.py:47] epoch 3794, training loss: 2090.03, average training loss: 1957.77, base loss: 2630.67
[INFO 2017-06-26 18:54:37,441 main.py:47] epoch 3795, training loss: 1897.64, average training loss: 1957.79, base loss: 2630.52
[INFO 2017-06-26 18:54:37,751 main.py:47] epoch 3796, training loss: 1960.47, average training loss: 1957.74, base loss: 2630.82
[INFO 2017-06-26 18:54:38,058 main.py:47] epoch 3797, training loss: 1937.15, average training loss: 1957.76, base loss: 2630.97
[INFO 2017-06-26 18:54:38,368 main.py:47] epoch 3798, training loss: 2262.40, average training loss: 1958.02, base loss: 2631.51
[INFO 2017-06-26 18:54:38,762 main.py:47] epoch 3799, training loss: 2159.47, average training loss: 1958.26, base loss: 2631.92
[INFO 2017-06-26 18:54:38,763 main.py:49] epoch 3799, testing
[INFO 2017-06-26 18:54:43,402 main.py:100] average testing loss: 1954.90, base loss: 2660.09
[INFO 2017-06-26 18:54:43,429 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:54:43,744 main.py:47] epoch 3800, training loss: 2198.57, average training loss: 1958.40, base loss: 2632.41
[INFO 2017-06-26 18:54:44,054 main.py:47] epoch 3801, training loss: 2321.69, average training loss: 1958.91, base loss: 2633.24
[INFO 2017-06-26 18:54:44,364 main.py:47] epoch 3802, training loss: 1824.79, average training loss: 1958.78, base loss: 2632.80
[INFO 2017-06-26 18:54:44,672 main.py:47] epoch 3803, training loss: 1813.30, average training loss: 1958.64, base loss: 2632.60
[INFO 2017-06-26 18:54:45,033 main.py:47] epoch 3804, training loss: 1953.70, average training loss: 1958.47, base loss: 2632.43
[INFO 2017-06-26 18:54:45,375 main.py:47] epoch 3805, training loss: 1928.72, average training loss: 1958.41, base loss: 2632.53
[INFO 2017-06-26 18:54:45,686 main.py:47] epoch 3806, training loss: 1731.43, average training loss: 1958.24, base loss: 2632.35
[INFO 2017-06-26 18:54:46,008 main.py:47] epoch 3807, training loss: 1810.16, average training loss: 1958.13, base loss: 2632.27
[INFO 2017-06-26 18:54:46,318 main.py:47] epoch 3808, training loss: 2222.22, average training loss: 1958.53, base loss: 2633.02
[INFO 2017-06-26 18:54:46,657 main.py:47] epoch 3809, training loss: 1941.16, average training loss: 1958.42, base loss: 2632.83
[INFO 2017-06-26 18:54:46,969 main.py:47] epoch 3810, training loss: 1794.28, average training loss: 1958.23, base loss: 2632.63
[INFO 2017-06-26 18:54:47,277 main.py:47] epoch 3811, training loss: 1710.09, average training loss: 1957.85, base loss: 2632.11
[INFO 2017-06-26 18:54:47,586 main.py:47] epoch 3812, training loss: 1752.20, average training loss: 1957.82, base loss: 2632.20
[INFO 2017-06-26 18:54:47,905 main.py:47] epoch 3813, training loss: 1726.68, average training loss: 1957.70, base loss: 2632.12
[INFO 2017-06-26 18:54:48,208 main.py:47] epoch 3814, training loss: 1875.80, average training loss: 1957.52, base loss: 2631.86
[INFO 2017-06-26 18:54:48,523 main.py:47] epoch 3815, training loss: 2065.32, average training loss: 1957.40, base loss: 2631.66
[INFO 2017-06-26 18:54:48,866 main.py:47] epoch 3816, training loss: 1828.32, average training loss: 1957.20, base loss: 2631.60
[INFO 2017-06-26 18:54:49,190 main.py:47] epoch 3817, training loss: 1806.68, average training loss: 1956.90, base loss: 2631.27
[INFO 2017-06-26 18:54:49,502 main.py:47] epoch 3818, training loss: 1531.61, average training loss: 1956.70, base loss: 2631.14
[INFO 2017-06-26 18:54:49,891 main.py:47] epoch 3819, training loss: 1899.96, average training loss: 1956.53, base loss: 2631.05
[INFO 2017-06-26 18:54:50,229 main.py:47] epoch 3820, training loss: 1739.22, average training loss: 1956.49, base loss: 2630.86
[INFO 2017-06-26 18:54:50,542 main.py:47] epoch 3821, training loss: 2009.89, average training loss: 1956.64, base loss: 2631.07
[INFO 2017-06-26 18:54:50,935 main.py:47] epoch 3822, training loss: 1733.53, average training loss: 1956.60, base loss: 2630.97
[INFO 2017-06-26 18:54:51,274 main.py:47] epoch 3823, training loss: 1820.48, average training loss: 1956.14, base loss: 2630.09
[INFO 2017-06-26 18:54:51,588 main.py:47] epoch 3824, training loss: 1750.43, average training loss: 1956.19, base loss: 2630.38
[INFO 2017-06-26 18:54:51,896 main.py:47] epoch 3825, training loss: 2254.04, average training loss: 1956.48, base loss: 2630.67
[INFO 2017-06-26 18:54:52,223 main.py:47] epoch 3826, training loss: 1982.44, average training loss: 1956.32, base loss: 2630.33
[INFO 2017-06-26 18:54:52,523 main.py:47] epoch 3827, training loss: 2164.11, average training loss: 1956.59, base loss: 2630.81
[INFO 2017-06-26 18:54:52,830 main.py:47] epoch 3828, training loss: 2225.31, average training loss: 1956.76, base loss: 2630.88
[INFO 2017-06-26 18:54:53,137 main.py:47] epoch 3829, training loss: 1729.57, average training loss: 1956.42, base loss: 2630.76
[INFO 2017-06-26 18:54:53,440 main.py:47] epoch 3830, training loss: 1973.85, average training loss: 1956.31, base loss: 2630.56
[INFO 2017-06-26 18:54:53,749 main.py:47] epoch 3831, training loss: 1789.87, average training loss: 1956.25, base loss: 2630.71
[INFO 2017-06-26 18:54:54,054 main.py:47] epoch 3832, training loss: 1663.12, average training loss: 1955.73, base loss: 2630.11
[INFO 2017-06-26 18:54:54,366 main.py:47] epoch 3833, training loss: 1788.91, average training loss: 1955.58, base loss: 2629.87
[INFO 2017-06-26 18:54:54,669 main.py:47] epoch 3834, training loss: 2252.16, average training loss: 1955.95, base loss: 2630.36
[INFO 2017-06-26 18:54:54,977 main.py:47] epoch 3835, training loss: 1749.48, average training loss: 1955.77, base loss: 2630.21
[INFO 2017-06-26 18:54:55,282 main.py:47] epoch 3836, training loss: 2039.99, average training loss: 1955.40, base loss: 2629.89
[INFO 2017-06-26 18:54:55,590 main.py:47] epoch 3837, training loss: 1847.16, average training loss: 1955.34, base loss: 2629.77
[INFO 2017-06-26 18:54:55,897 main.py:47] epoch 3838, training loss: 1743.24, average training loss: 1955.04, base loss: 2629.51
[INFO 2017-06-26 18:54:56,205 main.py:47] epoch 3839, training loss: 1721.58, average training loss: 1954.54, base loss: 2628.78
[INFO 2017-06-26 18:54:56,518 main.py:47] epoch 3840, training loss: 1694.55, average training loss: 1954.35, base loss: 2628.14
[INFO 2017-06-26 18:54:56,825 main.py:47] epoch 3841, training loss: 1947.00, average training loss: 1954.46, base loss: 2628.26
[INFO 2017-06-26 18:54:57,129 main.py:47] epoch 3842, training loss: 1860.36, average training loss: 1954.55, base loss: 2628.35
[INFO 2017-06-26 18:54:57,434 main.py:47] epoch 3843, training loss: 2294.24, average training loss: 1954.87, base loss: 2628.87
[INFO 2017-06-26 18:54:57,743 main.py:47] epoch 3844, training loss: 1639.28, average training loss: 1954.87, base loss: 2628.92
[INFO 2017-06-26 18:54:58,048 main.py:47] epoch 3845, training loss: 1673.76, average training loss: 1954.78, base loss: 2628.63
[INFO 2017-06-26 18:54:58,354 main.py:47] epoch 3846, training loss: 1886.52, average training loss: 1954.55, base loss: 2628.18
[INFO 2017-06-26 18:54:58,663 main.py:47] epoch 3847, training loss: 1700.88, average training loss: 1954.29, base loss: 2627.93
[INFO 2017-06-26 18:54:58,972 main.py:47] epoch 3848, training loss: 1786.02, average training loss: 1953.74, base loss: 2627.36
[INFO 2017-06-26 18:54:59,278 main.py:47] epoch 3849, training loss: 1953.59, average training loss: 1953.82, base loss: 2627.47
[INFO 2017-06-26 18:54:59,579 main.py:47] epoch 3850, training loss: 1833.36, average training loss: 1953.72, base loss: 2627.62
[INFO 2017-06-26 18:54:59,957 main.py:47] epoch 3851, training loss: 1800.65, average training loss: 1953.47, base loss: 2627.31
[INFO 2017-06-26 18:55:00,284 main.py:47] epoch 3852, training loss: 1760.74, average training loss: 1953.02, base loss: 2626.85
[INFO 2017-06-26 18:55:00,590 main.py:47] epoch 3853, training loss: 1794.66, average training loss: 1952.73, base loss: 2626.35
[INFO 2017-06-26 18:55:00,898 main.py:47] epoch 3854, training loss: 1787.90, average training loss: 1952.58, base loss: 2626.59
[INFO 2017-06-26 18:55:01,204 main.py:47] epoch 3855, training loss: 1763.53, average training loss: 1952.27, base loss: 2626.02
[INFO 2017-06-26 18:55:01,511 main.py:47] epoch 3856, training loss: 1775.99, average training loss: 1952.10, base loss: 2625.89
[INFO 2017-06-26 18:55:01,818 main.py:47] epoch 3857, training loss: 1928.69, average training loss: 1951.63, base loss: 2625.55
[INFO 2017-06-26 18:55:02,124 main.py:47] epoch 3858, training loss: 2223.78, average training loss: 1951.94, base loss: 2625.88
[INFO 2017-06-26 18:55:02,430 main.py:47] epoch 3859, training loss: 2418.31, average training loss: 1952.40, base loss: 2626.56
[INFO 2017-06-26 18:55:02,737 main.py:47] epoch 3860, training loss: 1967.87, average training loss: 1952.42, base loss: 2626.55
[INFO 2017-06-26 18:55:03,044 main.py:47] epoch 3861, training loss: 1998.82, average training loss: 1952.27, base loss: 2626.48
[INFO 2017-06-26 18:55:03,350 main.py:47] epoch 3862, training loss: 1858.44, average training loss: 1952.14, base loss: 2626.02
[INFO 2017-06-26 18:55:03,656 main.py:47] epoch 3863, training loss: 1929.97, average training loss: 1952.02, base loss: 2626.14
[INFO 2017-06-26 18:55:03,961 main.py:47] epoch 3864, training loss: 2091.98, average training loss: 1951.83, base loss: 2626.17
[INFO 2017-06-26 18:55:04,269 main.py:47] epoch 3865, training loss: 2097.53, average training loss: 1951.82, base loss: 2626.03
[INFO 2017-06-26 18:55:04,579 main.py:47] epoch 3866, training loss: 2003.62, average training loss: 1951.64, base loss: 2625.87
[INFO 2017-06-26 18:55:04,886 main.py:47] epoch 3867, training loss: 1882.86, average training loss: 1951.33, base loss: 2625.58
[INFO 2017-06-26 18:55:05,193 main.py:47] epoch 3868, training loss: 2153.78, average training loss: 1951.49, base loss: 2625.70
[INFO 2017-06-26 18:55:05,571 main.py:47] epoch 3869, training loss: 2024.39, average training loss: 1951.45, base loss: 2625.48
[INFO 2017-06-26 18:55:05,896 main.py:47] epoch 3870, training loss: 1811.68, average training loss: 1951.32, base loss: 2625.24
[INFO 2017-06-26 18:55:06,202 main.py:47] epoch 3871, training loss: 1814.90, average training loss: 1951.16, base loss: 2624.90
[INFO 2017-06-26 18:55:06,510 main.py:47] epoch 3872, training loss: 2057.60, average training loss: 1951.31, base loss: 2624.96
[INFO 2017-06-26 18:55:06,816 main.py:47] epoch 3873, training loss: 2543.89, average training loss: 1951.77, base loss: 2625.61
[INFO 2017-06-26 18:55:07,125 main.py:47] epoch 3874, training loss: 1698.35, average training loss: 1951.42, base loss: 2625.11
[INFO 2017-06-26 18:55:07,432 main.py:47] epoch 3875, training loss: 2188.77, average training loss: 1951.77, base loss: 2625.70
[INFO 2017-06-26 18:55:07,738 main.py:47] epoch 3876, training loss: 1809.09, average training loss: 1951.55, base loss: 2625.23
[INFO 2017-06-26 18:55:08,043 main.py:47] epoch 3877, training loss: 1658.54, average training loss: 1951.06, base loss: 2624.35
[INFO 2017-06-26 18:55:08,351 main.py:47] epoch 3878, training loss: 1628.79, average training loss: 1950.50, base loss: 2623.77
[INFO 2017-06-26 18:55:08,656 main.py:47] epoch 3879, training loss: 1945.86, average training loss: 1950.71, base loss: 2624.18
[INFO 2017-06-26 18:55:08,963 main.py:47] epoch 3880, training loss: 1850.36, average training loss: 1950.47, base loss: 2624.07
[INFO 2017-06-26 18:55:09,270 main.py:47] epoch 3881, training loss: 1656.44, average training loss: 1950.05, base loss: 2623.32
[INFO 2017-06-26 18:55:09,588 main.py:47] epoch 3882, training loss: 1974.01, average training loss: 1950.04, base loss: 2623.31
[INFO 2017-06-26 18:55:09,898 main.py:47] epoch 3883, training loss: 1926.73, average training loss: 1949.93, base loss: 2623.07
[INFO 2017-06-26 18:55:10,202 main.py:47] epoch 3884, training loss: 1871.79, average training loss: 1949.69, base loss: 2622.54
[INFO 2017-06-26 18:55:10,509 main.py:47] epoch 3885, training loss: 1769.36, average training loss: 1949.57, base loss: 2622.24
[INFO 2017-06-26 18:55:10,814 main.py:47] epoch 3886, training loss: 1850.30, average training loss: 1949.21, base loss: 2621.95
[INFO 2017-06-26 18:55:11,119 main.py:47] epoch 3887, training loss: 1752.16, average training loss: 1949.03, base loss: 2621.78
[INFO 2017-06-26 18:55:11,427 main.py:47] epoch 3888, training loss: 1864.00, average training loss: 1948.72, base loss: 2621.31
[INFO 2017-06-26 18:55:11,733 main.py:47] epoch 3889, training loss: 2118.69, average training loss: 1948.95, base loss: 2621.67
[INFO 2017-06-26 18:55:12,040 main.py:47] epoch 3890, training loss: 2289.96, average training loss: 1949.44, base loss: 2622.25
[INFO 2017-06-26 18:55:12,348 main.py:47] epoch 3891, training loss: 2056.54, average training loss: 1949.64, base loss: 2622.52
[INFO 2017-06-26 18:55:12,656 main.py:47] epoch 3892, training loss: 1974.29, average training loss: 1949.74, base loss: 2622.50
[INFO 2017-06-26 18:55:12,961 main.py:47] epoch 3893, training loss: 2142.29, average training loss: 1949.76, base loss: 2622.56
[INFO 2017-06-26 18:55:13,266 main.py:47] epoch 3894, training loss: 1817.36, average training loss: 1949.86, base loss: 2622.60
[INFO 2017-06-26 18:55:13,574 main.py:47] epoch 3895, training loss: 1967.91, average training loss: 1949.92, base loss: 2622.80
[INFO 2017-06-26 18:55:13,882 main.py:47] epoch 3896, training loss: 1894.37, average training loss: 1949.64, base loss: 2622.25
[INFO 2017-06-26 18:55:14,188 main.py:47] epoch 3897, training loss: 2058.13, average training loss: 1949.19, base loss: 2621.95
[INFO 2017-06-26 18:55:14,501 main.py:47] epoch 3898, training loss: 1726.07, average training loss: 1948.29, base loss: 2620.98
[INFO 2017-06-26 18:55:14,807 main.py:47] epoch 3899, training loss: 1800.95, average training loss: 1947.84, base loss: 2620.26
[INFO 2017-06-26 18:55:14,807 main.py:49] epoch 3899, testing
[INFO 2017-06-26 18:55:18,838 main.py:100] average testing loss: 1846.29, base loss: 2452.69
[INFO 2017-06-26 18:55:18,863 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:55:19,169 main.py:47] epoch 3900, training loss: 2099.03, average training loss: 1947.90, base loss: 2620.44
[INFO 2017-06-26 18:55:19,474 main.py:47] epoch 3901, training loss: 1705.86, average training loss: 1947.54, base loss: 2620.44
[INFO 2017-06-26 18:55:19,778 main.py:47] epoch 3902, training loss: 1725.21, average training loss: 1947.28, base loss: 2620.20
[INFO 2017-06-26 18:55:20,081 main.py:47] epoch 3903, training loss: 1915.43, average training loss: 1947.10, base loss: 2619.87
[INFO 2017-06-26 18:55:20,388 main.py:47] epoch 3904, training loss: 2017.03, average training loss: 1946.94, base loss: 2619.52
[INFO 2017-06-26 18:55:20,692 main.py:47] epoch 3905, training loss: 2027.99, average training loss: 1946.98, base loss: 2620.00
[INFO 2017-06-26 18:55:20,998 main.py:47] epoch 3906, training loss: 1993.94, average training loss: 1947.34, base loss: 2620.94
[INFO 2017-06-26 18:55:21,304 main.py:47] epoch 3907, training loss: 1744.97, average training loss: 1947.05, base loss: 2620.67
[INFO 2017-06-26 18:55:21,612 main.py:47] epoch 3908, training loss: 1985.86, average training loss: 1947.24, base loss: 2621.45
[INFO 2017-06-26 18:55:21,918 main.py:47] epoch 3909, training loss: 1968.25, average training loss: 1947.57, base loss: 2622.02
[INFO 2017-06-26 18:55:22,221 main.py:47] epoch 3910, training loss: 1852.61, average training loss: 1947.02, base loss: 2621.60
[INFO 2017-06-26 18:55:22,526 main.py:47] epoch 3911, training loss: 1792.52, average training loss: 1946.50, base loss: 2620.99
[INFO 2017-06-26 18:55:22,829 main.py:47] epoch 3912, training loss: 1858.81, average training loss: 1946.42, base loss: 2621.00
[INFO 2017-06-26 18:55:23,133 main.py:47] epoch 3913, training loss: 1929.05, average training loss: 1946.14, base loss: 2620.79
[INFO 2017-06-26 18:55:23,440 main.py:47] epoch 3914, training loss: 1774.27, average training loss: 1945.97, base loss: 2620.66
[INFO 2017-06-26 18:55:23,745 main.py:47] epoch 3915, training loss: 1824.19, average training loss: 1945.85, base loss: 2620.63
[INFO 2017-06-26 18:55:24,051 main.py:47] epoch 3916, training loss: 2216.08, average training loss: 1946.18, base loss: 2621.18
[INFO 2017-06-26 18:55:24,358 main.py:47] epoch 3917, training loss: 2350.41, average training loss: 1946.71, base loss: 2622.16
[INFO 2017-06-26 18:55:24,665 main.py:47] epoch 3918, training loss: 1923.30, average training loss: 1946.45, base loss: 2621.86
[INFO 2017-06-26 18:55:24,968 main.py:47] epoch 3919, training loss: 1804.35, average training loss: 1946.26, base loss: 2621.71
[INFO 2017-06-26 18:55:25,274 main.py:47] epoch 3920, training loss: 2088.99, average training loss: 1946.63, base loss: 2622.56
[INFO 2017-06-26 18:55:25,581 main.py:47] epoch 3921, training loss: 1826.00, average training loss: 1946.38, base loss: 2622.37
[INFO 2017-06-26 18:55:25,885 main.py:47] epoch 3922, training loss: 1730.66, average training loss: 1946.14, base loss: 2622.12
[INFO 2017-06-26 18:55:26,189 main.py:47] epoch 3923, training loss: 1985.78, average training loss: 1945.88, base loss: 2621.88
[INFO 2017-06-26 18:55:26,496 main.py:47] epoch 3924, training loss: 2095.14, average training loss: 1946.23, base loss: 2622.55
[INFO 2017-06-26 18:55:26,796 main.py:47] epoch 3925, training loss: 1789.79, average training loss: 1945.90, base loss: 2622.05
[INFO 2017-06-26 18:55:27,103 main.py:47] epoch 3926, training loss: 1926.70, average training loss: 1945.89, base loss: 2622.04
[INFO 2017-06-26 18:55:27,410 main.py:47] epoch 3927, training loss: 1739.68, average training loss: 1945.72, base loss: 2621.85
[INFO 2017-06-26 18:55:27,718 main.py:47] epoch 3928, training loss: 1884.97, average training loss: 1945.86, base loss: 2621.94
[INFO 2017-06-26 18:55:28,022 main.py:47] epoch 3929, training loss: 1861.00, average training loss: 1945.94, base loss: 2622.36
[INFO 2017-06-26 18:55:28,329 main.py:47] epoch 3930, training loss: 2200.20, average training loss: 1946.49, base loss: 2623.22
[INFO 2017-06-26 18:55:28,633 main.py:47] epoch 3931, training loss: 2060.10, average training loss: 1946.60, base loss: 2623.44
[INFO 2017-06-26 18:55:28,940 main.py:47] epoch 3932, training loss: 1775.24, average training loss: 1946.60, base loss: 2623.28
[INFO 2017-06-26 18:55:29,240 main.py:47] epoch 3933, training loss: 1767.37, average training loss: 1946.46, base loss: 2623.21
[INFO 2017-06-26 18:55:29,544 main.py:47] epoch 3934, training loss: 1948.50, average training loss: 1946.50, base loss: 2623.23
[INFO 2017-06-26 18:55:29,850 main.py:47] epoch 3935, training loss: 2058.60, average training loss: 1946.63, base loss: 2623.24
[INFO 2017-06-26 18:55:30,161 main.py:47] epoch 3936, training loss: 1930.05, average training loss: 1946.58, base loss: 2623.23
[INFO 2017-06-26 18:55:30,469 main.py:47] epoch 3937, training loss: 1943.26, average training loss: 1946.76, base loss: 2623.44
[INFO 2017-06-26 18:55:30,782 main.py:47] epoch 3938, training loss: 2023.72, average training loss: 1946.93, base loss: 2623.64
[INFO 2017-06-26 18:55:31,089 main.py:47] epoch 3939, training loss: 1580.70, average training loss: 1946.80, base loss: 2623.42
[INFO 2017-06-26 18:55:31,397 main.py:47] epoch 3940, training loss: 2053.06, average training loss: 1947.04, base loss: 2623.85
[INFO 2017-06-26 18:55:31,708 main.py:47] epoch 3941, training loss: 1828.49, average training loss: 1947.11, base loss: 2624.17
[INFO 2017-06-26 18:55:32,012 main.py:47] epoch 3942, training loss: 2291.37, average training loss: 1947.20, base loss: 2624.63
[INFO 2017-06-26 18:55:32,317 main.py:47] epoch 3943, training loss: 2046.09, average training loss: 1947.25, base loss: 2624.56
[INFO 2017-06-26 18:55:32,623 main.py:47] epoch 3944, training loss: 2047.86, average training loss: 1947.28, base loss: 2624.57
[INFO 2017-06-26 18:55:32,929 main.py:47] epoch 3945, training loss: 2006.44, average training loss: 1947.21, base loss: 2624.68
[INFO 2017-06-26 18:55:33,236 main.py:47] epoch 3946, training loss: 1795.74, average training loss: 1947.26, base loss: 2625.00
[INFO 2017-06-26 18:55:33,542 main.py:47] epoch 3947, training loss: 1809.85, average training loss: 1947.09, base loss: 2624.77
[INFO 2017-06-26 18:55:33,848 main.py:47] epoch 3948, training loss: 2054.08, average training loss: 1946.71, base loss: 2624.36
[INFO 2017-06-26 18:55:34,155 main.py:47] epoch 3949, training loss: 1756.71, average training loss: 1946.82, base loss: 2624.57
[INFO 2017-06-26 18:55:34,461 main.py:47] epoch 3950, training loss: 1843.73, average training loss: 1946.48, base loss: 2624.15
[INFO 2017-06-26 18:55:34,769 main.py:47] epoch 3951, training loss: 2121.64, average training loss: 1946.24, base loss: 2623.53
[INFO 2017-06-26 18:55:35,073 main.py:47] epoch 3952, training loss: 1941.52, average training loss: 1946.29, base loss: 2623.72
[INFO 2017-06-26 18:55:35,377 main.py:47] epoch 3953, training loss: 1872.83, average training loss: 1946.18, base loss: 2623.66
[INFO 2017-06-26 18:55:35,684 main.py:47] epoch 3954, training loss: 1867.34, average training loss: 1945.90, base loss: 2623.43
[INFO 2017-06-26 18:55:35,992 main.py:47] epoch 3955, training loss: 1904.09, average training loss: 1945.96, base loss: 2623.69
[INFO 2017-06-26 18:55:36,295 main.py:47] epoch 3956, training loss: 1685.18, average training loss: 1945.49, base loss: 2622.99
[INFO 2017-06-26 18:55:36,602 main.py:47] epoch 3957, training loss: 1674.26, average training loss: 1945.36, base loss: 2622.80
[INFO 2017-06-26 18:55:36,905 main.py:47] epoch 3958, training loss: 1798.04, average training loss: 1945.10, base loss: 2622.52
[INFO 2017-06-26 18:55:37,209 main.py:47] epoch 3959, training loss: 1994.46, average training loss: 1945.21, base loss: 2622.55
[INFO 2017-06-26 18:55:37,515 main.py:47] epoch 3960, training loss: 2277.78, average training loss: 1945.81, base loss: 2623.39
[INFO 2017-06-26 18:55:37,821 main.py:47] epoch 3961, training loss: 2144.49, average training loss: 1946.18, base loss: 2623.77
[INFO 2017-06-26 18:55:38,127 main.py:47] epoch 3962, training loss: 1724.85, average training loss: 1945.92, base loss: 2623.68
[INFO 2017-06-26 18:55:38,434 main.py:47] epoch 3963, training loss: 1955.26, average training loss: 1946.06, base loss: 2624.17
[INFO 2017-06-26 18:55:38,740 main.py:47] epoch 3964, training loss: 1998.05, average training loss: 1946.23, base loss: 2624.55
[INFO 2017-06-26 18:55:39,046 main.py:47] epoch 3965, training loss: 1913.03, average training loss: 1946.18, base loss: 2624.54
[INFO 2017-06-26 18:55:39,352 main.py:47] epoch 3966, training loss: 2041.26, average training loss: 1946.34, base loss: 2624.66
[INFO 2017-06-26 18:55:39,659 main.py:47] epoch 3967, training loss: 1872.72, average training loss: 1946.35, base loss: 2624.85
[INFO 2017-06-26 18:55:39,960 main.py:47] epoch 3968, training loss: 1676.96, average training loss: 1946.06, base loss: 2624.41
[INFO 2017-06-26 18:55:40,266 main.py:47] epoch 3969, training loss: 1639.26, average training loss: 1945.58, base loss: 2623.69
[INFO 2017-06-26 18:55:40,573 main.py:47] epoch 3970, training loss: 2087.69, average training loss: 1945.86, base loss: 2624.18
[INFO 2017-06-26 18:55:40,878 main.py:47] epoch 3971, training loss: 2074.73, average training loss: 1946.06, base loss: 2624.41
[INFO 2017-06-26 18:55:41,181 main.py:47] epoch 3972, training loss: 2062.84, average training loss: 1945.95, base loss: 2624.59
[INFO 2017-06-26 18:55:41,483 main.py:47] epoch 3973, training loss: 1864.66, average training loss: 1945.78, base loss: 2624.58
[INFO 2017-06-26 18:55:41,788 main.py:47] epoch 3974, training loss: 1885.79, average training loss: 1945.61, base loss: 2624.32
[INFO 2017-06-26 18:55:42,096 main.py:47] epoch 3975, training loss: 1971.90, average training loss: 1945.52, base loss: 2623.95
[INFO 2017-06-26 18:55:42,399 main.py:47] epoch 3976, training loss: 2005.55, average training loss: 1945.83, base loss: 2624.70
[INFO 2017-06-26 18:55:42,703 main.py:47] epoch 3977, training loss: 1815.57, average training loss: 1945.60, base loss: 2624.27
[INFO 2017-06-26 18:55:43,009 main.py:47] epoch 3978, training loss: 1977.20, average training loss: 1945.43, base loss: 2623.98
[INFO 2017-06-26 18:55:43,315 main.py:47] epoch 3979, training loss: 1728.45, average training loss: 1945.37, base loss: 2623.73
[INFO 2017-06-26 18:55:43,622 main.py:47] epoch 3980, training loss: 1851.49, average training loss: 1945.27, base loss: 2623.50
[INFO 2017-06-26 18:55:43,928 main.py:47] epoch 3981, training loss: 2180.48, average training loss: 1945.40, base loss: 2623.75
[INFO 2017-06-26 18:55:44,230 main.py:47] epoch 3982, training loss: 1865.23, average training loss: 1944.69, base loss: 2622.98
[INFO 2017-06-26 18:55:44,534 main.py:47] epoch 3983, training loss: 1791.81, average training loss: 1944.65, base loss: 2622.89
[INFO 2017-06-26 18:55:44,841 main.py:47] epoch 3984, training loss: 1732.27, average training loss: 1944.52, base loss: 2622.47
[INFO 2017-06-26 18:55:45,149 main.py:47] epoch 3985, training loss: 1649.78, average training loss: 1944.06, base loss: 2621.88
[INFO 2017-06-26 18:55:45,458 main.py:47] epoch 3986, training loss: 2151.91, average training loss: 1944.23, base loss: 2622.11
[INFO 2017-06-26 18:55:45,766 main.py:47] epoch 3987, training loss: 1827.85, average training loss: 1944.17, base loss: 2622.19
[INFO 2017-06-26 18:55:46,073 main.py:47] epoch 3988, training loss: 2099.43, average training loss: 1943.92, base loss: 2621.86
[INFO 2017-06-26 18:55:46,379 main.py:47] epoch 3989, training loss: 1969.37, average training loss: 1943.88, base loss: 2621.98
[INFO 2017-06-26 18:55:46,684 main.py:47] epoch 3990, training loss: 2093.30, average training loss: 1943.91, base loss: 2622.08
[INFO 2017-06-26 18:55:46,990 main.py:47] epoch 3991, training loss: 1960.97, average training loss: 1943.89, base loss: 2622.15
[INFO 2017-06-26 18:55:47,297 main.py:47] epoch 3992, training loss: 1932.25, average training loss: 1943.93, base loss: 2622.25
[INFO 2017-06-26 18:55:47,604 main.py:47] epoch 3993, training loss: 2061.61, average training loss: 1944.03, base loss: 2622.50
[INFO 2017-06-26 18:55:47,909 main.py:47] epoch 3994, training loss: 2037.71, average training loss: 1944.06, base loss: 2622.43
[INFO 2017-06-26 18:55:48,215 main.py:47] epoch 3995, training loss: 1813.15, average training loss: 1944.02, base loss: 2622.20
[INFO 2017-06-26 18:55:48,523 main.py:47] epoch 3996, training loss: 2019.54, average training loss: 1944.39, base loss: 2622.93
[INFO 2017-06-26 18:55:48,829 main.py:47] epoch 3997, training loss: 1638.27, average training loss: 1944.09, base loss: 2622.58
[INFO 2017-06-26 18:55:49,135 main.py:47] epoch 3998, training loss: 1901.16, average training loss: 1944.27, base loss: 2622.94
[INFO 2017-06-26 18:55:49,443 main.py:47] epoch 3999, training loss: 1922.01, average training loss: 1944.52, base loss: 2623.42
[INFO 2017-06-26 18:55:49,443 main.py:49] epoch 3999, testing
[INFO 2017-06-26 18:55:53,423 main.py:100] average testing loss: 1925.47, base loss: 2625.35
[INFO 2017-06-26 18:55:53,449 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:55:53,756 main.py:47] epoch 4000, training loss: 1900.72, average training loss: 1943.96, base loss: 2622.48
[INFO 2017-06-26 18:55:54,061 main.py:47] epoch 4001, training loss: 1761.78, average training loss: 1943.88, base loss: 2622.27
[INFO 2017-06-26 18:55:54,362 main.py:47] epoch 4002, training loss: 1925.65, average training loss: 1943.86, base loss: 2622.13
[INFO 2017-06-26 18:55:54,668 main.py:47] epoch 4003, training loss: 1675.76, average training loss: 1943.42, base loss: 2621.62
[INFO 2017-06-26 18:55:54,972 main.py:47] epoch 4004, training loss: 1815.54, average training loss: 1943.28, base loss: 2621.23
[INFO 2017-06-26 18:55:55,275 main.py:47] epoch 4005, training loss: 2361.91, average training loss: 1943.85, base loss: 2622.11
[INFO 2017-06-26 18:55:55,581 main.py:47] epoch 4006, training loss: 2150.49, average training loss: 1944.10, base loss: 2622.21
[INFO 2017-06-26 18:55:55,890 main.py:47] epoch 4007, training loss: 1707.12, average training loss: 1944.10, base loss: 2622.31
[INFO 2017-06-26 18:55:56,194 main.py:47] epoch 4008, training loss: 2042.20, average training loss: 1943.92, base loss: 2622.04
[INFO 2017-06-26 18:55:56,498 main.py:47] epoch 4009, training loss: 1678.11, average training loss: 1943.71, base loss: 2621.83
[INFO 2017-06-26 18:55:56,803 main.py:47] epoch 4010, training loss: 1548.02, average training loss: 1943.51, base loss: 2621.64
[INFO 2017-06-26 18:55:57,105 main.py:47] epoch 4011, training loss: 1622.82, average training loss: 1943.37, base loss: 2621.54
[INFO 2017-06-26 18:55:57,409 main.py:47] epoch 4012, training loss: 1827.52, average training loss: 1943.22, base loss: 2621.84
[INFO 2017-06-26 18:55:57,714 main.py:47] epoch 4013, training loss: 2127.88, average training loss: 1943.28, base loss: 2621.79
[INFO 2017-06-26 18:55:58,023 main.py:47] epoch 4014, training loss: 1757.50, average training loss: 1943.09, base loss: 2621.53
[INFO 2017-06-26 18:55:58,325 main.py:47] epoch 4015, training loss: 2273.55, average training loss: 1943.05, base loss: 2621.40
[INFO 2017-06-26 18:55:58,629 main.py:47] epoch 4016, training loss: 1759.93, average training loss: 1942.83, base loss: 2621.13
[INFO 2017-06-26 18:55:58,933 main.py:47] epoch 4017, training loss: 1652.84, average training loss: 1942.66, base loss: 2621.05
[INFO 2017-06-26 18:55:59,237 main.py:47] epoch 4018, training loss: 1866.88, average training loss: 1942.49, base loss: 2620.84
[INFO 2017-06-26 18:55:59,544 main.py:47] epoch 4019, training loss: 1914.39, average training loss: 1942.38, base loss: 2620.91
[INFO 2017-06-26 18:55:59,849 main.py:47] epoch 4020, training loss: 1967.83, average training loss: 1942.61, base loss: 2621.38
[INFO 2017-06-26 18:56:00,154 main.py:47] epoch 4021, training loss: 1545.59, average training loss: 1942.21, base loss: 2620.87
[INFO 2017-06-26 18:56:00,462 main.py:47] epoch 4022, training loss: 1929.56, average training loss: 1942.17, base loss: 2620.85
[INFO 2017-06-26 18:56:00,767 main.py:47] epoch 4023, training loss: 1936.00, average training loss: 1942.31, base loss: 2621.15
[INFO 2017-06-26 18:56:01,074 main.py:47] epoch 4024, training loss: 1828.85, average training loss: 1942.28, base loss: 2620.97
[INFO 2017-06-26 18:56:01,380 main.py:47] epoch 4025, training loss: 2186.42, average training loss: 1942.61, base loss: 2621.54
[INFO 2017-06-26 18:56:01,686 main.py:47] epoch 4026, training loss: 1672.41, average training loss: 1942.23, base loss: 2620.99
[INFO 2017-06-26 18:56:01,992 main.py:47] epoch 4027, training loss: 2155.20, average training loss: 1942.34, base loss: 2621.14
[INFO 2017-06-26 18:56:02,299 main.py:47] epoch 4028, training loss: 1670.68, average training loss: 1942.11, base loss: 2621.31
[INFO 2017-06-26 18:56:02,605 main.py:47] epoch 4029, training loss: 1649.68, average training loss: 1941.47, base loss: 2620.44
[INFO 2017-06-26 18:56:02,912 main.py:47] epoch 4030, training loss: 1787.28, average training loss: 1941.36, base loss: 2620.26
[INFO 2017-06-26 18:56:03,216 main.py:47] epoch 4031, training loss: 1798.30, average training loss: 1941.19, base loss: 2620.18
[INFO 2017-06-26 18:56:03,524 main.py:47] epoch 4032, training loss: 1774.91, average training loss: 1940.98, base loss: 2619.73
[INFO 2017-06-26 18:56:03,831 main.py:47] epoch 4033, training loss: 1778.25, average training loss: 1940.97, base loss: 2619.73
[INFO 2017-06-26 18:56:04,137 main.py:47] epoch 4034, training loss: 1591.45, average training loss: 1940.82, base loss: 2619.53
[INFO 2017-06-26 18:56:04,444 main.py:47] epoch 4035, training loss: 1654.26, average training loss: 1940.66, base loss: 2619.18
[INFO 2017-06-26 18:56:04,746 main.py:47] epoch 4036, training loss: 1828.52, average training loss: 1940.47, base loss: 2618.96
[INFO 2017-06-26 18:56:05,054 main.py:47] epoch 4037, training loss: 1794.48, average training loss: 1940.61, base loss: 2619.35
[INFO 2017-06-26 18:56:05,359 main.py:47] epoch 4038, training loss: 1952.29, average training loss: 1940.35, base loss: 2618.99
[INFO 2017-06-26 18:56:05,664 main.py:47] epoch 4039, training loss: 2029.33, average training loss: 1940.64, base loss: 2619.38
[INFO 2017-06-26 18:56:05,968 main.py:47] epoch 4040, training loss: 1799.61, average training loss: 1940.89, base loss: 2619.83
[INFO 2017-06-26 18:56:06,273 main.py:47] epoch 4041, training loss: 1854.80, average training loss: 1940.95, base loss: 2620.07
[INFO 2017-06-26 18:56:06,579 main.py:47] epoch 4042, training loss: 1685.87, average training loss: 1940.65, base loss: 2619.50
[INFO 2017-06-26 18:56:06,885 main.py:47] epoch 4043, training loss: 2035.01, average training loss: 1940.79, base loss: 2619.89
[INFO 2017-06-26 18:56:07,193 main.py:47] epoch 4044, training loss: 1642.86, average training loss: 1940.35, base loss: 2619.38
[INFO 2017-06-26 18:56:07,499 main.py:47] epoch 4045, training loss: 1844.95, average training loss: 1940.24, base loss: 2619.46
[INFO 2017-06-26 18:56:07,804 main.py:47] epoch 4046, training loss: 1869.34, average training loss: 1940.29, base loss: 2619.51
[INFO 2017-06-26 18:56:08,108 main.py:47] epoch 4047, training loss: 1986.56, average training loss: 1940.20, base loss: 2619.33
[INFO 2017-06-26 18:56:08,413 main.py:47] epoch 4048, training loss: 1644.81, average training loss: 1939.78, base loss: 2618.73
[INFO 2017-06-26 18:56:08,718 main.py:47] epoch 4049, training loss: 1719.80, average training loss: 1939.70, base loss: 2618.81
[INFO 2017-06-26 18:56:09,025 main.py:47] epoch 4050, training loss: 1868.94, average training loss: 1939.34, base loss: 2618.35
[INFO 2017-06-26 18:56:09,332 main.py:47] epoch 4051, training loss: 1639.09, average training loss: 1939.22, base loss: 2618.20
[INFO 2017-06-26 18:56:09,639 main.py:47] epoch 4052, training loss: 1720.08, average training loss: 1938.86, base loss: 2617.65
[INFO 2017-06-26 18:56:09,946 main.py:47] epoch 4053, training loss: 1990.97, average training loss: 1938.63, base loss: 2617.08
[INFO 2017-06-26 18:56:10,251 main.py:47] epoch 4054, training loss: 2031.33, average training loss: 1938.64, base loss: 2617.14
[INFO 2017-06-26 18:56:10,556 main.py:47] epoch 4055, training loss: 1602.95, average training loss: 1938.39, base loss: 2616.74
[INFO 2017-06-26 18:56:10,863 main.py:47] epoch 4056, training loss: 1980.08, average training loss: 1938.55, base loss: 2617.00
[INFO 2017-06-26 18:56:11,170 main.py:47] epoch 4057, training loss: 2053.54, average training loss: 1938.73, base loss: 2617.20
[INFO 2017-06-26 18:56:11,479 main.py:47] epoch 4058, training loss: 1831.70, average training loss: 1938.58, base loss: 2617.05
[INFO 2017-06-26 18:56:11,785 main.py:47] epoch 4059, training loss: 1626.99, average training loss: 1938.14, base loss: 2616.70
[INFO 2017-06-26 18:56:12,089 main.py:47] epoch 4060, training loss: 1640.48, average training loss: 1937.84, base loss: 2616.32
[INFO 2017-06-26 18:56:12,396 main.py:47] epoch 4061, training loss: 2032.27, average training loss: 1937.84, base loss: 2616.58
[INFO 2017-06-26 18:56:12,702 main.py:47] epoch 4062, training loss: 1727.18, average training loss: 1937.76, base loss: 2616.71
[INFO 2017-06-26 18:56:13,007 main.py:47] epoch 4063, training loss: 1700.10, average training loss: 1937.45, base loss: 2616.27
[INFO 2017-06-26 18:56:13,309 main.py:47] epoch 4064, training loss: 1991.57, average training loss: 1937.62, base loss: 2616.78
[INFO 2017-06-26 18:56:13,614 main.py:47] epoch 4065, training loss: 2056.03, average training loss: 1937.93, base loss: 2617.23
[INFO 2017-06-26 18:56:13,920 main.py:47] epoch 4066, training loss: 2136.85, average training loss: 1938.31, base loss: 2617.83
[INFO 2017-06-26 18:56:14,225 main.py:47] epoch 4067, training loss: 2317.94, average training loss: 1938.73, base loss: 2618.72
[INFO 2017-06-26 18:56:14,530 main.py:47] epoch 4068, training loss: 1927.93, average training loss: 1938.84, base loss: 2618.89
[INFO 2017-06-26 18:56:14,834 main.py:47] epoch 4069, training loss: 1946.98, average training loss: 1938.84, base loss: 2619.03
[INFO 2017-06-26 18:56:15,141 main.py:47] epoch 4070, training loss: 2153.09, average training loss: 1938.91, base loss: 2619.10
[INFO 2017-06-26 18:56:15,446 main.py:47] epoch 4071, training loss: 2000.54, average training loss: 1938.76, base loss: 2619.07
[INFO 2017-06-26 18:56:15,753 main.py:47] epoch 4072, training loss: 1970.03, average training loss: 1938.80, base loss: 2618.77
[INFO 2017-06-26 18:56:16,057 main.py:47] epoch 4073, training loss: 1727.59, average training loss: 1938.76, base loss: 2618.77
[INFO 2017-06-26 18:56:16,364 main.py:47] epoch 4074, training loss: 2057.40, average training loss: 1938.83, base loss: 2618.59
[INFO 2017-06-26 18:56:16,670 main.py:47] epoch 4075, training loss: 1814.35, average training loss: 1938.95, base loss: 2618.78
[INFO 2017-06-26 18:56:16,977 main.py:47] epoch 4076, training loss: 1742.05, average training loss: 1938.61, base loss: 2618.48
[INFO 2017-06-26 18:56:17,285 main.py:47] epoch 4077, training loss: 1980.36, average training loss: 1938.38, base loss: 2618.14
[INFO 2017-06-26 18:56:17,592 main.py:47] epoch 4078, training loss: 2014.49, average training loss: 1938.49, base loss: 2618.25
[INFO 2017-06-26 18:56:17,897 main.py:47] epoch 4079, training loss: 1795.79, average training loss: 1938.57, base loss: 2618.43
[INFO 2017-06-26 18:56:18,204 main.py:47] epoch 4080, training loss: 1862.36, average training loss: 1938.68, base loss: 2618.68
[INFO 2017-06-26 18:56:18,510 main.py:47] epoch 4081, training loss: 1983.47, average training loss: 1938.63, base loss: 2618.86
[INFO 2017-06-26 18:56:18,813 main.py:47] epoch 4082, training loss: 2062.11, average training loss: 1938.80, base loss: 2619.04
[INFO 2017-06-26 18:56:19,117 main.py:47] epoch 4083, training loss: 1659.55, average training loss: 1938.42, base loss: 2618.41
[INFO 2017-06-26 18:56:19,422 main.py:47] epoch 4084, training loss: 1966.43, average training loss: 1938.51, base loss: 2618.54
[INFO 2017-06-26 18:56:19,725 main.py:47] epoch 4085, training loss: 1764.07, average training loss: 1937.89, base loss: 2617.46
[INFO 2017-06-26 18:56:20,031 main.py:47] epoch 4086, training loss: 1901.84, average training loss: 1937.65, base loss: 2617.15
[INFO 2017-06-26 18:56:20,340 main.py:47] epoch 4087, training loss: 2214.15, average training loss: 1938.16, base loss: 2617.97
[INFO 2017-06-26 18:56:20,648 main.py:47] epoch 4088, training loss: 1954.86, average training loss: 1938.19, base loss: 2617.86
[INFO 2017-06-26 18:56:20,954 main.py:47] epoch 4089, training loss: 1851.41, average training loss: 1938.11, base loss: 2617.80
[INFO 2017-06-26 18:56:21,258 main.py:47] epoch 4090, training loss: 1937.34, average training loss: 1938.15, base loss: 2618.23
[INFO 2017-06-26 18:56:21,565 main.py:47] epoch 4091, training loss: 1636.36, average training loss: 1937.74, base loss: 2617.65
[INFO 2017-06-26 18:56:21,869 main.py:47] epoch 4092, training loss: 1878.28, average training loss: 1938.02, base loss: 2618.11
[INFO 2017-06-26 18:56:22,175 main.py:47] epoch 4093, training loss: 1941.48, average training loss: 1937.75, base loss: 2617.58
[INFO 2017-06-26 18:56:22,477 main.py:47] epoch 4094, training loss: 1917.42, average training loss: 1937.78, base loss: 2617.43
[INFO 2017-06-26 18:56:22,785 main.py:47] epoch 4095, training loss: 1817.39, average training loss: 1937.82, base loss: 2617.50
[INFO 2017-06-26 18:56:23,093 main.py:47] epoch 4096, training loss: 2115.05, average training loss: 1938.05, base loss: 2617.84
[INFO 2017-06-26 18:56:23,400 main.py:47] epoch 4097, training loss: 2091.72, average training loss: 1938.35, base loss: 2618.61
[INFO 2017-06-26 18:56:23,705 main.py:47] epoch 4098, training loss: 1694.90, average training loss: 1938.04, base loss: 2618.12
[INFO 2017-06-26 18:56:24,013 main.py:47] epoch 4099, training loss: 2168.29, average training loss: 1938.36, base loss: 2618.87
[INFO 2017-06-26 18:56:24,013 main.py:49] epoch 4099, testing
[INFO 2017-06-26 18:56:27,929 main.py:100] average testing loss: 1893.54, base loss: 2543.24
[INFO 2017-06-26 18:56:27,955 main.py:73] current best accuracy: 1787.83
[INFO 2017-06-26 18:56:28,265 main.py:47] epoch 4100, training loss: 1935.44, average training loss: 1938.49, base loss: 2619.10
[INFO 2017-06-26 18:56:28,570 main.py:47] epoch 4101, training loss: 1862.16, average training loss: 1938.42, base loss: 2618.88
[INFO 2017-06-26 18:56:28,877 main.py:47] epoch 4102, training loss: 1923.11, average training loss: 1938.16, base loss: 2618.43
[INFO 2017-06-26 18:56:29,185 main.py:47] epoch 4103, training loss: 1875.28, average training loss: 1937.82, base loss: 2617.77
[INFO 2017-06-26 18:56:29,491 main.py:47] epoch 4104, training loss: 1942.56, average training loss: 1937.85, base loss: 2617.63
[INFO 2017-06-26 18:56:29,797 main.py:47] epoch 4105, training loss: 2026.63, average training loss: 1937.81, base loss: 2617.80
[INFO 2017-06-26 18:56:30,103 main.py:47] epoch 4106, training loss: 2315.72, average training loss: 1938.13, base loss: 2618.27
[INFO 2017-06-26 18:56:30,414 main.py:47] epoch 4107, training loss: 1866.76, average training loss: 1938.06, base loss: 2618.43
[INFO 2017-06-26 18:56:30,722 main.py:47] epoch 4108, training loss: 2086.84, average training loss: 1938.37, base loss: 2618.81
[INFO 2017-06-26 18:56:31,030 main.py:47] epoch 4109, training loss: 1996.77, average training loss: 1938.39, base loss: 2618.90
[INFO 2017-06-26 18:56:31,335 main.py:47] epoch 4110, training loss: 2083.36, average training loss: 1938.47, base loss: 2618.84
[INFO 2017-06-26 18:56:31,639 main.py:47] epoch 4111, training loss: 1959.42, average training loss: 1938.64, base loss: 2619.26
[INFO 2017-06-26 18:56:31,943 main.py:47] epoch 4112, training loss: 1648.45, average training loss: 1938.48, base loss: 2618.90
[INFO 2017-06-26 18:56:32,246 main.py:47] epoch 4113, training loss: 2039.98, average training loss: 1938.48, base loss: 2618.85
[INFO 2017-06-26 18:56:32,553 main.py:47] epoch 4114, training loss: 1865.15, average training loss: 1938.77, base loss: 2619.37
[INFO 2017-06-26 18:56:32,857 main.py:47] epoch 4115, training loss: 2140.66, average training loss: 1939.00, base loss: 2619.75
[INFO 2017-06-26 18:56:33,163 main.py:47] epoch 4116, training loss: 1894.18, average training loss: 1938.75, base loss: 2619.47
[INFO 2017-06-26 18:56:33,467 main.py:47] epoch 4117, training loss: 2221.59, average training loss: 1939.28, base loss: 2620.19
[INFO 2017-06-26 18:56:33,773 main.py:47] epoch 4118, training loss: 1770.43, average training loss: 1939.00, base loss: 2619.76
[INFO 2017-06-26 18:56:34,075 main.py:47] epoch 4119, training loss: 2038.01, average training loss: 1939.07, base loss: 2620.05
[INFO 2017-06-26 18:56:34,382 main.py:47] epoch 4120, training loss: 1919.04, average training loss: 1938.74, base loss: 2619.90
[INFO 2017-06-26 18:56:34,689 main.py:47] epoch 4121, training loss: 1719.08, average training loss: 1938.42, base loss: 2619.37
[INFO 2017-06-26 18:56:34,992 main.py:47] epoch 4122, training loss: 2151.12, average training loss: 1938.84, base loss: 2620.23
[INFO 2017-06-26 18:56:35,295 main.py:47] epoch 4123, training loss: 1862.39, average training loss: 1939.06, base loss: 2620.60
[INFO 2017-06-26 18:56:35,603 main.py:47] epoch 4124, training loss: 2016.99, average training loss: 1939.29, base loss: 2621.14
[INFO 2017-06-26 18:56:35,911 main.py:47] epoch 4125, training loss: 1715.05, average training loss: 1938.82, base loss: 2620.68
[INFO 2017-06-26 18:56:36,220 main.py:47] epoch 4126, training loss: 2074.71, average training loss: 1938.62, base loss: 2620.18
[INFO 2017-06-26 18:56:36,528 main.py:47] epoch 4127, training loss: 2092.25, average training loss: 1938.72, base loss: 2620.48
[INFO 2017-06-26 18:56:36,836 main.py:47] epoch 4128, training loss: 2059.81, average training loss: 1938.98, base loss: 2620.77
[INFO 2017-06-26 18:56:37,144 main.py:47] epoch 4129, training loss: 2191.32, average training loss: 1939.31, base loss: 2621.13
[INFO 2017-06-26 18:56:37,450 main.py:47] epoch 4130, training loss: 1978.21, average training loss: 1939.23, base loss: 2621.08
[INFO 2017-06-26 18:56:37,760 main.py:47] epoch 4131, training loss: 1762.18, average training loss: 1939.31, base loss: 2621.14
[INFO 2017-06-26 18:56:38,067 main.py:47] epoch 4132, training loss: 2166.51, average training loss: 1939.43, base loss: 2621.14
[INFO 2017-06-26 18:56:38,375 main.py:47] epoch 4133, training loss: 1912.83, average training loss: 1939.48, base loss: 2621.24
[INFO 2017-06-26 18:56:38,682 main.py:47] epoch 4134, training loss: 1753.15, average training loss: 1939.37, base loss: 2620.91
[INFO 2017-06-26 18:56:38,992 main.py:47] epoch 4135, training loss: 1767.44, average training loss: 1939.16, base loss: 2620.52
[INFO 2017-06-26 18:56:39,307 main.py:47] epoch 4136, training loss: 1822.54, average training loss: 1939.16, base loss: 2620.44
[INFO 2017-06-26 18:56:39,637 main.py:47] epoch 4137, training loss: 1965.52, average training loss: 1939.21, base loss: 2620.81
[INFO 2017-06-26 18:56:39,956 main.py:47] epoch 4138, training loss: 1941.76, average training loss: 1939.59, base loss: 2621.60
[INFO 2017-06-26 18:56:40,267 main.py:47] epoch 4139, training loss: 2023.08, average training loss: 1939.78, base loss: 2621.89
[INFO 2017-06-26 18:56:40,573 main.py:47] epoch 4140, training loss: 2502.47, average training loss: 1940.20, base loss: 2622.46
[INFO 2017-06-26 18:56:40,880 main.py:47] epoch 4141, training loss: 1824.45, average training loss: 1940.21, base loss: 2622.15
[INFO 2017-06-26 18:56:41,184 main.py:47] epoch 4142, training loss: 1986.45, average training loss: 1940.17, base loss: 2621.96
[INFO 2017-06-26 18:56:41,496 main.py:47] epoch 4143, training loss: 1941.25, average training loss: 1940.39, base loss: 2622.57
[INFO 2017-06-26 18:56:41,806 main.py:47] epoch 4144, training loss: 2109.23, average training loss: 1940.41, base loss: 2622.41
[INFO 2017-06-26 18:56:42,110 main.py:47] epoch 4145, training loss: 1759.82, average training loss: 1939.84, base loss: 2621.65
[INFO 2017-06-26 18:56:42,416 main.py:47] epoch 4146, training loss: 1982.28, average training loss: 1940.03, base loss: 2622.03
